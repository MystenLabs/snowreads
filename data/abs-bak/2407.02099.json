{"id":"2407.02099","title":"Helpful assistant or fruitful facilitator? Investigating how personas\n  affect language model behavior","authors":"Pedro Henrique Luz de Araujo and Benjamin Roth","authorsParsed":[["de Araujo","Pedro Henrique Luz",""],["Roth","Benjamin",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 09:36:54 GMT"}],"updateDate":"2024-07-03","timestamp":1719913014000,"abstract":"  One way to personalize and steer generations from large language models (LLM)\nis to assign a persona: a role that describes how the user expects the LLM to\nbehave (e.g., a helpful assistant, a teacher, a woman). This paper investigates\nhow personas affect diverse aspects of model behavior. We assign to seven LLMs\n162 personas from 12 categories spanning variables like gender, sexual\norientation, and occupation. We prompt them to answer questions from five\ndatasets covering objective (e.g., questions about math and history) and\nsubjective tasks (e.g., questions about beliefs and values). We also compare\npersona's generations to two baseline settings: a control persona setting with\n30 paraphrases of \"a helpful assistant\" to control for models' prompt\nsensitivity, and an empty persona setting where no persona is assigned. We find\nthat for all models and datasets, personas show greater variability than the\ncontrol setting and that some measures of persona behavior generalize across\nmodels.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"hr2kFZdY3OaIxUhDMbZN8X9FK1xxwWqZp4M9P04evB8","pdfSize":"1641407","objectId":"0x2c15e81a4571f94507a9573e883e68d47f96ea1275a86fb80dd40ce11aea85eb","registeredEpoch":"3","certifiedEpoch":"3","startEpoch":"3","endEpoch":"203"}
