{"id":"2407.17115","title":"Reinforced Prompt Personalization for Recommendation with Large Language\n  Models","authors":"Wenyu Mao, Jiancan Wu, Weijian Chen, Chongming Gao, Xiang Wang,\n  Xiangnan He","authorsParsed":[["Mao","Wenyu",""],["Wu","Jiancan",""],["Chen","Weijian",""],["Gao","Chongming",""],["Wang","Xiang",""],["He","Xiangnan",""]],"versions":[{"version":"v1","created":"Wed, 24 Jul 2024 09:24:49 GMT"}],"updateDate":"2024-07-25","timestamp":1721813089000,"abstract":"  Designing effective prompts can empower LLMs to understand user preferences\nand provide recommendations by leveraging LLMs' intent comprehension and\nknowledge utilization capabilities. However, existing research predominantly\nconcentrates on task-wise prompting, developing fixed prompt templates composed\nof four patterns (i.e., role-playing, history records, reasoning guidance, and\noutput format) and applying them to all users for a given task. Although\nconvenient, task-wise prompting overlooks individual user differences, leading\nto potential mismatches in capturing user preferences. To address it, we\nintroduce the concept of instance-wise prompting to personalize discrete\nprompts for individual users and propose Reinforced Prompt Personalization\n(RPP) to optimize the four patterns in prompts using multi-agent reinforcement\nlearning (MARL). To boost efficiency, RPP formulates prompt personalization as\nselecting optimal sentences holistically across the four patterns, rather than\noptimizing word-by-word. To ensure the quality of prompts, RPP meticulously\ncrafts diverse expressions for each of the four patterns, considering multiple\nanalytical perspectives for specific recommendation tasks. In addition to RPP,\nour proposal of RPP+ aims to enhance the scalability of action space by\ndynamically refining actions with LLMs throughout the iterative process. We\nevaluate the effectiveness of RPP/RPP+ in ranking tasks over various datasets.\nExperimental results demonstrate the superiority of RPP/RPP+ over traditional\nrecommender models, few-shot methods, and other prompt-based methods,\nunderscoring the significance of instance-wise prompting for LLMs in\nrecommendation tasks and validating the effectiveness of RPP/RPP+. Our code is\navailable at https://github.com/maowenyu-11/RPP.\n","subjects":["Computing Research Repository/Information Retrieval"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"Ghb6BA7Yl_4YlDyy6bjDWqBjS0coJc4aBjkMIi80VxE","pdfSize":"4008276","objectId":"0xea80a0da8ef5e10634468a0fa04ce61fa4a325db0441634ee7958753dc78ee44","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
