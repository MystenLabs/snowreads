{"id":"2407.12680","title":"Reducing Biases towards Minoritized Populations in Medical Curricular\n  Content via Artificial Intelligence for Fairer Health Outcomes","authors":"Chiman Salavati and Shannon Song and Willmar Sosa Diaz and Scott A.\n  Hale and Roberto E. Montenegro and Fabricio Murai and Shiri Dori-Hacohen","authorsParsed":[["Salavati","Chiman",""],["Song","Shannon",""],["Diaz","Willmar Sosa",""],["Hale","Scott A.",""],["Montenegro","Roberto E.",""],["Murai","Fabricio",""],["Dori-Hacohen","Shiri",""]],"versions":[{"version":"v1","created":"Tue, 21 May 2024 04:11:18 GMT"}],"updateDate":"2024-07-18","timestamp":1716264678000,"abstract":"  Biased information (recently termed bisinformation) continues to be taught in\nmedical curricula, often long after having been debunked. In this paper, we\nintroduce BRICC, a firstin-class initiative that seeks to mitigate medical\nbisinformation using machine learning to systematically identify and flag text\nwith potential biases, for subsequent review in an expert-in-the-loop fashion,\nthus greatly accelerating an otherwise labor-intensive process. A gold-standard\nBRICC dataset was developed throughout several years, and contains over 12K\npages of instructional materials. Medical experts meticulously annotated these\ndocuments for bias according to comprehensive coding guidelines, emphasizing\ngender, sex, age, geography, ethnicity, and race. Using this labeled dataset,\nwe trained, validated, and tested medical bias classifiers. We test three\nclassifier approaches: a binary type-specific classifier, a general bias\nclassifier; an ensemble combining bias type-specific classifiers\nindependently-trained; and a multitask learning (MTL) model tasked with\npredicting both general and type-specific biases. While MTL led to some\nimprovement on race bias detection in terms of F1-score, it did not outperform\nbinary classifiers trained specifically on each task. On general bias\ndetection, the binary classifier achieves up to 0.923 of AUC, a 27.8%\nimprovement over the baseline. This work lays the foundations for debiasing\nmedical curricula by exploring a novel dataset and evaluating different\ntraining model strategies. Hence, it offers new pathways for more nuanced and\neffective mitigation of bisinformation.\n","subjects":["Computing Research Repository/Computers and Society","Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"D2vNmHRYMgUJqvreSBbJsfm51R-Qhp7derjRopO7hRw","pdfSize":"861737","objectId":"0x6ae8f6ecf6c676b038fd4dbe7ffe1d0313f1446b6378c1536deef60a0d5da8a6","registeredEpoch":"3","certifiedEpoch":"3","startEpoch":"3","endEpoch":"203"}
