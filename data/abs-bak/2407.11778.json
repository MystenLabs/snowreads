{"id":"2407.11778","title":"Local Feature Selection without Label or Feature Leakage for\n  Interpretable Machine Learning Predictions","authors":"Harrie Oosterhuis, Lijun Lyu, Avishek Anand","authorsParsed":[["Oosterhuis","Harrie",""],["Lyu","Lijun",""],["Anand","Avishek",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 14:36:30 GMT"}],"updateDate":"2024-07-17","timestamp":1721140590000,"abstract":"  Local feature selection in machine learning provides instance-specific\nexplanations by focusing on the most relevant features for each prediction,\nenhancing the interpretability of complex models. However, such methods tend to\nproduce misleading explanations by encoding additional information in their\nselections. In this work, we attribute the problem of misleading selections by\nformalizing the concepts of label and feature leakage. We rigorously derive the\nnecessary and sufficient conditions under which we can guarantee no leakage,\nand show existing methods do not meet these conditions. Furthermore, we propose\nthe first local feature selection method that is proven to have no leakage\ncalled SUWR. Our experimental results indicate that SUWR is less prone to\noverfitting and combines state-of-the-art predictive performance with high\nfeature-selection sparsity. Our generic and easily extendable formal approach\nprovides a strong theoretical basis for future work on interpretability with\nreliable explanations.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"s6FxZHEmIRgib3IWMAj9AbX2GxvDYP9u6qZ40RxdzzI","pdfSize":"853556","objectId":"0x3c9acc5442a1fd4fdbebed1eb577345b4ca010cd7e7b1b1aa4588863a3008f9e","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
