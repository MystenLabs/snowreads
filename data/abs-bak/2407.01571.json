{"id":"2407.01571","title":"Interpretable DRL-based Maneuver Decision of UCAV Dogfight","authors":"Haoran Han, Jian Cheng, Maolong Lv","authorsParsed":[["Han","Haoran",""],["Cheng","Jian",""],["Lv","Maolong",""]],"versions":[{"version":"v1","created":"Tue, 28 May 2024 00:43:47 GMT"}],"updateDate":"2024-07-03","timestamp":1716857027000,"abstract":"  This paper proposes a three-layer unmanned combat aerial vehicle (UCAV)\ndogfight frame where Deep reinforcement learning (DRL) is responsible for\nhigh-level maneuver decision. A four-channel low-level control law is firstly\nconstructed, followed by a library containing eight basic flight maneuvers\n(BFMs). Double deep Q network (DDQN) is applied for BFM selection in UCAV\ndogfight, where the opponent strategy during the training process is\nconstructed with DT. Our simulation result shows that, the agent can achieve a\nwin rate of 85.75% against the DT strategy, and positive results when facing\nvarious unseen opponents. Based on the proposed frame, interpretability of the\nDRL-based dogfight is significantly improved. The agent performs yo-yo to\nadjust its turn rate and gain higher maneuverability. Emergence of \"Dive and\nChase\" behavior also indicates the agent can generate a novel tactic that\nutilizes the drawback of its opponent.\n","subjects":["Computing Research Repository/Robotics","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/publicdomain/zero/1.0/","blobId":"Wl3kiXgQv-zWNELTwIxAYv6VKpqx2lrAg-XxWqaD7Pw","pdfSize":"5457329","objectId":"0xd73368f2166da69a75369c9f537fe7e764921c708450141b877230402acd0002","registeredEpoch":"3","certifiedEpoch":"3","startEpoch":"3","endEpoch":"203"}
