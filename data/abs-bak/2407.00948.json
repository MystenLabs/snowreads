{"id":"2407.00948","title":"The House Always Wins: A Framework for Evaluating Strategic Deception in\n  LLMs","authors":"Tanush Chopra and Michael Li","authorsParsed":[["Chopra","Tanush",""],["Li","Michael",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 04:07:49 GMT"}],"updateDate":"2024-07-02","timestamp":1719806869000,"abstract":"  We propose a framework for evaluating strategic deception in large language\nmodels (LLMs). In this framework, an LLM acts as a game master in two\nscenarios: one with random game mechanics and another where it can choose\nbetween random or deliberate actions. As an example, we use blackjack because\nthe action space nor strategies involve deception. We benchmark Llama3-70B,\nGPT-4-Turbo, and Mixtral in blackjack, comparing outcomes against expected\ndistributions in fair play to determine if LLMs develop strategies favoring the\n\"house.\" Our findings reveal that the LLMs exhibit significant deviations from\nfair play when given implicit randomness instructions, suggesting a tendency\ntowards strategic manipulation in ambiguous scenarios. However, when presented\nwith an explicit choice, the LLMs largely adhere to fair play, indicating that\nthe framing of instructions plays a crucial role in eliciting or mitigating\npotentially deceptive behaviors in AI systems.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"8WNJlRK3HuqUr5gzKDpiymMX4KhNsrM9_Bub3CqVwCo","pdfSize":"417808","objectId":"0xf28c841bcc66a8a5bd1b80476a841505131aa6bcc3700974b0461c2bd1854d22","registeredEpoch":"3","certifiedEpoch":"3","startEpoch":"3","endEpoch":"203"}
