{"id":"2407.08956","title":"DeCE: Deceptive Cross-Entropy Loss Designed for Defending Backdoor\n  Attacks","authors":"Guang Yang, Yu Zhou, Xiang Chen, Xiangyu Zhang, Terry Yue Zhuo, David\n  Lo, Taolue Chen","authorsParsed":[["Yang","Guang",""],["Zhou","Yu",""],["Chen","Xiang",""],["Zhang","Xiangyu",""],["Zhuo","Terry Yue",""],["Lo","David",""],["Chen","Taolue",""]],"versions":[{"version":"v1","created":"Fri, 12 Jul 2024 03:18:38 GMT"},{"version":"v2","created":"Wed, 21 Aug 2024 03:13:57 GMT"}],"updateDate":"2024-08-22","timestamp":1720754318000,"abstract":"  Code Language Models (CLMs), particularly those leveraging deep learning,\nhave achieved significant success in code intelligence domain. However, the\nissue of security, particularly backdoor attacks, is often overlooked in this\nprocess. The previous research has focused on designing backdoor attacks for\nCLMs, but effective defenses have not been adequately addressed. In particular,\nexisting defense methods from natural language processing, when directly\napplied to CLMs, are not effective enough and lack generality, working well in\nsome models and scenarios but failing in others, thus fall short in\nconsistently mitigating backdoor attacks. To bridge this gap, we first confirm\nthe phenomenon of ``early learning\" as a general occurrence during the training\nof CLMs. This phenomenon refers to that a model initially focuses on the main\nfeatures of training data but may become more sensitive to backdoor triggers\nover time, leading to overfitting and susceptibility to backdoor attacks. We\nthen analyze that overfitting to backdoor triggers results from the use of the\ncross-entropy loss function, where the unboundedness of cross-entropy leads the\nmodel to increasingly concentrate on the features of the poisoned data. Based\non this insight, we propose a general and effective loss function DeCE\n(Deceptive Cross-Entropy) by blending deceptive distributions and applying\nlabel smoothing to limit the gradient to be bounded, which prevents the model\nfrom overfitting to backdoor triggers and then enhances the security of CLMs\nagainst backdoor attacks. To verify the effectiveness of our defense method, we\nselect code synthesis tasks as our experimental scenarios. Our experiments\nacross various code synthesis datasets, models, and poisoning ratios\ndemonstrate the applicability and effectiveness of DeCE in enhancing the\nsecurity of CLMs.\n","subjects":["Computing Research Repository/Cryptography and Security","Computing Research Repository/Software Engineering"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"it1KaNFbKKjMX6TK5Bx_4-L9ydbT-9NlO_7HzNImpcM","pdfSize":"3093121","objectId":"0xa8661ef3991eab98f7d1e5babde4201d4eebf79af0df44dc448a5c1ce17338c8","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
