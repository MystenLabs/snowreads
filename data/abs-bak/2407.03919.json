{"id":"2407.03919","title":"MedRAT: Unpaired Medical Report Generation via Auxiliary Tasks","authors":"Elad Hirsch, Gefen Dawidowicz and Ayellet Tal","authorsParsed":[["Hirsch","Elad",""],["Dawidowicz","Gefen",""],["Tal","Ayellet",""]],"versions":[{"version":"v1","created":"Thu, 4 Jul 2024 13:31:47 GMT"},{"version":"v2","created":"Mon, 22 Jul 2024 07:49:34 GMT"}],"updateDate":"2024-07-23","timestamp":1720099907000,"abstract":"  Medical report generation from X-ray images is a challenging task,\nparticularly in an unpaired setting where paired image-report data is\nunavailable for training. To address this challenge, we propose a novel model\nthat leverages the available information in two distinct datasets, one\ncomprising reports and the other consisting of images. The core idea of our\nmodel revolves around the notion that combining auto-encoding report generation\nwith multi-modal (report-image) alignment can offer a solution. However, the\nchallenge persists regarding how to achieve this alignment when pair\ncorrespondence is absent. Our proposed solution involves the use of auxiliary\ntasks, particularly contrastive learning and classification, to position\nrelated images and reports in close proximity to each other. This approach\ndiffers from previous methods that rely on pre-processing steps, such as using\nexternal information stored in a knowledge graph. Our model, named MedRAT,\nsurpasses previous state-of-the-art methods, demonstrating the feasibility of\ngenerating comprehensive medical reports without the need for paired data or\nexternal tools.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/publicdomain/zero/1.0/","blobId":"Y8Z4RvcGmQX2uOYoU6xMZhY3nbzvMLUizXCfQXbmLT8","pdfSize":"1786755"}
