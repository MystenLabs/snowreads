{"id":"2407.11546","title":"V2X-M2C: Efficient Multi-Module Collaborative Perception with Two\n  Connections","authors":"Hyunchul Bae, Minhee Kang, Heejin Ahn","authorsParsed":[["Bae","Hyunchul",""],["Kang","Minhee",""],["Ahn","Heejin",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 09:51:52 GMT"}],"updateDate":"2024-07-17","timestamp":1721123512000,"abstract":"  In this paper, we investigate improving the perception performance of\nautonomous vehicles through communication with other vehicles and road\ninfrastructures. To this end, we introduce a collaborative perception model\n$\\textbf{V2X-M2C}$, consisting of multiple modules, each generating inter-agent\ncomplementary information, spatial global context, and spatial local\ninformation. Inspired by the question of why most existing architectures are\nsequential, we analyze both the $\\textit{sequential}$ and $\\textit{parallel}$\nconnections of the modules. The sequential connection synergizes the modules,\nwhereas the parallel connection independently improves each module. Extensive\nexperiments demonstrate that V2X-M2C achieves state-of-the-art perception\nperformance, increasing the detection accuracy by 8.00% to 10.87% and\ndecreasing the FLOPs by 42.81% to 52.64%.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"V67d7lC_x701SOmY1OqihB5GF_FVjVz2c6QyjkZK77E","pdfSize":"33007407","objectId":"0x294e48885bb447768cc09d68d0f38e628cfc59b4f8b36f8bd1d1be84a9999e59","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
