{"id":"2407.13519","title":"GPSFormer: A Global Perception and Local Structure Fitting-based\n  Transformer for Point Cloud Understanding","authors":"Changshuo Wang, Meiqing Wu, Siew-Kei Lam, Xin Ning, Shangshu Yu,\n  Ruiping Wang, Weijun Li, and Thambipillai Srikanthan","authorsParsed":[["Wang","Changshuo",""],["Wu","Meiqing",""],["Lam","Siew-Kei",""],["Ning","Xin",""],["Yu","Shangshu",""],["Wang","Ruiping",""],["Li","Weijun",""],["Srikanthan","Thambipillai",""]],"versions":[{"version":"v1","created":"Thu, 18 Jul 2024 13:53:15 GMT"},{"version":"v2","created":"Wed, 24 Jul 2024 08:23:26 GMT"}],"updateDate":"2024-07-25","timestamp":1721310795000,"abstract":"  Despite the significant advancements in pre-training methods for point cloud\nunderstanding, directly capturing intricate shape information from irregular\npoint clouds without reliance on external data remains a formidable challenge.\nTo address this problem, we propose GPSFormer, an innovative Global Perception\nand Local Structure Fitting-based Transformer, which learns detailed shape\ninformation from point clouds with remarkable precision. The core of GPSFormer\nis the Global Perception Module (GPM) and the Local Structure Fitting\nConvolution (LSFConv). Specifically, GPM utilizes Adaptive Deformable Graph\nConvolution (ADGConv) to identify short-range dependencies among similar\nfeatures in the feature space and employs Multi-Head Attention (MHA) to learn\nlong-range dependencies across all positions within the feature space,\nultimately enabling flexible learning of contextual representations. Inspired\nby Taylor series, we design LSFConv, which learns both low-order fundamental\nand high-order refinement information from explicitly encoded local geometric\nstructures. Integrating the GPM and LSFConv as fundamental components, we\nconstruct GPSFormer, a cutting-edge Transformer that effectively captures\nglobal and local structures of point clouds. Extensive experiments validate\nGPSFormer's effectiveness in three point cloud tasks: shape classification,\npart segmentation, and few-shot learning. The code of GPSFormer is available at\n\\url{https://github.com/changshuowang/GPSFormer}.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"QXRFVfjdqYWKu2MrkRzP6AYJC57xiYua662YIR-N6jU","pdfSize":"1191761","objectId":"0xc48c30ff36979eb8e0448a5aa3b6cd012ab721aad261cd46638d596562942d09","registeredEpoch":"3","certifiedEpoch":"3","startEpoch":"3","endEpoch":"203"}
