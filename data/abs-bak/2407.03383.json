{"id":"2407.03383","title":"Continuous Optimization for Offline Change Point Detection and\n  Estimation","authors":"Hans Reimann, Sarat Moka, and Georgy Sofronov","authorsParsed":[["Reimann","Hans",""],["Moka","Sarat",""],["Sofronov","Georgy",""]],"versions":[{"version":"v1","created":"Wed, 3 Jul 2024 01:19:59 GMT"}],"updateDate":"2024-07-08","timestamp":1719969599000,"abstract":"  This work explores use of novel advances in best subset selection for\nregression modelling via continuous optimization for offline change point\ndetection and estimation in univariate Gaussian data sequences. The approach\nexploits reformulating the normal mean multiple change point model into a\nregularized statistical inverse problem enforcing sparsity. After introducing\nthe problem statement, criteria and previous investigations via\nLasso-regularization, the recently developed framework of continuous\noptimization for best subset selection (COMBSS) is briefly introduced and\nrelated to the problem at hand. Supervised and unsupervised perspectives are\nexplored with the latter testing different approaches for the choice of\nregularization penalty parameters via the discrepancy principle and a\nconfidence bound. The main result is an adaptation and evaluation of the COMBSS\napproach for offline normal mean multiple change-point detection via\nexperimental results on simulated data for different choices of regularisation\nparameters. Results and future directions are discussed.\n","subjects":["Statistics/Methodology","Statistics/Computation","Statistics/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"pdcVvfOgv0OOqD_cXacAX8fggfZh0WxEN9KBR0ex2QY","pdfSize":"1244698"}
