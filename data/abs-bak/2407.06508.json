{"id":"2407.06508","title":"A Clinical Benchmark of Public Self-Supervised Pathology Foundation\n  Models","authors":"Gabriele Campanella and Shengjia Chen and Ruchika Verma and Jennifer\n  Zeng and Aryeh Stock and Matt Croken and Brandon Veremis and Abdulkadir Elmas\n  and Kuan-lin Huang and Ricky Kwan and Jane Houldsworth and Adam J. Schoenfeld\n  and Chad Vanderbilt","authorsParsed":[["Campanella","Gabriele",""],["Chen","Shengjia",""],["Verma","Ruchika",""],["Zeng","Jennifer",""],["Stock","Aryeh",""],["Croken","Matt",""],["Veremis","Brandon",""],["Elmas","Abdulkadir",""],["Huang","Kuan-lin",""],["Kwan","Ricky",""],["Houldsworth","Jane",""],["Schoenfeld","Adam J.",""],["Vanderbilt","Chad",""]],"versions":[{"version":"v1","created":"Tue, 9 Jul 2024 02:33:13 GMT"},{"version":"v2","created":"Wed, 10 Jul 2024 17:38:45 GMT"},{"version":"v3","created":"Thu, 11 Jul 2024 16:16:37 GMT"}],"updateDate":"2024-07-12","timestamp":1720492393000,"abstract":"  The use of self-supervised learning (SSL) to train pathology foundation\nmodels has increased substantially in the past few years. Notably, several\nmodels trained on large quantities of clinical data have been made publicly\navailable in recent months. This will significantly enhance scientific research\nin computational pathology and help bridge the gap between research and\nclinical deployment. With the increase in availability of public foundation\nmodels of different sizes, trained using different algorithms on different\ndatasets, it becomes important to establish a benchmark to compare the\nperformance of such models on a variety of clinically relevant tasks spanning\nmultiple organs and diseases. In this work, we present a collection of\npathology datasets comprising clinical slides associated with clinically\nrelevant endpoints including cancer diagnoses and a variety of biomarkers\ngenerated during standard hospital operation from two medical centers. We\nleverage these datasets to systematically assess the performance of public\npathology foundation models and provide insights into best practices for\ntraining new foundation models and selecting appropriate pretrained models.\n","subjects":["Electrical Engineering and Systems Science/Image and Video Processing","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"BRahwTKC3dafdtDWm11hXUSR38_DrsGKZEyJU0N0Jjs","pdfSize":"1768654"}
