{"id":"2407.05015","title":"How do you know that? Teaching Generative Language Models to Reference\n  Answers to Biomedical Questions","authors":"Bojana Ba\\v{s}aragin, Adela Ljaji\\'c, Darija Medvecki, Lorenzo\n  Cassano, Milo\\v{s} Ko\\v{s}prdi\\'c, Nikola Milo\\v{s}evi\\'c","authorsParsed":[["Bašaragin","Bojana",""],["Ljajić","Adela",""],["Medvecki","Darija",""],["Cassano","Lorenzo",""],["Košprdić","Miloš",""],["Milošević","Nikola",""]],"versions":[{"version":"v1","created":"Sat, 6 Jul 2024 09:10:05 GMT"}],"updateDate":"2024-07-09","timestamp":1720257005000,"abstract":"  Large language models (LLMs) have recently become the leading source of\nanswers for users' questions online. Despite their ability to offer eloquent\nanswers, their accuracy and reliability can pose a significant challenge. This\nis especially true for sensitive domains such as biomedicine, where there is a\nhigher need for factually correct answers. This paper introduces a biomedical\nretrieval-augmented generation (RAG) system designed to enhance the reliability\nof generated responses. The system is based on a fine-tuned LLM for the\nreferenced question-answering, where retrieved relevant abstracts from PubMed\nare passed to LLM's context as input through a prompt. Its output is an answer\nbased on PubMed abstracts, where each statement is referenced accordingly,\nallowing the users to verify the answer. Our retrieval system achieves an\nabsolute improvement of 23% compared to the PubMed search engine. Based on the\nmanual evaluation on a small sample, our fine-tuned LLM component achieves\ncomparable results to GPT-4 Turbo in referencing relevant abstracts. We make\nthe dataset used to fine-tune the models and the fine-tuned models based on\nMistral-7B-instruct-v0.1 and v0.2 publicly available.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by-sa/4.0/","blobId":"-5bwnyNA8yK1JaAJVHgRjTLqv5A-cavXYXCXGN4g2Y0","pdfSize":"320301"}
