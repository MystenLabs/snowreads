{"id":"2407.08726","title":"Map It Anywhere (MIA): Empowering Bird's Eye View Mapping using\n  Large-scale Public Data","authors":"Cherie Ho, Jiaye Zou, Omar Alama, Sai Mitheran Jagadesh Kumar,\n  Benjamin Chiang, Taneesh Gupta, Chen Wang, Nikhil Keetha, Katia Sycara,\n  Sebastian Scherer","authorsParsed":[["Ho","Cherie",""],["Zou","Jiaye",""],["Alama","Omar",""],["Kumar","Sai Mitheran Jagadesh",""],["Chiang","Benjamin",""],["Gupta","Taneesh",""],["Wang","Chen",""],["Keetha","Nikhil",""],["Sycara","Katia",""],["Scherer","Sebastian",""]],"versions":[{"version":"v1","created":"Thu, 11 Jul 2024 17:57:22 GMT"}],"updateDate":"2024-07-12","timestamp":1720720642000,"abstract":"  Top-down Bird's Eye View (BEV) maps are a popular representation for ground\nrobot navigation due to their richness and flexibility for downstream tasks.\nWhile recent methods have shown promise for predicting BEV maps from\nFirst-Person View (FPV) images, their generalizability is limited to small\nregions captured by current autonomous vehicle-based datasets. In this context,\nwe show that a more scalable approach towards generalizable map prediction can\nbe enabled by using two large-scale crowd-sourced mapping platforms, Mapillary\nfor FPV images and OpenStreetMap for BEV semantic maps. We introduce Map It\nAnywhere (MIA), a data engine that enables seamless curation and modeling of\nlabeled map prediction data from existing open-source map platforms. Using our\nMIA data engine, we display the ease of automatically collecting a dataset of\n1.2 million pairs of FPV images & BEV maps encompassing diverse geographies,\nlandscapes, environmental factors, camera models & capture scenarios. We\nfurther train a simple camera model-agnostic model on this data for BEV map\nprediction. Extensive evaluations using established benchmarks and our dataset\nshow that the data curated by MIA enables effective pretraining for\ngeneralizable BEV map prediction, with zero-shot performance far exceeding\nbaselines trained on existing datasets by 35%. Our analysis highlights the\npromise of using large-scale public maps for developing & testing generalizable\nBEV perception, paving the way for more robust autonomous navigation.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"wuho33_qnRZZzO8ATCBFwcpmXfj_5LFjpRvNrsQMU1g","pdfSize":"10447530","objectId":"0xb2a9e94a7b21a41b4a76e5bb33ae0cf5558954f12d42cb2a2dd0598f04f4e970","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
