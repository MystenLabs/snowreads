{"id":"2407.06078","title":"Few-Shot Keyword Spotting from Mixed Speech","authors":"Junming Yuan, Ying Shi, LanTian Li, Dong Wang, Askar Hamdulla","authorsParsed":[["Yuan","Junming",""],["Shi","Ying",""],["Li","LanTian",""],["Wang","Dong",""],["Hamdulla","Askar",""]],"versions":[{"version":"v1","created":"Fri, 5 Jul 2024 02:05:53 GMT"}],"updateDate":"2024-07-09","timestamp":1720145153000,"abstract":"  Few-shot keyword spotting (KWS) aims to detect unknown keywords with limited\ntraining samples. A commonly used approach is the pre-training and fine-tuning\nframework. While effective in clean conditions, this approach struggles with\nmixed keyword spotting -- simultaneously detecting multiple keywords blended in\nan utterance, which is crucial in real-world applications. Previous research\nhas proposed a Mix-Training (MT) approach to solve the problem, however, it has\nnever been tested in the few-shot scenario. In this paper, we investigate the\npossibility of using MT and other relevant methods to solve the two practical\nchallenges together: few-shot and mixed speech. Experiments conducted on the\nLibriSpeech and Google Speech Command corpora demonstrate that MT is highly\neffective on this task when employed in either the pre-training phase or the\nfine-tuning phase. Moreover, combining SSL-based large-scale pre-training\n(HuBert) and MT fine-tuning yields very strong results in all the test\nconditions.\n","subjects":["Computing Research Repository/Sound"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"Oe5xnEKvajD3GXmFAdtJ8Lbz3ThvP2RYq-w0NkaxzqE","pdfSize":"108766"}
