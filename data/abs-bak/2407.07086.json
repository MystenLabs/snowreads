{"id":"2407.07086","title":"Hypothetical Minds: Scaffolding Theory of Mind for Multi-Agent Tasks\n  with Large Language Models","authors":"Logan Cross, Violet Xiang, Agam Bhatia, Daniel LK Yamins, Nick Haber","authorsParsed":[["Cross","Logan",""],["Xiang","Violet",""],["Bhatia","Agam",""],["Yamins","Daniel LK",""],["Haber","Nick",""]],"versions":[{"version":"v1","created":"Tue, 9 Jul 2024 17:57:15 GMT"}],"updateDate":"2024-07-10","timestamp":1720547835000,"abstract":"  Multi-agent reinforcement learning (MARL) methods struggle with the\nnon-stationarity of multi-agent systems and fail to adaptively learn online\nwhen tested with novel agents. Here, we leverage large language models (LLMs)\nto create an autonomous agent that can handle these challenges. Our agent,\nHypothetical Minds, consists of a cognitively-inspired architecture, featuring\nmodular components for perception, memory, and hierarchical planning over two\nlevels of abstraction. We introduce the Theory of Mind module that scaffolds\nthe high-level planning process by generating hypotheses about other agents'\nstrategies in natural language. It then evaluates and iteratively refines these\nhypotheses by reinforcing hypotheses that make correct predictions about the\nother agents' behavior. Hypothetical Minds significantly improves performance\nover previous LLM-agent and RL baselines on a range of competitive, mixed\nmotive, and collaborative domains in the Melting Pot benchmark, including both\ndyadic and population-based environments. Additionally, comparisons against\nLLM-agent baselines and ablations reveal the importance of hypothesis\nevaluation and refinement for succeeding on complex scenarios.\n","subjects":["Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"a5O-gvHxYydETRb4RxJCEsgq4EBeeaS8teYKisDKP1o","pdfSize":"3519277"}
