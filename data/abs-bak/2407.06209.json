{"id":"2407.06209","title":"Self-supervised Pretraining for Partial Differential Equations","authors":"Varun Madhavan and Amal S Sebastian and Bharath Ramsundar and\n  Venkatasubramanian Viswanathan","authorsParsed":[["Madhavan","Varun",""],["Sebastian","Amal S",""],["Ramsundar","Bharath",""],["Viswanathan","Venkatasubramanian",""]],"versions":[{"version":"v1","created":"Wed, 3 Jul 2024 16:39:32 GMT"}],"updateDate":"2024-07-10","timestamp":1720024772000,"abstract":"  In this work, we describe a novel approach to building a neural PDE solver\nleveraging recent advances in transformer based neural network architectures.\nOur model can provide solutions for different values of PDE parameters without\nany need for retraining the network. The training is carried out in a\nself-supervised manner, similar to pretraining approaches applied in language\nand vision tasks. We hypothesize that the model is in effect learning a family\nof operators (for multiple parameters) mapping the initial condition to the\nsolution of the PDE at any future time step t. We compare this approach with\nthe Fourier Neural Operator (FNO), and demonstrate that it can generalize over\nthe space of PDE parameters, despite having a higher prediction error for\nindividual parameter values compared to the FNO. We show that performance on a\nspecific parameter can be improved by finetuning the model with very small\namounts of data. We also demonstrate that the model scales with data as well as\nmodel size.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"udyK64hKc6TfbRVDEnVI05fxXJwEnZqIG9B_jL8jKLc","pdfSize":"500163"}
