{"id":"2407.18421","title":"Self-Directed Synthetic Dialogues and Revisions Technical Report","authors":"Nathan Lambert, Hailey Schoelkopf, Aaron Gokaslan, Luca Soldaini,\n  Valentina Pyatkin, Louis Castricato","authorsParsed":[["Lambert","Nathan",""],["Schoelkopf","Hailey",""],["Gokaslan","Aaron",""],["Soldaini","Luca",""],["Pyatkin","Valentina",""],["Castricato","Louis",""]],"versions":[{"version":"v1","created":"Thu, 25 Jul 2024 22:42:36 GMT"}],"updateDate":"2024-07-29","timestamp":1721947356000,"abstract":"  Synthetic data has become an important tool in the fine-tuning of language\nmodels to follow instructions and solve complex problems. Nevertheless, the\nmajority of open data to date is often lacking multi-turn data and collected on\nclosed models, limiting progress on advancing open fine-tuning methods. We\nintroduce Self Directed Synthetic Dialogues (SDSD), an experimental dataset\nconsisting of guided conversations of language models talking to themselves.\nThe dataset consists of multi-turn conversations generated with DBRX, Llama 2\n70B, and Mistral Large, all instructed to follow a conversation plan generated\nprior to the conversation. We also explore including principles from\nConstitutional AI and other related works to create synthetic preference data\nvia revisions to the final conversation turn. We hope this work encourages\nfurther exploration in multi-turn data and the use of open models for expanding\nthe impact of synthetic data.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"CeQVh0RCfNCRmcsiwEgPOer-av6Jryfmg94en_EdV70","pdfSize":"1121777","objectId":"0x5cc98d59b63c55c98148a8eb9014368ec20811ac4294897f61ed57413cf60b35","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
