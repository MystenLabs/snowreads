{"id":"2407.20229","title":"Improving 2D Feature Representations by 3D-Aware Fine-Tuning","authors":"Yuanwen Yue, Anurag Das, Francis Engelmann, Siyu Tang, Jan Eric\n  Lenssen","authorsParsed":[["Yue","Yuanwen",""],["Das","Anurag",""],["Engelmann","Francis",""],["Tang","Siyu",""],["Lenssen","Jan Eric",""]],"versions":[{"version":"v1","created":"Mon, 29 Jul 2024 17:59:21 GMT"}],"updateDate":"2024-07-30","timestamp":1722275961000,"abstract":"  Current visual foundation models are trained purely on unstructured 2D data,\nlimiting their understanding of 3D structure of objects and scenes. In this\nwork, we show that fine-tuning on 3D-aware data improves the quality of\nemerging semantic features. We design a method to lift semantic 2D features\ninto an efficient 3D Gaussian representation, which allows us to re-render them\nfor arbitrary views. Using the rendered 3D-aware features, we design a\nfine-tuning strategy to transfer such 3D awareness into a 2D foundation model.\nWe demonstrate that models fine-tuned in that way produce features that readily\nimprove downstream task performance in semantic segmentation and depth\nestimation through simple linear probing. Notably, though fined-tuned on a\nsingle indoor dataset, the improvement is transferable to a variety of indoor\ndatasets and out-of-domain datasets. We hope our study encourages the community\nto consider injecting 3D awareness when training 2D foundation models. Project\npage: https://ywyue.github.io/FiT3D.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"fKzzjsXWDbqxHxzqZnLodjp_G322VXhb9S_DB5bNzJI","pdfSize":"19331022","objectId":"0x58337de0e23536a2f89cab988b6144b10e7625aaba700e3e590fdb61ae2910c6","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
