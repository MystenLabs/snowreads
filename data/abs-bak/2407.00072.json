{"id":"2407.00072","title":"Pistis-RAG: A Scalable Cascading Framework Towards Trustworthy\n  Retrieval-Augmented Generation","authors":"Yu Bai, Yukai Miao, Li Chen, Dan Li, Yanyu Ren, Hongtao Xie, Ce Yang,\n  Xuhui Cai","authorsParsed":[["Bai","Yu",""],["Miao","Yukai",""],["Chen","Li",""],["Li","Dan",""],["Ren","Yanyu",""],["Xie","Hongtao",""],["Yang","Ce",""],["Cai","Xuhui",""]],"versions":[{"version":"v1","created":"Fri, 21 Jun 2024 08:52:11 GMT"},{"version":"v2","created":"Wed, 3 Jul 2024 06:54:16 GMT"},{"version":"v3","created":"Thu, 11 Jul 2024 09:28:34 GMT"},{"version":"v4","created":"Thu, 1 Aug 2024 06:56:15 GMT"}],"updateDate":"2024-08-02","timestamp":1718959931000,"abstract":"  In Greek mythology, Pistis symbolized good faith, trust, and reliability.\nDrawing inspiration from these principles, Pistis-RAG is a scalable multi-stage\nframework designed to address the challenges of large-scale retrieval-augmented\ngeneration (RAG) systems. This framework consists of distinct stages: matching,\npre-ranking, ranking, reasoning, and aggregating. Each stage contributes to\nnarrowing the search space, prioritizing semantically relevant documents,\naligning with the large language model's (LLM) preferences, supporting complex\nchain-of-thought (CoT) methods, and combining information from multiple\nsources.\n  Our ranking stage introduces a significant innovation by recognizing that\nsemantic relevance alone may not lead to improved generation quality, due to\nthe sensitivity of the few-shot prompt order, as noted in previous research.\nThis critical aspect is often overlooked in current RAG frameworks.\n  We argue that the alignment issue between LLMs and external knowledge ranking\nmethods is tied to the model-centric paradigm dominant in RAG systems. We\npropose a content-centric approach, emphasizing seamless integration between\nLLMs and external information sources to optimize content transformation for\nspecific tasks.\n  Our novel ranking stage is designed specifically for RAG systems,\nincorporating principles of information retrieval while considering the unique\nbusiness scenarios reflected in LLM preferences and user feedback. We simulated\nfeedback signals on the MMLU benchmark, resulting in a 9.3% performance\nimprovement. Our model and code will be open-sourced on GitHub. Additionally,\nexperiments on real-world, large-scale data validate the scalability of our\nframework.\n","subjects":["Computing Research Repository/Information Retrieval","Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"85UwdTHdA44b-jxhF0gPhdoEaHXfdNf1qt2NMSOJ3Nw","pdfSize":"822006","objectId":"0xbee65c980cd0b5ae5da08e44df0bf9f758ca7b4181ee508946a93b0fc8fbef5c","registeredEpoch":"1","certifiedEpoch":"1","startEpoch":"1","endEpoch":"201"}
