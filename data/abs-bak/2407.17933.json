{"id":"2407.17933","title":"Segmentation by registration-enabled SAM prompt engineering using five\n  reference images","authors":"Yaxi Chen, Aleksandra Ivanova, Shaheer U. Saeed, Rikin Hargunani, Jie\n  Huang, Chaozong Liu, Yipeng Hu","authorsParsed":[["Chen","Yaxi",""],["Ivanova","Aleksandra",""],["Saeed","Shaheer U.",""],["Hargunani","Rikin",""],["Huang","Jie",""],["Liu","Chaozong",""],["Hu","Yipeng",""]],"versions":[{"version":"v1","created":"Thu, 25 Jul 2024 10:46:29 GMT"}],"updateDate":"2024-07-26","timestamp":1721904389000,"abstract":"  The recently proposed Segment Anything Model (SAM) is a general tool for\nimage segmentation, but it requires additional adaptation and careful\nfine-tuning for medical image segmentation, especially for small,\nirregularly-shaped, and boundary-ambiguous anatomical structures such as the\nknee cartilage that is of interest in this work. Repaired cartilage, after\ncertain surgical procedures, exhibits imaging patterns unseen to pre-training,\nposing further challenges for using models like SAM with or without\ngeneral-purpose fine-tuning. To address this, we propose a novel\nregistration-based prompt engineering framework for medical image segmentation\nusing SAM. This approach utilises established image registration algorithms to\nalign the new image (to-be-segmented) and a small number of reference images,\nwithout requiring segmentation labels. The spatial transformations generated by\nregistration align either the new image or pre-defined point-based prompts,\nbefore using them as input to SAM. This strategy, requiring as few as five\nreference images with defined point prompts, effectively prompts SAM for\ninference on new images, without needing any segmentation labels. Evaluation of\nMR images from patients who received cartilage stem cell therapy yielded Dice\nscores of 0.89, 0.87, 0.53, and 0.52 for segmenting femur, tibia, femoral- and\ntibial cartilages, respectively. This outperforms atlas-based label fusion and\nis comparable to supervised nnUNet, an upper-bound fair baseline in this\napplication, both of which require full segmentation labels for reference\nsamples. The codes are available at:\nhttps://github.com/chrissyinreallife/KneeSegmentWithSAM.git\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"sj0ojAJTWq53Lrp-lS6iXuayjTCy6Pa6jBirWfLIdjw","pdfSize":"656871","objectId":"0xacea9d29239c1aba2b795a32169292d6c8652a8244266ffb5645a4d4adfbd723","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
