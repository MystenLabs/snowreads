{"id":"2407.05734","title":"Empirical Study of Symmetrical Reasoning in Conversational Chatbots","authors":"Daniela N. Rim, Heeyoul Choi","authorsParsed":[["Rim","Daniela N.",""],["Choi","Heeyoul",""]],"versions":[{"version":"v1","created":"Mon, 8 Jul 2024 08:38:43 GMT"}],"updateDate":"2024-07-09","timestamp":1720427923000,"abstract":"  This work explores the capability of conversational chatbots powered by large\nlanguage models (LLMs), to understand and characterize predicate symmetry, a\ncognitive linguistic function traditionally believed to be an inherent human\ntrait. Leveraging in-context learning (ICL), a paradigm shift enabling chatbots\nto learn new tasks from prompts without re-training, we assess the symmetrical\nreasoning of five chatbots: ChatGPT 4, Huggingface chat AI, Microsoft's Copilot\nAI, LLaMA through Perplexity, and Gemini Advanced. Using the Symmetry Inference\nSentence (SIS) dataset by Tanchip et al. (2020), we compare chatbot responses\nagainst human evaluations to gauge their understanding of predicate symmetry.\nExperiment results reveal varied performance among chatbots, with some\napproaching human-like reasoning capabilities. Gemini, for example, reaches a\ncorrelation of 0.85 with human scores, while providing a sounding justification\nfor each symmetry evaluation. This study underscores the potential and\nlimitations of LLMs in mirroring complex cognitive processes as symmetrical\nreasoning.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"KbHOOVsNngdgLK-JRSU1VaJ-ewG3t-QB8KOPWNer3B0","pdfSize":"311336"}
