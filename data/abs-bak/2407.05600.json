{"id":"2407.05600","title":"GenArtist: Multimodal LLM as an Agent for Unified Image Generation and\n  Editing","authors":"Zhenyu Wang, Aoxue Li, Zhenguo Li, Xihui Liu","authorsParsed":[["Wang","Zhenyu",""],["Li","Aoxue",""],["Li","Zhenguo",""],["Liu","Xihui",""]],"versions":[{"version":"v1","created":"Mon, 8 Jul 2024 04:30:53 GMT"}],"updateDate":"2024-07-09","timestamp":1720413053000,"abstract":"  Despite the success achieved by existing image generation and editing\nmethods, current models still struggle with complex problems including\nintricate text prompts, and the absence of verification and self-correction\nmechanisms makes the generated images unreliable. Meanwhile, a single model\ntends to specialize in particular tasks and possess the corresponding\ncapabilities, making it inadequate for fulfilling all user requirements. We\npropose GenArtist, a unified image generation and editing system, coordinated\nby a multimodal large language model (MLLM) agent. We integrate a comprehensive\nrange of existing models into the tool library and utilize the agent for tool\nselection and execution. For a complex problem, the MLLM agent decomposes it\ninto simpler sub-problems and constructs a tree structure to systematically\nplan the procedure of generation, editing, and self-correction with\nstep-by-step verification. By automatically generating missing position-related\ninputs and incorporating position information, the appropriate tool can be\neffectively employed to address each sub-problem. Experiments demonstrate that\nGenArtist can perform various generation and editing tasks, achieving\nstate-of-the-art performance and surpassing existing models such as SDXL and\nDALL-E 3, as can be seen in Fig. 1. Project page is\nhttps://zhenyuw16.github.io/GenArtist_page.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"Yy674ZDMh6QaT801jb3r8SuZwZyhMZkDFLaSf9rYhvE","pdfSize":"6657932"}
