{"id":"2407.14332","title":"Unravelling in Collaborative Learning","authors":"Aymeric Capitaine, Etienne Boursier, Antoine Scheid, Eric Moulines,\n  Michael I. Jordan, El-Mahdi El-Mhamdi and Alain Durmus","authorsParsed":[["Capitaine","Aymeric",""],["Boursier","Etienne",""],["Scheid","Antoine",""],["Moulines","Eric",""],["Jordan","Michael I.",""],["El-Mhamdi","El-Mahdi",""],["Durmus","Alain",""]],"versions":[{"version":"v1","created":"Fri, 19 Jul 2024 14:12:48 GMT"}],"updateDate":"2024-07-22","timestamp":1721398368000,"abstract":"  Collaborative learning offers a promising avenue for leveraging decentralized\ndata. However, collaboration in groups of strategic learners is not a given. In\nthis work, we consider strategic agents who wish to train a model together but\nhave sampling distributions of different quality. The collaboration is\norganized by a benevolent aggregator who gathers samples so as to maximize\ntotal welfare, but is unaware of data quality. This setting allows us to shed\nlight on the deleterious effect of adverse selection in collaborative learning.\nMore precisely, we demonstrate that when data quality indices are private, the\ncoalition may undergo a phenomenon known as unravelling, wherein it shrinks up\nto the point that it becomes empty or solely comprised of the worst agent. We\nshow how this issue can be addressed without making use of external transfers,\nby proposing a novel method inspired by probabilistic verification. This\napproach makes the grand coalition a Nash equilibrium with high probability\ndespite information asymmetry, thereby breaking unravelling.\n","subjects":["Computing Research Repository/Computer Science and Game Theory"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"sY9CAN7pwyNOJXOg5czRCZGrBQZXANwdkYy0IQI5V28","pdfSize":"380766","objectId":"0x4515d99616b78e3d65119b6d715f1faa3f00d5b934d27766cf7762a9cc16d977","registeredEpoch":"1","certifiedEpoch":"1","startEpoch":"1","endEpoch":"201"}
