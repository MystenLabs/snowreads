{"id":"2407.07042","title":"ProtoSAM: One-Shot Medical Image Segmentation With Foundational Models","authors":"Lev Ayzenberg, Raja Giryes, Hayit Greenspan","authorsParsed":[["Ayzenberg","Lev",""],["Giryes","Raja",""],["Greenspan","Hayit",""]],"versions":[{"version":"v1","created":"Tue, 9 Jul 2024 17:04:08 GMT"},{"version":"v2","created":"Thu, 18 Jul 2024 07:58:11 GMT"}],"updateDate":"2024-07-19","timestamp":1720544648000,"abstract":"  This work introduces a new framework, ProtoSAM, for one-shot medical image\nsegmentation. It combines the use of prototypical networks, known for few-shot\nsegmentation, with SAM - a natural image foundation model. The method proposed\ncreates an initial coarse segmentation mask using the ALPnet prototypical\nnetwork, augmented with a DINOv2 encoder. Following the extraction of an\ninitial mask, prompts are extracted, such as points and bounding boxes, which\nare then input into the Segment Anything Model (SAM). State-of-the-art results\nare shown on several medical image datasets and demonstrate automated\nsegmentation capabilities using a single image example (one shot) with no need\nfor fine-tuning of the foundation model. Our code is available at:\nhttps://github.com/levayz/ProtoSAM\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"YmuKDC-y5PA0V_UXc2Sfupw66Du9olqdz37wKpYQdTc","pdfSize":"4927157"}
