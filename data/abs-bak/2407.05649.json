{"id":"2407.05649","title":"Graph Attention with Random Rewiring","authors":"Tongzhou Liao, Barnab\\'as P\\'oczos","authorsParsed":[["Liao","Tongzhou",""],["Póczos","Barnabás",""]],"versions":[{"version":"v1","created":"Mon, 8 Jul 2024 06:21:56 GMT"},{"version":"v2","created":"Thu, 18 Jul 2024 07:30:43 GMT"}],"updateDate":"2024-07-19","timestamp":1720419716000,"abstract":"  Graph Neural Networks (GNNs) have become fundamental in graph-structured deep\nlearning. Key paradigms of modern GNNs include message passing, graph rewiring,\nand Graph Transformers. This paper introduces Graph-Rewiring Attention with\nStochastic Structures (GRASS), a novel GNN architecture that combines the\nadvantages of these three paradigms. GRASS rewires the input graph by\nsuperimposing a random regular graph, enhancing long-range information\npropagation while preserving structural features of the input graph. It also\nemploys a unique additive attention mechanism tailored for graph-structured\ndata, providing a graph inductive bias while remaining computationally\nefficient. Our empirical evaluations demonstrate that GRASS achieves\nstate-of-the-art performance on multiple benchmark datasets, confirming its\npractical efficacy.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Neural and Evolutionary Computing"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"okQxTrCDfgePSiK_rX8LkV06HlArBvhMbAl4020NZWY","pdfSize":"531275"}
