{"id":"2407.01777","title":"Deepfake Audio Detection Using Spectrogram-based Feature and Ensemble of\n  Deep Learning Models","authors":"Lam Pham, Phat Lam, Truong Nguyen, Huyen Nguyen, Alexander Schindler","authorsParsed":[["Pham","Lam",""],["Lam","Phat",""],["Nguyen","Truong",""],["Nguyen","Huyen",""],["Schindler","Alexander",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 20:10:43 GMT"}],"updateDate":"2024-07-03","timestamp":1719864643000,"abstract":"  In this paper, we propose a deep learning based system for the task of\ndeepfake audio detection. In particular, the draw input audio is first\ntransformed into various spectrograms using three transformation methods of\nShort-time Fourier Transform (STFT), Constant-Q Transform (CQT), Wavelet\nTransform (WT) combined with different auditory-based filters of Mel,\nGammatone, linear filters (LF), and discrete cosine transform (DCT). Given the\nspectrograms, we evaluate a wide range of classification models based on three\ndeep learning approaches. The first approach is to train directly the\nspectrograms using our proposed baseline models of CNN-based model\n(CNN-baseline), RNN-based model (RNN-baseline), C-RNN model (C-RNN baseline).\nMeanwhile, the second approach is transfer learning from computer vision models\nsuch as ResNet-18, MobileNet-V3, EfficientNet-B0, DenseNet-121, SuffleNet-V2,\nSwint, Convnext-Tiny, GoogLeNet, MNASsnet, RegNet. In the third approach, we\nleverage the state-of-the-art audio pre-trained models of Whisper, Seamless,\nSpeechbrain, and Pyannote to extract audio embeddings from the input\nspectrograms. Then, the audio embeddings are explored by a Multilayer\nperceptron (MLP) model to detect the fake or real audio samples. Finally,\nhigh-performance deep learning models from these approaches are fused to\nachieve the best performance. We evaluated our proposed models on ASVspoof 2019\nbenchmark dataset. Our best ensemble model achieved an Equal Error Rate (EER)\nof 0.03, which is highly competitive to top-performing systems in the\nASVspoofing 2019 challenge. Experimental results also highlight the potential\nof selective spectrograms and deep learning approaches to enhance the task of\naudio deepfake detection.\n","subjects":["Computing Research Repository/Sound","Computing Research Repository/Artificial Intelligence","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"AjmKhLjWIQJkXaQyC4JHOdCE5O9DskuwxRjfT3bXoiE","pdfSize":"426216","objectId":"0xb0698a0da6873961bc91de4bcb9cefb7dffdd7e24e7061a82e6ee4d6d7a8ecb2","registeredEpoch":"3","certifiedEpoch":"3","startEpoch":"3","endEpoch":"203"}
