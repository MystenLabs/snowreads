{"id":"2407.17902","title":"Multi-Stage Face-Voice Association Learning with Keynote Speaker\n  Diarization","authors":"Ruijie Tao, Zhan Shi, Yidi Jiang, Duc-Tuan Truong, Eng-Siong Chng,\n  Massimo Alioto, Haizhou Li","authorsParsed":[["Tao","Ruijie",""],["Shi","Zhan",""],["Jiang","Yidi",""],["Truong","Duc-Tuan",""],["Chng","Eng-Siong",""],["Alioto","Massimo",""],["Li","Haizhou",""]],"versions":[{"version":"v1","created":"Thu, 25 Jul 2024 09:46:04 GMT"}],"updateDate":"2024-07-26","timestamp":1721900764000,"abstract":"  The human brain has the capability to associate the unknown person's voice\nand face by leveraging their general relationship, referred to as ``cross-modal\nspeaker verification''. This task poses significant challenges due to the\ncomplex relationship between the modalities. In this paper, we propose a\n``Multi-stage Face-voice Association Learning with Keynote Speaker\nDiarization''~(MFV-KSD) framework. MFV-KSD contains a keynote speaker\ndiarization front-end to effectively address the noisy speech inputs issue. To\nbalance and enhance the intra-modal feature learning and inter-modal\ncorrelation understanding, MFV-KSD utilizes a novel three-stage training\nstrategy. Our experimental results demonstrated robust performance, achieving\nthe first rank in the 2024 Face-voice Association in Multilingual Environments\n(FAME) challenge with an overall Equal Error Rate (EER) of 19.9%. Details can\nbe found in https://github.com/TaoRuijie/MFV-KSD.\n","subjects":["Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"xOT35Gm77xPqroPXgrQM83rtIBzMgJFvdXLExuwMFC8","pdfSize":"1654500","objectId":"0x76e8b2bb4634c0efee82b2daa1073b7847624c177b8ce1ca27b321160edd27e3","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
