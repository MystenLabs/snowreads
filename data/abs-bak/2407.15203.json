{"id":"2407.15203","title":"Mask Guided Gated Convolution for Amodal Content Completion","authors":"Kaziwa Saleh, S\\'andor Sz\\'en\\'asi, Zolt\\'an V\\'amossy","authorsParsed":[["Saleh","Kaziwa",""],["Szénási","Sándor",""],["Vámossy","Zoltán",""]],"versions":[{"version":"v1","created":"Sun, 21 Jul 2024 15:51:29 GMT"}],"updateDate":"2024-07-23","timestamp":1721577089000,"abstract":"  We present a model to reconstruct partially visible objects. The model takes\na mask as an input, which we call weighted mask. The mask is utilized by gated\nconvolutions to assign more weight to the visible pixels of the occluded\ninstance compared to the background, while ignoring the features of the\ninvisible pixels. By drawing more attention from the visible region, our model\ncan predict the invisible patch more effectively than the baseline models,\nespecially in instances with uniform texture. The model is trained on COCOA\ndataset and two subsets of it in a self-supervised manner. The results\ndemonstrate that our model generates higher quality and more texture-rich\noutputs compared to baseline models. Code is available at:\nhttps://github.com/KaziwaSaleh/mask-guided.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"BmThPdrYC9BjSOrKPSI9bZpIZHhfWLYAtFIapCYrXy4","pdfSize":"13201751","objectId":"0x3a8944f1fa879b150cd79d35ed1052ca2659f9a5e3a15aceef8cfe23ae27ffda","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
