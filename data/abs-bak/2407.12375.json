{"id":"2407.12375","title":"FETCH: A Memory-Efficient Replay Approach for Continual Learning in\n  Image Classification","authors":"Markus Wei{\\ss}flog, Peter Protzel, Peer Neubert","authorsParsed":[["Wei√üflog","Markus",""],["Protzel","Peter",""],["Neubert","Peer",""]],"versions":[{"version":"v1","created":"Wed, 17 Jul 2024 07:54:03 GMT"}],"updateDate":"2024-07-18","timestamp":1721202843000,"abstract":"  Class-incremental continual learning is an important area of research, as\nstatic deep learning methods fail to adapt to changing tasks and data\ndistributions. In previous works, promising results were achieved using replay\nand compressed replay techniques. In the field of regular replay, GDumb\nachieved outstanding results but requires a large amount of memory. This\nproblem can be addressed by compressed replay techniques. The goal of this work\nis to evaluate compressed replay in the pipeline of GDumb. We propose FETCH, a\ntwo-stage compression approach. First, the samples from the continual\ndatastream are encoded by the early layers of a pre-trained neural network.\nSecond, the samples are compressed before being stored in the episodic memory.\nFollowing GDumb, the remaining classification head is trained from scratch\nusing only the decompressed samples from the reply memory. We evaluate FETCH in\ndifferent scenarios and show that this approach can increase accuracy on\nCIFAR10 and CIFAR100. In our experiments, simple compression methods (e.g.,\nquantization of tensors) outperform deep autoencoders. In the future, FETCH\ncould serve as a baseline for benchmarking compressed replay learning in\nconstrained memory scenarios.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"05BOQ4U9GjPYnDJVFRiChO8VK6OXYidgxiLWXnVlJ2I","pdfSize":"1183168","objectId":"0x2c43b124251b292b7f0bf9e8c615bbd00e8c0a5f3be64d4e2a892652bfd1eb01","registeredEpoch":"3","certifiedEpoch":"3","startEpoch":"3","endEpoch":"203"}
