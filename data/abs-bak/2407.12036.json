{"id":"2407.12036","title":"Exploring Advanced Large Language Models with LLMsuite","authors":"Giorgio Roffo","authorsParsed":[["Roffo","Giorgio",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 05:37:17 GMT"}],"updateDate":"2024-07-18","timestamp":1719812237000,"abstract":"  This tutorial explores the advancements and challenges in the development of\nLarge Language Models (LLMs) such as ChatGPT and Gemini. It addresses inherent\nlimitations like temporal knowledge cutoffs, mathematical inaccuracies, and the\ngeneration of incorrect information, proposing solutions like Retrieval\nAugmented Generation (RAG), Program-Aided Language Models (PAL), and frameworks\nsuch as ReAct and LangChain. The integration of these techniques enhances LLM\nperformance and reliability, especially in multi-step reasoning and complex\ntask execution. The paper also covers fine-tuning strategies, including\ninstruction fine-tuning, parameter-efficient methods like LoRA, and\nReinforcement Learning from Human Feedback (RLHF) as well as Reinforced\nSelf-Training (ReST). Additionally, it provides a comprehensive survey of\ntransformer architectures and training techniques for LLMs. The toolbox for\nimplementing these techniques is publicly available at\nhttps://github.com/giorgioroffo/large_language_models_open_suite\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"YQYiwdPH8g0mMJZKhqsLlKzGpCSkEwMqlodZfvjnf8A","pdfSize":"4033129","objectId":"0xe20415ed3f7a1616a9144d819ec8832238185720c9cec246b5e0fe4d18d4dede","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
