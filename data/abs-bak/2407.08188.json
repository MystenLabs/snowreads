{"id":"2407.08188","title":"Position: Measure Dataset Diversity, Don't Just Claim It","authors":"Dora Zhao, Jerone T.A. Andrews, Orestis Papakyriakopoulos, Alice Xiang","authorsParsed":[["Zhao","Dora",""],["Andrews","Jerone T. A.",""],["Papakyriakopoulos","Orestis",""],["Xiang","Alice",""]],"versions":[{"version":"v1","created":"Thu, 11 Jul 2024 05:13:27 GMT"}],"updateDate":"2024-07-12","timestamp":1720674807000,"abstract":"  Machine learning (ML) datasets, often perceived as neutral, inherently\nencapsulate abstract and disputed social constructs. Dataset curators\nfrequently employ value-laden terms such as diversity, bias, and quality to\ncharacterize datasets. Despite their prevalence, these terms lack clear\ndefinitions and validation. Our research explores the implications of this\nissue by analyzing \"diversity\" across 135 image and text datasets. Drawing from\nsocial sciences, we apply principles from measurement theory to identify\nconsiderations and offer recommendations for conceptualizing, operationalizing,\nand evaluating diversity in datasets. Our findings have broader implications\nfor ML research, advocating for a more nuanced and precise approach to handling\nvalue-laden properties in dataset construction.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Computers and Society"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"71qI_xEWoHSbbngs6N1cxTtV-wTpWKUJoiY1x95IdjI","pdfSize":"1443185","objectId":"0x1b2771c50ac2b85a01d752fcec1692b09cc3073c28c2ef156b4dee6513e5441c","registeredEpoch":"1","certifiedEpoch":"1","startEpoch":"1","endEpoch":"201"}
