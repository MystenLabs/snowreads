{"id":"2407.05316","title":"Leveraging Topological Guidance for Improved Knowledge Distillation","authors":"Eun Som Jeon, Rahul Khurana, Aishani Pathak, Pavan Turaga","authorsParsed":[["Jeon","Eun Som",""],["Khurana","Rahul",""],["Pathak","Aishani",""],["Turaga","Pavan",""]],"versions":[{"version":"v1","created":"Sun, 7 Jul 2024 10:09:18 GMT"}],"updateDate":"2024-07-09","timestamp":1720346958000,"abstract":"  Deep learning has shown its efficacy in extracting useful features to solve\nvarious computer vision tasks. However, when the structure of the data is\ncomplex and noisy, capturing effective information to improve performance is\nvery difficult. To this end, topological data analysis (TDA) has been utilized\nto derive useful representations that can contribute to improving performance\nand robustness against perturbations. Despite its effectiveness, the\nrequirements for large computational resources and significant time consumption\nin extracting topological features through TDA are critical problems when\nimplementing it on small devices. To address this issue, we propose a framework\ncalled Topological Guidance-based Knowledge Distillation (TGD), which uses\ntopological features in knowledge distillation (KD) for image classification\ntasks. We utilize KD to train a superior lightweight model and provide\ntopological features with multiple teachers simultaneously. We introduce a\nmechanism for integrating features from different teachers and reducing the\nknowledge gap between teachers and the student, which aids in improving\nperformance. We demonstrate the effectiveness of our approach through diverse\nempirical evaluations.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"wSi1p4vm-FFMfn4Ye9_Nn8MYe7zXooqg2dhKr34mP3U","pdfSize":"10655239"}
