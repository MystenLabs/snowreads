{"id":"2407.15283","title":"Enhancing Hardware Fault Tolerance in Machines with Reinforcement\n  Learning Policy Gradient Algorithms","authors":"Sheila Schoepp, Mehran Taghian, Shotaro Miwa, Yoshihiro Mitsuka,\n  Shadan Golestan, Osmar Za\\\"iane","authorsParsed":[["Schoepp","Sheila",""],["Taghian","Mehran",""],["Miwa","Shotaro",""],["Mitsuka","Yoshihiro",""],["Golestan","Shadan",""],["Za√Øane","Osmar",""]],"versions":[{"version":"v1","created":"Sun, 21 Jul 2024 22:24:16 GMT"}],"updateDate":"2024-07-23","timestamp":1721600656000,"abstract":"  Industry is rapidly moving towards fully autonomous and interconnected\nsystems that can detect and adapt to changing conditions, including machine\nhardware faults. Traditional methods for adding hardware fault tolerance to\nmachines involve duplicating components and algorithmically reconfiguring a\nmachine's processes when a fault occurs. However, the growing interest in\nreinforcement learning-based robotic control offers a new perspective on\nachieving hardware fault tolerance. However, limited research has explored the\npotential of these approaches for hardware fault tolerance in machines. This\npaper investigates the potential of two state-of-the-art reinforcement learning\nalgorithms, Proximal Policy Optimization (PPO) and Soft Actor-Critic (SAC), to\nenhance hardware fault tolerance into machines. We assess the performance of\nthese algorithms in two OpenAI Gym simulated environments, Ant-v2 and\nFetchReach-v1. Robot models in these environments are subjected to six\nsimulated hardware faults. Additionally, we conduct an ablation study to\ndetermine the optimal method for transferring an agent's knowledge, acquired\nthrough learning in a normal (pre-fault) environment, to a (post-)fault\nenvironment in a continual learning setting. Our results demonstrate that\nreinforcement learning-based approaches can enhance hardware fault tolerance in\nsimulated machines, with adaptation occurring within minutes. Specifically, PPO\nexhibits the fastest adaptation when retaining the knowledge within its models,\nwhile SAC performs best when discarding all acquired knowledge. Overall, this\nstudy highlights the potential of reinforcement learning-based approaches, such\nas PPO and SAC, for hardware fault tolerance in machines. These findings pave\nthe way for the development of robust and adaptive machines capable of\neffectively operating in real-world scenarios.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Robotics"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"IYsuvFRzXBKs0RQhOYyCZ-io9bIXGJ2c7zMa-f6dIww","pdfSize":"6277459","objectId":"0x930f60cb06bc86545054b6da8e27de5705db1ffdf7594740c96bf898b2102bf8","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
