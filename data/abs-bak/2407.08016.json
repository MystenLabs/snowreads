{"id":"2407.08016","title":"Source Tracing of Audio Deepfake Systems","authors":"Nicholas Klein, Tianxiang Chen, Hemlata Tak, Ricardo Casal, Elie\n  Khoury","authorsParsed":[["Klein","Nicholas",""],["Chen","Tianxiang",""],["Tak","Hemlata",""],["Casal","Ricardo",""],["Khoury","Elie",""]],"versions":[{"version":"v1","created":"Wed, 10 Jul 2024 19:49:10 GMT"}],"updateDate":"2024-07-12","timestamp":1720640950000,"abstract":"  Recent progress in generative AI technology has made audio deepfakes\nremarkably more realistic. While current research on anti-spoofing systems\nprimarily focuses on assessing whether a given audio sample is fake or genuine,\nthere has been limited attention on discerning the specific techniques to\ncreate the audio deepfakes. Algorithms commonly used in audio deepfake\ngeneration, like text-to-speech (TTS) and voice conversion (VC), undergo\ndistinct stages including input processing, acoustic modeling, and waveform\ngeneration. In this work, we introduce a system designed to classify various\nspoofing attributes, capturing the distinctive features of individual modules\nthroughout the entire generation pipeline. We evaluate our system on two\ndatasets: the ASVspoof 2019 Logical Access and the Multi-Language Audio\nAnti-Spoofing Dataset (MLAAD). Results from both experiments demonstrate the\nrobustness of the system to identify the different spoofing attributes of\ndeepfake generation systems.\n","subjects":["Electrical Engineering and Systems Science/Audio and Speech Processing","Computing Research Repository/Sound"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"zLVX423L2dg4igxLBlwADAUr_6A5vv25qkI1Ote4Sig","pdfSize":"404491","objectId":"0x9900f70cb3c5ec6fe3be0274bb1345dff2a2eb6f1c3c58c8dcdec57cc3a5de2e","registeredEpoch":"1","certifiedEpoch":"1","startEpoch":"1","endEpoch":"201"}
