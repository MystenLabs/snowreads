{"id":"2407.08441","title":"Are Large Language Models Really Bias-Free? Jailbreak Prompts for\n  Assessing Adversarial Robustness to Bias Elicitation","authors":"Riccardo Cantini, Giada Cosenza, Alessio Orsino, Domenico Talia","authorsParsed":[["Cantini","Riccardo",""],["Cosenza","Giada",""],["Orsino","Alessio",""],["Talia","Domenico",""]],"versions":[{"version":"v1","created":"Thu, 11 Jul 2024 12:30:19 GMT"}],"updateDate":"2024-07-12","timestamp":1720701019000,"abstract":"  Large Language Models (LLMs) have revolutionized artificial intelligence,\ndemonstrating remarkable computational power and linguistic capabilities.\nHowever, these models are inherently prone to various biases stemming from\ntheir training data. These include selection, linguistic, and confirmation\nbiases, along with common stereotypes related to gender, ethnicity, sexual\norientation, religion, socioeconomic status, disability, and age. This study\nexplores the presence of these biases within the responses given by the most\nrecent LLMs, analyzing the impact on their fairness and reliability. We also\ninvestigate how known prompt engineering techniques can be exploited to\neffectively reveal hidden biases of LLMs, testing their adversarial robustness\nagainst jailbreak prompts specially crafted for bias elicitation. Extensive\nexperiments are conducted using the most widespread LLMs at different scales,\nconfirming that LLMs can still be manipulated to produce biased or\ninappropriate responses, despite their advanced capabilities and sophisticated\nalignment processes. Our findings underscore the importance of enhancing\nmitigation techniques to address these safety issues, toward a more sustainable\nand inclusive artificial intelligence.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"0ff1nkS-eXLIocPr5Cp0OoD8bx6Gwx7gePoRYblsB6o","pdfSize":"729145","objectId":"0xcacfca6d0e75d83db08600272ac4e50827869100e7b2d8544a38ecd25e84c625","registeredEpoch":"1","certifiedEpoch":"1","startEpoch":"1","endEpoch":"201"}
