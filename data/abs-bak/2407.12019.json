{"id":"2407.12019","title":"DIM: Dynamic Integration of Multimodal Entity Linking with Large\n  Language Model","authors":"Shezheng Song, Shasha Li, Jie Yu, Shan Zhao, Xiaopeng Li, Jun Ma,\n  Xiaodong Liu, Zhuo Li, Xiaoguang Mao","authorsParsed":[["Song","Shezheng",""],["Li","Shasha",""],["Yu","Jie",""],["Zhao","Shan",""],["Li","Xiaopeng",""],["Ma","Jun",""],["Liu","Xiaodong",""],["Li","Zhuo",""],["Mao","Xiaoguang",""]],"versions":[{"version":"v1","created":"Thu, 27 Jun 2024 15:18:23 GMT"}],"updateDate":"2024-07-18","timestamp":1719501503000,"abstract":"  Our study delves into Multimodal Entity Linking, aligning the mention in\nmultimodal information with entities in knowledge base. Existing methods are\nstill facing challenges like ambiguous entity representations and limited image\ninformation utilization. Thus, we propose dynamic entity extraction using\nChatGPT, which dynamically extracts entities and enhances datasets. We also\npropose a method: Dynamically Integrate Multimodal information with knowledge\nbase (DIM), employing the capability of the Large Language Model (LLM) for\nvisual understanding. The LLM, such as BLIP-2, extracts information relevant to\nentities in the image, which can facilitate improved extraction of entity\nfeatures and linking them with the dynamic entity representations provided by\nChatGPT. The experiments demonstrate that our proposed DIM method outperforms\nthe majority of existing methods on the three original datasets, and achieves\nstate-of-the-art (SOTA) on the dynamically enhanced datasets (Wiki+, Rich+,\nDiverse+). For reproducibility, our code and collected datasets are released on\n\\url{https://github.com/season1blue/DIM}.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"Bax6_p-BLOUcvVZn0Xb0Y7HBTPuyc8U5ReYzJ4uWzjI","pdfSize":"538583","objectId":"0x853ce97ccbe2379edfdcc79fe8cb4160e6006c489f0d934ec27b12952bef1d7b","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
