{"id":"2407.04699","title":"LaRa: Efficient Large-Baseline Radiance Fields","authors":"Anpei Chen and Haofei Xu and Stefano Esposito and Siyu Tang and\n  Andreas Geiger","authorsParsed":[["Chen","Anpei",""],["Xu","Haofei",""],["Esposito","Stefano",""],["Tang","Siyu",""],["Geiger","Andreas",""]],"versions":[{"version":"v1","created":"Fri, 5 Jul 2024 17:59:58 GMT"},{"version":"v2","created":"Mon, 15 Jul 2024 20:18:09 GMT"}],"updateDate":"2024-07-17","timestamp":1720202398000,"abstract":"  Radiance field methods have achieved photorealistic novel view synthesis and\ngeometry reconstruction. But they are mostly applied in per-scene optimization\nor small-baseline settings. While several recent works investigate feed-forward\nreconstruction with large baselines by utilizing transformers, they all operate\nwith a standard global attention mechanism and hence ignore the local nature of\n3D reconstruction. We propose a method that unifies local and global reasoning\nin transformer layers, resulting in improved quality and faster convergence.\nOur model represents scenes as Gaussian Volumes and combines this with an image\nencoder and Group Attention Layers for efficient feed-forward reconstruction.\nExperimental results demonstrate that our model, trained for two days on four\nGPUs, demonstrates high fidelity in reconstructing 360 deg radiance fields, and\nrobustness to zero-shot and out-of-domain testing. Our project Page:\nhttps://apchenstu.github.io/LaRa/.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"J6edIJrds_CTLcT3OFPn8EbJv5TuAy8YDtWywdb_gbU","pdfSize":"29037924"}
