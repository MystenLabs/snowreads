{"id":"2407.02067","title":"Crossroads of Continents: Automated Artifact Extraction for Cultural\n  Adaptation with Large Multimodal Models","authors":"Anjishnu Mukherjee, Ziwei Zhu, Antonios Anastasopoulos","authorsParsed":[["Mukherjee","Anjishnu",""],["Zhu","Ziwei",""],["Anastasopoulos","Antonios",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 08:55:41 GMT"}],"updateDate":"2024-07-03","timestamp":1719910541000,"abstract":"  In this work, we present a comprehensive three-phase study to examine (1) the\neffectiveness of large multimodal models (LMMs) in recognizing cultural\ncontexts; (2) the accuracy of their representations of diverse cultures; and\n(3) their ability to adapt content across cultural boundaries. We first\nintroduce Dalle Street, a large-scale dataset generated by DALL-E 3 and\nvalidated by humans, containing 9,935 images of 67 countries and 10 concept\nclasses. We reveal disparities in cultural understanding at the sub-region\nlevel with both open-weight (LLaVA) and closed-source (GPT-4V) models on Dalle\nStreet and other existing benchmarks. Next, we assess models' deeper culture\nunderstanding by an artifact extraction task and identify over 18,000 artifacts\nassociated with different countries. Finally, we propose a highly composable\npipeline, CultureAdapt, to adapt images from culture to culture. Our findings\nreveal a nuanced picture of the cultural competence of LMMs, highlighting the\nneed to develop culture-aware systems. Dataset and code are available at\nhttps://github.com/iamshnoo/crossroads\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by-sa/4.0/","blobId":"13TzoNv34zTQ58FAkMtC3bGLeEZgV4fGczw__78XlNE","pdfSize":"34327362","objectId":"0x4c7be8a3c65faa714f4ab53d0dac70c13caa21c440af193844d70ffe74f02c40","registeredEpoch":"3","certifiedEpoch":"3","startEpoch":"3","endEpoch":"203"}
