{"id":"2407.12517","title":"Evaluating the transferability potential of deep learning models for\n  climate downscaling","authors":"Ayush Prasad, Paula Harder, Qidong Yang, Prasanna Sattegeri, Daniela\n  Szwarcman, Campbell Watson, David Rolnick","authorsParsed":[["Prasad","Ayush",""],["Harder","Paula",""],["Yang","Qidong",""],["Sattegeri","Prasanna",""],["Szwarcman","Daniela",""],["Watson","Campbell",""],["Rolnick","David",""]],"versions":[{"version":"v1","created":"Wed, 17 Jul 2024 12:10:24 GMT"}],"updateDate":"2024-07-18","timestamp":1721218224000,"abstract":"  Climate downscaling, the process of generating high-resolution climate data\nfrom low-resolution simulations, is essential for understanding and adapting to\nclimate change at regional and local scales. Deep learning approaches have\nproven useful in tackling this problem. However, existing studies usually focus\non training models for one specific task, location and variable, which are\ntherefore limited in their generalizability and transferability. In this paper,\nwe evaluate the efficacy of training deep learning downscaling models on\nmultiple diverse climate datasets to learn more robust and transferable\nrepresentations. We evaluate the effectiveness of architectures zero-shot\ntransferability using CNNs, Fourier Neural Operators (FNOs), and vision\nTransformers (ViTs). We assess the spatial, variable, and product\ntransferability of downscaling models experimentally, to understand the\ngeneralizability of these different architecture types.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"dYOxTG3EJJHO_8wusA26UvBB8J-BfOBVqTJigJAanrI","pdfSize":"251939","objectId":"0x152ae06acca1c56104138e9c29c47967c3353cbb31f4c6d4565d8dbd1237fbca","registeredEpoch":"3","certifiedEpoch":"3","startEpoch":"3","endEpoch":"203"}
