{"id":"2407.04923","title":"OmChat: A Recipe to Train Multimodal Language Models with Strong Long\n  Context and Video Understanding","authors":"Tiancheng Zhao, Qianqian Zhang, Kyusong Lee, Peng Liu, Lu Zhang,\n  Chunxin Fang, Jiajia Liao, Kelei Jiang, Yibo Ma, Ruochen Xu","authorsParsed":[["Zhao","Tiancheng",""],["Zhang","Qianqian",""],["Lee","Kyusong",""],["Liu","Peng",""],["Zhang","Lu",""],["Fang","Chunxin",""],["Liao","Jiajia",""],["Jiang","Kelei",""],["Ma","Yibo",""],["Xu","Ruochen",""]],"versions":[{"version":"v1","created":"Sat, 6 Jul 2024 02:16:10 GMT"}],"updateDate":"2024-07-09","timestamp":1720232170000,"abstract":"  We introduce OmChat, a model designed to excel in handling long contexts and\nvideo understanding tasks. OmChat's new architecture standardizes how different\nvisual inputs are processed, making it more efficient and adaptable. It uses a\ndynamic vision encoding process to effectively handle images of various\nresolutions, capturing fine details across a range of image qualities. OmChat\nutilizes an active progressive multimodal pretraining strategy, which gradually\nincreases the model's capacity for long contexts and enhances its overall\nabilities. By selecting high-quality data during training, OmChat learns from\nthe most relevant and informative data points. With support for a context\nlength of up to 512K, OmChat demonstrates promising performance in tasks\ninvolving multiple images and videos, outperforming most open-source models in\nthese benchmarks. Additionally, OmChat proposes a prompting strategy for\nunifying complex multimodal inputs including single image text, multi-image\ntext and videos, and achieving competitive performance on single-image\nbenchmarks. To further evaluate the model's capabilities, we proposed a\nbenchmark dataset named Temporal Visual Needle in a Haystack. This dataset\nassesses OmChat's ability to comprehend temporal visual details within long\nvideos. Our analysis highlights several key factors contributing to OmChat's\nsuccess: support for any-aspect high image resolution, the active progressive\npretraining strategy, and high-quality supervised fine-tuning datasets. This\nreport provides a detailed overview of OmChat's capabilities and the strategies\nthat enhance its performance in visual understanding.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"jTa3AujZAC-VCCMAo5O8J5v1UvxzNX4d9WEUCBI7C50","pdfSize":"23919272"}
