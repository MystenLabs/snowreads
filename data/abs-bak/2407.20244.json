{"id":"2407.20244","title":"Steamroller Problems: An Evaluation of LLM Reasoning Capability with\n  Automated Theorem Prover Strategies","authors":"Lachlan McGinness, Peter Baumgartner","authorsParsed":[["McGinness","Lachlan",""],["Baumgartner","Peter",""]],"versions":[{"version":"v1","created":"Wed, 17 Jul 2024 22:49:23 GMT"}],"updateDate":"2024-07-31","timestamp":1721256563000,"abstract":"  This study presents the first examination of the ability of Large Language\nModels (LLMs) to follow reasoning strategies that are used to guide Automated\nTheorem Provers (ATPs). We evaluate the performance of GPT4, GPT3.5 Turbo and\nGoogle's recent Gemini model on problems from a steamroller domain. In addition\nto determining accuracy we make use of the Natural Language Processing library\nspaCy to explore new methods of investigating LLM's reasoning capabilities.\nThis led to one alarming result, the low correlation between correct reasoning\nand correct answers for any of the tested models. We found that the models'\nperformance when using the ATP reasoning strategies was comparable to one-shot\nchain of thought and observe that attention to uncertainty in the accuracy\nresults is critical when drawing conclusions about model performance.\nConsistent with previous speculation we confirm that LLMs have a preference\nfor, and are best able to follow, bottom up reasoning processes. However, the\nreasoning strategies can still be beneficial for deriving small and relevant\nsets of formulas for external processing by a trusted inference engine.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"tNnqRLFe8AVnPiXuU2_Xh1_2q8fKTQ4gKW8wON_YeHY","pdfSize":"750682","objectId":"0x7e3081ab81dcf85324120b0ec7552cd11a0259a6a913aff7fc77e75e7bad0f20","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
