{"id":"2407.13083","title":"Modeling and Driving Human Body Soundfields through Acoustic Primitives","authors":"Chao Huang, Dejan Markovic, Chenliang Xu, Alexander Richard","authorsParsed":[["Huang","Chao",""],["Markovic","Dejan",""],["Xu","Chenliang",""],["Richard","Alexander",""]],"versions":[{"version":"v1","created":"Thu, 18 Jul 2024 01:05:13 GMT"},{"version":"v2","created":"Sat, 20 Jul 2024 22:25:07 GMT"}],"updateDate":"2024-07-23","timestamp":1721264713000,"abstract":"  While rendering and animation of photorealistic 3D human body models have\nmatured and reached an impressive quality over the past years, modeling the\nspatial audio associated with such full body models has been largely ignored so\nfar. In this work, we present a framework that allows for high-quality spatial\naudio generation, capable of rendering the full 3D soundfield generated by a\nhuman body, including speech, footsteps, hand-body interactions, and others.\nGiven a basic audio-visual representation of the body in form of 3D body pose\nand audio from a head-mounted microphone, we demonstrate that we can render the\nfull acoustic scene at any point in 3D space efficiently and accurately. To\nenable near-field and realtime rendering of sound, we borrow the idea of\nvolumetric primitives from graphical neural rendering and transfer them into\nthe acoustic domain. Our acoustic primitives result in an order of magnitude\nsmaller soundfield representations and overcome deficiencies in near-field\nrendering compared to previous approaches.\n","subjects":["Computing Research Repository/Sound","Computing Research Repository/Computer Vision and Pattern Recognition","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"iLKFHSvbtjAFev1CqL1weaPEA4OehrDfoP2NW6B96j4","pdfSize":"13003274","objectId":"0xe2506e1ce38c4e999334115b0b58c5beaa4ede9632dc598131e07b8785bd391f","registeredEpoch":"3","certifiedEpoch":"3","startEpoch":"3","endEpoch":"203"}
