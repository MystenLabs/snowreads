{"id":"2407.03545","title":"On Evaluating Explanation Utility for Human-AI Decision Making in NLP","authors":"Fateme Hashemi Chaleshtori, Atreya Ghosal, Alexander Gill, Purbid\n  Bambroo, Ana Marasovi\\'c","authorsParsed":[["Chaleshtori","Fateme Hashemi",""],["Ghosal","Atreya",""],["Gill","Alexander",""],["Bambroo","Purbid",""],["MarasoviÄ‡","Ana",""]],"versions":[{"version":"v1","created":"Wed, 3 Jul 2024 23:53:27 GMT"}],"updateDate":"2024-07-08","timestamp":1720050807000,"abstract":"  Is explainability a false promise? This debate has emerged from the\ninsufficient evidence that explanations aid people in situations they are\nintroduced for. More human-centered, application-grounded evaluations of\nexplanations are needed to settle this. Yet, with no established guidelines for\nsuch studies in NLP, researchers accustomed to standardized proxy evaluations\nmust discover appropriate measurements, tasks, datasets, and sensible models\nfor human-AI teams in their studies.\n  To help with this, we first review fitting existing metrics. We then\nestablish requirements for datasets to be suitable for application-grounded\nevaluations. Among over 50 datasets available for explainability research in\nNLP, we find that 4 meet our criteria. By finetuning Flan-T5-3B, we demonstrate\nthe importance of reassessing the state of the art to form and study human-AI\nteams. Finally, we present the exemplar studies of human-AI decision-making for\none of the identified suitable tasks -- verifying the correctness of a legal\nclaim given a contract.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Human-Computer Interaction"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"yugg84jGCj2qCI2ojMFR8Y0_AUCJ9EhOexamMGoVWbY","pdfSize":"6124016"}
