{"id":"2407.03085","title":"Accelerated Inference for Partially Observed Markov Processes using\n  Automatic Differentiation","authors":"Kevin Tan, Giles Hooker, Edward L. Ionides","authorsParsed":[["Tan","Kevin",""],["Hooker","Giles",""],["Ionides","Edward L.",""]],"versions":[{"version":"v1","created":"Wed, 3 Jul 2024 13:06:46 GMT"}],"updateDate":"2024-07-04","timestamp":1720012006000,"abstract":"  Automatic differentiation (AD) has driven recent advances in machine\nlearning, including deep neural networks and Hamiltonian Markov Chain Monte\nCarlo methods. Partially observed nonlinear stochastic dynamical systems have\nproved resistant to AD techniques because widely used particle filter\nalgorithms yield an estimated likelihood function that is discontinuous as a\nfunction of the model parameters. We show how to embed two existing AD particle\nfilter methods in a theoretical framework that provides an extension to a new\nclass of algorithms. This new class permits a bias/variance tradeoff and hence\na mean squared error substantially lower than the existing algorithms. We\ndevelop likelihood maximization algorithms suited to the Monte Carlo properties\nof the AD gradient estimate. Our algorithms require only a differentiable\nsimulator for the latent dynamic system; by contrast, most previous approaches\nto AD likelihood maximization for particle filters require access to the\nsystem's transition probabilities. Numerical results indicate that a hybrid\nalgorithm that uses AD to refine a coarse solution from an iterated filtering\nalgorithm show substantial improvement on current state-of-the-art methods for\na challenging scientific benchmark problem.\n","subjects":["Statistics/Methodology","Statistics/Computation","Statistics/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"-_j_1d_qhNrjY0f8NsgaAR7VOuiz4Iyso1RZEFL1Xlw","pdfSize":"2787351"}
