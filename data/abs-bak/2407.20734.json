{"id":"2407.20734","title":"Efficient Pareto Manifold Learning with Low-Rank Structure","authors":"Weiyu Chen, James T. Kwok","authorsParsed":[["Chen","Weiyu",""],["Kwok","James T.",""]],"versions":[{"version":"v1","created":"Tue, 30 Jul 2024 11:09:27 GMT"}],"updateDate":"2024-07-31","timestamp":1722337767000,"abstract":"  Multi-task learning, which optimizes performance across multiple tasks, is\ninherently a multi-objective optimization problem. Various algorithms are\ndeveloped to provide discrete trade-off solutions on the Pareto front.\nRecently, continuous Pareto front approximations using a linear combination of\nbase networks have emerged as a compelling strategy. However, it suffers from\nscalability issues when the number of tasks is large. To address this issue, we\npropose a novel approach that integrates a main network with several low-rank\nmatrices to efficiently learn the Pareto manifold. It significantly reduces the\nnumber of parameters and facilitates the extraction of shared features. We also\nintroduce orthogonal regularization to further bolster performance. Extensive\nexperimental results demonstrate that the proposed approach outperforms\nstate-of-the-art baselines, especially on datasets with a large number of\ntasks.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"FUYrbLihQoC-0KHBs_kVW5UzHCkVpAWUqNNajywYxrE","pdfSize":"1516924","objectId":"0x0c7bdf549dee82656dd9811672534ac9fd5994498ebf6a24dda452c92b13ab39","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
