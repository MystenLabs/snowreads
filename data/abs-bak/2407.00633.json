{"id":"2407.00633","title":"DEAR: Disentangled Environment and Agent Representations for\n  Reinforcement Learning without Reconstruction","authors":"Ameya Pore, Riccardo Muradore and Diego Dall'Alba","authorsParsed":[["Pore","Ameya",""],["Muradore","Riccardo",""],["Dall'Alba","Diego",""]],"versions":[{"version":"v1","created":"Sun, 30 Jun 2024 09:15:21 GMT"}],"updateDate":"2024-07-02","timestamp":1719738921000,"abstract":"  Reinforcement Learning (RL) algorithms can learn robotic control tasks from\nvisual observations, but they often require a large amount of data, especially\nwhen the visual scene is complex and unstructured. In this paper, we explore\nhow the agent's knowledge of its shape can improve the sample efficiency of\nvisual RL methods. We propose a novel method, Disentangled Environment and\nAgent Representations (DEAR), that uses the segmentation mask of the agent as\nsupervision to learn disentangled representations of the environment and the\nagent through feature separation constraints. Unlike previous approaches, DEAR\ndoes not require reconstruction of visual observations. These representations\nare then used as an auxiliary loss to the RL objective, encouraging the agent\nto focus on the relevant features of the environment. We evaluate DEAR on two\nchallenging benchmarks: Distracting DeepMind control suite and Franka Kitchen\nmanipulation tasks. Our findings demonstrate that DEAR surpasses\nstate-of-the-art methods in sample efficiency, achieving comparable or superior\nperformance with reduced parameters. Our results indicate that integrating\nagent knowledge into visual RL methods has the potential to enhance their\nlearning efficiency and robustness.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"PceM7p4fGcjV4KGAE3aZbCFvpP8Zrh_NRNEbHhYu5cU","pdfSize":"3350801","objectId":"0x28f63b6f1de2680607ab7046c26513c3c8009f6147ba70de132922e7fd5e92ac","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
