{"id":"2407.10115","title":"A Bag of Tricks for Scaling CPU-based Deep FFMs to more than 300m\n  Predictions per Second","authors":"Bla\\v{z} \\v{S}krlj, Benjamin Ben-Shalom, Grega Ga\\v{s}per\\v{s}i\\v{c},\n  Adi Schwartz, Ramzi Hoseisi, Naama Ziporin, Davorin Kopi\\v{c}, Andra\\v{z}\n  Tori","authorsParsed":[["Škrlj","Blaž",""],["Ben-Shalom","Benjamin",""],["Gašperšič","Grega",""],["Schwartz","Adi",""],["Hoseisi","Ramzi",""],["Ziporin","Naama",""],["Kopič","Davorin",""],["Tori","Andraž",""]],"versions":[{"version":"v1","created":"Sun, 14 Jul 2024 08:10:20 GMT"}],"updateDate":"2024-07-16","timestamp":1720944620000,"abstract":"  Field-aware Factorization Machines (FFMs) have emerged as a powerful model\nfor click-through rate prediction, particularly excelling in capturing complex\nfeature interactions. In this work, we present an in-depth analysis of our\nin-house, Rust-based Deep FFM implementation, and detail its deployment on a\nCPU-only, multi-data-center scale. We overview key optimizations devised for\nboth training and inference, demonstrated by previously unpublished benchmark\nresults in efficient model search and online training. Further, we detail an\nin-house weight quantization that resulted in more than an order of magnitude\nreduction in bandwidth footprint related to weight transfers across\ndata-centres. We disclose the engine and associated techniques under an\nopen-source license to contribute to the broader machine learning community.\nThis paper showcases one of the first successful CPU-only deployments of Deep\nFFMs at such scale, marking a significant stride in practical, low-footprint\nclick-through rate prediction methodologies.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Information Retrieval"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"VnohiIoSSaxTGIe_WmlVHU8kG1I3EpV8r81pCX2x7CU","pdfSize":"4887061","objectId":"0xb13ab805488cb7670d8ea148131d88151beb121d241915f8b6ce4468f92d6d31","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
