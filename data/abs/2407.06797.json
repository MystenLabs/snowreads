{"id":"2407.06797","title":"ED-VAE: Entropy Decomposition of ELBO in Variational Autoencoders","authors":"Fotios Lygerakis, Elmar Rueckert","authorsParsed":[["Lygerakis","Fotios",""],["Rueckert","Elmar",""]],"versions":[{"version":"v1","created":"Tue, 9 Jul 2024 12:09:21 GMT"}],"updateDate":"2024-07-10","timestamp":1720526961000,"abstract":"  Traditional Variational Autoencoders (VAEs) are constrained by the\nlimitations of the Evidence Lower Bound (ELBO) formulation, particularly when\nutilizing simplistic, non-analytic, or unknown prior distributions. These\nlimitations inhibit the VAE's ability to generate high-quality samples and\nprovide clear, interpretable latent representations. This work introduces the\nEntropy Decomposed Variational Autoencoder (ED-VAE), a novel re-formulation of\nthe ELBO that explicitly includes entropy and cross-entropy components. This\nreformulation significantly enhances model flexibility, allowing for the\nintegration of complex and non-standard priors. By providing more detailed\ncontrol over the encoding and regularization of latent spaces, ED-VAE not only\nimproves interpretability but also effectively captures the complex\ninteractions between latent variables and observed data, thus leading to better\ngenerative performance.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence","Statistics/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"_MvIV_ObtzeUzcs1JOzZqYJzozl2pK6OgEEOeNXXzvc","pdfSize":"270089"}