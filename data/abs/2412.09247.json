{"id":"2412.09247","title":"Make Satire Boring Again: Reducing Stylistic Bias of Satirical Corpus by\n  Utilizing Generative LLMs","authors":"Asli Umay Ozturk, Recep Firat Cekinel, Pinar Karagoz","authorsParsed":[["Ozturk","Asli Umay",""],["Cekinel","Recep Firat",""],["Karagoz","Pinar",""]],"versions":[{"version":"v1","created":"Thu, 12 Dec 2024 12:57:55 GMT"}],"updateDate":"2024-12-13","timestamp":1734008275000,"abstract":"  Satire detection is essential for accurately extracting opinions from textual\ndata and combating misinformation online. However, the lack of diverse corpora\nfor satire leads to the problem of stylistic bias which impacts the models'\ndetection performances. This study proposes a debiasing approach for satire\ndetection, focusing on reducing biases in training data by utilizing generative\nlarge language models. The approach is evaluated in both cross-domain (irony\ndetection) and cross-lingual (English) settings. Results show that the\ndebiasing method enhances the robustness and generalizability of the models for\nsatire and irony detection tasks in Turkish and English. However, its impact on\ncausal language models, such as Llama-3.1, is limited. Additionally, this work\ncurates and presents the Turkish Satirical News Dataset with detailed human\nannotations, with case studies on classification, debiasing, and\nexplainability.\n","subjects":["Computer Science/Computation and Language"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"RHhgcOCoHbA_Puz4XJ4zwXPwK91tJ0L-iAosXt-kgZo","pdfSize":"2537972"}