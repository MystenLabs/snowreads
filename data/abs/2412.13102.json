{
  "id": "2412.13102",
  "title": "AIR-Bench: Automated Heterogeneous Information Retrieval Benchmark",
  "authors": "Jianlyu Chen, Nan Wang, Chaofan Li, Bo Wang, Shitao Xiao, Han Xiao,\n  Hao Liao, Defu Lian, Zheng Liu",
  "authorsParsed": [
    [
      "Chen",
      "Jianlyu",
      ""
    ],
    [
      "Wang",
      "Nan",
      ""
    ],
    [
      "Li",
      "Chaofan",
      ""
    ],
    [
      "Wang",
      "Bo",
      ""
    ],
    [
      "Xiao",
      "Shitao",
      ""
    ],
    [
      "Xiao",
      "Han",
      ""
    ],
    [
      "Liao",
      "Hao",
      ""
    ],
    [
      "Lian",
      "Defu",
      ""
    ],
    [
      "Liu",
      "Zheng",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Tue, 17 Dec 2024 17:15:21 GMT"
    },
    {
      "version": "v2",
      "created": "Wed, 18 Dec 2024 07:06:07 GMT"
    },
    {
      "version": "v3",
      "created": "Fri, 20 Dec 2024 05:42:38 GMT"
    }
  ],
  "updateDate": "2024-12-23",
  "timestamp": 1734455721000,
  "abstract": "  Evaluation plays a crucial role in the advancement of information retrieval\n(IR) models. However, current benchmarks, which are based on predefined domains\nand human-labeled data, face limitations in addressing evaluation needs for\nemerging domains both cost-effectively and efficiently. To address this\nchallenge, we propose the Automated Heterogeneous Information Retrieval\nBenchmark (AIR-Bench). AIR-Bench is distinguished by three key features: 1)\nAutomated. The testing data in AIR-Bench is automatically generated by large\nlanguage models (LLMs) without human intervention. 2) Heterogeneous. The\ntesting data in AIR-Bench is generated with respect to diverse tasks, domains\nand languages. 3) Dynamic. The domains and languages covered by AIR-Bench are\nconstantly augmented to provide an increasingly comprehensive evaluation\nbenchmark for community developers. We develop a reliable and robust data\ngeneration pipeline to automatically create diverse and high-quality evaluation\ndatasets based on real-world corpora. Our findings demonstrate that the\ngenerated testing data in AIR-Bench aligns well with human-labeled testing\ndata, making AIR-Bench a dependable benchmark for evaluating IR models. The\nresources in AIR-Bench are publicly available at\nhttps://github.com/AIR-Bench/AIR-Bench.\n",
  "subjects": [
    "Computer Science/Information Retrieval",
    "Computer Science/Computation and Language"
  ],
  "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
  "blobId": "SFCltkiBN_F2bcb6kDd01rtv156-EFb7COiMap6Ycms",
  "pdfSize": "1161955"
}