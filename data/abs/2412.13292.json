{"id":"2412.13292","title":"Hint Marginalization for Improved Reasoning in Large Language Models","authors":"Soumyasundar Pal, Didier Ch\\'etelat, Yingxue Zhang, Mark Coates","authorsParsed":[["Pal","Soumyasundar",""],["Ch√©telat","Didier",""],["Zhang","Yingxue",""],["Coates","Mark",""]],"versions":[{"version":"v1","created":"Tue, 17 Dec 2024 19:45:53 GMT"}],"updateDate":"2024-12-19","timestamp":1734464753000,"abstract":"  Large Language Models (LLMs) have exhibited an impressive capability to\nperform reasoning tasks, especially if they are encouraged to generate a\nsequence of intermediate steps. Reasoning performance can be improved by\nsuitably combining multiple LLM responses, generated either in parallel in a\nsingle query, or via sequential interactions with LLMs throughout the reasoning\nprocess. Existing strategies for combination, such as self-consistency and\nprogressive-hint-prompting, make inefficient usage of the LLM responses. We\npresent Hint Marginalization, a novel and principled algorithmic framework to\nenhance the reasoning capabilities of LLMs. Our approach can be viewed as an\niterative sampling strategy for forming a Monte Carlo approximation of an\nunderlying distribution of answers, with the goal of identifying the mode the\nmost likely answer. Empirical evaluation on several benchmark datasets for\narithmetic reasoning demonstrates the superiority of the proposed approach.\n","subjects":["Computer Science/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"5iFK0PLxyzL0Mrm08i21X4mt53-1HEDm6nMCXV-UppE","pdfSize":"1282123"}