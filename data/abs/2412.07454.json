{"id":"2412.07454","title":"Tazza: Shuffling Neural Network Parameters for Secure and Private\n  Federated Learning","authors":"Kichang Lee, Jaeho Jin, JaeYeon Park, Songkuk Kim, JeongGil Ko","authorsParsed":[["Lee","Kichang",""],["Jin","Jaeho",""],["Park","JaeYeon",""],["Kim","Songkuk",""],["Ko","JeongGil",""]],"versions":[{"version":"v1","created":"Tue, 10 Dec 2024 12:20:42 GMT"},{"version":"v2","created":"Mon, 3 Feb 2025 17:23:32 GMT"}],"updateDate":"2025-02-04","timestamp":1733833242000,"abstract":"  Federated learning enables decentralized model training without sharing raw\ndata, preserving data privacy. However, its vulnerability towards critical\nsecurity threats, such as gradient inversion and model poisoning by malicious\nclients, remain unresolved. Existing solutions often address these issues\nseparately, sacrificing either system robustness or model accuracy. This work\nintroduces Tazza, a secure and efficient federated learning framework that\nsimultaneously addresses both challenges. By leveraging the permutation\nequivariance and invariance properties of neural networks via weight shuffling\nand shuffled model validation, Tazza enhances resilience against diverse\npoisoning attacks, while ensuring data confidentiality and high model accuracy.\nComprehensive evaluations on various datasets and embedded platforms show that\nTazza achieves robust defense with up to 6.7x improved computational efficiency\ncompared to alternative schemes, without compromising performance.\n","subjects":["Computer Science/Machine Learning","Computer Science/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"kU1KquJKgqDFu6ojWg3E8Ip0fKs92uIQRgQTQx8xMwo","pdfSize":"5244855"}