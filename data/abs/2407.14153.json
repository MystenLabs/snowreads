{"id":"2407.14153","title":"ESP-MedSAM: Efficient Self-Prompting SAM for Universal\n  Domain-Generalized Medical Image Segmentation","authors":"Qing Xu, Jiaxuan Li, Xiangjian He, Ziyu Liu, Zhen Chen, Wenting Duan,\n  Chenxin Li, Maggie M. He, Fiseha B. Tesema, Wooi P. Cheah, Yi Wang, Rong Qu,\n  Jonathan M. Garibaldi","authorsParsed":[["Xu","Qing",""],["Li","Jiaxuan",""],["He","Xiangjian",""],["Liu","Ziyu",""],["Chen","Zhen",""],["Duan","Wenting",""],["Li","Chenxin",""],["He","Maggie M.",""],["Tesema","Fiseha B.",""],["Cheah","Wooi P.",""],["Wang","Yi",""],["Qu","Rong",""],["Garibaldi","Jonathan M.",""]],"versions":[{"version":"v1","created":"Fri, 19 Jul 2024 09:32:30 GMT"},{"version":"v2","created":"Wed, 7 Aug 2024 17:04:53 GMT"},{"version":"v3","created":"Thu, 8 Aug 2024 16:20:02 GMT"},{"version":"v4","created":"Sun, 18 Aug 2024 01:28:06 GMT"}],"updateDate":"2024-08-20","timestamp":1721381550000,"abstract":"  The universality of deep neural networks across different modalities and\ntheir generalization capabilities to unseen domains play an essential role in\nmedical image segmentation. The recent Segment Anything Model (SAM) has\ndemonstrated its potential in both settings. However, the huge computational\ncosts, demand for manual annotations as prompts and conflict-prone decoding\nprocess of SAM degrade its generalizability and applicability in clinical\nscenarios. To address these issues, we propose an efficient self-prompting SAM\nfor universal domain-generalized medical image segmentation, named ESP-MedSAM.\nSpecifically, we first devise the Multi-Modal Decoupled Knowledge Distillation\n(MMDKD) strategy to construct a lightweight semi-parameter sharing image\nencoder that produces discriminative visual features for diverse modalities.\nFurther, we introduce the Self-Patch Prompt Generator (SPPG) to automatically\ngenerate high-quality dense prompt embeddings for guiding segmentation\ndecoding. Finally, we design the Query-Decoupled Modality Decoder (QDMD) that\nleverages a one-to-one strategy to provide an independent decoding channel for\nevery modality. Extensive experiments indicate that ESP-MedSAM outperforms\nstate-of-the-arts in diverse medical imaging segmentation tasks, displaying\nsuperior modality universality and generalization capabilities. Especially,\nESP-MedSAM uses only 4.5\\% parameters compared to SAM-H. The source code is\navailable at https://github.com/xq141839/ESP-MedSAM.\n","subjects":["Electrical Engineering and Systems Science/Image and Video Processing","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"gjTMD3bKu68x4-R_onT6Ig9Wqxn-GlKZhUO2VZ_U9wg","pdfSize":"3429951","objectId":"0x9ac58a93884e5b94d54b3e7b3b42ae3d6707db51ce1747f0a7fb3f8d35574b63","registeredEpoch":"3","certifiedEpoch":"3","startEpoch":"3","endEpoch":"203"}
