{"id":"2407.02217","title":"Physics-Informed Model and Hybrid Planning for Efficient Dyna-Style\n  Reinforcement Learning","authors":"Zakariae El Asri, Olivier Sigaud, Nicolas Thome","authorsParsed":[["Asri","Zakariae El",""],["Sigaud","Olivier",""],["Thome","Nicolas",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 12:32:57 GMT"}],"updateDate":"2024-07-03","timestamp":1719923577000,"abstract":"  Applying reinforcement learning (RL) to real-world applications requires\naddressing a trade-off between asymptotic performance, sample efficiency, and\ninference time. In this work, we demonstrate how to address this triple\nchallenge by leveraging partial physical knowledge about the system dynamics.\nOur approach involves learning a physics-informed model to boost sample\nefficiency and generating imaginary trajectories from this model to learn a\nmodel-free policy and Q-function. Furthermore, we propose a hybrid planning\nstrategy, combining the learned policy and Q-function with the learned model to\nenhance time efficiency in planning. Through practical demonstrations, we\nillustrate that our method improves the compromise between sample efficiency,\ntime efficiency, and performance over state-of-the-art methods.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"obDtZyF0HnVlih_fQB4VTyXG-gFcCjz0qwssU7NIBT0","pdfSize":"3752005"}