{"id":"2407.14069","title":"Self-Supervised Video Representation Learning in a Heuristic Decoupled\n  Perspective","authors":"Zeen Song, Jingyao Wang, Jianqi Zhang, Changwen Zheng, Wenwen Qiang","authorsParsed":[["Song","Zeen",""],["Wang","Jingyao",""],["Zhang","Jianqi",""],["Zheng","Changwen",""],["Qiang","Wenwen",""]],"versions":[{"version":"v1","created":"Fri, 19 Jul 2024 06:53:54 GMT"}],"updateDate":"2024-07-22","timestamp":1721372034000,"abstract":"  Video contrastive learning (v-CL) has gained prominence as a leading\nframework for unsupervised video representation learning, showcasing impressive\nperformance across various tasks such as action classification and detection.\nIn the field of video representation learning, a feature extractor should\nideally capture both static and dynamic semantics. However, our series of\nexperiments reveals that existing v-CL methods predominantly capture static\nsemantics, with limited capturing of dynamic semantics. Through causal\nanalysis, we identify the root cause: the v-CL objective lacks explicit\nmodeling of dynamic features and the measurement of dynamic similarity is\nconfounded by static semantics, while the measurement of static similarity is\nconfounded by dynamic semantics. In response, we propose \"Bi-level Optimization\nof Learning Dynamic with Decoupling and Intervention\" (BOLD-DI) to capture both\nstatic and dynamic semantics in a decoupled manner. Our method can be\nseamlessly integrated into the existing v-CL methods and experimental results\nhighlight the significant improvements.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"7o72R4wkdNHUD0QtF2AMphjRAF_01mku8xu9Qvs8z7Q","pdfSize":"1398692","objectId":"0xd7820d400b62d1b0004494d8977db8c5ecc2cf385e9c29538d76aedbaf1925dc","registeredEpoch":"3","certifiedEpoch":"3","startEpoch":"3","endEpoch":"203"}
