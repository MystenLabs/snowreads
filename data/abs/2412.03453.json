{
  "id": "2412.03453",
  "title": "Pre-trained Multiple Latent Variable Generative Models are good\n  defenders against Adversarial Attacks",
  "authors": "Dario Serez, Marco Cristani, Alessio Del Bue, Vittorio Murino, Pietro\n  Morerio",
  "authorsParsed": [
    [
      "Serez",
      "Dario",
      ""
    ],
    [
      "Cristani",
      "Marco",
      ""
    ],
    [
      "Del Bue",
      "Alessio",
      ""
    ],
    [
      "Murino",
      "Vittorio",
      ""
    ],
    [
      "Morerio",
      "Pietro",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Wed, 4 Dec 2024 16:40:56 GMT"
    }
  ],
  "updateDate": "2024-12-05",
  "timestamp": 1733330456000,
  "abstract": "  Attackers can deliberately perturb classifiers' input with subtle noise,\naltering final predictions. Among proposed countermeasures, adversarial\npurification employs generative networks to preprocess input images, filtering\nout adversarial noise. In this study, we propose specific generators, defined\nMultiple Latent Variable Generative Models (MLVGMs), for adversarial\npurification. These models possess multiple latent variables that naturally\ndisentangle coarse from fine features. Taking advantage of these properties, we\nautoencode images to maintain class-relevant information, while discarding and\nre-sampling any detail, including adversarial noise. The procedure is\ncompletely training-free, exploring the generalization abilities of pre-trained\nMLVGMs on the adversarial purification downstream task. Despite the lack of\nlarge models, trained on billions of samples, we show that smaller MLVGMs are\nalready competitive with traditional methods, and can be used as foundation\nmodels. Official code released at https://github.com/SerezD/gen_adversarial.\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "w1QrivhsfcX3US-vZCZqVuiN73i8cU2vQu3pn0_aiM4",
  "pdfSize": "15852653"
}