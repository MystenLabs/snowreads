{
  "id": "2412.00083",
  "title": "Visual Error Patterns in Multi-Modal AI: A Statistical Approach",
  "authors": "Ching-Yi Wang",
  "authorsParsed": [
    [
      "Wang",
      "Ching-Yi",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Wed, 27 Nov 2024 01:20:08 GMT"
    },
    {
      "version": "v2",
      "created": "Wed, 4 Dec 2024 23:27:34 GMT"
    },
    {
      "version": "v3",
      "created": "Fri, 6 Dec 2024 02:01:54 GMT"
    }
  ],
  "updateDate": "2024-12-09",
  "timestamp": 1732670408000,
  "abstract": "  Multi-modal large language models (MLLMs), such as GPT-4o, excel at\nintegrating text and visual data but face systematic challenges when\ninterpreting ambiguous or incomplete visual stimuli. This study leverages\nstatistical modeling to analyze the factors driving these errors, using a\ndataset of geometric stimuli characterized by features like 3D, rotation, and\nmissing face/side. We applied parametric methods, non-parametric methods, and\nensemble techniques to predict classification errors, with the non-linear\ngradient boosting model achieving the highest performance (AUC=0.85) during\ncross-validation. Feature importance analysis highlighted difficulties in depth\nperception and reconstructing incomplete structures as key contributors to\nmisclassification. These findings demonstrate the effectiveness of statistical\napproaches for uncovering limitations in MLLMs and offer actionable insights\nfor enhancing model architectures by integrating contextual reasoning\nmechanisms.\n",
  "subjects": [
    "Computer Science/Machine Learning",
    "Computer Science/Artificial Intelligence",
    "Computer Science/Computer Vision and Pattern Recognition",
    "Statistics/Applications"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "RFpeYnxuVacS-Jxm7UNfmmN_mnKr3X8WmXTuQ5wVdXY",
  "pdfSize": "1166090"
}