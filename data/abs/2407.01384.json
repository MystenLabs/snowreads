{"id":"2407.01384","title":"Free-text Rationale Generation under Readability Level Control","authors":"Yi-Sheng Hsu, Nils Feldhus, Sherzod Hakimov","authorsParsed":[["Hsu","Yi-Sheng",""],["Feldhus","Nils",""],["Hakimov","Sherzod",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 15:34:17 GMT"}],"updateDate":"2024-07-02","timestamp":1719848057000,"abstract":"  Free-text rationales justify model decisions in natural language and thus\nbecome likable and accessible among approaches to explanation across many\ntasks. However, their effectiveness can be hindered by misinterpretation and\nhallucination. As a perturbation test, we investigate how large language models\n(LLMs) perform the task of natural language explanation (NLE) under the effects\nof readability level control, i.e., being prompted for a rationale targeting a\nspecific expertise level, such as sixth grade or college. We find that\nexplanations are adaptable to such instruction, but the requested readability\nis often misaligned with the measured text complexity according to traditional\nreadability metrics. Furthermore, the quality assessment shows that LLMs'\nratings of rationales across text complexity exhibit a similar pattern of\npreference as observed in natural language generation (NLG). Finally, our human\nevaluation suggests a generally satisfactory impression on rationales at all\nreadability levels, with high-school-level readability being most commonly\nperceived and favored.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"jgERok0ejNzfMuQ4RliAc3qCnYWcf0avrpcmtUucElk","pdfSize":"1044964"}