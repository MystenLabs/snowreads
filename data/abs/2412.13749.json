{"id":"2412.13749","title":"Multi-Exposure Image Fusion via Distilled 3D LUT Grid with Editable Mode","authors":"Xin Su and Zhuoran Zheng","authorsParsed":[["Su","Xin",""],["Zheng","Zhuoran",""]],"versions":[{"version":"v1","created":"Wed, 18 Dec 2024 11:33:16 GMT"}],"updateDate":"2024-12-19","timestamp":1734521596000,"abstract":"  With the rising imaging resolution of handheld devices, existing\nmulti-exposure image fusion algorithms struggle to generate a high dynamic\nrange image with ultra-high resolution in real-time. Apart from that, there is\na trend to design a manageable and editable algorithm as the different needs of\nreal application scenarios. To tackle these issues, we introduce 3D LUT\ntechnology, which can enhance images with ultra-high-definition (UHD)\nresolution in real time on resource-constrained devices. However, since the\nfusion of information from multiple images with different exposure rates is\nuncertain, and this uncertainty significantly trials the generalization power\nof the 3D LUT grid. To address this issue and ensure a robust learning space\nfor the model, we propose using a teacher-student network to model the\nuncertainty on the 3D LUT grid.Furthermore, we provide an editable mode for the\nmulti-exposure image fusion algorithm by using the implicit representation\nfunction to match the requirements in different scenarios. Extensive\nexperiments demonstrate that our proposed method is highly competitive in\nefficiency and accuracy.\n","subjects":["Computer Science/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"nmQPhEu32rmVnrlCo7seoSioIbi7AryVbx5D3g2lXkA","pdfSize":"47770210"}