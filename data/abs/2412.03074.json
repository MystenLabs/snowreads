{
  "id": "2412.03074",
  "title": "Analytic Study of Text-Free Speech Synthesis for Raw Audio using a\n  Self-Supervised Learning Model",
  "authors": "Joonyong Park, Daisuke Saito, Nobuaki Minematsu",
  "authorsParsed": [
    [
      "Park",
      "Joonyong",
      ""
    ],
    [
      "Saito",
      "Daisuke",
      ""
    ],
    [
      "Minematsu",
      "Nobuaki",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Wed, 4 Dec 2024 06:52:03 GMT"
    }
  ],
  "updateDate": "2024-12-05",
  "timestamp": 1733295123000,
  "abstract": "  We examine the text-free speech representations of raw audio obtained from a\nself-supervised learning (SSL) model by analyzing the synthesized speech using\nthe SSL representations instead of conventional text representations. Since raw\naudio does not have paired speech representations as transcribed texts do,\nobtaining speech representations from unpaired speech is crucial for augmenting\navailable datasets for speech synthesis. Specifically, the proposed speech\nsynthesis is conducted using discrete symbol representations from the SSL model\nin comparison with text representations, and analytical examinations of the\nsynthesized speech have been carried out. The results empirically show that\nusing text representations is advantageous for preserving semantic information,\nwhile using discrete symbol representations is superior for preserving acoustic\ncontent, including prosodic and intonational information.\n",
  "subjects": [
    "Computer Science/Computation and Language",
    "Computer Science/Sound",
    "Electrical Engineering and Systems Science/Audio and Speech Processing"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "J-FO7ULfL5gTnVKeHxJAPF1ktL0FFIlViNOeRoHanRY",
  "pdfSize": "451806"
}