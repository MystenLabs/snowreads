{"id":"2412.18207","title":"Sharper Error Bounds in Late Fusion Multi-view Clustering Using\n  Eigenvalue Proportion","authors":"Liang Du, Henghui Jiang, Xiaodong Li, Yiqing Guo, Yan Chen, Feijiang\n  Li, Peng Zhou, Yuhua Qian","authorsParsed":[["Du","Liang",""],["Jiang","Henghui",""],["Li","Xiaodong",""],["Guo","Yiqing",""],["Chen","Yan",""],["Li","Feijiang",""],["Zhou","Peng",""],["Qian","Yuhua",""]],"versions":[{"version":"v1","created":"Tue, 24 Dec 2024 06:24:08 GMT"}],"updateDate":"2024-12-25","timestamp":1735021448000,"abstract":"  Multi-view clustering (MVC) aims to integrate complementary information from\nmultiple views to enhance clustering performance. Late Fusion Multi-View\nClustering (LFMVC) has shown promise by synthesizing diverse clustering results\ninto a unified consensus. However, current LFMVC methods struggle with noisy\nand redundant partitions and often fail to capture high-order correlations\nacross views. To address these limitations, we present a novel theoretical\nframework for analyzing the generalization error bounds of multiple kernel\n$k$-means, leveraging local Rademacher complexity and principal eigenvalue\nproportions. Our analysis establishes a convergence rate of $\\mathcal{O}(1/n)$,\nsignificantly improving upon the existing rate in the order of\n$\\mathcal{O}(\\sqrt{k/n})$. Building on this insight, we propose a low-pass\ngraph filtering strategy within a multiple linear $k$-means framework to\nmitigate noise and redundancy, further refining the principal eigenvalue\nproportion and enhancing clustering accuracy. Experimental results on benchmark\ndatasets confirm that our approach outperforms state-of-the-art methods in\nclustering performance and robustness. The related codes is available at\nhttps://github.com/csliangdu/GMLKM .\n","subjects":["Computer Science/Machine Learning","Computer Science/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"tTa5ooiiyW3JBnzHSU5BgAxKWnnKR9VY0DXOjrlWwJM","pdfSize":"167819"}