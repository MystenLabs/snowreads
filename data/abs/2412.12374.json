{"id":"2412.12374","title":"Privacy in Metalearning and Multitask Learning: Modeling and Separations","authors":"Maryam Aliakbarpour, Konstantina Bairaktari, Adam Smith, Marika\n  Swanberg, Jonathan Ullman","authorsParsed":[["Aliakbarpour","Maryam",""],["Bairaktari","Konstantina",""],["Smith","Adam",""],["Swanberg","Marika",""],["Ullman","Jonathan",""]],"versions":[{"version":"v1","created":"Mon, 16 Dec 2024 22:07:33 GMT"}],"updateDate":"2024-12-18","timestamp":1734386853000,"abstract":"  Model personalization allows a set of individuals, each facing a different\nlearning task, to train models that are more accurate for each person than\nthose they could develop individually. The goals of personalization are\ncaptured in a variety of formal frameworks, such as multitask learning and\nmetalearning. Combining data for model personalization poses risks for privacy\nbecause the output of an individual's model can depend on the data of other\nindividuals. In this work we undertake a systematic study of differentially\nprivate personalized learning. Our first main contribution is to construct a\ntaxonomy of formal frameworks for private personalized learning. This taxonomy\ncaptures different formal frameworks for learning as well as different threat\nmodels for the attacker. Our second main contribution is to prove separations\nbetween the personalized learning problems corresponding to different choices.\nIn particular, we prove a novel separation between private multitask learning\nand private metalearning.\n","subjects":["Computer Science/Machine Learning","Computer Science/Cryptography and Security"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"jFF-kixFlJ9yr1jSNNtLT0kAQIbFvI9bTlObV49kRPQ","pdfSize":"383973"}