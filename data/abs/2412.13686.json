{"id":"2412.13686","title":"A hybrid learning agent for episodic learning tasks with unknown target\n  distance","authors":"Oliver Sefrin, Sabine W\\\"olk","authorsParsed":[["Sefrin","Oliver",""],["WÃ¶lk","Sabine",""]],"versions":[{"version":"v1","created":"Wed, 18 Dec 2024 10:23:46 GMT"}],"updateDate":"2024-12-19","timestamp":1734517426000,"abstract":"  The \"hybrid agent for quantum-accessible reinforcement learning\", as defined\nin (Hamann and W\\\"olk, 2022), provides a proven quasi-quadratic speedup and is\nexperimentally tested. However, the standard version can only be applied to\nepisodic learning tasks with fixed episode length. In many real-world\napplications, the information about the necessary number of steps within an\nepisode to reach a defined target is not available in advance and especially\nbefore reaching the target for the first time. Furthermore, in such scenarios,\nclassical agents have the advantage of observing at which step they reach the\ntarget. Whether the hybrid agent can provide an advantage in such learning\nscenarios was unknown so far. In this work, we introduce a hybrid agent with a\nstochastic episode length selection strategy to alleviate the need for\nknowledge about the necessary episode length. Through simulations, we test the\nadapted hybrid agent's performance versus classical counterparts. We find that\nthe hybrid agent learns faster than corresponding classical learning agents in\ncertain scenarios with unknown target distance and without fixed episode\nlength.\n","subjects":["Physics/Quantum Physics"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"TY1ibEHeBavrZZHiUqorA4zfuXV-q--MICRK7rD8s30","pdfSize":"692904"}