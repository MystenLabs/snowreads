{"id":"2412.14464","title":"LiftRefine: Progressively Refined View Synthesis from 3D Lifting with\n  Volume-Triplane Representations","authors":"Tung Do, Thuan Hoang Nguyen, Anh Tuan Tran, Rang Nguyen, Binh-Son Hua","authorsParsed":[["Do","Tung",""],["Nguyen","Thuan Hoang",""],["Tran","Anh Tuan",""],["Nguyen","Rang",""],["Hua","Binh-Son",""]],"versions":[{"version":"v1","created":"Thu, 19 Dec 2024 02:23:55 GMT"}],"updateDate":"2024-12-20","timestamp":1734575035000,"abstract":"  We propose a new view synthesis method via synthesizing a 3D neural field\nfrom both single or few-view input images. To address the ill-posed nature of\nthe image-to-3D generation problem, we devise a two-stage method that involves\na reconstruction model and a diffusion model for view synthesis. Our\nreconstruction model first lifts one or more input images to the 3D space from\na volume as the coarse-scale 3D representation followed by a tri-plane as the\nfine-scale 3D representation. To mitigate the ambiguity in occluded regions,\nour diffusion model then hallucinates missing details in the rendered images\nfrom tri-planes. We then introduce a new progressive refinement technique that\niteratively applies the reconstruction and diffusion model to gradually\nsynthesize novel views, boosting the overall quality of the 3D representations\nand their rendering. Empirical evaluation demonstrates the superiority of our\nmethod over state-of-the-art methods on the synthetic SRN-Car dataset, the\nin-the-wild CO3D dataset, and large-scale Objaverse dataset while achieving\nboth sampling efficacy and multi-view consistency.\n","subjects":["Computer Science/Computer Vision and Pattern Recognition","Computer Science/Graphics"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"vocvvZ0jrorG6BUAn4tfs1SYIYmsJkgdcRpX1DicZ1E","pdfSize":"23537018"}