{
  "id": "2412.05529",
  "title": "Upcycling Noise for Federated Unlearning",
  "authors": "Jianan Chen, Qin Hu, Fangtian Zhong, Yan Zhuang, Minghui Xu",
  "authorsParsed": [
    [
      "Chen",
      "Jianan",
      ""
    ],
    [
      "Hu",
      "Qin",
      ""
    ],
    [
      "Zhong",
      "Fangtian",
      ""
    ],
    [
      "Zhuang",
      "Yan",
      ""
    ],
    [
      "Xu",
      "Minghui",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Sat, 7 Dec 2024 04:07:40 GMT"
    }
  ],
  "updateDate": "2024-12-10",
  "timestamp": 1733544460000,
  "abstract": "  In Federated Learning (FL), multiple clients collaboratively train a model\nwithout sharing raw data. This paradigm can be further enhanced by Differential\nPrivacy (DP) to protect local data from information inference attacks and is\nthus termed DPFL. An emerging privacy requirement, ``the right to be\nforgotten'' for clients, poses new challenges to DPFL but remains largely\nunexplored. Despite numerous studies on federated unlearning (FU), they are\ninapplicable to DPFL because the noise introduced by the DP mechanism\ncompromises their effectiveness and efficiency. In this paper, we propose\nFederated Unlearning with Indistinguishability (FUI) to unlearn the local data\nof a target client in DPFL for the first time. FUI consists of two main steps:\nlocal model retraction and global noise calibration, resulting in an unlearning\nmodel that is statistically indistinguishable from the retrained model.\nSpecifically, we demonstrate that the noise added in DPFL can endow the\nunlearning model with a certain level of indistinguishability after local model\nretraction, and then fortify the degree of unlearning through global noise\ncalibration. Additionally, for the efficient and consistent implementation of\nthe proposed FUI, we formulate a two-stage Stackelberg game to derive optimal\nunlearning strategies for both the server and the target client. Privacy and\nconvergence analyses confirm theoretical guarantees, while experimental results\nbased on four real-world datasets illustrate that our proposed FUI achieves\nsuperior model performance and higher efficiency compared to mainstream FU\nschemes. Simulation results further verify the optimality of the derived\nunlearning strategies.\n",
  "subjects": [
    "Computer Science/Machine Learning",
    "Computer Science/Cryptography and Security",
    "Computer Science/Distributed, Parallel, and Cluster Computing"
  ],
  "license": "http://creativecommons.org/publicdomain/zero/1.0/",
  "blobId": "diG7CNeTtmowERjsOY4BNK0jAKPxcOosu-_mrAu9Ats",
  "pdfSize": "1934079"
}