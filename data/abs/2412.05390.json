{"id":"2412.05390","title":"Tabular data generation with tensor contraction layers and transformers","authors":"An\\'ibal Silva, Andr\\'e Restivo, Mois\\'es Santos and Carlos Soares","authorsParsed":[["Silva","Aníbal",""],["Restivo","André",""],["Santos","Moisés",""],["Soares","Carlos",""]],"versions":[{"version":"v1","created":"Fri, 6 Dec 2024 19:34:13 GMT"}],"updateDate":"2024-12-10","timestamp":1733513653000,"abstract":"  Generative modeling for tabular data has recently gained significant\nattention in the Deep Learning domain. Its objective is to estimate the\nunderlying distribution of the data. However, estimating the underlying\ndistribution of tabular data has its unique challenges. Specifically, this data\nmodality is composed of mixed types of features, making it a non-trivial task\nfor a model to learn intra-relationships between them. One approach to address\nmixture is to embed each feature into a continuous matrix via tokenization,\nwhile a solution to capture intra-relationships between variables is via the\ntransformer architecture. In this work, we empirically investigate the\npotential of using embedding representations on tabular data generation,\nutilizing tensor contraction layers and transformers to model the underlying\ndistribution of tabular data within Variational Autoencoders. Specifically, we\ncompare four architectural approaches: a baseline VAE model, two variants that\nfocus on tensor contraction layers and transformers respectively, and a hybrid\nmodel that integrates both techniques. Our empirical study, conducted across\nmultiple datasets from the OpenML CC18 suite, compares models over density\nestimation and Machine Learning efficiency metrics. The main takeaway from our\nresults is that leveraging embedding representations with the help of tensor\ncontraction layers improves density estimation metrics, albeit maintaining\ncompetitive performance in terms of machine learning efficiency.\n","subjects":["Computer Science/Machine Learning","Statistics/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"JUV2q8AO2umb1uCpwN3yLsIHUpemiW2MBKO53JwDovI","pdfSize":"5349283"}