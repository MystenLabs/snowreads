{
  "id": "2412.01132",
  "title": "Eyes on the Road: State-of-the-Art Video Question Answering Models\n  Assessment for Traffic Monitoring Tasks",
  "authors": "Joseph Raj Vishal, Divesh Basina, Aarya Choudhary, Bharatesh\n  Chakravarthi",
  "authorsParsed": [
    [
      "Vishal",
      "Joseph Raj",
      ""
    ],
    [
      "Basina",
      "Divesh",
      ""
    ],
    [
      "Choudhary",
      "Aarya",
      ""
    ],
    [
      "Chakravarthi",
      "Bharatesh",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Mon, 2 Dec 2024 05:15:32 GMT"
    }
  ],
  "updateDate": "2024-12-03",
  "timestamp": 1733116532000,
  "abstract": "  Recent advances in video question answering (VideoQA) offer promising\napplications, especially in traffic monitoring, where efficient video\ninterpretation is critical. Within ITS, answering complex, real-time queries\nlike \"How many red cars passed in the last 10 minutes?\" or \"Was there an\nincident between 3:00 PM and 3:05 PM?\" enhances situational awareness and\ndecision-making. Despite progress in vision-language models, VideoQA remains\nchallenging, especially in dynamic environments involving multiple objects and\nintricate spatiotemporal relationships. This study evaluates state-of-the-art\nVideoQA models using non-benchmark synthetic and real-world traffic sequences.\nThe framework leverages GPT-4o to assess accuracy, relevance, and consistency\nacross basic detection, temporal reasoning, and decomposition queries.\nVideoLLaMA-2 excelled with 57% accuracy, particularly in compositional\nreasoning and consistent answers. However, all models, including VideoLLaMA-2,\nfaced limitations in multi-object tracking, temporal coherence, and complex\nscene interpretation, highlighting gaps in current architectures. These\nfindings underscore VideoQA's potential in traffic monitoring but also\nemphasize the need for improvements in multi-object tracking, temporal\nreasoning, and compositional capabilities. Enhancing these areas could make\nVideoQA indispensable for incident detection, traffic flow management, and\nresponsive urban planning. The study's code and framework are open-sourced for\nfurther exploration: https://github.com/joe-rabbit/VideoQA_Pilot_Study\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "LOtdJ6khUuI22AcZtMjK8yM_HX21n4aBDT1s5iJisC4",
  "pdfSize": "2834246"
}