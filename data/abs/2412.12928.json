{
  "id": "2412.12928",
  "title": "Truthful Text Sanitization Guided by Inference Attacks",
  "authors": "Ildik\\'o Pil\\'an, Benet Manzanares-Salor, David S\\'anchez, Pierre\n  Lison",
  "authorsParsed": [
    [
      "Pilán",
      "Ildikó",
      ""
    ],
    [
      "Manzanares-Salor",
      "Benet",
      ""
    ],
    [
      "Sánchez",
      "David",
      ""
    ],
    [
      "Lison",
      "Pierre",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Tue, 17 Dec 2024 14:07:01 GMT"
    }
  ],
  "updateDate": "2024-12-18",
  "timestamp": 1734444421000,
  "abstract": "  The purpose of text sanitization is to rewrite those text spans in a document\nthat may directly or indirectly identify an individual, to ensure they no\nlonger disclose personal information. Text sanitization must strike a balance\nbetween preventing the leakage of personal information (privacy protection)\nwhile also retaining as much of the document's original content as possible\n(utility preservation). We present an automated text sanitization strategy\nbased on generalizations, which are more abstract (but still informative) terms\nthat subsume the semantic content of the original text spans. The approach\nrelies on instruction-tuned large language models (LLMs) and is divided into\ntwo stages. The LLM is first applied to obtain truth-preserving replacement\ncandidates and rank them according to their abstraction level. Those candidates\nare then evaluated for their ability to protect privacy by conducting inference\nattacks with the LLM. Finally, the system selects the most informative\nreplacement shown to be resistant to those attacks. As a consequence of this\ntwo-stage process, the chosen replacements effectively balance utility and\nprivacy. We also present novel metrics to automatically evaluate these two\naspects without the need to manually annotate data. Empirical results on the\nText Anonymization Benchmark show that the proposed approach leads to enhanced\nutility, with only a marginal increase in the risk of re-identifying protected\nindividuals compared to fully suppressing the original information.\nFurthermore, the selected replacements are shown to be more truth-preserving\nand abstractive than previous methods.\n",
  "subjects": [
    "Computer Science/Computation and Language"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "KM3e9GCEIl-nBNHK8dAoTiO4FUiQj0luICQDO5FDQc8",
  "pdfSize": "1328720"
}