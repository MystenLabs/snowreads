{
  "id": "2412.02623",
  "title": "The effect of priors on Learning with Restricted Boltzmann Machines",
  "authors": "Gianluca Manzan and Daniele Tantari",
  "authorsParsed": [
    [
      "Manzan",
      "Gianluca",
      ""
    ],
    [
      "Tantari",
      "Daniele",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Tue, 3 Dec 2024 17:52:38 GMT"
    }
  ],
  "updateDate": "2024-12-04",
  "timestamp": 1733248358000,
  "abstract": "  Restricted Boltzmann Machines (RBMs) are generative models designed to learn\nfrom data with a rich underlying structure. In this work, we explore a\nteacher-student setting where a student RBM learns from examples generated by a\nteacher RBM, with a focus on the effect of the unit priors on learning\nefficiency. We consider a parametric class of priors that interpolate between\ncontinuous (Gaussian) and binary variables. This approach models various\npossible choices of visible units, hidden units, and weights for both the\nteacher and student RBMs.\n  By analyzing the phase diagram of the posterior distribution in both the\nBayes optimal and mismatched regimes, we demonstrate the existence of a triple\npoint that defines the critical dataset size necessary for learning through\ngeneralization. The critical size is strongly influenced by the properties of\nthe teacher, and thus the data, but is unaffected by the properties of the\nstudent RBM. Nevertheless, a prudent choice of student priors can facilitate\ntraining by expanding the so-called signal retrieval region, where the machine\ngeneralizes effectively.\n",
  "subjects": [
    "Condensed Matter/Disordered Systems and Neural Networks",
    "Computer Science/Machine Learning"
  ],
  "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
  "blobId": "2A6K8IWYRPEJEl91WAq-Q4OHUjsZkK6dSYhJV6t22Dk",
  "pdfSize": "1323789"
}