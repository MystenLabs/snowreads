{"id":"2407.17447","title":"Fluent Student-Teacher Redteaming","authors":"T. Ben Thompson and Michael Sklar (Confirm Labs)","authorsParsed":[["Thompson","T. Ben","","Confirm Labs"],["Sklar","Michael","","Confirm Labs"]],"versions":[{"version":"v1","created":"Wed, 24 Jul 2024 17:23:18 GMT"}],"updateDate":"2024-07-26","timestamp":1721841798000,"abstract":"  Many publicly available language models have been safety tuned to reduce the\nlikelihood of toxic or liability-inducing text. Users or security analysts\nattempt to jailbreak or redteam these models with adversarial prompts which\ncause compliance with requests. One attack method is to apply discrete\noptimization techniques to the prompt. However, the resulting attack strings\nare often gibberish text, easily filtered by defenders due to high measured\nperplexity, and may fail for unseen tasks and/or well-tuned models. In this\nwork, we improve existing algorithms (primarily GCG and BEAST) to develop\npowerful and fluent attacks on safety-tuned models like Llama-2 and Phi-3. Our\ntechnique centers around a new distillation-based approach that encourages the\nvictim model to emulate a toxified finetune, either in terms of output\nprobabilities or internal activations. To encourage human-fluent attacks, we\nadd a multi-model perplexity penalty and a repetition penalty to the objective.\nWe also enhance optimizer strength by allowing token insertions, token swaps,\nand token deletions and by using longer attack sequences. The resulting process\nis able to reliably jailbreak the most difficult target models with prompts\nthat appear similar to human-written prompts. On Advbench we achieve attack\nsuccess rates $>93$% for Llama-2-7B, Llama-3-8B, and Vicuna-7B, while\nmaintaining model-measured perplexity $<33$; we achieve $95$% attack success\nfor Phi-3, though with higher perplexity. We also find a universally-optimized\nsingle fluent prompt that induces $>88$% compliance on previously unseen tasks\nacross Llama-2-7B, Phi-3-mini and Vicuna-7B and transfers to other black-box\nmodels.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"1S5xz5OwyPwxAywUi-3_0M9fr622OTd3ot9_jiSOKns","pdfSize":"1216644"}