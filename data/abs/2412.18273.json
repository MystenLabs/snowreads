{
  "id": "2412.18273",
  "title": "Sampling Bag of Views for Open-Vocabulary Object Detection",
  "authors": "Hojun Choi, Junsuk Choe, Hyunjung Shim",
  "authorsParsed": [
    [
      "Choi",
      "Hojun",
      ""
    ],
    [
      "Choe",
      "Junsuk",
      ""
    ],
    [
      "Shim",
      "Hyunjung",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Tue, 24 Dec 2024 08:32:38 GMT"
    }
  ],
  "updateDate": "2024-12-25",
  "timestamp": 1735029158000,
  "abstract": "  Existing open-vocabulary object detection (OVD) develops methods for testing\nunseen categories by aligning object region embeddings with corresponding VLM\nfeatures. A recent study leverages the idea that VLMs implicitly learn\ncompositional structures of semantic concepts within the image. Instead of\nusing an individual region embedding, it utilizes a bag of region embeddings as\na new representation to incorporate compositional structures into the OVD task.\nHowever, this approach often fails to capture the contextual concepts of each\nregion, leading to noisy compositional structures. This results in only\nmarginal performance improvements and reduced efficiency. To address this, we\npropose a novel concept-based alignment method that samples a more powerful and\nefficient compositional structure. Our approach groups contextually related\n``concepts'' into a bag and adjusts the scale of concepts within the bag for\nmore effective embedding alignment. Combined with Faster R-CNN, our method\nachieves improvements of 2.6 box AP50 and 0.5 mask AP over prior work on novel\ncategories in the open-vocabulary COCO and LVIS benchmarks. Furthermore, our\nmethod reduces CLIP computation in FLOPs by 80.3% compared to previous\nresearch, significantly enhancing efficiency. Experimental results demonstrate\nthat the proposed method outperforms previous state-of-the-art models on the\nOVD datasets.\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition",
    "Computer Science/Artificial Intelligence"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "y2kV-r48bAWlSEXWd2f-qF0eWE-x6zBjvSNhDvG52aM",
  "pdfSize": "4823082"
}