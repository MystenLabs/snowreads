{"id":"2407.12950","title":"Beyond the Veil of Similarity: Quantifying Semantic Continuity in\n  Explainable AI","authors":"Qi Huang, Emanuele Mezzi, Osman Mutlu, Miltiadis Kofinas, Vidya\n  Prasad, Shadnan Azwad Khan, Elena Ranguelova and Niki van Stein","authorsParsed":[["Huang","Qi",""],["Mezzi","Emanuele",""],["Mutlu","Osman",""],["Kofinas","Miltiadis",""],["Prasad","Vidya",""],["Khan","Shadnan Azwad",""],["Ranguelova","Elena",""],["van Stein","Niki",""]],"versions":[{"version":"v1","created":"Wed, 17 Jul 2024 18:32:41 GMT"}],"updateDate":"2024-07-19","timestamp":1721241161000,"abstract":"  We introduce a novel metric for measuring semantic continuity in Explainable\nAI methods and machine learning models. We posit that for models to be truly\ninterpretable and trustworthy, similar inputs should yield similar\nexplanations, reflecting a consistent semantic understanding. By leveraging XAI\ntechniques, we assess semantic continuity in the task of image recognition. We\nconduct experiments to observe how incremental changes in input affect the\nexplanations provided by different XAI methods. Through this approach, we aim\nto evaluate the models' capability to generalize and abstract semantic concepts\naccurately and to evaluate different XAI methods in correctly capturing the\nmodel behaviour. This paper contributes to the broader discourse on AI\ninterpretability by proposing a quantitative measure for semantic continuity\nfor XAI methods, offering insights into the models' and explainers' internal\nreasoning processes, and promoting more reliable and transparent AI systems.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"HIfF5iPwEU_FJHxL39FDU1_jML-qHduvh0GdMsxIO-o","pdfSize":"8009731"}