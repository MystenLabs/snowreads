{"id":"2407.12288","title":"Information-Theoretic Foundations for Machine Learning","authors":"Hong Jun Jeon, Benjamin Van Roy","authorsParsed":[["Jeon","Hong Jun",""],["Van Roy","Benjamin",""]],"versions":[{"version":"v1","created":"Wed, 17 Jul 2024 03:18:40 GMT"},{"version":"v2","created":"Thu, 18 Jul 2024 14:35:39 GMT"},{"version":"v3","created":"Tue, 20 Aug 2024 05:34:20 GMT"}],"updateDate":"2024-08-21","timestamp":1721186320000,"abstract":"  The staggering progress of machine learning in the past decade has been a\nsight to behold. In retrospect, it is both remarkable and unsettling that these\nmilestones were achievable with little to no rigorous theory to guide\nexperimentation. Despite this fact, practitioners have been able to guide their\nfuture experimentation via observations from previous large-scale empirical\ninvestigations. However, alluding to Plato's Allegory of the cave, it is likely\nthat the observations which form the field's notion of reality are but shadows\nrepresenting fragments of that reality. In this work, we propose a theoretical\nframework which attempts to answer what exists outside of the cave. To the\ntheorist, we provide a framework which is mathematically rigorous and leaves\nopen many interesting ideas for future exploration. To the practitioner, we\nprovide a framework whose results are very intuitive, general, and which will\nhelp form principles to guide future investigations. Concretely, we provide a\ntheoretical framework rooted in Bayesian statistics and Shannon's information\ntheory which is general enough to unify the analysis of many phenomena in\nmachine learning. Our framework characterizes the performance of an optimal\nBayesian learner, which considers the fundamental limits of information.\nThroughout this work, we derive very general theoretical results and apply them\nto derive insights specific to settings ranging from data which is\nindependently and identically distributed under an unknown distribution, to\ndata which is sequential, to data which exhibits hierarchical structure\namenable to meta-learning. We conclude with a section dedicated to\ncharacterizing the performance of misspecified algorithms. These results are\nexciting and particularly relevant as we strive to overcome increasingly\ndifficult machine learning challenges in this endlessly complex world.\n","subjects":["Statistics/Machine Learning","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"RQxOsG8Cv-Ut24wf1trjQH_NCIK_PbGlwqQcTKhlt38","pdfSize":"1363271"}