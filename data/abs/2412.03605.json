{"id":"2412.03605","title":"CBEval: A framework for evaluating and interpreting cognitive biases in\n  LLMs","authors":"Ammar Shaikh, Raj Abhijit Dandekar, Sreedath Panat, Rajat Dandekar","authorsParsed":[["Shaikh","Ammar",""],["Dandekar","Raj Abhijit",""],["Panat","Sreedath",""],["Dandekar","Rajat",""]],"versions":[{"version":"v1","created":"Wed, 4 Dec 2024 05:53:28 GMT"}],"updateDate":"2024-12-06","timestamp":1733291608000,"abstract":"  Rapid advancements in Large Language models (LLMs) has significantly enhanced\ntheir reasoning capabilities. Despite improved performance on benchmarks, LLMs\nexhibit notable gaps in their cognitive processes. Additionally, as reflections\nof human-generated data, these models have the potential to inherit cognitive\nbiases, raising concerns about their reasoning and decision making\ncapabilities. In this paper we present a framework to interpret, understand and\nprovide insights into a host of cognitive biases in LLMs. Conducting our\nresearch on frontier language models we're able to elucidate reasoning\nlimitations and biases, and provide reasoning behind these biases by\nconstructing influence graphs that identify phrases and words most responsible\nfor biases manifested in LLMs. We further investigate biases such as round\nnumber bias and cognitive bias barrier revealed when noting framing effect in\nlanguage models.\n","subjects":["Computer Science/Computation and Language","Computer Science/Artificial Intelligence","Computer Science/Human-Computer Interaction"],"license":"http://creativecommons.org/licenses/by-sa/4.0/","blobId":"VNM482_I2Hmh5H1-OOglehNrfhLUGtYfJJ-3CZ8SnZ8","pdfSize":"160801"}