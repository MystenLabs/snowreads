{
  "id": "2412.15246",
  "title": "Accelerating Retrieval-Augmented Generation",
  "authors": "Derrick Quinn, Mohammad Nouri, Neel Patel, John Salihu, Alireza\n  Salemi, Sukhan Lee, Hamed Zamani, Mohammad Alian",
  "authorsParsed": [
    [
      "Quinn",
      "Derrick",
      ""
    ],
    [
      "Nouri",
      "Mohammad",
      ""
    ],
    [
      "Patel",
      "Neel",
      ""
    ],
    [
      "Salihu",
      "John",
      ""
    ],
    [
      "Salemi",
      "Alireza",
      ""
    ],
    [
      "Lee",
      "Sukhan",
      ""
    ],
    [
      "Zamani",
      "Hamed",
      ""
    ],
    [
      "Alian",
      "Mohammad",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Sat, 14 Dec 2024 06:47:56 GMT"
    }
  ],
  "updateDate": "2024-12-23",
  "timestamp": 1734158876000,
  "abstract": "  An evolving solution to address hallucination and enhance accuracy in large\nlanguage models (LLMs) is Retrieval-Augmented Generation (RAG), which involves\naugmenting LLMs with information retrieved from an external knowledge source,\nsuch as the web. This paper profiles several RAG execution pipelines and\ndemystifies the complex interplay between their retrieval and generation\nphases. We demonstrate that while exact retrieval schemes are expensive, they\ncan reduce inference time compared to approximate retrieval variants because an\nexact retrieval model can send a smaller but more accurate list of documents to\nthe generative model while maintaining the same end-to-end accuracy. This\nobservation motivates the acceleration of the exact nearest neighbor search for\nRAG.\n  In this work, we design Intelligent Knowledge Store (IKS), a type-2 CXL\ndevice that implements a scale-out near-memory acceleration architecture with a\nnovel cache-coherent interface between the host CPU and near-memory\naccelerators. IKS offers 13.4-27.9x faster exact nearest neighbor search over a\n512GB vector database compared with executing the search on Intel Sapphire\nRapids CPUs. This higher search performance translates to 1.7-26.3x lower\nend-to-end inference time for representative RAG applications. IKS is\ninherently a memory expander; its internal DRAM can be disaggregated and used\nfor other applications running on the server to prevent DRAM, which is the most\nexpensive component in today's servers, from being stranded.\n",
  "subjects": [
    "Computer Science/Computation and Language",
    "Computer Science/Artificial Intelligence",
    "Computer Science/Hardware Architecture",
    "Computer Science/Distributed, Parallel, and Cluster Computing",
    "Computer Science/Information Retrieval"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "jxP_YrRmaHMOj6e0Gi_5c8ffzVQ3gIr6Hogrfssxsxo",
  "pdfSize": "1632547"
}