{
  "id": "2412.05035",
  "title": "SMIC: Semantic Multi-Item Compression based on CLIP dictionary",
  "authors": "Tom Bachard and Thomas Maugey",
  "authorsParsed": [
    [
      "Bachard",
      "Tom",
      ""
    ],
    [
      "Maugey",
      "Thomas",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Fri, 6 Dec 2024 13:39:36 GMT"
    }
  ],
  "updateDate": "2024-12-09",
  "timestamp": 1733492376000,
  "abstract": "  Semantic compression, a compression scheme where the distortion metric,\ntypically MSE, is replaced with semantic fidelity metrics, tends to become more\nand more popular. Most recent semantic compression schemes rely on the\nfoundation model CLIP. In this work, we extend such a scheme to image\ncollection compression, where inter-item redundancy is taken into account\nduring the coding phase. For that purpose, we first show that CLIP's latent\nspace allows for easy semantic additions and subtractions. From this property,\nwe define a dictionary-based multi-item codec that outperforms state-of-the-art\ngenerative codec in terms of compression rate, around $10^{-5}$ BPP per image,\nwhile not sacrificing semantic fidelity. We also show that the learned\ndictionary is of a semantic nature and works as a semantic projector for the\nsemantic content of images.\n",
  "subjects": [
    "Electrical Engineering and Systems Science/Image and Video Processing",
    "Computer Science/Computer Vision and Pattern Recognition",
    "Computer Science/Multimedia"
  ],
  "license": "http://creativecommons.org/licenses/by-sa/4.0/",
  "blobId": "wmUza_SmrUuCloJe8pO8wwafNRgzZD6Yg3oob4kYrBI",
  "pdfSize": "14708872"
}