{"id":"2407.11770","title":"Robust Utility-Preserving Text Anonymization Based on Large Language\n  Models","authors":"Tianyu Yang and Xiaodan Zhu and Iryna Gurevych","authorsParsed":[["Yang","Tianyu",""],["Zhu","Xiaodan",""],["Gurevych","Iryna",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 14:28:56 GMT"}],"updateDate":"2024-07-17","timestamp":1721140136000,"abstract":"  Text anonymization is crucial for sharing sensitive data while maintaining\nprivacy. Existing techniques face the emerging challenges of re-identification\nattack ability of Large Language Models (LLMs), which have shown advanced\ncapability in memorizing detailed information and patterns as well as\nconnecting disparate pieces of information. In defending against LLM-based\nre-identification attacks, anonymization could jeopardize the utility of the\nresulting anonymized data in downstream tasks -- the trade-off between privacy\nand data utility requires deeper understanding within the context of LLMs. This\npaper proposes a framework composed of three LLM-based components -- a privacy\nevaluator, a utility evaluator, and an optimization component, which work\ncollaboratively to perform anonymization. To provide a practical model for\nlarge-scale and real-time environments, we distill the anonymization\ncapabilities into a lightweight model using Direct Preference Optimization\n(DPO). Extensive experiments demonstrate that the proposed models outperform\nbaseline models, showing robustness in reducing the risk of re-identification\nwhile preserving greater data utility in downstream tasks. Our code and dataset\nare available at https://github.com/UKPLab/arxiv2024-rupta.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by-sa/4.0/","blobId":"r3bZZc8FHeYgtfp7O-6aUeYCjdzEa98nNLtC8sDRrC8","pdfSize":"1206657"}