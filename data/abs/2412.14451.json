{
  "id": "2412.14451",
  "title": "CLDG: Contrastive Learning on Dynamic Graphs",
  "authors": "Yiming Xu, Bin Shi, Teng Ma, Bo Dong, Haoyi Zhou, Qinghua Zheng",
  "authorsParsed": [
    [
      "Xu",
      "Yiming",
      ""
    ],
    [
      "Shi",
      "Bin",
      ""
    ],
    [
      "Ma",
      "Teng",
      ""
    ],
    [
      "Dong",
      "Bo",
      ""
    ],
    [
      "Zhou",
      "Haoyi",
      ""
    ],
    [
      "Zheng",
      "Qinghua",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Thu, 19 Dec 2024 01:59:24 GMT"
    }
  ],
  "updateDate": "2024-12-20",
  "timestamp": 1734573564000,
  "abstract": "  The graph with complex annotations is the most potent data type, whose\nconstantly evolving motivates further exploration of the unsupervised dynamic\ngraph representation. One of the representative paradigms is graph contrastive\nlearning. It constructs self-supervised signals by maximizing the mutual\ninformation between the statistic graph's augmentation views. However, the\nsemantics and labels may change within the augmentation process, causing a\nsignificant performance drop in downstream tasks. This drawback becomes greatly\nmagnified on dynamic graphs. To address this problem, we designed a simple yet\neffective framework named CLDG. Firstly, we elaborate that dynamic graphs have\ntemporal translation invariance at different levels. Then, we proposed a\nsampling layer to extract the temporally-persistent signals. It will encourage\nthe node to maintain consistent local and global representations, i.e.,\ntemporal translation invariance under the timespan views. The extensive\nexperiments demonstrate the effectiveness and efficiency of the method on seven\ndatasets by outperforming eight unsupervised state-of-the-art baselines and\nshowing competitiveness against four semi-supervised methods. Compared with the\nexisting dynamic graph method, the number of model parameters and training time\nis reduced by an average of 2,001.86 times and 130.31 times on seven datasets,\nrespectively.\n",
  "subjects": [
    "Computer Science/Machine Learning",
    "Computer Science/Artificial Intelligence"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "st--1elm8EXW1ByuXMxpTUbRvQXdb2iIKw6j7AVw1Aw",
  "pdfSize": "4157849"
}