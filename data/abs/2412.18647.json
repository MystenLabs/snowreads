{
  "id": "2412.18647",
  "title": "Nationality, Race, and Ethnicity Biases in and Consequences of Detecting\n  AI-Generated Self-Presentations",
  "authors": "Haoran Chu, Linjuan Rita Men, Sixiao Liu, Shupei Yuan, Yuan Sun",
  "authorsParsed": [
    [
      "Chu",
      "Haoran",
      ""
    ],
    [
      "Men",
      "Linjuan Rita",
      ""
    ],
    [
      "Liu",
      "Sixiao",
      ""
    ],
    [
      "Yuan",
      "Shupei",
      ""
    ],
    [
      "Sun",
      "Yuan",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Tue, 24 Dec 2024 18:31:44 GMT"
    }
  ],
  "updateDate": "2024-12-30",
  "timestamp": 1735065104000,
  "abstract": "  This study builds on person perception and human AI interaction (HAII)\ntheories to investigate how content and source cues, specifically race,\nethnicity, and nationality, affect judgments of AI-generated content in a\nhigh-stakes self-presentation context: college applications. Results of a\npre-registered experiment with a nationally representative U.S. sample (N =\n644) show that content heuristics, such as linguistic style, played a dominant\nrole in AI detection. Source heuristics, such as nationality, also emerged as a\nsignificant factor, with international students more likely to be perceived as\nusing AI, especially when their statements included AI-sounding features.\nInterestingly, Asian and Hispanic applicants were more likely to be judged as\nAI users when labeled as domestic students, suggesting interactions between\nracial stereotypes and AI detection. AI attribution led to lower perceptions of\npersonal statement quality and authenticity, as well as negative evaluations of\nthe applicant's competence, sociability, morality, and future success.\n",
  "subjects": [
    "Computer Science/Artificial Intelligence",
    "Computer Science/Human-Computer Interaction"
  ],
  "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
  "blobId": "sBRJSW8FiYTTuT4vB1ur7HS4nTIQRPtvgY-_eOyxKMQ",
  "pdfSize": "462833"
}