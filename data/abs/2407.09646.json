{"id":"2407.09646","title":"Hamba: Single-view 3D Hand Reconstruction with Graph-guided Bi-Scanning\n  Mamba","authors":"Haoye Dong, Aviral Chharia, Wenbo Gou, Francisco Vicente Carrasco,\n  Fernando De la Torre","authorsParsed":[["Dong","Haoye",""],["Chharia","Aviral",""],["Gou","Wenbo",""],["Carrasco","Francisco Vicente",""],["De la Torre","Fernando",""]],"versions":[{"version":"v1","created":"Fri, 12 Jul 2024 19:04:58 GMT"}],"updateDate":"2024-07-16","timestamp":1720811098000,"abstract":"  3D Hand reconstruction from a single RGB image is challenging due to the\narticulated motion, self-occlusion, and interaction with objects. Existing SOTA\nmethods employ attention-based transformers to learn the 3D hand pose and\nshape, but they fail to achieve robust and accurate performance due to\ninsufficient modeling of joint spatial relations. To address this problem, we\npropose a novel graph-guided Mamba framework, named Hamba, which bridges graph\nlearning and state space modeling. Our core idea is to reformulate Mamba's\nscanning into graph-guided bidirectional scanning for 3D reconstruction using a\nfew effective tokens. This enables us to learn the joint relations and spatial\nsequences for enhancing the reconstruction performance. Specifically, we design\na novel Graph-guided State Space (GSS) block that learns the graph-structured\nrelations and spatial sequences of joints and uses 88.5% fewer tokens than\nattention-based methods. Additionally, we integrate the state space features\nand the global features using a fusion module. By utilizing the GSS block and\nthe fusion module, Hamba effectively leverages the graph-guided state space\nmodeling features and jointly considers global and local features to improve\nperformance. Extensive experiments on several benchmarks and in-the-wild tests\ndemonstrate that Hamba significantly outperforms existing SOTAs, achieving the\nPA-MPVPE of 5.3mm and F@15mm of 0.992 on FreiHAND. Hamba is currently Rank 1 in\ntwo challenging competition leaderboards on 3D hand reconstruction. The code\nwill be available upon acceptance.\n[Website](https://humansensinglab.github.io/Hamba/).\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"tRNemzT5GoYUI--KXnAfZKJbRtyYg2aGZwujxTVM6bg","pdfSize":"15510903"}