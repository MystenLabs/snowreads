{"id":"2407.10005","title":"Fine-grained Analysis of In-context Linear Estimation: Data,\n  Architecture, and Beyond","authors":"Yingcong Li, Ankit Singh Rawat, Samet Oymak","authorsParsed":[["Li","Yingcong",""],["Rawat","Ankit Singh",""],["Oymak","Samet",""]],"versions":[{"version":"v1","created":"Sat, 13 Jul 2024 21:13:55 GMT"}],"updateDate":"2024-07-16","timestamp":1720905235000,"abstract":"  Recent research has shown that Transformers with linear attention are capable\nof in-context learning (ICL) by implementing a linear estimator through\ngradient descent steps. However, the existing results on the optimization\nlandscape apply under stylized settings where task and feature vectors are\nassumed to be IID and the attention weights are fully parameterized. In this\nwork, we develop a stronger characterization of the optimization and\ngeneralization landscape of ICL through contributions on architectures,\nlow-rank parameterization, and correlated designs: (1) We study the landscape\nof 1-layer linear attention and 1-layer H3, a state-space model. Under a\nsuitable correlated design assumption, we prove that both implement 1-step\npreconditioned gradient descent. We show that thanks to its native convolution\nfilters, H3 also has the advantage of implementing sample weighting and\noutperforming linear attention in suitable settings. (2) By studying correlated\ndesigns, we provide new risk bounds for retrieval augmented generation (RAG)\nand task-feature alignment which reveal how ICL sample complexity benefits from\ndistributional alignment. (3) We derive the optimal risk for low-rank\nparameterized attention weights in terms of covariance spectrum. Through this,\nwe also shed light on how LoRA can adapt to a new distribution by capturing the\nshift between task covariances. Experimental results corroborate our\ntheoretical findings. Overall, this work explores the optimization and risk\nlandscape of ICL in practically meaningful settings and contributes to a more\nthorough understanding of its mechanics.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language","Mathematics/Optimization and Control"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"M6J73TrZHGoxoohrCm2RpBW_LWP9ZHPQtfd25Z5kyFc","pdfSize":"769916"}