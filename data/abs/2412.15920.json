{"id":"2412.15920","title":"Data Preparation for Fairness-Performance Trade-Offs: A\n  Practitioner-Friendly Alternative?","authors":"Gianmario Voria, Rebecca Di Matteo, Giammaria Giordano, Gemma\n  Catolino, Fabio Palomba","authorsParsed":[["Voria","Gianmario",""],["Di Matteo","Rebecca",""],["Giordano","Giammaria",""],["Catolino","Gemma",""],["Palomba","Fabio",""]],"versions":[{"version":"v1","created":"Fri, 20 Dec 2024 14:12:39 GMT"}],"updateDate":"2024-12-23","timestamp":1734703959000,"abstract":"  As machine learning (ML) systems are increasingly adopted across industries,\naddressing fairness and bias has become essential. While many solutions focus\non ethical challenges in ML, recent studies highlight that data itself is a\nmajor source of bias. Pre-processing techniques, which mitigate bias before\ntraining, are effective but may impact model performance and pose integration\ndifficulties. In contrast, fairness-aware Data Preparation practices are both\nfamiliar to practitioners and easier to implement, providing a more accessible\napproach to reducing bias. Objective. This registered report proposes an\nempirical evaluation of how optimally selected fairness-aware practices,\napplied in early ML lifecycle stages, can enhance both fairness and\nperformance, potentially outperforming standard pre-processing bias mitigation\nmethods. Method. To this end, we will introduce FATE, an optimization technique\nfor selecting 'Data Preparation' pipelines that optimize fairness and\nperformance. Using FATE, we will analyze the fairness-performance trade-off,\ncomparing pipelines selected by FATE with results by pre-processing bias\nmitigation techniques.\n","subjects":["Computer Science/Software Engineering","Computer Science/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"qkUsKmn6N1DNyKTGTHgYfJxs7cHFiSvc_0UxLrHpizE","pdfSize":"400555"}