{
  "id": "2412.14642",
  "title": "TOMG-Bench: Evaluating LLMs on Text-based Open Molecule Generation",
  "authors": "Jiatong Li, Junxian Li, Yunqing Liu, Dongzhan Zhou, and Qing Li",
  "authorsParsed": [
    [
      "Li",
      "Jiatong",
      ""
    ],
    [
      "Li",
      "Junxian",
      ""
    ],
    [
      "Liu",
      "Yunqing",
      ""
    ],
    [
      "Zhou",
      "Dongzhan",
      ""
    ],
    [
      "Li",
      "Qing",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Thu, 19 Dec 2024 08:51:16 GMT"
    }
  ],
  "updateDate": "2024-12-20",
  "timestamp": 1734598276000,
  "abstract": "  In this paper, we propose Text-based Open Molecule Generation Benchmark\n(TOMG-Bench), the first benchmark to evaluate the open-domain molecule\ngeneration capability of LLMs. TOMG-Bench encompasses a dataset of three major\ntasks: molecule editing (MolEdit), molecule optimization (MolOpt), and\ncustomized molecule generation (MolCustom). Each task further contains three\nsubtasks, with each subtask comprising 5,000 test samples. Given the inherent\ncomplexity of open molecule generation, we have also developed an automated\nevaluation system that helps measure both the quality and the accuracy of the\ngenerated molecules. Our comprehensive benchmarking of 25 LLMs reveals the\ncurrent limitations and potential areas for improvement in text-guided molecule\ndiscovery. Furthermore, with the assistance of OpenMolIns, a specialized\ninstruction tuning dataset proposed for solving challenges raised by\nTOMG-Bench, Llama3.1-8B could outperform all the open-source general LLMs, even\nsurpassing GPT-3.5-turbo by 46.5\\% on TOMG-Bench. Our codes and datasets are\navailable through https://github.com/phenixace/TOMG-Bench.\n",
  "subjects": [
    "Computer Science/Computation and Language"
  ],
  "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
  "blobId": "4DyIPTkR2Rz6R2rS3TPPgwWXsydbCippDM15bdXKK9Y",
  "pdfSize": "1419051"
}