{
  "id": "2412.13195",
  "title": "CoMPaSS: Enhancing Spatial Understanding in Text-to-Image Diffusion\n  Models",
  "authors": "Gaoyang Zhang, Bingtao Fu, Qingnan Fan, Qi Zhang, Runxing Liu, Hong\n  Gu, Huaqi Zhang, Xinguo Liu",
  "authorsParsed": [
    [
      "Zhang",
      "Gaoyang",
      ""
    ],
    [
      "Fu",
      "Bingtao",
      ""
    ],
    [
      "Fan",
      "Qingnan",
      ""
    ],
    [
      "Zhang",
      "Qi",
      ""
    ],
    [
      "Liu",
      "Runxing",
      ""
    ],
    [
      "Gu",
      "Hong",
      ""
    ],
    [
      "Zhang",
      "Huaqi",
      ""
    ],
    [
      "Liu",
      "Xinguo",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Tue, 17 Dec 2024 18:59:50 GMT"
    }
  ],
  "updateDate": "2024-12-18",
  "timestamp": 1734461990000,
  "abstract": "  Text-to-image diffusion models excel at generating photorealistic images, but\ncommonly struggle to render accurate spatial relationships described in text\nprompts. We identify two core issues underlying this common failure: 1) the\nambiguous nature of spatial-related data in existing datasets, and 2) the\ninability of current text encoders to accurately interpret the spatial\nsemantics of input descriptions. We address these issues with CoMPaSS, a\nversatile training framework that enhances spatial understanding of any T2I\ndiffusion model. CoMPaSS solves the ambiguity of spatial-related data with the\nSpatial Constraints-Oriented Pairing (SCOP) data engine, which curates\nspatially-accurate training data through a set of principled spatial\nconstraints. To better exploit the curated high-quality spatial priors, CoMPaSS\nfurther introduces a Token ENcoding ORdering (TENOR) module to allow better\nexploitation of high-quality spatial priors, effectively compensating for the\nshortcoming of text encoders. Extensive experiments on four popular open-weight\nT2I diffusion models covering both UNet- and MMDiT-based architectures\ndemonstrate the effectiveness of CoMPaSS by setting new state-of-the-arts with\nsubstantial relative gains across well-known benchmarks on spatial\nrelationships generation, including VISOR (+98%), T2I-CompBench Spatial (+67%),\nand GenEval Position (+131%). Code will be available at\nhttps://github.com/blurgyy/CoMPaSS.\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "K4zSUp2Gvg0lQgN-4pSvewN5bgFINePgpOYeermJagE",
  "pdfSize": "10980682"
}