{"id":"2412.10704","title":"VisDoM: Multi-Document QA with Visually Rich Elements Using Multimodal\n  Retrieval-Augmented Generation","authors":"Manan Suri, Puneet Mathur, Franck Dernoncourt, Kanika Goswami, Ryan A.\n  Rossi, Dinesh Manocha","authorsParsed":[["Suri","Manan",""],["Mathur","Puneet",""],["Dernoncourt","Franck",""],["Goswami","Kanika",""],["Rossi","Ryan A.",""],["Manocha","Dinesh",""]],"versions":[{"version":"v1","created":"Sat, 14 Dec 2024 06:24:55 GMT"},{"version":"v2","created":"Tue, 11 Feb 2025 07:05:58 GMT"}],"updateDate":"2025-02-12","timestamp":1734157495000,"abstract":"  Understanding information from a collection of multiple documents,\nparticularly those with visually rich elements, is important for\ndocument-grounded question answering. This paper introduces VisDoMBench, the\nfirst comprehensive benchmark designed to evaluate QA systems in multi-document\nsettings with rich multimodal content, including tables, charts, and\npresentation slides. We propose VisDoMRAG, a novel multimodal Retrieval\nAugmented Generation (RAG) approach that simultaneously utilizes visual and\ntextual RAG, combining robust visual retrieval capabilities with sophisticated\nlinguistic reasoning. VisDoMRAG employs a multi-step reasoning process\nencompassing evidence curation and chain-of-thought reasoning for concurrent\ntextual and visual RAG pipelines. A key novelty of VisDoMRAG is its\nconsistency-constrained modality fusion mechanism, which aligns the reasoning\nprocesses across modalities at inference time to produce a coherent final\nanswer. This leads to enhanced accuracy in scenarios where critical information\nis distributed across modalities and improved answer verifiability through\nimplicit context attribution. Through extensive experiments involving\nopen-source and proprietary large language models, we benchmark\nstate-of-the-art document QA methods on VisDoMBench. Extensive results show\nthat VisDoMRAG outperforms unimodal and long-context LLM baselines for\nend-to-end multimodal document QA by 12-20%.\n","subjects":["Computer Science/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"NvpOeiQe0vGaRhQBKTUx81uY5Lq1ngexpISy3VbO3Y0","pdfSize":"6617437"}