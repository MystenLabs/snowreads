{"id":"2407.12875","title":"ChatBCG: Can AI Read Your Slide Deck?","authors":"Nikita Singh, Rob Balian, Lukas Martinelli","authorsParsed":[["Singh","Nikita",""],["Balian","Rob",""],["Martinelli","Lukas",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 06:00:45 GMT"}],"updateDate":"2024-07-19","timestamp":1721109645000,"abstract":"  Multimodal models like GPT4o and Gemini Flash are exceptional at inference\nand summarization tasks, which approach human-level in performance. However, we\nfind that these models underperform compared to humans when asked to do very\nspecific 'reading and estimation' tasks, particularly in the context of visual\ncharts in business decks. This paper evaluates the accuracy of GPT 4o and\nGemini Flash-1.5 in answering straightforward questions about data on labeled\ncharts (where data is clearly annotated on the graphs), and unlabeled charts\n(where data is not clearly annotated and has to be inferred from the X and Y\naxis). We conclude that these models aren't currently capable of reading a deck\naccurately end-to-end if it contains any complex or unlabeled charts. Even if a\nuser created a deck of only labeled charts, the model would only be able to\nread 7-8 out of 15 labeled charts perfectly end-to-end. For full list of slide\ndeck figures visit https://www.repromptai.com/chat_bcg\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"5dJ_A_JCVh4pLJQJb-e2FzxmqPhA4XJ2coqG-JtIxSc","pdfSize":"593316","objectId":"0x7608010b7ddca07df127d08b6a9d9ca24e88e251281b001ad697356e9d50e805","registeredEpoch":"3","certifiedEpoch":"3","startEpoch":"3","endEpoch":"203"}
