{"id":"2407.07757","title":"Can ChatGPT Pass a Theory of Computing Course?","authors":"Matei A. Golesteanu, Garrett B. Vowinkel, Ryan E. Dougherty","authorsParsed":[["Golesteanu","Matei A.",""],["Vowinkel","Garrett B.",""],["Dougherty","Ryan E.",""]],"versions":[{"version":"v1","created":"Wed, 10 Jul 2024 15:34:06 GMT"}],"updateDate":"2024-07-11","timestamp":1720625646000,"abstract":"  Large Language Models (LLMs) have had considerable difficulty when prompted\nwith mathematical questions, especially those within theory of computing (ToC)\ncourses. In this paper, we detail two experiments regarding our own ToC course\nand the ChatGPT LLM. For the first, we evaluated ChatGPT's ability to pass our\nown ToC course's exams. For the second, we created a database of sample ToC\nquestions and responses to accommodate other ToC offerings' choices for topics\nand structure. We scored each of ChatGPT's outputs on these questions. Overall,\nwe determined that ChatGPT can pass our ToC course, and is adequate at\nunderstanding common formal definitions and answering \"simple\"-style questions,\ne.g., true/false and multiple choice. However, ChatGPT often makes nonsensical\nclaims in open-ended responses, such as proofs.\n","subjects":["Computing Research Repository/Computers and Society"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"IRyeXlgsN0bsd09-JoWEoxuQJP-W2drtP0Bazh-MMEY","pdfSize":"541263"}