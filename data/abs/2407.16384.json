{"id":"2407.16384","title":"A Multitask Deep Learning Model for Classification and Regression of\n  Hyperspectral Images: Application to the large-scale dataset","authors":"Koushikey Chhapariya, Alexandre Benoit, Krishna Mohan Buddhiraju, and\n  Anil Kumar","authorsParsed":[["Chhapariya","Koushikey",""],["Benoit","Alexandre",""],["Buddhiraju","Krishna Mohan",""],["Kumar","Anil",""]],"versions":[{"version":"v1","created":"Tue, 23 Jul 2024 11:14:54 GMT"}],"updateDate":"2024-07-24","timestamp":1721733294000,"abstract":"  Multitask learning is a widely recognized technique in the field of computer\nvision and deep learning domain. However, it is still a research question in\nremote sensing, particularly for hyperspectral imaging. Moreover, most of the\nresearch in the remote sensing domain focuses on small and single-task-based\nannotated datasets, which limits the generalizability and scalability of the\ndeveloped models to more diverse and complex real-world scenarios. Thus, in\nthis study, we propose a multitask deep learning model designed to perform\nmultiple classification and regression tasks simultaneously on hyperspectral\nimages. We validated our approach on a large hyperspectral dataset called\nTAIGA, which contains 13 forest variables, including three categorical\nvariables and ten continuous variables with different biophysical parameters.\nWe design a sharing encoder and task-specific decoder network to streamline\nfeature learning while allowing each task-specific decoder to focus on the\nunique aspects of its respective task.\n  Additionally, a dense atrous pyramid pooling layer and attention network were\nintegrated to extract multi-scale contextual information and enable selective\ninformation processing by prioritizing task-specific features. Further, we\ncomputed multitask loss and optimized its parameters for the proposed framework\nto improve the model performance and efficiency across diverse tasks. A\ncomprehensive qualitative and quantitative analysis of the results shows that\nthe proposed method significantly outperforms other state-of-the-art methods.\nWe trained our model across 10 seeds/trials to ensure robustness. Our proposed\nmodel demonstrates higher mean performance while maintaining lower or\nequivalent variability. To make the work reproducible, the codes will be\navailable at\nhttps://github.com/Koushikey4596/Multitask-Deep-Learning-Model-for-Taiga-datatset.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"-nelR9rVlRf8CW17u5OEC4yt6e5lnzUM1gFKAlSMUMI","pdfSize":"31752516"}