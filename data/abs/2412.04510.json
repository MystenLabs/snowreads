{"id":"2412.04510","title":"A Taxonomy of System-Level Attacks on Deep Learning Models in Autonomous\n  Vehicles","authors":"Masoud Jamshidiyan Tehrani, Jinhan Kim, Rosmael Zidane Lekeufack\n  Foulefack, Alessandro Marchetto, Paolo Tonella","authorsParsed":[["Tehrani","Masoud Jamshidiyan",""],["Kim","Jinhan",""],["Foulefack","Rosmael Zidane Lekeufack",""],["Marchetto","Alessandro",""],["Tonella","Paolo",""]],"versions":[{"version":"v1","created":"Wed, 4 Dec 2024 09:49:55 GMT"}],"updateDate":"2024-12-09","timestamp":1733305795000,"abstract":"  The advent of deep learning and its astonishing performance in perception\ntasks, such as object recognition and classification, has enabled its usage in\ncomplex systems, including autonomous vehicles. On the other hand, deep\nlearning models are susceptible to mis-predictions when small, adversarial\nchanges are introduced into their input. Such mis-predictions can be triggered\nin the real world and can propagate to a failure of the entire system, as\nopposed to a localized mis-prediction. In recent years, a growing number of\nresearch works have investigated ways to mount attacks against autonomous\nvehicles that exploit deep learning components for perception tasks. Such\nattacks are directed toward elements of the environment where these systems\noperate and their effectiveness is assessed in terms of system-level failures\ntriggered by them. There has been however no systematic attempt to analyze and\ncategorize such attacks. In this paper, we present the first taxonomy of\nsystem-level attacks against autonomous vehicles. We constructed our taxonomy\nby first collecting 8,831 papers, then filtering them down to 1,125 candidates\nand eventually selecting a set of 19 highly relevant papers that satisfy all\ninclusion criteria. Then, we tagged them with taxonomy categories, involving\nthree assessors per paper. The resulting taxonomy includes 12 top-level\ncategories and several sub-categories. The taxonomy allowed us to investigate\nthe attack features, the most attacked components, the underlying threat\nmodels, and the propagation chains from input perturbation to system-level\nfailure. We distilled several lessons for practitioners and identified possible\ndirections for future work for researchers.\n","subjects":["Computer Science/Cryptography and Security","Computer Science/Software Engineering"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"j2wfGEhc9cSVY6xidY-cLVOJyJ1nrzJgPD8xR6gYcvI","pdfSize":"1054375"}