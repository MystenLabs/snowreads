{"id":"2412.20218","title":"YAD: Leveraging T5 for Improved Automatic Diacritization of Yor\\`ub\\'a\n  Text","authors":"Akindele Michael Olawole, Jesujoba O. Alabi, Aderonke Busayo Sakpere,\n  David I. Adelani","authorsParsed":[["Olawole","Akindele Michael",""],["Alabi","Jesujoba O.",""],["Sakpere","Aderonke Busayo",""],["Adelani","David I.",""]],"versions":[{"version":"v1","created":"Sat, 28 Dec 2024 17:03:30 GMT"}],"updateDate":"2024-12-31","timestamp":1735405410000,"abstract":"  In this work, we present Yor\\`ub\\'a automatic diacritization (YAD) benchmark\ndataset for evaluating Yor\\`ub\\'a diacritization systems. In addition, we\npre-train text-to-text transformer, T5 model for Yor\\`ub\\'a and showed that\nthis model outperform several multilingually trained T5 models. Lastly, we\nshowed that more data and larger models are better at diacritization for\nYor\\`ub\\'a\n","subjects":["Computer Science/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"5TlrAqhDmRM2f7E4Ool17oltB60FMz4Jj0OJYM3OC10","pdfSize":"99915"}