{"id":"2407.17470","title":"SV4D: Dynamic 3D Content Generation with Multi-Frame and Multi-View\n  Consistency","authors":"Yiming Xie, Chun-Han Yao, Vikram Voleti, Huaizu Jiang, Varun Jampani","authorsParsed":[["Xie","Yiming",""],["Yao","Chun-Han",""],["Voleti","Vikram",""],["Jiang","Huaizu",""],["Jampani","Varun",""]],"versions":[{"version":"v1","created":"Wed, 24 Jul 2024 17:59:43 GMT"}],"updateDate":"2024-07-25","timestamp":1721843983000,"abstract":"  We present Stable Video 4D (SV4D), a latent video diffusion model for\nmulti-frame and multi-view consistent dynamic 3D content generation. Unlike\nprevious methods that rely on separately trained generative models for video\ngeneration and novel view synthesis, we design a unified diffusion model to\ngenerate novel view videos of dynamic 3D objects. Specifically, given a\nmonocular reference video, SV4D generates novel views for each video frame that\nare temporally consistent. We then use the generated novel view videos to\noptimize an implicit 4D representation (dynamic NeRF) efficiently, without the\nneed for cumbersome SDS-based optimization used in most prior works. To train\nour unified novel view video generation model, we curated a dynamic 3D object\ndataset from the existing Objaverse dataset. Extensive experimental results on\nmultiple datasets and user studies demonstrate SV4D's state-of-the-art\nperformance on novel-view video synthesis as well as 4D generation compared to\nprior works.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"HyRK58crm-HJwOBbEetsT6eNKNtVKx8TxnR0zynBCGI","pdfSize":"4891448"}