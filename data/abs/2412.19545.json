{
  "id": "2412.19545",
  "title": "Enhancing Media Literacy: The Effectiveness of (Human) Annotations and\n  Bias Visualizations on Bias Detection",
  "authors": "Timo Spinde, Fei Wu, Wolfgang Gaissmaier, Gianluca Demartini, Helge\n  Giese",
  "authorsParsed": [
    [
      "Spinde",
      "Timo",
      ""
    ],
    [
      "Wu",
      "Fei",
      ""
    ],
    [
      "Gaissmaier",
      "Wolfgang",
      ""
    ],
    [
      "Demartini",
      "Gianluca",
      ""
    ],
    [
      "Giese",
      "Helge",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Fri, 27 Dec 2024 09:19:22 GMT"
    },
    {
      "version": "v2",
      "created": "Mon, 30 Dec 2024 09:26:00 GMT"
    }
  ],
  "updateDate": "2024-12-31",
  "timestamp": 1735291162000,
  "abstract": "  Marking biased texts is a practical approach to increase media bias awareness\namong news consumers. However, little is known about the generalizability of\nsuch awareness to new topics or unmarked news articles, and the role of\nmachine-generated bias labels in enhancing awareness remains unclear. This\nstudy tests how news consumers may be trained and pre-bunked to detect media\nbias with bias labels obtained from different sources (Human or AI) and in\nvarious manifestations. We conducted two experiments with 470 and 846\nparticipants, exposing them to various bias-labeling conditions. We\nsubsequently tested how much bias they could identify in unlabeled news\nmaterials on new topics. The results show that both Human (t(467) = 4.55, p <\n.001, d = 0.42) and AI labels (t(467) = 2.49, p = .039, d = 0.23) increased\ncorrect detection compared to the control group. Human labels demonstrate\nlarger effect sizes and higher statistical significance. The control group\n(t(467) = 4.51, p < .001, d = 0.21) also improves performance through mere\nexposure to study materials. We also find that participants trained with marked\nbiased phrases detected bias most reliably (F(834,1) = 44.00, p < .001,\n{\\eta}2part = 0.048). Our experimental framework provides theoretical\nimplications for systematically assessing the generalizability of learning\neffects in identifying media bias. These findings also provide practical\nimplications for developing news-reading platforms that offer bias indicators\nand designing media literacy curricula to enhance media bias awareness.\n",
  "subjects": [
    "Computer Science/Human-Computer Interaction"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "SSXwMTIOr8HqTpXhKgVnQO6khgL3IKTjKPAMNO49PmU",
  "pdfSize": "1039246"
}