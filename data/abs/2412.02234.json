{
  "id": "2412.02234",
  "title": "CubeFormer: A Simple yet Effective Baseline for Lightweight Image\n  Super-Resolution",
  "authors": "Jikai Wang, Huan Zheng, Jianbing Shen",
  "authorsParsed": [
    [
      "Wang",
      "Jikai",
      ""
    ],
    [
      "Zheng",
      "Huan",
      ""
    ],
    [
      "Shen",
      "Jianbing",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Tue, 3 Dec 2024 08:02:26 GMT"
    }
  ],
  "updateDate": "2024-12-04",
  "timestamp": 1733212946000,
  "abstract": "  Lightweight image super-resolution (SR) methods aim at increasing the\nresolution and restoring the details of an image using a lightweight neural\nnetwork. However, current lightweight SR methods still suffer from inferior\nperformance and unpleasant details. Our analysis reveals that these methods are\nhindered by constrained feature diversity, which adversely impacts feature\nrepresentation and detail recovery. To respond this issue, we propose a simple\nyet effective baseline called CubeFormer, designed to enhance feature richness\nby completing holistic information aggregation. To be specific, we introduce\ncube attention, which expands 2D attention to 3D space, facilitating exhaustive\ninformation interactions, further encouraging comprehensive information\nextraction and promoting feature variety. In addition, we inject block and grid\nsampling strategies to construct intra-cube transformer blocks (Intra-CTB) and\ninter-cube transformer blocks (Inter-CTB), which perform local and global\nmodeling, respectively. Extensive experiments show that our CubeFormer achieves\nstate-of-the-art performance on commonly used SR benchmarks. Our source code\nand models will be publicly available.\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition"
  ],
  "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
  "blobId": "h47X97occc8lPcLqMI87svIVW-HPn8djR-HZ1KW6Zng",
  "pdfSize": "3345188"
}