{"id":"2412.10428","title":"Observing Micromotives and Macrobehavior of Large Language Models","authors":"Yuyang Cheng, Xingwei Qu, Tomas Goldsack, Chenghua Lin, Chung-Chi Chen","authorsParsed":[["Cheng","Yuyang",""],["Qu","Xingwei",""],["Goldsack","Tomas",""],["Lin","Chenghua",""],["Chen","Chung-Chi",""]],"versions":[{"version":"v1","created":"Tue, 10 Dec 2024 23:25:14 GMT"}],"updateDate":"2024-12-17","timestamp":1733873114000,"abstract":"  Thomas C. Schelling, awarded the 2005 Nobel Memorial Prize in Economic\nSciences, pointed out that ``individuals decisions (micromotives), while often\npersonal and localized, can lead to societal outcomes (macrobehavior) that are\nfar more complex and different from what the individuals intended.'' The\ncurrent research related to large language models' (LLMs') micromotives, such\nas preferences or biases, assumes that users will make more appropriate\ndecisions once LLMs are devoid of preferences or biases. Consequently, a series\nof studies has focused on removing bias from LLMs. In the NLP community, while\nthere are many discussions on LLMs' micromotives, previous studies have seldom\nconducted a systematic examination of how LLMs may influence society's\nmacrobehavior. In this paper, we follow the design of Schelling's model of\nsegregation to observe the relationship between the micromotives and\nmacrobehavior of LLMs. Our results indicate that, regardless of the level of\nbias in LLMs, a highly segregated society will emerge as more people follow\nLLMs' suggestions. We hope our discussion will spark further consideration of\nthe fundamental assumption regarding the mitigation of LLMs' micromotives and\nencourage a reevaluation of how LLMs may influence users and society.\n","subjects":["Physics/Physics and Society","Computer Science/Artificial Intelligence","Computer Science/Computation and Language"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"6__zrmIN1FrX1YzWVnpevVlO1PnY4kaUVr2PvfqMnEk","pdfSize":"1632583"}