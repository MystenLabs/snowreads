{"id":"2407.00186","title":"DCSM 2.0: Deep Conditional Shape Models for Data Efficient Segmentation","authors":"Athira J Jacob, Puneet Sharma and Daniel Rueckert","authorsParsed":[["Jacob","Athira J",""],["Sharma","Puneet",""],["Rueckert","Daniel",""]],"versions":[{"version":"v1","created":"Fri, 28 Jun 2024 18:52:11 GMT"}],"updateDate":"2024-07-02","timestamp":1719600731000,"abstract":"  Segmentation is often the first step in many medical image analyses\nworkflows. Deep learning approaches, while giving state-of-the-art accuracies,\nare data intensive and do not scale well to low data regimes. We introduce Deep\nConditional Shape Models 2.0, which uses an edge detector, along with an\nimplicit shape function conditioned on edge maps, to leverage cross-modality\nshape information. The shape function is trained exclusively on a source domain\n(contrasted CT) and applied to the target domain of interest (3D\nechocardiography). We demonstrate data efficiency in the target domain by\nvarying the amounts of training data used in the edge detection stage. We\nobserve that DCSM 2.0 outperforms the baseline at all data levels in terms of\nHausdorff distances, and while using 50% or less of the training data in terms\nof average mesh distance, and at 10% or less of the data with the dice\ncoefficient. The method scales well to low data regimes, with gains of up to 5%\nin dice coefficient, 2.58 mm in average surface distance and 21.02 mm in\nHausdorff distance when using just 2% (22 volumes) of the training data.\n","subjects":["Electrical Engineering and Systems Science/Image and Video Processing","Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"4xcAFGFjwXPrMvdoUcgnLsbkksoYHwkaGXg9rMDSZaE","pdfSize":"255153","objectId":"0x5cac0465fab7c5dbcd5a9b75ae5a4e2ed4cdbe608b18ccd5abbd42f39b7d0390","registeredEpoch":"1","certifiedEpoch":"1","startEpoch":"1","endEpoch":"201"}
