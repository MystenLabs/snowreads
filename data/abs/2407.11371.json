{"id":"2407.11371","title":"Estimating Agreement by Chance for Sequence Annotation","authors":"Diya Li, Carolyn Ros\\'e, Ao Yuan, Chunxiao Zhou","authorsParsed":[["Li","Diya",""],["Ros√©","Carolyn",""],["Yuan","Ao",""],["Zhou","Chunxiao",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 04:32:47 GMT"}],"updateDate":"2024-07-17","timestamp":1721104367000,"abstract":"  In the field of natural language processing, correction of performance\nassessment for chance agreement plays a crucial role in evaluating the\nreliability of annotations. However, there is a notable dearth of research\nfocusing on chance correction for assessing the reliability of sequence\nannotation tasks, despite their widespread prevalence in the field. To address\nthis gap, this paper introduces a novel model for generating random\nannotations, which serves as the foundation for estimating chance agreement in\nsequence annotation tasks. Utilizing the proposed randomization model and a\nrelated comparison approach, we successfully derive the analytical form of the\ndistribution, enabling the computation of the probable location of each\nannotated text segment and subsequent chance agreement estimation. Through a\ncombination simulation and corpus-based evaluation, we successfully assess its\napplicability and validate its accuracy and efficacy.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"RCcxLkNoL-wLP2mgOPrbCNRWXAWwY_shdEhYGNDO0Ko","pdfSize":"742851"}