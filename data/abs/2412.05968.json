{
  "id": "2412.05968",
  "title": "LVS-Net: A Lightweight Vessels Segmentation Network for Retinal Image\n  Analysis",
  "authors": "Mehwish Mehmood, Shahzaib Iqbal, Tariq Mahmood Khan, Ivor Spence and\n  Muhammad Fahim",
  "authorsParsed": [
    [
      "Mehmood",
      "Mehwish",
      ""
    ],
    [
      "Iqbal",
      "Shahzaib",
      ""
    ],
    [
      "Khan",
      "Tariq Mahmood",
      ""
    ],
    [
      "Spence",
      "Ivor",
      ""
    ],
    [
      "Fahim",
      "Muhammad",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Sun, 8 Dec 2024 15:21:37 GMT"
    }
  ],
  "updateDate": "2024-12-10",
  "timestamp": 1733671297000,
  "abstract": "  The analysis of retinal images for the diagnosis of various diseases is one\nof the emerging areas of research. Recently, the research direction has been\ninclined towards investigating several changes in retinal blood vessels in\nsubjects with many neurological disorders, including dementia. This research\nfocuses on detecting diseases early by improving the performance of models for\nsegmentation of retinal vessels with fewer parameters, which reduces\ncomputational costs and supports faster processing. This paper presents a novel\nlightweight encoder-decoder model that segments retinal vessels to improve the\nefficiency of disease detection. It incorporates multi-scale convolutional\nblocks in the encoder to accurately identify vessels of various sizes and\nthicknesses. The bottleneck of the model integrates the Focal Modulation\nAttention and Spatial Feature Refinement Blocks to refine and enhance essential\nfeatures for efficient segmentation. The decoder upsamples features and\nintegrates them with the corresponding feature in the encoder using skip\nconnections and the spatial feature refinement block at every upsampling stage\nto enhance feature representation at various scales. The estimated computation\ncomplexity of our proposed model is around 29.60 GFLOP with 0.71 million\nparameters and 2.74 MB of memory size, and it is evaluated using public\ndatasets, that is, DRIVE, CHASE\\_DB, and STARE. It outperforms existing models\nwith dice scores of 86.44\\%, 84.22\\%, and 87.88\\%, respectively.\n",
  "subjects": [
    "Electrical Engineering and Systems Science/Image and Video Processing",
    "Computer Science/Artificial Intelligence",
    "Computer Science/Computer Vision and Pattern Recognition"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "2DE4xvdm8_19VsCfgd04nNWWcDh2sVzlGPc97zLVJ6g",
  "pdfSize": "4352089"
}