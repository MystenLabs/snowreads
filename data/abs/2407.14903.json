{"id":"2407.14903","title":"Automated Patient Positioning with Learned 3D Hand Gestures","authors":"Zhongpai Gao and Abhishek Sharma and Meng Zheng and Benjamin Planche\n  and Terrence Chen and Ziyan Wu","authorsParsed":[["Gao","Zhongpai",""],["Sharma","Abhishek",""],["Zheng","Meng",""],["Planche","Benjamin",""],["Chen","Terrence",""],["Wu","Ziyan",""]],"versions":[{"version":"v1","created":"Sat, 20 Jul 2024 15:32:24 GMT"}],"updateDate":"2024-07-23","timestamp":1721489544000,"abstract":"  Positioning patients for scanning and interventional procedures is a critical\ntask that requires high precision and accuracy. The conventional workflow\ninvolves manually adjusting the patient support to align the center of the\ntarget body part with the laser projector or other guiding devices. This\nprocess is not only time-consuming but also prone to inaccuracies. In this\nwork, we propose an automated patient positioning system that utilizes a camera\nto detect specific hand gestures from technicians, allowing users to indicate\nthe target patient region to the system and initiate automated positioning. Our\napproach relies on a novel multi-stage pipeline to recognize and interpret the\ntechnicians' gestures, translating them into precise motions of medical\ndevices. We evaluate our proposed pipeline during actual MRI scanning\nprocedures, using RGB-Depth cameras to capture the process. Results show that\nour system achieves accurate and precise patient positioning with minimal\ntechnician intervention. Furthermore, we validate our method on HaGRID, a\nlarge-scale hand gesture dataset, demonstrating its effectiveness in hand\ndetection and gesture recognition.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"YxrJRk2qUjk5Nli57Tc6tu0n6MrlzpjqJupKbYOIG0c","pdfSize":"1184346"}