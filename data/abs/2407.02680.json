{"id":"2407.02680","title":"KGym: A Platform and Dataset to Benchmark Large Language Models on Linux\n  Kernel Crash Resolution","authors":"Alex Mathai, Chenxi Huang, Petros Maniatis, Aleksandr Nogikh, Franjo\n  Ivancic, Junfeng Yang, Baishakhi Ray","authorsParsed":[["Mathai","Alex",""],["Huang","Chenxi",""],["Maniatis","Petros",""],["Nogikh","Aleksandr",""],["Ivancic","Franjo",""],["Yang","Junfeng",""],["Ray","Baishakhi",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 21:44:22 GMT"},{"version":"v2","created":"Thu, 4 Jul 2024 01:31:38 GMT"},{"version":"v3","created":"Mon, 8 Jul 2024 16:04:12 GMT"}],"updateDate":"2024-07-09","timestamp":1719956662000,"abstract":"  Large Language Models (LLMs) are consistently improving at increasingly\nrealistic software engineering (SE) tasks. In real-world software stacks,\nsignificant SE effort is spent developing foundational system software like the\nLinux kernel. Unlike application-level software, a systems codebase like Linux\nis multilingual (low-level C/Assembly/Bash/Rust); gigantic (>20 million lines);\ncritical (impacting billions of devices worldwide), and highly concurrent\n(involving complex multi-threading). To evaluate if ML models are useful while\ndeveloping such large-scale systems-level software, we introduce kGym (a\nplatform) and kBench (a dataset). The kGym platform provides a SE environment\nfor large-scale experiments on the Linux kernel, including compiling and\nrunning kernels in parallel across several virtual machines, detecting\noperations and crashes, inspecting logs, and querying and patching the code\nbase. We use kGym to facilitate evaluation on kBench, a crash resolution\nbenchmark drawn from real-world Linux kernel bugs. An example bug in kBench\ncontains crashing stack traces, a bug-reproducer file, a developer-written fix,\nand other associated data. To understand current performance, we conduct\nbaseline experiments by prompting LLMs to resolve Linux kernel crashes. Our\ninitial evaluations reveal that the best performing LLM achieves 0.72% and\n5.38% in the unassisted and assisted (i.e., buggy files disclosed to the model)\nsettings, respectively. These results highlight the need for further research\nto enhance model performance in SE tasks. Improving performance on kBench\nrequires models to master new learning skills, including understanding the\ncause of crashes and repairing faults, writing memory-safe and hardware-aware\ncode, and understanding concurrency. As a result, this work opens up multiple\navenues of research at the intersection of machine learning and systems\nsoftware.\n","subjects":["Computing Research Repository/Software Engineering"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"W7CjEJxR71Zyv4jLO3al5-4ue2mdHMEUGYVsgYMe55g","pdfSize":"4551790"}