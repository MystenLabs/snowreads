{
  "id": "2412.12092",
  "title": "No More Tuning: Prioritized Multi-Task Learning with Lagrangian\n  Differential Multiplier Methods",
  "authors": "Zhengxing Cheng, Yuheng Huang, Zhixuan Zhang, Dan Ou, Qingwen Liu",
  "authorsParsed": [
    [
      "Cheng",
      "Zhengxing",
      ""
    ],
    [
      "Huang",
      "Yuheng",
      ""
    ],
    [
      "Zhang",
      "Zhixuan",
      ""
    ],
    [
      "Ou",
      "Dan",
      ""
    ],
    [
      "Liu",
      "Qingwen",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Mon, 16 Dec 2024 18:58:28 GMT"
    }
  ],
  "updateDate": "2024-12-17",
  "timestamp": 1734375508000,
  "abstract": "  Given the ubiquity of multi-task in practical systems, Multi-Task Learning\n(MTL) has found widespread application across diverse domains. In real-world\nscenarios, these tasks often have different priorities. For instance, In web\nsearch, relevance is often prioritized over other metrics, such as\nclick-through rates or user engagement. Existing frameworks pay insufficient\nattention to the prioritization among different tasks, which typically adjust\ntask-specific loss function weights to differentiate task priorities. However,\nthis approach encounters challenges as the number of tasks grows, leading to\nexponential increases in hyper-parameter tuning complexity. Furthermore, the\nsimultaneous optimization of multiple objectives can negatively impact the\nperformance of high-priority tasks due to interference from lower-priority\ntasks.\n  In this paper, we introduce a novel multi-task learning framework employing\nLagrangian Differential Multiplier Methods for step-wise multi-task\noptimization. It is designed to boost the performance of high-priority tasks\nwithout interference from other tasks. Its primary advantage lies in its\nability to automatically optimize multiple objectives without requiring\nbalancing hyper-parameters for different tasks, thereby eliminating the need\nfor manual tuning. Additionally, we provide theoretical analysis demonstrating\nthat our method ensures optimization guarantees, enhancing the reliability of\nthe process. We demonstrate its effectiveness through experiments on multiple\npublic datasets and its application in Taobao search, a large-scale industrial\nsearch ranking system, resulting in significant improvements across various\nbusiness metrics.\n",
  "subjects": [
    "Computer Science/Machine Learning",
    "Computer Science/Information Retrieval"
  ],
  "license": "http://creativecommons.org/licenses/by-sa/4.0/",
  "blobId": "wR7BsxaOY9DxAdCNVw8xtb4RVmzcwhtswlE4FcnMBXA",
  "pdfSize": "207169"
}