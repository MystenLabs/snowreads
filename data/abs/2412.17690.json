{"id":"2412.17690","title":"RAGONITE: Iterative Retrieval on Induced Databases and Verbalized RDF\n  for Conversational QA over KGs with RAG","authors":"Rishiraj Saha Roy, Chris Hinze, Joel Schlotthauer, Farzad Naderi,\n  Viktor Hangya, Andreas Foltyn, Luzian Hahn, Fabian Kuech","authorsParsed":[["Roy","Rishiraj Saha",""],["Hinze","Chris",""],["Schlotthauer","Joel",""],["Naderi","Farzad",""],["Hangya","Viktor",""],["Foltyn","Andreas",""],["Hahn","Luzian",""],["Kuech","Fabian",""]],"versions":[{"version":"v1","created":"Mon, 23 Dec 2024 16:16:30 GMT"},{"version":"v2","created":"Tue, 24 Dec 2024 11:03:42 GMT"},{"version":"v3","created":"Wed, 25 Dec 2024 15:05:04 GMT"}],"updateDate":"2024-12-30","timestamp":1734970590000,"abstract":"  Conversational question answering (ConvQA) is a convenient means of searching\nover RDF knowledge graphs (KGs), where a prevalent approach is to translate\nnatural language questions to SPARQL queries. However, SPARQL has certain\nshortcomings: (i) it is brittle for complex intents and conversational\nquestions, and (ii) it is not suitable for more abstract needs. Instead, we\npropose a novel two-pronged system where we fuse: (i) SQL-query results over a\ndatabase automatically derived from the KG, and (ii) text-search results over\nverbalizations of KG facts. Our pipeline supports iterative retrieval: when the\nresults of any branch are found to be unsatisfactory, the system can\nautomatically opt for further rounds. We put everything together in a retrieval\naugmented generation (RAG) setup, where an LLM generates a coherent response\nfrom accumulated search results. We demonstrate the superiority of our proposed\nsystem over several baselines on a knowledge graph of BMW automobiles.\n","subjects":["Computer Science/Computation and Language","Computer Science/Information Retrieval"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"QV93roGauKA2oATu1lpna3CHBF2P9LqwwkKJC7CZBAI","pdfSize":"2969233"}