{"id":"2412.08392","title":"The Roles of English in Evaluating Multilingual Language Models","authors":"Wessel Poelman, Miryam de Lhoneux","authorsParsed":[["Poelman","Wessel",""],["de Lhoneux","Miryam",""]],"versions":[{"version":"v1","created":"Wed, 11 Dec 2024 14:02:55 GMT"}],"updateDate":"2024-12-12","timestamp":1733925775000,"abstract":"  Multilingual natural language processing is getting increased attention, with\nnumerous models, benchmarks, and methods being released for many languages.\nEnglish is often used in multilingual evaluation to prompt language models\n(LMs), mainly to overcome the lack of instruction tuning data in other\nlanguages. In this position paper, we lay out two roles of English in\nmultilingual LM evaluations: as an interface and as a natural language. We\nargue that these roles have different goals: task performance versus language\nunderstanding. This discrepancy is highlighted with examples from datasets and\nevaluation setups. Numerous works explicitly use English as an interface to\nboost task performance. We recommend to move away from this imprecise method\nand instead focus on furthering language understanding.\n","subjects":["Computer Science/Computation and Language","Computer Science/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"znqCaG28aD3sb4Qp6jHytgVyTDSvX0JrZsHqyeEwBWA","pdfSize":"301998"}