{
  "id": "2412.17034",
  "title": "Shaping the Safety Boundaries: Understanding and Defending Against\n  Jailbreaks in Large Language Models",
  "authors": "Lang Gao and Xiangliang Zhang and Preslav Nakov and Xiuying Chen",
  "authorsParsed": [
    [
      "Gao",
      "Lang",
      ""
    ],
    [
      "Zhang",
      "Xiangliang",
      ""
    ],
    [
      "Nakov",
      "Preslav",
      ""
    ],
    [
      "Chen",
      "Xiuying",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Sun, 22 Dec 2024 14:18:39 GMT"
    }
  ],
  "updateDate": "2024-12-24",
  "timestamp": 1734877119000,
  "abstract": "  Jailbreaking in Large Language Models (LLMs) is a major security concern as\nit can deceive LLMs to generate harmful text. Yet, there is still insufficient\nunderstanding of how jailbreaking works, which makes it hard to develop\neffective defense strategies. We aim to shed more light into this issue: we\nconduct a detailed large-scale analysis of seven different jailbreak methods\nand find that these disagreements stem from insufficient observation samples.\nIn particular, we introduce \\textit{safety boundary}, and we find that\njailbreaks shift harmful activations outside that safety boundary, where LLMs\nare less sensitive to harmful information. We also find that the low and the\nmiddle layers are critical in such shifts, while deeper layers have less\nimpact. Leveraging on these insights, we propose a novel defense called\n\\textbf{Activation Boundary Defense} (ABD), which adaptively constrains the\nactivations within the safety boundary. We further use Bayesian optimization to\nselectively apply the defense method to the low and the middle layers. Our\nexperiments on several benchmarks show that ABD achieves an average DSR of over\n98\\% against various forms of jailbreak attacks, with less than 2\\% impact on\nthe model's general capabilities.\n",
  "subjects": [
    "Computer Science/Computation and Language"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "Z-vk6QMfvz3UuZdzzZde2kFFeUMP7J8rAQPaPYUvdu8",
  "pdfSize": "7289218"
}