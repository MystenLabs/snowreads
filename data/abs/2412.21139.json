{"id":"2412.21139","title":"Training Software Engineering Agents and Verifiers with SWE-Gym","authors":"Jiayi Pan, Xingyao Wang, Graham Neubig, Navdeep Jaitly, Heng Ji, Alane\n  Suhr, and Yizhe Zhang","authorsParsed":[["Pan","Jiayi",""],["Wang","Xingyao",""],["Neubig","Graham",""],["Jaitly","Navdeep",""],["Ji","Heng",""],["Suhr","Alane",""],["Zhang","Yizhe",""]],"versions":[{"version":"v1","created":"Mon, 30 Dec 2024 18:15:39 GMT"}],"updateDate":"2024-12-31","timestamp":1735582539000,"abstract":"  We present SWE-Gym, the first environment for training real-world software\nengineering (SWE) agents. SWE-Gym contains 2,438 real-world Python task\ninstances, each comprising a codebase with an executable runtime environment,\nunit tests, and a task specified in natural language. We use SWE-Gym to train\nlanguage model based SWE agents , achieving up to 19% absolute gains in resolve\nrate on the popular SWE-Bench Verified and Lite test sets. We also experiment\nwith inference-time scaling through verifiers trained on agent trajectories\nsampled from SWE-Gym. When combined with our fine-tuned SWE agents, we achieve\n32.0% and 26.0% on SWE-Bench Verified and Lite, respectively, reflecting a new\nstate-of-the-art for open-weight SWE agents. To facilitate further research, we\npublicly release SWE-Gym, models, and agent trajectories.\n","subjects":["Computer Science/Software Engineering","Computer Science/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"gYJUZgGGL97LUrQc41QVGhycZfKtjBxi-q2Oqq4jjZs","pdfSize":"601451"}