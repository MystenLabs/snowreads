{"id":"2412.13030","title":"Are Data Experts Buying into Differentially Private Synthetic Data?\n  Gathering Community Perspectives","authors":"Lucas Rosenblatt, Bill Howe, Julia Stoyanovich","authorsParsed":[["Rosenblatt","Lucas",""],["Howe","Bill",""],["Stoyanovich","Julia",""]],"versions":[{"version":"v1","created":"Tue, 17 Dec 2024 15:50:14 GMT"}],"updateDate":"2024-12-18","timestamp":1734450614000,"abstract":"  Data privacy is a core tenet of responsible computing, and in the United\nStates, differential privacy (DP) is the dominant technical operationalization\nof privacy-preserving data analysis. With this study, we qualitatively examine\none class of DP mechanisms: private data synthesizers. To that end, we\nconducted semi-structured interviews with data experts: academics and\npractitioners who regularly work with data. Broadly, our findings suggest that\nquantitative DP benchmarks must be grounded in practitioner needs, while\ncommunication challenges persist. Participants expressed a need for\ncontext-aware DP solutions, focusing on parity between research outcomes on\nreal and synthetic data. Our analysis led to three recommendations: (1) improve\nexisting insufficient sanitized benchmarks; successful DP implementations\nrequire well-documented, partner-vetted use cases, (2) organizations using DP\nsynthetic data should publish discipline-specific standards of evidence, and\n(3) tiered data access models could allow researchers to gradually access\nsensitive data based on demonstrated competence with high-privacy, low-fidelity\nsynthetic data.\n","subjects":["Computer Science/Human-Computer Interaction","Computer Science/Cryptography and Security","Computer Science/Databases"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"stvlOy1LG8tZnHxiQME07WFf5cxHUXih9T1GM7OGs3k","pdfSize":"2081775"}