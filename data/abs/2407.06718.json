{"id":"2407.06718","title":"A Simple Architecture for Enterprise Large Language Model Applications\n  based on Role based security and Clearance Levels using Retrieval-Augmented\n  Generation or Mixture of Experts","authors":"Atilla \\\"Ozg\\\"ur and Y{\\i}lmaz Uygun","authorsParsed":[["Özgür","Atilla",""],["Uygun","Yılmaz",""]],"versions":[{"version":"v1","created":"Tue, 9 Jul 2024 09:46:23 GMT"}],"updateDate":"2024-07-10","timestamp":1720518383000,"abstract":"  This study proposes a simple architecture for Enterprise application for\nLarge Language Models (LLMs) for role based security and NATO clearance levels.\nOur proposal aims to address the limitations of current LLMs in handling\nsecurity and information access. The proposed architecture could be used while\nutilizing Retrieval-Augmented Generation (RAG) and fine tuning of Mixture of\nexperts models (MoE). It could be used only with RAG, or only with MoE or with\nboth of them. Using roles and security clearance level of the user, documents\nin RAG and experts in MoE are filtered. This way information leakage is\nprevented.\n","subjects":["Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"TSNoSLrexE6r9etYVCQrSSV47de1wBgcLFt6VUuBit8","pdfSize":"805317"}