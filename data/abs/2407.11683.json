{"id":"2407.11683","title":"Distractors-Immune Representation Learning with Cross-modal Contrastive\n  Regularization for Change Captioning","authors":"Yunbin Tu, Liang Li, Li Su, Chenggang Yan, Qingming Huang","authorsParsed":[["Tu","Yunbin",""],["Li","Liang",""],["Su","Li",""],["Yan","Chenggang",""],["Huang","Qingming",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 13:00:33 GMT"}],"updateDate":"2024-07-17","timestamp":1721134833000,"abstract":"  Change captioning aims to succinctly describe the semantic change between a\npair of similar images, while being immune to distractors (illumination and\nviewpoint changes). Under these distractors, unchanged objects often appear\npseudo changes about location and scale, and certain objects might overlap\nothers, resulting in perturbational and discrimination-degraded features\nbetween two images. However, most existing methods directly capture the\ndifference between them, which risk obtaining error-prone difference features.\nIn this paper, we propose a distractors-immune representation learning network\nthat correlates the corresponding channels of two image representations and\ndecorrelates different ones in a self-supervised manner, thus attaining a pair\nof stable image representations under distractors. Then, the model can better\ninteract them to capture the reliable difference features for caption\ngeneration. To yield words based on the most related difference features, we\nfurther design a cross-modal contrastive regularization, which regularizes the\ncross-modal alignment by maximizing the contrastive alignment between the\nattended difference features and generated words. Extensive experiments show\nthat our method outperforms the state-of-the-art methods on four public\ndatasets. The code is available at https://github.com/tuyunbin/DIRL.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"hOhbyGQSciEof0-8wQyfv1zwf7lzqpiTd1iSTrRxyFQ","pdfSize":"2722626"}