{"id":"2412.11378","title":"FinLoRA: Finetuning Quantized Financial Large Language Models Using\n  Low-Rank Adaptation","authors":"Dannong Wang, Daniel Kim, Bo Jin, Xingjian Zhao, Tianfan Fu, Steve\n  Yang, and Xiao-Yang Liu","authorsParsed":[["Wang","Dannong",""],["Kim","Daniel",""],["Jin","Bo",""],["Zhao","Xingjian",""],["Fu","Tianfan",""],["Yang","Steve",""],["Liu","Xiao-Yang",""]],"versions":[{"version":"v1","created":"Mon, 16 Dec 2024 02:05:49 GMT"},{"version":"v2","created":"Mon, 20 Jan 2025 15:39:58 GMT"}],"updateDate":"2025-01-22","timestamp":1734314749000,"abstract":"  Finetuned large language models (LLMs) have shown remarkable performance in\nfinancial tasks, such as sentiment analysis and information retrieval. Due to\nprivacy concerns, finetuning and deploying Financial LLMs (FinLLMs) locally are\ncrucial for institutions. However, finetuning FinLLMs poses challenges\nincluding GPU memory constraints and long input sequences. In this paper, we\nemploy quantized low-rank adaptation (QLoRA) to finetune FinLLMs, which\nleverage low-rank matrix decomposition and quantization techniques to\nsignificantly reduce computational requirements while maintaining high model\nperformance. We also employ data and pipeline parallelism to enable local\nfinetuning using cost-effective, widely accessible GPUs. Experiments on\nfinancial datasets demonstrate that our method achieves substantial\nimprovements in accuracy, GPU memory usage, and time efficiency, underscoring\nthe potential of lowrank methods for scalable and resource-efficient LLM\nfinetuning.\n","subjects":["Computer Science/Machine Learning"],"license":"http://creativecommons.org/licenses/by-sa/4.0/","blobId":"QQAg2zoCbTFYhOCrx7x5Nspzie0R_bg6eb00hWGrlEw","pdfSize":"92568"}