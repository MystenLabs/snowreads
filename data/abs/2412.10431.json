{"id":"2412.10431","title":"CUPS: Improving Human Pose-Shape Estimators with Conformalized Deep\n  Uncertainty","authors":"Harry Zhang, Luca Carlone","authorsParsed":[["Zhang","Harry",""],["Carlone","Luca",""]],"versions":[{"version":"v1","created":"Wed, 11 Dec 2024 03:11:44 GMT"}],"updateDate":"2024-12-17","timestamp":1733886704000,"abstract":"  We introduce CUPS, a novel method for learning sequence-to-sequence 3D human\nshapes and poses from RGB videos with uncertainty quantification. To improve on\ntop of prior work, we develop a method to generate and score multiple\nhypotheses during training, effectively integrating uncertainty quantification\ninto the learning process. This process results in a deep uncertainty function\nthat is trained end-to-end with the 3D pose estimator. Post-training, the\nlearned deep uncertainty model is used as the conformity score, which can be\nused to calibrate a conformal predictor in order to assess the quality of the\noutput prediction. Since the data in human pose-shape learning is not fully\nexchangeable, we also present two practical bounds for the coverage gap in\nconformal prediction, developing theoretical backing for the uncertainty bound\nof our model. Our results indicate that by taking advantage of deep uncertainty\nwith conformal prediction, our method achieves state-of-the-art performance\nacross various metrics and datasets while inheriting the probabilistic\nguarantees of conformal prediction.\n","subjects":["Computer Science/Computer Vision and Pattern Recognition","Computer Science/Robotics"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"x1zW1Wff_DJ0u9CFrYsATLeJhrNexx-V5CuXCTtbJQw","pdfSize":"4177601"}