{
  "id": "2412.18196",
  "title": "Robustness-aware Automatic Prompt Optimization",
  "authors": "Zeru Shi, Zhenting Wang, Yongye Su, Weidi Luo, Hang Gao, Fan Yang,\n  Ruixiang Tang, Yongfeng Zhang",
  "authorsParsed": [
    [
      "Shi",
      "Zeru",
      ""
    ],
    [
      "Wang",
      "Zhenting",
      ""
    ],
    [
      "Su",
      "Yongye",
      ""
    ],
    [
      "Luo",
      "Weidi",
      ""
    ],
    [
      "Gao",
      "Hang",
      ""
    ],
    [
      "Yang",
      "Fan",
      ""
    ],
    [
      "Tang",
      "Ruixiang",
      ""
    ],
    [
      "Zhang",
      "Yongfeng",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Tue, 24 Dec 2024 06:05:08 GMT"
    },
    {
      "version": "v2",
      "created": "Sat, 15 Feb 2025 05:03:21 GMT"
    }
  ],
  "updateDate": "2025-02-18",
  "timestamp": 1735020308000,
  "abstract": "  The performance of Large Language Models (LLMs) depends on the quality of\nprompts and the semantic and structural integrity of the input data. However,\nexisting prompt generation methods primarily focus on well-structured input\ndata, often neglecting the impact of perturbed inputs on prompt effectiveness.\nTo address this limitation, we propose BATprompt (By Adversarial Training\nprompt), a novel method for prompt generation designed to withstand input\nperturbations (such as typos in the input). Inspired by adversarial training\ntechniques, BATprompt demonstrates strong performance on a variety of perturbed\ntasks through a two-step process: adversarial perturbation and iterative\noptimization on unperturbed input via LLM. Unlike conventional adversarial\nattack methods, BATprompt does not need access to model parameters and\ngradients. Instead, BATprompt leverages the advanced reasoning, language\nunderstanding and self reflection capabilities of LLMs to simulate gradients,\nguiding the generation of adversarial perturbations and optimizing prompt\nperformance. We evaluate BATprompt on multiple datasets across both language\nunderstanding and generation tasks. The results indicate that BATprompt\noutperforms existing prompt generation methods, delivering superior robustness\nand performance under diverse perturbation scenarios.\n",
  "subjects": [
    "Computer Science/Computation and Language",
    "Computer Science/Machine Learning"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "VTvtHo_7jIIF0JTQTBrLlYqzqst3xrvBEKIEBey6rSg",
  "pdfSize": "9669874"
}