{
  "id": "2412.14903",
  "title": "Long Time Behavior and Stabilization for Displacement Monotone Mean\n  Field Games",
  "authors": "Marco Cirant and Alp\\'ar R. M\\'esz\\'aros",
  "authorsParsed": [
    [
      "Cirant",
      "Marco",
      ""
    ],
    [
      "Mészáros",
      "Alpár R.",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Thu, 19 Dec 2024 14:34:56 GMT"
    }
  ],
  "updateDate": "2024-12-20",
  "timestamp": 1734618896000,
  "abstract": "  This paper is devoted to the study of the long time behavior of Nash\nequilibria in Mean Field Games within the framework of displacement\nmonotonicity. We first show that any two equilibria defined on the time horizon\n$[0,T]$ must be close as $T \\to \\infty$, in a suitable sense, independently of\ninitial/terminal conditions. The way this stability property is made\nquantitative involves the $L^2$ distance between solutions of the associated\nPontryagin system of FBSDEs that characterizes the equilibria. Therefore, this\nimplies in particular the stability in the 2-Wasserstein distance for the two\nflows of probability measures describing the agent population density and the\n$L^2$ distance between the co-states of agents, that are related to the optimal\nfeedback controls. We then prove that the value function of a typical agent\nconverges as $T \\to \\infty$, and we describe this limit via an infinite horizon\nMFG system, involving an ergodic constant. All of our convergence results hold\ntrue in a unified way for deterministic and idiosyncratic noise driven Mean\nField Games, in the case of strongly displacement monotone non-separable\nHamiltonians. All these are quantitative at exponential rates.\n",
  "subjects": [
    "Mathematics/Optimization and Control",
    "Mathematics/Analysis of PDEs"
  ],
  "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
  "blobId": "olPBzzzBg6-cIuGtoI42C_FWIyLQ6dmld-ppihprcMY",
  "pdfSize": "542817"
}