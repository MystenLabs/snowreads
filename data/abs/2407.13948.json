{"id":"2407.13948","title":"Assurance of AI Systems From a Dependability Perspective","authors":"Robin Bloomfield and John Rushby","authorsParsed":[["Bloomfield","Robin",""],["Rushby","John",""]],"versions":[{"version":"v1","created":"Thu, 18 Jul 2024 23:55:43 GMT"},{"version":"v2","created":"Wed, 7 Aug 2024 22:40:12 GMT"}],"updateDate":"2024-08-09","timestamp":1721346943000,"abstract":"  We outline the principles of classical assurance for computer-based systems\nthat pose significant risks. We then consider application of these principles\nto systems that employ Artificial Intelligence (AI) and Machine Learning (ML).\n  A key element in this \"dependability\" perspective is a requirement to have\nnear-complete understanding of the behavior of critical components, and this is\nconsidered infeasible for AI and ML. Hence the dependability perspective aims\nto minimize trust in AI and ML elements by using \"defense in depth\" with a\nhierarchy of less complex systems, some of which may be highly assured\nconventionally engineered components, to \"guard\" them. This may be contrasted\nwith the \"trustworthy\" perspective that seeks to apply assurance to the AI and\nML elements themselves.\n  In cyber-physical and many other systems, it is difficult to provide guards\nthat do not depend on AI and ML to perceive their environment (e.g., other\nvehicles sharing the road with a self-driving car), so both perspectives are\nneeded and there is a continuum or spectrum between them. We focus on\narchitectures toward the dependability end of the continuum and invite others\nto consider additional points along the spectrum.\n  For guards that require perception using AI and ML, we examine ways to\nminimize the trust placed in these elements; they include diversity, defense in\ndepth, explanations, and micro-ODDs. We also examine methods to enforce\nacceptable behavior, given a model of the world. These include classical\ncyber-physical calculations and envelopes, and normative rules based on\noverarching principles, constitutions, ethics, or reputation. We apply our\nperspective to autonomous systems, AI systems for specific functions, generic\nAI such as Large Language Models, and to Artificial General Intelligence (AGI),\nand we propose current best practice and an agenda for research.\n","subjects":["Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"WuT25k1Vy-xSqkFeyF-Gmg89Jv8KRDffaVM4sx4cnr0","pdfSize":"951779"}