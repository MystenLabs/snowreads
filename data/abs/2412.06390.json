{
  "id": "2412.06390",
  "title": "Edge Delayed Deep Deterministic Policy Gradient: efficient continuous\n  control for edge scenarios",
  "authors": "Alberto Sinigaglia, Niccol\\`o Turcato, Ruggero Carli, Gian Antonio\n  Susto",
  "authorsParsed": [
    [
      "Sinigaglia",
      "Alberto",
      ""
    ],
    [
      "Turcato",
      "Niccol√≤",
      ""
    ],
    [
      "Carli",
      "Ruggero",
      ""
    ],
    [
      "Susto",
      "Gian Antonio",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Mon, 9 Dec 2024 11:17:04 GMT"
    }
  ],
  "updateDate": "2024-12-10",
  "timestamp": 1733743024000,
  "abstract": "  Deep Reinforcement Learning is gaining increasing attention thanks to its\ncapability to learn complex policies in high-dimensional settings. Recent\nadvancements utilize a dual-network architecture to learn optimal policies\nthrough the Q-learning algorithm. However, this approach has notable drawbacks,\nsuch as an overestimation bias that can disrupt the learning process and\ndegrade the performance of the resulting policy. To address this, novel\nalgorithms have been developed that mitigate overestimation bias by employing\nmultiple Q-functions. Edge scenarios, which prioritize privacy, have recently\ngained prominence. In these settings, limited computational resources pose a\nsignificant challenge for complex Machine Learning approaches, making the\nefficiency of algorithms crucial for their performance. In this work, we\nintroduce a novel Reinforcement Learning algorithm tailored for edge scenarios,\ncalled Edge Delayed Deep Deterministic Policy Gradient (EdgeD3). EdgeD3\nenhances the Deep Deterministic Policy Gradient (DDPG) algorithm, achieving\nsignificantly improved performance with $25\\%$ less Graphics Process Unit (GPU)\ntime while maintaining the same memory usage. Additionally, EdgeD3 consistently\nmatches or surpasses the performance of state-of-the-art methods across various\nbenchmarks, all while using $30\\%$ fewer computational resources and requiring\n$30\\%$ less memory.\n",
  "subjects": [
    "Computer Science/Machine Learning",
    "Computer Science/Artificial Intelligence"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "haMJlSr1bzGUneeIUGt9OBO2u2Hm5b27ymCtD5RIhzA",
  "pdfSize": "1237380"
}