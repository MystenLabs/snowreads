{"id":"2407.13954","title":"Neural topology optimization: the good, the bad, and the ugly","authors":"Suryanarayanan Manoj Sanu, Alejandro M. Aragon, Miguel A. Bessa","authorsParsed":[["Sanu","Suryanarayanan Manoj",""],["Aragon","Alejandro M.",""],["Bessa","Miguel A.",""]],"versions":[{"version":"v1","created":"Fri, 19 Jul 2024 00:10:56 GMT"}],"updateDate":"2024-07-22","timestamp":1721347856000,"abstract":"  Neural networks (NNs) hold great promise for advancing inverse design via\ntopology optimization (TO), yet misconceptions about their application persist.\nThis article focuses on neural topology optimization (neural TO), which\nleverages NNs to reparameterize the decision space and reshape the optimization\nlandscape. While the method is still in its infancy, our analysis tools reveal\ncritical insights into the NNs' impact on the optimization process. We\ndemonstrate that the choice of NN architecture significantly influences the\nobjective landscape and the optimizer's path to an optimum. Notably, NNs\nintroduce non-convexities even in otherwise convex landscapes, potentially\ndelaying convergence in convex problems but enhancing exploration for\nnon-convex problems. This analysis lays the groundwork for future advancements\nby highlighting: 1) the potential of neural TO for non-convex problems and\ndedicated GPU hardware (the \"good\"), 2) the limitations in smooth landscapes\n(the \"bad\"), and 3) the complex challenge of selecting optimal NN architectures\nand hyperparameters for superior performance (the \"ugly\").\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Numerical Analysis","Mathematics/Numerical Analysis"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"qv5EJygougS1BarcnFWmmwdhw8BzGyzYDz2Ha79K3Yw","pdfSize":"20776424"}