{
  "id": "2412.20155",
  "title": "Stable-TTS: Stable Speaker-Adaptive Text-to-Speech Synthesis via Prosody\n  Prompting",
  "authors": "Wooseok Han, Minki Kang, Changhun Kim, Eunho Yang",
  "authorsParsed": [
    [
      "Han",
      "Wooseok",
      ""
    ],
    [
      "Kang",
      "Minki",
      ""
    ],
    [
      "Kim",
      "Changhun",
      ""
    ],
    [
      "Yang",
      "Eunho",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Sat, 28 Dec 2024 13:54:30 GMT"
    }
  ],
  "updateDate": "2024-12-31",
  "timestamp": 1735394070000,
  "abstract": "  Speaker-adaptive Text-to-Speech (TTS) synthesis has attracted considerable\nattention due to its broad range of applications, such as personalized voice\nassistant services. While several approaches have been proposed, they often\nexhibit high sensitivity to either the quantity or the quality of target speech\nsamples. To address these limitations, we introduce Stable-TTS, a novel\nspeaker-adaptive TTS framework that leverages a small subset of a high-quality\npre-training dataset, referred to as prior samples. Specifically, Stable-TTS\nachieves prosody consistency by leveraging the high-quality prosody of prior\nsamples, while effectively capturing the timbre of the target speaker.\nAdditionally, it employs a prior-preservation loss during fine-tuning to\nmaintain the synthesis ability for prior samples to prevent overfitting on\ntarget samples. Extensive experiments demonstrate the effectiveness of\nStable-TTS even under limited amounts of and noisy target speech samples.\n",
  "subjects": [
    "Computer Science/Sound",
    "Computer Science/Artificial Intelligence",
    "Electrical Engineering and Systems Science/Audio and Speech Processing"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "ZUD5rif2VVpdM9jLHYFKn4sSFkMlOUZLHHQuhFHoET0",
  "pdfSize": "1092677"
}