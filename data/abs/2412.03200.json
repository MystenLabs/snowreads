{"id":"2412.03200","title":"Fab-ME: A Vision State-Space and Attention-Enhanced Framework for Fabric\n  Defect Detection","authors":"Shuai Wang, Huiyan Kong, Baotian Li, Fa Zheng","authorsParsed":[["Wang","Shuai",""],["Kong","Huiyan",""],["Li","Baotian",""],["Zheng","Fa",""]],"versions":[{"version":"v1","created":"Wed, 4 Dec 2024 10:40:17 GMT"},{"version":"v2","created":"Thu, 5 Dec 2024 16:02:22 GMT"}],"updateDate":"2024-12-06","timestamp":1733308817000,"abstract":"  Effective defect detection is critical for ensuring the quality,\nfunctionality, and economic value of textile products. However, existing\nmethods face challenges in achieving high accuracy, real-time performance, and\nefficient global information extraction. To address these issues, we propose\nFab-ME, an advanced framework based on YOLOv8s, specifically designed for the\naccurate detection of 20 fabric defect types. Our contributions include the\nintroduction of the cross-stage partial bottleneck with two convolutions (C2F)\nvision state-space (C2F-VMamba) module, which integrates visual state-space\n(VSS) blocks into the YOLOv8s feature fusion network neck, enhancing the\ncapture of intricate details and global context while maintaining high\nprocessing speeds. Additionally, we incorporate an enhanced multi-scale channel\nattention (EMCA) module into the final layer of the feature extraction network,\nsignificantly improving sensitivity to small targets. Experimental results on\nthe Tianchi fabric defect detection dataset demonstrate that Fab-ME achieves a\n3.5% improvement in mAP@0.5 compared to the original YOLOv8s, validating its\neffectiveness for precise and efficient fabric defect detection.\n","subjects":["Computer Science/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"TyYhdtwLXU_gF14j2y4FBpRO83PbdxSJXEhPTGnKTfg","pdfSize":"2141306"}