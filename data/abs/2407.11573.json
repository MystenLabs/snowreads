{"id":"2407.11573","title":"Probing the Efficacy of Federated Parameter-Efficient Fine-Tuning of\n  Vision Transformers for Medical Image Classification","authors":"Naif Alkhunaizi, Faris Almalik, Rouqaiah Al-Refai, Muzammal Naseer,\n  Karthik Nandakumar","authorsParsed":[["Alkhunaizi","Naif",""],["Almalik","Faris",""],["Al-Refai","Rouqaiah",""],["Naseer","Muzammal",""],["Nandakumar","Karthik",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 10:28:50 GMT"}],"updateDate":"2024-07-17","timestamp":1721125730000,"abstract":"  With the advent of large pre-trained transformer models, fine-tuning these\nmodels for various downstream tasks is a critical problem. Paucity of training\ndata, the existence of data silos, and stringent privacy constraints exacerbate\nthis fine-tuning problem in the medical imaging domain, creating a strong need\nfor algorithms that enable collaborative fine-tuning of pre-trained models.\nMoreover, the large size of these models necessitates the use of\nparameter-efficient fine-tuning (PEFT) to reduce the communication burden in\nfederated learning. In this work, we systematically investigate various\nfederated PEFT strategies for adapting a Vision Transformer (ViT) model\n(pre-trained on a large natural image dataset) for medical image\nclassification. Apart from evaluating known PEFT techniques, we introduce new\nfederated variants of PEFT algorithms such as visual prompt tuning (VPT),\nlow-rank decomposition of visual prompts, stochastic block attention\nfine-tuning, and hybrid PEFT methods like low-rank adaptation (LoRA)+VPT.\nMoreover, we perform a thorough empirical analysis to identify the optimal PEFT\nmethod for the federated setting and understand the impact of data distribution\non federated PEFT, especially for out-of-domain (OOD) and non-IID data. The key\ninsight of this study is that while most federated PEFT methods work well for\nin-domain transfer, there is a substantial accuracy vs. efficiency trade-off\nwhen dealing with OOD and non-IID scenarios, which is commonly the case in\nmedical imaging. Specifically, every order of magnitude reduction in\nfine-tuned/exchanged parameters can lead to a 4% drop in accuracy. Thus, the\ninitial model choice is crucial for federated PEFT. It is preferable to use\nmedical foundation models learned from in-domain medical image data (if\navailable) rather than general vision models.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"IwNNj0fqG4JVZmqVAEROuKvGv989g8mIIi8u_5zrssg","pdfSize":"2278491"}