{"id":"2407.11894","title":"Deep Learning without Global Optimization by Random Fourier Neural\n  Networks","authors":"Owen Davis, Gianluca Geraci, Mohammad Motamed","authorsParsed":[["Davis","Owen",""],["Geraci","Gianluca",""],["Motamed","Mohammad",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 16:23:40 GMT"}],"updateDate":"2024-07-17","timestamp":1721147020000,"abstract":"  We introduce a new training algorithm for variety of deep neural networks\nthat utilize random complex exponential activation functions. Our approach\nemploys a Markov Chain Monte Carlo sampling procedure to iteratively train\nnetwork layers, avoiding global and gradient-based optimization while\nmaintaining error control. It consistently attains the theoretical\napproximation rate for residual networks with complex exponential activation\nfunctions, determined by network complexity. Additionally, it enables efficient\nlearning of multiscale and high-frequency features, producing interpretable\nparameter distributions. Despite using sinusoidal basis functions, we do not\nobserve Gibbs phenomena in approximating discontinuous target functions.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Numerical Analysis","Mathematics/Numerical Analysis","Statistics/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"qa3WKXt2mdWGsbXu6goZPNpQaNTN9FshAP5tgq1uMGA","pdfSize":"2001531","objectId":"0xa02bd940a56843744e5ec2ae4ad5dc7bb60d39f8c91e0e438675814cc692cade","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
