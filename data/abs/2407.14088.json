{"id":"2407.14088","title":"Impact of Model Size on Fine-tuned LLM Performance in Data-to-Text\n  Generation: A State-of-the-Art Investigation","authors":"Joy Mahapatra, Utpal Garain","authorsParsed":[["Mahapatra","Joy",""],["Garain","Utpal",""]],"versions":[{"version":"v1","created":"Fri, 19 Jul 2024 07:54:30 GMT"}],"updateDate":"2024-07-22","timestamp":1721375670000,"abstract":"  Data-to-text (D2T) generation aims to generate human-readable text from\nsemi-structured data, such as tables and graphs. The recent success of D2T is\nlargely attributed to advancements in LLMs. Despite the success of LLMs, no\nresearch has been conducted to illustrate the impact of model size on the\nperformance of fine-tuned LLMs for D2T tasks. D2T model performance is\ntypically assessed based on three key qualities: \\textit{readability}\n(indicates fluency and coherence), \\textit{informativeness} (measures content\nsimilarity), and \\textit{faithfulness} (assesses consistency of factual\ninformation). It is currently uncertain whether increasing the size of LLMs\neffectively improves performance in D2T tasks across these three qualities. The\nobjective of this study is to investigate the performance of fine-tuned LLMs in\nD2T tasks in terms of model size. Through extensive comparative analysis, we\naim to elucidate both the advantages and limitations of scaling model sizes\nacross five widely used D2T datasets (E2E, ViGGo, WikiTableText, DART, and\nWebNLG) and twelve state-of-the-art LLMs with varying sizes from five different\nLLM families (T5, BART, OPT, BLOOM, and Llama 2). To comprehensively cover all\nthe three essential qualities of D2T models, we incorporate six widely\nrecognized automatic metrics -- \\textsc{BLEU}, \\textsc{METEOR},\n\\textsc{BERTScore}, \\textsc{MoverScore}, \\textsc{Parent}, and\n\\textsc{BARTScore}. We also provide an in-depth analysis of LLM performance\nconcerning model size in the presence of source-reference divergence, a\ncritical aspect of D2T tasks. Our investigation reveals that increasing LLM\nsize enhances \\textit{readability} and \\textit{informativeness} in D2T tasks,\nbut larger (in terms of size) LLMs may sacrifice \\textit{faithfulness}.\nMoreover, small-sized LLMs show more resilience than larger ones when\nsource-reference divergence is present.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"sQEV726Y6Adke6LzUK6IX6LvJu1RInOt22St1FdQ9Po","pdfSize":"5574050"}