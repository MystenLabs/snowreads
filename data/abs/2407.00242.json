{"id":"2407.00242","title":"EHRmonize: A Framework for Medical Concept Abstraction from Electronic\n  Health Records using Large Language Models","authors":"Jo\\~ao Matos, Jack Gallifant, Jian Pei, A. Ian Wong","authorsParsed":[["Matos","Jo√£o",""],["Gallifant","Jack",""],["Pei","Jian",""],["Wong","A. Ian",""]],"versions":[{"version":"v1","created":"Fri, 28 Jun 2024 21:39:20 GMT"}],"updateDate":"2024-07-02","timestamp":1719610760000,"abstract":"  Electronic health records (EHRs) contain vast amounts of complex data, but\nharmonizing and processing this information remains a challenging and costly\ntask requiring significant clinical expertise. While large language models\n(LLMs) have shown promise in various healthcare applications, their potential\nfor abstracting medical concepts from EHRs remains largely unexplored. We\nintroduce EHRmonize, a framework leveraging LLMs to abstract medical concepts\nfrom EHR data. Our study uses medication data from two real-world EHR databases\nto evaluate five LLMs on two free-text extraction and six binary classification\ntasks across various prompting strategies. GPT-4o's with 10-shot prompting\nachieved the highest performance in all tasks, accompanied by Claude-3.5-Sonnet\nin a subset of tasks. GPT-4o achieved an accuracy of 97% in identifying generic\nroute names, 82% for generic drug names, and 100% in performing binary\nclassification of antibiotics. While EHRmonize significantly enhances\nefficiency, reducing annotation time by an estimated 60%, we emphasize that\nclinician oversight remains essential. Our framework, available as a Python\npackage, offers a promising tool to assist clinicians in EHR data abstraction,\npotentially accelerating healthcare research and improving data harmonization\nprocesses.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"5rcgNlHHMkfVn3BiGpGzYNGuAVZzFNRAbKiHTSDqfN8","pdfSize":"1821884"}