{"id":"2407.14229","title":"Words2Contact: Identifying Support Contacts from Verbal Instructions\n  Using Foundation Models","authors":"Dionis Totsila, Quentin Rouxel, Jean-Baptiste Mouret, Serena Ivaldi","authorsParsed":[["Totsila","Dionis",""],["Rouxel","Quentin",""],["Mouret","Jean-Baptiste",""],["Ivaldi","Serena",""]],"versions":[{"version":"v1","created":"Fri, 19 Jul 2024 11:57:34 GMT"}],"updateDate":"2024-07-22","timestamp":1721390254000,"abstract":"  This paper presents Words2Contact, a language-guided multi-contact placement\npipeline leveraging large language models and vision language models. Our\nmethod is a key component for language-assisted teleoperation and human-robot\ncooperation, where human operators can instruct the robots where to place their\nsupport contacts before whole-body reaching or manipulation using natural\nlanguage. Words2Contact transforms the verbal instructions of a human operator\ninto contact placement predictions; it also deals with iterative corrections,\nuntil the human is satisfied with the contact location identified in the\nrobot's field of view. We benchmark state-of-the-art LLMs and VLMs for size and\nperformance in contact prediction. We demonstrate the effectiveness of the\niterative correction process, showing that users, even naive, quickly learn how\nto instruct the system to obtain accurate locations. Finally, we validate\nWords2Contact in real-world experiments with the Talos humanoid robot,\ninstructed by human operators to place support contacts on different locations\nand surfaces to avoid falling when reaching for distant objects.\n","subjects":["Computing Research Repository/Robotics","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"mlXHRzsxlkSm1nff-wdpFOhZz162zTrK2Dimo2DChLM","pdfSize":"13473130"}