{"id":"2407.19809","title":"Twins-PainViT: Towards a Modality-Agnostic Vision Transformer Framework\n  for Multimodal Automatic Pain Assessment using Facial Videos and fNIRS","authors":"Stefanos Gkikas, Manolis Tsiknakis","authorsParsed":[["Gkikas","Stefanos",""],["Tsiknakis","Manolis",""]],"versions":[{"version":"v1","created":"Mon, 29 Jul 2024 09:02:43 GMT"}],"updateDate":"2024-07-30","timestamp":1722243763000,"abstract":"  Automatic pain assessment plays a critical role for advancing healthcare and\noptimizing pain management strategies. This study has been submitted to the\nFirst Multimodal Sensing Grand Challenge for Next-Gen Pain Assessment\n(AI4PAIN). The proposed multimodal framework utilizes facial videos and fNIRS\nand presents a modality-agnostic approach, alleviating the need for\ndomain-specific models. Employing a dual ViT configuration and adopting\nwaveform representations for the fNIRS, as well as for the extracted embeddings\nfrom the two modalities, demonstrate the efficacy of the proposed method,\nachieving an accuracy of 46.76% in the multilevel pain assessment task.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/publicdomain/zero/1.0/","blobId":"0uRdvQH5Bimte8yyZwzA5g7omlIKjc6OO_oJQCSRSX0","pdfSize":"3488796"}