{"id":"2407.02700","title":"Output Range Analysis for Deep Neural Networks based on Simulated\n  Annealing Processes","authors":"Helder Rojas, Nilton Rojas, Espinoza J. B., Luis Huamanchumo","authorsParsed":[["Rojas","Helder",""],["Rojas","Nilton",""],["B.","Espinoza J.",""],["Huamanchumo","Luis",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 22:47:40 GMT"}],"updateDate":"2024-07-04","timestamp":1719960460000,"abstract":"  This paper tackles the challenging problem of output range estimation for\nDeep Neural Networks (DNNs), introducing a novel algorithm based on Simulated\nAnnealing (SA). Our approach addresses the lack of local geometric information\nand high non-linearity in DNNs, making it versatile across various\narchitectures, especially Residual Neural Networks (ResNets). We present a\nstraightforward, implementation-friendly algorithm that avoids restrictive\nassumptions about network architecture. Through theoretical analysis and\nexperimental evaluations, including tests on the Ackley function, we\ndemonstrate our algorithm's effectiveness in navigating complex, non-convex\nsurfaces and accurately estimating DNN output ranges. Futhermore, the Python\ncodes of this experimental evaluation that support our results are available in\nour GitHub repository\n(https://github.com/Nicerova7/output-range-analysis-for-deep-neural-networks-with-simulated-annealing).\n","subjects":["Computing Research Repository/Machine Learning","Mathematics/Probability","Statistics/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"hXnuS2TQRIhU8s-pW-dIp_d2zIHpWx-nzTm9vYKsDBI","pdfSize":"2440194"}