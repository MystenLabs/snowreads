{"id":"2407.13750","title":"Pose-guided multi-task video transformer for driver action recognition","authors":"Ricardo Pizarro and Roberto Valle and Luis Miguel Bergasa and Jos\\'e\n  M. Buenaposada and Luis Baumela","authorsParsed":[["Pizarro","Ricardo",""],["Valle","Roberto",""],["Bergasa","Luis Miguel",""],["Buenaposada","Jos√© M.",""],["Baumela","Luis",""]],"versions":[{"version":"v1","created":"Thu, 18 Jul 2024 17:53:51 GMT"}],"updateDate":"2024-07-19","timestamp":1721325231000,"abstract":"  We investigate the task of identifying situations of distracted driving\nthrough analysis of in-car videos. To tackle this challenge we introduce a\nmulti-task video transformer that predicts both distracted actions and driver\npose. Leveraging VideoMAEv2, a large pre-trained architecture, our approach\nincorporates semantic information from human keypoint locations to enhance\naction recognition and decrease computational overhead by minimizing the number\nof spatio-temporal tokens. By guiding token selection with pose and class\ninformation, we notably reduce the model's computational requirements while\npreserving the baseline accuracy. Our model surpasses existing state-of-the art\nresults in driver action recognition while exhibiting superior efficiency\ncompared to current video transformer-based approaches.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"j7gPlVQGK8FV4IXHv7MiMc7xfYBG0dISjCDS69MS9tQ","pdfSize":"5315455"}