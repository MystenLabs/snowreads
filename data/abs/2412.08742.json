{
  "id": "2412.08742",
  "title": "In-Context Learning with Topological Information for Knowledge Graph\n  Completion",
  "authors": "Udari Madhushani Sehwag, Kassiani Papasotiriou, Jared Vann, and\n  Sumitra Ganesh",
  "authorsParsed": [
    [
      "Sehwag",
      "Udari Madhushani",
      ""
    ],
    [
      "Papasotiriou",
      "Kassiani",
      ""
    ],
    [
      "Vann",
      "Jared",
      ""
    ],
    [
      "Ganesh",
      "Sumitra",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Wed, 11 Dec 2024 19:29:36 GMT"
    }
  ],
  "updateDate": "2024-12-13",
  "timestamp": 1733945376000,
  "abstract": "  Knowledge graphs (KGs) are crucial for representing and reasoning over\nstructured information, supporting a wide range of applications such as\ninformation retrieval, question answering, and decision-making. However, their\neffectiveness is often hindered by incompleteness, limiting their potential for\nreal-world impact. While knowledge graph completion (KGC) has been extensively\nstudied in the literature, recent advances in generative AI models,\nparticularly large language models (LLMs), have introduced new opportunities\nfor innovation. In-context learning has recently emerged as a promising\napproach for leveraging pretrained knowledge of LLMs across a range of natural\nlanguage processing tasks and has been widely adopted in both academia and\nindustry. However, how to utilize in-context learning for effective KGC remains\nrelatively underexplored. We develop a novel method that incorporates\ntopological information through in-context learning to enhance KGC performance.\nBy integrating ontological knowledge and graph structure into the context of\nLLMs, our approach achieves strong performance in the transductive setting\ni.e., nodes in the test graph dataset are present in the training graph\ndataset. Furthermore, we apply our approach to KGC in the more challenging\ninductive setting, i.e., nodes in the training graph dataset and test graph\ndataset are disjoint, leveraging the ontology to infer useful information about\nmissing nodes which serve as contextual cues for the LLM during inference. Our\nmethod demonstrates superior performance compared to baselines on the\nILPC-small and ILPC-large datasets.\n",
  "subjects": [
    "Computer Science/Computation and Language",
    "Computer Science/Artificial Intelligence"
  ],
  "license": "http://creativecommons.org/publicdomain/zero/1.0/",
  "blobId": "Kz-Gc8E35arbx9CFkrjdjeKL4wkqPpACZGYLzYn463Y",
  "pdfSize": "217106"
}