{"id":"2407.20768","title":"HyperMM : Robust Multimodal Learning with Varying-sized Inputs","authors":"Hava Chaptoukaev, Vincenzo Marcian\\'o, Francesco Galati, Maria A.\n  Zuluaga","authorsParsed":[["Chaptoukaev","Hava",""],["Marcian√≥","Vincenzo",""],["Galati","Francesco",""],["Zuluaga","Maria A.",""]],"versions":[{"version":"v1","created":"Tue, 30 Jul 2024 12:13:18 GMT"}],"updateDate":"2024-07-31","timestamp":1722341598000,"abstract":"  Combining multiple modalities carrying complementary information through\nmultimodal learning (MML) has shown considerable benefits for diagnosing\nmultiple pathologies. However, the robustness of multimodal models to missing\nmodalities is often overlooked. Most works assume modality completeness in the\ninput data, while in clinical practice, it is common to have incomplete\nmodalities. Existing solutions that address this issue rely on modality\nimputation strategies before using supervised learning models. These\nstrategies, however, are complex, computationally costly and can strongly\nimpact subsequent prediction models. Hence, they should be used with parsimony\nin sensitive applications such as healthcare. We propose HyperMM, an end-to-end\nframework designed for learning with varying-sized inputs. Specifically, we\nfocus on the task of supervised MML with missing imaging modalities without\nusing imputation before training. We introduce a novel strategy for training a\nuniversal feature extractor using a conditional hypernetwork, and propose a\npermutation-invariant neural network that can handle inputs of varying\ndimensions to process the extracted features, in a two-phase task-agnostic\nframework. We experimentally demonstrate the advantages of our method in two\ntasks: Alzheimer's disease detection and breast cancer classification. We\ndemonstrate that our strategy is robust to high rates of missing data and that\nits flexibility allows it to handle varying-sized datasets beyond the scenario\nof missing modalities.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"B4bx7BORDs1O9UfwyFPZavHYJ2wH9cO3fltsNpP3jTk","pdfSize":"1340398","objectId":"0x4073487d9513d22070196b628006c4b2ac9ebbf202d044b5bc046b5506db328f","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
