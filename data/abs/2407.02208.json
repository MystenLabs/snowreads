{"id":"2407.02208","title":"How to Learn in a Noisy World? Self-Correcting the Real-World Data Noise\n  on Machine Translation","authors":"Yan Meng, Di Wu, Christof Monz","authorsParsed":[["Meng","Yan",""],["Wu","Di",""],["Monz","Christof",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 12:15:15 GMT"}],"updateDate":"2024-07-03","timestamp":1719922515000,"abstract":"  The massive amounts of web-mined parallel data contain large amounts of\nnoise. Semantic misalignment, as the primary source of the noise, poses a\nchallenge for training machine translation systems. In this paper, we first\nstudy the impact of real-world hard-to-detect misalignment noise by proposing a\nprocess to simulate the realistic misalignment controlled by semantic\nsimilarity. After quantitatively analyzing the impact of simulated misalignment\non machine translation, we show the limited effectiveness of widely used\npre-filters to improve the translation performance, underscoring the necessity\nof more fine-grained ways to handle data noise. By observing the increasing\nreliability of the model's self-knowledge for distinguishing misaligned and\nclean data at the token-level, we propose a self-correction approach which\nleverages the model's prediction distribution to revise the training\nsupervision from the ground-truth data over training time. Through\ncomprehensive experiments, we show that our self-correction method not only\nimproves translation performance in the presence of simulated misalignment\nnoise but also proves effective for real-world noisy web-mined datasets across\neight translation tasks.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"__IosADDSSIMaW7mu1AfSWmWTJS-Z54b4Kbs6tABUHc","pdfSize":"1521804","objectId":"0x65b1b4f11cb18fba89ac66d6887b12f501a743f70c2456bcb9cb1628ca731f75","registeredEpoch":"3","certifiedEpoch":"3","startEpoch":"3","endEpoch":"203"}
