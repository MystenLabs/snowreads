{"id":"2412.12693","title":"SPHERE: Unveiling Spatial Blind Spots in Vision-Language Models Through\n  Hierarchical Evaluation","authors":"Wenyu Zhang, Wei En Ng, Lixin Ma, Yuwen Wang, Jungqi Zhao, Allison\n  Koenecke, Boyang Li, Lu Wang","authorsParsed":[["Zhang","Wenyu",""],["Ng","Wei En",""],["Ma","Lixin",""],["Wang","Yuwen",""],["Zhao","Jungqi",""],["Koenecke","Allison",""],["Li","Boyang",""],["Wang","Lu",""]],"versions":[{"version":"v1","created":"Tue, 17 Dec 2024 09:10:55 GMT"},{"version":"v2","created":"Mon, 17 Feb 2025 10:28:00 GMT"}],"updateDate":"2025-02-18","timestamp":1734426655000,"abstract":"  Current vision-language models may grasp basic spatial cues and simple\ndirections (e.g. left, right, front, back), but struggle with the\nmulti-dimensional spatial reasoning necessary for human-like understanding and\nreal-world applications. To address this gap, we develop SPHERE (Spatial\nPerception and Hierarchical Evaluation of REasoning), a hierarchical evaluation\nframework supported by a new human-annotated dataset. SPHERE systematically\nprobes models across increasing levels of complexity, from fundamental skills\nto multi-skill integration and high-level reasoning that combines spatial,\nvisual, and logical understanding. Benchmark evaluation of state-of-the-art\nmodels reveals significant deficiencies, especially in reasoning about distance\nand proximity, understanding both egocentric and allocentric perspectives, and\napplying spatial logic in physical contexts. These findings expose critical\nblind spots in existing models and underscore the need for more advanced\nspatial reasoning techniques, driving the development of vision-language models\nthat align more closely with human spatial cognition. The dataset will be\nopen-sourced upon publication.\n","subjects":["Computer Science/Computer Vision and Pattern Recognition","Computer Science/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"CcpjtuDEDcjBzDEIAx9g6SS3rK58tRH_ZKb8F7nfS3U","pdfSize":"1425854"}