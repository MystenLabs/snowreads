{
  "id": "2412.04729",
  "title": "Espresso: High Compression For Rich Extraction From Videos for Your\n  Vision-Language Model",
  "authors": "Keunwoo Peter Yu, Achal Dave, Rares Ambrus, Jean Mercat",
  "authorsParsed": [
    [
      "Yu",
      "Keunwoo Peter",
      ""
    ],
    [
      "Dave",
      "Achal",
      ""
    ],
    [
      "Ambrus",
      "Rares",
      ""
    ],
    [
      "Mercat",
      "Jean",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Fri, 6 Dec 2024 02:39:50 GMT"
    },
    {
      "version": "v2",
      "created": "Thu, 12 Dec 2024 06:31:47 GMT"
    }
  ],
  "updateDate": "2024-12-13",
  "timestamp": 1733452790000,
  "abstract": "  Most of the current vision-language models (VLMs) for videos struggle to\nunderstand videos longer than a few seconds. This is primarily due to the fact\nthat they do not scale to utilizing a large number of frames. In order to\naddress this limitation, we propose Espresso, a novel method that extracts and\ncompresses spatial and temporal information separately. Through extensive\nevaluations, we show that spatial and temporal compression in Espresso each\nhave a positive impact on the long-form video understanding capabilities; when\ncombined, their positive impact increases. Furthermore, we show that Espresso's\nperformance scales well with more training data, and that Espresso is far more\neffective than the existing projectors for VLMs in long-form video\nunderstanding. Moreover, we devise a more difficult evaluation setting for\nEgoSchema called \"needle-in-a-haystack\" that multiplies the lengths of the\ninput videos. Espresso achieves SOTA performance on this task, outperforming\nthe SOTA VLMs that have been trained on much more training data.\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "aV5fmA1BQfuz3Rw57TFOxtVeM30DT67EQJhRsJ0Y6Wg",
  "pdfSize": "4215765"
}