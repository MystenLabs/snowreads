{"id":"2412.01765","title":"Planning and Reasoning with 3D Deformable Objects for Hierarchical\n  Text-to-3D Robotic Shaping","authors":"Alison Bartsch, Amir Barati Farimani","authorsParsed":[["Bartsch","Alison",""],["Farimani","Amir Barati",""]],"versions":[{"version":"v1","created":"Mon, 2 Dec 2024 18:03:12 GMT"}],"updateDate":"2024-12-03","timestamp":1733162592000,"abstract":"  Deformable object manipulation remains a key challenge in developing\nautonomous robotic systems that can be successfully deployed in real-world\nscenarios. In this work, we explore the challenges of deformable object\nmanipulation through the task of sculpting clay into 3D shapes. We propose the\nfirst coarse-to-fine autonomous sculpting system in which the sculpting agent\nfirst selects how many and where to place discrete chunks of clay into the\nworkspace to create a coarse shape, and then iteratively refines the shape with\nsequences of deformation actions. We leverage large language models for\nsub-goal generation, and train a point cloud region-based action model to\npredict robot actions from the desired point cloud sub-goals. Additionally, our\nmethod is the first autonomous sculpting system that is a real-world text-to-3D\nshaping pipeline without any explicit 3D goals or sub-goals provided to the\nsystem. We demonstrate our method is able to successfully create a set of\nsimple shapes solely from text-based prompting. Furthermore, we explore\nrigorously how to best quantify success for the text-to-3D sculpting task, and\ncompare existing text-image and text-point cloud similarity metrics to human\nevaluations for this task. For experimental videos, human evaluation details,\nand full prompts, please see our project website:\nhttps://sites.google.com/andrew.cmu.edu/hierarchicalsculpting\n","subjects":["Computer Science/Robotics"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"DK-FFjVDl1aLPGokgSjJ8sUicD06H3VbXbEA84WxaX4","pdfSize":"2618452"}