{"id":"2407.17874","title":"Improving Domain-Specific ASR with LLM-Generated Contextual Descriptions","authors":"Jiwon Suh, Injae Na, Woohwan Jung","authorsParsed":[["Suh","Jiwon",""],["Na","Injae",""],["Jung","Woohwan",""]],"versions":[{"version":"v1","created":"Thu, 25 Jul 2024 08:44:04 GMT"}],"updateDate":"2024-07-26","timestamp":1721897044000,"abstract":"  End-to-end automatic speech recognition (E2E ASR) systems have significantly\nimproved speech recognition through training on extensive datasets. Despite\nthese advancements, they still struggle to accurately recognize domain specific\nwords, such as proper nouns and technical terminologies. To address this\nproblem, we propose a method to utilize the state-of-the-art Whisper without\nmodifying its architecture, preserving its generalization performance while\nenabling it to leverage descriptions effectively. Moreover, we propose two\nadditional training techniques to improve the domain specific ASR: decoder\nfine-tuning, and context perturbation. We also propose a method to use a Large\nLanguage Model (LLM) to generate descriptions with simple metadata, when\ndescriptions are unavailable. Our experiments demonstrate that proposed methods\nnotably enhance domain-specific ASR accuracy on real-life datasets, with\nLLM-generated descriptions outperforming human-crafted ones in effectiveness.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"x1dqYgrdoipLuSnONmSjT076gfjvPmOb4vNUZU_eEqc","pdfSize":"243820"}