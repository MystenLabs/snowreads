{"id":"2407.08853","title":"GPT-4 is judged more human than humans in displaced and inverted Turing\n  tests","authors":"Ishika Rathi, Sydney Taylor, Benjamin K. Bergen, and Cameron R. Jones","authorsParsed":[["Rathi","Ishika",""],["Taylor","Sydney",""],["Bergen","Benjamin K.",""],["Jones","Cameron R.",""]],"versions":[{"version":"v1","created":"Thu, 11 Jul 2024 20:28:24 GMT"}],"updateDate":"2024-07-15","timestamp":1720729704000,"abstract":"  Everyday AI detection requires differentiating between people and AI in\ninformal, online conversations. In many cases, people will not interact\ndirectly with AI systems but instead read conversations between AI systems and\nother people. We measured how well people and large language models can\ndiscriminate using two modified versions of the Turing test: inverted and\ndisplaced. GPT-3.5, GPT-4, and displaced human adjudicators judged whether an\nagent was human or AI on the basis of a Turing test transcript. We found that\nboth AI and displaced human judges were less accurate than interactive\ninterrogators, with below chance accuracy overall. Moreover, all three judged\nthe best-performing GPT-4 witness to be human more often than human witnesses.\nThis suggests that both humans and current LLMs struggle to distinguish between\nthe two when they are not actively interrogating the person, underscoring an\nurgent need for more accurate tools to detect AI in conversations.\n","subjects":["Computing Research Repository/Human-Computer Interaction","Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"9vEEmZPv9TkOe13zpkCWiW3IVdCEOQxiRdV9FZl714Y","pdfSize":"344241"}