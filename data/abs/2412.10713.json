{
  "id": "2412.10713",
  "title": "RAT: Adversarial Attacks on Deep Reinforcement Agents for Targeted\n  Behaviors",
  "authors": "Fengshuo Bai, Runze Liu, Yali Du, Ying Wen, Yaodong Yang",
  "authorsParsed": [
    [
      "Bai",
      "Fengshuo",
      ""
    ],
    [
      "Liu",
      "Runze",
      ""
    ],
    [
      "Du",
      "Yali",
      ""
    ],
    [
      "Wen",
      "Ying",
      ""
    ],
    [
      "Yang",
      "Yaodong",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Sat, 14 Dec 2024 06:56:11 GMT"
    }
  ],
  "updateDate": "2024-12-17",
  "timestamp": 1734159371000,
  "abstract": "  Evaluating deep reinforcement learning (DRL) agents against targeted behavior\nattacks is critical for assessing their robustness. These attacks aim to\nmanipulate the victim into specific behaviors that align with the attacker's\nobjectives, often bypassing traditional reward-based defenses. Prior methods\nhave primarily focused on reducing cumulative rewards; however, rewards are\ntypically too generic to capture complex safety requirements effectively. As a\nresult, focusing solely on reward reduction can lead to suboptimal attack\nstrategies, particularly in safety-critical scenarios where more precise\nbehavior manipulation is needed. To address these challenges, we propose RAT, a\nmethod designed for universal, targeted behavior attacks. RAT trains an\nintention policy that is explicitly aligned with human preferences, serving as\na precise behavioral target for the adversary. Concurrently, an adversary\nmanipulates the victim's policy to follow this target behavior. To enhance the\neffectiveness of these attacks, RAT dynamically adjusts the state occupancy\nmeasure within the replay buffer, allowing for more controlled and effective\nbehavior manipulation. Our empirical results on robotic simulation tasks\ndemonstrate that RAT outperforms existing adversarial attack algorithms in\ninducing specific behaviors. Additionally, RAT shows promise in improving agent\nrobustness, leading to more resilient policies. We further validate RAT by\nguiding Decision Transformer agents to adopt behaviors aligned with human\npreferences in various MuJoCo tasks, demonstrating its effectiveness across\ndiverse tasks.\n",
  "subjects": [
    "Computer Science/Machine Learning",
    "Computer Science/Artificial Intelligence",
    "Computer Science/Cryptography and Security",
    "Computer Science/Robotics"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "DmWdcXCQrIfyDex5eIXIabHigUvCXSXUAiw2f1KWsMo",
  "pdfSize": "3484713"
}