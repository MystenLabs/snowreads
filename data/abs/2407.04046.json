{"id":"2407.04046","title":"Systematic Task Exploration with LLMs: A Study in Citation Text\n  Generation","authors":"Furkan \\c{S}ahinu\\c{c}, Ilia Kuznetsov, Yufang Hou, Iryna Gurevych","authorsParsed":[["Şahinuç","Furkan",""],["Kuznetsov","Ilia",""],["Hou","Yufang",""],["Gurevych","Iryna",""]],"versions":[{"version":"v1","created":"Thu, 4 Jul 2024 16:41:08 GMT"}],"updateDate":"2024-07-08","timestamp":1720111268000,"abstract":"  Large language models (LLMs) bring unprecedented flexibility in defining and\nexecuting complex, creative natural language generation (NLG) tasks. Yet, this\nflexibility brings new challenges, as it introduces new degrees of freedom in\nformulating the task inputs and instructions and in evaluating model\nperformance. To facilitate the exploration of creative NLG tasks, we propose a\nthree-component research framework that consists of systematic input\nmanipulation, reference data, and output measurement. We use this framework to\nexplore citation text generation -- a popular scholarly NLP task that lacks\nconsensus on the task definition and evaluation metric and has not yet been\ntackled within the LLM paradigm. Our results highlight the importance of\nsystematically investigating both task instruction and input configuration when\nprompting LLMs, and reveal non-trivial relationships between different\nevaluation metrics used for citation text generation. Additional human\ngeneration and human evaluation experiments provide new qualitative insights\ninto the task to guide future research in citation text generation. We make our\ncode and data publicly available.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by-sa/4.0/","blobId":"aLR8mqEldoB_6XZjdCdVJxS9-CVdP5uo-c7jvQloO-0","pdfSize":"792672"}
