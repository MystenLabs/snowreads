{"id":"2407.15352","title":"MAVEN-Fact: A Large-scale Event Factuality Detection Dataset","authors":"Chunyang Li, Hao Peng, Xiaozhi Wang, Yunjia Qi, Lei Hou, Bin Xu,\n  Juanzi Li","authorsParsed":[["Li","Chunyang",""],["Peng","Hao",""],["Wang","Xiaozhi",""],["Qi","Yunjia",""],["Hou","Lei",""],["Xu","Bin",""],["Li","Juanzi",""]],"versions":[{"version":"v1","created":"Mon, 22 Jul 2024 03:43:46 GMT"}],"updateDate":"2024-07-23","timestamp":1721619826000,"abstract":"  Event Factuality Detection (EFD) task determines the factuality of textual\nevents, i.e., classifying whether an event is a fact, possibility, or\nimpossibility, which is essential for faithfully understanding and utilizing\nevent knowledge. However, due to the lack of high-quality large-scale data,\nevent factuality detection is under-explored in event understanding research,\nwhich limits the development of EFD community. To address these issues and\nprovide faithful event understanding, we introduce MAVEN-Fact, a large-scale\nand high-quality EFD dataset based on the MAVEN dataset. MAVEN-Fact includes\nfactuality annotations of 112,276 events, making it the largest EFD dataset.\nExtensive experiments demonstrate that MAVEN-Fact is challenging for both\nconventional fine-tuned models and large language models (LLMs). Thanks to the\ncomprehensive annotations of event arguments and relations in MAVEN, MAVEN-Fact\nalso supports some further analyses and we find that adopting event arguments\nand relations helps in event factuality detection for fine-tuned models but\ndoes not benefit LLMs. Furthermore, we preliminarily study an application case\nof event factuality detection and find it helps in mitigating event-related\nhallucination in LLMs. Our dataset and codes can be obtained from\n\\url{https://github.com/lcy2723/MAVEN-FACT}\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"9VYBFvnZWAKah169CySvYsoG-5z4tKZAS6RaiRv0Hc8","pdfSize":"574313"}