{"id":"2412.17203","title":"Agile TLB Prefetching and Prediction Replacement Policy","authors":"Melkamu Mersha, Tsion Abay, Mingziem Bitewa, Gedare Bloom","authorsParsed":[["Mersha","Melkamu",""],["Abay","Tsion",""],["Bitewa","Mingziem",""],["Bloom","Gedare",""]],"versions":[{"version":"v1","created":"Mon, 23 Dec 2024 00:46:53 GMT"}],"updateDate":"2024-12-24","timestamp":1734914813000,"abstract":"  Virtual-to-physical address translation is a critical performance bottleneck\nin paging-based virtual memory systems. The Translation Lookaside Buffer (TLB)\naccelerates address translation by caching frequently accessed mappings, but\nTLB misses lead to costly page walks. Hardware and software techniques address\nthis challenge. Hardware approaches enhance TLB reach through system-level\nsupport, while software optimizations include TLB prefetching, replacement\npolicies, superpages, and page size adjustments. Prefetching Page Table Entries\n(PTEs) for future accesses reduces bottlenecks but may incur overhead from\nincorrect predictions. Integrating an Agile TLB Prefetcher (ATP) with SBFP\noptimizes performance by leveraging page table locality and dynamically\nidentifying essential free PTEs during page walks. Predictive replacement\npolicies further improve TLB performance. Traditional LRU replacement is\nlimited to near-instant references, while advanced policies like SRRIP, GHRP,\nSHiP, SDBP, and CHiRP enhance performance by targeting specific inefficiencies.\nCHiRP, tailored for L2 TLBs, surpasses other policies by leveraging control\nflow history to detect dead blocks, utilizing L2 TLB entries for learning\ninstead of sampling. These integrated techniques collectively address key\nchallenges in virtual memory management.\n","subjects":["Computer Science/Hardware Architecture"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"pbIbLDk3c06XVV9xb3dMGDop7tOqsweVOfj8lLM3eC8","pdfSize":"425196"}