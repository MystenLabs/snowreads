{"id":"2407.03847","title":"Comparing Differentiable Logics for Learning with Logical Constraints","authors":"Thomas Flinkow, Barak A. Pearlmutter, Rosemary Monahan","authorsParsed":[["Flinkow","Thomas",""],["Pearlmutter","Barak A.",""],["Monahan","Rosemary",""]],"versions":[{"version":"v1","created":"Thu, 4 Jul 2024 11:28:40 GMT"}],"updateDate":"2024-07-08","timestamp":1720092520000,"abstract":"  Extensive research on formal verification of machine learning systems\nindicates that learning from data alone often fails to capture underlying\nbackground knowledge such as specifications implicitly available in the data.\nVarious neural network verifiers have been developed to ensure that a\nmachine-learnt model satisfies correctness and safety properties, however, they\ntypically assume a trained network with fixed weights. A promising approach for\ncreating machine learning models that inherently satisfy constraints after\ntraining is to encode background knowledge as explicit logical constraints that\nguide the learning process via so-called differentiable logics. In this paper,\nwe experimentally compare and evaluate various logics from the literature,\npresenting our findings and highlighting open problems for future work.\n","subjects":["Computing Research Repository/Logic in Computer Science"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"c7LOUdd9ckFUBtmisS9J48JFbkcK3pHoUPvRD6ixl7Q","pdfSize":"962846"}