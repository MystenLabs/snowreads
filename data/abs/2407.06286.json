{"id":"2407.06286","title":"Characterization of topological structures in different neural network\n  architectures","authors":"Pawe{\\l} \\'Swider","authorsParsed":[["Świder","Paweł",""]],"versions":[{"version":"v1","created":"Mon, 8 Jul 2024 18:02:18 GMT"}],"updateDate":"2024-07-10","timestamp":1720461738000,"abstract":"  One of the most crucial tasks in the future will be to understand what is\ngoing on in neural networks, as they will become even more powerful and widely\ndeployed. This work aims to use TDA methods to analyze neural representations.\nWe develop methods for analyzing representations from different architectures\nand check how one should use them to obtain valid results. Our findings\nindicate that removing outliers does not have much impact on the results and\nthat we should compare representations with the same number of elements. We\napplied these methods for ResNet, VGG19, and ViT architectures and found\nsubstantial differences along with some similarities. Additionally, we\ndetermined that models with similar architecture tend to have a similar\ntopology of representations and models with a larger number of layers change\ntheir topology more smoothly. Furthermore, we found that the topology of\npre-trained and finetuned models starts to differ in the middle and final\nlayers while remaining quite similar in the initial layers. These findings\ndemonstrate the efficacy of TDA in the analysis of neural network behavior.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"tc6IYU64ydqfLotBSFiKt7546UbKzDabVuvrDhcVUNw","pdfSize":"3262953"}