{"id":"2407.07461","title":"Drantal-NeRF: Diffusion-Based Restoration for Anti-aliasing Neural\n  Radiance Field","authors":"Ganlin Yang, Kaidong Zhang, Jingjing Fu, Dong Liu","authorsParsed":[["Yang","Ganlin",""],["Zhang","Kaidong",""],["Fu","Jingjing",""],["Liu","Dong",""]],"versions":[{"version":"v1","created":"Wed, 10 Jul 2024 08:32:13 GMT"}],"updateDate":"2024-07-11","timestamp":1720600333000,"abstract":"  Aliasing artifacts in renderings produced by Neural Radiance Field (NeRF) is\na long-standing but complex issue in the field of 3D implicit representation,\nwhich arises from a multitude of intricate causes and was mitigated by\ndesigning more advanced but complex scene parameterization methods before. In\nthis paper, we present a Diffusion-based restoration method for anti-aliasing\nNeural Radiance Field (Drantal-NeRF). We consider the anti-aliasing issue from\na low-level restoration perspective by viewing aliasing artifacts as a kind of\ndegradation model added to clean ground truths. By leveraging the powerful\nprior knowledge encapsulated in diffusion model, we could restore the\nhigh-realism anti-aliasing renderings conditioned on aliased low-quality\ncounterparts. We further employ a feature-wrapping operation to ensure\nmulti-view restoration consistency and finetune the VAE decoder to better adapt\nto the scene-specific data distribution. Our proposed method is easy to\nimplement and agnostic to various NeRF backbones. We conduct extensive\nexperiments on challenging large-scale urban scenes as well as unbounded\n360-degree scenes and achieve substantial qualitative and quantitative\nimprovements.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"RHc2P9rY2ZlR0sVN4jsSgQPj3yOn1kXSjCkxIDnp4m8","pdfSize":"9735917","objectId":"0x642e05ab15dac934184ceb0b27aa331b29e511b99c9a09474c6bd5803d14c16e","registeredEpoch":"1","certifiedEpoch":"1","startEpoch":"1","endEpoch":"201"}
