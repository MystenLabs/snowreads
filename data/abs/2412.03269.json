{"id":"2412.03269","title":"Theory and Fast Learned Solver for $\\ell^1$-TV Regularization","authors":"Xinling Liu, Jianjun Wang, Bangti Jin","authorsParsed":[["Liu","Xinling",""],["Wang","Jianjun",""],["Jin","Bangti",""]],"versions":[{"version":"v1","created":"Wed, 4 Dec 2024 12:25:21 GMT"}],"updateDate":"2024-12-05","timestamp":1733315121000,"abstract":"  The $\\ell^1$ and total variation (TV) penalties have been used successfully\nin many areas, and the combination of the $\\ell^1$ and TV penalties can lead to\nfurther improved performance. In this work, we investigate the mathematical\ntheory and numerical algorithms for the $\\ell^1$-TV model in the context of\nsignal recovery: we derive the sample complexity of the $\\ell^1$-TV model for\nrecovering signals with sparsity and gradient sparsity. Also we propose a novel\nalgorithm (PGM-ISTA) for the regularized $\\ell^1$-TV problem, and establish its\nglobal convergence and parameter selection criteria. Furthermore, we construct\na fast learned solver (LPGM-ISTA) by unrolling PGM-ISTA. The results for the\nexperiment on ECG signals show the superior performance of LPGM-ISTA in terms\nof recovery accuracy and computational efficiency.\n","subjects":["Mathematics/Numerical Analysis","Computer Science/Numerical Analysis"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"c3N55HWykEUUpcCwA2mOdQhSUEVNaWouYemC_iaGkYk","pdfSize":"2914816"}