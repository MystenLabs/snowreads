{"id":"2412.16928","title":"AV-DTEC: Self-Supervised Audio-Visual Fusion for Drone Trajectory\n  Estimation and Classification","authors":"Zhenyuan Xiao, Yizhuo Yang, Guili Xu, Xianglong Zeng, Shenghai Yuan","authorsParsed":[["Xiao","Zhenyuan",""],["Yang","Yizhuo",""],["Xu","Guili",""],["Zeng","Xianglong",""],["Yuan","Shenghai",""]],"versions":[{"version":"v1","created":"Sun, 22 Dec 2024 08:58:15 GMT"}],"updateDate":"2024-12-24","timestamp":1734857895000,"abstract":"  The increasing use of compact UAVs has created significant threats to public\nsafety, while traditional drone detection systems are often bulky and costly.\nTo address these challenges, we propose AV-DTEC, a lightweight self-supervised\naudio-visual fusion-based anti-UAV system. AV-DTEC is trained using\nself-supervised learning with labels generated by LiDAR, and it simultaneously\nlearns audio and visual features through a parallel selective state-space\nmodel. With the learned features, a specially designed plug-and-play\nprimary-auxiliary feature enhancement module integrates visual features into\naudio features for better robustness in cross-lighting conditions. To reduce\nreliance on auxiliary features and align modalities, we propose a\nteacher-student model that adaptively adjusts the weighting of visual features.\nAV-DTEC demonstrates exceptional accuracy and effectiveness in real-world\nmulti-modality data. The code and trained models are publicly accessible on\nGitHub\n  \\url{https://github.com/AmazingDay1/AV-DETC}.\n","subjects":["Computer Science/Sound","Computer Science/Computer Vision and Pattern Recognition","Computer Science/Multimedia","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"5sq-tzhA0H3JrJJ4RjNdbBZOSB-Vnqv3or_D_g3P48A","pdfSize":"2831195"}