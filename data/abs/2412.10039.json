{
  "id": "2412.10039",
  "title": "Are you doing better than random guessing? A call for using negative\n  controls when evaluating causal discovery algorithms",
  "authors": "Anne Helby Petersen",
  "authorsParsed": [
    [
      "Petersen",
      "Anne Helby",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Fri, 13 Dec 2024 11:00:26 GMT"
    }
  ],
  "updateDate": "2024-12-16",
  "timestamp": 1734087626000,
  "abstract": "  New proposals for causal discovery algorithms are typically evaluated using\nsimulations and a few select real data examples with known data generating\nmechanisms. However, there does not exist a general guideline for how such\nevaluation studies should be designed, and therefore, comparing results across\ndifferent studies can be difficult. In this article, we propose a common\nevaluation baseline by posing the question: Are we doing better than random\nguessing? For the task of graph skeleton estimation, we derive exact\ndistributional results under random guessing for the expected behavior of a\nrange of typical causal discovery evaluation metrics (including precision and\nrecall). We show that these metrics can achieve very large values under random\nguessing in certain scenarios, and hence warn against using them without also\nreporting negative control results, i.e., performance under random guessing. We\nalso propose an exact test of overall skeleton fit, and showcase its use on a\nreal data application. Finally, we propose a general pipeline for using random\ncontrols beyond the skeleton estimation task, and apply it both in a simulated\nexample and a real data application.\n",
  "subjects": [
    "Statistics/Methodology",
    "Statistics/Machine Learning"
  ],
  "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
  "blobId": "mH2MgL9cc0IId45oPTFuQsEl0xUcvyU8bXoOKF4Da-4",
  "pdfSize": "330475"
}