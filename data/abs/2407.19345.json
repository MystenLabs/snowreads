{"id":"2407.19345","title":"Inference-Time Selective Debiasing","authors":"Gleb Kuzmin, Neemesh Yadav, Ivan Smirnov, Timothy Baldwin, Artem\n  Shelmanov","authorsParsed":[["Kuzmin","Gleb",""],["Yadav","Neemesh",""],["Smirnov","Ivan",""],["Baldwin","Timothy",""],["Shelmanov","Artem",""]],"versions":[{"version":"v1","created":"Sat, 27 Jul 2024 21:56:23 GMT"},{"version":"v2","created":"Wed, 21 Aug 2024 12:22:51 GMT"}],"updateDate":"2024-08-22","timestamp":1722117383000,"abstract":"  We propose selective debiasing -- an inference-time safety mechanism that\naims to increase the overall quality of models in terms of prediction\nperformance and fairness in the situation when re-training a model is\nprohibitive. The method is inspired by selective prediction, where some\npredictions that are considered low quality are discarded at inference time. In\nour approach, we identify the potentially biased model predictions and, instead\nof discarding them, we debias them using LEACE -- a post-processing debiasing\nmethod. To select problematic predictions, we propose a bias quantification\napproach based on KL divergence, which achieves better results than standard UQ\nmethods. Experiments with text classification datasets demonstrate that\nselective debiasing helps to close the performance gap between post-processing\nmethods and at-training and pre-processing debiasing techniques.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"akMTlw7KSxc9Dq_aVm3UR1nl5k7grIuVNvSkt4YPZJQ","pdfSize":"325563"}