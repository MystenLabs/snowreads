{
  "id": "2412.15206",
  "title": "AutoTrust: Benchmarking Trustworthiness in Large Vision Language Models\n  for Autonomous Driving",
  "authors": "Shuo Xing, Hongyuan Hua, Xiangbo Gao, Shenzhe Zhu, Renjie Li, Kexin\n  Tian, Xiaopeng Li, Heng Huang, Tianbao Yang, Zhangyang Wang, Yang Zhou,\n  Huaxiu Yao, Zhengzhong Tu",
  "authorsParsed": [
    [
      "Xing",
      "Shuo",
      ""
    ],
    [
      "Hua",
      "Hongyuan",
      ""
    ],
    [
      "Gao",
      "Xiangbo",
      ""
    ],
    [
      "Zhu",
      "Shenzhe",
      ""
    ],
    [
      "Li",
      "Renjie",
      ""
    ],
    [
      "Tian",
      "Kexin",
      ""
    ],
    [
      "Li",
      "Xiaopeng",
      ""
    ],
    [
      "Huang",
      "Heng",
      ""
    ],
    [
      "Yang",
      "Tianbao",
      ""
    ],
    [
      "Wang",
      "Zhangyang",
      ""
    ],
    [
      "Zhou",
      "Yang",
      ""
    ],
    [
      "Yao",
      "Huaxiu",
      ""
    ],
    [
      "Tu",
      "Zhengzhong",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Thu, 19 Dec 2024 18:59:33 GMT"
    }
  ],
  "updateDate": "2024-12-20",
  "timestamp": 1734634773000,
  "abstract": "  Recent advancements in large vision language models (VLMs) tailored for\nautonomous driving (AD) have shown strong scene understanding and reasoning\ncapabilities, making them undeniable candidates for end-to-end driving systems.\nHowever, limited work exists on studying the trustworthiness of DriveVLMs -- a\ncritical factor that directly impacts public transportation safety. In this\npaper, we introduce AutoTrust, a comprehensive trustworthiness benchmark for\nlarge vision-language models in autonomous driving (DriveVLMs), considering\ndiverse perspectives -- including trustfulness, safety, robustness, privacy,\nand fairness. We constructed the largest visual question-answering dataset for\ninvestigating trustworthiness issues in driving scenarios, comprising over 10k\nunique scenes and 18k queries. We evaluated six publicly available VLMs,\nspanning from generalist to specialist, from open-source to commercial models.\nOur exhaustive evaluations have unveiled previously undiscovered\nvulnerabilities of DriveVLMs to trustworthiness threats. Specifically, we found\nthat the general VLMs like LLaVA-v1.6 and GPT-4o-mini surprisingly outperform\nspecialized models fine-tuned for driving in terms of overall trustworthiness.\nDriveVLMs like DriveLM-Agent are particularly vulnerable to disclosing\nsensitive information. Additionally, both generalist and specialist VLMs remain\nsusceptible to adversarial attacks and struggle to ensure unbiased\ndecision-making across diverse environments and populations. Our findings call\nfor immediate and decisive action to address the trustworthiness of DriveVLMs\n-- an issue of critical importance to public safety and the welfare of all\ncitizens relying on autonomous transportation systems. Our benchmark is\npublicly available at \\url{https://github.com/taco-group/AutoTrust}, and the\nleaderboard is released at \\url{https://taco-group.github.io/AutoTrust/}.\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition",
    "Computer Science/Machine Learning",
    "Computer Science/Robotics"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "a0jck5tIwHcuO4AR5Uw5B1OS00GjGPFkSVX3tLyEWDw",
  "pdfSize": "40742433"
}