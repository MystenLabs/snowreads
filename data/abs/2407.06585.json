{"id":"2407.06585","title":"D-MASTER: Mask Annealed Transformer for Unsupervised Domain Adaptation\n  in Breast Cancer Detection from Mammograms","authors":"Tajamul Ashraf, Krithika Rangarajan, Mohit Gambhir, Richa Gabha,\n  Chetan Arora","authorsParsed":[["Ashraf","Tajamul",""],["Rangarajan","Krithika",""],["Gambhir","Mohit",""],["Gabha","Richa",""],["Arora","Chetan",""]],"versions":[{"version":"v1","created":"Tue, 9 Jul 2024 06:35:17 GMT"}],"updateDate":"2024-07-10","timestamp":1720506917000,"abstract":"  We focus on the problem of Unsupervised Domain Adaptation (\\uda) for breast\ncancer detection from mammograms (BCDM) problem. Recent advancements have shown\nthat masked image modeling serves as a robust pretext task for UDA. However,\nwhen applied to cross-domain BCDM, these techniques struggle with breast\nabnormalities such as masses, asymmetries, and micro-calcifications, in part\ndue to the typically much smaller size of region of interest in comparison to\nnatural images. This often results in more false positives per image (FPI) and\nsignificant noise in pseudo-labels typically used to bootstrap such techniques.\nRecognizing these challenges, we introduce a transformer-based Domain-invariant\nMask Annealed Student Teacher autoencoder (D-MASTER) framework. D-MASTER\nadaptively masks and reconstructs multi-scale feature maps, enhancing the\nmodel's ability to capture reliable target domain features. D-MASTER also\nincludes adaptive confidence refinement to filter pseudo-labels, ensuring only\nhigh-quality detections are considered. We also provide a bounding box\nannotated subset of 1000 mammograms from the RSNA Breast Screening Dataset\n(referred to as RSNA-BSD1K) to support further research in BCDM. We evaluate\nD-MASTER on multiple BCDM datasets acquired from diverse domains. Experimental\nresults show a significant improvement of 9% and 13% in sensitivity at 0.3 FPI\nover state-of-the-art UDA techniques on publicly available benchmark INBreast\nand DDSM datasets respectively. We also report an improvement of 11% and 17% on\nIn-house and RSNA-BSD1K datasets respectively. The source code, pre-trained\nD-MASTER model, along with RSNA-BSD1K dataset annotations is available at\nhttps://dmaster-iitd.github.io/webpage.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"cVFMSmoCJZg9yj8gW_Xvq-pA0kY6GzvkLnEvVIODUIg","pdfSize":"10026686"}