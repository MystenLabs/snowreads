{"id":"2407.15264","title":"LSM-GNN: Large-scale Storage-based Multi-GPU GNN Training by Optimizing\n  Data Transfer Scheme","authors":"Jeongmin Brian Park, Kun Wu, Vikram Sharma Mailthody, Zaid Quresh,\n  Scott Mahlke, Wen-mei Hwu","authorsParsed":[["Park","Jeongmin Brian",""],["Wu","Kun",""],["Mailthody","Vikram Sharma",""],["Quresh","Zaid",""],["Mahlke","Scott",""],["Hwu","Wen-mei",""]],"versions":[{"version":"v1","created":"Sun, 21 Jul 2024 20:41:39 GMT"}],"updateDate":"2024-07-23","timestamp":1721594499000,"abstract":"  Graph Neural Networks (GNNs) are widely used today in recommendation systems,\nfraud detection, and node/link classification tasks. Real world GNNs continue\nto scale in size and require a large memory footprint for storing graphs and\nembeddings that often exceed the memory capacities of the target GPUs used for\ntraining. To address limited memory capacities, traditional GNN training\napproaches use graph partitioning and sharding techniques to scale up across\nmultiple GPUs within a node and/or scale out across multiple nodes. However,\nthis approach suffers from the high computational costs of graph partitioning\nalgorithms and inefficient communication across GPUs.\n  To address these overheads, we propose Large-scale Storage-based Multi-GPU\nGNN framework (LSM-GNN), a storagebased approach to train GNN models that\nutilizes a novel communication layer enabling GPU software caches to function\nas a system-wide shared cache with low overheads.LSM-GNN incorporates a hybrid\neviction policy that intelligently manages cache space by using both static and\ndynamic node information to significantly enhance cache performance.\nFurthermore, we introduce the Preemptive Victim-buffer Prefetcher (PVP), a\nmechanism for prefetching node feature data from a Victim Buffer located in CPU\npinned-memory to further reduce the pressure on the storage devices.\nExperimental results show that despite the lower compute capabilities and\nmemory capacities, LSM-GNN in a single node with two GPUs offers superior\nperformance over two-node-four-GPU Dist-DGL baseline and provides up to 3.75x\nspeed up on end-to-end epoch time while running large-scale GNN training\n","subjects":["Computing Research Repository/Distributed, Parallel, and Cluster Computing","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by-sa/4.0/","blobId":"ofSpgpqpaJrd3Cn1BbGsSgmwH4p47CLKrddEUokO93A","pdfSize":"2374833"}