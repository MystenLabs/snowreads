{"id":"2407.05710","title":"Saltzer & Schroeder for 2030: Security engineering principles in a world\n  of AI","authors":"Nikhil Patnaik, Joseph Hallett, Awais Rashid","authorsParsed":[["Patnaik","Nikhil",""],["Hallett","Joseph",""],["Rashid","Awais",""]],"versions":[{"version":"v1","created":"Mon, 8 Jul 2024 08:10:18 GMT"}],"updateDate":"2024-07-09","timestamp":1720426218000,"abstract":"  Writing secure code is challenging and so it is expected that, following the\nrelease of code-generative AI tools, such as ChatGPT and GitHub Copilot,\ndevelopers will use these tools to perform security tasks and use security\nAPIs. However, is the code generated by ChatGPT secure? How would the everyday\nsoftware or security engineer be able to tell?\n  As we approach the next decade we expect a greater adoption of\ncode-generative AI tools and to see developers use them to write secure code.\nIn preparation for this, we need to ensure security-by-design. In this paper,\nwe look back in time to Saltzer & Schroeder's security design principles as\nthey will need to evolve and adapt to the challenges that come with a world of\nAI-generated code.\n","subjects":["Computing Research Repository/Software Engineering"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"XPs3qwvcItPSTdid8nUElMSYtHB7gWTdUTshFmvRlPU","pdfSize":"149761"}