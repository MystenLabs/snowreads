{"id":"2407.07598","title":"Targeted Augmented Data for Audio Deepfake Detection","authors":"Marcella Astrid, Enjie Ghorbel, Djamila Aouada","authorsParsed":[["Astrid","Marcella",""],["Ghorbel","Enjie",""],["Aouada","Djamila",""]],"versions":[{"version":"v1","created":"Wed, 10 Jul 2024 12:31:53 GMT"}],"updateDate":"2024-07-11","timestamp":1720614713000,"abstract":"  The availability of highly convincing audio deepfake generators highlights\nthe need for designing robust audio deepfake detectors. Existing works often\nrely solely on real and fake data available in the training set, which may lead\nto overfitting, thereby reducing the robustness to unseen manipulations. To\nenhance the generalization capabilities of audio deepfake detectors, we propose\na novel augmentation method for generating audio pseudo-fakes targeting the\ndecision boundary of the model. Inspired by adversarial attacks, we perturb\noriginal real data to synthesize pseudo-fakes with ambiguous prediction\nprobabilities. Comprehensive experiments on two well-known architectures\ndemonstrate that the proposed augmentation contributes to improving the\ngeneralization capabilities of these architectures.\n","subjects":["Computing Research Repository/Sound","Computing Research Repository/Machine Learning","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"6J0xk2lpRrxphMwYBYke0O5wbXUx-06j-EgGSosi2pU","pdfSize":"515224"}