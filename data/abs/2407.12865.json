{"id":"2407.12865","title":"GRAD-SUM: Leveraging Gradient Summarization for Optimal Prompt\n  Engineering","authors":"Derek Austin, Elliott Chartock","authorsParsed":[["Austin","Derek",""],["Chartock","Elliott",""]],"versions":[{"version":"v1","created":"Fri, 12 Jul 2024 19:11:21 GMT"}],"updateDate":"2024-07-19","timestamp":1720811481000,"abstract":"  Prompt engineering for large language models (LLMs) is often a manual\ntime-intensive process that involves generating, evaluating, and refining\nprompts iteratively to ensure high-quality outputs. While there has been work\non automating prompt engineering, the solutions generally are either tuned to\nspecific tasks with given answers or are quite costly. We introduce GRAD-SUM, a\nscalable and flexible method for automatic prompt engineering that builds on\ngradient-based optimization techniques. Our approach incorporates user-defined\ntask descriptions and evaluation criteria, and features a novel gradient\nsummarization module to generalize feedback effectively. Our results\ndemonstrate that GRAD-SUM consistently outperforms existing methods across\nvarious benchmarks, highlighting its versatility and effectiveness in automatic\nprompt optimization.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"byfpenahyvMVgGpya7vhLsZDeMHT2TJS6RzPj-jD6Ik","pdfSize":"549940"}