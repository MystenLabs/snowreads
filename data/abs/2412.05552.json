{"id":"2412.05552","title":"SAME: Learning Generic Language-Guided Visual Navigation with\n  State-Adaptive Mixture of Experts","authors":"Gengze Zhou, Yicong Hong, Zun Wang, Chongyang Zhao, Mohit Bansal, Qi\n  Wu","authorsParsed":[["Zhou","Gengze",""],["Hong","Yicong",""],["Wang","Zun",""],["Zhao","Chongyang",""],["Bansal","Mohit",""],["Wu","Qi",""]],"versions":[{"version":"v1","created":"Sat, 7 Dec 2024 06:12:53 GMT"}],"updateDate":"2024-12-10","timestamp":1733551973000,"abstract":"  The academic field of learning instruction-guided visual navigation can be\ngenerally categorized into high-level category-specific search and low-level\nlanguage-guided navigation, depending on the granularity of language\ninstruction, in which the former emphasizes the exploration process, while the\nlatter concentrates on following detailed textual commands. Despite the\ndiffering focuses of these tasks, the underlying requirements of interpreting\ninstructions, comprehending the surroundings, and inferring action decisions\nremain consistent. This paper consolidates diverse navigation tasks into a\nunified and generic framework -- we investigate the core difficulties of\nsharing general knowledge and exploiting task-specific capabilities in learning\nnavigation and propose a novel State-Adaptive Mixture of Experts (SAME) model\nthat effectively enables an agent to infer decisions based on\ndifferent-granularity language and dynamic observations. Powered by SAME, we\npresent a versatile agent capable of addressing seven navigation tasks\nsimultaneously that outperforms or achieves highly comparable performance to\ntask-specific agents.\n","subjects":["Computer Science/Computer Vision and Pattern Recognition","Computer Science/Artificial Intelligence","Computer Science/Computation and Language","Computer Science/Machine Learning","Computer Science/Robotics"],"license":"http://creativecommons.org/licenses/by-sa/4.0/","blobId":"A5UrEq65C_ZTjtzUxeRIhvAZUCRovke-gKuzdrfBS4o","pdfSize":"2467210"}