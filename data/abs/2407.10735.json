{"id":"2407.10735","title":"Transforming Agency. On the mode of existence of Large Language Models","authors":"Xabier E. Barandiaran and Lola S. Almendros","authorsParsed":[["Barandiaran","Xabier E.",""],["Almendros","Lola S.",""]],"versions":[{"version":"v1","created":"Mon, 15 Jul 2024 14:01:35 GMT"},{"version":"v2","created":"Tue, 16 Jul 2024 09:53:15 GMT"}],"updateDate":"2024-07-17","timestamp":1721052095000,"abstract":"  This paper investigates the ontological characterization of Large Language\nModels (LLMs) like ChatGPT. Between inflationary and deflationary accounts, we\npay special attention to their status as agents. This requires explaining in\ndetail the architecture, processing, and training procedures that enable LLMs\nto display their capacities, and the extensions used to turn LLMs into\nagent-like systems. After a systematic analysis we conclude that a LLM fails to\nmeet necessary and sufficient conditions for autonomous agency in the light of\nembodied theories of mind: the individuality condition (it is not the product\nof its own activity, it is not even directly affected by it), the normativity\ncondition (it does not generate its own norms or goals), and, partially the\ninteractional asymmetry condition (it is not the origin and sustained source of\nits interaction with the environment). If not agents, then ... what are LLMs?\nWe argue that ChatGPT should be characterized as an interlocutor or linguistic\nautomaton, a library-that-talks, devoid of (autonomous) agency, but capable to\nengage performatively on non-purposeful yet purpose-structured and\npurpose-bounded tasks. When interacting with humans, a \"ghostly\" component of\nthe human-machine interaction makes it possible to enact genuine conversational\nexperiences with LLMs. Despite their lack of sensorimotor and biological\nembodiment, LLMs textual embodiment (the training corpus) and resource-hungry\ncomputational embodiment, significantly transform existing forms of human\nagency. Beyond assisted and extended agency, the LLM-human coupling can produce\nmidtended forms of agency, closer to the production of intentional agency than\nto the extended instrumentality of any previous technologies.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language","Computing Research Repository/Computers and Society","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by-sa/4.0/","blobId":"u60Aqul0VUEjPnCIwv8eHSzlMWbKm5Dq4aJY8-kbC8o","pdfSize":"749863"}