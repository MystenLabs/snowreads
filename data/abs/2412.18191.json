{
  "id": "2412.18191",
  "title": "Explaining Speaker and Spoof Embeddings via Probing",
  "authors": "Xuechen Liu, Junichi Yamagishi, Md Sahidullah, Tomi kinnunen",
  "authorsParsed": [
    [
      "Liu",
      "Xuechen",
      ""
    ],
    [
      "Yamagishi",
      "Junichi",
      ""
    ],
    [
      "Sahidullah",
      "Md",
      ""
    ],
    [
      "kinnunen",
      "Tomi",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Tue, 24 Dec 2024 05:56:49 GMT"
    }
  ],
  "updateDate": "2024-12-25",
  "timestamp": 1735019809000,
  "abstract": "  This study investigates the explainability of embedding representations,\nspecifically those used in modern audio spoofing detection systems based on\ndeep neural networks, known as spoof embeddings. Building on established work\nin speaker embedding explainability, we examine how well these spoof embeddings\ncapture speaker-related information. We train simple neural classifiers using\neither speaker or spoof embeddings as input, with speaker-related attributes as\ntarget labels. These attributes are categorized into two groups: metadata-based\ntraits (e.g., gender, age) and acoustic traits (e.g., fundamental frequency,\nspeaking rate). Our experiments on the ASVspoof 2019 LA evaluation set\ndemonstrate that spoof embeddings preserve several key traits, including\ngender, speaking rate, F0, and duration. Further analysis of gender and\nspeaking rate indicates that the spoofing detector partially preserves these\ntraits, potentially to ensure the decision process remains robust against them.\n",
  "subjects": [
    "Computer Science/Sound",
    "Electrical Engineering and Systems Science/Audio and Speech Processing"
  ],
  "license": "http://creativecommons.org/licenses/by-sa/4.0/",
  "blobId": "iGkEW4PmpXSlCDnUsJVhkkDkRa0GecfCcRXmX8I-OY8",
  "pdfSize": "350681"
}