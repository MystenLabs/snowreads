{
  "id": "2412.18274",
  "title": "GenAI Content Detection Task 2: AI vs. Human -- Academic Essay\n  Authenticity Challenge",
  "authors": "Shammur Absar Chowdhury, Hind Almerekhi, Mucahid Kutlu, Kaan Efe\n  Keles, Fatema Ahmad, Tasnim Mohiuddin, George Mikros, Firoj Alam",
  "authorsParsed": [
    [
      "Chowdhury",
      "Shammur Absar",
      ""
    ],
    [
      "Almerekhi",
      "Hind",
      ""
    ],
    [
      "Kutlu",
      "Mucahid",
      ""
    ],
    [
      "Keles",
      "Kaan Efe",
      ""
    ],
    [
      "Ahmad",
      "Fatema",
      ""
    ],
    [
      "Mohiuddin",
      "Tasnim",
      ""
    ],
    [
      "Mikros",
      "George",
      ""
    ],
    [
      "Alam",
      "Firoj",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Tue, 24 Dec 2024 08:33:44 GMT"
    }
  ],
  "updateDate": "2024-12-25",
  "timestamp": 1735029224000,
  "abstract": "  This paper presents a comprehensive overview of the first edition of the\nAcademic Essay Authenticity Challenge, organized as part of the GenAI Content\nDetection shared tasks collocated with COLING 2025. This challenge focuses on\ndetecting machine-generated vs. human-authored essays for academic purposes.\nThe task is defined as follows: \"Given an essay, identify whether it is\ngenerated by a machine or authored by a human.'' The challenge involves two\nlanguages: English and Arabic. During the evaluation phase, 25 teams submitted\nsystems for English and 21 teams for Arabic, reflecting substantial interest in\nthe task. Finally, seven teams submitted system description papers. The\nmajority of submissions utilized fine-tuned transformer-based models, with one\nteam employing Large Language Models (LLMs) such as Llama 2 and Llama 3. This\npaper outlines the task formulation, details the dataset construction process,\nand explains the evaluation framework. Additionally, we present a summary of\nthe approaches adopted by participating teams. Nearly all submitted systems\noutperformed the n-gram-based baseline, with the top-performing systems\nachieving F1 scores exceeding 0.98 for both languages, indicating significant\nprogress in the detection of machine-generated text.\n",
  "subjects": [
    "Computer Science/Computation and Language",
    "Computer Science/Artificial Intelligence"
  ],
  "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
  "blobId": "wVk3TCM9JKsieTvttXbum8qbHHIa82qTbsYLSoC5Lb8",
  "pdfSize": "287577"
}