{"id":"2407.13621","title":"Differential Privacy Mechanisms in Neural Tangent Kernel Regression","authors":"Jiuxiang Gu, Yingyu Liang, Zhizhou Sha, Zhenmei Shi, Zhao Song","authorsParsed":[["Gu","Jiuxiang",""],["Liang","Yingyu",""],["Sha","Zhizhou",""],["Shi","Zhenmei",""],["Song","Zhao",""]],"versions":[{"version":"v1","created":"Thu, 18 Jul 2024 15:57:55 GMT"}],"updateDate":"2024-07-19","timestamp":1721318275000,"abstract":"  Training data privacy is a fundamental problem in modern Artificial\nIntelligence (AI) applications, such as face recognition, recommendation\nsystems, language generation, and many others, as it may contain sensitive user\ninformation related to legal issues. To fundamentally understand how privacy\nmechanisms work in AI applications, we study differential privacy (DP) in the\nNeural Tangent Kernel (NTK) regression setting, where DP is one of the most\npowerful tools for measuring privacy under statistical learning, and NTK is one\nof the most popular analysis frameworks for studying the learning mechanisms of\ndeep neural networks. In our work, we can show provable guarantees for both\ndifferential privacy and test accuracy of our NTK regression. Furthermore, we\nconduct experiments on the basic image classification dataset CIFAR10 to\ndemonstrate that NTK regression can preserve good accuracy under a modest\nprivacy budget, supporting the validity of our analysis. To our knowledge, this\nis the first work to provide a DP guarantee for NTK regression.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Cryptography and Security"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"xrzNrdvEW0HBZnNfE_HOwDftJhZ52iNnL9P-TLopEo4","pdfSize":"730530"}