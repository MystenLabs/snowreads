{
  "id": "2412.04947",
  "title": "C$^2$LEVA: Toward Comprehensive and Contamination-Free Language Model\n  Evaluation",
  "authors": "Yanyang Li, Tin Long Wong, Cheung To Hung, Jianqiao Zhao, Duo Zheng,\n  Ka Wai Liu, Michael R. Lyu, Liwei Wang",
  "authorsParsed": [
    [
      "Li",
      "Yanyang",
      ""
    ],
    [
      "Wong",
      "Tin Long",
      ""
    ],
    [
      "Hung",
      "Cheung To",
      ""
    ],
    [
      "Zhao",
      "Jianqiao",
      ""
    ],
    [
      "Zheng",
      "Duo",
      ""
    ],
    [
      "Liu",
      "Ka Wai",
      ""
    ],
    [
      "Lyu",
      "Michael R.",
      ""
    ],
    [
      "Wang",
      "Liwei",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Fri, 6 Dec 2024 11:07:44 GMT"
    },
    {
      "version": "v2",
      "created": "Sun, 15 Dec 2024 07:31:09 GMT"
    }
  ],
  "updateDate": "2024-12-17",
  "timestamp": 1733483264000,
  "abstract": "  Recent advances in large language models (LLMs) have shown significant\npromise, yet their evaluation raises concerns, particularly regarding data\ncontamination due to the lack of access to proprietary training data. To\naddress this issue, we present C$^2$LEVA, a comprehensive bilingual benchmark\nfeaturing systematic contamination prevention. C$^2$LEVA firstly offers a\nholistic evaluation encompassing 22 tasks, each targeting a specific\napplication or ability of LLMs, and secondly a trustworthy assessment due to\nour contamination-free tasks, ensured by a systematic contamination prevention\nstrategy that fully automates test data renewal and enforces data protection\nduring benchmark data release. Our large-scale evaluation of 15 open-source and\nproprietary models demonstrates the effectiveness of C$^2$LEVA.\n",
  "subjects": [
    "Computer Science/Computation and Language"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "g_01Q87zhXELC6Chgjft-xcVd-vFlyMu61YIbK_X8tc",
  "pdfSize": "1549725"
}