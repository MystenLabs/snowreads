{"id":"2412.10989","title":"MASV: Speaker Verification with Global and Local Context Mamba","authors":"Yang Liu, Li Wan, Yiteng Huang, Ming Sun, Yangyang Shi, Florian Metze","authorsParsed":[["Liu","Yang",""],["Wan","Li",""],["Huang","Yiteng",""],["Sun","Ming",""],["Shi","Yangyang",""],["Metze","Florian",""]],"versions":[{"version":"v1","created":"Sat, 14 Dec 2024 22:44:38 GMT"}],"updateDate":"2024-12-17","timestamp":1734216278000,"abstract":"  Deep learning models like Convolutional Neural Networks and transformers have\nshown impressive capabilities in speech verification, gaining considerable\nattention in the research community. However, CNN-based approaches struggle\nwith modeling long-sequence audio effectively, resulting in suboptimal\nverification performance. On the other hand, transformer-based methods are\noften hindered by high computational demands, limiting their practicality. This\npaper presents the MASV model, a novel architecture that integrates the Mamba\nmodule into the ECAPA-TDNN framework. By introducing the Local Context\nBidirectional Mamba and Tri-Mamba block, the model effectively captures both\nglobal and local context within audio sequences. Experimental results\ndemonstrate that the MASV model substantially enhances verification\nperformance, surpassing existing models in both accuracy and efficiency.\n","subjects":["Electrical Engineering and Systems Science/Audio and Speech Processing","Computer Science/Sound"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"JL3P4ysRmwhHAH0gtQEhMFTOnPUe3NarDdQdDdVTT1I","pdfSize":"385127"}