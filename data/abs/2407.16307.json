{"id":"2407.16307","title":"Multimodal Unlearnable Examples: Protecting Data against Multimodal\n  Contrastive Learning","authors":"Xinwei Liu, Xiaojun Jia, Yuan Xun, Siyuan Liang, Xiaochun Cao","authorsParsed":[["Liu","Xinwei",""],["Jia","Xiaojun",""],["Xun","Yuan",""],["Liang","Siyuan",""],["Cao","Xiaochun",""]],"versions":[{"version":"v1","created":"Tue, 23 Jul 2024 09:00:52 GMT"},{"version":"v2","created":"Fri, 26 Jul 2024 08:39:19 GMT"}],"updateDate":"2024-07-29","timestamp":1721725252000,"abstract":"  Multimodal contrastive learning (MCL) has shown remarkable advances in\nzero-shot classification by learning from millions of image-caption pairs\ncrawled from the Internet. However, this reliance poses privacy risks, as\nhackers may unauthorizedly exploit image-text data for model training,\npotentially including personal and privacy-sensitive information. Recent works\npropose generating unlearnable examples by adding imperceptible perturbations\nto training images to build shortcuts for protection. However, they are\ndesigned for unimodal classification, which remains largely unexplored in MCL.\nWe first explore this context by evaluating the performance of existing methods\non image-caption pairs, and they do not generalize effectively to multimodal\ndata and exhibit limited impact to build shortcuts due to the lack of labels\nand the dispersion of pairs in MCL. In this paper, we propose Multi-step Error\nMinimization (MEM), a novel optimization process for generating multimodal\nunlearnable examples. It extends the Error-Minimization (EM) framework to\noptimize both image noise and an additional text trigger, thereby enlarging the\noptimized space and effectively misleading the model to learn the shortcut\nbetween the noise features and the text trigger. Specifically, we adopt\nprojected gradient descent to solve the noise minimization problem and use\nHotFlip to approximate the gradient and replace words to find the optimal text\ntrigger. Extensive experiments demonstrate the effectiveness of MEM, with\npost-protection retrieval results nearly half of random guessing, and its high\ntransferability across different models. Our code is available on the\nhttps://github.com/thinwayliu/Multimodal-Unlearnable-Examples\n","subjects":["Computing Research Repository/Multimedia","Computing Research Repository/Cryptography and Security"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"q-CU99H2dh8IxqEzU2xP8g2c6KQU9pDxyn171WO04rs","pdfSize":"4356138"}