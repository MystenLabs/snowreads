{
  "id": "2412.08294",
  "title": "EaCO: Resource Sharing Dynamics and Its Impact on Energy Efficiency for\n  DNN Training",
  "authors": "Kawsar Haghshenas and Mona Hashemi",
  "authorsParsed": [
    [
      "Haghshenas",
      "Kawsar",
      ""
    ],
    [
      "Hashemi",
      "Mona",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Wed, 11 Dec 2024 11:09:15 GMT"
    }
  ],
  "updateDate": "2024-12-12",
  "timestamp": 1733915355000,
  "abstract": "  Deep Learning Training (DLT) is a growing workload in shared GPU/CPU clusters\ndue to its high computational cost and increasing number of jobs. This\ncontributes to significant energy consumption in GPU clusters, further\nexacerbated by GPU under-utilization, as shown in production cluster logs.\nAddressing this challenge requires workload scheduling and resource allocation\npolicies for efficient GPU sharing to improve resource and energy efficiency\nwhile maintaining performance. However, previous works primarily optimize for\nperformance, often overlooking or even sacrificing energy efficiency.\n  In this paper, we present EaCO, the first energy-aware scheduling algorithm\ndesigned specifically for DLT workloads in GPU clusters. EaCO leverages\nhardware-supported context switching to enable GPU sharing across multiple DLT\njobs, improving resource and energy utilization. GPU sharing can increase Job\nCompletion Time (JCT) and may lead to contention if not employed carefully. To\naddress this, EaCO integrates experiment and historical-based predictions as\nwell as early-stage observations, ensuring performance expectations are met\nwhile optimizing energy efficiency.\n  We begin by experimentally exploring the dynamics of co-locating DLTs,\ninvestigating its impact on energy and resource utilization. Our results show\nthat co-location improves energy efficiency by up to 44% for individual jobs,\nand increases average GPU utilization to as high as 97%. Additionally,\nevaluations on large-scale clusters using production traces demonstrate that\nEaCO reduces total energy by up to 39% compared to existing algorithms, which\ncomes with a minimal increase in job runtime-less than 3.2% in our simulations.\n",
  "subjects": [
    "Computer Science/Distributed, Parallel, and Cluster Computing"
  ],
  "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
  "blobId": "GQA7SRoSg-COpUPzPuVCZYZOkMVCcqWvpgS8mUBox60",
  "pdfSize": "696568"
}