{
  "id": "2412.11618",
  "title": "EvoLlama: Enhancing LLMs' Understanding of Proteins via Multimodal\n  Structure and Sequence Representations",
  "authors": "Nuowei Liu, Changzhi Sun, Tao Ji, Junfeng Tian, Jianxin Tang, Yuanbin\n  Wu, Man Lan",
  "authorsParsed": [
    [
      "Liu",
      "Nuowei",
      ""
    ],
    [
      "Sun",
      "Changzhi",
      ""
    ],
    [
      "Ji",
      "Tao",
      ""
    ],
    [
      "Tian",
      "Junfeng",
      ""
    ],
    [
      "Tang",
      "Jianxin",
      ""
    ],
    [
      "Wu",
      "Yuanbin",
      ""
    ],
    [
      "Lan",
      "Man",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Mon, 16 Dec 2024 10:01:33 GMT"
    }
  ],
  "updateDate": "2024-12-17",
  "timestamp": 1734343293000,
  "abstract": "  Current Large Language Models (LLMs) for understanding proteins primarily\ntreats amino acid sequences as a text modality. Meanwhile, Protein Language\nModels (PLMs), such as ESM-2, have learned massive sequential evolutionary\nknowledge from the universe of natural protein sequences. Furthermore,\nstructure-based encoders like ProteinMPNN learn the structural information of\nproteins through Graph Neural Networks. However, whether the incorporation of\nprotein encoders can enhance the protein understanding of LLMs has not been\nexplored. To bridge this gap, we propose EvoLlama, a multimodal framework that\nconnects a structure-based encoder, a sequence-based protein encoder and an LLM\nfor protein understanding. EvoLlama consists of a ProteinMPNN structure\nencoder, an ESM-2 protein sequence encoder, a multimodal projector to align\nprotein and text representations and a Llama-3 text decoder. To train EvoLlama,\nwe fine-tune it on protein-oriented instructions and protein property\nprediction datasets verbalized via natural language instruction templates. Our\nexperiments show that EvoLlama's protein understanding capabilities have been\nsignificantly enhanced, outperforming other fine-tuned protein-oriented LLMs in\nzero-shot settings by an average of 1%-8% and surpassing the state-of-the-art\nbaseline with supervised fine-tuning by an average of 6%. On protein property\nprediction datasets, our approach achieves promising results that are\ncompetitive with state-of-the-art task-specific baselines. We will release our\ncode in a future version.\n",
  "subjects": [
    "Computer Science/Machine Learning",
    "Computer Science/Artificial Intelligence"
  ],
  "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
  "blobId": "AmkdgOwvIkr_HFAGzR68C3226KdJIJv64-gmxs155Cs",
  "pdfSize": "2031569"
}