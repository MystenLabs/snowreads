{"id":"2407.06498","title":"Enhancing spatial auditory attention decoding with neuroscience-inspired\n  prototype training","authors":"Zelin Qiu, Jianjun Gu, Dingding Yao and Junfeng Li","authorsParsed":[["Qiu","Zelin",""],["Gu","Jianjun",""],["Yao","Dingding",""],["Li","Junfeng",""]],"versions":[{"version":"v1","created":"Tue, 9 Jul 2024 02:03:19 GMT"}],"updateDate":"2024-07-10","timestamp":1720490599000,"abstract":"  The spatial auditory attention decoding (Sp-AAD) technology aims to determine\nthe direction of auditory attention in multi-talker scenarios via neural\nrecordings. Despite the success of recent Sp-AAD algorithms, their performance\nis hindered by trial-specific features in EEG data. This study aims to improve\ndecoding performance against these features. Studies in neuroscience indicate\nthat spatial auditory attention can be reflected in the topological\ndistribution of EEG energy across different frequency bands. This insight\nmotivates us to propose Prototype Training, a neuroscience-inspired method for\nSp-AAD. This method constructs prototypes with enhanced energy distribution\nrepresentations and reduced trial-specific characteristics, enabling the model\nto better capture auditory attention features. To implement prototype training,\nan EEGWaveNet that employs the wavelet transform of EEG is further proposed.\nDetailed experiments indicate that the EEGWaveNet with prototype training\noutperforms other competitive models on various datasets, and the effectiveness\nof the proposed method is also validated. As a training method independent of\nmodel architecture, prototype training offers new insights into the field of\nSp-AAD.\n","subjects":["Computing Research Repository/Human-Computer Interaction"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"sX7UB5hdRXppo-P1q1CJggECfsx31s3Q_R9qkzrmU5Q","pdfSize":"2102626"}