{
  "id": "2412.06258",
  "title": "Enhanced Multi-Object Tracking Using Pose-based Virtual Markers in 3x3\n  Basketball",
  "authors": "Li Yin, Calvin Yeung, Qingrui Hu, Jun Ichikawa, Hirotsugu Azechi,\n  Susumu Takahashi, Keisuke Fujii",
  "authorsParsed": [
    [
      "Yin",
      "Li",
      ""
    ],
    [
      "Yeung",
      "Calvin",
      ""
    ],
    [
      "Hu",
      "Qingrui",
      ""
    ],
    [
      "Ichikawa",
      "Jun",
      ""
    ],
    [
      "Azechi",
      "Hirotsugu",
      ""
    ],
    [
      "Takahashi",
      "Susumu",
      ""
    ],
    [
      "Fujii",
      "Keisuke",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Mon, 9 Dec 2024 07:16:50 GMT"
    }
  ],
  "updateDate": "2024-12-10",
  "timestamp": 1733728610000,
  "abstract": "  Multi-object tracking (MOT) is crucial for various multi-agent analyses such\nas evaluating team sports tactics and player movements and performance. While\npedestrian tracking has advanced with Tracking-by-Detection MOT, team sports\nlike basketball pose unique challenges. These challenges include players'\nunpredictable movements, frequent close interactions, and visual similarities\nthat complicate pose labeling and lead to significant occlusions, frequent ID\nswitches, and high manual annotation costs. To address these challenges, we\npropose a novel pose-based virtual marker (VM) MOT method for team sports,\nnamed Sports-vmTracking. This method builds on the vmTracking approach\ndeveloped for multi-animal tracking with active learning. First, we constructed\na 3x3 basketball pose dataset for VMs and applied active learning to enhance\nmodel performance in generating VMs. Then, we overlaid the VMs on video to\nidentify players, extract their poses with unique IDs, and convert these into\nbounding boxes for comparison with automated MOT methods. Using our 3x3\nbasketball dataset, we demonstrated that our VM configuration has been highly\neffective, and reduced the need for manual corrections and labeling during pose\nmodel training while maintaining high accuracy. Our approach achieved an\naverage HOTA score of 72.3%, over 10 points higher than other state-of-the-art\nmethods without VM, and resulted in 0 ID switches. Beyond improving performance\nin handling occlusions and minimizing ID switches, our framework could\nsubstantially increase the time and cost efficiency compared to traditional\nmanual annotation.\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition"
  ],
  "license": "http://creativecommons.org/licenses/by-sa/4.0/",
  "blobId": "g70SZiPcn5JVvY30B2n5eUnn7vMdntxxMoB0siRBdJE",
  "pdfSize": "2721499"
}