{
  "id": "2412.20195",
  "title": "Lower bounds on transformers with infinite precision",
  "authors": "Alexander Kozachinskiy",
  "authorsParsed": [
    [
      "Kozachinskiy",
      "Alexander",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Sat, 28 Dec 2024 16:09:25 GMT"
    }
  ],
  "updateDate": "2024-12-31",
  "timestamp": 1735402165000,
  "abstract": "  In this note, we use the VC dimension technique to prove the first lower\nbound against one-layer softmax transformers with infinite precision. We do so\nfor two tasks: function composition, considered by Peng, Narayanan, and\nPapadimitriou, and the SUM$_2$ task, considered by Sanford, Hsu, and Telgarsky.\n",
  "subjects": [
    "Computer Science/Machine Learning",
    "Computer Science/Artificial Intelligence",
    "Statistics/Machine Learning"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "PqrVkfUV7bL2jwFQmSwaDFhguORTh9XLgVtS8s94tT0",
  "pdfSize": "116947"
}