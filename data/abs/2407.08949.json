{"id":"2407.08949","title":"One-Shot Pose-Driving Face Animation Platform","authors":"He Feng, Donglin Di, Yongjia Ma, Wei Chen, Tonghua Su","authorsParsed":[["Feng","He",""],["Di","Donglin",""],["Ma","Yongjia",""],["Chen","Wei",""],["Su","Tonghua",""]],"versions":[{"version":"v1","created":"Fri, 12 Jul 2024 03:09:07 GMT"}],"updateDate":"2024-07-15","timestamp":1720753747000,"abstract":"  The objective of face animation is to generate dynamic and expressive talking\nhead videos from a single reference face, utilizing driving conditions derived\nfrom either video or audio inputs. Current approaches often require fine-tuning\nfor specific identities and frequently fail to produce expressive videos due to\nthe limited effectiveness of Wav2Pose modules. To facilitate the generation of\none-shot and more consecutive talking head videos, we refine an existing\nImage2Video model by integrating a Face Locator and Motion Frame mechanism. We\nsubsequently optimize the model using extensive human face video datasets,\nsignificantly enhancing its ability to produce high-quality and expressive\ntalking head videos. Additionally, we develop a demo platform using the Gradio\nframework, which streamlines the process, enabling users to quickly create\ncustomized talking head videos.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"YrTLxMtXAUTkqTTL4aqre4NjR_Je2nQr7xFbSQuab7I","pdfSize":"543595","objectId":"0x9be122455bed16b817c236a5eb078d8fa41469603320c069c6519932c040c369","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
