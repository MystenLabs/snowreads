{"id":"2407.18449","title":"Towards A Generalizable Pathology Foundation Model via Unified Knowledge\n  Distillation","authors":"Jiabo Ma, Zhengrui Guo, Fengtao Zhou, Yihui Wang, Yingxue Xu, Yu Cai,\n  Zhengjie Zhu, Cheng Jin, Yi Lin, Xinrui Jiang, Anjia Han, Li Liang, Ronald\n  Cheong Kin Chan, Jiguang Wang, Kwang-Ting Cheng, Hao Chen","authorsParsed":[["Ma","Jiabo",""],["Guo","Zhengrui",""],["Zhou","Fengtao",""],["Wang","Yihui",""],["Xu","Yingxue",""],["Cai","Yu",""],["Zhu","Zhengjie",""],["Jin","Cheng",""],["Lin","Yi",""],["Jiang","Xinrui",""],["Han","Anjia",""],["Liang","Li",""],["Chan","Ronald Cheong Kin",""],["Wang","Jiguang",""],["Cheng","Kwang-Ting",""],["Chen","Hao",""]],"versions":[{"version":"v1","created":"Fri, 26 Jul 2024 01:12:54 GMT"},{"version":"v2","created":"Sat, 3 Aug 2024 13:36:24 GMT"}],"updateDate":"2024-08-06","timestamp":1721956374000,"abstract":"  Foundation models pretrained on large-scale datasets are revolutionizing the\nfield of computational pathology (CPath). The generalization ability of\nfoundation models is crucial for the success in various downstream clinical\ntasks. However, current foundation models have only been evaluated on a limited\ntype and number of tasks, leaving their generalization ability and overall\nperformance unclear. To address this gap, we established a most comprehensive\nbenchmark to evaluate the performance of off-the-shelf foundation models across\nsix distinct clinical task types, encompassing a total of 39 specific tasks.\nOur findings reveal that existing foundation models excel at certain task types\nbut struggle to effectively handle the full breadth of clinical tasks. To\nimprove the generalization of pathology foundation models, we propose a unified\nknowledge distillation framework consisting of both expert and self knowledge\ndistillation, where the former allows the model to learn from the knowledge of\nmultiple expert models, while the latter leverages self-distillation to enable\nimage representation learning via local-global alignment. Based on this\nframework, a Generalizable Pathology Foundation Model (GPFM) is pretrained on a\nlarge-scale dataset consisting of 190 million images from around 86,000 public\nH&E whole slides across 34 major tissue types. Evaluated on the established\nbenchmark, GPFM achieves an impressive average rank of 1.36, with 29 tasks\nranked 1st, while the the second-best model, UNI, attains an average rank of\n2.96, with only 4 tasks ranked 1st. The superior generalization of GPFM\ndemonstrates its exceptional modeling capabilities across a wide range of\nclinical tasks, positioning it as a new cornerstone for feature representation\nin CPath.\n","subjects":["Electrical Engineering and Systems Science/Image and Video Processing","Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"v99ActZwgaL1mMgSsDi9i8T7L_QGfHp_dWz4gfA5t5k","pdfSize":"8765241","objectId":"0x9e2b45156687d5081d31e2485ac513c3ce9ec9fdb007b40f1fe8e03acc5d82cc","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
