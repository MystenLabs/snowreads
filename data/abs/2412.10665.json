{"id":"2412.10665","title":"Pretrained Event Classification Model for High Energy Physics Analysis","authors":"Joshua Ho, Benjamin Ryan Roberts, Shuo Han, Haichen Wang","authorsParsed":[["Ho","Joshua",""],["Roberts","Benjamin Ryan",""],["Han","Shuo",""],["Wang","Haichen",""]],"versions":[{"version":"v1","created":"Sat, 14 Dec 2024 03:45:07 GMT"}],"updateDate":"2024-12-17","timestamp":1734147907000,"abstract":"  We introduce a foundation model for event classification in high-energy\nphysics, built on a Graph Neural Network architecture and trained on 120\nmillion simulated proton-proton collision events spanning 12 distinct physics\nprocesses. The model is pretrained to learn a general and robust representation\nof collision data using challenging multiclass and multilabel classification\ntasks. Its performance is evaluated across five event classification tasks,\nwhich include both physics processes used during pretraining and new processes\nnot encountered during pretraining. Fine-tuning the pretrained model\nsignificantly improves classification performance, particularly in scenarios\nwith limited training data, demonstrating gains in both accuracy and\ncomputational efficiency. To investigate the underlying mechanisms behind these\nperformance improvements, we employ a representational similarity evaluation\nframework based on Centered Kernel Alignment. This analysis reveals notable\ndifferences in the learned representations of fine-tuned pretrained models\ncompared to baseline models trained from scratch.\n","subjects":["Physics/High Energy Physics - Phenomenology","Computer Science/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"v7uwTbyUrTKn4UcJHijMsdzXHWLacbZ518mHhSQf80s","pdfSize":"370667"}