{
  "id": "2412.11459",
  "title": "Understanding Knowledge Hijack Mechanism in In-context Learning through\n  Associative Memory",
  "authors": "Shuo Wang, Issei Sato",
  "authorsParsed": [
    [
      "Wang",
      "Shuo",
      ""
    ],
    [
      "Sato",
      "Issei",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Mon, 16 Dec 2024 05:33:05 GMT"
    }
  ],
  "updateDate": "2024-12-17",
  "timestamp": 1734327185000,
  "abstract": "  In-context learning (ICL) enables large language models (LLMs) to adapt to\nnew tasks without fine-tuning by leveraging contextual information provided\nwithin a prompt. However, ICL relies not only on contextual clues but also on\nthe global knowledge acquired during pretraining for the next token prediction.\nAnalyzing this process has been challenging due to the complex computational\ncircuitry of LLMs. This paper investigates the balance between in-context\ninformation and pretrained bigram knowledge in token prediction, focusing on\nthe induction head mechanism, a key component in ICL. Leveraging the fact that\na two-layer transformer can implement the induction head mechanism with\nassociative memories, we theoretically analyze the logits when a two-layer\ntransformer is given prompts generated by a bigram model. In the experiments,\nwe design specific prompts to evaluate whether the outputs of a two-layer\ntransformer align with the theoretical results.\n",
  "subjects": [
    "Computer Science/Computation and Language",
    "Computer Science/Machine Learning"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "f6dTxX5jgaJkSJB4QcDiQEOdP02BmZ8t4lZ-oAoaDas",
  "pdfSize": "2470054"
}