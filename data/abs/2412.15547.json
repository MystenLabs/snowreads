{
  "id": "2412.15547",
  "title": "NGQA: A Nutritional Graph Question Answering Benchmark for Personalized\n  Health-aware Nutritional Reasoning",
  "authors": "Zheyuan Zhang, Yiyang Li, Nhi Ha Lan Le, Zehong Wang, Tianyi Ma,\n  Vincent Galassi, Keerthiram Murugesan, Nuno Moniz, Werner Geyer, Nitesh V\n  Chawla, Chuxu Zhang, Yanfang Ye",
  "authorsParsed": [
    [
      "Zhang",
      "Zheyuan",
      ""
    ],
    [
      "Li",
      "Yiyang",
      ""
    ],
    [
      "Le",
      "Nhi Ha Lan",
      ""
    ],
    [
      "Wang",
      "Zehong",
      ""
    ],
    [
      "Ma",
      "Tianyi",
      ""
    ],
    [
      "Galassi",
      "Vincent",
      ""
    ],
    [
      "Murugesan",
      "Keerthiram",
      ""
    ],
    [
      "Moniz",
      "Nuno",
      ""
    ],
    [
      "Geyer",
      "Werner",
      ""
    ],
    [
      "Chawla",
      "Nitesh V",
      ""
    ],
    [
      "Zhang",
      "Chuxu",
      ""
    ],
    [
      "Ye",
      "Yanfang",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Fri, 20 Dec 2024 04:13:46 GMT"
    }
  ],
  "updateDate": "2024-12-23",
  "timestamp": 1734668026000,
  "abstract": "  Diet plays a critical role in human health, yet tailoring dietary reasoning\nto individual health conditions remains a major challenge. Nutrition Question\nAnswering (QA) has emerged as a popular method for addressing this problem.\nHowever, current research faces two critical limitations. On one hand, the\nabsence of datasets involving user-specific medical information severely limits\n\\textit{personalization}. This challenge is further compounded by the wide\nvariability in individual health needs. On the other hand, while large language\nmodels (LLMs), a popular solution for this task, demonstrate strong reasoning\nabilities, they struggle with the domain-specific complexities of personalized\nhealthy dietary reasoning, and existing benchmarks fail to capture these\nchallenges. To address these gaps, we introduce the Nutritional Graph Question\nAnswering (NGQA) benchmark, the first graph question answering dataset designed\nfor personalized nutritional health reasoning. NGQA leverages data from the\nNational Health and Nutrition Examination Survey (NHANES) and the Food and\nNutrient Database for Dietary Studies (FNDDS) to evaluate whether a food is\nhealthy for a specific user, supported by explanations of the key contributing\nnutrients. The benchmark incorporates three question complexity settings and\nevaluates reasoning across three downstream tasks. Extensive experiments with\nLLM backbones and baseline models demonstrate that the NGQA benchmark\neffectively challenges existing models. In sum, NGQA addresses a critical\nreal-world problem while advancing GraphQA research with a novel\ndomain-specific benchmark.\n",
  "subjects": [
    "Computer Science/Computation and Language",
    "Computer Science/Artificial Intelligence",
    "Computer Science/Machine Learning"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "lkb097JoHD9ZCNw7_kPPs1EndO_7nDrDoRDqvLFvpx8",
  "pdfSize": "2706897"
}