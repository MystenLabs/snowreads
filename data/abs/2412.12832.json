{
  "id": "2412.12832",
  "title": "DSGram: Dynamic Weighting Sub-Metrics for Grammatical Error Correction\n  in the Era of Large Language Models",
  "authors": "Jinxiang Xie, Yilin Li, Xunjian Yin, Xiaojun Wan",
  "authorsParsed": [
    [
      "Xie",
      "Jinxiang",
      ""
    ],
    [
      "Li",
      "Yilin",
      ""
    ],
    [
      "Yin",
      "Xunjian",
      ""
    ],
    [
      "Wan",
      "Xiaojun",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Tue, 17 Dec 2024 11:54:16 GMT"
    }
  ],
  "updateDate": "2024-12-18",
  "timestamp": 1734436456000,
  "abstract": "  Evaluating the performance of Grammatical Error Correction (GEC) models has\nbecome increasingly challenging, as large language model (LLM)-based GEC\nsystems often produce corrections that diverge from provided gold references.\nThis discrepancy undermines the reliability of traditional reference-based\nevaluation metrics. In this study, we propose a novel evaluation framework for\nGEC models, DSGram, integrating Semantic Coherence, Edit Level, and Fluency,\nand utilizing a dynamic weighting mechanism. Our framework employs the Analytic\nHierarchy Process (AHP) in conjunction with large language models to ascertain\nthe relative importance of various evaluation criteria. Additionally, we\ndevelop a dataset incorporating human annotations and LLM-simulated sentences\nto validate our algorithms and fine-tune more cost-effective models.\nExperimental results indicate that our proposed approach enhances the\neffectiveness of GEC model evaluations.\n",
  "subjects": [
    "Computer Science/Computation and Language",
    "Computer Science/Artificial Intelligence"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "a1ljejLRlM33JpWI3Tuo8WiV4zpR9hAImfe8PJMwL50",
  "pdfSize": "585602"
}