{"id":"2412.03123","title":"Robust Multi-bit Text Watermark with LLM-based Paraphrasers","authors":"Xiaojun Xu, Jinghan Jia, Yuanshun Yao, Yang Liu and Hang Li","authorsParsed":[["Xu","Xiaojun",""],["Jia","Jinghan",""],["Yao","Yuanshun",""],["Liu","Yang",""],["Li","Hang",""]],"versions":[{"version":"v1","created":"Wed, 4 Dec 2024 08:43:12 GMT"}],"updateDate":"2024-12-05","timestamp":1733301792000,"abstract":"  We propose an imperceptible multi-bit text watermark embedded by paraphrasing\nwith LLMs. We fine-tune a pair of LLM paraphrasers that are designed to behave\ndifferently so that their paraphrasing difference reflected in the text\nsemantics can be identified by a trained decoder. To embed our multi-bit\nwatermark, we use two paraphrasers alternatively to encode the pre-defined\nbinary code at the sentence level. Then we use a text classifier as the decoder\nto decode each bit of the watermark. Through extensive experiments, we show\nthat our watermarks can achieve over 99.99\\% detection AUC with small (1.1B)\ntext paraphrasers while keeping the semantic information of the original\nsentence. More importantly, our pipeline is robust under word substitution and\nsentence paraphrasing perturbations and generalizes well to\nout-of-distributional data. We also show the stealthiness of our watermark with\nLLM-based evaluation. We open-source the code:\nhttps://github.com/xiaojunxu/multi-bit-text-watermark.\n","subjects":["Computer Science/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"vDoigE_1jUG99NYFiW3DLK59JTsWLNZW0mV-DCXY4jM","pdfSize":"741164"}