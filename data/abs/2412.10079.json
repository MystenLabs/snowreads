{"id":"2412.10079","title":"Lost in the Middle, and In-Between: Enhancing Language Models' Ability\n  to Reason Over Long Contexts in Multi-Hop QA","authors":"George Arthur Baker, Ankush Raut, Sagi Shaier, Lawrence E Hunter,\n  Katharina von der Wense","authorsParsed":[["Baker","George Arthur",""],["Raut","Ankush",""],["Shaier","Sagi",""],["Hunter","Lawrence E",""],["von der Wense","Katharina",""]],"versions":[{"version":"v1","created":"Fri, 13 Dec 2024 12:13:19 GMT"}],"updateDate":"2024-12-16","timestamp":1734091999000,"abstract":"  Previous work finds that recent long-context language models fail to make\nequal use of information in the middle of their inputs, preferring pieces of\ninformation located at the tail ends which creates an undue bias in situations\nwhere we would like models to be equally capable of using different parts of\nthe input. Thus far, the problem has mainly only been considered in settings\nwith single pieces of critical information, leading us to question what happens\nwhen multiple necessary pieces of information are spread out over the inputs.\nHere, we demonstrate the effects of the \"lost in the middle\" problem in the\nmulti-hop question answering setting -- in which multiple reasoning \"hops\" over\ndisconnected documents are required -- and show that performance degrades not\nonly with respect to the distance of information from the edges of the context,\nbut also between pieces of information. Additionally, we experiment with means\nof alleviating the problem by reducing superfluous document contents through\nknowledge graph triple extraction and summarization, and prompting models to\nreason more thoroughly using chain-of-thought prompting.\n","subjects":["Computer Science/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"sFBz64ByjZXGUTuR1Tx-b6YUTWLTdAhvPYg3NybLYQw","pdfSize":"460090"}