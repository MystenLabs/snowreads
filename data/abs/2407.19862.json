{"id":"2407.19862","title":"Wavespace: A Highly Explorable Wavetable Generator","authors":"Hazounne Lee, Kihong Kim, Sungho Lee, Kyogu Lee","authorsParsed":[["Lee","Hazounne",""],["Kim","Kihong",""],["Lee","Sungho",""],["Lee","Kyogu",""]],"versions":[{"version":"v1","created":"Mon, 29 Jul 2024 10:31:42 GMT"}],"updateDate":"2024-07-30","timestamp":1722249102000,"abstract":"  Wavetable synthesis generates quasi-periodic waveforms of musical tones by\ninterpolating a list of waveforms called wavetable. As generative models that\nutilize latent representations offer various methods in waveform generation for\nmusical applications, studies in wavetable generation with invertible\narchitecture have also arisen recently. While they are promising, it is still\nchallenging to generate wavetables with detailed controls in disentangling\nfactors within the latent representation. In response, we present Wavespace, a\nnovel framework for wavetable generation that empowers users with enhanced\nparameter controls. Our model allows users to apply pre-defined conditions to\nthe output wavetables. We employ a variational autoencoder and completely\nfactorize its latent space to different waveform styles. We also condition the\ngenerator with auxiliary timbral and morphological descriptors. This way, users\ncan create unique wavetables by independently manipulating each latent subspace\nand descriptor parameters. Our framework is efficient enough for practical use;\nwe prototyped an oscillator plug-in as a proof of concept for real-time\nintegration of Wavespace within digital audio workspaces (DAWs).\n","subjects":["Computing Research Repository/Sound","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"OApWLNGTIUc6kuxD1SpL3abfny6Do1gk_kq5fsblG_g","pdfSize":"1702705"}