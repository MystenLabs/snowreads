{"id":"2407.14741","title":"Orthogonal Hyper-category Guided Multi-interest Elicitation for\n  Micro-video Matching","authors":"Beibei Li, Beihong Jin, Yisong Yu, Yiyuan Zheng, Jiageng Song, Wei\n  Zhuo, Tao Xiang","authorsParsed":[["Li","Beibei",""],["Jin","Beihong",""],["Yu","Yisong",""],["Zheng","Yiyuan",""],["Song","Jiageng",""],["Zhuo","Wei",""],["Xiang","Tao",""]],"versions":[{"version":"v1","created":"Sat, 20 Jul 2024 03:41:57 GMT"}],"updateDate":"2024-07-23","timestamp":1721446917000,"abstract":"  Watching micro-videos is becoming a part of public daily life. Usually, user\nwatching behaviors are thought to be rooted in their multiple different\ninterests. In the paper, we propose a model named OPAL for micro-video\nmatching, which elicits a user's multiple heterogeneous interests by\ndisentangling multiple soft and hard interest embeddings from user\ninteractions. Moreover, OPAL employs a two-stage training strategy, in which\nthe pre-train is to generate soft interests from historical interactions under\nthe guidance of orthogonal hyper-categories of micro-videos and the fine-tune\nis to reinforce the degree of disentanglement among the interests and learn the\ntemporal evolution of each interest of each user. We conduct extensive\nexperiments on two real-world datasets. The results show that OPAL not only\nreturns diversified micro-videos but also outperforms six state-of-the-art\nmodels in terms of recall and hit rate.\n","subjects":["Computing Research Repository/Information Retrieval","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"R6Eius-4L9MiWEjErM-DbJ0hWUXASfjtgUa_mu4tiMQ","pdfSize":"4118105"}