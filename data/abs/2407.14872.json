{"id":"2407.14872","title":"Adapt2Reward: Adapting Video-Language Models to Generalizable Robotic\n  Rewards via Failure Prompts","authors":"Yanting Yang, Minghao Chen, Qibo Qiu, Jiahao Wu, Wenxiao Wang, Binbin\n  Lin, Ziyu Guan, Xiaofei He","authorsParsed":[["Yang","Yanting",""],["Chen","Minghao",""],["Qiu","Qibo",""],["Wu","Jiahao",""],["Wang","Wenxiao",""],["Lin","Binbin",""],["Guan","Ziyu",""],["He","Xiaofei",""]],"versions":[{"version":"v1","created":"Sat, 20 Jul 2024 13:22:59 GMT"}],"updateDate":"2024-07-23","timestamp":1721481779000,"abstract":"  For a general-purpose robot to operate in reality, executing a broad range of\ninstructions across various environments is imperative. Central to the\nreinforcement learning and planning for such robotic agents is a generalizable\nreward function. Recent advances in vision-language models, such as CLIP, have\nshown remarkable performance in the domain of deep learning, paving the way for\nopen-domain visual recognition. However, collecting data on robots executing\nvarious language instructions across multiple environments remains a challenge.\nThis paper aims to transfer video-language models with robust generalization\ninto a generalizable language-conditioned reward function, only utilizing robot\nvideo data from a minimal amount of tasks in a singular environment. Unlike\ncommon robotic datasets used for training reward functions, human\nvideo-language datasets rarely contain trivial failure videos. To enhance the\nmodel's ability to distinguish between successful and failed robot executions,\nwe cluster failure video features to enable the model to identify patterns\nwithin. For each cluster, we integrate a newly trained failure prompt into the\ntext encoder to represent the corresponding failure mode. Our\nlanguage-conditioned reward function shows outstanding generalization to new\nenvironments and new instructions for robot planning and reinforcement\nlearning.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Robotics"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"jpCK56Bz3frz1obmK0uUz1L_JJY9CCdQnvE24_oR_H8","pdfSize":"3988013"}