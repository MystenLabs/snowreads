{
  "id": "2412.04626",
  "title": "BigDocs: An Open and Permissively-Licensed Dataset for Training\n  Multimodal Models on Document and Code Tasks",
  "authors": "Juan Rodriguez, Xiangru Jian, Siba Smarak Panigrahi, Tianyu Zhang,\n  Aarash Feizi, Abhay Puri, Akshay Kalkunte, Fran\\c{c}ois Savard, Ahmed Masry,\n  Shravan Nayak, Rabiul Awal, Mahsa Massoud, Amirhossein Abaskohi, Zichao Li,\n  Suyuchen Wang, Pierre-Andr\\'e No\\\"el, Mats Leon Richter, Saverio Vadacchino,\n  Shubbam Agarwal, Sanket Biswas, Sara Shanian, Ying Zhang, Noah Bolger, Kurt\n  MacDonald, Simon Fauvel, Sathwik Tejaswi, Srinivas Sunkara, Joao Monteiro,\n  Krishnamurthy DJ Dvijotham, Torsten Scholak, Nicolas Chapados, Sepideh\n  Kharagani, Sean Hughes, M. \\\"Ozsu, Siva Reddy, Marco Pedersoli, Yoshua\n  Bengio, Christopher Pal, Issam Laradji, Spandanna Gella, Perouz Taslakian,\n  David Vazquez, Sai Rajeswar",
  "authorsParsed": [
    [
      "Rodriguez",
      "Juan",
      ""
    ],
    [
      "Jian",
      "Xiangru",
      ""
    ],
    [
      "Panigrahi",
      "Siba Smarak",
      ""
    ],
    [
      "Zhang",
      "Tianyu",
      ""
    ],
    [
      "Feizi",
      "Aarash",
      ""
    ],
    [
      "Puri",
      "Abhay",
      ""
    ],
    [
      "Kalkunte",
      "Akshay",
      ""
    ],
    [
      "Savard",
      "François",
      ""
    ],
    [
      "Masry",
      "Ahmed",
      ""
    ],
    [
      "Nayak",
      "Shravan",
      ""
    ],
    [
      "Awal",
      "Rabiul",
      ""
    ],
    [
      "Massoud",
      "Mahsa",
      ""
    ],
    [
      "Abaskohi",
      "Amirhossein",
      ""
    ],
    [
      "Li",
      "Zichao",
      ""
    ],
    [
      "Wang",
      "Suyuchen",
      ""
    ],
    [
      "Noël",
      "Pierre-André",
      ""
    ],
    [
      "Richter",
      "Mats Leon",
      ""
    ],
    [
      "Vadacchino",
      "Saverio",
      ""
    ],
    [
      "Agarwal",
      "Shubbam",
      ""
    ],
    [
      "Biswas",
      "Sanket",
      ""
    ],
    [
      "Shanian",
      "Sara",
      ""
    ],
    [
      "Zhang",
      "Ying",
      ""
    ],
    [
      "Bolger",
      "Noah",
      ""
    ],
    [
      "MacDonald",
      "Kurt",
      ""
    ],
    [
      "Fauvel",
      "Simon",
      ""
    ],
    [
      "Tejaswi",
      "Sathwik",
      ""
    ],
    [
      "Sunkara",
      "Srinivas",
      ""
    ],
    [
      "Monteiro",
      "Joao",
      ""
    ],
    [
      "Dvijotham",
      "Krishnamurthy DJ",
      ""
    ],
    [
      "Scholak",
      "Torsten",
      ""
    ],
    [
      "Chapados",
      "Nicolas",
      ""
    ],
    [
      "Kharagani",
      "Sepideh",
      ""
    ],
    [
      "Hughes",
      "Sean",
      ""
    ],
    [
      "Özsu",
      "M.",
      ""
    ],
    [
      "Reddy",
      "Siva",
      ""
    ],
    [
      "Pedersoli",
      "Marco",
      ""
    ],
    [
      "Bengio",
      "Yoshua",
      ""
    ],
    [
      "Pal",
      "Christopher",
      ""
    ],
    [
      "Laradji",
      "Issam",
      ""
    ],
    [
      "Gella",
      "Spandanna",
      ""
    ],
    [
      "Taslakian",
      "Perouz",
      ""
    ],
    [
      "Vazquez",
      "David",
      ""
    ],
    [
      "Rajeswar",
      "Sai",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Thu, 5 Dec 2024 21:41:20 GMT"
    }
  ],
  "updateDate": "2024-12-09",
  "timestamp": 1733434880000,
  "abstract": "  Multimodal AI has the potential to significantly enhance\ndocument-understanding tasks, such as processing receipts, understanding\nworkflows, extracting data from documents, and summarizing reports. Code\ngeneration tasks that require long-structured outputs can also be enhanced by\nmultimodality. Despite this, their use in commercial applications is often\nlimited due to limited access to training data and restrictive licensing, which\nhinders open access. To address these limitations, we introduce BigDocs-7.5M, a\nhigh-quality, open-access dataset comprising 7.5 million multimodal documents\nacross 30 tasks. We use an efficient data curation process to ensure our data\nis high-quality and license-permissive. Our process emphasizes accountability,\nresponsibility, and transparency through filtering rules, traceable metadata,\nand careful content analysis. Additionally, we introduce BigDocs-Bench, a\nbenchmark suite with 10 novel tasks where we create datasets that reflect\nreal-world use cases involving reasoning over Graphical User Interfaces (GUI)\nand code generation from images. Our experiments show that training with\nBigDocs-Bench improves average performance up to 25.8% over closed-source\nGPT-4o in document reasoning and structured output tasks such as\nScreenshot2HTML or Image2Latex generation. Finally, human evaluations showed a\npreference for outputs from models trained on BigDocs over GPT-4o. This\nsuggests that BigDocs can help both academics and the open-source community\nutilize and improve AI tools to enhance multimodal capabilities and document\nreasoning. The project is hosted at https://bigdocs.github.io .\n",
  "subjects": [
    "Computer Science/Machine Learning",
    "Computer Science/Computation and Language"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "hPN5_s-RlIyZYdu1ZK9yZrus7BLAF2D0iVhd2ZZaR_o",
  "pdfSize": "20218943"
}