{"id":"2407.00509","title":"Leveraging Ontologies to Document Bias in Data","authors":"Mayra Russo and Maria-Esther Vidal","authorsParsed":[["Russo","Mayra",""],["Vidal","Maria-Esther",""]],"versions":[{"version":"v1","created":"Sat, 29 Jun 2024 18:41:07 GMT"},{"version":"v2","created":"Fri, 9 Aug 2024 18:18:55 GMT"}],"updateDate":"2024-08-13","timestamp":1719686467000,"abstract":"  Machine Learning (ML) systems are capable of reproducing and often amplifying\nundesired biases. This puts emphasis on the importance of operating under\npractices that enable the study and understanding of the intrinsic\ncharacteristics of ML pipelines, prompting the emergence of documentation\nframeworks with the idea that ``any remedy for bias starts with awareness of\nits existence''. However, a resource that can formally describe these pipelines\nin terms of biases detected is still amiss. To fill this gap, we present the\nDoc-BiasO ontology, a resource that aims to create an integrated vocabulary of\nbiases defined in the \\textit{fair-ML} literature and their measures, as well\nas to incorporate relevant terminology and the relationships between them.\nOverseeing ontology engineering best practices, we re-use existing vocabulary\non machine learning and AI, to foster knowledge sharing and interoperability\nbetween the actors concerned with its research, development, regulation, among\nothers. Overall, our main objective is to contribute towards clarifying\nexisting terminology on bias research as it rapidly expands to all areas of AI\nand to improve the interpretation of bias in data and downstream impact.\n","subjects":["Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"UOMEiGSoRfvWd9Q3DFP3mAwEfBKY4IIphJuBgRYRFQ8","pdfSize":"392608"}