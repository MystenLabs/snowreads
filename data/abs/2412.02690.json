{"id":"2412.02690","title":"FoundHand: Large-Scale Domain-Specific Learning for Controllable Hand\n  Image Generation","authors":"Kefan Chen, Chaerin Min, Linguang Zhang, Shreyas Hampali, Cem Keskin,\n  Srinath Sridhar","authorsParsed":[["Chen","Kefan",""],["Min","Chaerin",""],["Zhang","Linguang",""],["Hampali","Shreyas",""],["Keskin","Cem",""],["Sridhar","Srinath",""]],"versions":[{"version":"v1","created":"Tue, 3 Dec 2024 18:58:19 GMT"},{"version":"v2","created":"Wed, 4 Dec 2024 20:51:17 GMT"}],"updateDate":"2024-12-06","timestamp":1733252299000,"abstract":"  Despite remarkable progress in image generation models, generating realistic\nhands remains a persistent challenge due to their complex articulation, varying\nviewpoints, and frequent occlusions. We present FoundHand, a large-scale\ndomain-specific diffusion model for synthesizing single and dual hand images.\nTo train our model, we introduce FoundHand-10M, a large-scale hand dataset with\n2D keypoints and segmentation mask annotations. Our insight is to use 2D hand\nkeypoints as a universal representation that encodes both hand articulation and\ncamera viewpoint. FoundHand learns from image pairs to capture physically\nplausible hand articulations, natively enables precise control through 2D\nkeypoints, and supports appearance control. Our model exhibits core\ncapabilities that include the ability to repose hands, transfer hand\nappearance, and even synthesize novel views. This leads to zero-shot\ncapabilities for fixing malformed hands in previously generated images, or\nsynthesizing hand video sequences. We present extensive experiments and\nevaluations that demonstrate state-of-the-art performance of our method.\n","subjects":["Computer Science/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"ivlYV7UeouJbHhWknXv5_ULrpDHLsHARbru1chwwoFc","pdfSize":"16364655"}