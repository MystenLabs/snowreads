{
  "id": "2412.06191",
  "title": "Event fields: Capturing light fields at high speed, resolution, and\n  dynamic range",
  "authors": "Ziyuan Qu, Zihao Zou, Vivek Boominathan, Praneeth Chakravarthula,\n  Adithya Pediredla",
  "authorsParsed": [
    [
      "Qu",
      "Ziyuan",
      ""
    ],
    [
      "Zou",
      "Zihao",
      ""
    ],
    [
      "Boominathan",
      "Vivek",
      ""
    ],
    [
      "Chakravarthula",
      "Praneeth",
      ""
    ],
    [
      "Pediredla",
      "Adithya",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Mon, 9 Dec 2024 04:02:49 GMT"
    }
  ],
  "updateDate": "2024-12-10",
  "timestamp": 1733716969000,
  "abstract": "  Event cameras, which feature pixels that independently respond to changes in\nbrightness, are becoming increasingly popular in high-speed applications due to\ntheir lower latency, reduced bandwidth requirements, and enhanced dynamic range\ncompared to traditional frame-based cameras. Numerous imaging and vision\ntechniques have leveraged event cameras for high-speed scene understanding by\ncapturing high-framerate, high-dynamic range videos, primarily utilizing the\ntemporal advantages inherent to event cameras. Additionally, imaging and vision\ntechniques have utilized the light field-a complementary dimension to temporal\ninformation-for enhanced scene understanding. In this work, we propose \"Event\nFields\", a new approach that utilizes innovative optical designs for event\ncameras to capture light fields at high speed. We develop the underlying\nmathematical framework for Event Fields and introduce two foundational\nframeworks to capture them practically: spatial multiplexing to capture\ntemporal derivatives and temporal multiplexing to capture angular derivatives.\nTo realize these, we design two complementary optical setups one using a\nkaleidoscope for spatial multiplexing and another using a galvanometer for\ntemporal multiplexing. We evaluate the performance of both designs using a\ncustom-built simulator and real hardware prototypes, showcasing their distinct\nbenefits. Our event fields unlock the full advantages of typical light\nfields-like post-capture refocusing and depth estimation-now supercharged for\nhigh-speed and high-dynamic range scenes. This novel light-sensing paradigm\nopens doors to new applications in photography, robotics, and AR/VR, and\npresents fresh challenges in rendering and machine learning.\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition"
  ],
  "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
  "blobId": "UNOpRF7AU5RLLv6Bra9AXwA3gT8TiNZVyE7eRaDxUZk",
  "pdfSize": "28909410"
}