{"id":"2412.01791","title":"DextrAH-RGB: Visuomotor Policies to Grasp Anything with Dexterous Hands","authors":"Ritvik Singh, Arthur Allshire, Ankur Handa, Nathan Ratliff, Karl Van\n  Wyk","authorsParsed":[["Singh","Ritvik",""],["Allshire","Arthur",""],["Handa","Ankur",""],["Ratliff","Nathan",""],["Van Wyk","Karl",""]],"versions":[{"version":"v1","created":"Wed, 27 Nov 2024 23:15:06 GMT"},{"version":"v2","created":"Sat, 1 Feb 2025 07:58:23 GMT"}],"updateDate":"2025-02-04","timestamp":1732749306000,"abstract":"  One of the most important, yet challenging, skills for a dexterous robot is\ngrasping a diverse range of objects. Much of the prior work has been limited by\nspeed, generality, or reliance on depth maps and object poses. In this paper,\nwe introduce DextrAH-RGB, a system that can perform dexterous arm-hand grasping\nend-to-end from RGB image input. We train a privileged fabric-guided policy\n(FGP) in simulation through reinforcement learning that acts on a geometric\nfabric controller to dexterously grasp a wide variety of objects. We then\ndistill this privileged FGP into a RGB-based FGP strictly in simulation using\nphotorealistic tiled rendering. To our knowledge, this is the first work that\nis able to demonstrate robust sim2real transfer of an end2end RGB-based policy\nfor complex, dynamic, contact-rich tasks such as dexterous grasping.\nDextrAH-RGB is competitive with depth-based dexterous grasping policies, and\ngeneralizes to novel objects with unseen geometry, texture, and lighting\nconditions in the real world. Videos of our system grasping a diverse range of\nunseen objects are available at \\url{https://dextrah-rgb.github.io/}.\n","subjects":["Computer Science/Robotics"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"ek-k2Bo_5B4_hs0m4Pk40ZONmiPnL7TrQGh63rwqE1U","pdfSize":"12388418"}