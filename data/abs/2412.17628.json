{"id":"2412.17628","title":"Editing Implicit and Explicit Representations of Radiance Fields: A\n  Survey","authors":"Arthur Hubert, Gamal Elghazaly, Raphael Frank","authorsParsed":[["Hubert","Arthur",""],["Elghazaly","Gamal",""],["Frank","Raphael",""]],"versions":[{"version":"v1","created":"Mon, 23 Dec 2024 14:59:46 GMT"}],"updateDate":"2024-12-24","timestamp":1734965986000,"abstract":"  Neural Radiance Fields (NeRF) revolutionized novel view synthesis in recent\nyears by offering a new volumetric representation, which is compact and\nprovides high-quality image rendering. However, the methods to edit those\nradiance fields developed slower than the many improvements to other aspects of\nNeRF. With the recent development of alternative radiance field-based\nrepresentations inspired by NeRF as well as the worldwide rise in popularity of\ntext-to-image models, many new opportunities and strategies have emerged to\nprovide radiance field editing. In this paper, we deliver a comprehensive\nsurvey of the different editing methods present in the literature for NeRF and\nother similar radiance field representations. We propose a new taxonomy for\nclassifying existing works based on their editing methodologies, review\npioneering models, reflect on current and potential new applications of\nradiance field editing, and compare state-of-the-art approaches in terms of\nediting options and performance.\n","subjects":["Computer Science/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"EFtTWjUVI6SZM2UMSsjlo_ViYwTt-N7s_WUTZYFV5jA","pdfSize":"922609"}