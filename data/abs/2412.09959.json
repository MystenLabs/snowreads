{
  "id": "2412.09959",
  "title": "Efficient Dataset Distillation via Diffusion-Driven Patch Selection for\n  Improved Generalization",
  "authors": "Xinhao Zhong, Shuoyang Sun, Xulin Gu, Zhaoyang Xu, Yaowei Wang,\n  Jianlong Wu, Bin Chen",
  "authorsParsed": [
    [
      "Zhong",
      "Xinhao",
      ""
    ],
    [
      "Sun",
      "Shuoyang",
      ""
    ],
    [
      "Gu",
      "Xulin",
      ""
    ],
    [
      "Xu",
      "Zhaoyang",
      ""
    ],
    [
      "Wang",
      "Yaowei",
      ""
    ],
    [
      "Wu",
      "Jianlong",
      ""
    ],
    [
      "Chen",
      "Bin",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Fri, 13 Dec 2024 08:34:46 GMT"
    },
    {
      "version": "v2",
      "created": "Wed, 19 Feb 2025 16:11:13 GMT"
    }
  ],
  "updateDate": "2025-02-20",
  "timestamp": 1734078886000,
  "abstract": "  Dataset distillation offers an efficient way to reduce memory and\ncomputational costs by optimizing a smaller dataset with performance comparable\nto the full-scale original. However, for large datasets and complex deep\nnetworks (e.g., ImageNet-1K with ResNet-101), the extensive optimization space\nlimits performance, reducing its practicality. Recent approaches employ\npre-trained diffusion models to generate informative images directly, avoiding\npixel-level optimization and achieving notable results. However, these methods\noften face challenges due to distribution shifts between pre-trained models and\ntarget datasets, along with the need for multiple distillation steps across\nvarying settings. To address these issues, we propose a novel framework\northogonal to existing diffusion-based distillation methods, leveraging\ndiffusion models for selection rather than generation. Our method starts by\npredicting noise generated by the diffusion model based on input images and\ntext prompts (with or without label text), then calculates the corresponding\nloss for each pair. With the loss differences, we identify distinctive regions\nof the original images. Additionally, we perform intra-class clustering and\nranking on selected patches to maintain diversity constraints. This streamlined\nframework enables a single-step distillation process, and extensive experiments\ndemonstrate that our approach outperforms state-of-the-art methods across\nvarious metrics.\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "GEoaQS0N7VlD-qUU7ZLAoxzQgL8yMdJEoRocoiHcN-o",
  "pdfSize": "11606841"
}