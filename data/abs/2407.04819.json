{"id":"2407.04819","title":"RPN: Reconciled Polynomial Network Towards Unifying PGMs, Kernel SVMs,\n  MLP and KAN","authors":"Jiawei Zhang","authorsParsed":[["Zhang","Jiawei",""]],"versions":[{"version":"v1","created":"Fri, 5 Jul 2024 19:00:18 GMT"}],"updateDate":"2024-07-09","timestamp":1720206018000,"abstract":"  In this paper, we will introduce a novel deep model named Reconciled\nPolynomial Network (RPN) for deep function learning. RPN has a very general\narchitecture and can be used to build models with various complexities,\ncapacities, and levels of completeness, which all contribute to the correctness\nof these models. As indicated in the subtitle, RPN can also serve as the\nbackbone to unify different base models into one canonical representation. This\nincludes non-deep models, like probabilistic graphical models (PGMs) - such as\nBayesian network and Markov network - and kernel support vector machines\n(kernel SVMs), as well as deep models like the classic multi-layer perceptron\n(MLP) and the recent Kolmogorov-Arnold network (KAN).\n  Technically, RPN proposes to disentangle the underlying function to be\ninferred into the inner product of a data expansion function and a parameter\nreconciliation function. Together with the remainder function, RPN accurately\napproximates the underlying functions that governs data distributions. The data\nexpansion functions in RPN project data vectors from the input space to a\nhigh-dimensional intermediate space, specified by the expansion functions in\ndefinition. Meanwhile, RPN also introduces the parameter reconciliation\nfunctions to fabricate a small number of parameters into a higher-order\nparameter matrix to address the ``curse of dimensionality'' problem caused by\nthe data expansions. Moreover, the remainder functions provide RPN with\nadditional complementary information to reduce potential approximation errors.\nWe conducted extensive empirical experiments on numerous benchmark datasets\nacross multiple modalities, including continuous function datasets, discrete\nvision and language datasets, and classic tabular datasets, to investigate the\neffectiveness of RPN.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Information Theory","Mathematics/Information Theory","Statistics/Machine Learning"],"license":"http://creativecommons.org/licenses/by-sa/4.0/","blobId":"eN5LoqIzh4DJJiURMrIRcPR9rE-JIcNiRMJ7Yq1_XSM","pdfSize":"13009394"}