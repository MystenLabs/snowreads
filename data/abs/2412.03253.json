{"id":"2412.03253","title":"Alignment at Pre-training! Towards Native Alignment for Arabic LLMs","authors":"Juhao Liang, Zhenyang Cai, Jianqing Zhu, Huang Huang, Kewei Zong, Bang\n  An, Mosen Alharthi, Juncai He, Lian Zhang, Haizhou Li, Benyou Wang, Jinchao\n  Xu","authorsParsed":[["Liang","Juhao",""],["Cai","Zhenyang",""],["Zhu","Jianqing",""],["Huang","Huang",""],["Zong","Kewei",""],["An","Bang",""],["Alharthi","Mosen",""],["He","Juncai",""],["Zhang","Lian",""],["Li","Haizhou",""],["Wang","Benyou",""],["Xu","Jinchao",""]],"versions":[{"version":"v1","created":"Wed, 4 Dec 2024 11:52:03 GMT"}],"updateDate":"2024-12-05","timestamp":1733313123000,"abstract":"  The alignment of large language models (LLMs) is critical for developing\neffective and safe language models. Traditional approaches focus on aligning\nmodels during the instruction tuning or reinforcement learning stages, referred\nto in this paper as `post alignment'. We argue that alignment during the\npre-training phase, which we term `native alignment', warrants investigation.\nNative alignment aims to prevent unaligned content from the beginning, rather\nthan relying on post-hoc processing. This approach leverages extensively\naligned pre-training data to enhance the effectiveness and usability of\npre-trained models. Our study specifically explores the application of native\nalignment in the context of Arabic LLMs. We conduct comprehensive experiments\nand ablation studies to evaluate the impact of native alignment on model\nperformance and alignment stability. Additionally, we release open-source\nArabic LLMs that demonstrate state-of-the-art performance on various\nbenchmarks, providing significant benefits to the Arabic LLM community.\n","subjects":["Computer Science/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"DJvFAZT2IsBW-QiIfV2DWTRmBC-OWcrQC_xqW_zNlCg","pdfSize":"1257610"}