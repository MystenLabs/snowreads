{
  "id": "2412.20185",
  "title": "Pushing the Envelope of Low-Bit LLM via Dynamic Error Compensation",
  "authors": "Yeonhong Park, Jake Hyun, Hojoon Kim, Jae W. Lee",
  "authorsParsed": [
    [
      "Park",
      "Yeonhong",
      ""
    ],
    [
      "Hyun",
      "Jake",
      ""
    ],
    [
      "Kim",
      "Hojoon",
      ""
    ],
    [
      "Lee",
      "Jae W.",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Sat, 28 Dec 2024 15:51:02 GMT"
    }
  ],
  "updateDate": "2024-12-31",
  "timestamp": 1735401062000,
  "abstract": "  Quantization of Large Language Models (LLMs) has recently gained popularity,\nparticularly for on-device settings with limited hardware resources. While\nefficient, quantization inevitably degrades model quality, especially in\naggressive low-bit settings such as 3-bit and 4-bit precision. In this paper,\nwe propose QDEC, an inference scheme that improves the quality of low-bit LLMs\nwhile preserving the key benefits of quantization: GPU memory savings and\ninference latency reduction. QDEC stores the residual matrix -- the difference\nbetween full-precision and quantized weights -- in CPU, and dynamically fetches\nthe residuals for only a small portion of the weights. This portion corresponds\nto the salient channels, marked by activation outliers, with the fetched\nresiduals helping to correct quantization errors in these channels. Salient\nchannels are identified dynamically at each decoding step by analyzing the\ninput activations -- this allows for the adaptation to the dynamic nature of\nactivation distribution, and thus maximizes the effectiveness of error\ncompensation. We demonstrate the effectiveness of QDEC by augmenting\nstate-of-the-art quantization methods. For example, QDEC reduces the perplexity\nof a 3-bit Llama-3-8B-Instruct model from 10.15 to 9.12 -- outperforming its\n3.5-bit counterpart -- while adding less than 0.0003\\% to GPU memory usage and\nincurring only a 1.7\\% inference slowdown on NVIDIA RTX 4050 Mobile GPU. The\ncode will be publicly available soon.\n",
  "subjects": [
    "Computer Science/Machine Learning"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "TuumAvXuCDEDjdYV9b0kNzPdig2KvFgiyUgK3sxF2BQ",
  "pdfSize": "3118733"
}