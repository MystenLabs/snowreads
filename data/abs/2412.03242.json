{"id":"2412.03242","title":"Benchmarking terminology building capabilities of ChatGPT on an\n  English-Russian Fashion Corpus","authors":"Anastasiia Bezobrazova, Miriam Seghiri and Constantin Orasan","authorsParsed":[["Bezobrazova","Anastasiia",""],["Seghiri","Miriam",""],["Orasan","Constantin",""]],"versions":[{"version":"v1","created":"Wed, 4 Dec 2024 11:43:08 GMT"}],"updateDate":"2024-12-05","timestamp":1733312588000,"abstract":"  This paper compares the accuracy of the terms extracted using SketchEngine,\nTBXTools and ChatGPT. In addition, it evaluates the quality of the definitions\nproduced by ChatGPT for these terms. The research is carried out on a\ncomparable corpus of fashion magazines written in English and Russian collected\nfrom the web. A gold standard for the fashion terminology was also developed by\nidentifying web pages that can be harvested automatically and contain\ndefinitions of terms from the fashion domain in English and Russian. This gold\nstandard was used to evaluate the quality of the extracted terms and of the\ndefinitions produced. Our evaluation shows that TBXTools and SketchEngine,\nwhile capable of high recall, suffer from reduced precision as the number of\nterms increases, which affects their overall performance. Conversely, ChatGPT\ndemonstrates superior performance, maintaining or improving precision as more\nterms are considered. Analysis of the definitions produced by ChatGPT for 60\ncommonly used terms in English and Russian shows that ChatGPT maintains a\nreasonable level of accuracy and fidelity across languages, but sometimes the\ndefinitions in both languages miss crucial specifics and include unnecessary\ndeviations. Our research reveals that no single tool excels universally; each\nhas strengths suited to particular aspects of terminology extraction and\napplication.\n","subjects":["Computer Science/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"te-SONJ_b8zt6Wgx3JyLmgMCmiWXYJB_8TP0BqJV2m8","pdfSize":"652808"}