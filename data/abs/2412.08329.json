{
  "id": "2412.08329",
  "title": "BEIR-NL: Zero-shot Information Retrieval Benchmark for the Dutch\n  Language",
  "authors": "Nikolay Banar, Ehsan Lotfi, Walter Daelemans",
  "authorsParsed": [
    [
      "Banar",
      "Nikolay",
      ""
    ],
    [
      "Lotfi",
      "Ehsan",
      ""
    ],
    [
      "Daelemans",
      "Walter",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Wed, 11 Dec 2024 12:15:57 GMT"
    }
  ],
  "updateDate": "2024-12-12",
  "timestamp": 1733919357000,
  "abstract": "  Zero-shot evaluation of information retrieval (IR) models is often performed\nusing BEIR; a large and heterogeneous benchmark composed of multiple datasets,\ncovering different retrieval tasks across various domains. Although BEIR has\nbecome a standard benchmark for the zero-shot setup, its exclusively English\ncontent reduces its utility for underrepresented languages in IR, including\nDutch. To address this limitation and encourage the development of Dutch IR\nmodels, we introduce BEIR-NL by automatically translating the publicly\naccessible BEIR datasets into Dutch. Using BEIR-NL, we evaluated a wide range\nof multilingual dense ranking and reranking models, as well as the lexical BM25\nmethod. Our experiments show that BM25 remains a competitive baseline, and is\nonly outperformed by the larger dense models trained for retrieval. When\ncombined with reranking models, BM25 achieves performance on par with the best\ndense ranking models. In addition, we explored the impact of translation on the\ndata by back-translating a selection of datasets to English, and observed a\nperformance drop for both dense and lexical methods, indicating the limitations\nof translation for creating benchmarks. BEIR-NL is publicly available on the\nHugging Face hub.\n",
  "subjects": [
    "Computer Science/Computation and Language"
  ],
  "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
  "blobId": "3bd89AeKjmGK99J9XdomfKJaS7DxmMK_UtwZC_AEWLE",
  "pdfSize": "268427"
}