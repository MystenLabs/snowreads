{"id":"2412.09993","title":"Large Language Models for Persian $ \\leftrightarrow $ English Idiom\n  Translation","authors":"Sara Rezaeimanesh, Faezeh Hosseini, Yadollah Yaghoobzadeh","authorsParsed":[["Rezaeimanesh","Sara",""],["Hosseini","Faezeh",""],["Yaghoobzadeh","Yadollah",""]],"versions":[{"version":"v1","created":"Fri, 13 Dec 2024 09:29:27 GMT"},{"version":"v2","created":"Fri, 21 Feb 2025 21:45:48 GMT"}],"updateDate":"2025-02-25","timestamp":1734082167000,"abstract":"  Large language models (LLMs) have shown superior capabilities in translating\nfigurative language compared to neural machine translation (NMT) systems.\nHowever, the impact of different prompting methods and LLM-NMT combinations on\nidiom translation has yet to be thoroughly investigated. This paper introduces\ntwo parallel datasets of sentences containing idiomatic expressions for\nPersian$\\rightarrow$English and English$\\rightarrow$Persian translations, with\nPersian idioms sampled from our PersianIdioms resource, a collection of 2,200\nidioms and their meanings, with 700 including usage examples. Using these\ndatasets, we evaluate various open- and closed-source LLMs, NMT models, and\ntheir combinations. Translation quality is assessed through idiom translation\naccuracy and fluency. We also find that automatic evaluation methods like\nLLM-as-a-judge, BLEU, and BERTScore are effective for comparing different\naspects of model performance. Our experiments reveal that Claude-3.5-Sonnet\ndelivers outstanding results in both translation directions. For\nEnglish$\\rightarrow$Persian, combining weaker LLMs with Google Translate\nimproves results, while Persian$\\rightarrow$English translations benefit from\nsingle prompts for simpler models and complex prompts for advanced ones.\n","subjects":["Computer Science/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"RosU1FzdoqZR0h8k1gv7Tlc4oCbeuBEA6MzBtGvS4Cs","pdfSize":"215165"}