{"id":"2407.05213","title":"BadCLM: Backdoor Attack in Clinical Language Models for Electronic\n  Health Records","authors":"Weimin Lyu, Zexin Bi, Fusheng Wang, Chao Chen","authorsParsed":[["Lyu","Weimin",""],["Bi","Zexin",""],["Wang","Fusheng",""],["Chen","Chao",""]],"versions":[{"version":"v1","created":"Sat, 6 Jul 2024 23:56:43 GMT"}],"updateDate":"2024-07-09","timestamp":1720310203000,"abstract":"  The advent of clinical language models integrated into electronic health\nrecords (EHR) for clinical decision support has marked a significant\nadvancement, leveraging the depth of clinical notes for improved\ndecision-making. Despite their success, the potential vulnerabilities of these\nmodels remain largely unexplored. This paper delves into the realm of backdoor\nattacks on clinical language models, introducing an innovative attention-based\nbackdoor attack method, BadCLM (Bad Clinical Language Models). This technique\nclandestinely embeds a backdoor within the models, causing them to produce\nincorrect predictions when a pre-defined trigger is present in inputs, while\nfunctioning accurately otherwise. We demonstrate the efficacy of BadCLM through\nan in-hospital mortality prediction task with MIMIC III dataset, showcasing its\npotential to compromise model integrity. Our findings illuminate a significant\nsecurity risk in clinical decision support systems and pave the way for future\nendeavors in fortifying clinical language models against such vulnerabilities.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"1rSe7PeM_5GcNoHDIF0roxQMB7brRsQmIqVRTfbupi0","pdfSize":"1963574"}