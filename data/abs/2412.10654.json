{"id":"2412.10654","title":"Thinking with Knowledge Graphs: Enhancing LLM Reasoning Through\n  Structured Data","authors":"Xue Wu and Kostas Tsioutsiouliklis","authorsParsed":[["Wu","Xue",""],["Tsioutsiouliklis","Kostas",""]],"versions":[{"version":"v1","created":"Sat, 14 Dec 2024 02:51:47 GMT"}],"updateDate":"2024-12-17","timestamp":1734144707000,"abstract":"  Large Language Models (LLMs) have demonstrated remarkable capabilities in\nnatural language understanding and generation. However, they often struggle\nwith complex reasoning tasks and are prone to hallucination. Recent research\nhas shown promising results in leveraging knowledge graphs (KGs) to enhance LLM\nperformance. KGs provide a structured representation of entities and their\nrelationships, offering a rich source of information that can enhance the\nreasoning capabilities of LLMs. For this work, we have developed different\ntechniques that tightly integrate KG structures and semantics into LLM\nrepresentations. Our results show that we are able to significantly improve the\nperformance of LLMs in complex reasoning scenarios, and ground the reasoning\nprocess with KGs. We are the first to represent KGs with programming language\nand fine-tune pretrained LLMs with KGs. This integration facilitates more\naccurate and interpretable reasoning processes, paving the way for more\nadvanced reasoning capabilities of LLMs.\n","subjects":["Computer Science/Computation and Language","Computer Science/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"p8XcdL9kMvlJoBlFGIRSoVlL2qypPdHs3hZgK5Ny4Gg","pdfSize":"917653"}