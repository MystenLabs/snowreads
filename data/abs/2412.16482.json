{"id":"2412.16482","title":"Learn2Mix: Training Neural Networks Using Adaptive Data Integration","authors":"Shyam Venkatasubramanian, Vahid Tarokh","authorsParsed":[["Venkatasubramanian","Shyam",""],["Tarokh","Vahid",""]],"versions":[{"version":"v1","created":"Sat, 21 Dec 2024 04:40:07 GMT"},{"version":"v2","created":"Thu, 13 Feb 2025 21:25:23 GMT"}],"updateDate":"2025-02-17","timestamp":1734756007000,"abstract":"  Accelerating model convergence within resource-constrained environments is\ncritical to ensure fast and efficient neural network training. This work\npresents learn2mix, a novel training strategy that adaptively adjusts class\nproportions within batches, focusing on classes with higher error rates. Unlike\nclassical training methods that use static class proportions, learn2mix\ncontinually adapts class proportions during training, leading to faster\nconvergence. Empirical evaluations conducted on benchmark datasets show that\nneural networks trained with learn2mix converge faster than those trained with\nexisting approaches, achieving improved results for classification, regression,\nand reconstruction tasks under limited training resources and with imbalanced\nclasses. Our empirical findings are supported by theoretical analysis.\n","subjects":["Computer Science/Machine Learning","Statistics/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"oBSDX-zkDt2aFS9E1NqdufCgT3DNLzXhPka2z9bSu5E","pdfSize":"2044980"}