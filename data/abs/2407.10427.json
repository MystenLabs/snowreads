{"id":"2407.10427","title":"Transformer for Multitemporal Hyperspectral Image Unmixing","authors":"Hang Li, Qiankun Dong, Xueshuo Xie, Xia Xu, Tao Li, Zhenwei Shi","authorsParsed":[["Li","Hang",""],["Dong","Qiankun",""],["Xie","Xueshuo",""],["Xu","Xia",""],["Li","Tao",""],["Shi","Zhenwei",""]],"versions":[{"version":"v1","created":"Mon, 15 Jul 2024 04:02:01 GMT"}],"updateDate":"2024-07-16","timestamp":1721016121000,"abstract":"  Multitemporal hyperspectral image unmixing (MTHU) holds significant\nimportance in monitoring and analyzing the dynamic changes of surface. However,\ncompared to single-temporal unmixing, the multitemporal approach demands\ncomprehensive consideration of information across different phases, rendering\nit a greater challenge. To address this challenge, we propose the Multitemporal\nHyperspectral Image Unmixing Transformer (MUFormer), an end-to-end unsupervised\ndeep learning model. To effectively perform multitemporal hyperspectral image\nunmixing, we introduce two key modules: the Global Awareness Module (GAM) and\nthe Change Enhancement Module (CEM). The Global Awareness Module computes\nself-attention across all phases, facilitating global weight allocation. On the\nother hand, the Change Enhancement Module dynamically learns local temporal\nchanges by comparing endmember changes between adjacent phases. The synergy\nbetween these modules allows for capturing semantic information regarding\nendmember and abundance changes, thereby enhancing the effectiveness of\nmultitemporal hyperspectral image unmixing. We conducted experiments on one\nreal dataset and two synthetic datasets, demonstrating that our model\nsignificantly enhances the effect of multitemporal hyperspectral image\nunmixing.\n","subjects":["Electrical Engineering and Systems Science/Image and Video Processing","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"0A3T5Zny4uL0vlayrPuOvGr0iyXzYXpsq4Cg44i7U18","pdfSize":"8147691"}