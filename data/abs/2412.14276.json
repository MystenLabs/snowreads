{"id":"2412.14276","title":"Fake News Detection: Comparative Evaluation of BERT-like Models and\n  Large Language Models with Generative AI-Annotated Data","authors":"Shaina Raza, Drai Paulen-Patterson and Chen Ding","authorsParsed":[["Raza","Shaina",""],["Paulen-Patterson","Drai",""],["Ding","Chen",""]],"versions":[{"version":"v1","created":"Wed, 18 Dec 2024 19:15:17 GMT"},{"version":"v2","created":"Fri, 20 Dec 2024 12:45:58 GMT"}],"updateDate":"2024-12-23","timestamp":1734549317000,"abstract":"  Fake news poses a significant threat to public opinion and social stability\nin modern society. This study presents a comparative evaluation of BERT-like\nencoder-only models and autoregressive decoder-only large language models\n(LLMs) for fake news detection. We introduce a dataset of news articles labeled\nwith GPT-4 assistance (an AI-labeling method) and verified by human experts to\nensure reliability. Both BERT-like encoder-only models and LLMs were fine-tuned\non this dataset. Additionally, we developed an instruction-tuned LLM approach\nwith majority voting during inference for label generation. Our analysis\nreveals that BERT-like models generally outperform LLMs in classification\ntasks, while LLMs demonstrate superior robustness against text perturbations.\nCompared to weak labels (distant supervision) data, the results show that AI\nlabels with human supervision achieve better classification results. This study\nhighlights the effectiveness of combining AI-based annotation with human\noversight and demonstrates the performance of different families of machine\nlearning models for fake news detection\n","subjects":["Computer Science/Computation and Language","Computer Science/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"gHW0YfOYgbiEr3Oh1HkkU1thSBmoJLpd3zU4iFEY-n4","pdfSize":"1897804"}