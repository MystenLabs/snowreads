{"id":"2407.16616","title":"Implementing engrams from a machine learning perspective: the relevance\n  of a latent space","authors":"J Marco de Lucas","authorsParsed":[["de Lucas","J Marco",""]],"versions":[{"version":"v1","created":"Tue, 23 Jul 2024 16:24:29 GMT"}],"updateDate":"2024-07-24","timestamp":1721751869000,"abstract":"  In our previous work, we proposed that engrams in the brain could be\nbiologically implemented as autoencoders over recurrent neural networks. These\nautoencoders would comprise basic excitatory/inhibitory motifs, with credit\nassignment deriving from a simple homeostatic criterion. This brief note\nexamines the relevance of the latent space in these autoencoders. We consider\nthe relationship between the dimensionality of these autoencoders and the\ncomplexity of the information being encoded. We discuss how observed\ndifferences between species in their connectome could be linked to their\ncognitive capacities. Finally, we link this analysis with a basic but often\noverlooked fact: human cognition is likely limited by our own brain structure.\nHowever, this limitation does not apply to machine learning systems, and we\nshould be aware of the need to learn how to exploit this augmented vision of\nthe nature.\n","subjects":["Computing Research Repository/Neural and Evolutionary Computing","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"df6ApVKboU0GuHgnrji6yKa2tVNkI7LCLJXZ5AYUHe4","pdfSize":"479659","objectId":"0xe3a78871f267fe40c1ecf9459ccec4ccaa828db165d92e29a88b683c402bdfc9","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
