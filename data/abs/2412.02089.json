{"id":"2412.02089","title":"Offline Stochastic Optimization of Black-Box Objective Functions","authors":"Juncheng Dong, Zihao Wu, Hamid Jafarkhani, Ali Pezeshki, Vahid Tarokh","authorsParsed":[["Dong","Juncheng",""],["Wu","Zihao",""],["Jafarkhani","Hamid",""],["Pezeshki","Ali",""],["Tarokh","Vahid",""]],"versions":[{"version":"v1","created":"Tue, 3 Dec 2024 02:20:30 GMT"}],"updateDate":"2024-12-04","timestamp":1733192430000,"abstract":"  Many challenges in science and engineering, such as drug discovery and\ncommunication network design, involve optimizing complex and expensive\nblack-box functions across vast search spaces. Thus, it is essential to\nleverage existing data to avoid costly active queries of these black-box\nfunctions. To this end, while Offline Black-Box Optimization (BBO) is effective\nfor deterministic problems, it may fall short in capturing the stochasticity of\nreal-world scenarios. To address this, we introduce Stochastic Offline BBO\n(SOBBO), which tackles both black-box objectives and uncontrolled\nuncertainties. We propose two solutions: for large-data regimes, a\ndifferentiable surrogate allows for gradient-based optimization, while for\nscarce-data regimes, we directly estimate gradients under conservative field\nconstraints, improving robustness, convergence, and data efficiency. Numerical\nexperiments demonstrate the effectiveness of our approach on both synthetic and\nreal-world tasks.\n","subjects":["Computer Science/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"gqVPWPT8rd76t-zYO5sHzdLN05L12x4ILDWBo1yhZSA","pdfSize":"12599604"}