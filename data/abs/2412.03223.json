{"id":"2412.03223","title":"Linq-Embed-Mistral Technical Report","authors":"Chanyeol Choi, Junseong Kim, Seolhwa Lee, Jihoon Kwon, Sangmo Gu,\n  Yejin Kim, Minkyung Cho, Jy-yong Sohn","authorsParsed":[["Choi","Chanyeol",""],["Kim","Junseong",""],["Lee","Seolhwa",""],["Kwon","Jihoon",""],["Gu","Sangmo",""],["Kim","Yejin",""],["Cho","Minkyung",""],["Sohn","Jy-yong",""]],"versions":[{"version":"v1","created":"Wed, 4 Dec 2024 11:18:32 GMT"}],"updateDate":"2024-12-05","timestamp":1733311112000,"abstract":"  This report explores the enhancement of text retrieval performance using\nadvanced data refinement techniques. We develop\nLinq-Embed-Mistral\\footnote{\\url{https://huggingface.co/Linq-AI-Research/Linq-Embed-Mistral}}\nby building on the E5-mistral and Mistral-7B-v0.1 models, focusing on\nsophisticated data crafting, data filtering, and negative mining methods, which\nare highly tailored to each task, applied to both existing benchmark dataset\nand highly tailored synthetic dataset generated via large language models\n(LLMs). Linq-Embed-Mistral excels in the MTEB benchmarks (as of May 29, 2024),\nachieving an average score of 68.2 across 56 datasets, and ranks 1st among all\nmodels for retrieval tasks on the MTEB leaderboard with a performance score of\n60.2. This performance underscores its superior capability in enhancing search\nprecision and reliability. Our contributions include advanced data refinement\nmethods that significantly improve model performance on benchmark and synthetic\ndatasets, techniques for homogeneous task ordering and mixed task fine-tuning\nto enhance model generalization and stability, and a streamlined evaluation\nprocess using 4-bit precision and a light retrieval evaluation set, which\naccelerates validation without sacrificing accuracy.\n","subjects":["Computer Science/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"Yosf96xvcodterhKbrN25VfkTZZ-ya-CvQraXR3QS9E","pdfSize":"6230784"}