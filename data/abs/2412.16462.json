{
  "id": "2412.16462",
  "title": "Condensed Stein Variational Gradient Descent for Uncertainty\n  Quantification of Neural Networks",
  "authors": "Govinda Anantha Padmanabha, Cosmin Safta, Nikolaos Bouklas, Reese E.\n  Jones",
  "authorsParsed": [
    [
      "Padmanabha",
      "Govinda Anantha",
      ""
    ],
    [
      "Safta",
      "Cosmin",
      ""
    ],
    [
      "Bouklas",
      "Nikolaos",
      ""
    ],
    [
      "Jones",
      "Reese E.",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Sat, 21 Dec 2024 03:28:07 GMT"
    }
  ],
  "updateDate": "2024-12-24",
  "timestamp": 1734751687000,
  "abstract": "  We propose a Stein variational gradient descent method to concurrently\nsparsify, train, and provide uncertainty quantification of a complexly\nparameterized model such as a neural network. It employs a graph reconciliation\nand condensation process to reduce complexity and increase similarity in the\nStein ensemble of parameterizations. Therefore, the proposed condensed Stein\nvariational gradient (cSVGD) method provides uncertainty quantification on\nparameters, not just outputs. Furthermore, the parameter reduction speeds up\nthe convergence of the Stein gradient descent as it reduces the combinatorial\ncomplexity by aligning and differentiating the sensitivity to parameters. These\nproperties are demonstrated with an illustrative example and an application to\na representation problem in solid mechanics.\n",
  "subjects": [
    "Computer Science/Machine Learning",
    "Physics/Computational Physics",
    "Statistics/Machine Learning"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "8BQsUlztMezHuFbRCIargeqfP0hQuJID_hrDJdWYh_s",
  "pdfSize": "1669930"
}