{
  "id": "2412.04594",
  "title": "Learning Symmetries via Weight-Sharing with Doubly Stochastic Tensors",
  "authors": "Putri A. van der Linden, Alejandro Garc\\'ia-Castellanos, Sharvaree\n  Vadgama, Thijs P. Kuipers, Erik J. Bekkers",
  "authorsParsed": [
    [
      "van der Linden",
      "Putri A.",
      ""
    ],
    [
      "Garc√≠a-Castellanos",
      "Alejandro",
      ""
    ],
    [
      "Vadgama",
      "Sharvaree",
      ""
    ],
    [
      "Kuipers",
      "Thijs P.",
      ""
    ],
    [
      "Bekkers",
      "Erik J.",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Thu, 5 Dec 2024 20:15:34 GMT"
    },
    {
      "version": "v2",
      "created": "Tue, 14 Jan 2025 11:03:05 GMT"
    }
  ],
  "updateDate": "2025-01-15",
  "timestamp": 1733429734000,
  "abstract": "  Group equivariance has emerged as a valuable inductive bias in deep learning,\nenhancing generalization, data efficiency, and robustness. Classically, group\nequivariant methods require the groups of interest to be known beforehand,\nwhich may not be realistic for real-world data. Additionally, baking in fixed\ngroup equivariance may impose overly restrictive constraints on model\narchitecture. This highlights the need for methods that can dynamically\ndiscover and apply symmetries as soft constraints. For neural network\narchitectures, equivariance is commonly achieved through group transformations\nof a canonical weight tensor, resulting in weight sharing over a given group\n$G$. In this work, we propose to learn such a weight-sharing scheme by defining\na collection of learnable doubly stochastic matrices that act as soft\npermutation matrices on canonical weight tensors, which can take regular group\nrepresentations as a special case. This yields learnable kernel transformations\nthat are jointly optimized with downstream tasks. We show that when the dataset\nexhibits strong symmetries, the permutation matrices will converge to regular\ngroup representations and our weight-sharing networks effectively become\nregular group convolutions. Additionally, the flexibility of the method enables\nit to effectively pick up on partial symmetries.\n",
  "subjects": [
    "Computer Science/Machine Learning",
    "Computer Science/Computer Vision and Pattern Recognition"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "qEYllYlAF8UMSGKt-qhFs5WOa-rdBQlqMPDm7avQZic",
  "pdfSize": "3244128"
}