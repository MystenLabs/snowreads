{"id":"2407.06779","title":"Using Pretrained Large Language Model with Prompt Engineering to Answer\n  Biomedical Questions","authors":"Wenxin Zhou and Thuy Hang Ngo","authorsParsed":[["Zhou","Wenxin",""],["Ngo","Thuy Hang",""]],"versions":[{"version":"v1","created":"Tue, 9 Jul 2024 11:48:49 GMT"}],"updateDate":"2024-07-10","timestamp":1720525729000,"abstract":"  Our team participated in the BioASQ 2024 Task12b and Synergy tasks to build a\nsystem that can answer biomedical questions by retrieving relevant articles and\nsnippets from the PubMed database and generating exact and ideal answers. We\npropose a two-level information retrieval and question-answering system based\non pre-trained large language models (LLM), focused on LLM prompt engineering\nand response post-processing. We construct prompts with in-context few-shot\nexamples and utilize post-processing techniques like resampling and malformed\nresponse detection. We compare the performance of various pre-trained LLM\nmodels on this challenge, including Mixtral, OpenAI GPT and Llama2. Our\nbest-performing system achieved 0.14 MAP score on document retrieval, 0.05 MAP\nscore on snippet retrieval, 0.96 F1 score for yes/no questions, 0.38 MRR score\nfor factoid questions and 0.50 F1 score for list questions in Task 12b.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"kHmNPm0TTNQEDvwiqFXUF09KFIfhbTSoF_Z7rDnDIsU","pdfSize":"1257563"}