{"id":"2412.08961","title":"Belted and Ensembled Neural Network for Linear and Nonlinear Sufficient\n  Dimension Reduction","authors":"Yin Tang and Bing Li","authorsParsed":[["Tang","Yin",""],["Li","Bing",""]],"versions":[{"version":"v1","created":"Thu, 12 Dec 2024 05:48:34 GMT"}],"updateDate":"2024-12-13","timestamp":1733982514000,"abstract":"  We introduce a unified, flexible, and easy-to-implement framework of\nsufficient dimension reduction that can accommodate both linear and nonlinear\ndimension reduction, and both the conditional distribution and the conditional\nmean as the targets of estimation. This unified framework is achieved by a\nspecially structured neural network -- the Belted and Ensembled Neural Network\n(BENN) -- that consists of a narrow latent layer, which we call the belt, and a\nfamily of transformations of the response, which we call the ensemble. By\nstrategically placing the belt at different layers of the neural network, we\ncan achieve linear or nonlinear sufficient dimension reduction, and by choosing\nthe appropriate transformation families, we can achieve dimension reduction for\nthe conditional distribution or the conditional mean. Moreover, thanks to the\nadvantage of the neural network, the method is very fast to compute, overcoming\na computation bottleneck of the traditional sufficient dimension reduction\nestimators, which involves the inversion of a matrix of dimension either p or\nn. We develop the algorithm and convergence rate of our method, compare it with\nexisting sufficient dimension reduction methods, and apply it to two data\nexamples.\n","subjects":["Statistics/Machine Learning","Computer Science/Machine Learning","Mathematics/Statistics Theory","Statistics/Statistics Theory"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"KfGtt3r1ZVq-ZVB1aDqrEaCB5AWreN1zhSjPJhr3iy4","pdfSize":"1151066"}