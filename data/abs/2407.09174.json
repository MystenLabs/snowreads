{"id":"2407.09174","title":"DART: An Automated End-to-End Object Detection Pipeline with Data\n  Diversification, Open-Vocabulary Bounding Box Annotation, Pseudo-Label\n  Review, and Model Training","authors":"Chen Xin, Andreas Hartel, Enkelejda Kasneci","authorsParsed":[["Xin","Chen",""],["Hartel","Andreas",""],["Kasneci","Enkelejda",""]],"versions":[{"version":"v1","created":"Fri, 12 Jul 2024 11:16:44 GMT"},{"version":"v2","created":"Fri, 26 Jul 2024 11:01:21 GMT"},{"version":"v3","created":"Mon, 29 Jul 2024 09:14:07 GMT"}],"updateDate":"2024-08-27","timestamp":1720783004000,"abstract":"  Accurate real-time object detection is vital across numerous industrial\napplications, from safety monitoring to quality control. Traditional\napproaches, however, are hindered by arduous manual annotation and data\ncollection, struggling to adapt to ever-changing environments and novel target\nobjects. To address these limitations, this paper presents DART, an innovative\nautomated end-to-end pipeline that revolutionizes object detection workflows\nfrom data collection to model evaluation. It eliminates the need for laborious\nhuman labeling and extensive data collection while achieving outstanding\naccuracy across diverse scenarios. DART encompasses four key stages: (1) Data\nDiversification using subject-driven image generation (DreamBooth with SDXL),\n(2) Annotation via open-vocabulary object detection (Grounding DINO) to\ngenerate bounding box and class labels, (3) Review of generated images and\npseudo-labels by large multimodal models (InternVL-1.5 and GPT-4o) to guarantee\ncredibility, and (4) Training of real-time object detectors (YOLOv8 and\nYOLOv10) using the verified data. We apply DART to a self-collected dataset of\nconstruction machines named Liebherr Product, which contains over 15K\nhigh-quality images across 23 categories. The current instantiation of DART\nsignificantly increases average precision (AP) from 0.064 to 0.832. Its modular\ndesign ensures easy exchangeability and extensibility, allowing for future\nalgorithm upgrades, seamless integration of new object categories, and\nadaptability to customized environments without manual labeling and additional\ndata collection. The code and dataset are released at\nhttps://github.com/chen-xin-94/DART.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"OR2_d6dBpI7SkbCfVuDKTp3yowGdq4S5nXL4pvjXGN0","pdfSize":"31359531"}