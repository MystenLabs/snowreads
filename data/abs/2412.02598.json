{
  "id": "2412.02598",
  "title": "Efficient Algorithms for Low Tubal Rank Tensor Approximation with\n  Applications to Image Compression, Super-Resolution and Deep Learning",
  "authors": "Salman Ahmadi-Asl, Naeim Rezaeian, Cesar F. Caiafa, Andre L. F. de\n  Almeidad",
  "authorsParsed": [
    [
      "Ahmadi-Asl",
      "Salman",
      ""
    ],
    [
      "Rezaeian",
      "Naeim",
      ""
    ],
    [
      "Caiafa",
      "Cesar F.",
      ""
    ],
    [
      "de Almeidad",
      "Andre L. F.",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Tue, 3 Dec 2024 17:29:18 GMT"
    }
  ],
  "updateDate": "2024-12-04",
  "timestamp": 1733246958000,
  "abstract": "  In this paper we propose efficient randomized fixed-precision techniques for\nlow tubal rank approximation of tensors. The proposed methods are faster and\nmore efficient than the existing fixed-precision algorithms for approximating\nthe truncated tensor SVD (T-SVD). Besides, there are a few works on randomized\nsingle-pass algorithms for computing low tubal rank approximation of tensors,\nnone of them experimentally reports the robustness of such algorithms for\nlow-rank approximation of real-world data tensors e.g., images and videos. The\ncurrent single-pass algorithms for tensors are generalizations of those\ndeveloped for matrices to tensors. However, the single-pass randomized\nalgorithms for matrices have been recently improved and stabilized. Motivated\nby this progress, in this paper, we also generalize them to the tensor case\nbased on the tubal product (T-product). We conduct extensive simulations to\nstudy the robustness of them compared with the existing single-pass randomized\nalgorithms. In particular, we experimentally found that single-pass algorithms\nwith the sketching parameters of equal sizes usually lead to ill-conditioned\ntensor least-squares problems and inaccurate results. It is experimentally\nshown that our proposed single-pass algorithms are robust in this sense.\nNumerical results demonstrate that under the same conditions (setting the same\nhyper-parameters), our proposed algorithms provide better performance. Three\napplications to image compression, super-resolution problem and deep learning\nare also presented.\n",
  "subjects": [
    "Mathematics/Numerical Analysis",
    "Computer Science/Numerical Analysis"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "CsUG2E9TLq5Rs0HNxK6VZ_3tIvHlJxDD-Mv52M9OkyY",
  "pdfSize": "10815645"
}