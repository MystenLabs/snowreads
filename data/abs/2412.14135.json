{
  "id": "2412.14135",
  "title": "Scaling of Search and Learning: A Roadmap to Reproduce o1 from\n  Reinforcement Learning Perspective",
  "authors": "Zhiyuan Zeng, Qinyuan Cheng, Zhangyue Yin, Bo Wang, Shimin Li, Yunhua\n  Zhou, Qipeng Guo, Xuanjing Huang, Xipeng Qiu",
  "authorsParsed": [
    [
      "Zeng",
      "Zhiyuan",
      ""
    ],
    [
      "Cheng",
      "Qinyuan",
      ""
    ],
    [
      "Yin",
      "Zhangyue",
      ""
    ],
    [
      "Wang",
      "Bo",
      ""
    ],
    [
      "Li",
      "Shimin",
      ""
    ],
    [
      "Zhou",
      "Yunhua",
      ""
    ],
    [
      "Guo",
      "Qipeng",
      ""
    ],
    [
      "Huang",
      "Xuanjing",
      ""
    ],
    [
      "Qiu",
      "Xipeng",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Wed, 18 Dec 2024 18:24:47 GMT"
    }
  ],
  "updateDate": "2024-12-19",
  "timestamp": 1734546287000,
  "abstract": "  OpenAI o1 represents a significant milestone in Artificial Inteiligence,\nwhich achieves expert-level performances on many challanging tasks that require\nstrong reasoning ability.OpenAI has claimed that the main techinique behinds o1\nis the reinforcement learining. Recent works use alternative approaches like\nknowledge distillation to imitate o1's reasoning style, but their effectiveness\nis limited by the capability ceiling of the teacher model. Therefore, this\npaper analyzes the roadmap to achieving o1 from the perspective of\nreinforcement learning, focusing on four key components: policy initialization,\nreward design, search, and learning. Policy initialization enables models to\ndevelop human-like reasoning behaviors, equipping them with the ability to\neffectively explore solution spaces for complex problems. Reward design\nprovides dense and effective signals via reward shaping or reward modeling,\nwhich is the guidance for both search and learning. Search plays a crucial role\nin generating high-quality solutions during both training and testing phases,\nwhich can produce better solutions with more computation. Learning utilizes the\ndata generated by search for improving policy, which can achieve the better\nperformance with more parameters and more searched data. Existing open-source\nprojects that attempt to reproduce o1 can be seem as a part or a variant of our\nroadmap. Collectively, these components underscore how learning and search\ndrive o1's advancement, making meaningful contributions to the development of\nLLM.\n",
  "subjects": [
    "Computer Science/Artificial Intelligence",
    "Computer Science/Machine Learning"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "lOJ_LAw0a-NNqfHSqZhz1n9IyqHfsYDdZpEPmPrtV_Q",
  "pdfSize": "1848930"
}