{"id":"2407.00322","title":"LLM-Generated Natural Language Meets Scaling Laws: New Explorations and\n  Data Augmentation Methods","authors":"Zhenhua Wang, Guang Xu, Ming Ren","authorsParsed":[["Wang","Zhenhua",""],["Xu","Guang",""],["Ren","Ming",""]],"versions":[{"version":"v1","created":"Sat, 29 Jun 2024 05:40:17 GMT"}],"updateDate":"2024-07-02","timestamp":1719639617000,"abstract":"  With the ascent of large language models (LLM), natural language processing\nhas witnessed enhancements, such as LLM-based data augmentation. Nonetheless,\nprior research harbors two primary concerns: firstly, a lack of contemplation\nregarding whether the natural language generated by LLM (LLMNL) truly aligns\nwith human natural language (HNL), a critical foundational question; secondly,\nan oversight that augmented data is randomly generated by LLM, implying that\nnot all data may possess equal training value, that could impede the\nperformance of classifiers. To address these challenges, we introduce the\nscaling laws to intrinsically calculate LLMNL and HNL. Through extensive\nexperiments, we reveal slight deviations (approximately 0.2 Mandelbrot\nexponent) from Mandelbrot's law in LLMNL, underscore a complexity advantage in\nHNL, and supplement an interpretive discussion on language style. This\nestablishes a solid foundation for LLM's expansion. Further, we introduce a\nnovel data augmentation method for few-shot text classification, termed ZGPTDA,\nwhich leverages fuzzy computing mechanisms driven by the conformity to scaling\nlaws to make decisions about GPT-4 augmented data. Extensive experiments,\nconducted in real-world scenarios, confirms the effectiveness (improving F1 of\nBert and RoBerta by 7-10%) and competitiveness (surpassing recent AugGPT and\nGENCO methods by about 2% accuracy on DeBerta) of ZGPTDA. In addition, we\nreveal some interesting insights, e.g., Hilberg's law and Taylor's law can\nimpart more benefits to text classification, etc.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"QO6DrzD3j5T0R79Tg6MgUFZ9xP0fo4q3d0qoAhMJm0I","pdfSize":"1341247"}