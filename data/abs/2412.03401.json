{
  "id": "2412.03401",
  "title": "Benchmarking Pretrained Attention-based Models for Real-Time Recognition\n  in Robot-Assisted Esophagectomy",
  "authors": "Ronald L.P.D. de Jong, Yasmina al Khalil, Tim J.M. Jaspers, Romy C.\n  van Jaarsveld, Gino M. Kuiper, Yiping Li, Richard van Hillegersberg, Jelle P.\n  Ruurda, Marcel Breeuwer, Fons van der Sommen",
  "authorsParsed": [
    [
      "de Jong",
      "Ronald L. P. D.",
      ""
    ],
    [
      "Khalil",
      "Yasmina al",
      ""
    ],
    [
      "Jaspers",
      "Tim J. M.",
      ""
    ],
    [
      "van Jaarsveld",
      "Romy C.",
      ""
    ],
    [
      "Kuiper",
      "Gino M.",
      ""
    ],
    [
      "Li",
      "Yiping",
      ""
    ],
    [
      "van Hillegersberg",
      "Richard",
      ""
    ],
    [
      "Ruurda",
      "Jelle P.",
      ""
    ],
    [
      "Breeuwer",
      "Marcel",
      ""
    ],
    [
      "van der Sommen",
      "Fons",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Wed, 4 Dec 2024 15:32:37 GMT"
    },
    {
      "version": "v2",
      "created": "Wed, 18 Dec 2024 15:47:57 GMT"
    }
  ],
  "updateDate": "2024-12-19",
  "timestamp": 1733326357000,
  "abstract": "  Esophageal cancer is among the most common types of cancer worldwide. It is\ntraditionally treated using open esophagectomy, but in recent years,\nrobot-assisted minimally invasive esophagectomy (RAMIE) has emerged as a\npromising alternative. However, robot-assisted surgery can be challenging for\nnovice surgeons, as they often suffer from a loss of spatial orientation.\nComputer-aided anatomy recognition holds promise for improving surgical\nnavigation, but research in this area remains limited. In this study, we\ndeveloped a comprehensive dataset for semantic segmentation in RAMIE, featuring\nthe largest collection of vital anatomical structures and surgical instruments\nto date. Handling this diverse set of classes presents challenges, including\nclass imbalance and the recognition of complex structures such as nerves. This\nstudy aims to understand the challenges and limitations of current\nstate-of-the-art algorithms on this novel dataset and problem. Therefore, we\nbenchmarked eight real-time deep learning models using two pretraining\ndatasets. We assessed both traditional and attention-based networks,\nhypothesizing that attention-based networks better capture global patterns and\naddress challenges such as occlusion caused by blood or other tissues. The\nbenchmark includes our RAMIE dataset and the publicly available CholecSeg8k\ndataset, enabling a thorough assessment of surgical segmentation tasks. Our\nfindings indicate that pretraining on ADE20k, a dataset for semantic\nsegmentation, is more effective than pretraining on ImageNet. Furthermore,\nattention-based models outperform traditional convolutional neural networks,\nwith SegNeXt and Mask2Former achieving higher Dice scores, and Mask2Former\nadditionally excelling in average symmetric surface distance.\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition",
    "Computer Science/Artificial Intelligence"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "3a7qmmr5R_-UyzbEY7xYiEI8i4aWZOTGNxLlcfjcgQc",
  "pdfSize": "2622882"
}