{
  "id": "2412.17883",
  "title": "In Defence of Post-hoc Explainability",
  "authors": "Nick Oh",
  "authorsParsed": [
    [
      "Oh",
      "Nick",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Mon, 23 Dec 2024 06:22:03 GMT"
    }
  ],
  "updateDate": "2024-12-25",
  "timestamp": 1734934923000,
  "abstract": "  The widespread adoption of machine learning in scientific research has\ncreated a fundamental tension between model opacity and scientific\nunderstanding. Whilst some advocate for intrinsically interpretable models, we\nintroduce Computational Interpretabilism (CI) as a philosophical framework for\npost-hoc interpretability in scientific AI. Drawing parallels with human\nexpertise, where post-hoc rationalisation coexists with reliable performance,\nCI establishes that scientific knowledge emerges through structured model\ninterpretation when properly bounded by empirical validation. Through mediated\nunderstanding and bounded factivity, we demonstrate how post-hoc methods\nachieve epistemically justified insights without requiring complete mechanical\ntransparency, resolving tensions between model complexity and scientific\ncomprehension.\n",
  "subjects": [
    "Computer Science/Machine Learning",
    "Computer Science/Artificial Intelligence"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "D8uwWdIQ3cHAyqP4CgV5bJoq_htet7aQ3ynYrLAsm0s",
  "pdfSize": "337187"
}