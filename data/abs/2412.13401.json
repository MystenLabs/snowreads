{"id":"2412.13401","title":"Zero-Shot Low Light Image Enhancement with Diffusion Prior","authors":"Joshua Cho and Sara Aghajanzadeh and Zhen Zhu and D. A. Forsyth","authorsParsed":[["Cho","Joshua",""],["Aghajanzadeh","Sara",""],["Zhu","Zhen",""],["Forsyth","D. A.",""]],"versions":[{"version":"v1","created":"Wed, 18 Dec 2024 00:31:18 GMT"},{"version":"v2","created":"Sun, 22 Dec 2024 21:29:58 GMT"}],"updateDate":"2024-12-24","timestamp":1734481878000,"abstract":"  Balancing aesthetic quality with fidelity when enhancing images from\nchallenging, degraded sources is a core objective in computational photography.\nIn this paper, we address low light image enhancement (LLIE), a task in which\ndark images often contain limited visible information. Diffusion models, known\nfor their powerful image enhancement capacities, are a natural choice for this\nproblem. However, their deep generative priors can also lead to hallucinations,\nintroducing non-existent elements or substantially altering the visual\nsemantics of the original scene. In this work, we introduce a novel zero-shot\nmethod for controlling and refining the generative behavior of diffusion models\nfor dark-to-light image conversion tasks. Our method demonstrates superior\nperformance over existing state-of-the-art methods in the task of low-light\nimage enhancement, as evidenced by both quantitative metrics and qualitative\nanalysis.\n","subjects":["Computer Science/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"wzY9OLJ6b9ztzuZ0F6VOQZea8opjPoFsMeCj2BadA4s","pdfSize":"26352382"}