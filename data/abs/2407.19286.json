{"id":"2407.19286","title":"On Joint Noise Scaling in Differentially Private Federated Learning with\n  Multiple Local Steps","authors":"Mikko A. Heikkil\\\"a","authorsParsed":[["Heikkil√§","Mikko A.",""]],"versions":[{"version":"v1","created":"Sat, 27 Jul 2024 15:54:58 GMT"}],"updateDate":"2024-07-30","timestamp":1722095698000,"abstract":"  Federated learning is a distributed learning setting where the main aim is to\ntrain machine learning models without having to share raw data but only what is\nrequired for learning. To guarantee training data privacy and high-utility\nmodels, differential privacy and secure aggregation techniques are often\ncombined with federated learning. However, with fine-grained protection\ngranularities the currently existing techniques require the parties to\ncommunicate for each local optimisation step, if they want to fully benefit\nfrom the secure aggregation in terms of the resulting formal privacy\nguarantees. In this paper, we show how a simple new analysis allows the parties\nto perform multiple local optimisation steps while still benefiting from joint\nnoise scaling when using secure aggregation. We show that our analysis enables\nhigher utility models with guaranteed privacy protection under limited number\nof communication rounds.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Cryptography and Security"],"license":"http://creativecommons.org/licenses/by-sa/4.0/","blobId":"AZsynyWiU8nAnSqG0U7TbTDfgRQn0zr41-kMoWcoyx4","pdfSize":"401453"}