{"id":"2412.07199","title":"A Parametric Approach to Adversarial Augmentation for Cross-Domain Iris\n  Presentation Attack Detection","authors":"Debasmita Pal, Redwan Sony, Arun Ross","authorsParsed":[["Pal","Debasmita",""],["Sony","Redwan",""],["Ross","Arun",""]],"versions":[{"version":"v1","created":"Tue, 10 Dec 2024 05:31:34 GMT"}],"updateDate":"2024-12-11","timestamp":1733808694000,"abstract":"  Iris-based biometric systems are vulnerable to presentation attacks (PAs),\nwhere adversaries present physical artifacts (e.g., printed iris images,\ntextured contact lenses) to defeat the system. This has led to the development\nof various presentation attack detection (PAD) algorithms, which typically\nperform well in intra-domain settings. However, they often struggle to\ngeneralize effectively in cross-domain scenarios, where training and testing\nemploy different sensors, PA instruments, and datasets. In this work, we use\nadversarial training samples of both bonafide irides and PAs to improve the\ncross-domain performance of a PAD classifier. The novelty of our approach lies\nin leveraging transformation parameters from classical data augmentation\nschemes (e.g., translation, rotation) to generate adversarial samples. We\nachieve this through a convolutional autoencoder, ADV-GEN, that inputs original\ntraining samples along with a set of geometric and photometric transformations.\nThe transformation parameters act as regularization variables, guiding ADV-GEN\nto generate adversarial samples in a constrained search space. Experiments\nconducted on the LivDet-Iris 2017 database, comprising four datasets, and the\nLivDet-Iris 2020 dataset, demonstrate the efficacy of our proposed method. The\ncode is available at https://github.com/iPRoBe-lab/ADV-GEN-IrisPAD.\n","subjects":["Computer Science/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"-TUkh8PtBeaEn_YFjg9rIgmJc62uzAGH4tDGm1WW_PU","pdfSize":"3835901"}