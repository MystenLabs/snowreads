{
  "id": "2412.12496",
  "title": "Faster Vision Mamba is Rebuilt in Minutes via Merged Token Re-training",
  "authors": "Mingjia Shi, Yuhao Zhou, Ruiji Yu, Zekai Li, Zhiyuan Liang, Xuanlei\n  Zhao, Xiaojiang Peng, Shanmukha Ramakrishna Vedantam, Wangbo Zhao, Kai Wang,\n  Yang You",
  "authorsParsed": [
    [
      "Shi",
      "Mingjia",
      ""
    ],
    [
      "Zhou",
      "Yuhao",
      ""
    ],
    [
      "Yu",
      "Ruiji",
      ""
    ],
    [
      "Li",
      "Zekai",
      ""
    ],
    [
      "Liang",
      "Zhiyuan",
      ""
    ],
    [
      "Zhao",
      "Xuanlei",
      ""
    ],
    [
      "Peng",
      "Xiaojiang",
      ""
    ],
    [
      "Vedantam",
      "Shanmukha Ramakrishna",
      ""
    ],
    [
      "Zhao",
      "Wangbo",
      ""
    ],
    [
      "Wang",
      "Kai",
      ""
    ],
    [
      "You",
      "Yang",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Tue, 17 Dec 2024 02:56:35 GMT"
    },
    {
      "version": "v2",
      "created": "Tue, 4 Feb 2025 11:39:49 GMT"
    }
  ],
  "updateDate": "2025-02-05",
  "timestamp": 1734404195000,
  "abstract": "  Vision Mamba (e.g., Vim) has successfully been integrated into computer\nvision, and token reduction has yielded promising outcomes in Vision\nTransformers (ViTs). However, token reduction performs less effectively on\nVision Mamba compared to ViTs. Pruning informative tokens in Mamba leads to a\nhigh loss of key knowledge and bad performance. This makes it not a good\nsolution for enhancing efficiency in Mamba. Token merging, which preserves more\ntoken information than pruning, has demonstrated commendable performance in\nViTs. Nevertheless, vanilla merging performance decreases as the reduction\nratio increases either, failing to maintain the key knowledge in Mamba.\nRe-training the token-reduced model enhances the performance of Mamba, by\neffectively rebuilding the key knowledge. Empirically, pruned Vims only drop up\nto 0.9% accuracy on ImageNet-1K, recovered by our proposed framework R-MeeTo in\nour main evaluation. We show how simple and effective the fast recovery can be\nachieved at minute-level, in particular, a 35.9% accuracy spike over 3 epochs\nof training on Vim-Ti. Moreover, Vim-Ti/S/B are re-trained within 5/7/17\nminutes, and Vim-S only drop 1.3% with 1.2x (up to 1.5x) speed up in inference.\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition",
    "Computer Science/Artificial Intelligence"
  ],
  "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
  "blobId": "zuADRXri3ZUd3nmAlSJFfJXHA_9s1-9XwJ0Pkeq-1tQ",
  "pdfSize": "8261999"
}