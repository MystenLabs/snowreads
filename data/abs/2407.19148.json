{"id":"2407.19148","title":"Few-Shot Medical Image Segmentation with Large Kernel Attention","authors":"Xiaoxiao Wu, Xiaowei Chen, Zhenguo Gao, Shulei Qu, Yuanyuan Qiu","authorsParsed":[["Wu","Xiaoxiao",""],["Chen","Xiaowei",""],["Gao","Zhenguo",""],["Qu","Shulei",""],["Qiu","Yuanyuan",""]],"versions":[{"version":"v1","created":"Sat, 27 Jul 2024 02:28:30 GMT"}],"updateDate":"2024-07-30","timestamp":1722047310000,"abstract":"  Medical image segmentation has witnessed significant advancements with the\nemergence of deep learning. However, the reliance of most neural network models\non a substantial amount of annotated data remains a challenge for medical image\nsegmentation. To address this issue, few-shot segmentation methods based on\nmeta-learning have been employed. Presently, the methods primarily focus on\naligning the support set and query set to enhance performance, but this\napproach hinders further improvement of the model's effectiveness. In this\npaper, our objective is to propose a few-shot medical segmentation model that\nacquire comprehensive feature representation capabilities, which will boost\nsegmentation accuracy by capturing both local and long-range features. To\nachieve this, we introduce a plug-and-play attention module that dynamically\nenhances both query and support features, thereby improving the\nrepresentativeness of the extracted features. Our model comprises four key\nmodules: a dual-path feature extractor, an attention module, an adaptive\nprototype prediction module, and a multi-scale prediction fusion module.\nSpecifically, the dual-path feature extractor acquires multi-scale features by\nobtaining features of 32{\\times}32 size and 64{\\times}64 size. The attention\nmodule follows the feature extractor and captures local and long-range\ninformation. The adaptive prototype prediction module automatically adjusts the\nanomaly score threshold to predict prototypes, while the multi-scale fusion\nprediction module integrates prediction masks of various scales to produce the\nfinal segmentation result. We conducted experiments on publicly available MRI\ndatasets, namely CHAOS and CMR, and compared our method with other advanced\ntechniques. The results demonstrate that our method achieves state-of-the-art\nperformance.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"RU-h49i_O9sqrAds8d8GrHD3FtUYcHUGffiZ_v3SRG8","pdfSize":"3102891","objectId":"0x7daace1cc0616d634b0af2d9dc5513662bd78a464be3ebd3121b7ff2225b3b4f","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
