{
  "id": "2412.15380",
  "title": "Uncertainty-Guided Cross Attention Ensemble Mean Teacher for\n  Semi-supervised Medical Image Segmentation",
  "authors": "Meghana Karri, Amit Soni Arya, Koushik Biswas, Nicol`o Gennaro, Vedat\n  Cicek, Gorkem Durak, Yuri S. Velichko, Ulas Bagci",
  "authorsParsed": [
    [
      "Karri",
      "Meghana",
      ""
    ],
    [
      "Arya",
      "Amit Soni",
      ""
    ],
    [
      "Biswas",
      "Koushik",
      ""
    ],
    [
      "Gennaro",
      "Nicol`o",
      ""
    ],
    [
      "Cicek",
      "Vedat",
      ""
    ],
    [
      "Durak",
      "Gorkem",
      ""
    ],
    [
      "Velichko",
      "Yuri S.",
      ""
    ],
    [
      "Bagci",
      "Ulas",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Thu, 19 Dec 2024 20:16:58 GMT"
    }
  ],
  "updateDate": "2024-12-23",
  "timestamp": 1734639418000,
  "abstract": "  This work proposes a novel framework, Uncertainty-Guided Cross Attention\nEnsemble Mean Teacher (UG-CEMT), for achieving state-of-the-art performance in\nsemi-supervised medical image segmentation. UG-CEMT leverages the strengths of\nco-training and knowledge distillation by combining a Cross-attention Ensemble\nMean Teacher framework (CEMT) inspired by Vision Transformers (ViT) with\nuncertainty-guided consistency regularization and Sharpness-Aware Minimization\nemphasizing uncertainty. UG-CEMT improves semi-supervised performance while\nmaintaining a consistent network architecture and task setting by fostering\nhigh disparity between sub-networks. Experiments demonstrate significant\nadvantages over existing methods like Mean Teacher and Cross-pseudo Supervision\nin terms of disparity, domain generalization, and medical image segmentation\nperformance. UG-CEMT achieves state-of-the-art results on multi-center prostate\nMRI and cardiac MRI datasets, where object segmentation is particularly\nchallenging. Our results show that using only 10\\% labeled data, UG-CEMT\napproaches the performance of fully supervised methods, demonstrating its\neffectiveness in exploiting unlabeled data for robust medical image\nsegmentation. The code is publicly available at\n\\url{https://github.com/Meghnak13/UG-CEMT}\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "EYHFecVY_MaWzzTKK1fJ42yeNPOWt5bmc5i6XNCASQY",
  "pdfSize": "2528654"
}