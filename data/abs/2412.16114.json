{"id":"2412.16114","title":"The Content Moderator's Dilemma: Removal of Toxic Content and\n  Distortions to Online Discourse","authors":"Mahyar Habibi, Dirk Hovy and Carlo Schwarz","authorsParsed":[["Habibi","Mahyar",""],["Hovy","Dirk",""],["Schwarz","Carlo",""]],"versions":[{"version":"v1","created":"Fri, 20 Dec 2024 18:00:05 GMT"}],"updateDate":"2024-12-23","timestamp":1734717605000,"abstract":"  There is an ongoing debate about how to moderate toxic speech on social media\nand how content moderation affects online discourse. We propose and validate a\nmethodology for measuring the content-moderation-induced distortions in online\ndiscourse using text embeddings from computational linguistics. We test our\nmeasure on a representative dataset of 5 million US political Tweets and find\nthat removing toxic Tweets distorts online content. This finding is consistent\nacross different embedding models, toxicity metrics, and samples. Importantly,\nwe demonstrate that content-moderation-induced distortions are not caused by\nthe toxic language. Instead, we show that, as a side effect, content moderation\nshifts the mean and variance of the embedding space, distorting the topic\ncomposition of online content. Finally, we propose an alternative approach to\ncontent moderation that uses generative Large Language Models to rephrase toxic\nTweets to preserve their salvageable content rather than removing them\nentirely. We demonstrate that this rephrasing strategy reduces toxicity while\nminimizing distortions in online content.\n","subjects":["Computer Science/Social and Information Networks"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"Y32mXL1RB6luyuPzKlIR6dRNgsSuiMusYV9E2s269yw","pdfSize":"1472012"}