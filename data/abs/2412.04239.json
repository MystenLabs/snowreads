{"id":"2412.04239","title":"On Deep-Learning-Based Closures for Algebraic Surrogate Models of\n  Turbulent Flows","authors":"Benet Eiximeno, Marcial Sanch\\'is-Agudo, Arnau Mir\\'o, Ivette\n  Rodr\\'iguez, Ricardo Vinuesa, Oriol Lehmkuhl","authorsParsed":[["Eiximeno","Benet",""],["Sanchís-Agudo","Marcial",""],["Miró","Arnau",""],["Rodríguez","Ivette",""],["Vinuesa","Ricardo",""],["Lehmkuhl","Oriol",""]],"versions":[{"version":"v1","created":"Thu, 5 Dec 2024 15:21:10 GMT"}],"updateDate":"2024-12-06","timestamp":1733412070000,"abstract":"  A deep-learning-based closure model to address energy loss in low-dimensional\nsurrogate models based on proper-orthogonal-decomposition (POD) modes is\nintroduced. Using a transformer-encoder block with easy-attention mechanism,\nthe model predicts the spatial probability density function of fluctuations not\ncaptured by the truncated POD modes. The methodology is demonstrated on the\nwake of the Windsor body at yaw angles of [2.5,5,7.5,10,12.5], with 7.5 as a\ntest case. Key coherent modes are identified by clustering them based on\ndominant frequency dynamics using Hotelling T2 on the spectral properties of\ntemporal coefficients. These coherent modes account for nearly 60% of the total\nenergy while comprising less than 10% of all modes. A common POD basis is\ncreated by concatenating coherent modes from training angles and\northonormalizing the set, reducing the basis vectors from 142 to 90 without\nlosing information. Transformers with different size on the attention layer,\n(64, 128 and 256), are trained to model the missing fluctuations. Larger\nattention sizes always improve predictions for the training set, but the\ntransformer with an attention layer of size 256 overshoots the fluctuations\npredictions in the test set because they have lower intensity than in the\ntraining cases. Adding the predicted fluctuations closes the energy gap between\nthe reconstruction and the original flow field, improving predictions for\nenergy, root-mean-square velocity fluctuations, and instantaneous flow fields.\nThe deepest architecture reduces mean energy error from 37% to 12% and\ndecreases the Kullback--Leibler divergence of velocity distributions from\nKL=0.2 to below KL=0.026.\n","subjects":["Physics/Fluid Dynamics"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"mnq6seOahdz6kX6L23X99nBr9eCOg7mPvOg5NudrZQo","pdfSize":"6234522"}