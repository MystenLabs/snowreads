{
  "id": "2412.05315",
  "title": "Text Is Not All You Need: Multimodal Prompting Helps LLMs Understand\n  Humor",
  "authors": "Ashwin Baluja",
  "authorsParsed": [
    [
      "Baluja",
      "Ashwin",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Sun, 1 Dec 2024 06:49:31 GMT"
    }
  ],
  "updateDate": "2024-12-10",
  "timestamp": 1733035771000,
  "abstract": "  While Large Language Models (LLMs) have demonstrated impressive natural\nlanguage understanding capabilities across various text-based tasks,\nunderstanding humor has remained a persistent challenge. Humor is frequently\nmultimodal, relying on phonetic ambiguity, rhythm and timing to convey meaning.\nIn this study, we explore a simple multimodal prompting approach to humor\nunderstanding and explanation. We present an LLM with both the text and the\nspoken form of a joke, generated using an off-the-shelf text-to-speech (TTS)\nsystem. Using multimodal cues improves the explanations of humor compared to\ntextual prompts across all tested datasets.\n",
  "subjects": [
    "Computer Science/Computation and Language",
    "Computer Science/Computers and Society"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "pgXgEnLtD0rjJrAKgTy8nzTzFOyDIu_9Zm3RhQ7sPnI",
  "pdfSize": "349126"
}