{"id":"2412.11006","title":"Entropy-Regularized Process Reward Model","authors":"Hanning Zhang, Pengcheng Wang, Shizhe Diao, Yong Lin, Rui Pan, Hanze\n  Dong, Dylan Zhang, Pavlo Molchanov, Tong Zhang","authorsParsed":[["Zhang","Hanning",""],["Wang","Pengcheng",""],["Diao","Shizhe",""],["Lin","Yong",""],["Pan","Rui",""],["Dong","Hanze",""],["Zhang","Dylan",""],["Molchanov","Pavlo",""],["Zhang","Tong",""]],"versions":[{"version":"v1","created":"Sun, 15 Dec 2024 01:09:23 GMT"}],"updateDate":"2024-12-17","timestamp":1734224963000,"abstract":"  Large language models (LLMs) have shown promise in performing complex\nmulti-step reasoning, yet they continue to struggle with mathematical\nreasoning, often making systematic errors. A promising solution is\nreinforcement learning (RL) guided by reward models, particularly those\nfocusing on process rewards, which score each intermediate step rather than\nsolely evaluating the final outcome. This approach is more effective at guiding\npolicy models towards correct reasoning trajectories. In this work, we propose\nan entropy-regularized process reward model (ER-PRM) that integrates\nKL-regularized Markov Decision Processes (MDP) to balance policy optimization\nwith the need to prevent the policy from shifting too far from its initial\ndistribution. We derive a novel reward construction method based on the\ntheoretical results. Our theoretical analysis shows that we could derive the\noptimal reward model from the initial policy sampling. Our empirical\nexperiments on the MATH and GSM8K benchmarks demonstrate that ER-PRM\nconsistently outperforms existing process reward models, achieving 1%\nimprovement on GSM8K and 2-3% improvement on MATH under best-of-N evaluation,\nand more than 1% improvement under RLHF. These results highlight the efficacy\nof entropy-regularization in enhancing LLMs' reasoning capabilities.\n","subjects":["Computer Science/Machine Learning","Computer Science/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"OtQ5PxBxAwSc3p6piopDoyCPrEEIEyc8HWiEJFCXJP0","pdfSize":"2011265"}