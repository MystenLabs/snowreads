{"id":"2412.16592","title":"Leveraging Contrastive Learning for Semantic Segmentation with\n  Consistent Labels Across Varying Appearances","authors":"Javier Montalvo, Roberto Alcover-Couso, Pablo Carballeira, \\'Alvaro\n  Garc\\'ia-Mart\\'in, Juan C. SanMiguel, Marcos Escudero-Vi\\~nolo","authorsParsed":[["Montalvo","Javier",""],["Alcover-Couso","Roberto",""],["Carballeira","Pablo",""],["García-Martín","Álvaro",""],["SanMiguel","Juan C.",""],["Escudero-Viñolo","Marcos",""]],"versions":[{"version":"v1","created":"Sat, 21 Dec 2024 11:50:07 GMT"}],"updateDate":"2024-12-24","timestamp":1734781807000,"abstract":"  This paper introduces a novel synthetic dataset that captures urban scenes\nunder a variety of weather conditions, providing pixel-perfect,\nground-truth-aligned images to facilitate effective feature alignment across\ndomains. Additionally, we propose a method for domain adaptation and\ngeneralization that takes advantage of the multiple versions of each scene,\nenforcing feature consistency across different weather scenarios. Our\nexperimental results demonstrate the impact of our dataset in improving\nperformance across several alignment metrics, addressing key challenges in\ndomain adaptation and generalization for segmentation tasks. This research also\nexplores critical aspects of synthetic data generation, such as optimizing the\nbalance between the volume and variability of generated images to enhance\nsegmentation performance. Ultimately, this work sets forth a new paradigm for\nsynthetic data generation and domain adaptation.\n","subjects":["Computer Science/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"NRZ5CM7uavvpxjyeWda2g0qMBMol_WGmZaMajQ2pFfE","pdfSize":"17457773"}