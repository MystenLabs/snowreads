{
  "id": "2412.09796",
  "title": "AutoPatent: A Multi-Agent Framework for Automatic Patent Generation",
  "authors": "Qiyao Wang, Shiwen Ni, Huaren Liu, Shule Lu, Guhong Chen, Xi Feng, Chi\n  Wei, Qiang Qu, Hamid Alinejad-Rokny, Yuan Lin, Min Yang",
  "authorsParsed": [
    [
      "Wang",
      "Qiyao",
      ""
    ],
    [
      "Ni",
      "Shiwen",
      ""
    ],
    [
      "Liu",
      "Huaren",
      ""
    ],
    [
      "Lu",
      "Shule",
      ""
    ],
    [
      "Chen",
      "Guhong",
      ""
    ],
    [
      "Feng",
      "Xi",
      ""
    ],
    [
      "Wei",
      "Chi",
      ""
    ],
    [
      "Qu",
      "Qiang",
      ""
    ],
    [
      "Alinejad-Rokny",
      "Hamid",
      ""
    ],
    [
      "Lin",
      "Yuan",
      ""
    ],
    [
      "Yang",
      "Min",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Fri, 13 Dec 2024 02:27:34 GMT"
    }
  ],
  "updateDate": "2024-12-16",
  "timestamp": 1734056854000,
  "abstract": "  As the capabilities of Large Language Models (LLMs) continue to advance, the\nfield of patent processing has garnered increased attention within the natural\nlanguage processing community. However, the majority of research has been\nconcentrated on classification tasks, such as patent categorization and\nexamination, or on short text generation tasks like patent summarization and\npatent quizzes. In this paper, we introduce a novel and practical task known as\nDraft2Patent, along with its corresponding D2P benchmark, which challenges LLMs\nto generate full-length patents averaging 17K tokens based on initial drafts.\nPatents present a significant challenge to LLMs due to their specialized\nnature, standardized terminology, and extensive length. We propose a\nmulti-agent framework called AutoPatent which leverages the LLM-based planner\nagent, writer agents, and examiner agent with PGTree and RRAG to generate\nlengthy, intricate, and high-quality complete patent documents. The\nexperimental results demonstrate that our AutoPatent framework significantly\nenhances the ability to generate comprehensive patents across various LLMs.\nFurthermore, we have discovered that patents generated solely with the\nAutoPatent framework based on the Qwen2.5-7B model outperform those produced by\nlarger and more powerful LLMs, such as GPT-4o, Qwen2.5-72B, and LLAMA3.1-70B,\nin both objective metrics and human evaluations. We will make the data and code\navailable upon acceptance at \\url{https://github.com/QiYao-Wang/AutoPatent}.\n",
  "subjects": [
    "Computer Science/Computation and Language",
    "Computer Science/Artificial Intelligence"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "tGMW4pi48p2AHyBzm9B37U1HINDVK1Fnoq08KRlMmeQ",
  "pdfSize": "2789129"
}