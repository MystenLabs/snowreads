{
  "id": "2412.04083",
  "title": "Unified Framework for Open-World Compositional Zero-shot Learning",
  "authors": "Hirunima Jayasekara, Khoi Pham, Nirat Saini, Abhinav Shrivastava",
  "authorsParsed": [
    [
      "Jayasekara",
      "Hirunima",
      ""
    ],
    [
      "Pham",
      "Khoi",
      ""
    ],
    [
      "Saini",
      "Nirat",
      ""
    ],
    [
      "Shrivastava",
      "Abhinav",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Thu, 5 Dec 2024 11:36:37 GMT"
    }
  ],
  "updateDate": "2024-12-06",
  "timestamp": 1733398597000,
  "abstract": "  Open-World Compositional Zero-Shot Learning (OW-CZSL) addresses the challenge\nof recognizing novel compositions of known primitives and entities. Even though\nprior works utilize language knowledge for recognition, such approaches exhibit\nlimited interactions between language-image modalities. Our approach primarily\nfocuses on enhancing the inter-modality interactions through fostering richer\ninteractions between image and textual data. Additionally, we introduce a novel\nmodule aimed at alleviating the computational burden associated with exhaustive\nexploration of all possible compositions during the inference stage. While\nprevious methods exclusively learn compositions jointly or independently, we\nintroduce an advanced hybrid procedure that leverages both learning mechanisms\nto generate final predictions. Our proposed model, achieves state-of-the-art in\nOW-CZSL in three datasets, while surpassing Large Vision Language Models (LLVM)\nin two datasets.\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "mofKro6ukKJxnl1VWXIfZOMiXX85n8KmQzjk6s352RE",
  "pdfSize": "1772854"
}