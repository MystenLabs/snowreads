{"id":"2407.10714","title":"SEMINAR: Search Enhanced Multi-modal Interest Network and Approximate\n  Retrieval for Lifelong Sequential Recommendation","authors":"Kaiming Shen, Xichen Ding, Zixiang Zheng, Yuqi Gong, Qianqian Li,\n  Zhongyi Liu, Guannan Zhang","authorsParsed":[["Shen","Kaiming",""],["Ding","Xichen",""],["Zheng","Zixiang",""],["Gong","Yuqi",""],["Li","Qianqian",""],["Liu","Zhongyi",""],["Zhang","Guannan",""]],"versions":[{"version":"v1","created":"Mon, 15 Jul 2024 13:33:30 GMT"}],"updateDate":"2024-07-16","timestamp":1721050410000,"abstract":"  The modeling of users' behaviors is crucial in modern recommendation systems.\nA lot of research focuses on modeling users' lifelong sequences, which can be\nextremely long and sometimes exceed thousands of items. These models use the\ntarget item to search for the most relevant items from the historical sequence.\nHowever, training lifelong sequences in click through rate (CTR) prediction or\npersonalized search ranking (PSR) is extremely difficult due to the\ninsufficient learning problem of ID embedding, especially when the IDs in the\nlifelong sequence features do not exist in the samples of training dataset.\nAdditionally, existing target attention mechanisms struggle to learn the\nmulti-modal representations of items in the sequence well. The distribution of\nmulti-modal embedding (text, image and attributes) output of user's interacted\nitems are not properly aligned and there exist divergence across modalities. We\nalso observe that users' search query sequences and item browsing sequences can\nfully depict users' intents and benefit from each other. To address these\nchallenges, we propose a unified lifelong multi-modal sequence model called\nSEMINAR-Search Enhanced Multi-Modal Interest Network and Approximate Retrieval.\nSpecifically, a network called Pretraining Search Unit (PSU) learns the\nlifelong sequences of multi-modal query-item pairs in a pretraining-finetuning\nmanner with multiple objectives: multi-modal alignment, next query-item pair\nprediction, query-item relevance prediction, etc. After pretraining, the\ndownstream model restores the pretrained embedding as initialization and\nfinetunes the network. To accelerate the online retrieval speed of multi-modal\nembedding, we propose a multi-modal codebook-based product quantization\nstrategy to approximate the exact attention calculati\n","subjects":["Computing Research Repository/Information Retrieval","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"NLgPDdept78mhL64HpTYRm3SNG0C-LabqoK-ohcfCNc","pdfSize":"842568","objectId":"0x9be92cba5348d6c5322c7981cded892a1f83462c0e1bdfe51572b3b002c34050","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
