{"id":"2407.04467","title":"Are Large Language Models Strategic Decision Makers? A Study of\n  Performance and Bias in Two-Player Non-Zero-Sum Games","authors":"Nathan Herr, Fernando Acero, Roberta Raileanu, Mar\\'ia P\\'erez-Ortiz,\n  and Zhibin Li","authorsParsed":[["Herr","Nathan",""],["Acero","Fernando",""],["Raileanu","Roberta",""],["Pérez-Ortiz","María",""],["Li","Zhibin",""]],"versions":[{"version":"v1","created":"Fri, 5 Jul 2024 12:30:02 GMT"},{"version":"v2","created":"Tue, 16 Jul 2024 15:19:27 GMT"}],"updateDate":"2024-07-17","timestamp":1720182602000,"abstract":"  Large Language Models (LLMs) have been increasingly used in real-world\nsettings, yet their strategic abilities remain largely unexplored. Game theory\nprovides a good framework for assessing the decision-making abilities of LLMs\nin interactions with other agents. Although prior studies have shown that LLMs\ncan solve these tasks with carefully curated prompts, they fail when the\nproblem setting or prompt changes. In this work we investigate LLMs' behaviour\nin strategic games, Stag Hunt and Prisoner Dilemma, analyzing performance\nvariations under different settings and prompts. Our results show that the\ntested state-of-the-art LLMs exhibit at least one of the following systematic\nbiases: (1) positional bias, (2) payoff bias, or (3) behavioural bias.\nSubsequently, we observed that the LLMs' performance drops when the game\nconfiguration is misaligned with the affecting biases. Performance is assessed\nbased on the selection of the correct action, one which agrees with the\nprompted preferred behaviours of both players. Alignment refers to whether the\nLLM's bias aligns with the correct action. For example, GPT-4o's average\nperformance drops by 34% when misaligned. Additionally, the current trend of\n\"bigger and newer is better\" does not hold for the above, where GPT-4o (the\ncurrent best-performing LLM) suffers the most substantial performance drop.\nLastly, we note that while chain-of-thought prompting does reduce the effect of\nthe biases on most models, it is far from solving the problem at the\nfundamental level.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language","Computing Research Repository/Computer Science and Game Theory"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"DEbIdCMfA12jXDo6eFgbSpK3HBUaCACs8jmGZ0sWlnA","pdfSize":"18075098"}