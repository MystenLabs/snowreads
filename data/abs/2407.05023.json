{"id":"2407.05023","title":"SurgicalGaussian: Deformable 3D Gaussians for High-Fidelity Surgical\n  Scene Reconstruction","authors":"Weixing Xie, Junfeng Yao, Xianpeng Cao, Qiqin Lin, Zerui Tang, Xiao\n  Dong, Xiaohu Guo","authorsParsed":[["Xie","Weixing",""],["Yao","Junfeng",""],["Cao","Xianpeng",""],["Lin","Qiqin",""],["Tang","Zerui",""],["Dong","Xiao",""],["Guo","Xiaohu",""]],"versions":[{"version":"v1","created":"Sat, 6 Jul 2024 09:31:30 GMT"}],"updateDate":"2024-07-09","timestamp":1720258290000,"abstract":"  Dynamic reconstruction of deformable tissues in endoscopic video is a key\ntechnology for robot-assisted surgery. Recent reconstruction methods based on\nneural radiance fields (NeRFs) have achieved remarkable results in the\nreconstruction of surgical scenes. However, based on implicit representation,\nNeRFs struggle to capture the intricate details of objects in the scene and\ncannot achieve real-time rendering. In addition, restricted single view\nperception and occluded instruments also propose special challenges in surgical\nscene reconstruction. To address these issues, we develop SurgicalGaussian, a\ndeformable 3D Gaussian Splatting method to model dynamic surgical scenes. Our\napproach models the spatio-temporal features of soft tissues at each time stamp\nvia a forward-mapping deformation MLP and regularization to constrain local 3D\nGaussians to comply with consistent movement. With the depth initialization\nstrategy and tool mask-guided training, our method can remove surgical\ninstruments and reconstruct high-fidelity surgical scenes. Through experiments\non various surgical videos, our network outperforms existing method on many\naspects, including rendering quality, rendering speed and GPU usage. The\nproject page can be found at https://surgicalgaussian.github.io.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-sa/4.0/","blobId":"7TVd3ItQ8m7j3aSDBqAGrGr-RrhSwXp4EEhHhHfb17E","pdfSize":"4036432"}