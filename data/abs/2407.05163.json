{"id":"2407.05163","title":"A Domain Adaptation Model for Carotid Ultrasound: Image Harmonization,\n  Noise Reduction, and Impact on Cardiovascular Risk Markers","authors":"Mohd Usama, Emma Nyman, Ulf Naslund, Christer Gronlund","authorsParsed":[["Usama","Mohd",""],["Nyman","Emma",""],["Naslund","Ulf",""],["Gronlund","Christer",""]],"versions":[{"version":"v1","created":"Sat, 6 Jul 2024 19:44:00 GMT"}],"updateDate":"2024-07-09","timestamp":1720295040000,"abstract":"  Deep learning has been used extensively for medical image analysis\napplications, assuming the training and test data adhere to the same\nprobability distributions. However, a common challenge arises when dealing with\nmedical images generated by different systems or even the same system with\nvarying parameter settings. Such images often contain diverse textures and\nnoise patterns, violating the assumption. Consequently, models trained on data\nfrom one machine or setting usually struggle to perform effectively on data\nfrom another. To address this issue in ultrasound images, we proposed a\nGenerative Adversarial Network (GAN) based model in this paper. We formulated\nimage harmonization and denoising tasks as an image-to-image translation task,\nwherein we modified the texture pattern and reduced noise in Carotid ultrasound\nimages while keeping the image content (the anatomy) unchanged. The performance\nwas evaluated using feature distribution and pixel-space similarity metrics. In\naddition, blood-to-tissue contrast and influence on computed risk markers (Gray\nscale median, GSM) were evaluated. The results showed that domain adaptation\nwas achieved in both tasks (histogram correlation 0.920 and 0.844), as compared\nto no adaptation (0.890 and 0.707), and that the anatomy of the images was\nretained (structure similarity index measure of the arterial wall 0.71 and\n0.80). In addition, the image noise level (contrast) did not change in the\nimage harmonization task (-34.1 vs 35.2 dB) but was improved in the noise\nreduction task (-23.5 vs -46.7 dB). The model outperformed the CycleGAN in both\ntasks. Finally, the risk marker GSM increased by 7.6 (p<0.001) in task 1 but\nnot in task 2. We conclude that domain translation models are powerful tools\nfor ultrasound image improvement while retaining the underlying anatomy but\nthat downstream calculations of risk markers may be affected.\n","subjects":["Electrical Engineering and Systems Science/Image and Video Processing","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"OfqK1N33AM88v97yeuXYarUlxCKVf2A3jgGJyRtYGK0","pdfSize":"2036156"}