{"id":"2412.10705","title":"Efficient Adaptation of Multilingual Models for Japanese ASR","authors":"Mark Bajo, Haruka Fukukawa, Ryuji Morita, and Yuma Ogasawara","authorsParsed":[["Bajo","Mark",""],["Fukukawa","Haruka",""],["Morita","Ryuji",""],["Ogasawara","Yuma",""]],"versions":[{"version":"v1","created":"Sat, 14 Dec 2024 06:32:16 GMT"}],"updateDate":"2024-12-17","timestamp":1734157936000,"abstract":"  This study explores fine-tuning multilingual ASR (Automatic Speech\nRecognition) models, specifically OpenAI's Whisper-Tiny, to improve performance\nin Japanese. While multilingual models like Whisper offer versatility, they\noften lack precision in specific languages. Conversely, monolingual models like\nReazonSpeech excel in language-specific tasks but are less adaptable. Using\nJapanese-specific datasets and Low-Rank Adaptation (LoRA) along with end-to-end\n(E2E) training, we fine-tuned Whisper-Tiny to bridge this gap. Our results show\nthat fine-tuning reduced Whisper-Tiny's Character Error Rate (CER) from 32.7 to\n20.8 with LoRA and to 14.7 with end-to-end fine-tuning, surpassing\nWhisper-Base's CER of 20.2. However, challenges with domain-specific terms\nremain, highlighting the need for specialized datasets. These findings\ndemonstrate that fine-tuning multilingual models can achieve strong\nlanguage-specific performance while retaining their flexibility. This approach\nprovides a scalable solution for improving ASR in resource-constrained\nenvironments and languages with complex writing systems like Japanese.\n","subjects":["Computer Science/Computation and Language","Computer Science/Artificial Intelligence","Computer Science/Sound","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"-slc8hxlRG4N8gjK9Z07aNlSN37_Pgas_Qg-TbAFUzg","pdfSize":"6462431"}