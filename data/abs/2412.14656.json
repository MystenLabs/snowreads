{"id":"2412.14656","title":"Length Controlled Generation for Black-box LLMs","authors":"Yuxuan Gu, Wenjie Wang, Xiaocheng Feng, Weihong Zhong, Kun Zhu, Lei\n  Huang, Tat-Seng Chua, Bing Qin","authorsParsed":[["Gu","Yuxuan",""],["Wang","Wenjie",""],["Feng","Xiaocheng",""],["Zhong","Weihong",""],["Zhu","Kun",""],["Huang","Lei",""],["Chua","Tat-Seng",""],["Qin","Bing",""]],"versions":[{"version":"v1","created":"Thu, 19 Dec 2024 09:07:38 GMT"}],"updateDate":"2024-12-20","timestamp":1734599258000,"abstract":"  Large language models (LLMs) have demonstrated impressive instruction\nfollowing capabilities, while still struggling to accurately manage the length\nof the generated text, which is a fundamental requirement in many real-world\napplications. Existing length control methods involve fine-tuning the\nparameters of LLMs, which is inefficient and suboptimal for practical use. In\nthis paper, we propose a novel iterative sampling framework for text length\ncontrol, integrating the Metropolis-Hastings algorithm with an importance\nsampling acceleration strategy. This framework efficiently and reliably\nregulates LLMs to generate length-constrained text without modifying the\nunderlying parameters, thereby preserving the original capabilities of LLMs.\nExperimental results demonstrate that our framework achieves almost 100\\%\nsuccess rates of length control on Llama3.1 for tasks such as length-controlled\nabstractive summarization and length-constrained instruction following, with\nminimal additional computational overhead. This also highlights the significant\npotential of our method for precise length control across a broader range of\napplications, without compromising the versatility of LLMs.\n","subjects":["Computer Science/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"YPaVmBTl8KVKNGhNvXw8XERFC2dQwOcAw5DK6Pt1aOQ","pdfSize":"459611"}