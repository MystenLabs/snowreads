{
  "id": "2412.01558",
  "title": "VideoLights: Feature Refinement and Cross-Task Alignment Transformer for\n  Joint Video Highlight Detection and Moment Retrieval",
  "authors": "Dhiman Paul, Md Rizwan Parvez, Nabeel Mohammed, Shafin Rahman",
  "authorsParsed": [
    [
      "Paul",
      "Dhiman",
      ""
    ],
    [
      "Parvez",
      "Md Rizwan",
      ""
    ],
    [
      "Mohammed",
      "Nabeel",
      ""
    ],
    [
      "Rahman",
      "Shafin",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Mon, 2 Dec 2024 14:45:53 GMT"
    }
  ],
  "updateDate": "2024-12-03",
  "timestamp": 1733150753000,
  "abstract": "  Video Highlight Detection and Moment Retrieval (HD/MR) are essential in video\nanalysis. Recent joint prediction transformer models often overlook their\ncross-task dynamics and video-text alignment and refinement. Moreover, most\nmodels typically use limited, uni-directional attention mechanisms, resulting\nin weakly integrated representations and suboptimal performance in capturing\nthe interdependence between video and text modalities. Although large-language\nand vision-language models (LLM/LVLMs) have gained prominence across various\ndomains, their application in this field remains relatively underexplored. Here\nwe propose VideoLights, a novel HD/MR framework addressing these limitations\nthrough (i) Convolutional Projection and Feature Refinement modules with an\nalignment loss for better video-text feature alignment, (ii) Bi-Directional\nCross-Modal Fusion network for strongly coupled query-aware clip\nrepresentations, and (iii) Uni-directional joint-task feedback mechanism\nenhancing both tasks through correlation. In addition, (iv) we introduce hard\npositive/negative losses for adaptive error penalization and improved learning,\nand (v) leverage LVLMs like BLIP-2 for enhanced multimodal feature integration\nand intelligent pretraining using synthetic data generated from LVLMs.\nComprehensive experiments on QVHighlights, TVSum, and Charades-STA benchmarks\ndemonstrate state-of-the-art performance. Codes and models are available at\nhttps://github.com/dpaul06/VideoLights .\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition",
    "Computer Science/Artificial Intelligence"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "B0n2DE2_dlBUgy7IdS4IcOHe942YCul0XIFMM1TB2pg",
  "pdfSize": "4403039"
}