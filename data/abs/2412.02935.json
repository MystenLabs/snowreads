{"id":"2412.02935","title":"Dynamic Graph Neural ODE Network for Multi-modal Emotion Recognition in\n  Conversation","authors":"Yuntao Shou, Tao Meng, Wei Ai, Keqin Li","authorsParsed":[["Shou","Yuntao",""],["Meng","Tao",""],["Ai","Wei",""],["Li","Keqin",""]],"versions":[{"version":"v1","created":"Wed, 4 Dec 2024 01:07:59 GMT"},{"version":"v2","created":"Mon, 27 Jan 2025 02:01:59 GMT"}],"updateDate":"2025-01-28","timestamp":1733274479000,"abstract":"  Multimodal emotion recognition in conversation (MERC) refers to identifying\nand classifying human emotional states by combining data from multiple\ndifferent modalities (e.g., audio, images, text, video, etc.). Most existing\nmultimodal emotion recognition methods use GCN to improve performance, but\nexisting GCN methods are prone to overfitting and cannot capture the temporal\ndependency of the speaker's emotions. To address the above problems, we propose\na Dynamic Graph Neural Ordinary Differential Equation Network (DGODE) for MERC,\nwhich combines the dynamic changes of emotions to capture the temporal\ndependency of speakers' emotions, and effectively alleviates the overfitting\nproblem of GCNs. Technically, the key idea of DGODE is to utilize an adaptive\nmixhop mechanism to improve the generalization ability of GCNs and use the\ngraph ODE evolution network to characterize the continuous dynamics of node\nrepresentations over time and capture temporal dependencies. Extensive\nexperiments on two publicly available multimodal emotion recognition datasets\ndemonstrate that the proposed DGODE model has superior performance compared to\nvarious baselines. Furthermore, the proposed DGODE can also alleviate the\nover-smoothing problem, thereby enabling the construction of a deep GCN\nnetwork.\n","subjects":["Computer Science/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"SmrUTARVqHtlqmu6CfEJxifGAc2ugypWhL220ENIeNE","pdfSize":"1912214"}