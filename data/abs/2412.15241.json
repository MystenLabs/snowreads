{
  "id": "2412.15241",
  "title": "Quantifying Positional Biases in Text Embedding Models",
  "authors": "Samarth Goel, Reagan J. Lee, Kannan Ramchandran",
  "authorsParsed": [
    [
      "Goel",
      "Samarth",
      ""
    ],
    [
      "Lee",
      "Reagan J.",
      ""
    ],
    [
      "Ramchandran",
      "Kannan",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Fri, 13 Dec 2024 09:52:25 GMT"
    },
    {
      "version": "v2",
      "created": "Mon, 23 Dec 2024 17:59:23 GMT"
    },
    {
      "version": "v3",
      "created": "Wed, 1 Jan 2025 18:06:08 GMT"
    }
  ],
  "updateDate": "2025-01-03",
  "timestamp": 1734083545000,
  "abstract": "  Embedding models are crucial for tasks in Information Retrieval (IR) and\nsemantic similarity measurement, yet their handling of longer texts and\nassociated positional biases remains underexplored. In this study, we\ninvestigate the impact of content position and input size on text embeddings.\nOur experiments reveal that embedding models, irrespective of their positional\nencoding mechanisms, disproportionately prioritize the beginning of an input.\nAblation studies demonstrate that insertion of irrelevant text or removal at\nthe start of a document reduces cosine similarity between altered and original\nembeddings by up to 12.3% more than ablations at the end. Regression analysis\nfurther confirms this bias, with sentence importance declining as position\nmoves further from the start, even with with content-agnosticity. We\nhypothesize that this effect arises from pre-processing strategies and chosen\npositional encoding techniques. These findings quantify the sensitivity of\nretrieval systems and suggest a new lens towards embedding model robustness.\n",
  "subjects": [
    "Computer Science/Computation and Language",
    "Computer Science/Artificial Intelligence",
    "Computer Science/Information Retrieval"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "ytuEwkXoxwlFCqESmLkPQGkTgsFrOX6bFX3ti_b8MJM",
  "pdfSize": "961746"
}