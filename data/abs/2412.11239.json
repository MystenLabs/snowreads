{"id":"2412.11239","title":"Learning Set Functions with Implicit Differentiation","authors":"G\\\"ozde \\\"Ozcan, Chengzhi Shi, Stratis Ioannidis","authorsParsed":[["Özcan","Gözde",""],["Shi","Chengzhi",""],["Ioannidis","Stratis",""]],"versions":[{"version":"v1","created":"Sun, 15 Dec 2024 16:42:09 GMT"},{"version":"v2","created":"Tue, 17 Dec 2024 11:14:52 GMT"}],"updateDate":"2024-12-18","timestamp":1734280929000,"abstract":"  Ou et al. (2022) introduce the problem of learning set functions from data\ngenerated by a so-called optimal subset oracle. Their approach approximates the\nunderlying utility function with an energy-based model, whose parameters are\nestimated via mean-field variational inference. Ou et al. (2022) show this\nreduces to fixed point iterations; however, as the number of iterations\nincreases, automatic differentiation quickly becomes computationally\nprohibitive due to the size of the Jacobians that are stacked during\nbackpropagation. We address this challenge with implicit differentiation and\nexamine the convergence conditions for the fixed-point iterations. We\nempirically demonstrate the efficiency of our method on synthetic and\nreal-world subset selection applications including product recommendation, set\nanomaly detection and compound selection tasks.\n","subjects":["Computer Science/Machine Learning","Computer Science/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"s-AnUMpq8xg64BmLRb1RaDzsKhwZ-7ki-wVNVNZ9YDg","pdfSize":"504256"}