{"id":"2412.11764","title":"What Matters in Learning A Zero-Shot Sim-to-Real RL Policy for Quadrotor\n  Control? A Comprehensive Study","authors":"Jiayu Chen, Chao Yu, Yuqing Xie, Feng Gao, Yinuo Chen, Shu'ang Yu,\n  Wenhao Tang, Shilong Ji, Mo Mu, Yi Wu, Huazhong Yang, Yu Wang","authorsParsed":[["Chen","Jiayu",""],["Yu","Chao",""],["Xie","Yuqing",""],["Gao","Feng",""],["Chen","Yinuo",""],["Yu","Shu'ang",""],["Tang","Wenhao",""],["Ji","Shilong",""],["Mu","Mo",""],["Wu","Yi",""],["Yang","Huazhong",""],["Wang","Yu",""]],"versions":[{"version":"v1","created":"Mon, 16 Dec 2024 13:31:26 GMT"},{"version":"v2","created":"Tue, 17 Dec 2024 12:04:49 GMT"},{"version":"v3","created":"Mon, 23 Dec 2024 03:27:07 GMT"}],"updateDate":"2024-12-24","timestamp":1734355886000,"abstract":"  Executing precise and agile flight maneuvers is critical for quadrotors in\nvarious applications. Traditional quadrotor control approaches are limited by\ntheir reliance on flat trajectories or time-consuming optimization, which\nrestricts their flexibility. Recently, RL-based policy has emerged as a\npromising alternative due to its ability to directly map observations to\nactions, reducing the need for detailed system knowledge and actuation\nconstraints. However, a significant challenge remains in bridging the\nsim-to-real gap, where RL-based policies often experience instability when\ndeployed in real world. In this paper, we investigate key factors for learning\nrobust RL-based control policies that are capable of zero-shot deployment in\nreal-world quadrotors. We identify five critical factors and we develop a\nPPO-based training framework named SimpleFlight, which integrates these five\ntechniques. We validate the efficacy of SimpleFlight on Crazyflie quadrotor,\ndemonstrating that it achieves more than a 50% reduction in trajectory tracking\nerror compared to state-of-the-art RL baselines. The policy derived by\nSimpleFlight consistently excels across both smooth polynominal trajectories\nand challenging infeasible zigzag trajectories on small thrust-to-weight\nquadrotors. In contrast, baseline methods struggle with high-speed or\ninfeasible trajectories. To support further research and reproducibility, we\nintegrate SimpleFlight into a GPU-based simulator Omnidrones and provide\nopen-source access to the code and model checkpoints. We hope SimpleFlight will\noffer valuable insights for advancing RL-based quadrotor control. For more\ndetails, visit our project website at\nhttps://sites.google.com/view/simpleflight/.\n","subjects":["Computer Science/Robotics","Computer Science/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"Mzwpm67CEFhjpHjXjKwTYFOTjkleKsubwVktwg-DYHg","pdfSize":"4124034"}