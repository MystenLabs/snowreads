{"id":"2407.14435","title":"Jumping Ahead: Improving Reconstruction Fidelity with JumpReLU Sparse\n  Autoencoders","authors":"Senthooran Rajamanoharan, Tom Lieberum, Nicolas Sonnerat, Arthur\n  Conmy, Vikrant Varma, J\\'anos Kram\\'ar and Neel Nanda","authorsParsed":[["Rajamanoharan","Senthooran",""],["Lieberum","Tom",""],["Sonnerat","Nicolas",""],["Conmy","Arthur",""],["Varma","Vikrant",""],["Kramár","János",""],["Nanda","Neel",""]],"versions":[{"version":"v1","created":"Fri, 19 Jul 2024 16:07:19 GMT"},{"version":"v2","created":"Mon, 29 Jul 2024 15:27:03 GMT"},{"version":"v3","created":"Thu, 1 Aug 2024 17:42:04 GMT"}],"updateDate":"2024-08-02","timestamp":1721405239000,"abstract":"  Sparse autoencoders (SAEs) are a promising unsupervised approach for\nidentifying causally relevant and interpretable linear features in a language\nmodel's (LM) activations. To be useful for downstream tasks, SAEs need to\ndecompose LM activations faithfully; yet to be interpretable the decomposition\nmust be sparse -- two objectives that are in tension. In this paper, we\nintroduce JumpReLU SAEs, which achieve state-of-the-art reconstruction fidelity\nat a given sparsity level on Gemma 2 9B activations, compared to other recent\nadvances such as Gated and TopK SAEs. We also show that this improvement does\nnot come at the cost of interpretability through manual and automated\ninterpretability studies. JumpReLU SAEs are a simple modification of vanilla\n(ReLU) SAEs -- where we replace the ReLU with a discontinuous JumpReLU\nactivation function -- and are similarly efficient to train and run. By\nutilising straight-through-estimators (STEs) in a principled manner, we show\nhow it is possible to train JumpReLU SAEs effectively despite the discontinuous\nJumpReLU function introduced in the SAE's forward pass. Similarly, we use STEs\nto directly train L0 to be sparse, instead of training on proxies such as L1,\navoiding problems like shrinkage.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"dFMmGSeDSMtl47xhq0iJZLPgN96YNj9H8ZZYjD0zevc","pdfSize":"1297739","objectId":"0x62aa3e24cceff997b9266c2a38d15e091e3d0a6ac55142cd3000c8fd42086767","registeredEpoch":"1","certifiedEpoch":"1","startEpoch":"1","endEpoch":"201"}
