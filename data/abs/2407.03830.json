{"id":"2407.03830","title":"DocXplain: A Novel Model-Agnostic Explainability Method for Document\n  Image Classification","authors":"Saifullah Saifullah, Stefan Agne, Andreas Dengel, Sheraz Ahmed","authorsParsed":[["Saifullah","Saifullah",""],["Agne","Stefan",""],["Dengel","Andreas",""],["Ahmed","Sheraz",""]],"versions":[{"version":"v1","created":"Thu, 4 Jul 2024 10:59:15 GMT"}],"updateDate":"2024-07-08","timestamp":1720090755000,"abstract":"  Deep learning (DL) has revolutionized the field of document image analysis,\nshowcasing superhuman performance across a diverse set of tasks. However, the\ninherent black-box nature of deep learning models still presents a significant\nchallenge to their safe and robust deployment in industry. Regrettably, while a\nplethora of research has been dedicated in recent years to the development of\nDL-powered document analysis systems, research addressing their transparency\naspects has been relatively scarce. In this paper, we aim to bridge this\nresearch gap by introducing DocXplain, a novel model-agnostic explainability\nmethod specifically designed for generating high interpretability feature\nattribution maps for the task of document image classification. In particular,\nour approach involves independently segmenting the foreground and background\nfeatures of the documents into different document elements and then ablating\nthese elements to assign feature importance. We extensively evaluate our\nproposed approach in the context of document image classification, utilizing 4\ndifferent evaluation metrics, 2 widely recognized document benchmark datasets,\nand 10 state-of-the-art document image classification models. By conducting a\nthorough quantitative and qualitative analysis against 9 existing\nstate-of-the-art attribution methods, we demonstrate the superiority of our\napproach in terms of both faithfulness and interpretability. To the best of the\nauthors' knowledge, this work presents the first model-agnostic\nattribution-based explainability method specifically tailored for document\nimages. We anticipate that our work will significantly contribute to advancing\nresearch on transparency, fairness, and robustness of document image\nclassification models.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-sa/4.0/","blobId":"Rk5TR2qrnnSgPR21-VL0a_fbgnlxqWAZ5djXMYg9vlQ","pdfSize":"33704829"}