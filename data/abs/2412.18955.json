{"id":"2412.18955","title":"Leave-One-EquiVariant: Alleviating invariance-related information loss\n  in contrastive music representations","authors":"Julien Guinot, Elio Quinton, Gy\\\"orgy Fazekas","authorsParsed":[["Guinot","Julien",""],["Quinton","Elio",""],["Fazekas","Gy√∂rgy",""]],"versions":[{"version":"v1","created":"Wed, 25 Dec 2024 18:06:44 GMT"}],"updateDate":"2024-12-30","timestamp":1735150004000,"abstract":"  Contrastive learning has proven effective in self-supervised musical\nrepresentation learning, particularly for Music Information Retrieval (MIR)\ntasks. However, reliance on augmentation chains for contrastive view generation\nand the resulting learnt invariances pose challenges when different downstream\ntasks require sensitivity to certain musical attributes. To address this, we\npropose the Leave One EquiVariant (LOEV) framework, which introduces a\nflexible, task-adaptive approach compared to previous work by selectively\npreserving information about specific augmentations, allowing the model to\nmaintain task-relevant equivariances. We demonstrate that LOEV alleviates\ninformation loss related to learned invariances, improving performance on\naugmentation related tasks and retrieval without sacrificing general\nrepresentation quality. Furthermore, we introduce a variant of LOEV, LOEV++,\nwhich builds a disentangled latent space by design in a self-supervised manner,\nand enables targeted retrieval based on augmentation related attributes.\n","subjects":["Computer Science/Sound","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"7hLp0UoNkC6vQI-ji1Jc4y-ytAzuOTkTQCHCDhtd558","pdfSize":"1745329"}