{"id":"2407.06867","title":"Distributionally robust risk evaluation with an isotonic constraint","authors":"Yu Gui, Rina Foygel Barber, Cong Ma","authorsParsed":[["Gui","Yu",""],["Barber","Rina Foygel",""],["Ma","Cong",""]],"versions":[{"version":"v1","created":"Tue, 9 Jul 2024 13:56:34 GMT"},{"version":"v2","created":"Tue, 3 Sep 2024 14:57:54 GMT"}],"updateDate":"2024-09-04","timestamp":1720533394000,"abstract":"  Statistical learning under distribution shift is challenging when neither\nprior knowledge nor fully accessible data from the target distribution is\navailable. Distributionally robust learning (DRL) aims to control the\nworst-case statistical performance within an uncertainty set of candidate\ndistributions, but how to properly specify the set remains challenging. To\nenable distributional robustness without being overly conservative, in this\npaper, we propose a shape-constrained approach to DRL, which incorporates prior\ninformation about the way in which the unknown target distribution differs from\nits estimate. More specifically, we assume the unknown density ratio between\nthe target distribution and its estimate is isotonic with respect to some\npartial order. At the population level, we provide a solution to the\nshape-constrained optimization problem that does not involve the isotonic\nconstraint. At the sample level, we provide consistency results for an\nempirical estimator of the target in a range of different settings. Empirical\nstudies on both synthetic and real data examples demonstrate the improved\naccuracy of the proposed shape-constrained approach.\n","subjects":["Statistics/Methodology","Statistics/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"-wFm_kkD-btUem6E0aTjeWoBYyBeBT7L28LujYgYOCA","pdfSize":"1483725"}