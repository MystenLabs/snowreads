{
  "id": "2412.07273",
  "title": "Temporal-Aware Evaluation and Learning for Temporal Graph Neural\n  Networks",
  "authors": "Junwei Su, Shan Wu",
  "authorsParsed": [
    [
      "Su",
      "Junwei",
      ""
    ],
    [
      "Wu",
      "Shan",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Tue, 10 Dec 2024 07:56:33 GMT"
    },
    {
      "version": "v2",
      "created": "Sun, 15 Dec 2024 04:10:49 GMT"
    }
  ],
  "updateDate": "2024-12-17",
  "timestamp": 1733817393000,
  "abstract": "  Temporal Graph Neural Networks (TGNNs) are a family of graph neural networks\ndesigned to model and learn dynamic information from temporal graphs. Given\ntheir substantial empirical success, there is an escalating interest in TGNNs\nwithin the research community. However, the majority of these efforts have been\nchannelled towards algorithm and system design, with the evaluation metrics\nreceiving comparatively less attention. Effective evaluation metrics are\ncrucial for providing detailed performance insights, particularly in the\ntemporal domain. This paper investigates the commonly used evaluation metrics\nfor TGNNs and illustrates the failure mechanisms of these metrics in capturing\nessential temporal structures in the predictive behaviour of TGNNs. We provide\na mathematical formulation of existing performance metrics and utilize an\ninstance-based study to underscore their inadequacies in identifying volatility\nclustering (the occurrence of emerging errors within a brief interval). This\nphenomenon has profound implications for both algorithm and system design in\nthe temporal domain. To address this deficiency, we introduce a new\nvolatility-aware evaluation metric (termed volatility cluster statistics),\ndesigned for a more refined analysis of model temporal performance.\nAdditionally, we demonstrate how this metric can serve as a\ntemporal-volatility-aware training objective to alleviate the clustering of\ntemporal errors. Through comprehensive experiments on various TGNN models, we\nvalidate our analysis and the proposed approach. The empirical results offer\nrevealing insights: 1) existing TGNNs are prone to making errors with\nvolatility clustering, and 2) TGNNs with different mechanisms to capture\ntemporal information exhibit distinct volatility clustering patterns. Our\nempirical findings demonstrate that our proposed training objective effectively\nreduces volatility clusters in error.\n",
  "subjects": [
    "Computer Science/Machine Learning",
    "Computer Science/Artificial Intelligence"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "rVQLhHNIs8c8ZgiALrLr0sF0HVFUe7nfNY_QP_m3A4M",
  "pdfSize": "495475"
}