{
  "id": "2412.04623",
  "title": "Using Diffusion Priors for Video Amodal Segmentation",
  "authors": "Kaihua Chen, Deva Ramanan, Tarasha Khurana",
  "authorsParsed": [
    [
      "Chen",
      "Kaihua",
      ""
    ],
    [
      "Ramanan",
      "Deva",
      ""
    ],
    [
      "Khurana",
      "Tarasha",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Thu, 5 Dec 2024 21:30:40 GMT"
    }
  ],
  "updateDate": "2024-12-09",
  "timestamp": 1733434240000,
  "abstract": "  Object permanence in humans is a fundamental cue that helps in understanding\npersistence of objects, even when they are fully occluded in the scene. Present\nday methods in object segmentation do not account for this amodal nature of the\nworld, and only work for segmentation of visible or modal objects. Few amodal\nmethods exist; single-image segmentation methods cannot handle high-levels of\nocclusions which are better inferred using temporal information, and\nmulti-frame methods have focused solely on segmenting rigid objects. To this\nend, we propose to tackle video amodal segmentation by formulating it as a\nconditional generation task, capitalizing on the foundational knowledge in\nvideo generative models. Our method is simple; we repurpose these models to\ncondition on a sequence of modal mask frames of an object along with contextual\npseudo-depth maps, to learn which object boundary may be occluded and\ntherefore, extended to hallucinate the complete extent of an object. This is\nfollowed by a content completion stage which is able to inpaint the occluded\nregions of an object. We benchmark our approach alongside a wide array of\nstate-of-the-art methods on four datasets and show a dramatic improvement of\nupto 13% for amodal segmentation in an object's occluded region.\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "qJFYtRWINQtMMJWWmxG4qHDViUYd4XA2FgIAfJoR8pk",
  "pdfSize": "37892494"
}