{
  "id": "2412.10432",
  "title": "Imitate Before Detect: Aligning Machine Stylistic Preference for\n  Machine-Revised Text Detection",
  "authors": "Jiaqi Chen, Xiaoye Zhu, Tianyang Liu, Ying Chen, Xinhui Chen, Yiwen\n  Yuan, Chak Tou Leong, Zuchao Li, Tang Long, Lei Zhang, Chenyu Yan, Guanghao\n  Mei, Jie Zhang, Lefei Zhang",
  "authorsParsed": [
    [
      "Chen",
      "Jiaqi",
      ""
    ],
    [
      "Zhu",
      "Xiaoye",
      ""
    ],
    [
      "Liu",
      "Tianyang",
      ""
    ],
    [
      "Chen",
      "Ying",
      ""
    ],
    [
      "Chen",
      "Xinhui",
      ""
    ],
    [
      "Yuan",
      "Yiwen",
      ""
    ],
    [
      "Leong",
      "Chak Tou",
      ""
    ],
    [
      "Li",
      "Zuchao",
      ""
    ],
    [
      "Long",
      "Tang",
      ""
    ],
    [
      "Zhang",
      "Lei",
      ""
    ],
    [
      "Yan",
      "Chenyu",
      ""
    ],
    [
      "Mei",
      "Guanghao",
      ""
    ],
    [
      "Zhang",
      "Jie",
      ""
    ],
    [
      "Zhang",
      "Lefei",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Wed, 11 Dec 2024 03:17:14 GMT"
    },
    {
      "version": "v2",
      "created": "Sun, 22 Dec 2024 15:47:50 GMT"
    }
  ],
  "updateDate": "2024-12-24",
  "timestamp": 1733887034000,
  "abstract": "  Large Language Models (LLMs) have revolutionized text generation, making\ndetecting machine-generated text increasingly challenging. Although past\nmethods have achieved good performance on detecting pure machine-generated\ntext, those detectors have poor performance on distinguishing machine-revised\ntext (rewriting, expansion, and polishing), which can have only minor changes\nfrom its original human prompt. As the content of text may originate from human\nprompts, detecting machine-revised text often involves identifying distinctive\nmachine styles, e.g., worded favored by LLMs. However, existing methods\nstruggle to detect machine-style phrasing hidden within the content contributed\nby humans. We propose the \"Imitate Before Detect\" (ImBD) approach, which first\nimitates the machine-style token distribution, and then compares the\ndistribution of the text to be tested with the machine-style distribution to\ndetermine whether the text has been machine-revised. To this end, we introduce\nstyle preference optimization (SPO), which aligns a scoring LLM model to the\npreference of text styles generated by machines. The aligned scoring model is\nthen used to calculate the style-conditional probability curvature (Style-CPC),\nquantifying the log probability difference between the original and\nconditionally sampled texts for effective detection. We conduct extensive\ncomparisons across various scenarios, encompassing text revisions by six LLMs,\nfour distinct text domains, and three machine revision types. Compared to\nexisting state-of-the-art methods, our method yields a 13% increase in AUC for\ndetecting text revised by open-source LLMs, and improves performance by 5% and\n19% for detecting GPT-3.5 and GPT-4o revised text, respectively. Notably, our\nmethod surpasses the commercially trained GPT-Zero with just $1,000$ samples\nand five minutes of SPO, demonstrating its efficiency and effectiveness.\n",
  "subjects": [
    "Computer Science/Computation and Language",
    "Computer Science/Artificial Intelligence",
    "Computer Science/Cryptography and Security"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "EfMvhmoBDMqeXYSeaiuRdjcqbeSp_EQO72BXQBA2zXs",
  "pdfSize": "2632374"
}