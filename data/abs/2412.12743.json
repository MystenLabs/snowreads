{"id":"2412.12743","title":"Training a Distributed Acoustic Sensing Traffic Monitoring Network With\n  Video Inputs","authors":"Khen Cohen, Liav Hen, and Ariel Lellouch","authorsParsed":[["Cohen","Khen",""],["Hen","Liav",""],["Lellouch","Ariel",""]],"versions":[{"version":"v1","created":"Tue, 17 Dec 2024 10:06:42 GMT"}],"updateDate":"2024-12-18","timestamp":1734430002000,"abstract":"  Distributed Acoustic Sensing (DAS) has emerged as a promising tool for\nreal-time traffic monitoring in densely populated areas. In this paper, we\npresent a novel concept that integrates DAS data with co-located visual\ninformation. We use YOLO-derived vehicle location and classification from\ncamera inputs as labeled data to train a detection and classification neural\nnetwork utilizing DAS data only. Our model achieves a performance exceeding 94%\nfor detection and classification, and about 1.2% false alarm rate. We\nillustrate the model's application in monitoring traffic over a week, yielding\nstatistical insights that could benefit future smart city developments. Our\napproach highlights the potential of combining fiber-optic sensors with visual\ninformation, focusing on practicality and scalability, protecting privacy, and\nminimizing infrastructure costs. To encourage future research, we share our\ndataset.\n","subjects":["Physics/Geophysics","Computer Science/Computer Vision and Pattern Recognition","Computer Science/Machine Learning","Electrical Engineering and Systems Science/Signal Processing","Physics/Optics"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"F5KW8qWzzkJZsC_F8MrtBKd-8QGvilug8Gq7zEk7iPQ","pdfSize":"16133539"}