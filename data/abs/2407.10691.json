{"id":"2407.10691","title":"$\\texttt{MixGR}$: Enhancing Retriever Generalization for Scientific\n  Domain through Complementary Granularity","authors":"Fengyu Cai, Xinran Zhao, Tong Chen, Sihao Chen, Hongming Zhang, Iryna\n  Gurevych, Heinz Koeppl","authorsParsed":[["Cai","Fengyu",""],["Zhao","Xinran",""],["Chen","Tong",""],["Chen","Sihao",""],["Zhang","Hongming",""],["Gurevych","Iryna",""],["Koeppl","Heinz",""]],"versions":[{"version":"v1","created":"Mon, 15 Jul 2024 13:04:09 GMT"}],"updateDate":"2024-07-16","timestamp":1721048649000,"abstract":"  Recent studies show the growing significance of document retrieval in the\ngeneration of LLMs, i.e., RAG, within the scientific domain by bridging their\nknowledge gap. However, dense retrievers often struggle with domain-specific\nretrieval and complex query-document relationships, particularly when query\nsegments correspond to various parts of a document. To alleviate such prevalent\nchallenges, this paper introduces $\\texttt{MixGR}$, which improves dense\nretrievers' awareness of query-document matching across various levels of\ngranularity in queries and documents using a zero-shot approach.\n$\\texttt{MixGR}$ fuses various metrics based on these granularities to a united\nscore that reflects a comprehensive query-document similarity. Our experiments\ndemonstrate that $\\texttt{MixGR}$ outperforms previous document retrieval by\n24.7% and 9.8% on nDCG@5 with unsupervised and supervised retrievers,\nrespectively, averaged on queries containing multiple subqueries from five\nscientific retrieval datasets. Moreover, the efficacy of two downstream\nscientific question-answering tasks highlights the advantage of\n$\\texttt{MixGR}$to boost the application of LLMs in the scientific domain.\n","subjects":["Computing Research Repository/Information Retrieval","Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"GkSVia2hsDRVobwSkaPb_ksq1EljfkJv6x_uOA5mLFs","pdfSize":"1099385"}