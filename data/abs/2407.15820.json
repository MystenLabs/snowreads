{"id":"2407.15820","title":"On shallow planning under partial observability","authors":"Randy Lefebvre, Audrey Durand","authorsParsed":[["Lefebvre","Randy",""],["Durand","Audrey",""]],"versions":[{"version":"v1","created":"Mon, 22 Jul 2024 17:34:07 GMT"}],"updateDate":"2024-07-23","timestamp":1721669647000,"abstract":"  Formulating a real-world problem under the Reinforcement Learning framework\ninvolves non-trivial design choices, such as selecting a discount factor for\nthe learning objective (discounted cumulative rewards), which articulates the\nplanning horizon of the agent. This work investigates the impact of the\ndiscount factor on the biasvariance trade-off given structural parameters of\nthe underlying Markov Decision Process. Our results support the idea that a\nshorter planning horizon might be beneficial, especially under partial\nobservability.\n","subjects":["Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"oveVnvKLM7cqtC2zHa3DRXnufXD1x912CxGgctvrH7Q","pdfSize":"625515"}