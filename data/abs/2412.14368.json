{"id":"2412.14368","title":"Memorization Over Reasoning? Exposing and Mitigating Verbatim\n  Memorization in Large Language Models' Character Understanding Evaluation","authors":"Yuxuan Jiang, Francis Ferraro","authorsParsed":[["Jiang","Yuxuan",""],["Ferraro","Francis",""]],"versions":[{"version":"v1","created":"Wed, 18 Dec 2024 22:04:56 GMT"},{"version":"v2","created":"Mon, 23 Dec 2024 23:46:55 GMT"},{"version":"v3","created":"Mon, 30 Dec 2024 04:09:29 GMT"},{"version":"v4","created":"Thu, 20 Feb 2025 20:02:27 GMT"}],"updateDate":"2025-02-24","timestamp":1734559496000,"abstract":"  Recently, Large Language Models (LLMs) have shown impressive performance in\ncharacter understanding tasks, such as analyzing the roles, personalities, and\nrelationships of fictional characters. However, the extensive pre-training\ncorpora used by LLMs raise concerns that they may rely on memorizing popular\nfictional works rather than genuinely understanding and reasoning about them.\nIn this work, we argue that 'gist memory'-capturing essential meaning - should\nbe the primary mechanism for character understanding tasks, as opposed to\n'verbatim memory' - exact match of a string. We introduce a simple yet\neffective method to mitigate mechanized memorization in character understanding\nevaluations while preserving the essential implicit cues needed for\ncomprehension and reasoning. Our approach reduces memorization-driven\nperformance on popular fictional works from 96% accuracy to 72% and results in\nup to an 18% drop in accuracy across various character understanding tasks.\nThese findings underscore the issue of data contamination in existing\nbenchmarks, which often measure memorization rather than true character\nunderstanding.\n","subjects":["Computer Science/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"RQqxA4hzpNCCt74GFIhoVSSzbsVU8z3VveQcPUDmcJw","pdfSize":"405330"}