{
  "id": "2412.18917",
  "title": "Open-Vocabulary Panoptic Segmentation Using BERT Pre-Training of\n  Vision-Language Multiway Transformer Model",
  "authors": "Yi-Chia Chen, Wei-Hua Li, Chu-Song Chen",
  "authorsParsed": [
    [
      "Chen",
      "Yi-Chia",
      ""
    ],
    [
      "Li",
      "Wei-Hua",
      ""
    ],
    [
      "Chen",
      "Chu-Song",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Wed, 25 Dec 2024 14:31:00 GMT"
    }
  ],
  "updateDate": "2024-12-30",
  "timestamp": 1735137060000,
  "abstract": "  Open-vocabulary panoptic segmentation remains a challenging problem. One of\nthe biggest difficulties lies in training models to generalize to an unlimited\nnumber of classes using limited categorized training data. Recent popular\nmethods involve large-scale vision-language pre-trained foundation models, such\nas CLIP. In this paper, we propose OMTSeg for open-vocabulary segmentation\nusing another large-scale vision-language pre-trained model called BEiT-3 and\nleveraging the cross-modal attention between visual and linguistic features in\nBEiT-3 to achieve better performance. Experiments result demonstrates that\nOMTSeg performs favorably against state-of-the-art models.\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition",
    "Computer Science/Artificial Intelligence",
    "Computer Science/Machine Learning"
  ],
  "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
  "blobId": "V9IM77-kl_F8-NxrwDRxeqXDHInTgGYQggHYf6Et3C8",
  "pdfSize": "524965"
}