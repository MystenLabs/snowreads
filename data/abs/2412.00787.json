{"id":"2412.00787","title":"TSUBF-Net: Trans-Spatial UNet-like Network with Bi-direction Fusion for\n  Segmentation of Adenoid Hypertrophy in CT","authors":"Rulin Zhou, Yingjie Feng, Guankun Wang, Xiaopin Zhong, Zongze Wu,\n  Qiang Wu, Xi Zhang","authorsParsed":[["Zhou","Rulin",""],["Feng","Yingjie",""],["Wang","Guankun",""],["Zhong","Xiaopin",""],["Wu","Zongze",""],["Wu","Qiang",""],["Zhang","Xi",""]],"versions":[{"version":"v1","created":"Sun, 1 Dec 2024 12:21:23 GMT"}],"updateDate":"2024-12-03","timestamp":1733055683000,"abstract":"  Adenoid hypertrophy stands as a common cause of obstructive sleep\napnea-hypopnea syndrome in children. It is characterized by snoring, nasal\ncongestion, and growth disorders. Computed Tomography (CT) emerges as a pivotal\nmedical imaging modality, utilizing X-rays and advanced computational\ntechniques to generate detailed cross-sectional images. Within the realm of\npediatric airway assessments, CT imaging provides an insightful perspective on\nthe shape and volume of enlarged adenoids. Despite the advances of deep\nlearning methods for medical imaging analysis, there remains an emptiness in\nthe segmentation of adenoid hypertrophy in CT scans. To address this research\ngap, we introduce TSUBF-Nett (Trans-Spatial UNet-like Network based on\nBi-direction Fusion), a 3D medical image segmentation framework. TSUBF-Net is\nengineered to effectively discern intricate 3D spatial interlayer features in\nCT scans and enhance the extraction of boundary-blurring features. Notably, we\npropose two innovative modules within the U-shaped network architecture:the\nTrans-Spatial Perception module (TSP) and the Bi-directional Sampling\nCollaborated Fusion module (BSCF).These two modules are in charge of operating\nduring the sampling process and strategically fusing down-sampled and\nup-sampled features, respectively. Furthermore, we introduce the Sobel loss\nterm, which optimizes the smoothness of the segmentation results and enhances\nmodel accuracy. Extensive 3D segmentation experiments are conducted on several\ndatasets. TSUBF-Net is superior to the state-of-the-art methods with the lowest\nHD95: 7.03, IoU:85.63, and DSC: 92.26 on our own AHSD dataset. The results in\nthe other two public datasets also demonstrate that our methods can robustly\nand effectively address the challenges of 3D segmentation in CT scans.\n","subjects":["Electrical Engineering and Systems Science/Image and Video Processing","Computer Science/Artificial Intelligence","Computer Science/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"0J8fOLo1l6cjiEV2zGPr2sqjY3fMA44mmgoufyYLOwI","pdfSize":"2431801"}