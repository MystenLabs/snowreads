{"id":"2412.05435","title":"UniScene: Unified Occupancy-centric Driving Scene Generation","authors":"Bohan Li, Jiazhe Guo, Hongsi Liu, Yingshuang Zou, Yikang Ding, Xiwu\n  Chen, Hu Zhu, Feiyang Tan, Chi Zhang, Tiancai Wang, Shuchang Zhou, Li Zhang,\n  Xiaojuan Qi, Hao Zhao, Mu Yang, Wenjun Zeng, Xin Jin","authorsParsed":[["Li","Bohan",""],["Guo","Jiazhe",""],["Liu","Hongsi",""],["Zou","Yingshuang",""],["Ding","Yikang",""],["Chen","Xiwu",""],["Zhu","Hu",""],["Tan","Feiyang",""],["Zhang","Chi",""],["Wang","Tiancai",""],["Zhou","Shuchang",""],["Zhang","Li",""],["Qi","Xiaojuan",""],["Zhao","Hao",""],["Yang","Mu",""],["Zeng","Wenjun",""],["Jin","Xin",""]],"versions":[{"version":"v1","created":"Fri, 6 Dec 2024 21:41:52 GMT"}],"updateDate":"2024-12-10","timestamp":1733521312000,"abstract":"  Generating high-fidelity, controllable, and annotated training data is\ncritical for autonomous driving. Existing methods typically generate a single\ndata form directly from a coarse scene layout, which not only fails to output\nrich data forms required for diverse downstream tasks but also struggles to\nmodel the direct layout-to-data distribution. In this paper, we introduce\nUniScene, the first unified framework for generating three key data forms -\nsemantic occupancy, video, and LiDAR - in driving scenes. UniScene employs a\nprogressive generation process that decomposes the complex task of scene\ngeneration into two hierarchical steps: (a) first generating semantic occupancy\nfrom a customized scene layout as a meta scene representation rich in both\nsemantic and geometric information, and then (b) conditioned on occupancy,\ngenerating video and LiDAR data, respectively, with two novel transfer\nstrategies of Gaussian-based Joint Rendering and Prior-guided Sparse Modeling.\nThis occupancy-centric approach reduces the generation burden, especially for\nintricate scenes, while providing detailed intermediate representations for the\nsubsequent generation stages. Extensive experiments demonstrate that UniScene\noutperforms previous SOTAs in the occupancy, video, and LiDAR generation, which\nalso indeed benefits downstream driving tasks.\n","subjects":["Computer Science/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"te5h25JTcoWJDeH2KNIlQ5HYlwSj3-PS5in10Z_e58Q","pdfSize":"38763958"}