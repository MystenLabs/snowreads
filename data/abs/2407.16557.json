{"id":"2407.16557","title":"Patched RTC: evaluating LLMs for diverse software development tasks","authors":"Asankhaya Sharma","authorsParsed":[["Sharma","Asankhaya",""]],"versions":[{"version":"v1","created":"Tue, 23 Jul 2024 15:12:14 GMT"}],"updateDate":"2024-07-24","timestamp":1721747534000,"abstract":"  This paper introduces Patched Round-Trip Correctness (Patched RTC), a novel\nevaluation technique for Large Language Models (LLMs) applied to diverse\nsoftware development tasks, particularly focusing on \"outer loop\" activities\nsuch as bug fixing, code review, and documentation updates. Patched RTC extends\nthe original Round-Trip Correctness method to work with any LLM and downstream\ntask, offering a self-evaluating framework that measures consistency and\nrobustness of model responses without human intervention. The study\ndemonstrates a correlation between Patched RTC scores and task-specific\naccuracy metrics, presenting it as an alternative to the LLM-as-Judge paradigm\nfor open-domain task evaluation. We implement Patched RTC in an open-source\nframework called patchwork, allowing for transparent evaluation during\ninference across various patchflows. Experiments comparing GPT-3.5 and GPT-4\nmodels across different software development tasks reveal that Patched RTC\neffectively distinguishes model performance and task difficulty. The paper also\nexplores the impact of consistency prompts on improving model accuracy,\nsuggesting that Patched RTC can guide prompt refinement and model selection for\ncomplex software development workflows.\n","subjects":["Computing Research Repository/Software Engineering","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"aVkruZYs_7y25i-hLNSSJVd88yCoLq--el21xlXLfCo","pdfSize":"465276","objectId":"0xb360d67fba301f47826a26965b9ff6c11c605828e1d5ff78e5929e03cf626628","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
