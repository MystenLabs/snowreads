{"id":"2407.00574","title":"OfCaM: Global Human Mesh Recovery via Optimization-free Camera Motion\n  Scale Calibration","authors":"Fengyuan Yang, Kerui Gu, Ha Linh Nguyen, Angela Yao","authorsParsed":[["Yang","Fengyuan",""],["Gu","Kerui",""],["Nguyen","Ha Linh",""],["Yao","Angela",""]],"versions":[{"version":"v1","created":"Sun, 30 Jun 2024 03:31:21 GMT"}],"updateDate":"2024-07-02","timestamp":1719718281000,"abstract":"  Accurate camera motion estimation is critical to estimate human motion in the\nglobal space. A standard and widely used method for estimating camera motion is\nSimultaneous Localization and Mapping (SLAM). However, SLAM only provides a\ntrajectory up to an unknown scale factor. Different from previous attempts that\noptimize the scale factor, this paper presents Optimization-free Camera Motion\nScale Calibration (OfCaM), a novel framework that utilizes prior knowledge from\nhuman mesh recovery (HMR) models to directly calibrate the unknown scale\nfactor. Specifically, OfCaM leverages the absolute depth of human-background\ncontact joints from HMR predictions as a calibration reference, enabling the\nprecise recovery of SLAM camera trajectory scale in global space. With this\ncorrectly scaled camera motion and HMR's local motion predictions, we achieve\nmore accurate global human motion estimation. To compensate for scenes where we\ndetect SLAM failure, we adopt a local-to-global motion mapping to fuse with\npreviously derived motion to enhance robustness. Simple yet powerful, our\nmethod sets a new standard for global human mesh estimation tasks, reducing\nglobal human motion error by 60% over the prior SOTA while also demanding\norders of magnitude less inference time compared with optimization-based\nmethods.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"zGukLYJp3Rufq-SzVJDCoZXEWTozkJ2wbjhL_WNwkeQ","pdfSize":"7336533"}