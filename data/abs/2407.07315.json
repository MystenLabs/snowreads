{"id":"2407.07315","title":"CosmoCLIP: Generalizing Large Vision-Language Models for Astronomical\n  Imaging","authors":"Raza Imam, Mohammed Talha Alam, Umaima Rahman, Mohsen Guizani, Fakhri\n  Karray","authorsParsed":[["Imam","Raza",""],["Alam","Mohammed Talha",""],["Rahman","Umaima",""],["Guizani","Mohsen",""],["Karray","Fakhri",""]],"versions":[{"version":"v1","created":"Wed, 10 Jul 2024 02:24:43 GMT"}],"updateDate":"2024-07-11","timestamp":1720578283000,"abstract":"  Existing vision-text contrastive learning models enhance representation\ntransferability and support zero-shot prediction by matching paired image and\ncaption embeddings while pushing unrelated pairs apart. However, astronomical\nimage-label datasets are significantly smaller compared to general image and\nlabel datasets available from the internet. We introduce CosmoCLIP, an\nastronomical image-text contrastive learning framework precisely fine-tuned on\nthe pre-trained CLIP model using SpaceNet and BLIP-based captions. SpaceNet,\nattained via FLARE, constitutes ~13k optimally distributed images, while BLIP\nacts as a rich knowledge extractor. The rich semantics derived from this\nSpaceNet and BLIP descriptions, when learned contrastively, enable CosmoCLIP to\nachieve superior generalization across various in-domain and out-of-domain\ntasks. Our results demonstrate that CosmoCLIP is a straightforward yet powerful\nframework, significantly outperforming CLIP in zero-shot classification and\nimage-text retrieval tasks.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"sU3wWUb4WH9lAP_5iNCR6W3kYmgeplUbDI8UCIFEHU8","pdfSize":"1018481"}
