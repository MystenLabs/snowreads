{"id":"2412.14988","title":"Stitch Contrast and Segment_Learning a Human Action Segmentation Model\n  Using Trimmed Skeleton Videos","authors":"Haitao Tian, Pierre Payeur","authorsParsed":[["Tian","Haitao",""],["Payeur","Pierre",""]],"versions":[{"version":"v1","created":"Thu, 19 Dec 2024 16:00:10 GMT"},{"version":"v2","created":"Sat, 21 Dec 2024 13:19:14 GMT"}],"updateDate":"2024-12-24","timestamp":1734624010000,"abstract":"  Existing skeleton-based human action classification models rely on\nwell-trimmed action-specific skeleton videos for both training and testing,\nprecluding their scalability to real-world applications where untrimmed videos\nexhibiting concatenated actions are predominant. To overcome this limitation,\nrecently introduced skeleton action segmentation models involve un-trimmed\nskeleton videos into end-to-end training. The model is optimized to provide\nframe-wise predictions for any length of testing videos, simultaneously\nrealizing action localization and classification. Yet, achieving such an\nimprovement im-poses frame-wise annotated skeleton videos, which remains\ntime-consuming in practice. This paper features a novel framework for\nskeleton-based action segmentation trained on short trimmed skeleton videos,\nbut that can run on longer un-trimmed videos. The approach is implemented in\nthree steps: Stitch, Contrast, and Segment. First, Stitch proposes a tem-poral\nskeleton stitching scheme that treats trimmed skeleton videos as elementary\nhuman motions that compose a semantic space and can be sampled to generate\nmulti-action stitched se-quences. Contrast learns contrastive representations\nfrom stitched sequences with a novel discrimination pretext task that enables a\nskeleton encoder to learn meaningful action-temporal contexts to improve action\nsegmentation. Finally, Segment relates the proposed method to action\nsegmentation by learning a segmentation layer while handling particular da-ta\navailability. Experiments involve a trimmed source dataset and an untrimmed\ntarget dataset in an adaptation formulation for real-world skeleton-based human\naction segmentation to evaluate the effectiveness of the proposed method.\n","subjects":["Computer Science/Computer Vision and Pattern Recognition","Computer Science/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"Y2Zd_KVrr1GFF78xSBeX34dCoVlmyIaGd9HhNAgb-fo","pdfSize":"1120582"}