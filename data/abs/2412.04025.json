{"id":"2412.04025","title":"Exploring the Influence of Label Aggregation on Minority Voices:\n  Implications for Dataset Bias and Model Training","authors":"Mugdha Pandya, Nafise Sadat Moosavi, Diana Maynard","authorsParsed":[["Pandya","Mugdha",""],["Moosavi","Nafise Sadat",""],["Maynard","Diana",""]],"versions":[{"version":"v1","created":"Thu, 5 Dec 2024 10:00:49 GMT"}],"updateDate":"2024-12-06","timestamp":1733392849000,"abstract":"  Resolving disagreement in manual annotation typically consists of removing\nunreliable annotators and using a label aggregation strategy such as majority\nvote or expert opinion to resolve disagreement. These may have the side-effect\nof silencing or under-representing minority but equally valid opinions. In this\npaper, we study the impact of standard label aggregation strategies on minority\nopinion representation in sexism detection. We investigate the quality and\nvalue of minority annotations, and then examine their effect on the class\ndistributions in gold labels, as well as how this affects the behaviour of\nmodels trained on the resulting datasets. Finally, we discuss the potential\nbiases introduced by each method and how they can be amplified by the models.\n","subjects":["Computer Science/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"04nNjm7mdWir9fvhUodVcgl3mYaFxiib7n0LZPPrgag","pdfSize":"571933"}