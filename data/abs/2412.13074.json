{"id":"2412.13074","title":"Predicting Change, Not States: An Alternate Framework for Neural PDE\n  Surrogates","authors":"Anthony Zhou and Amir Barati Farimani","authorsParsed":[["Zhou","Anthony",""],["Farimani","Amir Barati",""]],"versions":[{"version":"v1","created":"Tue, 17 Dec 2024 16:41:53 GMT"}],"updateDate":"2024-12-18","timestamp":1734453713000,"abstract":"  Neural surrogates for partial differential equations (PDEs) have become\npopular due to their potential to quickly simulate physics. With a few\nexceptions, neural surrogates generally treat the forward evolution of\ntime-dependent PDEs as a black box by directly predicting the next state. While\nthis is a natural and easy framework for applying neural surrogates, it can be\nan over-simplified and rigid framework for predicting physics. In this work, we\npropose an alternative framework in which neural solvers predict the temporal\nderivative and an ODE integrator forwards the solution in time, which has\nlittle overhead and is broadly applicable across model architectures and PDEs.\nWe find that by simply changing the training target and introducing numerical\nintegration during inference, neural surrogates can gain accuracy and\nstability. Predicting temporal derivatives also allows models to not be\nconstrained to a specific temporal discretization, allowing for flexible\ntime-stepping during inference or training on higher-resolution PDE data.\nLastly, we investigate why this new framework can be beneficial and in what\nsituations does it work well.\n","subjects":["Computer Science/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"wi4uOn6UkP5BfrjzCYzDB_oHeYiZW1boHGeKrb7jTP0","pdfSize":"4244383"}