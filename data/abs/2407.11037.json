{"id":"2407.11037","title":"ISQuant: apply squant to the real deployment","authors":"Dezan Zhao","authorsParsed":[["Zhao","Dezan",""]],"versions":[{"version":"v1","created":"Fri, 5 Jul 2024 15:10:05 GMT"}],"updateDate":"2024-07-17","timestamp":1720192205000,"abstract":"  The model quantization technique of deep neural networks has garnered\nsignificant attention and has proven to be highly useful in compressing model\nsize, reducing computation costs, and accelerating inference. Many researchers\nemploy fake quantization for analyzing or training the quantization process.\nHowever, fake quantization is not the final form for deployment, and there\nexists a gap between the academic setting and real-world deployment.\nAdditionally, the inclusion of additional computation with scale and zero-point\nmakes deployment a challenging task. In this study, we first analyze why the\ncombination of quantization and dequantization is used to train the model and\ndraw the conclusion that fake quantization research is reasonable due to the\ndisappearance of weight gradients and the ability to approximate between fake\nand real quantization. Secondly, we propose ISQuant as a solution for deploying\n8-bit models. ISQuant is fast and easy to use for most 8-bit models, requiring\nfewer parameters and less computation. ISQuant also inherits the advantages of\nSQuant, such as not requiring training data and being very fast at the first\nlevel of quantization. Finally We conduct some experiments and found the\nresults is acceptable.our code is available at https://github.com/\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"P1Qi6_qAC2vUJN4VgOFTuYnpPcWp8ElfZA6NS7-zv5c","pdfSize":"360277"}