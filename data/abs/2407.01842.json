{"id":"2407.01842","title":"CLIP the Divergence: Language-guided Unsupervised Domain Adaptation","authors":"Jinjing Zhu, Yucheng Chen, Lin Wang","authorsParsed":[["Zhu","Jinjing",""],["Chen","Yucheng",""],["Wang","Lin",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 22:52:14 GMT"}],"updateDate":"2024-07-03","timestamp":1719874334000,"abstract":"  Unsupervised domain adaption (UDA) has emerged as a popular solution to\ntackle the divergence between the labeled source and unlabeled target domains.\nRecently, some research efforts have been made to leverage large\nvision-language models, such as CLIP, and then fine-tune or learn prompts from\nthem for addressing the challenging UDA task. In this work, we shift the gear\nto a new direction by directly leveraging CLIP to measure the domain divergence\nand propose a novel language-guided approach for UDA, dubbed as CLIP-Div. Our\nkey idea is to harness CLIP to 1) measure the domain divergence via the\nacquired domain-agnostic distribution and 2) calibrate the target pseudo labels\nwith language guidance, to effectively reduce the domain gap and improve the\nUDA model's generalization capability. Specifically, our major technical\ncontribution lies in the proposed two novel language-guided domain divergence\nmeasurement losses: absolute divergence and relative divergence. These loss\nterms furnish precise guidelines for aligning the distributions of the source\nand target domains with the domain-agnostic distribution derived from CLIP.\nAdditionally, we propose a language-guided pseudo-labeling strategy for\ncalibrating the target pseudo labels. Buttressed by it, we show that a further\nimplementation for self-training can enhance the UDA model's generalization\ncapability on the target domain. CLIP-Div surpasses state-of-the-art CNN-based\nmethods by a substantial margin, achieving a performance boost of +10.3% on\nOffice-Home, +1.5% on Office-31, +0.2% on VisDA-2017, and +24.3% on DomainNet,\nrespectively.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"K6EW4kIt5JinN3uJClBC37scAyW9DD8LVSZUxI3Kau0","pdfSize":"4166514"}