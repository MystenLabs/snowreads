{"id":"2412.04903","title":"EACO: Enhancing Alignment in Multimodal LLMs via Critical Observation","authors":"Yongxin Wang, Meng Cao, Haokun Lin, Mingfei Han, Liang Ma, Jin Jiang,\n  Yuhao Cheng, Xiaodan Liang","authorsParsed":[["Wang","Yongxin",""],["Cao","Meng",""],["Lin","Haokun",""],["Han","Mingfei",""],["Ma","Liang",""],["Jiang","Jin",""],["Cheng","Yuhao",""],["Liang","Xiaodan",""]],"versions":[{"version":"v1","created":"Fri, 6 Dec 2024 09:59:47 GMT"},{"version":"v2","created":"Mon, 16 Dec 2024 13:47:29 GMT"}],"updateDate":"2024-12-17","timestamp":1733479187000,"abstract":"  Multimodal large language models (MLLMs) have achieved remarkable progress on\nvarious visual question answering and reasoning tasks leveraging instruction\nfine-tuning specific datasets. They can also learn from preference data\nannotated by human to enhance their reasoning ability and mitigate\nhallucinations. Most of preference data is generated from the model itself.\nHowever, existing methods require high-quality critical labels, which are\ncostly and rely on human or proprietary models like GPT-4V. In this work, we\npropose Enhancing Alignment in MLLMs via Critical Observation (EACO), which\naligns MLLMs by self-generated preference data using only 5k images\neconomically. Our approach begins with collecting and refining a Scoring\nEvaluation Instruction-tuning dataset to train a critical evaluation model,\ntermed the Critic. This Critic observes model responses across multiple\ndimensions, selecting preferred and non-preferred outputs for refined Direct\nPreference Optimization (DPO) tuning. To further enhance model performance, we\nemploy an additional supervised fine-tuning stage after preference tuning. EACO\nreduces the overall hallucinations by 65.6% on HallusionBench and improves the\nreasoning ability by 21.8% on MME-Cognition. EACO achieves an 8.5% improvement\nover LLaVA-v1.6-Mistral-7B across multiple benchmarks. Remarkably, EACO also\nshows the potential critical ability in open-source MLLMs, demonstrating that\nEACO is a viable path to boost the competence of MLLMs.\n","subjects":["Computer Science/Computer Vision and Pattern Recognition","Computer Science/Artificial Intelligence","Computer Science/Computation and Language","Computer Science/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"8CKqcX0scU5Low2fUuLQD8hivMYhQ4jlQ0EIvKVKboU","pdfSize":"2549745"}