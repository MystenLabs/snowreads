{"id":"2412.00979","title":"Hierarchical Prompt Decision Transformer: Improving Few-Shot Policy\n  Generalization with Global and Adaptive Guidance","authors":"Zhe Wang, Haozhu Wang, Yanjun Qi","authorsParsed":[["Wang","Zhe",""],["Wang","Haozhu",""],["Qi","Yanjun",""]],"versions":[{"version":"v1","created":"Sun, 1 Dec 2024 22:02:07 GMT"},{"version":"v2","created":"Fri, 13 Dec 2024 03:31:51 GMT"}],"updateDate":"2024-12-16","timestamp":1733090527000,"abstract":"  Decision transformers recast reinforcement learning as a conditional sequence\ngeneration problem, offering a simple but effective alternative to traditional\nvalue or policy-based methods. A recent key development in this area is the\nintegration of prompting in decision transformers to facilitate few-shot policy\ngeneralization. However, current methods mainly use static prompt segments to\nguide rollouts, limiting their ability to provide context-specific guidance.\nAddressing this, we introduce a hierarchical prompting approach enabled by\nretrieval augmentation. Our method learns two layers of soft tokens as guiding\nprompts: (1) global tokens encapsulating task-level information about\ntrajectories, and (2) adaptive tokens that deliver focused, timestep-specific\ninstructions. The adaptive tokens are dynamically retrieved from a curated set\nof demonstration segments, ensuring context-aware guidance. Experiments across\nseven benchmark tasks in the MuJoCo and MetaWorld environments demonstrate the\nproposed approach consistently outperforms all baseline methods, suggesting\nthat hierarchical prompting for decision transformers is an effective strategy\nto enable few-shot policy generalization.\n","subjects":["Computer Science/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"EpvBi8sUTwhqI0EnP35ZFj-aUunfTw5VDPlDk-CXnTU","pdfSize":"1809206"}