{
  "id": "2412.13698",
  "title": "Towards Efficient and Explainable Hate Speech Detection via Model\n  Distillation",
  "authors": "Paloma Piot, Javier Parapar",
  "authorsParsed": [
    [
      "Piot",
      "Paloma",
      ""
    ],
    [
      "Parapar",
      "Javier",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Wed, 18 Dec 2024 10:42:53 GMT"
    }
  ],
  "updateDate": "2024-12-19",
  "timestamp": 1734518573000,
  "abstract": "  Automatic detection of hate and abusive language is essential to combat its\nonline spread. Moreover, recognising and explaining hate speech serves to\neducate people about its negative effects. However, most current detection\nmodels operate as black boxes, lacking interpretability and explainability. In\nthis context, Large Language Models (LLMs) have proven effective for hate\nspeech detection and to promote interpretability. Nevertheless, they are\ncomputationally costly to run. In this work, we propose distilling big language\nmodels by using Chain-of-Thought to extract explanations that support the hate\nspeech classification task. Having small language models for these tasks will\ncontribute to their use in operational settings. In this paper, we demonstrate\nthat distilled models deliver explanations of the same quality as larger models\nwhile surpassing them in classification performance. This dual capability,\nclassifying and explaining, advances hate speech detection making it more\naffordable, understandable and actionable.\n",
  "subjects": [
    "Computer Science/Computation and Language"
  ],
  "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
  "blobId": "mq2RBCVCAX5EaHT5PmPpZVb4zBEqhVY-ES3B9qqwQf8",
  "pdfSize": "969549"
}