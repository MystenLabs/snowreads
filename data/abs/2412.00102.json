{
  "id": "2412.00102",
  "title": "ElectroVizQA: How well do Multi-modal LLMs perform in Electronics Visual\n  Question Answering?",
  "authors": "Pragati Shuddhodhan Meshram, Swetha Karthikeyan, Bhavya, Suma Bhat",
  "authorsParsed": [
    [
      "Meshram",
      "Pragati Shuddhodhan",
      ""
    ],
    [
      "Karthikeyan",
      "Swetha",
      ""
    ],
    [
      "Bhavya",
      "",
      ""
    ],
    [
      "Bhat",
      "Suma",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Wed, 27 Nov 2024 20:25:07 GMT"
    }
  ],
  "updateDate": "2024-12-03",
  "timestamp": 1732739107000,
  "abstract": "  Multi-modal Large Language Models (MLLMs) are gaining significant attention\nfor their ability to process multi-modal data, providing enhanced contextual\nunderstanding of complex problems. MLLMs have demonstrated exceptional\ncapabilities in tasks such as Visual Question Answering (VQA); however, they\noften struggle with fundamental engineering problems, and there is a scarcity\nof specialized datasets for training on topics like digital electronics. To\naddress this gap, we propose a benchmark dataset called ElectroVizQA\nspecifically designed to evaluate MLLMs' performance on digital electronic\ncircuit problems commonly found in undergraduate curricula. This dataset, the\nfirst of its kind tailored for the VQA task in digital electronics, comprises\napproximately 626 visual questions, offering a comprehensive overview of\ndigital electronics topics. This paper rigorously assesses the extent to which\nMLLMs can understand and solve digital electronic circuit questions, providing\ninsights into their capabilities and limitations within this specialized\ndomain. By introducing this benchmark dataset, we aim to motivate further\nresearch and development in the application of MLLMs to engineering education,\nultimately bridging the performance gap and enhancing the efficacy of these\nmodels in technical fields.\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition",
    "Computer Science/Computation and Language",
    "Computer Science/Machine Learning"
  ],
  "license": "http://creativecommons.org/licenses/by-sa/4.0/",
  "blobId": "bgVhkbjS2Ktdkfku4pjlIcswSlOzCPVFCQ3ATojoSIA",
  "pdfSize": "2795787"
}