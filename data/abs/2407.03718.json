{"id":"2407.03718","title":"Multi-Convformer: Extending Conformer with Multiple Convolution Kernels","authors":"Darshan Prabhu, Yifan Peng, Preethi Jyothi, Shinji Watanabe","authorsParsed":[["Prabhu","Darshan",""],["Peng","Yifan",""],["Jyothi","Preethi",""],["Watanabe","Shinji",""]],"versions":[{"version":"v1","created":"Thu, 4 Jul 2024 08:08:12 GMT"},{"version":"v2","created":"Wed, 24 Jul 2024 02:03:47 GMT"}],"updateDate":"2024-07-25","timestamp":1720080492000,"abstract":"  Convolutions have become essential in state-of-the-art end-to-end Automatic\nSpeech Recognition~(ASR) systems due to their efficient modelling of local\ncontext. Notably, its use in Conformers has led to superior performance\ncompared to vanilla Transformer-based ASR systems. While components other than\nthe convolution module in the Conformer have been reexamined, altering the\nconvolution module itself has been far less explored. Towards this, we\nintroduce Multi-Convformer that uses multiple convolution kernels within the\nconvolution module of the Conformer in conjunction with gating. This helps in\nimproved modeling of local dependencies at varying granularities. Our model\nrivals existing Conformer variants such as CgMLP and E-Branchformer in\nperformance, while being more parameter efficient. We empirically compare our\napproach with Conformer and its variants across four different datasets and\nthree different modelling paradigms and show up to 8% relative word error\nrate~(WER) improvements.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning","Computing Research Repository/Sound","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by-sa/4.0/","blobId":"oxf4q58wsNWBBZk8ekB4mmNxbxFhj92ULwFfRKSbioU","pdfSize":"1249826"}