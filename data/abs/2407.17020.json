{"id":"2407.17020","title":"EAFormer: Scene Text Segmentation with Edge-Aware Transformers","authors":"Haiyang Yu, Teng Fu, Bin Li, Xiangyang Xue","authorsParsed":[["Yu","Haiyang",""],["Fu","Teng",""],["Li","Bin",""],["Xue","Xiangyang",""]],"versions":[{"version":"v1","created":"Wed, 24 Jul 2024 06:00:33 GMT"}],"updateDate":"2024-07-25","timestamp":1721800833000,"abstract":"  Scene text segmentation aims at cropping texts from scene images, which is\nusually used to help generative models edit or remove texts. The existing text\nsegmentation methods tend to involve various text-related supervisions for\nbetter performance. However, most of them ignore the importance of text edges,\nwhich are significant for downstream applications. In this paper, we propose\nEdge-Aware Transformers, termed EAFormer, to segment texts more accurately,\nespecially at the edge of texts. Specifically, we first design a text edge\nextractor to detect edges and filter out edges of non-text areas. Then, we\npropose an edge-guided encoder to make the model focus more on text edges.\nFinally, an MLP-based decoder is employed to predict text masks. We have\nconducted extensive experiments on commonly-used benchmarks to verify the\neffectiveness of EAFormer. The experimental results demonstrate that the\nproposed method can perform better than previous methods, especially on the\nsegmentation of text edges. Considering that the annotations of several\nbenchmarks (e.g., COCO_TS and MLT_S) are not accurate enough to fairly evaluate\nour methods, we have relabeled these datasets. Through experiments, we observe\nthat our method can achieve a higher performance improvement when more accurate\nannotations are used for training.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"BL8FT2riPlrS3xp1PbAphZx5xKcsj_8lGFFizEXfsi4","pdfSize":"4598396"}