{"id":"2407.15100","title":"A General Framework for Data-Use Auditing of ML Models","authors":"Zonghao Huang, Neil Zhenqiang Gong, Michael K. Reiter","authorsParsed":[["Huang","Zonghao",""],["Gong","Neil Zhenqiang",""],["Reiter","Michael K.",""]],"versions":[{"version":"v1","created":"Sun, 21 Jul 2024 09:32:34 GMT"},{"version":"v2","created":"Sun, 4 Aug 2024 05:55:40 GMT"}],"updateDate":"2024-08-06","timestamp":1721554354000,"abstract":"  Auditing the use of data in training machine-learning (ML) models is an\nincreasingly pressing challenge, as myriad ML practitioners routinely leverage\nthe effort of content creators to train models without their permission. In\nthis paper, we propose a general method to audit an ML model for the use of a\ndata-owner's data in training, without prior knowledge of the ML task for which\nthe data might be used. Our method leverages any existing black-box membership\ninference method, together with a sequential hypothesis test of our own design,\nto detect data use with a quantifiable, tunable false-detection rate. We show\nthe effectiveness of our proposed framework by applying it to audit data use in\ntwo types of ML models, namely image classifiers and foundation models.\n","subjects":["Computing Research Repository/Cryptography and Security","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"SUA7FWQI-w9o_EkCVjthd3Vat0bZNKif-_Nyt3HDntQ","pdfSize":"1223166","objectId":"0x5657f5254a8c8286885d3ac456dcf9250dd66fbea02a401f7dd5ed2aac25721e","registeredEpoch":"1","certifiedEpoch":"1","startEpoch":"1","endEpoch":"201"}
