{"id":"2412.12169","title":"Regulation of Language Models With Interpretability Will Likely Result\n  In A Performance Trade-Off","authors":"Eoin M. Kenny and Julie A. Shah","authorsParsed":[["Kenny","Eoin M.",""],["Shah","Julie A.",""]],"versions":[{"version":"v1","created":"Thu, 12 Dec 2024 02:11:06 GMT"}],"updateDate":"2024-12-18","timestamp":1733969466000,"abstract":"  Regulation is increasingly cited as the most important and pressing concern\nin machine learning. However, it is currently unknown how to implement this,\nand perhaps more importantly, how it would effect model performance alongside\nhuman collaboration if actually realized. In this paper, we attempt to answer\nthese questions by building a regulatable large-language model (LLM), and then\nquantifying how the additional constraints involved affect (1) model\nperformance, alongside (2) human collaboration. Our empirical results reveal\nthat it is possible to force an LLM to use human-defined features in a\ntransparent way, but a \"regulation performance trade-off\" previously not\nconsidered reveals itself in the form of a 7.34% classification performance\ndrop. Surprisingly however, we show that despite this, such systems actually\nimprove human task performance speed and appropriate confidence in a realistic\ndeployment setting compared to no AI assistance, thus paving a way for fair,\nregulatable AI, which benefits users.\n","subjects":["Computer Science/Machine Learning","Computer Science/Artificial Intelligence","Computer Science/Computers and Society"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"YDjfUTY_ub0VZc48_VKTsMeFBS2GED4AcmWEYRkymiM","pdfSize":"885778"}