{"id":"2412.13746","title":"RAG-RewardBench: Benchmarking Reward Models in Retrieval Augmented\n  Generation for Preference Alignment","authors":"Zhuoran Jin, Hongbang Yuan, Tianyi Men, Pengfei Cao, Yubo Chen, Kang\n  Liu, Jun Zhao","authorsParsed":[["Jin","Zhuoran",""],["Yuan","Hongbang",""],["Men","Tianyi",""],["Cao","Pengfei",""],["Chen","Yubo",""],["Liu","Kang",""],["Zhao","Jun",""]],"versions":[{"version":"v1","created":"Wed, 18 Dec 2024 11:28:05 GMT"}],"updateDate":"2024-12-19","timestamp":1734521285000,"abstract":"  Despite the significant progress made by existing retrieval augmented\nlanguage models (RALMs) in providing trustworthy responses and grounding in\nreliable sources, they often overlook effective alignment with human\npreferences. In the alignment process, reward models (RMs) act as a crucial\nproxy for human values to guide optimization. However, it remains unclear how\nto evaluate and select a reliable RM for preference alignment in RALMs. To this\nend, we propose RAG-RewardBench, the first benchmark for evaluating RMs in RAG\nsettings. First, we design four crucial and challenging RAG-specific scenarios\nto assess RMs, including multi-hop reasoning, fine-grained citation,\nappropriate abstain, and conflict robustness. Then, we incorporate 18 RAG\nsubsets, six retrievers, and 24 RALMs to increase the diversity of data\nsources. Finally, we adopt an LLM-as-a-judge approach to improve preference\nannotation efficiency and effectiveness, exhibiting a strong correlation with\nhuman annotations. Based on the RAG-RewardBench, we conduct a comprehensive\nevaluation of 45 RMs and uncover their limitations in RAG scenarios.\nAdditionally, we also reveal that existing trained RALMs show almost no\nimprovement in preference alignment, highlighting the need for a shift towards\npreference-aligned training.We release our benchmark and code publicly at\nhttps://huggingface.co/datasets/jinzhuoran/RAG-RewardBench/ for future work.\n","subjects":["Computer Science/Computation and Language","Computer Science/Artificial Intelligence","Computer Science/Information Retrieval"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"IbFXGe6IU-iP8dH1pg06AMVN-tYy9tSeHHESW-8RxW4","pdfSize":"1767448"}