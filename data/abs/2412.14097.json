{
  "id": "2412.14097",
  "title": "Adaptive Concept Bottleneck for Foundation Models Under Distribution\n  Shifts",
  "authors": "Jihye Choi, Jayaram Raghuram, Yixuan Li, Somesh Jha",
  "authorsParsed": [
    [
      "Choi",
      "Jihye",
      ""
    ],
    [
      "Raghuram",
      "Jayaram",
      ""
    ],
    [
      "Li",
      "Yixuan",
      ""
    ],
    [
      "Jha",
      "Somesh",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Wed, 18 Dec 2024 17:47:46 GMT"
    }
  ],
  "updateDate": "2024-12-19",
  "timestamp": 1734544066000,
  "abstract": "  Advancements in foundation models (FMs) have led to a paradigm shift in\nmachine learning. The rich, expressive feature representations from these\npre-trained, large-scale FMs are leveraged for multiple downstream tasks,\nusually via lightweight fine-tuning of a shallow fully-connected network\nfollowing the representation. However, the non-interpretable, black-box nature\nof this prediction pipeline can be a challenge, especially in critical domains\nsuch as healthcare, finance, and security. In this paper, we explore the\npotential of Concept Bottleneck Models (CBMs) for transforming complex,\nnon-interpretable foundation models into interpretable decision-making\npipelines using high-level concept vectors. Specifically, we focus on the\ntest-time deployment of such an interpretable CBM pipeline \"in the wild\", where\nthe input distribution often shifts from the original training distribution. We\nfirst identify the potential failure modes of such a pipeline under different\ntypes of distribution shifts. Then we propose an adaptive concept bottleneck\nframework to address these failure modes, that dynamically adapts the\nconcept-vector bank and the prediction layer based solely on unlabeled data\nfrom the target domain, without access to the source (training) dataset.\nEmpirical evaluations with various real-world distribution shifts show that our\nadaptation method produces concept-based interpretations better aligned with\nthe test data and boosts post-deployment accuracy by up to 28%, aligning the\nCBM performance with that of non-interpretable classification.\n",
  "subjects": [
    "Computer Science/Machine Learning",
    "Computer Science/Artificial Intelligence",
    "Computer Science/Computer Vision and Pattern Recognition"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "PYqrb9e9R_omw74rD6zFODY256yQz5xGWppcICIgAr0",
  "pdfSize": "3828695"
}