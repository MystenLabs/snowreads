{"id":"2412.03084","title":"Hybrid deep learning-based strategy for the hepatocellular carcinoma\n  cancer grade classification of H&E stained liver histopathology images","authors":"Ajinkya Deshpande, Deep Gupta, Ankit Bhurane, Nisha Meshram, Sneha\n  Singh, Petia Radeva","authorsParsed":[["Deshpande","Ajinkya",""],["Gupta","Deep",""],["Bhurane","Ankit",""],["Meshram","Nisha",""],["Singh","Sneha",""],["Radeva","Petia",""]],"versions":[{"version":"v1","created":"Wed, 4 Dec 2024 07:26:36 GMT"}],"updateDate":"2024-12-05","timestamp":1733297196000,"abstract":"  Hepatocellular carcinoma (HCC) is a common type of liver cancer whose\nearly-stage diagnosis is a common challenge, mainly due to the manual\nassessment of hematoxylin and eosin-stained whole slide images, which is a\ntime-consuming process and may lead to variability in decision-making. For\naccurate detection of HCC, we propose a hybrid deep learning-based architecture\nthat uses transfer learning to extract the features from pre-trained\nconvolutional neural network (CNN) models and a classifier made up of a\nsequence of fully connected layers. This study uses a publicly available The\nCancer Genome Atlas Hepatocellular Carcinoma (TCGA-LIHC)database (n=491) for\nmodel development and database of Kasturba Gandhi Medical College (KMC), India\nfor validation. The pre-processing step involves patch extraction, colour\nnormalization, and augmentation that results in 3920 patches for the TCGA\ndataset. The developed hybrid deep neural network consisting of a CNN-based\npre-trained feature extractor and a customized artificial neural network-based\nclassifier is trained using five-fold cross-validation. For this study, eight\ndifferent state-of-the-art models are trained and tested as feature extractors\nfor the proposed hybrid model. The proposed hybrid model with ResNet50-based\nfeature extractor provided the sensitivity, specificity, F1-score, accuracy,\nand AUC of 100.00%, 100.00%, 100.00%, 100.00%, and 1.00, respectively on the\nTCGA database. On the KMC database, EfficientNetb3 resulted in the optimal\nchoice of the feature extractor giving sensitivity, specificity, F1-score,\naccuracy, and AUC of 96.97, 98.85, 96.71, 96.71, and 0.99, respectively. The\nproposed hybrid models showed improvement in accuracy of 2% and 4% over the\npre-trained models in TCGA-LIHC and KMC databases.\n","subjects":["Electrical Engineering and Systems Science/Image and Video Processing","Computer Science/Computer Vision and Pattern Recognition","Computer Science/Machine Learning","Quantitative Biology/Quantitative Methods"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"mg11puGUG2KeLe60I4m_LE3fZFMOUyNCJnolF9ammgo","pdfSize":"5444862"}