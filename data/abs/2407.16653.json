{"id":"2407.16653","title":"Aggregated Attributions for Explanatory Analysis of 3D Segmentation\n  Models","authors":"Maciej Chrabaszcz and Hubert Baniecki and Piotr Komorowski and Szymon\n  P{\\l}otka and Przemyslaw Biecek","authorsParsed":[["Chrabaszcz","Maciej",""],["Baniecki","Hubert",""],["Komorowski","Piotr",""],["PÅ‚otka","Szymon",""],["Biecek","Przemyslaw",""]],"versions":[{"version":"v1","created":"Tue, 23 Jul 2024 17:14:01 GMT"},{"version":"v2","created":"Wed, 24 Jul 2024 07:18:46 GMT"}],"updateDate":"2024-07-25","timestamp":1721754841000,"abstract":"  Analysis of 3D segmentation models, especially in the context of medical\nimaging, is often limited to segmentation performance metrics that overlook the\ncrucial aspect of explainability and bias. Currently, effectively explaining\nthese models with saliency maps is challenging due to the high dimensions of\ninput images multiplied by the ever-growing number of segmented class labels.\nTo this end, we introduce Agg^2Exp, a methodology for aggregating fine-grained\nvoxel attributions of the segmentation model's predictions. Unlike classical\nexplanation methods that primarily focus on the local feature attribution,\nAgg^2Exp enables a more comprehensive global view on the importance of\npredicted segments in 3D images. Our benchmarking experiments show that\ngradient-based voxel attributions are more faithful to the model's predictions\nthan perturbation-based explanations. As a concrete use-case, we apply Agg^2Exp\nto discover knowledge acquired by the Swin UNEt TRansformer model trained on\nthe TotalSegmentator v2 dataset for segmenting anatomical structures in\ncomputed tomography medical images. Agg^2Exp facilitates the explanatory\nanalysis of large segmentation models beyond their predictive performance.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"It-De-4TAdlkPoE7H9GU-pmvkjkbktjN1OwIkTOzgOI","pdfSize":"29288175"}