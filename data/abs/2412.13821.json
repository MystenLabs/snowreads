{
  "id": "2412.13821",
  "title": "Towards Responsible Governing AI Proliferation",
  "authors": "Edward Kembery",
  "authorsParsed": [
    [
      "Kembery",
      "Edward",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Wed, 18 Dec 2024 13:10:35 GMT"
    }
  ],
  "updateDate": "2024-12-19",
  "timestamp": 1734527435000,
  "abstract": "  This paper argues that existing governance mechanisms for mitigating risks\nfrom AI systems are based on the `Big Compute' paradigm -- a set of assumptions\nabout the relationship between AI capabilities and infrastructure -- that may\nnot hold in the future. To address this, the paper introduces the\n`Proliferation' paradigm, which anticipates the rise of smaller, decentralized,\nopen-sourced AI models which are easier to augment, and easier to train without\nbeing detected. It posits that these developments are both probable and likely\nto introduce both benefits and novel risks that are difficult to mitigate\nthrough existing governance mechanisms. The final section explores governance\nstrategies to address these risks, focusing on access governance, decentralized\ncompute oversight, and information security. Whilst these strategies offer\npotential solutions, the paper acknowledges their limitations and cautions\ndevelopers to weigh benefits against developments that could lead to a\n`vulnerable world'.\n",
  "subjects": [
    "Computer Science/Computers and Society"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "_hIUg3gBiPoczQ4EEkuAwb6NyOg3RoohVho-ItqCgz4",
  "pdfSize": "727274"
}