{"id":"2407.08947","title":"Constructing Concept-based Models to Mitigate Spurious Correlations with\n  Minimal Human Effort","authors":"Jeeyung Kim, Ze Wang and Qiang Qiu","authorsParsed":[["Kim","Jeeyung",""],["Wang","Ze",""],["Qiu","Qiang",""]],"versions":[{"version":"v1","created":"Fri, 12 Jul 2024 03:07:28 GMT"}],"updateDate":"2024-07-15","timestamp":1720753648000,"abstract":"  Enhancing model interpretability can address spurious correlations by\nrevealing how models draw their predictions. Concept Bottleneck Models (CBMs)\ncan provide a principled way of disclosing and guiding model behaviors through\nhuman-understandable concepts, albeit at a high cost of human efforts in data\nannotation. In this paper, we leverage a synergy of multiple foundation models\nto construct CBMs with nearly no human effort. We discover undesirable biases\nin CBMs built on pre-trained models and propose a novel framework designed to\nexploit pre-trained models while being immune to these biases, thereby reducing\nvulnerability to spurious correlations. Specifically, our method offers a\nseamless pipeline that adopts foundation models for assessing potential\nspurious correlations in datasets, annotating concepts for images, and refining\nthe annotations for improved robustness. We evaluate the proposed method on\nmultiple datasets, and the results demonstrate its effectiveness in reducing\nmodel reliance on spurious correlations while preserving its interpretability.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"KBG2sLNZhvriBrOnGsu5r6IEN9Y5SzvBOjOcLqOQylQ","pdfSize":"5411229","objectId":"0x743affe115064ded238b424b520399ba8d0cec44f14e96150a0f9055e3b8081a","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
