{
  "id": "2412.04898",
  "title": "Mitigating Instance-Dependent Label Noise: Integrating Self-Supervised\n  Pretraining with Pseudo-Label Refinement",
  "authors": "Gouranga Bala, Anuj Gupta, Subrat Kumar Behera, Amit Sethi",
  "authorsParsed": [
    [
      "Bala",
      "Gouranga",
      ""
    ],
    [
      "Gupta",
      "Anuj",
      ""
    ],
    [
      "Behera",
      "Subrat Kumar",
      ""
    ],
    [
      "Sethi",
      "Amit",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Fri, 6 Dec 2024 09:56:49 GMT"
    }
  ],
  "updateDate": "2024-12-09",
  "timestamp": 1733479009000,
  "abstract": "  Deep learning models rely heavily on large volumes of labeled data to achieve\nhigh performance. However, real-world datasets often contain noisy labels due\nto human error, ambiguity, or resource constraints during the annotation\nprocess. Instance-dependent label noise (IDN), where the probability of a label\nbeing corrupted depends on the input features, poses a significant challenge\nbecause it is more prevalent and harder to address than instance-independent\nnoise. In this paper, we propose a novel hybrid framework that combines\nself-supervised learning using SimCLR with iterative pseudo-label refinement to\nmitigate the effects of IDN. The self-supervised pre-training phase enables the\nmodel to learn robust feature representations without relying on potentially\nnoisy labels, establishing a noise-agnostic foundation. Subsequently, we employ\nan iterative training process with pseudo-label refinement, where confidently\npredicted samples are identified through a multistage approach and their labels\nare updated to improve label quality progressively. We evaluate our method on\nthe CIFAR-10 and CIFAR-100 datasets augmented with synthetic instance-dependent\nnoise at varying noise levels. Experimental results demonstrate that our\napproach significantly outperforms several state-of-the-art methods,\nparticularly under high noise conditions, achieving notable improvements in\nclassification accuracy and robustness. Our findings suggest that integrating\nself-supervised learning with iterative pseudo-label refinement offers an\neffective strategy for training deep neural networks on noisy datasets\nafflicted by instance-dependent label noise.\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition",
    "Computer Science/Machine Learning"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "F4VxQWB2v6qux8Efzmx4SUeOgSwi4Eu-V1M6_nAismc",
  "pdfSize": "192271"
}