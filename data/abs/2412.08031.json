{
  "id": "2412.08031",
  "title": "Constrained Best Arm Identification in Grouped Bandits",
  "authors": "Sahil Dharod, Malyala Preethi Sravani, Sakshi Heda, Sharayu Moharir",
  "authorsParsed": [
    [
      "Dharod",
      "Sahil",
      ""
    ],
    [
      "Sravani",
      "Malyala Preethi",
      ""
    ],
    [
      "Heda",
      "Sakshi",
      ""
    ],
    [
      "Moharir",
      "Sharayu",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Wed, 11 Dec 2024 02:19:19 GMT"
    }
  ],
  "updateDate": "2024-12-12",
  "timestamp": 1733883559000,
  "abstract": "  We study a grouped bandit setting where each arm comprises multiple\nindependent sub-arms referred to as attributes. Each attribute of each arm has\nan independent stochastic reward. We impose the constraint that for an arm to\nbe deemed feasible, the mean reward of all its attributes should exceed a\nspecified threshold. The goal is to find the arm with the highest mean reward\naveraged across attributes among the set of feasible arms in the fixed\nconfidence setting. We first characterize a fundamental limit on the\nperformance of any policy. Following this, we propose a near-optimal confidence\ninterval-based policy to solve this problem and provide analytical guarantees\nfor the policy. We compare the performance of the proposed policy with that of\ntwo suitably modified versions of action elimination via simulations.\n",
  "subjects": [
    "Computer Science/Machine Learning"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "GFj01cDo9wa7MaEP5yfZAXcYT6rM9p9xAA4b44Aip38",
  "pdfSize": "255429"
}