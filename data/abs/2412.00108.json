{
  "id": "2412.00108",
  "title": "Act Now: A Novel Online Forecasting Framework for Large-Scale Streaming\n  Data",
  "authors": "Daojun Liang, Haixia Zhang, Jing Wang, Dongfeng Yuan and Minggao Zhang",
  "authorsParsed": [
    [
      "Liang",
      "Daojun",
      ""
    ],
    [
      "Zhang",
      "Haixia",
      ""
    ],
    [
      "Wang",
      "Jing",
      ""
    ],
    [
      "Yuan",
      "Dongfeng",
      ""
    ],
    [
      "Zhang",
      "Minggao",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Thu, 28 Nov 2024 01:39:45 GMT"
    }
  ],
  "updateDate": "2024-12-03",
  "timestamp": 1732757985000,
  "abstract": "  In this paper, we find that existing online forecasting methods have the\nfollowing issues: 1) They do not consider the update frequency of streaming\ndata and directly use labels (future signals) to update the model, leading to\ninformation leakage. 2) Eliminating information leakage can exacerbate concept\ndrift and online parameter updates can damage prediction accuracy. 3) Leaving\nout a validation set cuts off the model's continued learning. 4) Existing GPU\ndevices cannot support online learning of large-scale streaming data. To\naddress the above issues, we propose a novel online learning framework,\nAct-Now, to improve the online prediction on large-scale streaming data.\nFirstly, we introduce a Random Subgraph Sampling (RSS) algorithm designed to\nenable efficient model training. Then, we design a Fast Stream Buffer (FSB) and\na Slow Stream Buffer (SSB) to update the model online. FSB updates the model\nimmediately with the consistent pseudo- and partial labels to avoid information\nleakage. SSB updates the model in parallel using complete labels from earlier\ntimes. Further, to address concept drift, we propose a Label Decomposition\nmodel (Lade) with statistical and normalization flows. Lade forecasts both the\nstatistical variations and the normalized future values of the data,\nintegrating them through a combiner to produce the final predictions. Finally,\nwe propose to perform online updates on the validation set to ensure the\nconsistency of model learning on streaming data. Extensive experiments\ndemonstrate that the proposed Act-Now framework performs well on large-scale\nstreaming data, with an average 28.4% and 19.5% performance improvement,\nrespectively. Experiments can be reproduced via\nhttps://github.com/Anoise/Act-Now.\n",
  "subjects": [
    "Computer Science/Machine Learning"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "QiD_SWLB-QW8eYCGjPP9_w0_NMD_Aptrr24R1PNCor0",
  "pdfSize": "805859"
}