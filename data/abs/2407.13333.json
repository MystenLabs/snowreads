{"id":"2407.13333","title":"Using Speech Foundational Models in Loss Functions for Hearing Aid\n  Speech Enhancement","authors":"Robert Sutherland, George Close, Thomas Hain, Stefan Goetze, Jon\n  Barker","authorsParsed":[["Sutherland","Robert",""],["Close","George",""],["Hain","Thomas",""],["Goetze","Stefan",""],["Barker","Jon",""]],"versions":[{"version":"v1","created":"Thu, 18 Jul 2024 09:32:57 GMT"}],"updateDate":"2024-07-19","timestamp":1721295177000,"abstract":"  Machine learning techniques are an active area of research for speech\nenhancement for hearing aids, with one particular focus on improving the\nintelligibility of a noisy speech signal. Recent work has shown that feature\nencodings from self-supervised speech representation models can effectively\ncapture speech intelligibility. In this work, it is shown that the distance\nbetween self-supervised speech representations of clean and noisy speech\ncorrelates more strongly with human intelligibility ratings than other\nsignal-based metrics. Experiments show that training a speech enhancement model\nusing this distance as part of a loss function improves the performance over\nusing an SNR-based loss function, demonstrated by an increase in HASPI, STOI,\nPESQ and SI-SNR scores. This method takes inference of a high parameter count\nmodel only at training time, meaning the speech enhancement model can remain\nsmaller, as is required for hearing aids.\n","subjects":["Computing Research Repository/Sound","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"YnjiNw4EqNepd0Xz8eWwwHc9y-h0rjTdbTdW0ghm54Y","pdfSize":"2725323"}