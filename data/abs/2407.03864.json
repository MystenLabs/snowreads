{"id":"2407.03864","title":"Adversarial Robustness of VAEs across Intersectional Subgroups","authors":"Chethan Krishnamurthy Ramanaik, Arjun Roy, Eirini Ntoutsi","authorsParsed":[["Ramanaik","Chethan Krishnamurthy",""],["Roy","Arjun",""],["Ntoutsi","Eirini",""]],"versions":[{"version":"v1","created":"Thu, 4 Jul 2024 11:53:51 GMT"}],"updateDate":"2024-07-08","timestamp":1720094031000,"abstract":"  Despite advancements in Autoencoders (AEs) for tasks like dimensionality\nreduction, representation learning and data generation, they remain vulnerable\nto adversarial attacks. Variational Autoencoders (VAEs), with their\nprobabilistic approach to disentangling latent spaces, show stronger resistance\nto such perturbations compared to deterministic AEs; however, their resilience\nagainst adversarial inputs is still a concern. This study evaluates the\nrobustness of VAEs against non-targeted adversarial attacks by optimizing\nminimal sample-specific perturbations to cause maximal damage across diverse\ndemographic subgroups (combinations of age and gender). We investigate two\nquestions: whether there are robustness disparities among subgroups, and what\nfactors contribute to these disparities, such as data scarcity and\nrepresentation entanglement. Our findings reveal that robustness disparities\nexist but are not always correlated with the size of the subgroup. By using\ndownstream gender and age classifiers and examining latent embeddings, we\nhighlight the vulnerability of subgroups like older women, who are prone to\nmisclassification due to adversarial perturbations pushing their\nrepresentations toward those of other subgroups.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"Y_I550UCxhSWlH_tlvRyUvSRo4NGnDM-h1iKFpGof7c","pdfSize":"11403814"}