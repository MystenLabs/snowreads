{"id":"2412.01398","title":"Holistic Understanding of 3D Scenes as Universal Scene Description","authors":"Anna-Maria Halacheva, Yang Miao, Jan-Nico Zaech, Xi Wang, Luc Van\n  Gool, Danda Pani Paudel","authorsParsed":[["Halacheva","Anna-Maria",""],["Miao","Yang",""],["Zaech","Jan-Nico",""],["Wang","Xi",""],["Van Gool","Luc",""],["Paudel","Danda Pani",""]],"versions":[{"version":"v1","created":"Mon, 2 Dec 2024 11:33:55 GMT"}],"updateDate":"2024-12-03","timestamp":1733139235000,"abstract":"  3D scene understanding is a long-standing challenge in computer vision and a\nkey component in enabling mixed reality, wearable computing, and embodied AI.\nProviding a solution to these applications requires a multifaceted approach\nthat covers scene-centric, object-centric, as well as interaction-centric\ncapabilities. While there exist numerous datasets approaching the former two\nproblems, the task of understanding interactable and articulated objects is\nunderrepresented and only partly covered by current works. In this work, we\naddress this shortcoming and introduce (1) an expertly curated dataset in the\nUniversal Scene Description (USD) format, featuring high-quality manual\nannotations, for instance, segmentation and articulation on 280 indoor scenes;\n(2) a learning-based model together with a novel baseline capable of predicting\npart segmentation along with a full specification of motion attributes,\nincluding motion type, articulated and interactable parts, and motion\nparameters; (3) a benchmark serving to compare upcoming methods for the task at\nhand. Overall, our dataset provides 8 types of annotations - object and part\nsegmentations, motion types, movable and interactable parts, motion parameters,\nconnectivity, and object mass annotations. With its broad and high-quality\nannotations, the data provides the basis for holistic 3D scene understanding\nmodels. All data is provided in the USD format, allowing interoperability and\neasy integration with downstream tasks. We provide open access to our dataset,\nbenchmark, and method's source code.\n","subjects":["Computer Science/Computer Vision and Pattern Recognition","Computer Science/Robotics"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"WShJuPgBn2gOu6QUe12g6JZzdycE54kAHgRIB19vbu4","pdfSize":"10767289"}