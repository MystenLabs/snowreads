{"id":"2407.20959","title":"Learning Ordinality in Semantic Segmentation","authors":"Rafael Cristino and Ricardo P. M. Cruz and Jaime S. Cardoso","authorsParsed":[["Cristino","Rafael",""],["Cruz","Ricardo P. M.",""],["Cardoso","Jaime S.",""]],"versions":[{"version":"v1","created":"Tue, 30 Jul 2024 16:36:15 GMT"}],"updateDate":"2024-07-31","timestamp":1722357375000,"abstract":"  Semantic segmentation consists of predicting a semantic label for each image\npixel. Conventional deep learning models do not take advantage of ordinal\nrelations that might exist in the domain at hand. For example, it is known that\nthe pupil is inside the iris, and the lane markings are inside the road. Such\ndomain knowledge can be employed as constraints to make the model more robust.\nThe current literature on this topic has explored pixel-wise ordinal\nsegmentation methods, which treat each pixel as an independent observation and\npromote ordinality in its representation. This paper proposes novel spatial\nordinal segmentation methods, which take advantage of the structured image\nspace by considering each pixel as an observation dependent on its neighborhood\ncontext to also promote ordinal spatial consistency. When evaluated with five\nbiomedical datasets and multiple configurations of autonomous driving datasets,\nordinal methods resulted in more ordinally-consistent models, with substantial\nimprovements in ordinal metrics and some increase in the Dice coefficient. It\nwas also shown that the incorporation of ordinal consistency results in models\nwith better generalization abilities.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"WMpuUsFDnxCnqGVZSYn4txXL8MOiJbHymliooyqFOkk","pdfSize":"987563"}