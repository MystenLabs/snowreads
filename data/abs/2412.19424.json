{"id":"2412.19424","title":"Temporal Context Consistency Above All: Enhancing Long-Term Anticipation\n  by Learning and Enforcing Temporal Constraints","authors":"Alberto Mat\\'e, Mariella Dimiccoli","authorsParsed":[["Mat√©","Alberto",""],["Dimiccoli","Mariella",""]],"versions":[{"version":"v1","created":"Fri, 27 Dec 2024 03:29:10 GMT"}],"updateDate":"2024-12-30","timestamp":1735270150000,"abstract":"  This paper proposes a method for long-term action anticipation (LTA), the\ntask of predicting action labels and their duration in a video given the\nobservation of an initial untrimmed video interval. We build on an\nencoder-decoder architecture with parallel decoding and make two key\ncontributions. First, we introduce a bi-directional action context regularizer\nmodule on the top of the decoder that ensures temporal context coherence in\ntemporally adjacent segments. Second, we learn from classified segments a\ntransition matrix that models the probability of transitioning from one action\nto another and the sequence is optimized globally over the full prediction\ninterval. In addition, we use a specialized encoder for the task of action\nsegmentation to increase the quality of the predictions in the observation\ninterval at inference time, leading to a better understanding of the past. We\nvalidate our methods on four benchmark datasets for LTA, the EpicKitchen-55,\nEGTEA+, 50Salads and Breakfast demonstrating superior or comparable performance\nto state-of-the-art methods, including probabilistic models and also those\nbased on Large Language Models, that assume trimmed video as input. The code\nwill be released upon acceptance.\n","subjects":["Computer Science/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"99vTnLLIhpqLP-kuv-nuD2BCy6uC5mWtM9T-Lx5xv3I","pdfSize":"5473328"}