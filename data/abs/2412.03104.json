{
  "id": "2412.03104",
  "title": "ChatTS: Aligning Time Series with LLMs via Synthetic Data for Enhanced\n  Understanding and Reasoning",
  "authors": "Zhe Xie, Zeyan Li, Xiao He, Longlong Xu, Xidao Wen, Tieying Zhang,\n  Jianjun Chen, Rui Shi, Dan Pei",
  "authorsParsed": [
    [
      "Xie",
      "Zhe",
      ""
    ],
    [
      "Li",
      "Zeyan",
      ""
    ],
    [
      "He",
      "Xiao",
      ""
    ],
    [
      "Xu",
      "Longlong",
      ""
    ],
    [
      "Wen",
      "Xidao",
      ""
    ],
    [
      "Zhang",
      "Tieying",
      ""
    ],
    [
      "Chen",
      "Jianjun",
      ""
    ],
    [
      "Shi",
      "Rui",
      ""
    ],
    [
      "Pei",
      "Dan",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Wed, 4 Dec 2024 08:06:15 GMT"
    },
    {
      "version": "v2",
      "created": "Wed, 1 Jan 2025 07:23:17 GMT"
    }
  ],
  "updateDate": "2025-01-03",
  "timestamp": 1733299575000,
  "abstract": "  Understanding time series is crucial for its application in real-world\nscenarios. Recently, large language models (LLMs) have been increasingly\napplied to time series tasks, leveraging their strong language capabilities to\nenhance various applications. However, research on multimodal LLMs (MLLMs) for\ntime series understanding and reasoning remains limited, primarily due to the\nscarcity of high-quality datasets that align time series with textual\ninformation. This paper introduces ChatTS, a novel MLLM designed for time\nseries analysis. ChatTS treats time series as a modality, similar to how vision\nMLLMs process images, enabling it to perform both understanding and reasoning\nwith time series. To address the scarcity of training data, we propose an\nattribute-based method for generating synthetic time series with detailed\nattribute descriptions. We further introduce Time Series Evol-Instruct, a novel\napproach that generates diverse time series Q&As, enhancing the model's\nreasoning capabilities. To the best of our knowledge, ChatTS is the first\nTS-MLLM that takes multivariate time series as input for understanding and\nreasoning, which is fine-tuned exclusively on synthetic datasets. We evaluate\nits performance using benchmark datasets with real-world data, including six\nalignment tasks and four reasoning tasks. Our results show that ChatTS\nsignificantly outperforms existing vision-based MLLMs (e.g., GPT-4o) and\ntext/agent-based LLMs, achieving a 46.0% improvement in alignment tasks and a\n25.8% improvement in reasoning tasks.\n",
  "subjects": [
    "Computer Science/Artificial Intelligence"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "5Sew2t3kfuZTRqTfIKac3Z50HsU2lSgWEnUyFaaGiOQ",
  "pdfSize": "2872848"
}