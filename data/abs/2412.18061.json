{"id":"2412.18061","title":"Lla-VAP: LSTM Ensemble of Llama and VAP for Turn-Taking Prediction","authors":"Hyunbae Jeon and Frederic Guintu and Rayvant Sahni","authorsParsed":[["Jeon","Hyunbae",""],["Guintu","Frederic",""],["Sahni","Rayvant",""]],"versions":[{"version":"v1","created":"Tue, 24 Dec 2024 00:20:38 GMT"}],"updateDate":"2024-12-25","timestamp":1734999638000,"abstract":"  Turn-taking prediction is the task of anticipating when the speaker in a\nconversation will yield their turn to another speaker to begin speaking. This\nproject expands on existing strategies for turn-taking prediction by employing\na multi-modal ensemble approach that integrates large language models (LLMs)\nand voice activity projection (VAP) models. By combining the linguistic\ncapabilities of LLMs with the temporal precision of VAP models, we aim to\nimprove the accuracy and efficiency of identifying TRPs in both scripted and\nunscripted conversational scenarios. Our methods are evaluated on the\nIn-Conversation Corpus (ICC) and Coached Conversational Preference Elicitation\n(CCPE) datasets, highlighting the strengths and limitations of current models\nwhile proposing a potentially more robust framework for enhanced prediction.\n","subjects":["Computer Science/Sound","Computer Science/Computation and Language","Computer Science/Human-Computer Interaction","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"UrgB4TCzfk2LtKFi1sfz6XIrN_uugYS788rmSMeYZCY","pdfSize":"3443428"}