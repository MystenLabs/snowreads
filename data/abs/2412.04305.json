{"id":"2412.04305","title":"ALMA: Alignment with Minimal Annotation","authors":"Michihiro Yasunaga, Leonid Shamis, Chunting Zhou, Andrew Cohen, Jason\n  Weston, Luke Zettlemoyer, Marjan Ghazvininejad","authorsParsed":[["Yasunaga","Michihiro",""],["Shamis","Leonid",""],["Zhou","Chunting",""],["Cohen","Andrew",""],["Weston","Jason",""],["Zettlemoyer","Luke",""],["Ghazvininejad","Marjan",""]],"versions":[{"version":"v1","created":"Thu, 5 Dec 2024 16:26:31 GMT"}],"updateDate":"2024-12-06","timestamp":1733415991000,"abstract":"  Recent approaches to large language model (LLM) alignment typically require\nmillions of human annotations or rely on external aligned models for synthetic\ndata generation. This paper introduces ALMA: Alignment with Minimal Annotation,\ndemonstrating that effective alignment can be achieved using only 9,000 labeled\nexamples -- less than 1% of conventional approaches. ALMA generates large\namounts of high-quality synthetic alignment data through new techniques:\ndiverse prompt synthesis via few-shot learning, diverse response generation\nwith multiple model checkpoints, and judge (reward model) enhancement through\nscore aggregation and self-distillation. Using only a pretrained Llama3 base\nmodel, 5,000 SFT examples, and 4,000 judge annotations, ALMA achieves\nperformance close to Llama3-Instruct across diverse alignment benchmarks (e.g.,\n0.1% difference on AlpacaEval 2.0 score). These results are achieved with a\nmulti-round, self-bootstrapped data synthesis and training recipe that\ncontinues to improve for 10 rounds, surpassing the typical 3-round ceiling of\nprevious methods. These results suggest that base models already possess\nsufficient knowledge for effective alignment, and that synthetic data\ngeneration methods can expose it.\n","subjects":["Computer Science/Computation and Language","Computer Science/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"MUt8SrYpADjh5VZEJRlBOs8NEpU7yNM1i9UpzoWMo_A","pdfSize":"1010717"}