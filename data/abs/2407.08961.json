{"id":"2407.08961","title":"Tissue-Contrastive Semi-Masked Autoencoders for Segmentation Pretraining\n  on Chest CT","authors":"Jie Zheng, Ru Wen, Haiqin Hu, Lina Wei, Kui Su, Wei Chen, Chen Liu,\n  and Jun Wang","authorsParsed":[["Zheng","Jie",""],["Wen","Ru",""],["Hu","Haiqin",""],["Wei","Lina",""],["Su","Kui",""],["Chen","Wei",""],["Liu","Chen",""],["Wang","Jun",""]],"versions":[{"version":"v1","created":"Fri, 12 Jul 2024 03:24:17 GMT"}],"updateDate":"2024-07-15","timestamp":1720754657000,"abstract":"  Existing Masked Image Modeling (MIM) depends on a spatial patch-based\nmasking-reconstruction strategy to perceive objects'features from unlabeled\nimages, which may face two limitations when applied to chest CT: 1) inefficient\nfeature learning due to complex anatomical details presented in CT images, and\n2) suboptimal knowledge transfer owing to input disparity between upstream and\ndownstream models. To address these issues, we propose a new MIM method named\nTissue-Contrastive Semi-Masked Autoencoder (TCS-MAE) for modeling chest CT\nimages. Our method has two novel designs: 1) a tissue-based\nmasking-reconstruction strategy to capture more fine-grained anatomical\nfeatures, and 2) a dual-AE architecture with contrastive learning between the\nmasked and original image views to bridge the gap of the upstream and\ndownstream models. To validate our method, we systematically investigate\nrepresentative contrastive, generative, and hybrid self-supervised learning\nmethods on top of tasks involving segmenting pneumonia, mediastinal tumors, and\nvarious organs. The results demonstrate that, compared to existing methods, our\nTCS-MAE more effectively learns tissue-aware representations, thereby\nsignificantly enhancing segmentation performance across all tasks.\n","subjects":["Electrical Engineering and Systems Science/Image and Video Processing","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"kXWBfu_Oy2byUkDQIEol_YGgn-bX5CbKDHUjDgAhuBg","pdfSize":"1393564"}