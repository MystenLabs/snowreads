{
  "id": "2412.03304",
  "title": "Global MMLU: Understanding and Addressing Cultural and Linguistic Biases\n  in Multilingual Evaluation",
  "authors": "Shivalika Singh, Angelika Romanou, Cl\\'ementine Fourrier, David I.\n  Adelani, Jian Gang Ngui, Daniel Vila-Suero, Peerat Limkonchotiwat, Kelly\n  Marchisio, Wei Qi Leong, Yosephine Susanto, Raymond Ng, Shayne Longpre,\n  Wei-Yin Ko, Sebastian Ruder, Madeline Smith, Antoine Bosselut, Alice Oh,\n  Andre F. T. Martins, Leshem Choshen, Daphne Ippolito, Enzo Ferrante, Marzieh\n  Fadaee, Beyza Ermis, Sara Hooker",
  "authorsParsed": [
    [
      "Singh",
      "Shivalika",
      ""
    ],
    [
      "Romanou",
      "Angelika",
      ""
    ],
    [
      "Fourrier",
      "Cl√©mentine",
      ""
    ],
    [
      "Adelani",
      "David I.",
      ""
    ],
    [
      "Ngui",
      "Jian Gang",
      ""
    ],
    [
      "Vila-Suero",
      "Daniel",
      ""
    ],
    [
      "Limkonchotiwat",
      "Peerat",
      ""
    ],
    [
      "Marchisio",
      "Kelly",
      ""
    ],
    [
      "Leong",
      "Wei Qi",
      ""
    ],
    [
      "Susanto",
      "Yosephine",
      ""
    ],
    [
      "Ng",
      "Raymond",
      ""
    ],
    [
      "Longpre",
      "Shayne",
      ""
    ],
    [
      "Ko",
      "Wei-Yin",
      ""
    ],
    [
      "Ruder",
      "Sebastian",
      ""
    ],
    [
      "Smith",
      "Madeline",
      ""
    ],
    [
      "Bosselut",
      "Antoine",
      ""
    ],
    [
      "Oh",
      "Alice",
      ""
    ],
    [
      "Martins",
      "Andre F. T.",
      ""
    ],
    [
      "Choshen",
      "Leshem",
      ""
    ],
    [
      "Ippolito",
      "Daphne",
      ""
    ],
    [
      "Ferrante",
      "Enzo",
      ""
    ],
    [
      "Fadaee",
      "Marzieh",
      ""
    ],
    [
      "Ermis",
      "Beyza",
      ""
    ],
    [
      "Hooker",
      "Sara",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Wed, 4 Dec 2024 13:27:09 GMT"
    },
    {
      "version": "v2",
      "created": "Wed, 19 Feb 2025 13:30:23 GMT"
    }
  ],
  "updateDate": "2025-02-20",
  "timestamp": 1733318829000,
  "abstract": "  Cultural biases in multilingual datasets pose significant challenges for\ntheir effectiveness as global benchmarks. These biases stem not only from\ndifferences in language but also from the cultural knowledge required to\ninterpret questions, reducing the practical utility of translated datasets like\nMMLU. Furthermore, translation often introduces artefacts that can distort the\nmeaning or clarity of questions in the target language. A common practice in\nmultilingual evaluation is to rely on machine-translated evaluation sets, but\nsimply translating a dataset is insufficient to address these challenges. In\nthis work, we trace the impact of both of these issues on multilingual\nevaluations and ensuing model performances. Our large-scale evaluation of\nstate-of-the-art open and proprietary models illustrates that progress on MMLU\ndepends heavily on learning Western-centric concepts, with 28% of all questions\nrequiring culturally sensitive knowledge. Moreover, for questions requiring\ngeographic knowledge, an astounding 84.9% focus on either North American or\nEuropean regions. Rankings of model evaluations change depending on whether\nthey are evaluated on the full portion or the subset of questions annotated as\nculturally sensitive, showing the distortion to model rankings when blindly\nrelying on translated MMLU. We release Global MMLU, an improved MMLU with\nevaluation coverage across 42 languages -- with improved overall quality by\nengaging with compensated professional and community annotators to verify\ntranslation quality while also rigorously evaluating cultural biases present in\nthe original dataset. This comprehensive Global MMLU set also includes\ndesignated subsets labeled as culturally sensitive and culturally agnostic to\nallow for more holistic, complete evaluation.\n",
  "subjects": [
    "Computer Science/Computation and Language"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "CtkySw9_intSXCQtSg88-QxM-De8qbY2J78UdKXrOVo",
  "pdfSize": "7522029"
}