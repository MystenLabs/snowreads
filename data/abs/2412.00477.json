{"id":"2412.00477","title":"LineGS : 3D Line Segment Representation on 3D Gaussian Splatting","authors":"Chenggang Yang, Yuang Shi","authorsParsed":[["Yang","Chenggang",""],["Shi","Yuang",""]],"versions":[{"version":"v1","created":"Sat, 30 Nov 2024 13:29:36 GMT"},{"version":"v2","created":"Wed, 11 Dec 2024 15:26:17 GMT"},{"version":"v3","created":"Fri, 13 Dec 2024 06:57:07 GMT"}],"updateDate":"2024-12-16","timestamp":1732973376000,"abstract":"  Abstract representations of 3D scenes play a crucial role in computer vision,\nenabling a wide range of applications such as mapping, localization, surface\nreconstruction, and even advanced tasks like SLAM and rendering. Among these\nrepresentations, line segments are widely used because of their ability to\nsuccinctly capture the structural features of a scene. However, existing 3D\nreconstruction methods often face significant challenges. Methods relying on 2D\nprojections suffer from instability caused by errors in multi-view matching and\nocclusions, while direct 3D approaches are hampered by noise and sparsity in 3D\npoint cloud data. This paper introduces LineGS, a novel method that combines\ngeometry-guided 3D line reconstruction with a 3D Gaussian splatting model to\naddress these challenges and improve representation ability. The method\nleverages the high-density Gaussian point distributions along the edge of the\nscene to refine and optimize initial line segments generated from traditional\ngeometric approaches. By aligning these segments with the underlying geometric\nfeatures of the scene, LineGS achieves a more precise and reliable\nrepresentation of 3D structures. The results show significant improvements in\nboth geometric accuracy and model compactness compared to baseline methods.\n","subjects":["Computer Science/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"lmbGbmTsdsXjWl3NQ2L8q8sJzp3e_todyyePBVv3Myk","pdfSize":"16508853"}