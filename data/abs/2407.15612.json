{"id":"2407.15612","title":"Can GPT-4 learn to analyze moves in research article abstracts?","authors":"Danni Yu, Marina Bondi, Ken Hyland","authorsParsed":[["Yu","Danni",""],["Bondi","Marina",""],["Hyland","Ken",""]],"versions":[{"version":"v1","created":"Mon, 22 Jul 2024 13:14:27 GMT"},{"version":"v2","created":"Wed, 24 Jul 2024 21:10:24 GMT"}],"updateDate":"2024-07-26","timestamp":1721654067000,"abstract":"  One of the most powerful and enduring ideas in written discourse analysis is\nthat genres can be described in terms of the moves which structure a writer's\npurpose. Considerable research has sought to identify these distinct\ncommunicative acts, but analyses have been beset by problems of subjectivity,\nreliability and the time-consuming need for multiple coders to confirm\nanalyses. In this paper we employ the affordances of GPT-4 to automate the\nannotation process by using natural language prompts. Focusing on abstracts\nfrom articles in four applied linguistics journals, we devise prompts which\nenable the model to identify moves effectively. The annotated outputs of these\nprompts were evaluated by two assessors with a third addressing disagreements.\nThe results show that an 8-shot prompt was more effective than one using two,\nconfirming that the inclusion of examples illustrating areas of variability can\nenhance GPT-4's ability to recognize multiple moves in a single sentence and\nreduce bias related to textual position. We suggest that GPT-4 offers\nconsiderable potential in automating this annotation process, when human actors\nwith domain specific linguistic expertise inform the prompting process.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"2uFExKm5Dzflx9Z2vguNSVPGEnxs0S3HmJRKu3R7REQ","pdfSize":"660161"}