{"id":"2412.11736","title":"Personalized LLM for Generating Customized Responses to the Same Query\n  from Different Users","authors":"Hang Zeng, Chaoyue Niu, Fan Wu, Chengfei Lv, Guihai Chen","authorsParsed":[["Zeng","Hang",""],["Niu","Chaoyue",""],["Wu","Fan",""],["Lv","Chengfei",""],["Chen","Guihai",""]],"versions":[{"version":"v1","created":"Mon, 16 Dec 2024 12:57:19 GMT"}],"updateDate":"2024-12-17","timestamp":1734353839000,"abstract":"  Existing work on large language model (LLM) personalization assigned\ndifferent responding roles to LLM, but overlooked the diversity of questioners.\nIn this work, we propose a new form of questioner-aware LLM personalization,\ngenerating different responses even for the same query from different\nquestioners. We design a dual-tower model architecture with a cross-questioner\ngeneral encoder and a questioner-specific encoder. We further apply contrastive\nlearning with multi-view augmentation, pulling close the dialogue\nrepresentations of the same questioner, while pulling apart those of different\nquestioners. To mitigate the impact of question diversity on\nquestioner-contrastive learning, we cluster the dialogues based on question\nsimilarity and restrict the scope of contrastive learning within each cluster.\nWe also build a multi-questioner dataset from English and Chinese scripts and\nWeChat records, called MQDialog, containing 173 questioners and 12 responders.\nExtensive evaluation with different metrics shows a significant improvement in\nthe quality of personalized response generation.\n","subjects":["Computer Science/Computation and Language"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"q8QRcY8nsx84zTcUKR2MyNrDJTrRu2PcAvRBVk8f9m8","pdfSize":"1724792"}