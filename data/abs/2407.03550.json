{"id":"2407.03550","title":"CoMix: A Comprehensive Benchmark for Multi-Task Comic Understanding","authors":"Emanuele Vivoli, Marco Bertini, Dimosthenis Karatzas","authorsParsed":[["Vivoli","Emanuele",""],["Bertini","Marco",""],["Karatzas","Dimosthenis",""]],"versions":[{"version":"v1","created":"Thu, 4 Jul 2024 00:07:50 GMT"}],"updateDate":"2024-07-08","timestamp":1720051670000,"abstract":"  The comic domain is rapidly advancing with the development of single-page\nanalysis and synthesis models. However, evaluation metrics and datasets lag\nbehind, often limited to small-scale or single-style test sets. We introduce a\nnovel benchmark, CoMix, designed to evaluate the multi-task capabilities of\nmodels in comic analysis. Unlike existing benchmarks that focus on isolated\ntasks such as object detection or text recognition, CoMix addresses a broader\nrange of tasks including object detection, speaker identification, character\nre-identification, reading order, and multi-modal reasoning tasks like\ncharacter naming and dialogue generation. Our benchmark comprises three\nexisting datasets with expanded annotations to support multi-task evaluation.\nTo mitigate the over-representation of manga-style data, we have incorporated a\nnew dataset of carefully selected American comic-style books, thereby enriching\nthe diversity of comic styles. CoMix is designed to assess pre-trained models\nin zero-shot and limited fine-tuning settings, probing their transfer\ncapabilities across different comic styles and tasks. The validation split of\nthe benchmark is publicly available for research purposes, and an evaluation\nserver for the held-out test split is also provided. Comparative results\nbetween human performance and state-of-the-art models reveal a significant\nperformance gap, highlighting substantial opportunities for advancements in\ncomic understanding. The dataset, baseline models, and code are accessible at\nthe repository link. This initiative sets a new standard for comprehensive\ncomic analysis, providing the community with a common benchmark for evaluation\non a large and varied set.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"DzQj17Gt-x15jjHuO-GZzLlxRAdz307ZwncWOT7-3z0","pdfSize":"22236987"}