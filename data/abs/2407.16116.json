{"id":"2407.16116","title":"Robust and consistent model evaluation criteria in high-dimensional\n  regression","authors":"Sumito Kurata, Kei Hirose","authorsParsed":[["Kurata","Sumito",""],["Hirose","Kei",""]],"versions":[{"version":"v1","created":"Tue, 23 Jul 2024 01:38:31 GMT"},{"version":"v2","created":"Wed, 24 Jul 2024 14:44:45 GMT"}],"updateDate":"2024-07-25","timestamp":1721698711000,"abstract":"  In the last two decades, sparse regularization methods such as the LASSO have\nbeen applied in various fields. Most of the regularization methods have one or\nmore regularization parameters, and to select the value of the regularization\nparameter is essentially equal to select a model, thus we need to determine the\nregularization parameter adequately. Regarding the determination of the\nregularization parameter in the linear regression model, we often apply the\ninformation criteria like the AIC and BIC, however, it has been pointed out\nthat these criteria are sensitive to outliers and tend not to perform well in\nhigh-dimensional settings. Outliers generally have a negative influence on not\nonly estimation but also model selection, consequently, it is important to\nemploy a selection method that is robust against outliers. In addition, when\nthe number of explanatory variables is quite large, most conventional criteria\nare prone to select unnecessary explanatory variables. In this paper, we\npropose model evaluation criteria via the statistical divergence with\nexcellence in robustness in both of parametric estimation and model selection.\nFurthermore, our proposed criteria simultaneously achieve the selection\nconsistency with the robustness even in high-dimensional settings. We also\nreport the results of some numerical examples to verify that the proposed\ncriteria perform robust and consistent variable selection compared with the\nconventional selection methods.\n","subjects":["Statistics/Methodology"],"license":"http://creativecommons.org/licenses/by-sa/4.0/","blobId":"ErE1Df-H-aPhB_m-4rh4W-Or7R8x7pnBqKiOkmOZ_Q8","pdfSize":"531943"}