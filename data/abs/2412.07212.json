{"id":"2412.07212","title":"A Distributed Deep Koopman Learning Algorithm for Control","authors":"Wenjian Hao, Zehui Lu, Devesh Upadhyay, Shaoshuai Mou","authorsParsed":[["Hao","Wenjian",""],["Lu","Zehui",""],["Upadhyay","Devesh",""],["Mou","Shaoshuai",""]],"versions":[{"version":"v1","created":"Tue, 10 Dec 2024 06:08:57 GMT"}],"updateDate":"2024-12-11","timestamp":1733810937000,"abstract":"  This paper proposes a distributed data-driven framework to address the\nchallenge of dynamics learning from a large amount of training data for optimal\ncontrol purposes, named distributed deep Koopman learning for control (DDKC).\nSuppose a system states-inputs trajectory and a multi-agent system (MAS), the\nkey idea of DDKC is to assign each agent in MAS an offline partial trajectory,\nand each agent approximates the unknown dynamics linearly relying on the deep\nneural network (DNN) and Koopman operator theory by communicating information\nwith other agents to reach a consensus of the approximated dynamics for all\nagents in MAS. Simulations on a surface vehicle first show that the proposed\nmethod achieves the consensus in terms of the learned dynamics and the learned\ndynamics from each agent can achieve reasonably small estimation errors over\nthe testing data. Furthermore, simulations in combination with model predictive\ncontrol (MPC) to drive the surface vehicle for goal-tracking and\nstation-keeping tasks demonstrate the learned dynamics from DDKC are precise\nenough to be used for the optimal control design.\n","subjects":["Electrical Engineering and Systems Science/Systems and Control","Computer Science/Systems and Control"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"WXFaMrTd8tWOvnamMr4O-Z41K9UzOeiuF_c5IAc627I","pdfSize":"676179"}