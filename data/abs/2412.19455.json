{"id":"2412.19455","title":"NijiGAN: Transform What You See into Anime with Contrastive\n  Semi-Supervised Learning and Neural Ordinary Differential Equations","authors":"Kevin Putra Santoso, Anny Yuniarti, Dwiyasa Nakula, Dimas Prihady\n  Setyawan, Adam Haidar Azizi, Jeany Aurellia P. Dewati, Farah Dhia Fadhila,\n  Maria T. Elvara Bumbungan","authorsParsed":[["Santoso","Kevin Putra",""],["Yuniarti","Anny",""],["Nakula","Dwiyasa",""],["Setyawan","Dimas Prihady",""],["Azizi","Adam Haidar",""],["Dewati","Jeany Aurellia P.",""],["Fadhila","Farah Dhia",""],["Bumbungan","Maria T. Elvara",""]],"versions":[{"version":"v1","created":"Fri, 27 Dec 2024 04:46:44 GMT"}],"updateDate":"2024-12-30","timestamp":1735274804000,"abstract":"  Generative AI has transformed the animation industry. Several models have\nbeen developed for image-to-image translation, particularly focusing on\nconverting real-world images into anime through unpaired translation.\nScenimefy, a notable approach utilizing contrastive learning, achieves high\nfidelity anime scene translation by addressing limited paired data through\nsemi-supervised training. However, it faces limitations due to its reliance on\npaired data from a fine-tuned StyleGAN in the anime domain, often producing\nlow-quality datasets. Additionally, Scenimefy's high parameter architecture\npresents opportunities for computational optimization. This research introduces\nNijiGAN, a novel model incorporating Neural Ordinary Differential Equations\n(NeuralODEs), which offer unique advantages in continuous transformation\nmodeling compared to traditional residual networks. NijiGAN successfully\ntransforms real-world scenes into high fidelity anime visuals using half of\nScenimefy's parameters. It employs pseudo-paired data generated through\nScenimefy for supervised training, eliminating dependence on low-quality paired\ndata and improving the training process. Our comprehensive evaluation includes\nablation studies, qualitative, and quantitative analysis comparing NijiGAN to\nsimilar models. The testing results demonstrate that NijiGAN produces\nhigher-quality images compared to AnimeGAN, as evidenced by a Mean Opinion\nScore (MOS) of 2.192, it surpasses AnimeGAN's MOS of 2.160. Furthermore, our\nmodel achieved a Frechet Inception Distance (FID) score of 58.71, outperforming\nScenimefy's FID score of 60.32. These results demonstrate that NijiGAN achieves\ncompetitive performance against existing state-of-the-arts, especially\nScenimefy as the baseline model.\n","subjects":["Computer Science/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-sa/4.0/","blobId":"WlIfG-Fwd61ER9ZtAfDYpxJ5X234tCa8bfNdI5nuykE","pdfSize":"14237135"}