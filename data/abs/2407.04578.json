{"id":"2407.04578","title":"Resource-Efficient Speech Quality Prediction through Quantization Aware\n  Training and Binary Activation Maps","authors":"Mattias Nilsson, Riccardo Miccini, Cl\\'ement Laroche, Tobias\n  Piechowiak, and Friedemann Zenke","authorsParsed":[["Nilsson","Mattias",""],["Miccini","Riccardo",""],["Laroche","Cl√©ment",""],["Piechowiak","Tobias",""],["Zenke","Friedemann",""]],"versions":[{"version":"v1","created":"Fri, 5 Jul 2024 15:15:00 GMT"}],"updateDate":"2024-07-08","timestamp":1720192500000,"abstract":"  As speech processing systems in mobile and edge devices become more\ncommonplace, the demand for unintrusive speech quality monitoring increases.\nDeep learning methods provide high-quality estimates of objective and\nsubjective speech quality metrics. However, their significant computational\nrequirements are often prohibitive on resource-constrained devices. To address\nthis issue, we investigated binary activation maps (BAMs) for speech quality\nprediction on a convolutional architecture based on DNSMOS. We show that the\nbinary activation model with quantization aware training matches the predictive\nperformance of the baseline model. It further allows using other compression\ntechniques. Combined with 8-bit weight quantization, our approach results in a\n25-fold memory reduction during inference, while replacing almost all dot\nproducts with summations. Our findings show a path toward substantial resource\nsavings by supporting mixed-precision binary multiplication in hard- and\nsoftware.\n","subjects":["Computing Research Repository/Sound","Computing Research Repository/Neural and Evolutionary Computing","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"mbEqKTDcdKWDMhCWhcedAf5NYHEjgYvzXPUT0V3AL4w","pdfSize":"284754"}