{"id":"2407.12879","title":"Large Visual-Language Models Are Also Good Classifiers: A Study of\n  In-Context Multimodal Fake News Detection","authors":"Ye Jiang and Yimin Wang","authorsParsed":[["Jiang","Ye",""],["Wang","Yimin",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 09:28:23 GMT"},{"version":"v2","created":"Tue, 20 Aug 2024 00:57:55 GMT"}],"updateDate":"2024-08-21","timestamp":1721122103000,"abstract":"  Large visual-language models (LVLMs) exhibit exceptional performance in\nvisual-language reasoning across diverse cross-modal benchmarks. Despite these\nadvances, recent research indicates that Large Language Models (LLMs), like\nGPT-3.5-turbo, underachieve compared to well-trained smaller models, such as\nBERT, in Fake News Detection (FND), prompting inquiries into LVLMs' efficacy in\nFND tasks. Although performance could improve through fine-tuning LVLMs, the\nsubstantial parameters and requisite pre-trained weights render it a\nresource-heavy endeavor for FND applications. This paper initially assesses the\nFND capabilities of two notable LVLMs, CogVLM and GPT4V, in comparison to a\nsmaller yet adeptly trained CLIP model in a zero-shot context. The findings\ndemonstrate that LVLMs can attain performance competitive with that of the\nsmaller model. Next, we integrate standard in-context learning (ICL) with\nLVLMs, noting improvements in FND performance, though limited in scope and\nconsistency. To address this, we introduce the \\textbf{I}n-context\n\\textbf{M}ultimodal \\textbf{F}ake \\textbf{N}ews \\textbf{D}etection (IMFND)\nframework, enriching in-context examples and test inputs with predictions and\ncorresponding probabilities from a well-trained smaller model. This strategic\nintegration directs the LVLMs' focus towards news segments associated with\nhigher probabilities, thereby improving their analytical accuracy. The\nexperimental results suggest that the IMFND framework significantly boosts the\nFND efficiency of LVLMs, achieving enhanced accuracy over the standard ICL\napproach across three publicly available FND datasets.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"TGcvn4j4qOd27588Gl79PinJ_EHdrvw_88agqx8n-sU","pdfSize":"1240073","objectId":"0x4d5bc464b5c0b6dd53f9b18af0bdf1a5946988c53a2763606c75d9f09df205e3","registeredEpoch":"3","certifiedEpoch":"3","startEpoch":"3","endEpoch":"203"}
