{"id":"2412.08602","title":"Empirical Measurements of AI Training Power Demand on a GPU-Accelerated\n  Node","authors":"Imran Latif, Alex C. Newkirk, Matthew R. Carbone, Arslan Munir, Yuewei\n  Lin, Jonathan Koomey, Xi Yu, Zhiuha Dong","authorsParsed":[["Latif","Imran",""],["Newkirk","Alex C.",""],["Carbone","Matthew R.",""],["Munir","Arslan",""],["Lin","Yuewei",""],["Koomey","Jonathan",""],["Yu","Xi",""],["Dong","Zhiuha",""]],"versions":[{"version":"v1","created":"Wed, 11 Dec 2024 18:19:07 GMT"},{"version":"v2","created":"Fri, 20 Dec 2024 16:46:20 GMT"}],"updateDate":"2024-12-23","timestamp":1733941147000,"abstract":"  The expansion of artificial intelligence (AI) applications has driven\nsubstantial investment in computational infrastructure, especially by cloud\ncomputing providers. Quantifying the energy footprint of this infrastructure\nrequires models parameterized by the power demand of AI hardware during\ntraining. We empirically measured the instantaneous power draw of an 8-GPU\nNVIDIA H100 HGX node during the training of open-source image classifier\n(ResNet) and large-language models (Llama2-13b). The maximum observed power\ndraw was approximately 8.4 kW, 18% lower than the manufacturer-rated 10.2 kW,\neven with GPUs near full utilization. Holding model architecture constant,\nincreasing batch size from 512 to 4096 images for ResNet reduced total training\nenergy consumption by a factor of 4. These findings can inform capacity\nplanning for data center operators and energy use estimates by researchers.\nFuture work will investigate the impact of cooling technology and carbon-aware\nscheduling on AI workload energy consumption.\n","subjects":["Computer Science/Hardware Architecture"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"XRKmeuwf5ZSUMdp5iJeHI5SnkqFVuS_4F45LpARTaVY","pdfSize":"307246"}