{"id":"2407.06935","title":"Bayesian Federated Learning with Hamiltonian Monte Carlo: Algorithm and\n  Theory","authors":"Jiajun Liang, Qian Zhang, Wei Deng, Qifan Song, Guang Lin","authorsParsed":[["Liang","Jiajun",""],["Zhang","Qian",""],["Deng","Wei",""],["Song","Qifan",""],["Lin","Guang",""]],"versions":[{"version":"v1","created":"Tue, 9 Jul 2024 15:10:59 GMT"}],"updateDate":"2024-07-10","timestamp":1720537859000,"abstract":"  This work introduces a novel and efficient Bayesian federated learning\nalgorithm, namely, the Federated Averaging stochastic Hamiltonian Monte Carlo\n(FA-HMC), for parameter estimation and uncertainty quantification. We establish\nrigorous convergence guarantees of FA-HMC on non-iid distributed data sets,\nunder the strong convexity and Hessian smoothness assumptions. Our analysis\ninvestigates the effects of parameter space dimension, noise on gradients and\nmomentum, and the frequency of communication (between the central node and\nlocal nodes) on the convergence and communication costs of FA-HMC. Beyond that,\nwe establish the tightness of our analysis by showing that the convergence rate\ncannot be improved even for continuous FA-HMC process. Moreover, extensive\nempirical studies demonstrate that FA-HMC outperforms the existing Federated\nAveraging-Langevin Monte Carlo (FA-LD) algorithm.\n","subjects":["Computing Research Repository/Machine Learning","Statistics/Computation","Statistics/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"ndJWozq5EtA2p9fOFy0jXbSmAZj-RYxbrxfeAhJ75WI","pdfSize":"828439"}