{"id":"2407.00626","title":"Maximum Entropy Inverse Reinforcement Learning of Diffusion Models with\n  Energy-Based Models","authors":"Sangwoong Yoon, Himchan Hwang, Dohyun Kwon, Yung-Kyun Noh, Frank C.\n  Park","authorsParsed":[["Yoon","Sangwoong",""],["Hwang","Himchan",""],["Kwon","Dohyun",""],["Noh","Yung-Kyun",""],["Park","Frank C.",""]],"versions":[{"version":"v1","created":"Sun, 30 Jun 2024 08:52:17 GMT"}],"updateDate":"2024-07-02","timestamp":1719737537000,"abstract":"  We present a maximum entropy inverse reinforcement learning (IRL) approach\nfor improving the sample quality of diffusion generative models, especially\nwhen the number of generation time steps is small. Similar to how IRL trains a\npolicy based on the reward function learned from expert demonstrations, we\ntrain (or fine-tune) a diffusion model using the log probability density\nestimated from training data. Since we employ an energy-based model (EBM) to\nrepresent the log density, our approach boils down to the joint training of a\ndiffusion model and an EBM. Our IRL formulation, named Diffusion by Maximum\nEntropy IRL (DxMI), is a minimax problem that reaches equilibrium when both\nmodels converge to the data distribution. The entropy maximization plays a key\nrole in DxMI, facilitating the exploration of the diffusion model and ensuring\nthe convergence of the EBM. We also propose Diffusion by Dynamic Programming\n(DxDP), a novel reinforcement learning algorithm for diffusion models, as a\nsubroutine in DxMI. DxDP makes the diffusion model update in DxMI efficient by\ntransforming the original problem into an optimal control formulation where\nvalue functions replace back-propagation in time. Our empirical studies show\nthat diffusion models fine-tuned using DxMI can generate high-quality samples\nin as few as 4 and 10 steps. Additionally, DxMI enables the training of an EBM\nwithout MCMC, stabilizing EBM training dynamics and enhancing anomaly detection\nperformance.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"G4OdZ8H6hfO3ktBR8HA_m0TCyhrQUfY4VEGhBxACMfc","pdfSize":"2166111","objectId":"0xbb0e23b5b1191bd60bf9a28335c1d0be6dbe2b15066a7cc093a2a995549a3f94","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
