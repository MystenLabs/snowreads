{
  "id": "2412.08772",
  "title": "On improving generalization in a class of learning problems with the\n  method of small parameters for weakly-controlled optimal gradient systems",
  "authors": "Getachew K. Befekadu",
  "authorsParsed": [
    [
      "Befekadu",
      "Getachew K.",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Wed, 11 Dec 2024 20:50:29 GMT"
    }
  ],
  "updateDate": "2024-12-13",
  "timestamp": 1733950229000,
  "abstract": "  In this paper, we provide a mathematical framework for improving\ngeneralization in a class of learning problems which is related to point\nestimations for modeling of high-dimensional nonlinear functions. In\nparticular, we consider a variational problem for a weakly-controlled gradient\nsystem, whose control input enters into the system dynamics as a coefficient to\na nonlinear term which is scaled by a small parameter. Here, the optimization\nproblem consists of a cost functional, which is associated with how to gauge\nthe quality of the estimated model parameters at a certain fixed final time\nw.r.t. the model validating dataset, while the weakly-controlled gradient\nsystem, whose the time-evolution is guided by the model training dataset and\nits perturbed version with small random noise. Using the perturbation theory,\nwe provide results that will allow us to solve a sequence of optimization\nproblems, i.e., a set of decomposed optimization problems, so as to aggregate\nthe corresponding approximate optimal solutions that are reasonably sufficient\nfor improving generalization in such a class of learning problems. Moreover, we\nalso provide an estimate for the rate of convergence for such approximate\noptimal solutions. Finally, we present some numerical results for a typical\ncase of nonlinear regression problem.\n",
  "subjects": [
    "Mathematics/Optimization and Control",
    "Statistics/Machine Learning"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "aIH6FNAo-cxceBfuBQjztlic6M56j-D0Grlp8HJt7Hk",
  "pdfSize": "922574"
}