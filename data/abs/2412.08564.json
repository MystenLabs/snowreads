{"id":"2412.08564","title":"Template-Based Visual Program Distillation","authors":"Michal Shlapentokh-Rothman and Yu-Xiong Wang and Derek Hoiem","authorsParsed":[["Shlapentokh-Rothman","Michal",""],["Wang","Yu-Xiong",""],["Hoiem","Derek",""]],"versions":[{"version":"v1","created":"Wed, 11 Dec 2024 17:32:21 GMT"},{"version":"v2","created":"Wed, 19 Feb 2025 01:01:54 GMT"}],"updateDate":"2025-02-20","timestamp":1733938341000,"abstract":"  For users with limited computational resources, visual programming or\nprompting large language models (LLMs) to generate executable code for visual\ntasks, like visual question answering (VQA), remains largely inaccessible. Even\nwith techniques such as distillation, adapting visual programming to smaller\nmodels or specific datasets is still quite challenging due to high annotation\ncosts. We propose a low-cost visual program distillation method that can be\nused for models with fewer than 1 billion parameters and requires no\nhuman-generated program annotations. We achieve this through synthetic data\naugmentation based on decoupling programs into higher-level skills, called\ntemplates, and their corresponding arguments. Experimental results show that,\nwith a relatively small amount of question/answer data, small language models\ncan generate high-quality visual programs with the added benefit of much faster\ninference.\n","subjects":["Computer Science/Computer Vision and Pattern Recognition","Computer Science/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"FKtrOsKSpJQtWy_T_LdoXaPt3f8rSmCZK5oKvrKAqTU","pdfSize":"1048796"}