{"id":"2412.09770","title":"Learning Visually Grounded Domain Ontologies via Embodied Conversation\n  and Explanation","authors":"Jonghyuk Park, Alex Lascarides, Subramanian Ramamoorthy","authorsParsed":[["Park","Jonghyuk",""],["Lascarides","Alex",""],["Ramamoorthy","Subramanian",""]],"versions":[{"version":"v1","created":"Fri, 13 Dec 2024 00:28:21 GMT"}],"updateDate":"2024-12-16","timestamp":1734049701000,"abstract":"  In this paper, we offer a learning framework in which the agent's knowledge\ngaps are overcome through corrective feedback from a teacher whenever the agent\nexplains its (incorrect) predictions. We test it in a low-resource visual\nprocessing scenario, in which the agent must learn to recognize distinct types\nof toy truck. The agent starts the learning process with no ontology about what\ntypes of trucks exist nor which parts they have, and a deficient model for\nrecognizing those parts from visual input. The teacher's feedback to the\nagent's explanations addresses its lack of relevant knowledge in the ontology\nvia a generic rule (e.g., \"dump trucks have dumpers\"), whereas an inaccurate\npart recognition is corrected by a deictic statement (e.g., \"this is not a\ndumper\"). The learner utilizes this feedback not only to improve its estimate\nof the hypothesis space of possible domain ontologies and probability\ndistributions over them, but also to use those estimates to update its visual\ninterpretation of the scene. Our experiments demonstrate that teacher-learner\npairs utilizing explanations and corrections are more data-efficient than those\nwithout such a faculty.\n","subjects":["Computer Science/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"9YcJfp1WkVEE61TnjrVCMlzQP8t4l-a6R5o4I48qrU0","pdfSize":"1198444"}