{"id":"2407.14879","title":"Thompson Sampling Itself is Differentially Private","authors":"Tingting Ou, Marco Avella Medina, Rachel Cummings","authorsParsed":[["Ou","Tingting",""],["Medina","Marco Avella",""],["Cummings","Rachel",""]],"versions":[{"version":"v1","created":"Sat, 20 Jul 2024 14:01:03 GMT"}],"updateDate":"2024-07-23","timestamp":1721484063000,"abstract":"  In this work we first show that the classical Thompson sampling algorithm for\nmulti-arm bandits is differentially private as-is, without any modification. We\nprovide per-round privacy guarantees as a function of problem parameters and\nshow composition over $T$ rounds; since the algorithm is unchanged, existing\n$O(\\sqrt{NT\\log N})$ regret bounds still hold and there is no loss in\nperformance due to privacy. We then show that simple modifications -- such as\npre-pulling all arms a fixed number of times, increasing the sampling variance\n-- can provide tighter privacy guarantees. We again provide privacy guarantees\nthat now depend on the new parameters introduced in the modification, which\nallows the analyst to tune the privacy guarantee as desired. We also provide a\nnovel regret analysis for this new algorithm, and show how the new parameters\nalso impact expected regret. Finally, we empirically validate and illustrate\nour theoretical findings in two parameter regimes and demonstrate that tuning\nthe new parameters substantially improve the privacy-regret tradeoff.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Data Structures and Algorithms","Statistics/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"7nG0of8qhJOV_Xf_1YLgaVvmfWFEZk1S82v52b_dRH8","pdfSize":"888647"}