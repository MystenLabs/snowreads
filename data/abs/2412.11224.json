{"id":"2412.11224","title":"GenLit: Reformulating Single-Image Relighting as Video Generation","authors":"Shrisha Bharadwaj, Haiwen Feng, Victoria Abrevaya, Michael J. Black","authorsParsed":[["Bharadwaj","Shrisha",""],["Feng","Haiwen",""],["Abrevaya","Victoria",""],["Black","Michael J.",""]],"versions":[{"version":"v1","created":"Sun, 15 Dec 2024 15:40:40 GMT"}],"updateDate":"2024-12-17","timestamp":1734277240000,"abstract":"  Manipulating the illumination within a single image represents a fundamental\nchallenge in computer vision and graphics. This problem has been traditionally\naddressed using inverse rendering techniques, which require explicit 3D asset\nreconstruction and costly ray tracing simulations. Meanwhile, recent\nadvancements in visual foundation models suggest that a new paradigm could soon\nbe practical and possible -- one that replaces explicit physical models with\nnetworks that are trained on massive amounts of image and video data. In this\npaper, we explore the potential of exploiting video diffusion models, and in\nparticular Stable Video Diffusion (SVD), in understanding the physical world to\nperform relighting tasks given a single image. Specifically, we introduce\nGenLit, a framework that distills the ability of a graphics engine to perform\nlight manipulation into a video generation model, enabling users to directly\ninsert and manipulate a point light in the 3D world within a given image and\ngenerate the results directly as a video sequence. We find that a model\nfine-tuned on only a small synthetic dataset (270 objects) is able to\ngeneralize to real images, enabling single-image relighting with realistic ray\ntracing effects and cast shadows. These results reveal the ability of video\nfoundation models to capture rich information about lighting, material, and\nshape. Our findings suggest that such models, with minimal training, can be\nused for physically-based rendering without explicit physically asset\nreconstruction and complex ray tracing. This further suggests the potential of\nsuch models for controllable and physically accurate image synthesis tasks.\n","subjects":["Computer Science/Computer Vision and Pattern Recognition","Computer Science/Graphics"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"p9PmhF2j9Q9dcZ6re5H3dNzvn14OgBf_bcKdZuf5sHw","pdfSize":"44278686"}