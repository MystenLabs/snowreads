{"id":"2407.06079","title":"Layered Diffusion Model for One-Shot High Resolution Text-to-Image\n  Synthesis","authors":"Emaad Khwaja, Abdullah Rashwan, Ting Chen, Oliver Wang, Suraj\n  Kothawade, Yeqing Li","authorsParsed":[["Khwaja","Emaad",""],["Rashwan","Abdullah",""],["Chen","Ting",""],["Wang","Oliver",""],["Kothawade","Suraj",""],["Li","Yeqing",""]],"versions":[{"version":"v1","created":"Mon, 8 Jul 2024 16:25:34 GMT"}],"updateDate":"2024-07-09","timestamp":1720455934000,"abstract":"  We present a one-shot text-to-image diffusion model that can generate\nhigh-resolution images from natural language descriptions. Our model employs a\nlayered U-Net architecture that simultaneously synthesizes images at multiple\nresolution scales. We show that this method outperforms the baseline of\nsynthesizing images only at the target resolution, while reducing the\ncomputational cost per step. We demonstrate that higher resolution synthesis\ncan be achieved by layering convolutions at additional resolution scales, in\ncontrast to other methods which require additional models for super-resolution\nsynthesis.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"ZQjtjyL6n_nj9scAJNGv99-00nq-XJLc8G0ONBloUDo","pdfSize":"17965903"}