{"id":"2407.15828","title":"J-CHAT: Japanese Large-scale Spoken Dialogue Corpus for Spoken Dialogue\n  Language Modeling","authors":"Wataru Nakata, Kentaro Seki, Hitomi Yanaka, Yuki Saito, Shinnosuke\n  Takamichi, Hiroshi Saruwatari","authorsParsed":[["Nakata","Wataru",""],["Seki","Kentaro",""],["Yanaka","Hitomi",""],["Saito","Yuki",""],["Takamichi","Shinnosuke",""],["Saruwatari","Hiroshi",""]],"versions":[{"version":"v1","created":"Mon, 22 Jul 2024 17:46:50 GMT"}],"updateDate":"2024-07-23","timestamp":1721670410000,"abstract":"  Spoken dialogue plays a crucial role in human-AI interactions, necessitating\ndialogue-oriented spoken language models (SLMs). To develop versatile SLMs,\nlarge-scale and diverse speech datasets are essential. Additionally, to ensure\nhiqh-quality speech generation, the data must be spontaneous like in-wild data\nand must be acoustically clean with noise removed. Despite the critical need,\nno open-source corpus meeting all these criteria has been available. This study\naddresses this gap by constructing and releasing a large-scale spoken dialogue\ncorpus, named Japanese Corpus for Human-AI Talks (J-CHAT), which is publicly\naccessible. Furthermore, this paper presents a language-independent method for\ncorpus construction and describes experiments on dialogue generation using SLMs\ntrained on J-CHAT. Experimental results indicate that the collected data from\nmultiple domains by our method improve the naturalness and meaningfulness of\ndialogue generation.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Sound","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"dH8sBVKlU3fYwoIjvIZtqb-p7dSH5AAVEn14cxOp-vI","pdfSize":"2125143"}