{"id":"2407.05022","title":"A Principled Framework for Evaluating on Typologically Diverse Languages","authors":"Esther Ploeger and Wessel Poelman and Andreas Holck H{\\o}eg-Petersen\n  and Anders Schlichtkrull and Miryam de Lhoneux and Johannes Bjerva","authorsParsed":[["Ploeger","Esther",""],["Poelman","Wessel",""],["HÃ¸eg-Petersen","Andreas Holck",""],["Schlichtkrull","Anders",""],["de Lhoneux","Miryam",""],["Bjerva","Johannes",""]],"versions":[{"version":"v1","created":"Sat, 6 Jul 2024 09:31:02 GMT"}],"updateDate":"2024-07-09","timestamp":1720258262000,"abstract":"  Beyond individual languages, multilingual natural language processing (NLP)\nresearch increasingly aims to develop models that perform well across languages\ngenerally. However, evaluating these systems on all the world's languages is\npractically infeasible. To attain generalizability, representative language\nsampling is essential. Previous work argues that generalizable multilingual\nevaluation sets should contain languages with diverse typological properties.\nHowever, 'typologically diverse' language samples have been found to vary\nconsiderably in this regard, and popular sampling methods are flawed and\ninconsistent. We present a language sampling framework for selecting highly\ntypologically diverse languages given a sampling frame, informed by language\ntypology. We compare sampling methods with a range of metrics and find that our\nsystematic methods consistently retrieve more typologically diverse language\nselections than previous methods in NLP. Moreover, we provide evidence that\nthis affects generalizability in multilingual model evaluation, emphasizing the\nimportance of diverse language sampling in NLP evaluation.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"vQi2KIyP4JQ1zaaK_84Juo0lkwjD_Y3EUGqWGNSNlDk","pdfSize":"4999532"}
