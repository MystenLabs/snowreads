{"id":"2407.11950","title":"Temporally Consistent Stereo Matching","authors":"Jiaxi Zeng, Chengtang Yao, Yuwei Wu, Yunde Jia","authorsParsed":[["Zeng","Jiaxi",""],["Yao","Chengtang",""],["Wu","Yuwei",""],["Jia","Yunde",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 17:44:34 GMT"}],"updateDate":"2024-07-17","timestamp":1721151874000,"abstract":"  Stereo matching provides depth estimation from binocular images for\ndownstream applications. These applications mostly take video streams as input\nand require temporally consistent depth maps. However, existing methods mainly\nfocus on the estimation at the single-frame level. This commonly leads to\ntemporally inconsistent results, especially in ill-posed regions. In this\npaper, we aim to leverage temporal information to improve the temporal\nconsistency, accuracy, and efficiency of stereo matching. To achieve this, we\nformulate video stereo matching as a process of temporal disparity completion\nfollowed by continuous iterative refinements. Specifically, we first project\nthe disparity of the previous timestamp to the current viewpoint, obtaining a\nsemi-dense disparity map. Then, we complete this map through a disparity\ncompletion module to obtain a well-initialized disparity map. The state\nfeatures from the current completion module and from the past refinement are\nfused together, providing a temporally coherent state for subsequent\nrefinement. Based on this coherent state, we introduce a dual-space refinement\nmodule to iteratively refine the initialized result in both disparity and\ndisparity gradient spaces, improving estimations in ill-posed regions.\nExtensive experiments demonstrate that our method effectively alleviates\ntemporal inconsistency while enhancing both accuracy and efficiency.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"IHseNXTPe0bN11PFeqX6bSzg16O4YeQJ2F4YoFqRygs","pdfSize":"5450033"}