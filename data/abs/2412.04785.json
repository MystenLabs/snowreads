{"id":"2412.04785","title":"Differentially Private Random Feature Model","authors":"Chunyang Liao, Deanna Needell, Alexander Xue","authorsParsed":[["Liao","Chunyang",""],["Needell","Deanna",""],["Xue","Alexander",""]],"versions":[{"version":"v1","created":"Fri, 6 Dec 2024 05:31:08 GMT"}],"updateDate":"2024-12-09","timestamp":1733463068000,"abstract":"  Designing privacy-preserving machine learning algorithms has received great\nattention in recent years, especially in the setting when the data contains\nsensitive information. Differential privacy (DP) is a widely used mechanism for\ndata analysis with privacy guarantees. In this paper, we produce a\ndifferentially private random feature model. Random features, which were\nproposed to approximate large-scale kernel machines, have been used to study\nprivacy-preserving kernel machines as well. We consider the over-parametrized\nregime (more features than samples) where the non-private random feature model\nis learned via solving the min-norm interpolation problem, and then we apply\noutput perturbation techniques to produce a private model. We show that our\nmethod preserves privacy and derive a generalization error bound for the\nmethod. To the best of our knowledge, we are the first to consider\nprivacy-preserving random feature models in the over-parametrized regime and\nprovide theoretical guarantees. We empirically compare our method with other\nprivacy-preserving learning methods in the literature as well. Our results show\nthat our approach is superior to the other methods in terms of generalization\nperformance on synthetic data and benchmark data sets. Additionally, it was\nrecently observed that DP mechanisms may exhibit and exacerbate disparate\nimpact, which means that the outcomes of DP learning algorithms vary\nsignificantly among different groups. We show that both theoretically and\nempirically, random features have the potential to reduce disparate impact, and\nhence achieve better fairness.\n","subjects":["Computer Science/Machine Learning","Computer Science/Cryptography and Security"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"4-OIrQL-vWBejxcd-Wi83KDvKbJKKIKDQworq7HhTzc","pdfSize":"774845"}