{"id":"2412.10782","title":"ANaGRAM: A Natural Gradient Relative to Adapted Model for efficient\n  PINNs learning","authors":"Nilo Schwencke, Cyril Furtlehner","authorsParsed":[["Schwencke","Nilo",""],["Furtlehner","Cyril",""]],"versions":[{"version":"v1","created":"Sat, 14 Dec 2024 10:38:09 GMT"}],"updateDate":"2024-12-17","timestamp":1734172689000,"abstract":"  In the recent years, Physics Informed Neural Networks (PINNs) have received\nstrong interest as a method to solve PDE driven systems, in particular for data\nassimilation purpose. This method is still in its infancy, with many\nshortcomings and failures that remain not properly understood. In this paper we\npropose a natural gradient approach to PINNs which contributes to speed-up and\nimprove the accuracy of the training. Based on an in depth analysis of the\ndifferential geometric structures of the problem, we come up with two distinct\ncontributions: (i) a new natural gradient algorithm that scales as $\\min(P^2S,\nS^2P)$, where $P$ is the number of parameters, and $S$ the batch size; (ii) a\nmathematically principled reformulation of the PINNs problem that allows the\nextension of natural gradient to it, with proved connections to Green's\nfunction theory.\n","subjects":["Computer Science/Machine Learning","Computer Science/Artificial Intelligence","Computer Science/Numerical Analysis","Mathematics/Numerical Analysis","Mathematics/Optimization and Control"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"uzLuwCbAiYfRmbKuH9d0yVRHKqsBwVH6gkxSkPwmeiU","pdfSize":"7134666"}