{"id":"2407.17598","title":"Harnessing DRL for URLLC in Open RAN: A Trade-off Exploration","authors":"Rana Muhammad Sohaib, Syed Tariq Shah, Oluwakayode Onireti, and\n  Muhammad Ali Imran","authorsParsed":[["Sohaib","Rana Muhammad",""],["Shah","Syed Tariq",""],["Onireti","Oluwakayode",""],["Imran","Muhammad Ali",""]],"versions":[{"version":"v1","created":"Wed, 24 Jul 2024 19:06:20 GMT"}],"updateDate":"2024-07-26","timestamp":1721847980000,"abstract":"  The advent of Ultra-Reliable Low Latency Communication (URLLC) alongside the\nemergence of Open RAN (ORAN) architectures presents unprecedented challenges\nand opportunities in Radio Resource Management (RRM) for next-generation\ncommunication systems. This paper presents a comprehensive trade-off analysis\nof Deep Reinforcement Learning (DRL) approaches designed to enhance URLLC\nperformance within ORAN's flexible and dynamic framework. By investigating\nvarious DRL strategies for optimising RRM parameters, we explore the intricate\nbalance between reliability, latency, and the newfound adaptability afforded by\nORAN principles. Through extensive simulation results, our study compares the\nefficacy of different DRL models in achieving URLLC objectives in an ORAN\ncontext, highlighting the potential of DRL to navigate the complexities\nintroduced by ORAN. The proposed study provides valuable insights into the\npractical implementation of DRL-based RRM solutions in ORAN-enabled wireless\nnetworks. It sheds light on the benefits and challenges of integrating DRL and\nORAN for URLLC enhancements. Our findings contribute to the ongoing discourse\non advancements in URLLC and ORAN, offering a roadmap for future research to\npursue efficient, reliable, and flexible communication systems.\n","subjects":["Electrical Engineering and Systems Science/Signal Processing"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"-m_RSJcmLxo_9OwJ-KqV4dz_UuxB5fQcvI_f75Ze6Hg","pdfSize":"5410228"}