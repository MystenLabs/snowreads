{"id":"2407.05599","title":"Generative Debunking of Climate Misinformation","authors":"Francisco Zanartu, Yulia Otmakhova, John Cook, Lea Frermann","authorsParsed":[["Zanartu","Francisco",""],["Otmakhova","Yulia",""],["Cook","John",""],["Frermann","Lea",""]],"versions":[{"version":"v1","created":"Mon, 8 Jul 2024 04:21:58 GMT"}],"updateDate":"2024-07-09","timestamp":1720412518000,"abstract":"  Misinformation about climate change causes numerous negative impacts,\nnecessitating corrective responses. Psychological research has offered various\nstrategies for reducing the influence of climate misinformation, such as the\nfact-myth-fallacy-fact-structure. However, practically implementing corrective\ninterventions at scale represents a challenge. Automatic detection and\ncorrection of misinformation offers a solution to the misinformation problem.\nThis study documents the development of large language models that accept as\ninput a climate myth and produce a debunking that adheres to the\nfact-myth-fallacy-fact (``truth sandwich'') structure, by incorporating\ncontrarian claim classification and fallacy detection into an LLM prompting\nframework. We combine open (Mixtral, Palm2) and proprietary (GPT-4) LLMs with\nprompting strategies of varying complexity. Experiments reveal promising\nperformance of GPT-4 and Mixtral if combined with structured prompts. We\nidentify specific challenges of debunking generation and human evaluation, and\nmap out avenues for future work. We release a dataset of high-quality\ntruth-sandwich debunkings, source code and a demo of the debunking system.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Computers and Society"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"L9VT7AkdwsLr8iMg1L-ugF20hoqZcB4dvgwwGNZU6fg","pdfSize":"313483"}
