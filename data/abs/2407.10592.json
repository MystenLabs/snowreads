{"id":"2407.10592","title":"InsertDiffusion: Identity Preserving Visualization of Objects through a\n  Training-Free Diffusion Architecture","authors":"Phillip Mueller, Jannik Wiese, Ioan Craciun, Lars Mikelsons","authorsParsed":[["Mueller","Phillip",""],["Wiese","Jannik",""],["Craciun","Ioan",""],["Mikelsons","Lars",""]],"versions":[{"version":"v1","created":"Mon, 15 Jul 2024 10:15:58 GMT"}],"updateDate":"2024-07-16","timestamp":1721038558000,"abstract":"  Recent advancements in image synthesis are fueled by the advent of\nlarge-scale diffusion models. Yet, integrating realistic object visualizations\nseamlessly into new or existing backgrounds without extensive training remains\na challenge. This paper introduces InsertDiffusion, a novel, training-free\ndiffusion architecture that efficiently embeds objects into images while\npreserving their structural and identity characteristics. Our approach utilizes\noff-the-shelf generative models and eliminates the need for fine-tuning, making\nit ideal for rapid and adaptable visualizations in product design and\nmarketing. We demonstrate superior performance over existing methods in terms\nof image realism and alignment with input conditions. By decomposing the\ngeneration task into independent steps, InsertDiffusion offers a scalable\nsolution that extends the capabilities of diffusion models for practical\napplications, achieving high-quality visualizations that maintain the\nauthenticity of the original objects.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"0XURRt_M8lX1n63wb6Uqf5FjtGuSxcdcvc94wbqS_Kg","pdfSize":"17175158"}