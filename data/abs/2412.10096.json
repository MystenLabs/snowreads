{
  "id": "2412.10096",
  "title": "Reward Machine Inference for Robotic Manipulation",
  "authors": "Mattijs Baert, Sam Leroux, Pieter Simoens",
  "authorsParsed": [
    [
      "Baert",
      "Mattijs",
      ""
    ],
    [
      "Leroux",
      "Sam",
      ""
    ],
    [
      "Simoens",
      "Pieter",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Fri, 13 Dec 2024 12:32:53 GMT"
    }
  ],
  "updateDate": "2024-12-16",
  "timestamp": 1734093173000,
  "abstract": "  Learning from Demonstrations (LfD) and Reinforcement Learning (RL) have\nenabled robot agents to accomplish complex tasks. Reward Machines (RMs) enhance\nRL's capability to train policies over extended time horizons by structuring\nhigh-level task information. In this work, we introduce a novel LfD approach\nfor learning RMs directly from visual demonstrations of robotic manipulation\ntasks. Unlike previous methods, our approach requires no predefined\npropositions or prior knowledge of the underlying sparse reward signals.\nInstead, it jointly learns the RM structure and identifies key high-level\nevents that drive transitions between RM states. We validate our method on\nvision-based manipulation tasks, showing that the inferred RM accurately\ncaptures task structure and enables an RL agent to effectively learn an optimal\npolicy.\n",
  "subjects": [
    "Computer Science/Robotics",
    "Computer Science/Machine Learning"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "6JPmchjzoImAxogP0OKPOfRHeywoTta46qbYRzyB5KA",
  "pdfSize": "1071761"
}