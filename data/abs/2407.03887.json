{"id":"2407.03887","title":"Unsupervised speech enhancement with spectral kurtosis and double deep\n  priors","authors":"Hien Ohnaka and Ryoichi Miyazaki","authorsParsed":[["Ohnaka","Hien",""],["Miyazaki","Ryoichi",""]],"versions":[{"version":"v1","created":"Thu, 4 Jul 2024 12:25:13 GMT"}],"updateDate":"2024-07-08","timestamp":1720095913000,"abstract":"  This paper proposes an unsupervised DNN-based speech enhancement approach\nfounded on deep priors (DPs). Here, DP signifies that DNNs are more inclined to\nproduce clean speech signals than noises. Conventional methods based on DP\ntypically involve training on a noisy speech signal using a random noise\nfeature as input, stopping training only a clean speech signal is generated.\nHowever, such conventional approaches encounter challenges in determining the\noptimal stop timing, experience performance degradation due to environmental\nbackground noise, and suffer a trade-off between distortion of the clean speech\nsignal and noise reduction performance. To address these challenges, we utilize\ntwo DNNs: one to generate a clean speech signal and the other to generate\nnoise. The combined output of these networks closely approximates the noisy\nspeech signal, with a loss term based on spectral kurtosis utilized to separate\nthe noisy speech signal into a clean speech signal and noise. The key advantage\nof this method lies in its ability to circumvent trade-offs and early stopping\nproblems, as the signal is decomposed by enough steps. Through evaluation\nexperiments, we demonstrate that the proposed method outperforms conventional\nmethods in the case of white Gaussian and environmental noise while effectively\nmitigating early stopping problems.\n","subjects":["Computing Research Repository/Sound","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"u1MTpP8GFD-Kqh1SQ7AeX6DrU5sOu77WVTeAUxATEtU","pdfSize":"3084134"}