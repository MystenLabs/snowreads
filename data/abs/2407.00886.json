{"id":"2407.00886","title":"Mechanistic Interpretation through Contextual Decomposition in\n  Transformers","authors":"Aliyah R. Hsu, Yeshwanth Cherapanamjeri, Anobel Y. Odisho, Peter R.\n  Carroll, Bin Yu","authorsParsed":[["Hsu","Aliyah R.",""],["Cherapanamjeri","Yeshwanth",""],["Odisho","Anobel Y.",""],["Carroll","Peter R.",""],["Yu","Bin",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 01:12:20 GMT"}],"updateDate":"2024-07-02","timestamp":1719796340000,"abstract":"  Transformers exhibit impressive capabilities but are often regarded as black\nboxes due to challenges in understanding the complex nonlinear relationships\nbetween features. Interpreting machine learning models is of paramount\nimportance to mitigate risks, and mechanistic interpretability is in particular\nof current interest as it opens up a window for guiding manual modifications\nand reverse-engineering solutions. In this work, we introduce contextual\ndecomposition for transformers (CD-T), extending a prior work on CD for RNNs\nand CNNs, to address mechanistic interpretation computationally efficiently.\nCD-T is a flexible interpretation method for transformers. It can capture\ncontributions of combinations of input features or source internal components\n(e.g. attention heads, feed-forward networks) to (1) final predictions or (2)\nthe output of any target internal component. Using CD-T, we propose a novel\nalgorithm for circuit discovery. On a real-world pathology report\nclassification task: we show CD-T distills a more faithful circuit of attention\nheads with improved computational efficiency (speed up 2x) than a prior\nbenchmark, path patching. As a versatile interpretation method, CD-T also\nexhibits exceptional capabilities for local interpretations. CD-T is shown to\nreliably find words and phrases of contrasting sentiment/topic on SST-2 and\nAGNews datasets. Through human experiments, we demonstrate CD-T enables users\nto identify the more accurate of two models and to better trust a model's\noutputs compared to alternative interpretation methods such as SHAP and LIME.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"WU_BiSLmU1kVhl2Xxbj71Ke0tNo8Pu18yA2AjKYYb3M","pdfSize":"1024105"}