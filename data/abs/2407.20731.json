{"id":"2407.20731","title":"In-Situ Techniques on GPU-Accelerated Data-Intensive Applications","authors":"Yi Ju, Mingshuai Li, Adalberto Perez, Laura Bellentani, Niclas\n  Jansson, Stefano Markidis, Philipp Schlatter, Erwin Laure","authorsParsed":[["Ju","Yi",""],["Li","Mingshuai",""],["Perez","Adalberto",""],["Bellentani","Laura",""],["Jansson","Niclas",""],["Markidis","Stefano",""],["Schlatter","Philipp",""],["Laure","Erwin",""]],"versions":[{"version":"v1","created":"Tue, 30 Jul 2024 11:03:00 GMT"}],"updateDate":"2024-07-31","timestamp":1722337380000,"abstract":"  The computational power of High-Performance Computing (HPC) systems is\nconstantly increasing, however, their input/output (IO) performance grows\nrelatively slowly, and their storage capacity is also limited. This unbalance\npresents significant challenges for applications such as Molecular Dynamics\n(MD) and Computational Fluid Dynamics (CFD), which generate massive amounts of\ndata for further visualization or analysis. At the same time, checkpointing is\ncrucial for long runs on HPC clusters, due to limited walltimes and/or failures\nof system components, and typically requires the storage of large amount of\ndata. Thus, restricted IO performance and storage capacity can lead to\nbottlenecks for the performance of full application workflows (as compared to\ncomputational kernels without IO). In-situ techniques, where data is further\nprocessed while still in memory rather to write it out over the I/O subsystem,\ncan help to tackle these problems. In contrast to traditional post-processing\nmethods, in-situ techniques can reduce or avoid the need to write or read data\nvia the IO subsystem. They offer a promising approach for applications aiming\nto leverage the full power of large scale HPC systems. In-situ techniques can\nalso be applied to hybrid computational nodes on HPC systems consisting of\ngraphics processing units (GPUs) and central processing units (CPUs). On one\nnode, the GPUs would have significant performance advantages over the CPUs.\nTherefore, current approaches for GPU-accelerated applications often focus on\nmaximizing GPU usage, leaving CPUs underutilized. In-situ tasks using CPUs to\nperform data analysis or preprocess data concurrently to the running\nsimulation, offer a possibility to improve this underutilization.\n","subjects":["Computing Research Repository/Performance","Computing Research Repository/Computational Engineering, Finance, and Science"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"AkzIG_PvQ_otqPWlFIUnodcEIGuXApXzA5vbDJxC-SU","pdfSize":"719620"}