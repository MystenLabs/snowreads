{"id":"2412.19755","title":"\"Did my figure do justice to the answer?\" : Towards Multimodal Short\n  Answer Grading with Feedback (MMSAF)","authors":"Pritam Sil, Bhaskaran Raman, Pushpak Bhattacharyya","authorsParsed":[["Sil","Pritam",""],["Raman","Bhaskaran",""],["Bhattacharyya","Pushpak",""]],"versions":[{"version":"v1","created":"Fri, 27 Dec 2024 17:33:39 GMT"},{"version":"v2","created":"Sat, 15 Feb 2025 21:52:23 GMT"}],"updateDate":"2025-02-18","timestamp":1735320819000,"abstract":"  Assessments play a vital role in a student's learning process by providing\nfeedback on a student's proficiency level in a subject. While assessments often\nmake use of short answer questions, it is often difficult to grade such\nquestions at a large scale. Moreover, such questions often involve students\ndrawing supporting diagrams along with their textual explanations. Such\nquestions often promote multimodal literacy and are aligned with\ncompetency-based questions, which demand a deeper cognitive processing ability\nfrom students. However, existing literature does not deal with the automatic\ngrading of such answers. Thus, to bridge this gap, we propose the Multimodal\nShort Answer Grading with Feedback (MMSAF) problem along with a dataset of 2197\ndata points. Additionally, we provide an automated framework for generating\nsuch datasets. Our evaluations on existing Large Language Models (LLMs) over\nthis dataset achieved an overall accuracy of 55% on the Level of Correctness\nlabels and 75% on Image Relevance labels. As per human experts, Pixtral was\nmore aligned towards human judgement and values for biology and ChatGPT for\nphysics and chemistry and achieved a score of 4 or more out of 5 in most\nparameters.\n","subjects":["Computer Science/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"gMKT2LfHK6RVTkXVf66qHK0s27Dum4i7cmhIW-fFjw0","pdfSize":"728512"}