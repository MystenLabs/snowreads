{"id":"2407.20292","title":"From pixels to planning: scale-free active inference","authors":"Karl Friston, Conor Heins, Tim Verbelen, Lancelot Da Costa, Tommaso\n  Salvatori, Dimitrije Markovic, Alexander Tschantz, Magnus Koudahl,\n  Christopher Buckley, Thomas Parr","authorsParsed":[["Friston","Karl",""],["Heins","Conor",""],["Verbelen","Tim",""],["Da Costa","Lancelot",""],["Salvatori","Tommaso",""],["Markovic","Dimitrije",""],["Tschantz","Alexander",""],["Koudahl","Magnus",""],["Buckley","Christopher",""],["Parr","Thomas",""]],"versions":[{"version":"v1","created":"Sat, 27 Jul 2024 14:20:48 GMT"}],"updateDate":"2024-07-31","timestamp":1722090048000,"abstract":"  This paper describes a discrete state-space model -- and accompanying methods\n-- for generative modelling. This model generalises partially observed Markov\ndecision processes to include paths as latent variables, rendering it suitable\nfor active inference and learning in a dynamic setting. Specifically, we\nconsider deep or hierarchical forms using the renormalisation group. The\nensuing renormalising generative models (RGM) can be regarded as discrete\nhomologues of deep convolutional neural networks or continuous state-space\nmodels in generalised coordinates of motion. By construction, these\nscale-invariant models can be used to learn compositionality over space and\ntime, furnishing models of paths or orbits; i.e., events of increasing temporal\ndepth and itinerancy. This technical note illustrates the automatic discovery,\nlearning and deployment of RGMs using a series of applications. We start with\nimage classification and then consider the compression and generation of movies\nand music. Finally, we apply the same variational principles to the learning of\nAtari-like games.\n","subjects":["Computing Research Repository/Machine Learning","Quantitative Biology/Neurons and Cognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"H8NIUQkSu6bZBeW9elS6AkweqprZDYyhhMVPkCgqF7k","pdfSize":"3361200"}