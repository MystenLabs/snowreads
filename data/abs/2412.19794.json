{
  "id": "2412.19794",
  "title": "MVTamperBench: Evaluating Robustness of Vision-Language Models",
  "authors": "Amit Agarwal, Srikant Panda, Angeline Charles, Bhargava Kumar, Hitesh\n  Patel, Priyaranjan Pattnayak, Taki Hasan Rafi, Tejaswini Kumar, Dong-Kyu Chae",
  "authorsParsed": [
    [
      "Agarwal",
      "Amit",
      ""
    ],
    [
      "Panda",
      "Srikant",
      ""
    ],
    [
      "Charles",
      "Angeline",
      ""
    ],
    [
      "Kumar",
      "Bhargava",
      ""
    ],
    [
      "Patel",
      "Hitesh",
      ""
    ],
    [
      "Pattnayak",
      "Priyaranjan",
      ""
    ],
    [
      "Rafi",
      "Taki Hasan",
      ""
    ],
    [
      "Kumar",
      "Tejaswini",
      ""
    ],
    [
      "Chae",
      "Dong-Kyu",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Fri, 27 Dec 2024 18:47:05 GMT"
    },
    {
      "version": "v2",
      "created": "Mon, 30 Dec 2024 04:20:52 GMT"
    },
    {
      "version": "v3",
      "created": "Wed, 15 Jan 2025 19:04:48 GMT"
    },
    {
      "version": "v4",
      "created": "Fri, 17 Jan 2025 18:18:21 GMT"
    }
  ],
  "updateDate": "2025-01-20",
  "timestamp": 1735325225000,
  "abstract": "  Multimodal Large Language Models (MLLMs) have driven major advances in video\nunderstanding, yet their vulnerability to adversarial tampering and\nmanipulations remains underexplored. To address this gap, we introduce\nMVTamperBench, a benchmark that systematically evaluates MLLM robustness\nagainst five prevalent tampering techniques: rotation, masking, substitution,\nrepetition, and dropping. Built from 3.4K original videos-expanded to over 17K\ntampered clips spanning 19 video tasks.\n  MVTamperBench challenges models to detect manipulations in spatial and\ntemporal coherence. We evaluate 45 recent MLLMs from 15+ model families,\nrevealing substantial variability in resilience across tampering types and\nshowing that larger parameter counts do not necessarily guarantee robustness.\nMVTamperBench sets a new benchmark for developing tamper-resilient MLLM in\nsafety-critical applications, including detecting clickbait, preventing harmful\ncontent distribution, and enforcing policies on media platforms. We release all\ncode and data to foster open research in trustworthy video understanding.\n  Code: https://amitbcp.github.io/MVTamperBench/ Data:\nhttps://huggingface.co/datasets/Srikant86/MVTamperBench\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition"
  ],
  "license": "http://creativecommons.org/licenses/by-sa/4.0/",
  "blobId": "jCaCFC7QkhRBzMBG3VmoHs5axdetGCw5XS3bLvI9ZIQ",
  "pdfSize": "25357175"
}