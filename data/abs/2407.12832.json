{"id":"2407.12832","title":"Sentence-level Aggregation of Lexical Metrics Correlate Stronger with\n  Human Judgements than Corpus-level Aggregation","authors":"Paulo Cavalin, Pedro Henrique Domingues, Claudio Pinhanez","authorsParsed":[["Cavalin","Paulo",""],["Domingues","Pedro Henrique",""],["Pinhanez","Claudio",""]],"versions":[{"version":"v1","created":"Wed, 3 Jul 2024 13:46:24 GMT"}],"updateDate":"2024-07-19","timestamp":1720014384000,"abstract":"  In this paper we show that corpus-level aggregation hinders considerably the\ncapability of lexical metrics to accurately evaluate machine translation (MT)\nsystems. With empirical experiments we demonstrate that averaging individual\nsegment-level scores can make metrics such as BLEU and chrF correlate much\nstronger with human judgements and make them behave considerably more similar\nto neural metrics such as COMET and BLEURT. We show that this difference exists\nbecause corpus- and segment-level aggregation differs considerably owing to the\nclassical average of ratio versus ratio of averages Mathematical problem.\nMoreover, as we also show, such difference affects considerably the statistical\nrobustness of corpus-level aggregation. Considering that neural metrics\ncurrently only cover a small set of sufficiently-resourced languages, the\nresults in this paper can help make the evaluation of MT systems for\nlow-resource languages more trustworthy.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"tE5N7ckuo4zaw8uSdoBi9wAaSLjxoOIC7abhJwTC0tc","pdfSize":"375161"}