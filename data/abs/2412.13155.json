{
  "id": "2412.13155",
  "title": "F-Bench: Rethinking Human Preference Evaluation Metrics for Benchmarking\n  Face Generation, Customization, and Restoration",
  "authors": "Lu Liu, Huiyu Duan, Qiang Hu, Liu Yang, Chunlei Cai, Tianxiao Ye,\n  Huayu Liu, Xiaoyun Zhang, Guangtao Zhai",
  "authorsParsed": [
    [
      "Liu",
      "Lu",
      ""
    ],
    [
      "Duan",
      "Huiyu",
      ""
    ],
    [
      "Hu",
      "Qiang",
      ""
    ],
    [
      "Yang",
      "Liu",
      ""
    ],
    [
      "Cai",
      "Chunlei",
      ""
    ],
    [
      "Ye",
      "Tianxiao",
      ""
    ],
    [
      "Liu",
      "Huayu",
      ""
    ],
    [
      "Zhang",
      "Xiaoyun",
      ""
    ],
    [
      "Zhai",
      "Guangtao",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Tue, 17 Dec 2024 18:28:48 GMT"
    }
  ],
  "updateDate": "2024-12-18",
  "timestamp": 1734460128000,
  "abstract": "  Artificial intelligence generative models exhibit remarkable capabilities in\ncontent creation, particularly in face image generation, customization, and\nrestoration. However, current AI-generated faces (AIGFs) often fall short of\nhuman preferences due to unique distortions, unrealistic details, and\nunexpected identity shifts, underscoring the need for a comprehensive quality\nevaluation framework for AIGFs. To address this need, we introduce FaceQ, a\nlarge-scale, comprehensive database of AI-generated Face images with\nfine-grained Quality annotations reflecting human preferences. The FaceQ\ndatabase comprises 12,255 images generated by 29 models across three tasks: (1)\nface generation, (2) face customization, and (3) face restoration. It includes\n32,742 mean opinion scores (MOSs) from 180 annotators, assessed across multiple\ndimensions: quality, authenticity, identity (ID) fidelity, and text-image\ncorrespondence. Using the FaceQ database, we establish F-Bench, a benchmark for\ncomparing and evaluating face generation, customization, and restoration\nmodels, highlighting strengths and weaknesses across various prompts and\nevaluation dimensions. Additionally, we assess the performance of existing\nimage quality assessment (IQA), face quality assessment (FQA), AI-generated\ncontent image quality assessment (AIGCIQA), and preference evaluation metrics,\nmanifesting that these standard metrics are relatively ineffective in\nevaluating authenticity, ID fidelity, and text-image correspondence. The FaceQ\ndatabase will be publicly available upon publication.\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "z-3xEQiEu6fwoQmEAaXs9PsTgHlrGWEx6MwMXT9l6fo",
  "pdfSize": "32482459"
}