{"id":"2412.20386","title":"PTQ4VM: Post-Training Quantization for Visual Mamba","authors":"Younghyun Cho, Changhun Lee, Seonggon Kim, Eunhyeok Park","authorsParsed":[["Cho","Younghyun",""],["Lee","Changhun",""],["Kim","Seonggon",""],["Park","Eunhyeok",""]],"versions":[{"version":"v1","created":"Sun, 29 Dec 2024 07:21:33 GMT"}],"updateDate":"2024-12-31","timestamp":1735456893000,"abstract":"  Visual Mamba is an approach that extends the selective space state model,\nMamba, to vision tasks. It processes image tokens sequentially in a fixed\norder, accumulating information to generate outputs. Despite its growing\npopularity for delivering high-quality outputs at a low computational cost\nacross various tasks, Visual Mamba is highly susceptible to quantization, which\nmakes further performance improvements challenging. Our analysis reveals that\nthe fixed token access order in Visual Mamba introduces unique quantization\nchallenges, which we categorize into three main issues: 1) token-wise variance,\n2) channel-wise outliers, and 3) a long tail of activations. To address these\nchallenges, we propose Post-Training Quantization for Visual Mamba (PTQ4VM),\nwhich introduces two key strategies: Per-Token Static (PTS) quantization and\nJoint Learning of Smoothing Scale and Step Size (JLSS). To the our best\nknowledge, this is the first quantization study on Visual Mamba. PTQ4VM can be\napplied to various Visual Mamba backbones, converting the pretrained model to a\nquantized format in under 15 minutes without notable quality degradation.\nExtensive experiments on large-scale classification and regression tasks\ndemonstrate its effectiveness, achieving up to 1.83x speedup on GPUs with\nnegligible accuracy loss compared to FP16. Our code is available at\nhttps://github.com/YoungHyun197/ptq4vm.\n","subjects":["Computer Science/Computer Vision and Pattern Recognition","Computer Science/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"_rEgA9UG42tJxA3wyVmOmo24YBWOQxOQGopos778-Ao","pdfSize":"7520213"}