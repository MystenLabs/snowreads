{"id":"2412.10257","title":"Targeted Angular Reversal of Weights (TARS) for Knowledge Removal in\n  Large Language Models","authors":"Harry J. Davies, Giorgos Iacovides, Danilo P. Mandic","authorsParsed":[["Davies","Harry J.",""],["Iacovides","Giorgos",""],["Mandic","Danilo P.",""]],"versions":[{"version":"v1","created":"Fri, 13 Dec 2024 16:26:34 GMT"},{"version":"v2","created":"Mon, 16 Dec 2024 14:54:00 GMT"}],"updateDate":"2024-12-17","timestamp":1734107194000,"abstract":"  The sheer scale of data required to train modern large language models (LLMs)\nposes significant risks, as models are likely to gain knowledge of sensitive\ntopics such as bio-security, as well the ability to replicate copyrighted\nworks. Methods designed to remove such knowledge must do so from all prompt\ndirections, in a multi-lingual capacity and without degrading general model\nperformance. To this end, we introduce the targeted angular reversal (TARS)\nmethod of knowledge removal from LLMs. The TARS method firstly leverages the\nLLM in combination with a detailed prompt to aggregate information about a\nselected concept in the internal representation space of the LLM. It then\nrefines this approximate concept vector to trigger the concept token with high\nprobability, by perturbing the approximate concept vector with noise and\ntransforming it into token scores with the language model head. The feedforward\nweight vectors in the LLM which operate directly on the internal representation\nspace, and have the highest cosine similarity with this targeting vector, are\nthen replaced by a reversed targeting vector, thus limiting the ability of the\nconcept to propagate through the model. The modularity of the TARS method\nallows for a sequential removal of concepts from Llama 3.1 8B, such as the\nfamous literary detective Sherlock Holmes, and the planet Saturn. It is\ndemonstrated that the probability of triggering target concepts can be reduced\nto 0.00 with as few as 1 TARS edit, whilst simultaneously removing the\nknowledge bi-directionally. Moreover, knowledge is shown to be removed across\nall languages despite only being targeted in English. Importantly, TARS has\nminimal impact on the general model capabilities, as after removing 5 diverse\nconcepts in a modular fashion, there is minimal KL divergence in the next token\nprobabilities of the LLM on large corpora of Wikipedia text (median of 0.0015).\n","subjects":["Computer Science/Computation and Language","Computer Science/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"2LAPlJVIZ3vQ0QvtwFUdGN_pPgAEl2nR8dcoiZNd5KU","pdfSize":"670000"}