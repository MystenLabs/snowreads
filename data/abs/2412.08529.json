{
  "id": "2412.08529",
  "title": "TECO: Improving Multimodal Intent Recognition with Text Enhancement\n  through Commonsense Knowledge Extraction",
  "authors": "Quynh-Mai Thi Nguyen, Lan-Nhi Thi Nguyen, Cam-Van Thi Nguyen",
  "authorsParsed": [
    [
      "Nguyen",
      "Quynh-Mai Thi",
      ""
    ],
    [
      "Nguyen",
      "Lan-Nhi Thi",
      ""
    ],
    [
      "Nguyen",
      "Cam-Van Thi",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Wed, 11 Dec 2024 16:38:48 GMT"
    }
  ],
  "updateDate": "2024-12-12",
  "timestamp": 1733935128000,
  "abstract": "  The objective of multimodal intent recognition (MIR) is to leverage various\nmodalities-such as text, video, and audio-to detect user intentions, which is\ncrucial for understanding human language and context in dialogue systems.\nDespite advances in this field, two main challenges persist: (1) effectively\nextracting and utilizing semantic information from robust textual features; (2)\naligning and fusing non-verbal modalities with verbal ones effectively. This\npaper proposes a Text Enhancement with CommOnsense Knowledge Extractor (TECO)\nto address these challenges. We begin by extracting relations from both\ngenerated and retrieved knowledge to enrich the contextual information in the\ntext modality. Subsequently, we align and integrate visual and acoustic\nrepresentations with these enhanced text features to form a cohesive multimodal\nrepresentation. Our experimental results show substantial improvements over\nexisting baseline methods.\n",
  "subjects": [
    "Computer Science/Computation and Language"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "0fJwsiBcTxmxH9iA78bm40QPB4QQI_BsWq5vqOmmSDA",
  "pdfSize": "9147045"
}