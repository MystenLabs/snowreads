{"id":"2412.16524","title":"LLaVA-SLT: Visual Language Tuning for Sign Language Translation","authors":"Han Liang, Chengyu Huang, Yuecheng Xu, Cheng Tang, Weicai Ye, Juze\n  Zhang, Xin Chen, Jingyi Yu, Lan Xu","authorsParsed":[["Liang","Han",""],["Huang","Chengyu",""],["Xu","Yuecheng",""],["Tang","Cheng",""],["Ye","Weicai",""],["Zhang","Juze",""],["Chen","Xin",""],["Yu","Jingyi",""],["Xu","Lan",""]],"versions":[{"version":"v1","created":"Sat, 21 Dec 2024 08:01:08 GMT"}],"updateDate":"2024-12-24","timestamp":1734768068000,"abstract":"  In the realm of Sign Language Translation (SLT), reliance on costly\ngloss-annotated datasets has posed a significant barrier. Recent advancements\nin gloss-free SLT methods have shown promise, yet they often largely lag behind\ngloss-based approaches in terms of translation accuracy. To narrow this\nperformance gap, we introduce LLaVA-SLT, a pioneering Large Multimodal Model\n(LMM) framework designed to leverage the power of Large Language Models (LLMs)\nthrough effectively learned visual language embeddings. Our model is trained\nthrough a trilogy. First, we propose linguistic continued pretraining. We scale\nup the LLM and adapt it to the sign language domain using an extensive corpus\ndataset, effectively enhancing its textual linguistic knowledge about sign\nlanguage. Then, we adopt visual contrastive pretraining to align the visual\nencoder with a large-scale pretrained text encoder. We propose hierarchical\nvisual encoder that learns a robust word-level intermediate representation that\nis compatible with LLM token embeddings. Finally, we propose visual language\ntuning. We freeze pretrained models and employ a lightweight trainable MLP\nconnector. It efficiently maps the pretrained visual language embeddings into\nthe LLM token embedding space, enabling downstream SLT task. Our comprehensive\nexperiments demonstrate that LLaVA-SLT outperforms the state-of-the-art\nmethods. By using extra annotation-free data, it even closes to the gloss-based\naccuracy.\n","subjects":["Computer Science/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"P6djz3pSNJgbafCIckRCzmSH4bUruqt0Q4wY5B4kh0s","pdfSize":"8086799"}