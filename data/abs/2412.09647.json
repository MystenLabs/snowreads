{
  "id": "2412.09647",
  "title": "Bench2Drive-R: Turning Real World Data into Reactive Closed-Loop\n  Autonomous Driving Benchmark by Generative Model",
  "authors": "Junqi You, Xiaosong Jia, Zhiyuan Zhang, Yutao Zhu, Junchi Yan",
  "authorsParsed": [
    [
      "You",
      "Junqi",
      ""
    ],
    [
      "Jia",
      "Xiaosong",
      ""
    ],
    [
      "Zhang",
      "Zhiyuan",
      ""
    ],
    [
      "Zhu",
      "Yutao",
      ""
    ],
    [
      "Yan",
      "Junchi",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Wed, 11 Dec 2024 06:35:18 GMT"
    }
  ],
  "updateDate": "2024-12-16",
  "timestamp": 1733898918000,
  "abstract": "  For end-to-end autonomous driving (E2E-AD), the evaluation system remains an\nopen problem. Existing closed-loop evaluation protocols usually rely on\nsimulators like CARLA being less realistic; while NAVSIM using real-world\nvision data, yet is limited to fixed planning trajectories in short horizon and\nassumes other agents are not reactive.\n  We introduce Bench2Drive-R, a generative framework that enables reactive\nclosed-loop evaluation. Unlike existing video generative models for AD, the\nproposed designs are tailored for interactive simulation, where sensor\nrendering and behavior rollout are decoupled by applying a separate behavioral\ncontroller to simulate the reactions of surrounding agents. As a result, the\nrenderer could focus on image fidelity, control adherence, and spatial-temporal\ncoherence. For temporal consistency, due to the step-wise interaction nature of\nsimulation, we design a noise modulating temporal encoder with Gaussian\nblurring to encourage long-horizon autoregressive rollout of image sequences\nwithout deteriorating distribution shifts. For spatial consistency, a retrieval\nmechanism, which takes the spatially nearest images as references, is\nintroduced to to ensure scene-level rendering fidelity during the generation\nprocess. The spatial relations between target and reference are explicitly\nmodeled with 3D relative position encodings and the potential over-reliance of\nreference images is mitigated with hierarchical sampling and classifier-free\nguidance.\n  We compare the generation quality of Bench2Drive-R with existing generative\nmodels and achieve state-of-the-art performance. We further integrate\nBench2Drive-R into nuPlan and evaluate the generative qualities with\nclosed-loop simulation results. We will open source our code.\n",
  "subjects": [
    "Computer Science/Robotics",
    "Computer Science/Computer Vision and Pattern Recognition",
    "Computer Science/Machine Learning"
  ],
  "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
  "blobId": "brwtivSdbLqQSKrzv2rbMb6SLUoNFIm2v4N5uc1S2Hs",
  "pdfSize": "42281366"
}