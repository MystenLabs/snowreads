{"id":"2407.03842","title":"Beyond Viewpoint: Robust 3D Object Recognition under Arbitrary Views\n  through Joint Multi-Part Representation","authors":"Linlong Fan, Ye Huang, Yanqi Ge, Wen Li, Lixin Duan","authorsParsed":[["Fan","Linlong",""],["Huang","Ye",""],["Ge","Yanqi",""],["Li","Wen",""],["Duan","Lixin",""]],"versions":[{"version":"v1","created":"Thu, 4 Jul 2024 11:16:47 GMT"},{"version":"v2","created":"Wed, 17 Jul 2024 17:52:05 GMT"}],"updateDate":"2024-07-18","timestamp":1720091807000,"abstract":"  Existing view-based methods excel at recognizing 3D objects from predefined\nviewpoints, but their exploration of recognition under arbitrary views is\nlimited. This is a challenging and realistic setting because each object has\ndifferent viewpoint positions and quantities, and their poses are not aligned.\nHowever, most view-based methods, which aggregate multiple view features to\nobtain a global feature representation, hard to address 3D object recognition\nunder arbitrary views. Due to the unaligned inputs from arbitrary views, it is\nchallenging to robustly aggregate features, leading to performance degradation.\nIn this paper, we introduce a novel Part-aware Network (PANet), which is a\npart-based representation, to address these issues. This part-based\nrepresentation aims to localize and understand different parts of 3D objects,\nsuch as airplane wings and tails. It has properties such as viewpoint\ninvariance and rotation robustness, which give it an advantage in addressing\nthe 3D object recognition problem under arbitrary views. Our results on\nbenchmark datasets clearly demonstrate that our proposed method outperforms\nexisting view-based aggregation baselines for the task of 3D object recognition\nunder arbitrary views, even surpassing most fixed viewpoint methods.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"TXL5etde-BHO-0bXPftrhpXPgJZE-024J_jtAMs-4Gs","pdfSize":"7467774"}
