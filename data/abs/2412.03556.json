{
  "id": "2412.03556",
  "title": "Best-of-N Jailbreaking",
  "authors": "John Hughes, Sara Price, Aengus Lynch, Rylan Schaeffer, Fazl Barez,\n  Sanmi Koyejo, Henry Sleight, Erik Jones, Ethan Perez, Mrinank Sharma",
  "authorsParsed": [
    [
      "Hughes",
      "John",
      ""
    ],
    [
      "Price",
      "Sara",
      ""
    ],
    [
      "Lynch",
      "Aengus",
      ""
    ],
    [
      "Schaeffer",
      "Rylan",
      ""
    ],
    [
      "Barez",
      "Fazl",
      ""
    ],
    [
      "Koyejo",
      "Sanmi",
      ""
    ],
    [
      "Sleight",
      "Henry",
      ""
    ],
    [
      "Jones",
      "Erik",
      ""
    ],
    [
      "Perez",
      "Ethan",
      ""
    ],
    [
      "Sharma",
      "Mrinank",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Wed, 4 Dec 2024 18:51:32 GMT"
    },
    {
      "version": "v2",
      "created": "Thu, 19 Dec 2024 22:37:45 GMT"
    }
  ],
  "updateDate": "2024-12-23",
  "timestamp": 1733338292000,
  "abstract": "  We introduce Best-of-N (BoN) Jailbreaking, a simple black-box algorithm that\njailbreaks frontier AI systems across modalities. BoN Jailbreaking works by\nrepeatedly sampling variations of a prompt with a combination of augmentations\n- such as random shuffling or capitalization for textual prompts - until a\nharmful response is elicited. We find that BoN Jailbreaking achieves high\nattack success rates (ASRs) on closed-source language models, such as 89% on\nGPT-4o and 78% on Claude 3.5 Sonnet when sampling 10,000 augmented prompts.\nFurther, it is similarly effective at circumventing state-of-the-art\nopen-source defenses like circuit breakers. BoN also seamlessly extends to\nother modalities: it jailbreaks vision language models (VLMs) such as GPT-4o\nand audio language models (ALMs) like Gemini 1.5 Pro, using modality-specific\naugmentations. BoN reliably improves when we sample more augmented prompts.\nAcross all modalities, ASR, as a function of the number of samples (N),\nempirically follows power-law-like behavior for many orders of magnitude. BoN\nJailbreaking can also be composed with other black-box algorithms for even more\neffective attacks - combining BoN with an optimized prefix attack achieves up\nto a 35% increase in ASR. Overall, our work indicates that, despite their\ncapability, language models are sensitive to seemingly innocuous changes to\ninputs, which attackers can exploit across modalities.\n",
  "subjects": [
    "Computer Science/Computation and Language",
    "Computer Science/Artificial Intelligence",
    "Computer Science/Machine Learning"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "YRcp3BIKElYv80NOw4tyVLbcQOy5wvx2lI-sA9S1b5E",
  "pdfSize": "9156508"
}