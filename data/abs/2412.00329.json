{"id":"2412.00329","title":"Language Models in Software Development Tasks: An Experimental Analysis\n  of Energy and Accuracy","authors":"Negar Alizadeh, Boris Belchev, Nishant Saurabh, Patricia Kelbert,\n  Fernando Castor","authorsParsed":[["Alizadeh","Negar",""],["Belchev","Boris",""],["Saurabh","Nishant",""],["Kelbert","Patricia",""],["Castor","Fernando",""]],"versions":[{"version":"v1","created":"Sat, 30 Nov 2024 03:02:50 GMT"},{"version":"v2","created":"Fri, 17 Jan 2025 12:53:37 GMT"}],"updateDate":"2025-01-20","timestamp":1732935770000,"abstract":"  The use of generative AI-based coding assistants like ChatGPT and Github\nCopilot is a reality in contemporary software development. Many of these tools\nare provided as remote APIs. Using third-party APIs raises data privacy and\nsecurity concerns for client companies, which motivates the use of\nlocally-deployed language models. In this study, we explore the trade-off\nbetween model accuracy and energy consumption, aiming to provide valuable\ninsights to help developers make informed decisions when selecting a language\nmodel. We investigate the performance of 18 families of LLMs in typical\nsoftware development tasks on two real-world infrastructures, a commodity GPU\nand a powerful AI-specific GPU. Given that deploying LLMs locally requires\npowerful infrastructure which might not be affordable for everyone, we consider\nboth full-precision and quantized models. Our findings reveal that employing a\nbig LLM with a higher energy budget does not always translate to significantly\nimproved accuracy. Additionally, quantized versions of large models generally\noffer better efficiency and accuracy compared to full-precision versions of\nmedium-sized ones. Apart from that, not a single model is suitable for all\ntypes of software development tasks.\n","subjects":["Computer Science/Software Engineering"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"vm25zrGgFAC-McUS_4uK_I06VzDHfC8Bd5s1ce9-e5U","pdfSize":"731592"}