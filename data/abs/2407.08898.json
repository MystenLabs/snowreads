{"id":"2407.08898","title":"IDAT: A Multi-Modal Dataset and Toolkit for Building and Evaluating\n  Interactive Task-Solving Agents","authors":"Shrestha Mohanty, Negar Arabzadeh, Andrea Tupini, Yuxuan Sun, Alexey\n  Skrynnik, Artem Zholus, Marc-Alexandre C\\^ot\\'e, Julia Kiseleva","authorsParsed":[["Mohanty","Shrestha",""],["Arabzadeh","Negar",""],["Tupini","Andrea",""],["Sun","Yuxuan",""],["Skrynnik","Alexey",""],["Zholus","Artem",""],["Côté","Marc-Alexandre",""],["Kiseleva","Julia",""]],"versions":[{"version":"v1","created":"Fri, 12 Jul 2024 00:07:43 GMT"}],"updateDate":"2024-07-15","timestamp":1720742863000,"abstract":"  Seamless interaction between AI agents and humans using natural language\nremains a key goal in AI research. This paper addresses the challenges of\ndeveloping interactive agents capable of understanding and executing grounded\nnatural language instructions through the IGLU competition at NeurIPS. Despite\nadvancements, challenges such as a scarcity of appropriate datasets and the\nneed for effective evaluation platforms persist. We introduce a scalable data\ncollection tool for gathering interactive grounded language instructions within\na Minecraft-like environment, resulting in a Multi-Modal dataset with around\n9,000 utterances and over 1,000 clarification questions. Additionally, we\npresent a Human-in-the-Loop interactive evaluation platform for qualitative\nanalysis and comparison of agent performance through multi-turn communication\nwith human annotators. We offer to the community these assets referred to as\nIDAT (IGLU Dataset And Toolkit) which aim to advance the development of\nintelligent, interactive AI agents and provide essential resources for further\nresearch.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"QnlRzkoo4mrY-DzFvzDpofPmp5MkuyPsBpU2e_gtCTo","pdfSize":"3908740"}