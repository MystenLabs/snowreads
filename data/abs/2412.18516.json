{"id":"2412.18516","title":"Generating Explanations for Autonomous Robots: a Systematic Review","authors":"David Sobr\\'in-Hidalgo, \\'Angel Manuel Guerrero-Higueras and Vicente\n  Matell\\'an-Olivera","authorsParsed":[["Sobrín-Hidalgo","David",""],["Guerrero-Higueras","Ángel Manuel",""],["Matellán-Olivera","Vicente",""]],"versions":[{"version":"v1","created":"Tue, 24 Dec 2024 15:53:01 GMT"},{"version":"v2","created":"Thu, 30 Jan 2025 11:19:53 GMT"}],"updateDate":"2025-01-31","timestamp":1735055581000,"abstract":"  Building trust between humans and robots has long interested the robotics\ncommunity. Various studies have aimed to clarify the factors that influence the\ndevelopment of user trust. In Human-Robot Interaction (HRI) environments, a\ncritical aspect of trust development is the robot's ability to make its\nbehavior understandable. The concept of an eXplainable Autonomous Robot (XAR)\naddresses this requirement. However, giving a robot self-explanatory abilities\nis a complex task. Robot behavior includes multiple skills and diverse\nsubsystems. This complexity led to research into a wide range of methods for\ngenerating explanations about robot behavior. This paper presents a systematic\nliterature review that analyzes existing strategies for generating explanations\nin robots and studies the current XAR trends. Results indicate promising\nadvancements in explainability systems. However, these systems are still unable\nto fully cover the complex behavior of autonomous robots. Furthermore, we also\nidentify a lack of consensus on the theoretical concept of explainability, and\nthe need for a robust methodology to assess explainability methods and tools\nhas been identified.\n","subjects":["Computer Science/Robotics"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"CmquChys-6338tZFL-cPovcdMQ3VNyQ3dR1RcWM7Ero","pdfSize":"1288675"}