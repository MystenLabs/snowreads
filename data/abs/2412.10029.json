{
  "id": "2412.10029",
  "title": "Enhancing Fine-Grained Vision-Language Pretraining with Negative\n  Augmented Samples",
  "authors": "Yeyuan Wang, Dehong Gao, Lei Yi, Linbo Jin, Jinxia Zhang, Libin Yang,\n  Xiaoyan Cai",
  "authorsParsed": [
    [
      "Wang",
      "Yeyuan",
      ""
    ],
    [
      "Gao",
      "Dehong",
      ""
    ],
    [
      "Yi",
      "Lei",
      ""
    ],
    [
      "Jin",
      "Linbo",
      ""
    ],
    [
      "Zhang",
      "Jinxia",
      ""
    ],
    [
      "Yang",
      "Libin",
      ""
    ],
    [
      "Cai",
      "Xiaoyan",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Fri, 13 Dec 2024 10:39:31 GMT"
    }
  ],
  "updateDate": "2024-12-16",
  "timestamp": 1734086371000,
  "abstract": "  Existing Vision-Language Pretraining (VLP) methods have achieved remarkable\nimprovements across a variety of vision-language tasks, confirming their\neffectiveness in capturing coarse-grained semantic correlations. However, their\ncapability for fine-grained understanding, which is critical for many nuanced\nvision-language applications, remains limited. Prevailing VLP models often\noverlook the intricate distinctions in expressing different modal features and\ntypically depend on the similarity of holistic features for cross-modal\ninteractions. Moreover, these models directly align and integrate features from\ndifferent modalities, focusing more on coarse-grained general representations,\nthus failing to capture the nuanced differences necessary for tasks demanding a\nmore detailed perception. In response to these limitations, we introduce\nNegative Augmented Samples(NAS), a refined vision-language pretraining model\nthat innovatively incorporates NAS to specifically address the challenge of\nfine-grained understanding. NAS utilizes a Visual Dictionary(VD) as a semantic\nbridge between visual and linguistic domains. Additionally, it employs a\nNegative Visual Augmentation(NVA) method based on the VD to generate\nchallenging negative image samples. These samples deviate from positive samples\nexclusively at the token level, thereby necessitating that the model discerns\nthe subtle disparities between positive and negative samples with greater\nprecision. Comprehensive experiments validate the efficacy of NAS components\nand underscore its potential to enhance fine-grained vision-language\ncomprehension.\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition"
  ],
  "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
  "blobId": "G2TGv_g0M-S9y4eRE_cnLEf05JRHJsFhg5t-jNbTCGo",
  "pdfSize": "4517793"
}