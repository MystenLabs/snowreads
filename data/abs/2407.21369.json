{"id":"2407.21369","title":"An LLM-based Readability Measurement for Unit Tests' Context-aware\n  Inputs","authors":"Zhichao Zhou, Yutian Tang, Yun Lin, Jingzhu He","authorsParsed":[["Zhou","Zhichao",""],["Tang","Yutian",""],["Lin","Yun",""],["He","Jingzhu",""]],"versions":[{"version":"v1","created":"Wed, 31 Jul 2024 06:35:15 GMT"},{"version":"v2","created":"Mon, 19 Aug 2024 01:54:38 GMT"}],"updateDate":"2024-08-20","timestamp":1722407715000,"abstract":"  Automated test techniques usually generate unit tests with higher code\ncoverage than manual tests. However, the readability of automated tests is\ncrucial for code comprehension and maintenance. The readability of unit tests\ninvolves many aspects. In this paper, we focus on test inputs. The central\nlimitation of existing studies on input readability is that they focus on test\ncodes alone without taking the tested source codes into consideration, making\nthem either ignore different source codes' different readability requirements\nor require manual efforts to write readable inputs. However, we observe that\nthe source codes specify the contexts that test inputs must satisfy. Based on\nsuch observation, we introduce the \\underline{C}ontext \\underline{C}onsistency\n\\underline{C}riterion (a.k.a, C3), which is a readability measurement tool that\nleverages Large Language Models to extract primitive-type (including\nstring-type) parameters' readability contexts from the source codes and checks\nwhether test inputs are consistent with those contexts. We have also proposed\nEvoSuiteC3. It leverages C3's extracted contexts to help EvoSuite generate\nreadable test inputs. We have evaluated C3's performance on $409$ \\java{}\nclasses and compared manual and automated tests' readability under C3\nmeasurement. The results are two-fold. First, The Precision, Recall, and\nF1-Score of C3's mined readability contexts are \\precision{}, \\recall{}, and\n\\fone{}, respectively. Second, under C3's measurement, the string-type input\nreadability scores of EvoSuiteC3, ChatUniTest (an LLM-based test generation\ntool), manual tests, and two traditional tools (EvoSuite and Randoop) are\n$90\\%$, $83\\%$, $68\\%$, $8\\%$, and $8\\%$, showing the traditional tools'\ninability in generating readable string-type inputs.\n","subjects":["Computing Research Repository/Software Engineering"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"zYLhR0f1Hm4wkd06O7KVwD213ISH8XO98Ie2LqW44KA","pdfSize":"856756"}