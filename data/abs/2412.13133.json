{"id":"2412.13133","title":"Analyzing Toxicity in Open Source Software Communications Using\n  Psycholinguistics and Moral Foundations Theory","authors":"Ramtin Ehsani, Rezvaneh Rezapour, Preetha Chatterjee","authorsParsed":[["Ehsani","Ramtin",""],["Rezapour","Rezvaneh",""],["Chatterjee","Preetha",""]],"versions":[{"version":"v1","created":"Tue, 17 Dec 2024 17:52:00 GMT"},{"version":"v2","created":"Wed, 18 Dec 2024 13:47:49 GMT"},{"version":"v3","created":"Mon, 27 Jan 2025 18:47:40 GMT"}],"updateDate":"2025-01-28","timestamp":1734457920000,"abstract":"  Studies have shown that toxic behavior can cause contributors to leave, and\nhinder newcomers' (especially from underrepresented communities) participation\nin Open Source Software (OSS) projects. Thus, detection of toxic language plays\na crucial role in OSS collaboration and inclusivity. Off-the-shelf toxicity\ndetectors are ineffective when applied to OSS communications, due to the\ndistinct nature of toxicity observed in these channels (e.g., entitlement and\narrogance are more frequently observed on GitHub than on Reddit or Twitter). In\nthis paper, we investigate a machine learning-based approach for the automatic\ndetection of toxic communications in OSS. We leverage psycholinguistic\nlexicons, and Moral Foundations Theory to analyze toxicity in two types of OSS\ncommunication channels; issue comments and code reviews. Our evaluation\nindicates that our approach can achieve a significant performance improvement\n(up to 7% increase in F1 score) over the existing domain-specific toxicity\ndetector. We found that using moral values as features is more effective than\nlinguistic cues, resulting in 67.50% F1-measure in identifying toxic instances\nin code review data and 64.83% in issue comments. While the detection accuracy\nis far from accurate, this improvement demonstrates the potential of\nintegrating moral and psycholinguistic features in toxicity detection models.\nThese findings highlight the importance of context-specific models that\nconsider the unique communication styles within OSS, where interpersonal and\nvalue-driven language dynamics differ markedly from general social media\nplatforms. Future work could focus on refining these models to further enhance\ndetection accuracy, possibly by incorporating community-specific norms and\nconversational context to better capture the nuanced expressions of toxicity in\nOSS environments.\n","subjects":["Computer Science/Software Engineering"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"13h098FhyccBsKoP0OazXxJocIRWCFLNrj22cJtSx0c","pdfSize":"631092"}