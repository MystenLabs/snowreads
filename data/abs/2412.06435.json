{"id":"2412.06435","title":"Simulating Human-like Daily Activities with Desire-driven Autonomy","authors":"Yiding Wang, Yuxuan Chen, Fangwei Zhong, Long Ma, Yizhou Wang","authorsParsed":[["Wang","Yiding",""],["Chen","Yuxuan",""],["Zhong","Fangwei",""],["Ma","Long",""],["Wang","Yizhou",""]],"versions":[{"version":"v1","created":"Mon, 9 Dec 2024 12:21:20 GMT"}],"updateDate":"2024-12-10","timestamp":1733746880000,"abstract":"  Existing task-oriented AI agents often depend on explicit instructions or\nexternal rewards, limiting their ability to be driven by intrinsic motivations\nlike humans. In this paper, we present a desire-driven autonomy framework to\nguide a Large Language Model-based (LLM-based) agent to simulate human-like\ndaily activities. In contrast to previous agents, our Desire-driven Autonomous\nAgent (D2A) operates on the principle of intrinsic desire, allowing it to\npropose and select tasks that fulfill its motivational framework autonomously.\nInspired by the Theory of Needs, the motivational framework incorporates an\nunderstanding of human-like desires, such as the need for social interaction,\npersonal fulfillment, and self-care. Utilizing a desire-driven task generation\nmechanism, the agent evaluates its current state and takes a sequence of\nactivities aligned with its intrinsic motivations. Through simulations, we\ndemonstrate that our Desire-driven Autonomous Agent (D2A) generates coherent,\ncontextually relevant daily activities while exhibiting variability and\nadaptability similar to human behavior. A comparative analysis with other\nLLM-based frameworks demonstrates that our approach significantly enhances the\nrationality of the simulated activities.\n","subjects":["Computer Science/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"71DVU9-xq1Guv2uRBXOuGV07l5ruphrW0kBDnA2rdbc","pdfSize":"3378458"}