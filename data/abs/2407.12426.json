{"id":"2407.12426","title":"Sharif-STR at SemEval-2024 Task 1: Transformer as a Regression Model for\n  Fine-Grained Scoring of Textual Semantic Relations","authors":"Seyedeh Fatemeh Ebrahimi, Karim Akhavan Azari, Amirmasoud Iravani,\n  Hadi Alizadeh, Zeinab Sadat Taghavi, Hossein Sameti","authorsParsed":[["Ebrahimi","Seyedeh Fatemeh",""],["Azari","Karim Akhavan",""],["Iravani","Amirmasoud",""],["Alizadeh","Hadi",""],["Taghavi","Zeinab Sadat",""],["Sameti","Hossein",""]],"versions":[{"version":"v1","created":"Wed, 17 Jul 2024 09:25:18 GMT"}],"updateDate":"2024-07-18","timestamp":1721208318000,"abstract":"  Semantic Textual Relatedness holds significant relevance in Natural Language\nProcessing, finding applications across various domains. Traditionally,\napproaches to STR have relied on knowledge-based and statistical methods.\nHowever, with the emergence of Large Language Models, there has been a paradigm\nshift, ushering in new methodologies. In this paper, we delve into the\ninvestigation of sentence-level STR within Track A (Supervised) by leveraging\nfine-tuning techniques on the RoBERTa transformer. Our study focuses on\nassessing the efficacy of this approach across different languages. Notably,\nour findings indicate promising advancements in STR performance, particularly\nin Latin languages. Specifically, our results demonstrate notable improvements\nin English, achieving a correlation of 0.82 and securing a commendable 19th\nrank. Similarly, in Spanish, we achieved a correlation of 0.67, securing the\n15th position. However, our approach encounters challenges in languages like\nArabic, where we observed a correlation of only 0.38, resulting in a 20th rank.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"llZVeh31SyYEso2asLAWhCW5mfgTRhBu2FP-5Mnudyw","pdfSize":"1359896","objectId":"0x783ad014639291900779476bee0917f6e1581b8d32a5b3df1965f97bc081230b","registeredEpoch":"3","certifiedEpoch":"3","startEpoch":"3","endEpoch":"203"}
