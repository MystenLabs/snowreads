{"id":"2412.17023","title":"Parameter-Efficient Interventions for Enhanced Model Merging","authors":"Marcin Osial, Daniel Marczak, Bartosz Zieli\\'nski","authorsParsed":[["Osial","Marcin",""],["Marczak","Daniel",""],["Zieli≈Ñski","Bartosz",""]],"versions":[{"version":"v1","created":"Sun, 22 Dec 2024 13:58:12 GMT"}],"updateDate":"2024-12-24","timestamp":1734875892000,"abstract":"  Model merging combines knowledge from task-specific models into a unified\nmulti-task model to avoid joint training on all task data. However, current\nmethods face challenges due to representation bias, which can interfere with\ntasks performance. As a remedy, we propose IntervMerge, a novel approach to\nmulti-task model merging that effectively mitigates representation bias across\nthe model using taskspecific interventions. To further enhance its efficiency,\nwe introduce mini-interventions, which modify only part of the representation,\nthereby reducing the additional parameters without compromising performance.\nExperimental results demonstrate that IntervMerge consistently outperforms the\nstate-of-the-art approaches using fewer parameters.\n","subjects":["Computer Science/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"LGTgla5C3ce1fw3TKa1DA_jpjCm_wtGZdHxuhk1clxQ","pdfSize":"6135357"}