{"id":"2412.06061","title":"Curse of Attention: A Kernel-Based Perspective for Why Transformers Fail\n  to Generalize on Time Series Forecasting and Beyond","authors":"Yekun Ke, Yingyu Liang, Zhenmei Shi, Zhao Song, Chiwun Yang","authorsParsed":[["Ke","Yekun",""],["Liang","Yingyu",""],["Shi","Zhenmei",""],["Song","Zhao",""],["Yang","Chiwun",""]],"versions":[{"version":"v1","created":"Sun, 8 Dec 2024 20:29:06 GMT"}],"updateDate":"2024-12-10","timestamp":1733689746000,"abstract":"  The application of transformer-based models on time series forecasting (TSF)\ntasks has long been popular to study. However, many of these works fail to beat\nthe simple linear residual model, and the theoretical understanding of this\nissue is still limited. In this work, we propose the first theoretical\nexplanation of the inefficiency of transformers on TSF tasks. We attribute the\nmechanism behind it to {\\bf Asymmetric Learning} in training attention\nnetworks. When the sign of the previous step is inconsistent with the sign of\nthe current step in the next-step-prediction time series, attention fails to\nlearn the residual features. This makes it difficult to generalize on\nout-of-distribution (OOD) data, especially on the sign-inconsistent\nnext-step-prediction data, with the same representation pattern, whereas a\nlinear residual network could easily accomplish it. We hope our theoretical\ninsights provide important necessary conditions for designing the expressive\nand efficient transformer-based architecture for practitioners.\n","subjects":["Computer Science/Machine Learning","Computer Science/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"rESAc9e6igHR38sBqoLjeMpqE93aysMvZUhL-rqrh0g","pdfSize":"877731"}