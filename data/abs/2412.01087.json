{"id":"2412.01087","title":"Gated Parametric Neuron for Spike-based Audio Recognition","authors":"Haoran Wang and Herui Zhang and Siyang Li and Dongrui Wu","authorsParsed":[["Wang","Haoran",""],["Zhang","Herui",""],["Li","Siyang",""],["Wu","Dongrui",""]],"versions":[{"version":"v1","created":"Mon, 2 Dec 2024 03:46:26 GMT"}],"updateDate":"2024-12-03","timestamp":1733111186000,"abstract":"  Spiking neural networks (SNNs) aim to simulate real neural networks in the\nhuman brain with biologically plausible neurons. The leaky integrate-and-fire\n(LIF) neuron is one of the most widely studied SNN architectures. However, it\nhas the vanishing gradient problem when trained with backpropagation.\nAdditionally, its neuronal parameters are often manually specified and fixed,\nin contrast to the heterogeneity of real neurons in the human brain. This paper\nproposes a gated parametric neuron (GPN) to process spatio-temporal information\neffectively with the gating mechanism. Compared with the LIF neuron, the GPN\nhas two distinguishing advantages: 1) it copes well with the vanishing\ngradients by improving the flow of gradient propagation; and, 2) it learns\nspatio-temporal heterogeneous neuronal parameters automatically. Additionally,\nwe use the same gate structure to eliminate initial neuronal parameter\nselection and design a hybrid recurrent neural network-SNN structure.\nExperiments on two spike-based audio datasets demonstrated that the GPN network\noutperformed several state-of-the-art SNNs, could mitigate vanishing gradients,\nand had spatio-temporal heterogeneous parameters. Our work shows the ability of\nSNNs to handle long-term dependencies and achieve high performance\nsimultaneously.\n","subjects":["Computer Science/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"qJsFy5fV84u1VqHTQRochwQkTQvqy_eWy8MCi10Q-FU","pdfSize":"6790133"}