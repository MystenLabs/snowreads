{
  "id": "2412.09687",
  "title": "DQA: An Efficient Method for Deep Quantization of Deep Neural Network\n  Activations",
  "authors": "Wenhao Hu, Paul Henderson, Jos\\'e Cano",
  "authorsParsed": [
    [
      "Hu",
      "Wenhao",
      ""
    ],
    [
      "Henderson",
      "Paul",
      ""
    ],
    [
      "Cano",
      "Jos√©",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Thu, 12 Dec 2024 19:03:53 GMT"
    }
  ],
  "updateDate": "2024-12-16",
  "timestamp": 1734030233000,
  "abstract": "  Quantization of Deep Neural Network (DNN) activations is a commonly used\ntechnique to reduce compute and memory demands during DNN inference, which can\nbe particularly beneficial on resource-constrained devices. To achieve high\naccuracy, existing methods for quantizing activations rely on complex\nmathematical computations or perform extensive searches for the best\nhyper-parameters. However, these expensive operations are impractical on\ndevices with limited computation capabilities, memory capacities, and energy\nbudgets. Furthermore, many existing methods do not focus on sub-6-bit (or deep)\nquantization.\n  To fill these gaps, in this paper we propose DQA (Deep Quantization of DNN\nActivations), a new method that focuses on sub-6-bit quantization of\nactivations and leverages simple shifting-based operations and Huffman coding\nto be efficient and achieve high accuracy. We evaluate DQA with 3, 4, and 5-bit\nquantization levels and three different DNN models for two different tasks,\nimage classification and image segmentation, on two different datasets. DQA\nshows significantly better accuracy (up to 29.28%) compared to the direct\nquantization method and the state-of-the-art NoisyQuant for sub-6-bit\nquantization.\n",
  "subjects": [
    "Computer Science/Machine Learning",
    "Computer Science/Computer Vision and Pattern Recognition",
    "Statistics/Machine Learning"
  ],
  "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
  "blobId": "272vybkyhCKX_ecfQbxgukk6N_iq3yCVRCQHv1B3lew",
  "pdfSize": "531276"
}