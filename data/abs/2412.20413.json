{
  "id": "2412.20413",
  "title": "EraseAnything: Enabling Concept Erasure in Rectified Flow Transformers",
  "authors": "Daiheng Gao, Shilin Lu, Shaw Walters, Wenbo Zhou, Jiaming Chu, Jie\n  Zhang, Bang Zhang, Mengxi Jia, Jian Zhao, Zhaoxin Fan, Weiming Zhang",
  "authorsParsed": [
    [
      "Gao",
      "Daiheng",
      ""
    ],
    [
      "Lu",
      "Shilin",
      ""
    ],
    [
      "Walters",
      "Shaw",
      ""
    ],
    [
      "Zhou",
      "Wenbo",
      ""
    ],
    [
      "Chu",
      "Jiaming",
      ""
    ],
    [
      "Zhang",
      "Jie",
      ""
    ],
    [
      "Zhang",
      "Bang",
      ""
    ],
    [
      "Jia",
      "Mengxi",
      ""
    ],
    [
      "Zhao",
      "Jian",
      ""
    ],
    [
      "Fan",
      "Zhaoxin",
      ""
    ],
    [
      "Zhang",
      "Weiming",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Sun, 29 Dec 2024 09:42:53 GMT"
    },
    {
      "version": "v2",
      "created": "Thu, 2 Jan 2025 13:26:55 GMT"
    }
  ],
  "updateDate": "2025-01-03",
  "timestamp": 1735465373000,
  "abstract": "  Removing unwanted concepts from large-scale text-to-image (T2I) diffusion\nmodels while maintaining their overall generative quality remains an open\nchallenge. This difficulty is especially pronounced in emerging paradigms, such\nas Stable Diffusion (SD) v3 and Flux, which incorporate flow matching and\ntransformer-based architectures. These advancements limit the transferability\nof existing concept-erasure techniques that were originally designed for the\nprevious T2I paradigm (e.g., SD v1.4). In this work, we introduce\nEraseAnything, the first method specifically developed to address concept\nerasure within the latest flow-based T2I framework. We formulate concept\nerasure as a bi-level optimization problem, employing LoRA-based parameter\ntuning and an attention map regularizer to selectively suppress undesirable\nactivations. Furthermore, we propose a self-contrastive learning strategy to\nensure that removing unwanted concepts does not inadvertently harm performance\non unrelated ones. Experimental results demonstrate that EraseAnything\nsuccessfully fills the research gap left by earlier methods in this new T2I\nparadigm, achieving state-of-the-art performance across a wide range of concept\nerasure tasks.\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition"
  ],
  "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
  "blobId": "JGJCz0bsfgd2T__ofojR5oCJZbTZsBuk7tTALARE8F0",
  "pdfSize": "47178909"
}