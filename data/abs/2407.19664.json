{"id":"2407.19664","title":"Adaptive Soft Error Protection for Deep Learning","authors":"Xinghua Xue, Cheng Liu","authorsParsed":[["Xue","Xinghua",""],["Liu","Cheng",""]],"versions":[{"version":"v1","created":"Mon, 29 Jul 2024 02:54:52 GMT"}],"updateDate":"2024-07-30","timestamp":1722221692000,"abstract":"  The rising incidence of soft errors in hardware systems represents a\nconsiderable risk to the reliability of deep learning systems and can\nprecipitate severe malfunctions. Although essential, soft error mitigation can\nimpose substantial costs on deep learning systems that are inherently demanding\nin terms of computation and memory. Previous research has primarily explored\nvariations in vulnerability among different components of computing engines or\nneural networks, aiming for selective protection to minimize protection\noverhead. Our approach diverges from these studies by recognizing that the\nsusceptibility of deep learning tasks to soft errors is heavily\ninput-dependent. Notably, some inputs are simpler for deep learning models and\ninherently exhibit greater tolerance to soft errors. Conversely, more complex\ninputs are prone to soft error impact. Based on these insights, we introduce an\nadaptive soft error protection strategy that tailors protection to the\ncomputational demands of individual inputs. To implement this strategy, we\ndevelop a metric for assessing the complexity of inputs and deploy a\nlightweight machine learning algorithm to gauge input difficulty. Subsequently,\nwe employ robust protection for challenging inputs and minimal protection for\nsimpler ones. Our experimental evaluation across diverse datasets and deep\nlearning tasks reveals that our adaptive strategy reduces the soft error\nprotection overhead by an average of 46.9%, without compromising system\nreliability.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"KojSas6cG7d6FsvgkftAZhU7gu5SJhzWhqiqqiqQSVE","pdfSize":"881970"}