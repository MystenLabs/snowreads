{"id":"2412.07481","title":"Manta: Enhancing Mamba for Few-Shot Action Recognition of Long\n  Sub-Sequence","authors":"Wenbo Huang, Jinghui Zhang, Guang Li, Lei Zhang, Shuoyuan Wang, Fang\n  Dong, Jiahui Jin, Takahiro Ogawa, Miki Haseyama","authorsParsed":[["Huang","Wenbo",""],["Zhang","Jinghui",""],["Li","Guang",""],["Zhang","Lei",""],["Wang","Shuoyuan",""],["Dong","Fang",""],["Jin","Jiahui",""],["Ogawa","Takahiro",""],["Haseyama","Miki",""]],"versions":[{"version":"v1","created":"Tue, 10 Dec 2024 13:03:42 GMT"},{"version":"v2","created":"Fri, 20 Dec 2024 05:29:17 GMT"},{"version":"v3","created":"Mon, 23 Dec 2024 04:25:42 GMT"},{"version":"v4","created":"Sun, 23 Feb 2025 13:03:13 GMT"}],"updateDate":"2025-02-25","timestamp":1733835822000,"abstract":"  In few-shot action recognition (FSAR), long sub-sequences of video naturally\nexpress entire actions more effectively. However, the high computational\ncomplexity of mainstream Transformer-based methods limits their application.\nRecent Mamba demonstrates efficiency in modeling long sequences, but directly\napplying Mamba to FSAR overlooks the importance of local feature modeling and\nalignment. Moreover, long sub-sequences within the same class accumulate\nintra-class variance, which adversely impacts FSAR performance. To solve these\nchallenges, we propose a Matryoshka MAmba and CoNtrasTive LeArning framework\n(Manta). Firstly, the Matryoshka Mamba introduces multiple Inner Modules to\nenhance local feature representation, rather than directly modeling global\nfeatures. An Outer Module captures dependencies of timeline between these local\nfeatures for implicit temporal alignment. Secondly, a hybrid contrastive\nlearning paradigm, combining both supervised and unsupervised methods, is\ndesigned to mitigate the negative effects of intra-class variance accumulation.\nThe Matryoshka Mamba and the hybrid contrastive learning paradigm operate in\ntwo parallel branches within Manta, enhancing Mamba for FSAR of long\nsub-sequence. Manta achieves new state-of-the-art performance on prominent\nbenchmarks, including SSv2, Kinetics, UCF101, and HMDB51. Extensive empirical\nstudies prove that Manta significantly improves FSAR of long sub-sequence from\nmultiple perspectives.\n","subjects":["Computer Science/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"uubBS5qs3GlaN8GwLBxaRHOArT3wcx9oQwai6Rr_tvs","pdfSize":"6151970"}