{"id":"2407.18414","title":"Adversarial Robust Decision Transformer: Enhancing Robustness of RvS via\n  Minimax Returns-to-go","authors":"Xiaohang Tang, Afonso Marques, Parameswaran Kamalaruban, Ilija\n  Bogunovic","authorsParsed":[["Tang","Xiaohang",""],["Marques","Afonso",""],["Kamalaruban","Parameswaran",""],["Bogunovic","Ilija",""]],"versions":[{"version":"v1","created":"Thu, 25 Jul 2024 22:12:47 GMT"}],"updateDate":"2024-07-29","timestamp":1721945567000,"abstract":"  Decision Transformer (DT), as one of the representative Reinforcement\nLearning via Supervised Learning (RvS) methods, has achieved strong performance\nin offline learning tasks by leveraging the powerful Transformer architecture\nfor sequential decision-making. However, in adversarial environments, these\nmethods can be non-robust, since the return is dependent on the strategies of\nboth the decision-maker and adversary. Training a probabilistic model\nconditioned on observed return to predict action can fail to generalize, as the\ntrajectories that achieve a return in the dataset might have done so due to a\nweak and suboptimal behavior adversary. To address this, we propose a\nworst-case-aware RvS algorithm, the Adversarial Robust Decision Transformer\n(ARDT), which learns and conditions the policy on in-sample minimax\nreturns-to-go. ARDT aligns the target return with the worst-case return learned\nthrough minimax expectile regression, thereby enhancing robustness against\npowerful test-time adversaries. In experiments conducted on sequential games\nwith full data coverage, ARDT can generate a maximin (Nash Equilibrium)\nstrategy, the solution with the largest adversarial robustness. In large-scale\nsequential games and continuous adversarial RL environments with partial data\ncoverage, ARDT demonstrates significantly superior robustness to powerful\ntest-time adversaries and attains higher worst-case returns compared to\ncontemporary DT methods.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"6zJwS1PBE0eXFyc31eFZvaa6VjPAQ71A7wSC3gaLHXM","pdfSize":"934004","objectId":"0x10df4cdbdd281a6f8183592f37b5e1845451a9eac144c90717c1a2ca9c0648ec","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
