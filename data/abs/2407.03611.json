{"id":"2407.03611","title":"An Empirical Study on Capability of Large Language Models in\n  Understanding Code Semantics","authors":"Thu-Trang Nguyen, Thanh Trong Vu, Hieu Dinh Vo and Son Nguyen","authorsParsed":[["Nguyen","Thu-Trang",""],["Vu","Thanh Trong",""],["Vo","Hieu Dinh",""],["Nguyen","Son",""]],"versions":[{"version":"v1","created":"Thu, 4 Jul 2024 03:40:58 GMT"}],"updateDate":"2024-07-08","timestamp":1720064458000,"abstract":"  Large Language Models for Code (code LLMs) have demonstrated remarkable\nperformance across various software engineering (SE) tasks, increasing the\napplication of code LLMs in software development. Despite the success of code\nLLMs, there remain significant concerns about the actual capabilities and\nreliability of these models, \"whether these models really learn the semantics\nof code from the training data and leverage the learned knowledge to perform\nthe SE tasks\". In this paper, we introduce EMPICA, a comprehensive framework\ndesigned to systematically and empirically evaluate the capabilities of code\nLLMs in understanding code semantics. Specifically, EMPICA systematically\nintroduces controlled modifications/transformations into the input code and\nexamines the models' responses. Generally, code LLMs must be robust to\nsemantically equivalent code inputs and be sensitive to non-equivalent ones for\nall SE tasks. Specifically, for every SE task, given an input code snippet c\nand its semantic equivalent variants, code LLMs must robustly produce\nconsistent/equivalent outputs while they are expected to generate different\noutputs for c and its semantic non-equivalent variants. Our experimental\nresults on three representative code understanding tasks, including code\nsummarization, method name prediction, and output prediction, reveal that the\nrobustness and sensitivity of the state-of-the-art code LLMs to code\ntransformations vary significantly across tasks and transformation operators.\nIn addition, the code LLMs exhibit better robustness to the semantic preserving\ntransformations than their sensitivity to the semantic non-preserving\ntransformations. These results highlight a need to enhance the model's\ncapabilities of understanding code semantics, especially the sensitivity\nproperty.\n","subjects":["Computing Research Repository/Software Engineering","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"3MVmTr_PBaRSXgp-Q8YNA_1QZ8--8SBe-A96ecJ2P5Q","pdfSize":"3993394"}