{
  "id": "2412.01978",
  "title": "Human-centred test and evaluation of military AI",
  "authors": "David Helmer, Michael Boardman, S. Kate Conroy, Adam J. Hepworth,\n  Manoj Harjani",
  "authorsParsed": [
    [
      "Helmer",
      "David",
      ""
    ],
    [
      "Boardman",
      "Michael",
      ""
    ],
    [
      "Conroy",
      "S. Kate",
      ""
    ],
    [
      "Hepworth",
      "Adam J.",
      ""
    ],
    [
      "Harjani",
      "Manoj",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Mon, 2 Dec 2024 21:14:55 GMT"
    }
  ],
  "updateDate": "2024-12-04",
  "timestamp": 1733174095000,
  "abstract": "  The REAIM 2024 Blueprint for Action states that AI applications in the\nmilitary domain should be ethical and human-centric and that humans must remain\nresponsible and accountable for their use and effects. Developing rigorous test\nand evaluation, verification and validation (TEVV) frameworks will contribute\nto robust oversight mechanisms. TEVV in the development and deployment of AI\nsystems needs to involve human users throughout the lifecycle. Traditional\nhuman-centred test and evaluation methods from human factors need to be adapted\nfor deployed AI systems that require ongoing monitoring and evaluation. The\nlanguage around AI-enabled systems should be shifted to inclusion of the\nhuman(s) as a component of the system. Standards and requirements supporting\nthis adjusted definition are needed, as are metrics and means to evaluate them.\nThe need for dialogue between technologists and policymakers on human-centred\nTEVV will be evergreen, but dialogue needs to be initiated with an objective in\nmind for it to be productive. Development of TEVV throughout system lifecycle\nis critical to support this evolution including the issue of human scalability\nand impact on scale of achievable testing. Communication between technical and\nnon technical communities must be improved to ensure operators and\npolicy-makers understand risk assumed by system use and to better inform\nresearch and development. Test and evaluation in support of responsible AI\ndeployment must include the effect of the human to reflect operationally\nrealised system performance. Means of communicating the results of TEVV to\nthose using and making decisions regarding the use of AI based systems will be\nkey in informing risk based decisions regarding use.\n",
  "subjects": [
    "Computer Science/Human-Computer Interaction",
    "Computer Science/Artificial Intelligence"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "UC4rFTVGKBL0n1iVmEwQn8sKlSUir-5imbwz02eUPp0",
  "pdfSize": "148017"
}