{
  "id": "2412.11988",
  "title": "SciFaultyQA: Benchmarking LLMs on Faulty Science Question Detection with\n  a GAN-Inspired Approach to Synthetic Dataset Generation",
  "authors": "Debarshi Kundu",
  "authorsParsed": [
    [
      "Kundu",
      "Debarshi",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Mon, 16 Dec 2024 17:11:48 GMT"
    }
  ],
  "updateDate": "2024-12-17",
  "timestamp": 1734369108000,
  "abstract": "  Consider the problem: ``If one man and one woman can produce one child in one\nyear, how many children will be produced by one woman and three men in 0.5\nyears?\" Current large language models (LLMs) such as GPT-4o, GPT-o1-preview,\nand Gemini Flash frequently answer \"0.5,\" which does not make sense. While\nthese models sometimes acknowledge the unrealistic nature of the question, in\nmany cases (8 out of 10 trials), they provide the nonsensical answer of \"0.5\nchild.\" Additionally, temporal variation has been observed: if an LLM answers\ncorrectly once (by recognizing the faulty nature of the question), subsequent\nresponses are more likely to also reflect this understanding. However, this is\ninconsistent.\n  These types of questions have motivated us to develop a dataset of science\nquestions, SciFaultyQA, where the questions themselves are intentionally\nfaulty. We observed that LLMs often proceed to answer these flawed questions\nwithout recognizing their inherent issues, producing results that are logically\nor scientifically invalid. By analyzing such patterns, we developed a novel\nmethod for generating synthetic datasets to evaluate and benchmark the\nperformance of various LLMs in identifying these flawed questions. We have also\ndeveloped novel approaches to reduce the errors.\n",
  "subjects": [
    "Computer Science/Computation and Language",
    "Computer Science/Machine Learning"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "1IrV5_NX3HKVeMd8Vs1I5qDRkoDnpq52yifIS1S4Y3I",
  "pdfSize": "163532"
}