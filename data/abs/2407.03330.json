{"id":"2407.03330","title":"Efficient Visibility Approximation for Game AI using Neural\n  Omnidirectional Distance Fields","authors":"Zhi Ying, Nicholas Edwards and Mikhail Kutuzov","authorsParsed":[["Ying","Zhi",""],["Edwards","Nicholas",""],["Kutuzov","Mikhail",""]],"versions":[{"version":"v1","created":"Thu, 9 May 2024 11:44:10 GMT"}],"updateDate":"2024-07-08","timestamp":1715255050000,"abstract":"  Visibility information is critical in game AI applications, but the\ncomputational cost of raycasting-based methods poses a challenge for real-time\nsystems. To address this challenge, we propose a novel method that represents a\npartitioned game scene as neural Omnidirectional Distance Fields (ODFs),\nallowing scalable and efficient visibility approximation between positions\nwithout raycasting. For each position of interest, we map its omnidirectional\ndistance data from the spherical surface onto a UV plane. We then use\nmulti-resolution grids and bilinearly interpolated features to encode\ndirections. This allows us to use a compact multi-layer perceptron (MLP) to\nreconstruct the high-frequency directional distance data at these positions,\nensuring fast inference speed. We demonstrate the effectiveness of our method\nthrough offline experiments and in-game evaluation. For in-game evaluation, we\nconduct a side-by-side comparison with raycasting-based visibility tests in\nthree different scenes. Using a compact MLP (128 neurons and 2 layers), our\nmethod achieves an average cold start speedup of 9.35 times and warm start\nspeedup of 4.8 times across these scenes. In addition, unlike the\nraycasting-based method, whose evaluation time is affected by the\ncharacteristics of the scenes, our method's evaluation time remains constant.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Graphics"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"j72uvikxFh29F1QjKUeg51OJ1bnm9u3GkggwVJJA1yo","pdfSize":"13591638"}