{"id":"2407.07712","title":"Deep-Graph-Sprints: Accelerated Representation Learning in\n  Continuous-Time Dynamic Graphs","authors":"Ahmad Naser Eddin, Jacopo Bono, David Apar\\'icio, Hugo Ferreira, Pedro\n  Ribeiro, Pedro Bizarro","authorsParsed":[["Eddin","Ahmad Naser",""],["Bono","Jacopo",""],["Apar√≠cio","David",""],["Ferreira","Hugo",""],["Ribeiro","Pedro",""],["Bizarro","Pedro",""]],"versions":[{"version":"v1","created":"Wed, 10 Jul 2024 14:44:25 GMT"},{"version":"v2","created":"Tue, 23 Jul 2024 17:01:12 GMT"}],"updateDate":"2024-07-24","timestamp":1720622665000,"abstract":"  Continuous-time dynamic graphs (CTDGs) are essential for modeling\ninterconnected, evolving systems. Traditional methods for extracting knowledge\nfrom these graphs often depend on feature engineering or deep learning. Feature\nengineering is limited by the manual and time-intensive nature of crafting\nfeatures, while deep learning approaches suffer from high inference latency,\nmaking them impractical for real-time applications. This paper introduces\nDeep-Graph-Sprints (DGS), a novel deep learning architecture designed for\nefficient representation learning on CTDGs with low-latency inference\nrequirements. We benchmark DGS against state-of-the-art feature engineering and\ngraph neural network methods using five diverse datasets. The results indicate\nthat DGS achieves competitive performance while improving inference speed up to\n12x compared to other deep learning approaches on our tested benchmarks. Our\nmethod effectively bridges the gap between deep representation learning and\nlow-latency application requirements for CTDGs.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Social and Information Networks"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"L7X5IMGNYFQ3Wgl93Gaim0OsPYEXkOCf3_4HB7cr8yg","pdfSize":"988094"}