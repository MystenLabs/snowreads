{
  "id": "2412.09173",
  "title": "ReFF: Reinforcing Format Faithfulness in Language Models across Varied\n  Tasks",
  "authors": "Jiashu Yao, Heyan Huang, Zeming Liu, Haoyu Wen, Wei Su, Boao Qian,\n  Yuhang Guo",
  "authorsParsed": [
    [
      "Yao",
      "Jiashu",
      ""
    ],
    [
      "Huang",
      "Heyan",
      ""
    ],
    [
      "Liu",
      "Zeming",
      ""
    ],
    [
      "Wen",
      "Haoyu",
      ""
    ],
    [
      "Su",
      "Wei",
      ""
    ],
    [
      "Qian",
      "Boao",
      ""
    ],
    [
      "Guo",
      "Yuhang",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Thu, 12 Dec 2024 11:03:25 GMT"
    }
  ],
  "updateDate": "2024-12-13",
  "timestamp": 1734001405000,
  "abstract": "  Following formatting instructions to generate well-structured content is a\nfundamental yet often unmet capability for large language models (LLMs). To\nstudy this capability, which we refer to as format faithfulness, we present\nFormatBench, a comprehensive format-related benchmark. Compared to previous\nformat-related benchmarks, FormatBench involves a greater variety of tasks in\nterms of application scenes (traditional NLP tasks, creative works, autonomous\nagency tasks), human-LLM interaction styles (single-turn instruction,\nmulti-turn chat), and format types (inclusion, wrapping, length, coding).\nMoreover, each task in FormatBench is attached with a format checker program.\nExtensive experiments on the benchmark reveal that state-of-the-art open- and\nclosed-source LLMs still suffer from severe deficiency in format faithfulness.\nBy virtue of the decidable nature of formats, we propose to Reinforce Format\nFaithfulness (ReFF) to help LLMs generate formatted output as instructed\nwithout compromising general quality. Without any annotated data, ReFF can\nsubstantially improve the format faithfulness rate (e.g., from 21.6% in\noriginal LLaMA3 to 95.0% on caption segmentation task), while keep the general\nquality comparable (e.g., from 47.3 to 46.4 in F1 scores). Combined with\nlabeled training data, ReFF can simultaneously improve both format faithfulness\n(e.g., from 21.6% in original LLaMA3 to 75.5%) and general quality (e.g., from\n47.3 to 61.6 in F1 scores). We further offer an interpretability analysis to\nexplain how ReFF improves both format faithfulness and general quality.\n",
  "subjects": [
    "Computer Science/Computation and Language"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "ZaEjAB9Fhr9l25L8coL-5kwvci-XIzuc7y3YeBjrurc",
  "pdfSize": "3313928"
}