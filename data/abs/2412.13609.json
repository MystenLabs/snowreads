{
  "id": "2412.13609",
  "title": "Sign-IDD: Iconicity Disentangled Diffusion for Sign Language Production",
  "authors": "Shengeng Tang, Jiayi He, Dan Guo, Yanyan Wei, Feng Li, Richang Hong",
  "authorsParsed": [
    [
      "Tang",
      "Shengeng",
      ""
    ],
    [
      "He",
      "Jiayi",
      ""
    ],
    [
      "Guo",
      "Dan",
      ""
    ],
    [
      "Wei",
      "Yanyan",
      ""
    ],
    [
      "Li",
      "Feng",
      ""
    ],
    [
      "Hong",
      "Richang",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Wed, 18 Dec 2024 08:36:35 GMT"
    },
    {
      "version": "v2",
      "created": "Thu, 19 Dec 2024 03:12:19 GMT"
    }
  ],
  "updateDate": "2024-12-20",
  "timestamp": 1734510995000,
  "abstract": "  Sign Language Production (SLP) aims to generate semantically consistent sign\nvideos from textual statements, where the conversion from textual glosses to\nsign poses (G2P) is a crucial step. Existing G2P methods typically treat sign\nposes as discrete three-dimensional coordinates and directly fit them, which\noverlooks the relative positional relationships among joints. To this end, we\nprovide a new perspective, constraining joint associations and gesture details\nby modeling the limb bones to improve the accuracy and naturalness of the\ngenerated poses. In this work, we propose a pioneering iconicity disentangled\ndiffusion framework, termed Sign-IDD, specifically designed for SLP. Sign-IDD\nincorporates a novel Iconicity Disentanglement (ID) module to bridge the gap\nbetween relative positions among joints. The ID module disentangles the\nconventional 3D joint representation into a 4D bone representation, comprising\nthe 3D spatial direction vector and 1D spatial distance vector between adjacent\njoints. Additionally, an Attribute Controllable Diffusion (ACD) module is\nintroduced to further constrain joint associations, in which the attribute\nseparation layer aims to separate the bone direction and length attributes, and\nthe attribute control layer is designed to guide the pose generation by\nleveraging the above attributes. The ACD module utilizes the gloss embeddings\nas semantic conditions and finally generates sign poses from noise embeddings.\nExtensive experiments on PHOENIX14T and USTC-CSL datasets validate the\neffectiveness of our method. The code is available at:\nhttps://github.com/NaVi-start/Sign-IDD.\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition",
    "Computer Science/Multimedia"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "frjAI3lTzO6hLlePkzzuWa1sMVW06LchrS-ibU8WEGE",
  "pdfSize": "1832608"
}