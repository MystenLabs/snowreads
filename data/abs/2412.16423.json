{"id":"2412.16423","title":"Technical Report: Small Language Model for Japanese Clinical and\n  Medicine","authors":"Shogo Watanabe","authorsParsed":[["Watanabe","Shogo",""]],"versions":[{"version":"v1","created":"Sat, 21 Dec 2024 01:12:48 GMT"}],"updateDate":"2024-12-24","timestamp":1734743568000,"abstract":"  This report presents a small language model (SLM) for Japanese clinical and\nmedicine, named NCVC-slm-1. This 1B parameters model was trained using Japanese\ntext classified to be of high-quality. Moreover, NCVC-slm-1 was augmented with\nrespect to clinical and medicine content that includes the variety of diseases,\ndrugs, and examinations. Using a carefully designed pre-processing, a\nspecialized morphological analyzer and tokenizer, this small and light-weight\nmodel performed not only to generate text but also indicated the feasibility of\nunderstanding clinical and medicine text. In comparison to other large language\nmodels, a fine-tuning NCVC-slm-1 demonstrated the highest scores on 6 tasks of\ntotal 8 on JMED-LLM. According to this result, SLM indicated the feasibility of\nperforming several downstream tasks in the field of clinical and medicine.\nHopefully, NCVC-slm-1 will be contributed to develop and accelerate the field\nof clinical and medicine for a bright future.\n","subjects":["Computer Science/Computation and Language","Computer Science/Artificial Intelligence","Computer Science/Machine Learning"],"license":"http://creativecommons.org/licenses/by-sa/4.0/","blobId":"EkMk_GIgO14Rajm8X6uaxJ3sbZPDWJOwqomJkjuO3Ow","pdfSize":"8884700"}