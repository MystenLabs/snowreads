{
  "id": "2412.15652",
  "title": "Error-driven Data-efficient Large Multimodal Model Tuning",
  "authors": "Barry Menglong Yao (UC Davis), Qifan Wang (Meta AI), Lifu Huang (UC\n  Davis)",
  "authorsParsed": [
    [
      "Yao",
      "Barry Menglong",
      "",
      "UC Davis"
    ],
    [
      "Wang",
      "Qifan",
      "",
      "Meta AI"
    ],
    [
      "Huang",
      "Lifu",
      "",
      "UC\n  Davis"
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Fri, 20 Dec 2024 08:07:11 GMT"
    }
  ],
  "updateDate": "2024-12-23",
  "timestamp": 1734682031000,
  "abstract": "  Large Multimodal Models (LMMs) have demonstrated impressive performance\nacross numerous academic benchmarks. However, fine-tuning still remains\nessential to achieve satisfactory performance on downstream tasks, while the\ntask-specific tuning samples are usually not readily available or expensive and\ntime-consuming to obtain. To address this, we propose an error-driven\ndata-efficient tuning framework that aims to efficiently adapt generic LMMs to\nnewly emerging tasks without requiring any task-specific training samples. In\nour approach, a generic LMM, acting as a student model, is first evaluated on a\nsmall validation set of the target task, and then a more powerful model, acting\nas a teacher model, identifies the erroneous steps within the student model's\nreasoning steps and analyzes its capability gaps from fully addressing the\ntarget task. Based on these gaps, targeted training samples are further\nretrieved from existing task-agnostic datasets to tune the student model and\ntailor it to the target task. We perform extensive experiments across three\ndifferent training data scales and seven tasks, demonstrating that our training\nparadigm significantly and efficiently improves LMM's performance on downstream\ntasks, achieving an average performance boost of 7.01%.\n",
  "subjects": [
    "Computer Science/Computation and Language"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "oQ0s0Hf-3Z5C8a1IQJOdcCMtdtNsasrfre2fzySq6Oc",
  "pdfSize": "858147"
}