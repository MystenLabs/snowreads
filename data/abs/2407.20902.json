{"id":"2407.20902","title":"Machine learning surrogates for efficient hydrologic modeling: Insights\n  from stochastic simulations of managed aquifer recharge","authors":"Timothy Dai and Kate Maher and Zach Perzan","authorsParsed":[["Dai","Timothy",""],["Maher","Kate",""],["Perzan","Zach",""]],"versions":[{"version":"v1","created":"Tue, 30 Jul 2024 15:24:27 GMT"}],"updateDate":"2024-07-31","timestamp":1722353067000,"abstract":"  Process-based hydrologic models are invaluable tools for understanding the\nterrestrial water cycle and addressing modern water resources problems.\nHowever, many hydrologic models are computationally expensive and, depending on\nthe resolution and scale, simulations can take on the order of hours to days to\ncomplete. While techniques such as uncertainty quantification and optimization\nhave become valuable tools for supporting management decisions, these analyses\ntypically require hundreds of model simulations, which are too computationally\nexpensive to perform with a process-based hydrologic model. To address this\ngap, we propose a hybrid modeling workflow in which a process-based model is\nused to generate an initial set of simulations and a machine learning (ML)\nsurrogate model is then trained to perform the remaining simulations required\nfor downstream analysis. As a case study, we apply this workflow to simulations\nof variably saturated groundwater flow at a prospective managed aquifer\nrecharge (MAR) site. We compare the accuracy and computational efficiency of\nseveral ML architectures, including deep convolutional networks, recurrent\nneural networks, vision transformers, and networks with Fourier transforms. Our\nresults demonstrate that ML surrogate models can achieve under 10% mean\nabsolute percentage error and yield order-of-magnitude runtime savings over\nprocessed-based models. We also offer practical recommendations for training\nhydrologic surrogate models, including implementing data normalization to\nimprove accuracy, using a normalized loss function to improve training\nstability and downsampling input features to decrease memory requirements.\n","subjects":["Physics/Geophysics","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"Zc5CeaOlgfVha6f-EalQdvugRqX3I-vHRzVfY5iiDGc","pdfSize":"3367045","objectId":"0x27a508bde0d395956b304d3f7171420210a88033870054ad0343d25d5ed20ac0","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
