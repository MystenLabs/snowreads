{"id":"2412.16195","title":"Machine Learning-Based Automated Assessment of Intracorporeal Suturing\n  in Laparoscopic Fundoplication","authors":"Shekhar Madhav Khairnar, Huu Phong Nguyen, Alexis Desir, Carla\n  Holcomb, Daniel J. Scott, Ganesh Sankaranarayanan","authorsParsed":[["Khairnar","Shekhar Madhav",""],["Nguyen","Huu Phong",""],["Desir","Alexis",""],["Holcomb","Carla",""],["Scott","Daniel J.",""],["Sankaranarayanan","Ganesh",""]],"versions":[{"version":"v1","created":"Mon, 16 Dec 2024 17:44:44 GMT"}],"updateDate":"2024-12-24","timestamp":1734371084000,"abstract":"  Automated assessment of surgical skills using artificial intelligence (AI)\nprovides trainees with instantaneous feedback. After bimanual tool motions are\ncaptured, derived kinematic metrics are reliable predictors of performance in\nlaparoscopic tasks. Implementing automated tool tracking requires\ntime-intensive human annotation. We developed AI-based tool tracking using the\nSegment Anything Model (SAM) to eliminate the need for human annotators. Here,\nwe describe a study evaluating the usefulness of our tool tracking model in\nautomated assessment during a laparoscopic suturing task in the fundoplication\nprocedure. An automated tool tracking model was applied to recorded videos of\nNissen fundoplication on porcine bowel. Surgeons were grouped as novices\n(PGY1-2) and experts (PGY3-5, attendings). The beginning and end of each\nsuturing step were segmented, and motions of the left and right tools were\nextracted. A low-pass filter with a 24 Hz cut-off frequency removed noise.\nPerformance was assessed using supervised and unsupervised models, and an\nablation study compared results. Kinematic features--RMS velocity, RMS\nacceleration, RMS jerk, total path length, and Bimanual Dexterity--were\nextracted and analyzed using Logistic Regression, Random Forest, Support Vector\nClassifier, and XGBoost. PCA was performed for feature reduction. For\nunsupervised learning, a Denoising Autoencoder (DAE) model with classifiers,\nsuch as a 1-D CNN and traditional models, was trained. Data were extracted for\n28 participants (9 novices, 19 experts). Supervised learning with PCA and\nRandom Forest achieved an accuracy of 0.795 and an F1 score of 0.778. The\nunsupervised 1-D CNN achieved superior results with an accuracy of 0.817 and an\nF1 score of 0.806, eliminating the need for kinematic feature computation. We\ndemonstrated an AI model capable of automated performance classification,\nindependent of human annotation.\n","subjects":["Computer Science/Computer Vision and Pattern Recognition","Computer Science/Artificial Intelligence","Computer Science/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"fE5AuOiWjgwn9aVpXYmNQzWG8tQmyiNuWNPr1BmybK8","pdfSize":"1079346"}