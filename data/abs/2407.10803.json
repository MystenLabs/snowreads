{"id":"2407.10803","title":"DINO Pre-training for Vision-based End-to-end Autonomous Driving","authors":"Shubham Juneja, Povilas Daniu\\v{s}is, Virginijus Marcinkevi\\v{c}ius","authorsParsed":[["Juneja","Shubham",""],["Daniušis","Povilas",""],["Marcinkevičius","Virginijus",""]],"versions":[{"version":"v1","created":"Mon, 15 Jul 2024 15:18:57 GMT"}],"updateDate":"2024-07-16","timestamp":1721056737000,"abstract":"  In this article, we focus on the pre-training of visual autonomous driving\nagents in the context of imitation learning. Current methods often rely on a\nclassification-based pre-training, which we hypothesise to be holding back from\nextending capabilities of implicit image understanding. We propose pre-training\nthe visual encoder of a driving agent using the self-distillation with no\nlabels (DINO) method, which relies on a self-supervised learning paradigm.% and\nis trained on an unrelated task. Our experiments in CARLA environment in\naccordance with the Leaderboard benchmark reveal that the proposed pre-training\nis more efficient than classification-based pre-training, and is on par with\nthe recently proposed pre-training based on visual place recognition (VPRPre).\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Machine Learning","Computing Research Repository/Robotics"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"qYOp8USQUlecPNDvogtQ_7TySsAT68JA0pwqBrgDR_0","pdfSize":"432465","objectId":"0x97dc9696582ca4d8bc7b45efe995661e12185453960c422a97da533dd261c175","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
