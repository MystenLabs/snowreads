{
  "id": "2412.13656",
  "title": "GLCF: A Global-Local Multimodal Coherence Analysis Framework for Talking\n  Face Generation Detection",
  "authors": "Xiaocan Chen, Qilin Yin, Jiarui Liu, Wei Lu, Xiangyang Luo, Jiantao\n  Zhou",
  "authorsParsed": [
    [
      "Chen",
      "Xiaocan",
      ""
    ],
    [
      "Yin",
      "Qilin",
      ""
    ],
    [
      "Liu",
      "Jiarui",
      ""
    ],
    [
      "Lu",
      "Wei",
      ""
    ],
    [
      "Luo",
      "Xiangyang",
      ""
    ],
    [
      "Zhou",
      "Jiantao",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Wed, 18 Dec 2024 09:34:59 GMT"
    },
    {
      "version": "v2",
      "created": "Mon, 24 Feb 2025 06:29:16 GMT"
    }
  ],
  "updateDate": "2025-02-25",
  "timestamp": 1734514499000,
  "abstract": "  Talking face generation (TFG) allows for producing lifelike talking videos of\nany character using only facial images and accompanying text. Abuse of this\ntechnology could pose significant risks to society, creating the urgent need\nfor research into corresponding detection methods. However, research in this\nfield has been hindered by the lack of public datasets. In this paper, we\nconstruct the first large-scale multi-scenario talking face dataset (MSTF),\nwhich contains 22 audio and video forgery techniques, filling the gap of\ndatasets in this field. The dataset covers 11 generation scenarios and more\nthan 20 semantic scenarios, closer to the practical application scenario of\nTFG. Besides, we also propose a TFG detection framework, which leverages the\nanalysis of both global and local coherence in the multimodal content of TFG\nvideos. Therefore, a region-focused smoothness detection module (RSFDM) and a\ndiscrepancy capture-time frame aggregation module (DCTAM) are introduced to\nevaluate the global temporal coherence of TFG videos, aggregating multi-grained\nspatial information. Additionally, a visual-audio fusion module (V-AFM) is\ndesigned to evaluate audiovisual coherence within a localized temporal\nperspective. Comprehensive experiments demonstrate the reasonableness and\nchallenges of our datasets, while also indicating the superiority of our\nproposed method compared to the state-of-the-art deepfake detection approaches.\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition"
  ],
  "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
  "blobId": "Ow2VcSfHs98Mvduseg8LcFgQXLk-LgX273N940mz7_c",
  "pdfSize": "3509891"
}