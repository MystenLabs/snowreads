{"id":"2412.01199","title":"TinyFusion: Diffusion Transformers Learned Shallow","authors":"Gongfan Fang, Kunjun Li, Xinyin Ma, Xinchao Wang","authorsParsed":[["Fang","Gongfan",""],["Li","Kunjun",""],["Ma","Xinyin",""],["Wang","Xinchao",""]],"versions":[{"version":"v1","created":"Mon, 2 Dec 2024 07:05:39 GMT"}],"updateDate":"2024-12-03","timestamp":1733123139000,"abstract":"  Diffusion Transformers have demonstrated remarkable capabilities in image\ngeneration but often come with excessive parameterization, resulting in\nconsiderable inference overhead in real-world applications. In this work, we\npresent TinyFusion, a depth pruning method designed to remove redundant layers\nfrom diffusion transformers via end-to-end learning. The core principle of our\napproach is to create a pruned model with high recoverability, allowing it to\nregain strong performance after fine-tuning. To accomplish this, we introduce a\ndifferentiable sampling technique to make pruning learnable, paired with a\nco-optimized parameter to simulate future fine-tuning. While prior works focus\non minimizing loss or error after pruning, our method explicitly models and\noptimizes the post-fine-tuning performance of pruned models. Experimental\nresults indicate that this learnable paradigm offers substantial benefits for\nlayer pruning of diffusion transformers, surpassing existing importance-based\nand error-based methods. Additionally, TinyFusion exhibits strong\ngeneralization across diverse architectures, such as DiTs, MARs, and SiTs.\nExperiments with DiT-XL show that TinyFusion can craft a shallow diffusion\ntransformer at less than 7% of the pre-training cost, achieving a 2$\\times$\nspeedup with an FID score of 2.86, outperforming competitors with comparable\nefficiency. Code is available at https://github.com/VainF/TinyFusion.\n","subjects":["Computer Science/Computer Vision and Pattern Recognition","Computer Science/Artificial Intelligence","Computer Science/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"Mw_pk8_zVx0Y0aZnrl-3BOHXYipqMuC-_FsU1vDJzd4","pdfSize":"6784045"}