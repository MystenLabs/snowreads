{"id":"2407.02066","title":"BiasDora: Exploring Hidden Biased Associations in Vision-Language Models","authors":"Chahat Raj, Anjishnu Mukherjee, Aylin Caliskan, Antonios\n  Anastasopoulos, Ziwei Zhu","authorsParsed":[["Raj","Chahat",""],["Mukherjee","Anjishnu",""],["Caliskan","Aylin",""],["Anastasopoulos","Antonios",""],["Zhu","Ziwei",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 08:55:40 GMT"}],"updateDate":"2024-07-03","timestamp":1719910540000,"abstract":"  Existing works examining Vision Language Models (VLMs) for social biases\npredominantly focus on a limited set of documented bias associations, such as\ngender:profession or race:crime. This narrow scope often overlooks a vast range\nof unexamined implicit associations, restricting the identification and, hence,\nmitigation of such biases. We address this gap by probing VLMs to (1) uncover\nhidden, implicit associations across 9 bias dimensions. We systematically\nexplore diverse input and output modalities and (2) demonstrate how biased\nassociations vary in their negativity, toxicity, and extremity. Our work (3)\nidentifies subtle and extreme biases that are typically not recognized by\nexisting methodologies. We make the Dataset of retrieved associations, (Dora),\npublicly available here https://github.com/chahatraj/BiasDora.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by-sa/4.0/","blobId":"8atDYZcpbl0rwhZJ1RgweFs0IyJjs-5DI1kUb5BpLZQ","pdfSize":"28620897"}