{"id":"2407.16726","title":"Topology Reorganized Graph Contrastive Learning with Mitigating Semantic\n  Drift","authors":"Jiaqiang Zhang, Songcan Chen","authorsParsed":[["Zhang","Jiaqiang",""],["Chen","Songcan",""]],"versions":[{"version":"v1","created":"Tue, 23 Jul 2024 13:55:33 GMT"}],"updateDate":"2024-07-25","timestamp":1721742933000,"abstract":"  Graph contrastive learning (GCL) is an effective paradigm for node\nrepresentation learning in graphs. The key components hidden behind GCL are\ndata augmentation and positive-negative pair selection. Typical data\naugmentations in GCL, such as uniform deletion of edges, are generally blind\nand resort to local perturbation, which is prone to producing under-diversity\nviews. Additionally, there is a risk of making the augmented data traverse to\nother classes. Moreover, most methods always treat all other samples as\nnegatives. Such a negative pairing naturally results in sampling bias and\nlikewise may make the learned representation suffer from semantic drift.\nTherefore, to increase the diversity of the contrastive view, we propose two\nsimple and effective global topological augmentations to compensate current\nGCL. One is to mine the semantic correlation between nodes in the feature\nspace. The other is to utilize the algebraic properties of the adjacency matrix\nto characterize the topology by eigen-decomposition. With the help of both, we\ncan retain important edges to build a better view. To reduce the risk of\nsemantic drift, a prototype-based negative pair selection is further designed\nwhich can filter false negative samples. Extensive experiments on various tasks\ndemonstrate the advantages of the model compared to the state-of-the-art\nmethods.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"rz7c_G7PwdtH5fmP-JfI3zzWsxOmP0VY7Qv0I6xnTVg","pdfSize":"4029723"}