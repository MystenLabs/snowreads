{"id":"2412.00103","title":"MLLM-Search: A Zero-Shot Approach to Finding People using Multimodal\n  Large Language Models","authors":"Angus Fung, Aaron Hao Tan, Haitong Wang, Beno Benhabib, Goldie Nejat","authorsParsed":[["Fung","Angus",""],["Tan","Aaron Hao",""],["Wang","Haitong",""],["Benhabib","Beno",""],["Nejat","Goldie",""]],"versions":[{"version":"v1","created":"Wed, 27 Nov 2024 21:59:29 GMT"}],"updateDate":"2024-12-03","timestamp":1732744769000,"abstract":"  Robotic search of people in human-centered environments, including healthcare\nsettings, is challenging as autonomous robots need to locate people without\ncomplete or any prior knowledge of their schedules, plans or locations.\nFurthermore, robots need to be able to adapt to real-time events that can\ninfluence a person's plan in an environment. In this paper, we present\nMLLM-Search, a novel zero-shot person search architecture that leverages\nmultimodal large language models (MLLM) to address the mobile robot problem of\nsearching for a person under event-driven scenarios with varying user\nschedules. Our approach introduces a novel visual prompting method to provide\nrobots with spatial understanding of the environment by generating a spatially\ngrounded waypoint map, representing navigable waypoints by a topological graph\nand regions by semantic labels. This is incorporated into a MLLM with a region\nplanner that selects the next search region based on the semantic relevance to\nthe search scenario, and a waypoint planner which generates a search path by\nconsidering the semantically relevant objects and the local spatial context\nthrough our unique spatial chain-of-thought prompting approach. Extensive 3D\nphotorealistic experiments were conducted to validate the performance of\nMLLM-Search in searching for a person with a changing schedule in different\nenvironments. An ablation study was also conducted to validate the main design\nchoices of MLLM-Search. Furthermore, a comparison study with state-of-the art\nsearch methods demonstrated that MLLM-Search outperforms existing methods with\nrespect to search efficiency. Real-world experiments with a mobile robot in a\nmulti-room floor of a building showed that MLLM-Search was able to generalize\nto finding a person in a new unseen environment.\n","subjects":["Computer Science/Robotics","Computer Science/Artificial Intelligence","Computer Science/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"Kzjn1d7ixKz4GbPH_O7Du0Qm45qnKtWlf1iD6PRh3tA","pdfSize":"5271847"}