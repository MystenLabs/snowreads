{"id":"2407.04280","title":"LearnerVoice: A Dataset of Non-Native English Learners' Spontaneous\n  Speech","authors":"Haechan Kim, Junho Myung, Seoyoung Kim, Sungpah Lee, Dongyeop Kang,\n  Juho Kim","authorsParsed":[["Kim","Haechan",""],["Myung","Junho",""],["Kim","Seoyoung",""],["Lee","Sungpah",""],["Kang","Dongyeop",""],["Kim","Juho",""]],"versions":[{"version":"v1","created":"Fri, 5 Jul 2024 06:25:54 GMT"}],"updateDate":"2024-07-08","timestamp":1720160754000,"abstract":"  Prevalent ungrammatical expressions and disfluencies in spontaneous speech\nfrom second language (L2) learners pose unique challenges to Automatic Speech\nRecognition (ASR) systems. However, few datasets are tailored to L2 learner\nspeech. We publicly release LearnerVoice, a dataset consisting of 50.04 hours\nof audio and transcriptions of L2 learners' spontaneous speech. Our linguistic\nanalysis reveals that transcriptions in our dataset contain L2S (L2 learner's\nSpontaneous speech) features, consisting of ungrammatical expressions and\ndisfluencies (e.g., filler words, word repetitions, self-repairs, false\nstarts), significantly more than native speech datasets. Fine-tuning\nwhisper-small.en with LearnerVoice achieves a WER of 10.26%, 44.2% lower than\nvanilla whisper-small.en. Furthermore, our qualitative analysis indicates that\n54.2% of errors from the vanilla model on LearnerVoice are attributable to L2S\nfeatures, with 48.1% of them being reduced in the fine-tuned model.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Sound","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by-sa/4.0/","blobId":"hNiT7MSeO3fiLiN3eLcUjFVAbyhQTeZ0sgV5WxdcpEU","pdfSize":"399613"}
