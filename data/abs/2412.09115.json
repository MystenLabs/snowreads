{"id":"2412.09115","title":"Vision CNNs trained to estimate spatial latents learned similar\n  ventral-stream-aligned representations","authors":"Yudi Xie, Weichen Huang, Esther Alter, Jeremy Schwartz, Joshua B.\n  Tenenbaum, James J. DiCarlo","authorsParsed":[["Xie","Yudi",""],["Huang","Weichen",""],["Alter","Esther",""],["Schwartz","Jeremy",""],["Tenenbaum","Joshua B.",""],["DiCarlo","James J.",""]],"versions":[{"version":"v1","created":"Thu, 12 Dec 2024 09:49:16 GMT"},{"version":"v2","created":"Mon, 17 Feb 2025 17:50:21 GMT"}],"updateDate":"2025-02-18","timestamp":1733996956000,"abstract":"  Studies of the functional role of the primate ventral visual stream have\ntraditionally focused on object categorization, often ignoring -- despite much\nprior evidence -- its role in estimating \"spatial\" latents such as object\nposition and pose. Most leading ventral stream models are derived by optimizing\nnetworks for object categorization, which seems to imply that the ventral\nstream is also derived under such an objective. Here, we explore an alternative\nhypothesis: Might the ventral stream be optimized for estimating spatial\nlatents? And a closely related question: How different -- if at all -- are\nrepresentations learned from spatial latent estimation compared to\ncategorization? To ask these questions, we leveraged synthetic image datasets\ngenerated by a 3D graphic engine and trained convolutional neural networks\n(CNNs) to estimate different combinations of spatial and category latents. We\nfound that models trained to estimate just a few spatial latents achieve neural\nalignment scores comparable to those trained on hundreds of categories, and the\nspatial latent performance of models strongly correlates with their neural\nalignment. Spatial latent and category-trained models have very similar -- but\nnot identical -- internal representations, especially in their early and middle\nlayers. We provide evidence that this convergence is partly driven by\nnon-target latent variability in the training data, which facilitates the\nimplicit learning of representations of those non-target latents. Taken\ntogether, these results suggest that many training objectives, such as spatial\nlatents, can lead to similar models aligned neurally with the ventral stream.\nThus, one should not assume that the ventral stream is optimized for object\ncategorization only. As a field, we need to continue to sharpen our measures of\ncomparing models to brains to better understand the functional roles of the\nventral stream.\n","subjects":["Quantitative Biology/Neurons and Cognition","Computer Science/Computer Vision and Pattern Recognition","Computer Science/Machine Learning","Computer Science/Neural and Evolutionary Computing"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"SOw_flmUSV5poN5D8nsyw7XW0b74WZabA0-J08AYU8U","pdfSize":"18343070"}