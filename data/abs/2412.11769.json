{"id":"2412.11769","title":"Does it Chug? Towards a Data-Driven Understanding of Guitar Tone\n  Description","authors":"Pratik Sutar, Jason Naradowsky, Yusuke Miyao","authorsParsed":[["Sutar","Pratik",""],["Naradowsky","Jason",""],["Miyao","Yusuke",""]],"versions":[{"version":"v1","created":"Mon, 16 Dec 2024 13:44:19 GMT"}],"updateDate":"2024-12-17","timestamp":1734356659000,"abstract":"  Natural language is commonly used to describe instrument timbre, such as a\n\"warm\" or \"heavy\" sound. As these descriptors are based on human perception,\nthere can be disagreement over which acoustic features correspond to a given\nadjective. In this work, we pursue a data-driven approach to further our\nunderstanding of such adjectives in the context of guitar tone. Our main\ncontribution is a dataset of timbre adjectives, constructed by processing\nsingle clips of instrument audio to produce varied timbres through adjustments\nin EQ and effects such as distortion. Adjective annotations are obtained for\neach clip by crowdsourcing experts to complete a pairwise comparison and a\nlabeling task. We examine the dataset and reveal correlations between adjective\nratings and highlight instances where the data contradicts prevailing theories\non spectral features and timbral adjectives, suggesting a need for a more\nnuanced, data-driven understanding of timbre.\n","subjects":["Computer Science/Sound","Computer Science/Artificial Intelligence","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"sjA9cENEb7vjRvcft31Q_n0WaDhYTLNwCuV9yeeEwT0","pdfSize":"472325"}