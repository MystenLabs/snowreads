{"id":"2412.05479","title":"TACO: Learning Multi-modal Action Models with Synthetic\n  Chains-of-Thought-and-Action","authors":"Zixian Ma, Jianguo Zhang, Zhiwei Liu, Jieyu Zhang, Juntao Tan, Manli\n  Shu, Juan Carlos Niebles, Shelby Heinecke, Huan Wang, Caiming Xiong, Ranjay\n  Krishna, Silvio Savarese","authorsParsed":[["Ma","Zixian",""],["Zhang","Jianguo",""],["Liu","Zhiwei",""],["Zhang","Jieyu",""],["Tan","Juntao",""],["Shu","Manli",""],["Niebles","Juan Carlos",""],["Heinecke","Shelby",""],["Wang","Huan",""],["Xiong","Caiming",""],["Krishna","Ranjay",""],["Savarese","Silvio",""]],"versions":[{"version":"v1","created":"Sat, 7 Dec 2024 00:42:04 GMT"},{"version":"v2","created":"Tue, 10 Dec 2024 07:33:12 GMT"}],"updateDate":"2024-12-11","timestamp":1733532124000,"abstract":"  While open-source multi-modal language models perform well on simple question\nanswering tasks, they often fail on complex questions that require multiple\ncapabilities, such as fine-grained recognition, visual grounding, and\nreasoning, and that demand multi-step solutions. We present TACO, a family of\nmulti-modal large action models designed to improve performance on such\ncomplex, multi-step, and multi-modal tasks. During inference, TACO produces\nchains-of-thought-and-action (CoTA), executes intermediate steps by invoking\nexternal tools such as OCR, depth estimation and calculator, then integrates\nboth the thoughts and action outputs to produce coherent responses. To train\nTACO, we create a large dataset of over 1M synthetic CoTA traces generated with\nGPT-4o and Python programs. We then experiment with various data filtering and\nmixing techniques and obtain a final subset of 293K high-quality CoTA examples.\nThis dataset enables TACO to learn complex reasoning and action paths,\nsurpassing existing models trained on instruction tuning data with only direct\nanswers. Our model TACO outperforms the instruction-tuned baseline across 8\nbenchmarks, achieving a 3.6% improvement on average, with gains of up to 15% in\nMMVet tasks involving OCR, mathematical reasoning, and spatial reasoning.\nTraining on high-quality CoTA traces sets a new standard for complex\nmulti-modal reasoning, highlighting the need for structured, multi-step\ninstruction tuning in advancing open-source mutli-modal models' capabilities.\n","subjects":["Computer Science/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"Jq2b7H0048L0hUswf3QlaTW_HKe92yrF-tV3BMmLRFU","pdfSize":"15856220"}