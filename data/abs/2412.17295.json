{
  "id": "2412.17295",
  "title": "Friends-MMC: A Dataset for Multi-modal Multi-party Conversation\n  Understanding",
  "authors": "Yueqian Wang, Xiaojun Meng, Yuxuan Wang, Jianxin Liang, Qun Liu,\n  Dongyan Zhao",
  "authorsParsed": [
    [
      "Wang",
      "Yueqian",
      ""
    ],
    [
      "Meng",
      "Xiaojun",
      ""
    ],
    [
      "Wang",
      "Yuxuan",
      ""
    ],
    [
      "Liang",
      "Jianxin",
      ""
    ],
    [
      "Liu",
      "Qun",
      ""
    ],
    [
      "Zhao",
      "Dongyan",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Mon, 23 Dec 2024 05:32:48 GMT"
    }
  ],
  "updateDate": "2024-12-24",
  "timestamp": 1734931968000,
  "abstract": "  Multi-modal multi-party conversation (MMC) is a less studied yet important\ntopic of research due to that it well fits real-world scenarios and thus\npotentially has more widely-used applications. Compared with the traditional\nmulti-modal conversations, MMC requires stronger character-centered\nunderstanding abilities as there are many interlocutors appearing in both the\nvisual and textual context. To facilitate the study of this problem, we present\nFriends-MMC in this paper, an MMC dataset that contains 24,000+ unique\nutterances paired with video context. To explore the character-centered\nunderstanding of the dialogue, we also annotate the speaker of each utterance,\nthe names and bounding bboxes of faces that appear in the video. Based on this\nFriends-MMC dataset, we further study two fundamental MMC tasks: conversation\nspeaker identification and conversation response prediction, both of which have\nthe multi-party nature with the video or image as visual context. For\nconversation speaker identification, we demonstrate the inefficiencies of\nexisting methods such as pre-trained models, and propose a simple yet effective\nbaseline method that leverages an optimization solver to utilize the context of\ntwo modalities to achieve better performance. For conversation response\nprediction, we fine-tune generative dialogue models on Friend-MMC, and analyze\nthe benefits of speaker information. The code and dataset is publicly available\nat https://github.com/yellow-binary-tree/Friends-MMC and thus we call for more\nattention on modeling speaker information when understanding conversations.\n",
  "subjects": [
    "Computer Science/Computation and Language"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "lW4DcWhoHAbc3ZUWGM7zyz-ElQITGuJgiRXj-Ve706k",
  "pdfSize": "3467602"
}