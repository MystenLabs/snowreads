{"id":"2412.07935","title":"Non-Normal Diffusion Models","authors":"Henry Li","authorsParsed":[["Li","Henry",""]],"versions":[{"version":"v1","created":"Tue, 10 Dec 2024 21:31:12 GMT"}],"updateDate":"2024-12-12","timestamp":1733866272000,"abstract":"  Diffusion models generate samples by incrementally reversing a process that\nturns data into noise. We show that when the step size goes to zero, the\nreversed process is invariant to the distribution of these increments. This\nreveals a previously unconsidered parameter in the design of diffusion models:\nthe distribution of the diffusion step $\\Delta x_k := x_{k} - x_{k + 1}$. This\nparameter is implicitly set by default to be normally distributed in most\ndiffusion models. By lifting this assumption, we generalize the framework for\ndesigning diffusion models and establish an expanded class of diffusion\nprocesses with greater flexibility in the choice of loss function used during\ntraining. We demonstrate the effectiveness of these models on density\nestimation and generative modeling tasks on standard image datasets, and show\nthat different choices of the distribution of $\\Delta x_k$ result in\nqualitatively different generated samples.\n","subjects":["Computer Science/Machine Learning","Computer Science/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"BJjdV2d_P7GKEj_ijL8tuHozcJWv2f7c4fCFH55x_B8","pdfSize":"723026"}