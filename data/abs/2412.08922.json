{"id":"2412.08922","title":"A Flexible Plug-and-Play Module for Generating Variable-Length","authors":"Liyang He, Yuren Zhang, Rui Li, Zhenya Huang, Runze Wu, Enhong Chen","authorsParsed":[["He","Liyang",""],["Zhang","Yuren",""],["Li","Rui",""],["Huang","Zhenya",""],["Wu","Runze",""],["Chen","Enhong",""]],"versions":[{"version":"v1","created":"Thu, 12 Dec 2024 04:13:09 GMT"}],"updateDate":"2024-12-13","timestamp":1733976789000,"abstract":"  Deep supervised hashing has become a pivotal technique in large-scale image\nretrieval, offering significant benefits in terms of storage and search\nefficiency. However, existing deep supervised hashing models predominantly\nfocus on generating fixed-length hash codes. This approach fails to address the\ninherent trade-off between efficiency and effectiveness when using hash codes\nof varying lengths. To determine the optimal hash code length for a specific\ntask, multiple models must be trained for different lengths, leading to\nincreased training time and computational overhead. Furthermore, the current\nparadigm overlooks the potential relationships between hash codes of different\nlengths, limiting the overall effectiveness of the models. To address these\nchallenges, we propose the Nested Hash Layer (NHL), a plug-and-play module\ndesigned for existing deep supervised hashing models. The NHL framework\nintroduces a novel mechanism to simultaneously generate hash codes of varying\nlengths in a nested manner. To tackle the optimization conflicts arising from\nthe multiple learning objectives associated with different code lengths, we\nfurther propose an adaptive weights strategy that dynamically monitors and\nadjusts gradients during training. Additionally, recognizing that the\nstructural information in longer hash codes can provide valuable guidance for\nshorter hash codes, we develop a long-short cascade self-distillation method\nwithin the NHL to enhance the overall quality of the generated hash codes.\nExtensive experiments demonstrate that NHL not only accelerates the training\nprocess but also achieves superior retrieval performance across various deep\nhashing models. Our code is publicly available at\nhttps://github.com/hly1998/NHL.\n","subjects":["Computer Science/Computer Vision and Pattern Recognition","Computer Science/Information Retrieval"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"622RArBbNCFlqR-IdzQVK_0z2xZVXKgqThG68387iaw","pdfSize":"1389421"}