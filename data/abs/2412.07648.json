{"id":"2412.07648","title":"Spatio-temporal Latent Representations for the Analysis of Acoustic\n  Scenes in-the-wild","authors":"Claudia Montero-Ram\\'irez, Esther Rituerto-Gonz\\'alez, Carmen\n  Pel\\'aez-Moreno","authorsParsed":[["Montero-Ramírez","Claudia",""],["Rituerto-González","Esther",""],["Peláez-Moreno","Carmen",""]],"versions":[{"version":"v1","created":"Tue, 10 Dec 2024 16:34:08 GMT"}],"updateDate":"2024-12-11","timestamp":1733848448000,"abstract":"  In the field of acoustic scene analysis, this paper presents a novel approach\nto find spatio-temporal latent representations from in-the-wild audio data. By\nusing WE-LIVE, an in-house collected dataset that includes audio recordings in\ndiverse real-world environments together with sparse GPS coordinates,\nself-annotated emotional and situational labels, we tackle the challenging task\nof associating each audio segment with its corresponding location as a pretext\ntask, with the final aim of acoustically detecting violent (anomalous)\ncontexts, left as further work. By generating acoustic embeddings and using the\nself-supervised learning paradigm, we aim to use the model-generated latent\nspace to acoustically characterize the spatio-temporal context. We use YAMNet,\nan acoustic events classifier trained in AudioSet to temporally locate and\nidentify acoustic events in WE-LIVE. In order to transform the discrete\nacoustic events into embeddings, we compare the information-retrieval-based\nTF-IDF algorithm and Node2Vec as an analogy to Natural Language Processing\ntechniques. A VAE is then trained to provide a further adapted latent space.\nThe analysis was carried out by measuring the cosine distance and visualizing\ndata distribution via t-Distributed Stochastic Neighbor Embedding, revealing\ndistinct acoustic scenes. Specifically, we discern variations between indoor\nand subway environments. Notably, these distinctions emerge within the latent\nspace of the VAE, a stark contrast to the random distribution of data points\nbefore encoding. In summary, our research contributes a pioneering approach for\nextracting spatio-temporal latent representations from in-the-wild audio data.\n","subjects":["Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"JfbqGQJOr9aVwubxt7KPXvqyM8bQFN_JOhTr02UCMfo","pdfSize":"1130511"}