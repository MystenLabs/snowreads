{"id":"2412.10982","title":"MedG-KRP: Medical Graph Knowledge Representation Probing","authors":"Gabriel R. Rosenbaum, Lavender Yao Jiang, Ivaxi Sheth, Jaden Stryker,\n  Anton Alyakin, Daniel Alexander Alber, Nicolas K. Goff, Young Joon Fred Kwon,\n  John Markert, Mustafa Nasir-Moin, Jan Moritz Niehues, Karl L. Sangwon, Eunice\n  Yang, and Eric Karl Oermann","authorsParsed":[["Rosenbaum","Gabriel R.",""],["Jiang","Lavender Yao",""],["Sheth","Ivaxi",""],["Stryker","Jaden",""],["Alyakin","Anton",""],["Alber","Daniel Alexander",""],["Goff","Nicolas K.",""],["Kwon","Young Joon Fred",""],["Markert","John",""],["Nasir-Moin","Mustafa",""],["Niehues","Jan Moritz",""],["Sangwon","Karl L.",""],["Yang","Eunice",""],["Oermann","Eric Karl",""]],"versions":[{"version":"v1","created":"Sat, 14 Dec 2024 22:23:20 GMT"},{"version":"v2","created":"Tue, 17 Dec 2024 02:06:18 GMT"}],"updateDate":"2024-12-18","timestamp":1734215000000,"abstract":"  Large language models (LLMs) have recently emerged as powerful tools, finding\nmany medical applications. LLMs' ability to coalesce vast amounts of\ninformation from many sources to generate a response-a process similar to that\nof a human expert-has led many to see potential in deploying LLMs for clinical\nuse. However, medicine is a setting where accurate reasoning is paramount. Many\nresearchers are questioning the effectiveness of multiple choice question\nanswering (MCQA) benchmarks, frequently used to test LLMs. Researchers and\nclinicians alike must have complete confidence in LLMs' abilities for them to\nbe deployed in a medical setting. To address this need for understanding, we\nintroduce a knowledge graph (KG)-based method to evaluate the biomedical\nreasoning abilities of LLMs. Essentially, we map how LLMs link medical concepts\nin order to better understand how they reason. We test GPT-4, Llama3-70b, and\nPalmyraMed-70b, a specialized medical model. We enlist a panel of medical\nstudents to review a total of 60 LLM-generated graphs and compare these graphs\nto BIOS, a large biomedical KG. We observe GPT-4 to perform best in our human\nreview but worst in our ground truth comparison; vice-versa with PalmyraMed,\nthe medical model. Our work provides a means of visualizing the medical\nreasoning pathways of LLMs so they can be implemented in clinical settings\nsafely and effectively.\n","subjects":["Computer Science/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"PE71XGSf-yfxW7hxtGyQ1j3pU0oQSde_o_aIpBBuQmE","pdfSize":"290775"}