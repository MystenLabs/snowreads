{"id":"2407.15585","title":"Competing DEA procedures: analysis, testing, and comparisons","authors":"Gregory Koronakos, Jose H Dula, and Dimitris K Despotis","authorsParsed":[["Koronakos","Gregory",""],["Dula","Jose H",""],["Despotis","Dimitris K",""]],"versions":[{"version":"v1","created":"Mon, 22 Jul 2024 12:23:08 GMT"}],"updateDate":"2024-07-23","timestamp":1721650988000,"abstract":"  Reducing the computational time to process large data sets in Data\nEnvelopment Analysis (DEA) is the objective of many studies. Contributions\ninclude fundamentally innovative procedures, new or improved preprocessors, and\nhybridization between - and among - all these. Ultimately, new contributions\nare made when the number and size of the LPs solved is somehow reduced. This\npaper provides a comprehensive analysis and comparison of two competing\nprocedures to process DEA data sets: BuildHull and Enhanced Hierarchical\nDecomposition (EHD). A common ground for comparison is made by examining their\nsequential implementations, applying to both the same preprocessors - when\npermitted - on a suite of data sets widely employed in the computational DEA\nliterature. In addition to reporting on execution time, we discuss how the data\ncharacteristics affect performance and we introduce using the number and size\nof the LPs solved to better understand performances and explain differences.\nOur experiments show that the dominance of BuildHull can be substantial in\nlarge-scale and high-density datasets. Comparing and explaining performance\nbased on the number and size of LPS lays the groundwork for a comparison of the\nparallel implementations of procedures BuildHull and EHD.\n","subjects":["Mathematics/Optimization and Control","Computing Research Repository/Databases"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"OKaFQ6ML2E-fI0pWGKReBlomGGJu8sMuENWsB_KBldY","pdfSize":"2821943"}