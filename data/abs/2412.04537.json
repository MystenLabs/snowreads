{"id":"2412.04537","title":"Understanding Hidden Computations in Chain-of-Thought Reasoning","authors":"Aryasomayajula Ram Bharadwaj","authorsParsed":[["Bharadwaj","Aryasomayajula Ram",""]],"versions":[{"version":"v1","created":"Thu, 5 Dec 2024 18:43:11 GMT"}],"updateDate":"2024-12-09","timestamp":1733424191000,"abstract":"  Chain-of-Thought (CoT) prompting has significantly enhanced the reasoning\nabilities of large language models. However, recent studies have shown that\nmodels can still perform complex reasoning tasks even when the CoT is replaced\nwith filler(hidden) characters (e.g., \"...\"), leaving open questions about how\nmodels internally process and represent reasoning steps. In this paper, we\ninvestigate methods to decode these hidden characters in transformer models\ntrained with filler CoT sequences. By analyzing layer-wise representations\nusing the logit lens method and examining token rankings, we demonstrate that\nthe hidden characters can be recovered without loss of performance. Our\nfindings provide insights into the internal mechanisms of transformer models\nand open avenues for improving interpretability and transparency in language\nmodel reasoning.\n","subjects":["Computer Science/Computation and Language","Computer Science/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"5xQE4uwEj3cpCK2G8bmRbP6wmQWeKbv1oCZUMe9Rc6g","pdfSize":"744784"}