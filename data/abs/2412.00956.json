{"id":"2412.00956","title":"Large Language Models as Mirrors of Societal Moral Standards","authors":"Evi Papadopoulou, Hadi Mohammadi and Ayoub Bagheri","authorsParsed":[["Papadopoulou","Evi",""],["Mohammadi","Hadi",""],["Bagheri","Ayoub",""]],"versions":[{"version":"v1","created":"Sun, 1 Dec 2024 20:20:35 GMT"}],"updateDate":"2024-12-03","timestamp":1733084435000,"abstract":"  Prior research has demonstrated that language models can, to a limited\nextent, represent moral norms in a variety of cultural contexts. This research\naims to replicate these findings and further explore their validity,\nconcentrating on issues like 'homosexuality' and 'divorce'. This study\nevaluates the effectiveness of these models using information from two surveys,\nthe WVS and the PEW, that encompass moral perspectives from over 40 countries.\nThe results show that biases exist in both monolingual and multilingual models,\nand they typically fall short of accurately capturing the moral intricacies of\ndiverse cultures. However, the BLOOM model shows the best performance,\nexhibiting some positive correlations, but still does not achieve a\ncomprehensive moral understanding. This research underscores the limitations of\ncurrent PLMs in processing cross-cultural differences in values and highlights\nthe importance of developing culturally aware AI systems that better align with\nuniversal human values.\n","subjects":["Computer Science/Artificial Intelligence","Computer Science/Computation and Language","Computer Science/Symbolic Computation"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"z_q7iSkTLcSSZ-jQBmuMMdvZbdG5MVpt7KgN3J3Egxs","pdfSize":"828973"}