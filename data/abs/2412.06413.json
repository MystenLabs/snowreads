{
  "id": "2412.06413",
  "title": "World-Consistent Data Generation for Vision-and-Language Navigation",
  "authors": "Yu Zhong, Rui Zhang, Zihao Zhang, Shuo Wang, Chuan Fang, Xishan Zhang,\n  Jiaming Guo, Shaohui Peng, Di Huang, Yanyang Yan, Xing Hu, Ping Tan, Qi Guo",
  "authorsParsed": [
    [
      "Zhong",
      "Yu",
      ""
    ],
    [
      "Zhang",
      "Rui",
      ""
    ],
    [
      "Zhang",
      "Zihao",
      ""
    ],
    [
      "Wang",
      "Shuo",
      ""
    ],
    [
      "Fang",
      "Chuan",
      ""
    ],
    [
      "Zhang",
      "Xishan",
      ""
    ],
    [
      "Guo",
      "Jiaming",
      ""
    ],
    [
      "Peng",
      "Shaohui",
      ""
    ],
    [
      "Huang",
      "Di",
      ""
    ],
    [
      "Yan",
      "Yanyang",
      ""
    ],
    [
      "Hu",
      "Xing",
      ""
    ],
    [
      "Tan",
      "Ping",
      ""
    ],
    [
      "Guo",
      "Qi",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Mon, 9 Dec 2024 11:40:54 GMT"
    }
  ],
  "updateDate": "2024-12-10",
  "timestamp": 1733744454000,
  "abstract": "  Vision-and-Language Navigation (VLN) is a challenging task that requires an\nagent to navigate through photorealistic environments following\nnatural-language instructions. One main obstacle existing in VLN is data\nscarcity, leading to poor generalization performance over unseen environments.\nTough data argumentation is a promising way for scaling up the dataset, how to\ngenerate VLN data both diverse and world-consistent remains problematic. To\ncope with this issue, we propose the world-consistent data generation (WCGEN),\nan efficacious data-augmentation framework satisfying both diversity and\nworld-consistency, targeting at enhancing the generalizations of agents to\nnovel environments. Roughly, our framework consists of two stages, the\ntrajectory stage which leverages a point-cloud based technique to ensure\nspatial coherency among viewpoints, and the viewpoint stage which adopts a\nnovel angle synthesis method to guarantee spatial and wraparound consistency\nwithin the entire observation. By accurately predicting viewpoint changes with\n3D knowledge, our approach maintains the world-consistency during the\ngeneration procedure. Experiments on a wide range of datasets verify the\neffectiveness of our method, demonstrating that our data augmentation strategy\nenables agents to achieve new state-of-the-art results on all navigation tasks,\nand is capable of enhancing the VLN agents' generalization ability to unseen\nenvironments.\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition"
  ],
  "license": "http://creativecommons.org/publicdomain/zero/1.0/",
  "blobId": "o_uF9GnRZVDMVyY0nwOvZtb-XspRs3tNR9ADiCSBBzg",
  "pdfSize": "3774938"
}