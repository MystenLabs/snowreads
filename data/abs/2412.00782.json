{"id":"2412.00782","title":"Memories of Forgotten Concepts","authors":"Matan Rusanovsky, Shimon Malnick, Amir Jevnisek, Ohad Fried and Shai\n  Avidan","authorsParsed":[["Rusanovsky","Matan",""],["Malnick","Shimon",""],["Jevnisek","Amir",""],["Fried","Ohad",""],["Avidan","Shai",""]],"versions":[{"version":"v1","created":"Sun, 1 Dec 2024 12:12:24 GMT"}],"updateDate":"2024-12-03","timestamp":1733055144000,"abstract":"  Diffusion models dominate the space of text-to-image generation, yet they may\nproduce undesirable outputs, including explicit content or private data. To\nmitigate this, concept ablation techniques have been explored to limit the\ngeneration of certain concepts. In this paper, we reveal that the erased\nconcept information persists in the model and that erased concept images can be\ngenerated using the right latent. Utilizing inversion methods, we show that\nthere exist latent seeds capable of generating high quality images of erased\nconcepts. Moreover, we show that these latents have likelihoods that overlap\nwith those of images outside the erased concept. We extend this to demonstrate\nthat for every image from the erased concept set, we can generate many seeds\nthat generate the erased concept. Given the vast space of latents capable of\ngenerating ablated concept images, our results suggest that fully erasing\nconcept information may be intractable, highlighting possible vulnerabilities\nin current concept ablation techniques.\n","subjects":["Computer Science/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"LGjaGL8AQlCwFzqZ23fqr5QhbpiOQfdBBH5HAXiiYzY","pdfSize":"29979019"}