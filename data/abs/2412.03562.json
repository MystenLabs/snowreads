{
  "id": "2412.03562",
  "title": "Characterizing the Distinguishability of Product Distributions through\n  Multicalibration",
  "authors": "Cassandra Marcussen, Aaron L. Putterman, Salil Vadhan",
  "authorsParsed": [
    [
      "Marcussen",
      "Cassandra",
      ""
    ],
    [
      "Putterman",
      "Aaron L.",
      ""
    ],
    [
      "Vadhan",
      "Salil",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Wed, 4 Dec 2024 18:56:19 GMT"
    },
    {
      "version": "v2",
      "created": "Tue, 25 Feb 2025 16:59:28 GMT"
    }
  ],
  "updateDate": "2025-02-26",
  "timestamp": 1733338579000,
  "abstract": "  Given a sequence of samples $x_1, \\dots , x_k$ promised to be drawn from one\nof two distributions $X_0, X_1$, a well-studied problem in statistics is to\ndecide $\\textit{which}$ distribution the samples are from. Information\ntheoretically, the maximum advantage in distinguishing the two distributions\ngiven $k$ samples is captured by the total variation distance between\n$X_0^{\\otimes k}$ and $X_1^{\\otimes k}$. However, when we restrict our\nattention to $\\textit{efficient distinguishers}$ (i.e., small circuits) of\nthese two distributions, exactly characterizing the ability to distinguish\n$X_0^{\\otimes k}$ and $X_1^{\\otimes k}$ is more involved and less understood.\n  In this work, we give a general way to reduce bounds on the computational\nindistinguishability of $X_0$ and $X_1$ to bounds on the\n$\\textit{information-theoretic}$ indistinguishability of some specific, related\nvariables $\\widetilde{X}_0$ and $\\widetilde{X}_1$. As a consequence, we prove a\nnew, tight characterization of the number of samples $k$ needed to efficiently\ndistinguish $X_0^{\\otimes k}$ and $X_1^{\\otimes k}$ with constant advantage as\n  \\[\n  k = \\Theta\\left(d_H^{-2}\\left(\\widetilde{X}_0, \\widetilde{X}_1\\right)\\right),\n  \\] which is the inverse of the squared Hellinger distance $d_H$ between two\ndistributions $\\widetilde{X}_0$ and $\\widetilde{X}_1$ that are computationally\nindistinguishable from $X_0$ and $X_1$. Likewise, our framework can be used to\nre-derive a result of Geier (TCC 2022), proving nearly-tight bounds on how\ncomputational indistinguishability scales with the number of samples for\narbitrary product distributions.\n",
  "subjects": [
    "Computer Science/Cryptography and Security",
    "Computer Science/Computational Complexity"
  ],
  "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
  "blobId": "GZkMR3tfeY66DLW_KW0MKCM5AcCYzvTqfoADfzZBtRo",
  "pdfSize": "411465"
}