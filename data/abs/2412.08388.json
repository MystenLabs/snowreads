{
  "id": "2412.08388",
  "title": "LOMA: Language-assisted Semantic Occupancy Network via Triplane Mamba",
  "authors": "Yubo Cui, Zhiheng Li, Jiaqiang Wang, Zheng Fang",
  "authorsParsed": [
    [
      "Cui",
      "Yubo",
      ""
    ],
    [
      "Li",
      "Zhiheng",
      ""
    ],
    [
      "Wang",
      "Jiaqiang",
      ""
    ],
    [
      "Fang",
      "Zheng",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Wed, 11 Dec 2024 13:55:42 GMT"
    }
  ],
  "updateDate": "2024-12-12",
  "timestamp": 1733925342000,
  "abstract": "  Vision-based 3D occupancy prediction has become a popular research task due\nto its versatility and affordability. Nowadays, conventional methods usually\nproject the image-based vision features to 3D space and learn the geometric\ninformation through the attention mechanism, enabling the 3D semantic occupancy\nprediction. However, these works usually face two main challenges: 1) Limited\ngeometric information. Due to the lack of geometric information in the image\nitself, it is challenging to directly predict 3D space information, especially\nin large-scale outdoor scenes. 2) Local restricted interaction. Due to the\nquadratic complexity of the attention mechanism, they often use modified local\nattention to fuse features, resulting in a restricted fusion. To address these\nproblems, in this paper, we propose a language-assisted 3D semantic occupancy\nprediction network, named LOMA. In the proposed vision-language framework, we\nfirst introduce a VL-aware Scene Generator (VSG) module to generate the 3D\nlanguage feature of the scene. By leveraging the vision-language model, this\nmodule provides implicit geometric knowledge and explicit semantic information\nfrom the language. Furthermore, we present a Tri-plane Fusion Mamba (TFM) block\nto efficiently fuse the 3D language feature and 3D vision feature. The proposed\nmodule not only fuses the two features with global modeling but also avoids too\nmuch computation costs. Experiments on the SemanticKITTI and SSCBench-KITTI360\ndatasets show that our algorithm achieves new state-of-the-art performances in\nboth geometric and semantic completion tasks. Our code will be open soon.\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "9qguYYREbTI6ZeH6_4UpYmym4BBnZ8iOgnrwzl6tM1o",
  "pdfSize": "1974955"
}