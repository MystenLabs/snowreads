{"id":"2412.02066","title":"CLERF: Contrastive LEaRning for Full Range Head Pose Estimation","authors":"Ting-Ruen Wei, Haowei Liu, Huei-Chung Hu, Xuyang Wu, Yi Fang, Hsin-Tai\n  Wu","authorsParsed":[["Wei","Ting-Ruen",""],["Liu","Haowei",""],["Hu","Huei-Chung",""],["Wu","Xuyang",""],["Fang","Yi",""],["Wu","Hsin-Tai",""]],"versions":[{"version":"v1","created":"Tue, 3 Dec 2024 01:08:03 GMT"}],"updateDate":"2024-12-04","timestamp":1733188083000,"abstract":"  We introduce a novel framework for representation learning in head pose\nestimation (HPE). Previously such a scheme was difficult due to head pose data\nsparsity, making triplet sampling infeasible. Recent progress in 3D generative\nadversarial networks (3D-aware GAN) has opened the door for easily sampling\ntriplets (anchor, positive, negative). We perform contrastive learning on\nextensively augmented data including geometric transformations and demonstrate\nthat contrastive learning allows networks to learn genuine features that\ncontribute to accurate HPE. On the other hand, we observe that existing HPE\nworks struggle to predict head poses as accurately when test image rotation\nmatrices are slightly out of the training dataset distribution. Experiments\nshow that our methodology performs on par with state-of-the-art models on\nstandard test datasets and outperforms them when images are slightly rotated/\nflipped or full range head pose. To the best of our knowledge, we are the first\nto deliver a true full range HPE model capable of accurately predicting any\nhead pose including upside-down pose. Furthermore, we compared with other\nexisting full-yaw range models and demonstrated superior results.\n","subjects":["Computer Science/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"VeyTHI2R3QoqrTxt004JYCWbd7Wr0LPTcQfX7E0YiJA","pdfSize":"9878591"}