{
  "id": "2412.08117",
  "title": "LatentSpeech: Latent Diffusion for Text-To-Speech Generation",
  "authors": "Haowei Lou, Helen Paik, Pari Delir Haghighi, Wen Hu, Lina Yao",
  "authorsParsed": [
    [
      "Lou",
      "Haowei",
      ""
    ],
    [
      "Paik",
      "Helen",
      ""
    ],
    [
      "Haghighi",
      "Pari Delir",
      ""
    ],
    [
      "Hu",
      "Wen",
      ""
    ],
    [
      "Yao",
      "Lina",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Wed, 11 Dec 2024 05:55:06 GMT"
    }
  ],
  "updateDate": "2024-12-12",
  "timestamp": 1733896506000,
  "abstract": "  Diffusion-based Generative AI gains significant attention for its superior\nperformance over other generative techniques like Generative Adversarial\nNetworks and Variational Autoencoders. While it has achieved notable\nadvancements in fields such as computer vision and natural language processing,\ntheir application in speech generation remains under-explored. Mainstream\nText-to-Speech systems primarily map outputs to Mel-Spectrograms in the\nspectral space, leading to high computational loads due to the sparsity of\nMelSpecs. To address these limitations, we propose LatentSpeech, a novel TTS\ngeneration approach utilizing latent diffusion models. By using latent\nembeddings as the intermediate representation, LatentSpeech reduces the target\ndimension to 5% of what is required for MelSpecs, simplifying the processing\nfor the TTS encoder and vocoder and enabling efficient high-quality speech\ngeneration. This study marks the first integration of latent diffusion models\nin TTS, enhancing the accuracy and naturalness of generated speech.\nExperimental results on benchmark datasets demonstrate that LatentSpeech\nachieves a 25% improvement in Word Error Rate and a 24% improvement in Mel\nCepstral Distortion compared to existing models, with further improvements\nrising to 49.5% and 26%, respectively, with additional training data. These\nfindings highlight the potential of LatentSpeech to advance the\nstate-of-the-art in TTS technology\n",
  "subjects": [
    "Computer Science/Sound",
    "Computer Science/Artificial Intelligence",
    "Computer Science/Computation and Language",
    "Computer Science/Machine Learning",
    "Computer Science/Multimedia",
    "Electrical Engineering and Systems Science/Audio and Speech Processing"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "WNm764maSWo0Y6Yzx38o5vavPClk-khG32bDukCCSW4",
  "pdfSize": "672534"
}