{"id":"2412.18069","title":"Improving Factuality with Explicit Working Memory","authors":"Mingda Chen, Yang Li, Karthik Padthe, Rulin Shao, Alicia Sun, Luke\n  Zettlemoyer, Gargi Ghosh, Wen-tau Yih","authorsParsed":[["Chen","Mingda",""],["Li","Yang",""],["Padthe","Karthik",""],["Shao","Rulin",""],["Sun","Alicia",""],["Zettlemoyer","Luke",""],["Ghosh","Gargi",""],["Yih","Wen-tau",""]],"versions":[{"version":"v1","created":"Tue, 24 Dec 2024 00:55:59 GMT"},{"version":"v2","created":"Tue, 18 Feb 2025 14:15:34 GMT"}],"updateDate":"2025-02-19","timestamp":1735001759000,"abstract":"  Large language models can generate factually inaccurate content, a problem\nknown as hallucination. Recent works have built upon retrieved-augmented\ngeneration to improve factuality through iterative prompting but these methods\nare limited by the traditional RAG design. To address these challenges, we\nintroduce EWE (Explicit Working Memory), a novel approach that enhances\nfactuality in long-form text generation by integrating a working memory that\nreceives real-time feedback from external resources. The memory is refreshed\nbased on online fact-checking and retrieval feedback, allowing EWE to rectify\nfalse claims during the generation process and ensure more accurate and\nreliable outputs. Our experiments demonstrate that Ewe outperforms strong\nbaselines on four fact-seeking long-form generation datasets, increasing the\nfactuality metric, VeriScore, by 2 to 6 points absolute without sacrificing the\nhelpfulness of the responses. Further analysis reveals that the design of rules\nfor memory updates, configurations of memory units, and the quality of the\nretrieval datastore are crucial factors for influencing model performance.\n","subjects":["Computer Science/Computation and Language"],"license":"http://creativecommons.org/licenses/by-sa/4.0/","blobId":"glzXnlMdoSiXmQo_H-rWNmXrWoteHPZNFXpqFc7pk1s","pdfSize":"1165619"}