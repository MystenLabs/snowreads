{"id":"2412.02509","title":"FCL-ViT: Task-Aware Attention Tuning for Continual Learning","authors":"Anestis Kaimakamidis, Ioannis Pitas","authorsParsed":[["Kaimakamidis","Anestis",""],["Pitas","Ioannis",""]],"versions":[{"version":"v1","created":"Tue, 3 Dec 2024 15:48:33 GMT"},{"version":"v2","created":"Wed, 4 Dec 2024 17:35:48 GMT"}],"updateDate":"2024-12-05","timestamp":1733240913000,"abstract":"  Continual Learning (CL) involves adapting the prior Deep Neural Network (DNN)\nknowledge to new tasks, without forgetting the old ones. However, modern CL\ntechniques focus on provisioning memory capabilities to existing DNN models\nrather than designing new ones that are able to adapt according to the task at\nhand. This paper presents the novel Feedback Continual Learning Vision\nTransformer (FCL-ViT) that uses a feedback mechanism to generate real-time\ndynamic attention features tailored to the current task. The FCL-ViT operates\nin two Phases. In phase 1, the generic image features are produced and\ndetermine where the Transformer should attend on the current image. In phase 2,\ntask-specific image features are generated that leverage dynamic attention. To\nthis end, Tunable self-Attention Blocks (TABs) and Task Specific Blocks (TSBs)\nare introduced that operate in both phases and are responsible for tuning the\nTABs attention, respectively. The FCL-ViT surpasses state-of-the-art\nperformance on Continual Learning compared to benchmark methods, while\nretaining a small number of trainable DNN parameters.\n","subjects":["Computer Science/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"zA9Thp4piu_0x5tbsQ0EZKKk6yztu5SBDO9hjuYNkyo","pdfSize":"379444"}