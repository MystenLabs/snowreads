{"id":"2407.05682","title":"Retrieved In-Context Principles from Previous Mistakes","authors":"Hao Sun, Yong Jiang, Bo Wang, Yingyan Hou, Yan Zhang, Pengjun Xie, Fei\n  Huang","authorsParsed":[["Sun","Hao",""],["Jiang","Yong",""],["Wang","Bo",""],["Hou","Yingyan",""],["Zhang","Yan",""],["Xie","Pengjun",""],["Huang","Fei",""]],"versions":[{"version":"v1","created":"Mon, 8 Jul 2024 07:32:26 GMT"}],"updateDate":"2024-07-09","timestamp":1720423946000,"abstract":"  In-context learning (ICL) has been instrumental in adapting Large Language\nModels (LLMs) to downstream tasks using correct input-output examples. Recent\nadvances have attempted to improve model performance through principles derived\nfrom mistakes, yet these approaches suffer from lack of customization and\ninadequate error coverage. To address these limitations, we propose Retrieved\nIn-Context Principles (RICP), a novel teacher-student framework. In RICP, the\nteacher model analyzes mistakes from the student model to generate reasons and\ninsights for preventing similar mistakes. These mistakes are clustered based on\ntheir underlying reasons for developing task-level principles, enhancing the\nerror coverage of principles. During inference, the most relevant mistakes for\neach question are retrieved to create question-level principles, improving the\ncustomization of the provided guidance. RICP is orthogonal to existing\nprompting methods and does not require intervention from the teacher model\nduring inference. Experimental results across seven reasoning benchmarks reveal\nthat RICP effectively enhances performance when applied to various prompting\nstrategies.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"JeBBvw3Ww3Bi5jOb8IBfAY5SH05IZYULPUDL6BnUXKE","pdfSize":"1152934"}