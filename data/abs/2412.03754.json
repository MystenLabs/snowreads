{
  "id": "2412.03754",
  "title": "Enhancing IR-based Fault Localization using Large Language Models",
  "authors": "Shuai Shao, Tingting Yu",
  "authorsParsed": [
    [
      "Shao",
      "Shuai",
      ""
    ],
    [
      "Yu",
      "Tingting",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Wed, 4 Dec 2024 22:47:51 GMT"
    }
  ],
  "updateDate": "2024-12-06",
  "timestamp": 1733352471000,
  "abstract": "  Information Retrieval-based Fault Localization (IRFL) techniques aim to\nidentify source files containing the root causes of reported failures. While\nexisting techniques excel in ranking source files, challenges persist in bug\nreport analysis and query construction, leading to potential information loss.\nLeveraging large language models like GPT-4, this paper enhances IRFL by\ncategorizing bug reports based on programming entities, stack traces, and\nnatural language text. Tailored query strategies, the initial step in our\napproach (LLmiRQ), are applied to each category. To address inaccuracies in\nqueries, we introduce a user and conversational-based query reformulation\napproach, termed LLmiRQ+. Additionally, to further enhance query utilization,\nwe implement a learning-to-rank model that leverages key features such as class\nname match score and call graph score. This approach significantly improves the\nrelevance and accuracy of queries. Evaluation on 46 projects with 6,340 bug\nreports yields an MRR of 0.6770 and MAP of 0.5118, surpassing seven\nstate-of-the-art IRFL techniques, showcasing superior performance.\n",
  "subjects": [
    "Computer Science/Software Engineering"
  ],
  "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
  "blobId": "KEZNn7sIXdx82wyIlD5YvMc1ZgxnPZxbOD_h3Cvddg0",
  "pdfSize": "728832"
}