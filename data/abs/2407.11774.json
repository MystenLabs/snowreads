{"id":"2407.11774","title":"Sharif-MGTD at SemEval-2024 Task 8: A Transformer-Based Approach to\n  Detect Machine Generated Text","authors":"Seyedeh Fatemeh Ebrahimi, Karim Akhavan Azari, Amirmasoud Iravani,\n  Arian Qazvini, Pouya Sadeghi, Zeinab Sadat Taghavi, Hossein Sameti","authorsParsed":[["Ebrahimi","Seyedeh Fatemeh",""],["Azari","Karim Akhavan",""],["Iravani","Amirmasoud",""],["Qazvini","Arian",""],["Sadeghi","Pouya",""],["Taghavi","Zeinab Sadat",""],["Sameti","Hossein",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 14:33:01 GMT"}],"updateDate":"2024-07-17","timestamp":1721140381000,"abstract":"  Detecting Machine-Generated Text (MGT) has emerged as a significant area of\nstudy within Natural Language Processing. While language models generate text,\nthey often leave discernible traces, which can be scrutinized using either\ntraditional feature-based methods or more advanced neural language models. In\nthis research, we explore the effectiveness of fine-tuning a RoBERTa-base\ntransformer, a powerful neural architecture, to address MGT detection as a\nbinary classification task. Focusing specifically on Subtask A\n(Monolingual-English) within the SemEval-2024 competition framework, our\nproposed system achieves an accuracy of 78.9% on the test dataset, positioning\nus at 57th among participants. Our study addresses this challenge while\nconsidering the limited hardware resources, resulting in a system that excels\nat identifying human-written texts but encounters challenges in accurately\ndiscerning MGTs.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"sGX1ZxvaR8kBoLwZLLfH2OGkkzzwqMZD2caCSHZr1aw","pdfSize":"561543","objectId":"0x2e43443e0fa8eac5addab405bbfa7c2f8671bf2ae35ceabc2ac5b8e72e9898b7","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
