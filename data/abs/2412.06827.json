{
  "id": "2412.06827",
  "title": "Enhancing LLMs for Physics Problem-Solving using Reinforcement Learning\n  with Human-AI Feedback",
  "authors": "Avinash Anand, Kritarth Prasad, Chhavi Kirtani, Ashwin R Nair, Mohit\n  Gupta, Saloni Garg, Anurag Gautam, Snehal Buldeo, Rajiv Ratn Shah",
  "authorsParsed": [
    [
      "Anand",
      "Avinash",
      ""
    ],
    [
      "Prasad",
      "Kritarth",
      ""
    ],
    [
      "Kirtani",
      "Chhavi",
      ""
    ],
    [
      "Nair",
      "Ashwin R",
      ""
    ],
    [
      "Gupta",
      "Mohit",
      ""
    ],
    [
      "Garg",
      "Saloni",
      ""
    ],
    [
      "Gautam",
      "Anurag",
      ""
    ],
    [
      "Buldeo",
      "Snehal",
      ""
    ],
    [
      "Shah",
      "Rajiv Ratn",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Fri, 6 Dec 2024 21:17:47 GMT"
    }
  ],
  "updateDate": "2024-12-11",
  "timestamp": 1733519867000,
  "abstract": "  Large Language Models (LLMs) have demonstrated strong capabilities in\ntext-based tasks but struggle with the complex reasoning required for physics\nproblems, particularly in advanced arithmetic and conceptual understanding.\nWhile some research has explored ways to enhance LLMs in physics education\nusing techniques such as prompt engineering and Retrieval Augmentation\nGeneration (RAG), not enough effort has been made in addressing their\nlimitations in physics reasoning. This paper presents a novel approach to\nimproving LLM performance on physics questions using Reinforcement Learning\nwith Human and Artificial Intelligence Feedback (RLHAIF). We evaluate several\nreinforcement learning methods, including Proximal Policy Optimization (PPO),\nDirect Preference Optimization (DPO), and Remax optimization. These methods are\nchosen to investigate RL policy performance with different settings on the\nPhyQA dataset, which includes challenging physics problems from high school\ntextbooks. Our RLHAIF model, tested on leading LLMs like LLaMA2 and Mistral,\nachieved superior results, notably with the MISTRAL-PPO model, demonstrating\nmarked improvements in reasoning and accuracy. It achieved high scores, with a\n58.67 METEOR score and a 0.74 Reasoning score, making it a strong example for\nfuture physics reasoning research in this area.\n",
  "subjects": [
    "Computer Science/Machine Learning",
    "Computer Science/Artificial Intelligence"
  ],
  "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
  "blobId": "pDUPIBfUfRBDbskhsHMEDLLco9Vs-SaLA-js2L9lWeo",
  "pdfSize": "661336"
}