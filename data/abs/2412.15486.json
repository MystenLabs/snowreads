{"id":"2412.15486","title":"Toward Appearance-based Autonomous Landing Site Identification for\n  Multirotor Drones in Unstructured Environments","authors":"Joshua Springer, Gylfi {\\TH}\\'or Gu{\\dh}mundsson, Marcel Kyas","authorsParsed":[["Springer","Joshua",""],["Guðmundsson","Gylfi Þór",""],["Kyas","Marcel",""]],"versions":[{"version":"v1","created":"Fri, 20 Dec 2024 01:48:37 GMT"}],"updateDate":"2024-12-23","timestamp":1734659317000,"abstract":"  A remaining challenge in multirotor drone flight is the autonomous\nidentification of viable landing sites in unstructured environments. One\napproach to solve this problem is to create lightweight, appearance-based\nterrain classifiers that can segment a drone's RGB images into safe and unsafe\nregions. However, such classifiers require data sets of images and masks that\ncan be prohibitively expensive to create. We propose a pipeline to\nautomatically generate synthetic data sets to train these classifiers,\nleveraging modern drones' ability to survey terrain automatically and the\nability to automatically calculate landing safety masks from terrain models\nderived from such surveys. We then train a U-Net on the synthetic data set,\ntest it on real-world data for validation, and demonstrate it on our drone\nplatform in real-time.\n","subjects":["Computer Science/Computer Vision and Pattern Recognition","Computer Science/Machine Learning","Computer Science/Robotics"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"WaqHzyuK1vtAl-DHWSJo1qfkST2YQ3-ykewTEn3lZfU","pdfSize":"5923930"}