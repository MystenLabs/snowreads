{
  "id": "2412.05553",
  "title": "Psych-Occlusion: Using Visual Psychophysics for Aerial Detection of\n  Occluded Persons during Search and Rescue",
  "authors": "Arturo Miguel Russell Bernal, Jane Cleland-Huang, Walter Scheirer",
  "authorsParsed": [
    [
      "Bernal",
      "Arturo Miguel Russell",
      ""
    ],
    [
      "Cleland-Huang",
      "Jane",
      ""
    ],
    [
      "Scheirer",
      "Walter",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Sat, 7 Dec 2024 06:22:42 GMT"
    }
  ],
  "updateDate": "2024-12-10",
  "timestamp": 1733552562000,
  "abstract": "  The success of Emergency Response (ER) scenarios, such as search and rescue,\nis often dependent upon the prompt location of a lost or injured person. With\nthe increasing use of small Unmanned Aerial Systems (sUAS) as \"eyes in the sky\"\nduring ER scenarios, efficient detection of persons from aerial views plays a\ncrucial role in achieving a successful mission outcome. Fatigue of human\noperators during prolonged ER missions, coupled with limited human resources,\nhighlights the need for sUAS equipped with Computer Vision (CV) capabilities to\naid in finding the person from aerial views. However, the performance of CV\nmodels onboard sUAS substantially degrades under real-life rigorous conditions\nof a typical ER scenario, where person search is hampered by occlusion and low\ntarget resolution. To address these challenges, we extracted images from the\nNOMAD dataset and performed a crowdsource experiment to collect behavioural\nmeasurements when humans were asked to \"find the person in the picture\". We\nexemplify the use of our behavioral dataset, Psych-ER, by using its human\naccuracy data to adapt the loss function of a detection model. We tested our\nloss adaptation on a RetinaNet model evaluated on NOMAD against increasing\ndistance and occlusion, with our psychophysical loss adaptation showing\nimprovements over the baseline at higher distances across different levels of\nocclusion, without degrading performance at closer distances. To the best of\nour knowledge, our work is the first human-guided approach to address the\nlocation task of a detection model, while addressing real-world challenges of\naerial search and rescue. All datasets and code can be found at:\nhttps://github.com/ArtRuss/NOMAD.\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "nIdHZJIuLdNBquZYqtgav7BkLB8RKPMKqsY00EpPG4s",
  "pdfSize": "28303187"
}