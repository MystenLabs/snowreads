{"id":"2407.09099","title":"Music Proofreading with RefinPaint: Where and How to Modify Compositions\n  given Context","authors":"Pedro Ramoneda, Martin Rocamora, Taketo Akama","authorsParsed":[["Ramoneda","Pedro",""],["Rocamora","Martin",""],["Akama","Taketo",""]],"versions":[{"version":"v1","created":"Fri, 12 Jul 2024 08:52:27 GMT"}],"updateDate":"2024-07-15","timestamp":1720774347000,"abstract":"  Autoregressive generative transformers are key in music generation, producing\ncoherent compositions but facing challenges in human-machine collaboration. We\npropose RefinPaint, an iterative technique that improves the sampling process.\nIt does this by identifying the weaker music elements using a feedback model,\nwhich then informs the choices for resampling by an inpainting model. This\ndual-focus methodology not only facilitates the machine's ability to improve\nits automatic inpainting generation through repeated cycles but also offers a\nvaluable tool for humans seeking to refine their compositions with automatic\nproofreading. Experimental results suggest RefinPaint's effectiveness in\ninpainting and proofreading tasks, demonstrating its value for refining music\ncreated by both machines and humans. This approach not only facilitates\ncreativity but also aids amateur composers in improving their work.\n","subjects":["Computing Research Repository/Sound","Computing Research Repository/Artificial Intelligence","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"nYgqTnXYITCGIEKuLR8Jvi2ic7t22S6ib4CSSJ8AMAw","pdfSize":"805005"}