{
  "id": "2412.06040",
  "title": "The AI Double Standard: Humans Judge All AIs for the Actions of One",
  "authors": "Aikaterina Manoli, Janet V. T. Pauketat, Jacy Reese Anthis",
  "authorsParsed": [
    [
      "Manoli",
      "Aikaterina",
      ""
    ],
    [
      "Pauketat",
      "Janet V. T.",
      ""
    ],
    [
      "Anthis",
      "Jacy Reese",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Sun, 8 Dec 2024 19:26:52 GMT"
    }
  ],
  "updateDate": "2024-12-10",
  "timestamp": 1733686012000,
  "abstract": "  Robots and other artificial intelligence (AI) systems are widely perceived as\nmoral agents responsible for their actions. As AI proliferates, these\nperceptions may become entangled via the moral spillover of attitudes towards\none AI to attitudes towards other AIs. We tested how the seemingly harmful and\nimmoral actions of an AI or human agent spill over to attitudes towards other\nAIs or humans in two preregistered experiments. In Study 1 (N = 720), we\nestablished the moral spillover effect in human-AI interaction by showing that\nimmoral actions increased attributions of negative moral agency (i.e., acting\nimmorally) and decreased attributions of positive moral agency (i.e., acting\nmorally) and moral patiency (i.e., deserving moral concern) to both the agent\n(a chatbot or human assistant) and the group to which they belong (all chatbot\nor human assistants). There was no significant difference in the spillover\neffects between the AI and human contexts. In Study 2 (N = 684), we tested\nwhether spillover persisted when the agent was individuated with a name and\ndescribed as an AI or human, rather than specifically as a chatbot or personal\nassistant. We found that spillover persisted in the AI context but not in the\nhuman context, possibly because AIs were perceived as more homogeneous due to\ntheir outgroup status relative to humans. This asymmetry suggests a double\nstandard whereby AIs are judged more harshly than humans when one agent morally\ntransgresses. With the proliferation of diverse, autonomous AI systems, HCI\nresearch and design should account for the fact that experiences with one AI\ncould easily generalize to perceptions of all AIs and negative HCI outcomes,\nsuch as reduced trust.\n",
  "subjects": [
    "Computer Science/Artificial Intelligence",
    "Computer Science/Computers and Society",
    "Computer Science/Emerging Technologies",
    "Computer Science/Human-Computer Interaction"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "VScQKXlAm4nLcMVgFFNJ2JQYMafYjitUuV_rlNf5GYs",
  "pdfSize": "1486300"
}