{"id":"2407.17716","title":"Describe Where You Are: Improving Noise-Robustness for Speech Emotion\n  Recognition with Text Description of the Environment","authors":"Seong-Gyun Leem, Daniel Fulford, Jukka-Pekka Onnela, David Gard, and\n  Carlos Busso","authorsParsed":[["Leem","Seong-Gyun",""],["Fulford","Daniel",""],["Onnela","Jukka-Pekka",""],["Gard","David",""],["Busso","Carlos",""]],"versions":[{"version":"v1","created":"Thu, 25 Jul 2024 02:30:40 GMT"}],"updateDate":"2024-07-26","timestamp":1721874640000,"abstract":"  Speech emotion recognition (SER) systems often struggle in real-world\nenvironments, where ambient noise severely degrades their performance. This\npaper explores a novel approach that exploits prior knowledge of testing\nenvironments to maximize SER performance under noisy conditions. To address\nthis task, we propose a text-guided, environment-aware training where an SER\nmodel is trained with contaminated speech samples and their paired noise\ndescription. We use a pre-trained text encoder to extract the text-based\nenvironment embedding and then fuse it to a transformer-based SER model during\ntraining and inference. We demonstrate the effectiveness of our approach\nthrough our experiment with the MSP-Podcast corpus and real-world additive\nnoise samples collected from the Freesound repository. Our experiment indicates\nthat the text-based environment descriptions processed by a large language\nmodel (LLM) produce representations that improve the noise-robustness of the\nSER system. In addition, our proposed approach with an LLM yields better\nperformance than our environment-agnostic baselines, especially in low\nsignal-to-noise ratio (SNR) conditions. When testing at -5dB SNR level, our\nproposed method shows better performance than our best baseline model by 31.8 %\n(arousal), 23.5% (dominance), and 9.5% (valence).\n","subjects":["Computing Research Repository/Sound","Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"WnhU3eNVgKq-MC7o-vRH2yhR6KlOA9dQZYD4fh15Le8","pdfSize":"713887","objectId":"0x78efb454cb25e6c15896ee0bf64b21dc08a2a747bc5a015c6af2d30b8716ebc8","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
