{"id":"2407.09415","title":"A Benchmark Environment for Offline Reinforcement Learning in Racing\n  Games","authors":"Girolamo Macaluso, Alessandro Sestini and Andrew D. Bagdanov","authorsParsed":[["Macaluso","Girolamo",""],["Sestini","Alessandro",""],["Bagdanov","Andrew D.",""]],"versions":[{"version":"v1","created":"Fri, 12 Jul 2024 16:44:03 GMT"}],"updateDate":"2024-07-15","timestamp":1720802643000,"abstract":"  Offline Reinforcement Learning (ORL) is a promising approach to reduce the\nhigh sample complexity of traditional Reinforcement Learning (RL) by\neliminating the need for continuous environmental interactions. ORL exploits a\ndataset of pre-collected transitions and thus expands the range of application\nof RL to tasks in which the excessive environment queries increase training\ntime and decrease efficiency, such as in modern AAA games. This paper\nintroduces OfflineMania a novel environment for ORL research. It is inspired by\nthe iconic TrackMania series and developed using the Unity 3D game engine. The\nenvironment simulates a single-agent racing game in which the objective is to\ncomplete the track through optimal navigation. We provide a variety of datasets\nto assess ORL performance. These datasets, created from policies of varying\nability and in different sizes, aim to offer a challenging testbed for\nalgorithm development and evaluation. We further establish a set of baselines\nfor a range of Online RL, ORL, and hybrid Offline to Online RL approaches using\nour environment.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"4pTrxZocJfcLG1JAkagG7fiydo6SDUHkuwCOlZ8w9wY","pdfSize":"843441"}