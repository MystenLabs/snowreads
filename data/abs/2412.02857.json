{
  "id": "2412.02857",
  "title": "Measuring Bias of Web-filtered Text Datasets and Bias Propagation\n  Through Training",
  "authors": "Youssef Mansour and Reinhard Heckel",
  "authorsParsed": [
    [
      "Mansour",
      "Youssef",
      ""
    ],
    [
      "Heckel",
      "Reinhard",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Tue, 3 Dec 2024 21:43:58 GMT"
    }
  ],
  "updateDate": "2024-12-05",
  "timestamp": 1733262238000,
  "abstract": "  We investigate biases in pretraining datasets for large language models\n(LLMs) through dataset classification experiments. Building on prior work\ndemonstrating the existence of biases in popular computer vision datasets, we\nanalyze popular open-source pretraining datasets for LLMs derived from\nCommonCrawl including C4, RefinedWeb, DolmaCC, RedPajama-V2, FineWeb, and\nDCLM-Baseline. Despite those datasets being obtained with similar filtering and\ndeduplication steps, neural networks can classify surprisingly well which\ndataset a single text sequence belongs to, significantly better than a human\ncan. This indicates that popular pretraining datasets have their own unique\nbiases or fingerprints. Those biases remain even when the text is rewritten\nwith LLMs. Moreover, these biases propagate through training: Random sequences\ngenerated by models trained on those datasets can be classified well by a\nclassifier trained on the original datasets.\n",
  "subjects": [
    "Computer Science/Machine Learning"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "e9Sw61Te7oFmQrrHbwSOaRfmjO1p1JhtkwajTvjZTh0",
  "pdfSize": "410302"
}