{
  "id": "2412.13623",
  "title": "Unifying Attribution-Based Explanations Using Functional Decomposition",
  "authors": "Arne Gevaert, Yvan Saeys",
  "authorsParsed": [
    [
      "Gevaert",
      "Arne",
      ""
    ],
    [
      "Saeys",
      "Yvan",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Wed, 18 Dec 2024 09:04:07 GMT"
    }
  ],
  "updateDate": "2024-12-19",
  "timestamp": 1734512647000,
  "abstract": "  The black box problem in machine learning has led to the introduction of an\never-increasing set of explanation methods for complex models. These\nexplanations have different properties, which in turn has led to the problem of\nmethod selection: which explanation method is most suitable for a given use\ncase? In this work, we propose a unifying framework of attribution-based\nexplanation methods, which provides a step towards a rigorous study of the\nsimilarities and differences of explanations. We first introduce removal-based\nattribution methods (RBAMs), and show that an extensively broad selection of\nexisting methods can be viewed as such RBAMs. We then introduce the canonical\nadditive decomposition (CAD). This is a general construction for additively\ndecomposing any function based on the central idea of removing (groups of)\nfeatures. We proceed to show that indeed every valid additive decomposition is\nan instance of the CAD, and that any removal-based attribution method is\nassociated with a specific CAD. Next, we show that any removal-based\nattribution method can be completely defined as a game-theoretic value or\ninteraction index for a specific (possibly constant-shifted) cooperative game,\nwhich is defined using the corresponding CAD of the method. We then use this\nintrinsic connection to define formal descriptions of specific behaviours of\nexplanation methods, which we also call functional axioms, and identify\nsufficient conditions on the corresponding CAD and game-theoretic value or\ninteraction index of an attribution method under which the attribution method\nis guaranteed to adhere to these functional axioms. Finally, we show how this\nunifying framework can be used to develop new, efficient approximations for\nexisting explanation methods.\n",
  "subjects": [
    "Computer Science/Machine Learning",
    "Computer Science/Artificial Intelligence"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "5oBMlvyOKcikSqmNsjaoPtvDnnh72-iwIi51xH_IseI",
  "pdfSize": "952061"
}