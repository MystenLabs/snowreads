{
  "id": "2412.01630",
  "title": "Review of Mathematical Optimization in Federated Learning",
  "authors": "Shusen Yang and Fangyuan Zhao and Zihao Zhou and Liang Shi and Xuebin\n  Ren and Zongben Xu",
  "authorsParsed": [
    [
      "Yang",
      "Shusen",
      ""
    ],
    [
      "Zhao",
      "Fangyuan",
      ""
    ],
    [
      "Zhou",
      "Zihao",
      ""
    ],
    [
      "Shi",
      "Liang",
      ""
    ],
    [
      "Ren",
      "Xuebin",
      ""
    ],
    [
      "Xu",
      "Zongben",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Mon, 2 Dec 2024 15:45:46 GMT"
    }
  ],
  "updateDate": "2024-12-03",
  "timestamp": 1733154346000,
  "abstract": "  Federated Learning (FL) has been becoming a popular interdisciplinary\nresearch area in both applied mathematics and information sciences.\nMathematically, FL aims to collaboratively optimize aggregate objective\nfunctions over distributed datasets while satisfying a variety of privacy and\nsystem constraints.Different from conventional distributed optimization\nmethods, FL needs to address several specific issues (e.g., non-i.i.d. data\ndistributions and differential private noises), which pose a set of new\nchallenges in the problem formulation, algorithm design, and convergence\nanalysis. In this paper, we will systematically review existing FL optimization\nresearch including their assumptions, formulations, methods, and theoretical\nresults. Potential future directions are also discussed.\n",
  "subjects": [
    "Computer Science/Machine Learning",
    "Computer Science/Distributed, Parallel, and Cluster Computing"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "pYnALoGtx19xj97q2JNv4NeBkLZ1YjqaTSVpiJJ2Q0U",
  "pdfSize": "1051778"
}