{"id":"2407.10344","title":"GLIM: 3D Range-Inertial Localization and Mapping with GPU-Accelerated\n  Scan Matching Factors","authors":"Kenji Koide, Masashi Yokozuka, Shuji Oishi, and Atsuhiko Banno","authorsParsed":[["Koide","Kenji",""],["Yokozuka","Masashi",""],["Oishi","Shuji",""],["Banno","Atsuhiko",""]],"versions":[{"version":"v1","created":"Sun, 14 Jul 2024 22:11:13 GMT"}],"updateDate":"2024-07-16","timestamp":1720995073000,"abstract":"  This article presents GLIM, a 3D range-inertial localization and mapping\nframework with GPU-accelerated scan matching factors. The odometry estimation\nmodule of GLIM employs a combination of fixed-lag smoothing and keyframe-based\npoint cloud matching that makes it possible to deal with a few seconds of\ncompletely degenerated range data while efficiently reducing trajectory\nestimation drift. It also incorporates multi-camera visual feature constraints\nin a tightly coupled way to further improve the stability and accuracy. The\nglobal trajectory optimization module directly minimizes the registration\nerrors between submaps over the entire map. This approach enables us to\naccurately constrain the relative pose between submaps with a small overlap.\nAlthough both the odometry estimation and global trajectory optimization\nalgorithms require much more computation than existing methods, we show that\nthey can be run in real-time due to the careful design of the registration\nerror evaluation algorithm and the entire system to fully leverage GPU parallel\nprocessing.\n","subjects":["Computing Research Repository/Robotics"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"ObyXwkucIz3Drl24cHD6OEJYAM6BFNp5UBna0pHh6s0","pdfSize":"18014128"}