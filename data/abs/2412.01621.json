{"id":"2412.01621","title":"NYT-Connections: A Deceptively Simple Text Classification Task that\n  Stumps System-1 Thinkers","authors":"Angel Yahir Loredo Lopez, Tyler McDonald, and Ali Emami","authorsParsed":[["Lopez","Angel Yahir Loredo",""],["McDonald","Tyler",""],["Emami","Ali",""]],"versions":[{"version":"v1","created":"Mon, 2 Dec 2024 15:41:47 GMT"},{"version":"v2","created":"Wed, 12 Feb 2025 14:03:19 GMT"},{"version":"v3","created":"Tue, 25 Feb 2025 12:59:42 GMT"}],"updateDate":"2025-02-26","timestamp":1733154107000,"abstract":"  Large Language Models (LLMs) have shown impressive performance on various\nbenchmarks, yet their ability to engage in deliberate reasoning remains\nquestionable. We present NYT-Connections, a collection of 358 simple word\nclassification puzzles derived from the New York Times Connections game. This\nbenchmark is designed to penalize quick, intuitive \"System 1\" thinking,\nisolating fundamental reasoning skills. We evaluated six recent LLMs, a simple\nmachine learning heuristic, and humans across three configurations:\nsingle-attempt, multiple attempts without hints, and multiple attempts with\ncontextual hints. Our findings reveal a significant performance gap: even\ntop-performing LLMs like GPT-4 fall short of human performance by nearly 30%.\nNotably, advanced prompting techniques such as Chain-of-Thought and\nSelf-Consistency show diminishing returns as task difficulty increases.\nNYT-Connections uniquely combines linguistic isolation, resistance to intuitive\nshortcuts, and regular updates to mitigate data leakage, offering a novel tool\nfor assessing LLM reasoning capabilities.\n","subjects":["Computer Science/Computation and Language","Computer Science/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"oE7VJsPcO5DFCcbykEVP06KkZagQGoTq38TMEpbBcd4","pdfSize":"3929837"}