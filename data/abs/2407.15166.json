{"id":"2407.15166","title":"Adversarial Circuit Evaluation","authors":"Niels uit de Bos, Adri\\`a Garriga-Alonso","authorsParsed":[["de Bos","Niels uit",""],["Garriga-Alonso","Adri√†",""]],"versions":[{"version":"v1","created":"Sun, 21 Jul 2024 13:43:44 GMT"}],"updateDate":"2024-07-23","timestamp":1721569424000,"abstract":"  Circuits are supposed to accurately describe how a neural network performs a\nspecific task, but do they really? We evaluate three circuits found in the\nliterature (IOI, greater-than, and docstring) in an adversarial manner,\nconsidering inputs where the circuit's behavior maximally diverges from the\nfull model. Concretely, we measure the KL divergence between the full model's\noutput and the circuit's output, calculated through resample ablation, and we\nanalyze the worst-performing inputs. Our results show that the circuits for the\nIOI and docstring tasks fail to behave similarly to the full model even on\ncompletely benign inputs from the original task, indicating that more robust\ncircuits are needed for safety-critical applications.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"11AExYgiq4qbTsXMYEagoGSzz2S6zsRhGXPCK64EogI","pdfSize":"1000157"}