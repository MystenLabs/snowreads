{
  "id": "2412.14100",
  "title": "Parameter-efficient Fine-tuning for improved Convolutional Baseline for\n  Brain Tumor Segmentation in Sub-Saharan Africa Adult Glioma Dataset",
  "authors": "Bijay Adhikari, Pratibha Kulung, Jakesh Bohaju, Laxmi Kanta Poudel,\n  Confidence Raymond, Dong Zhang, Udunna C Anazodo, Bishesh Khanal, Mahesh\n  Shakya",
  "authorsParsed": [
    [
      "Adhikari",
      "Bijay",
      ""
    ],
    [
      "Kulung",
      "Pratibha",
      ""
    ],
    [
      "Bohaju",
      "Jakesh",
      ""
    ],
    [
      "Poudel",
      "Laxmi Kanta",
      ""
    ],
    [
      "Raymond",
      "Confidence",
      ""
    ],
    [
      "Zhang",
      "Dong",
      ""
    ],
    [
      "Anazodo",
      "Udunna C",
      ""
    ],
    [
      "Khanal",
      "Bishesh",
      ""
    ],
    [
      "Shakya",
      "Mahesh",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Wed, 18 Dec 2024 17:48:32 GMT"
    }
  ],
  "updateDate": "2024-12-19",
  "timestamp": 1734544112000,
  "abstract": "  Automating brain tumor segmentation using deep learning methods is an ongoing\nchallenge in medical imaging. Multiple lingering issues exist including\ndomain-shift and applications in low-resource settings which brings a unique\nset of challenges including scarcity of data. As a step towards solving these\nspecific problems, we propose Convolutional adapter-inspired\nParameter-efficient Fine-tuning (PEFT) of MedNeXt architecture. To validate our\nidea, we show our method performs comparable to full fine-tuning with the added\nbenefit of reduced training compute using BraTS-2021 as pre-training dataset\nand BraTS-Africa as the fine-tuning dataset. BraTS-Africa consists of a small\ndataset (60 train / 35 validation) from the Sub-Saharan African population with\nmarked shift in the MRI quality compared to BraTS-2021 (1251 train samples). We\nfirst show that models trained on BraTS-2021 dataset do not generalize well to\nBraTS-Africa as shown by 20% reduction in mean dice on BraTS-Africa validation\nsamples. Then, we show that PEFT can leverage both the BraTS-2021 and\nBraTS-Africa dataset to obtain mean dice of 0.8 compared to 0.72 when trained\nonly on BraTS-Africa. Finally, We show that PEFT (0.80 mean dice) results in\ncomparable performance to full fine-tuning (0.77 mean dice) which may show PEFT\nto be better on average but the boxplots show that full finetuning results is\nmuch lesser variance in performance. Nevertheless, on disaggregation of the\ndice metrics, we find that the model has tendency to oversegment as shown by\nhigh specificity (0.99) compared to relatively low sensitivity(0.75). The\nsource code is available at\nhttps://github.com/CAMERA-MRI/SPARK2024/tree/main/PEFT_MedNeXt\n",
  "subjects": [
    "Electrical Engineering and Systems Science/Image and Video Processing",
    "Computer Science/Computer Vision and Pattern Recognition",
    "Computer Science/Machine Learning"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "bzgNeQ56oVLzj2QdQA3r-47ZS5FDRecPuntXRHimbMc",
  "pdfSize": "1580912"
}