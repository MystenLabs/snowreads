{"id":"2412.06029","title":"Latent-Reframe: Enabling Camera Control for Video Diffusion Model\n  without Training","authors":"Zhenghong Zhou, Jie An, Jiebo Luo","authorsParsed":[["Zhou","Zhenghong",""],["An","Jie",""],["Luo","Jiebo",""]],"versions":[{"version":"v1","created":"Sun, 8 Dec 2024 18:59:54 GMT"}],"updateDate":"2024-12-10","timestamp":1733684394000,"abstract":"  Precise camera pose control is crucial for video generation with diffusion\nmodels. Existing methods require fine-tuning with additional datasets\ncontaining paired videos and camera pose annotations, which are both\ndata-intensive and computationally costly, and can disrupt the pre-trained\nmodel distribution. We introduce Latent-Reframe, which enables camera control\nin a pre-trained video diffusion model without fine-tuning. Unlike existing\nmethods, Latent-Reframe operates during the sampling stage, maintaining\nefficiency while preserving the original model distribution. Our approach\nreframes the latent code of video frames to align with the input camera\ntrajectory through time-aware point clouds. Latent code inpainting and\nharmonization then refine the model latent space, ensuring high-quality video\ngeneration. Experimental results demonstrate that Latent-Reframe achieves\ncomparable or superior camera control precision and video quality to\ntraining-based methods, without the need for fine-tuning on additional\ndatasets.\n","subjects":["Computer Science/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"JZU-RLJ_ypSiT092CU8NsnhI1MfpP-9YAItITivVzxg","pdfSize":"14082776"}