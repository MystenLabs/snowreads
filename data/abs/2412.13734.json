{
  "id": "2412.13734",
  "title": "Text2Relight: Creative Portrait Relighting with Text Guidance",
  "authors": "Junuk Cha, Mengwei Ren, Krishna Kumar Singh, He Zhang, Yannick\n  Hold-Geoffroy, Seunghyun Yoon, HyunJoon Jung, Jae Shin Yoon, Seungryul Baek",
  "authorsParsed": [
    [
      "Cha",
      "Junuk",
      ""
    ],
    [
      "Ren",
      "Mengwei",
      ""
    ],
    [
      "Singh",
      "Krishna Kumar",
      ""
    ],
    [
      "Zhang",
      "He",
      ""
    ],
    [
      "Hold-Geoffroy",
      "Yannick",
      ""
    ],
    [
      "Yoon",
      "Seunghyun",
      ""
    ],
    [
      "Jung",
      "HyunJoon",
      ""
    ],
    [
      "Yoon",
      "Jae Shin",
      ""
    ],
    [
      "Baek",
      "Seungryul",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Wed, 18 Dec 2024 11:12:10 GMT"
    }
  ],
  "updateDate": "2024-12-19",
  "timestamp": 1734520330000,
  "abstract": "  We present a lighting-aware image editing pipeline that, given a portrait\nimage and a text prompt, performs single image relighting. Our model modifies\nthe lighting and color of both the foreground and background to align with the\nprovided text description. The unbounded nature in creativeness of a text\nallows us to describe the lighting of a scene with any sensory features\nincluding temperature, emotion, smell, time, and so on. However, the modeling\nof such mapping between the unbounded text and lighting is extremely\nchallenging due to the lack of dataset where there exists no scalable data that\nprovides large pairs of text and relighting, and therefore, current text-driven\nimage editing models does not generalize to lighting-specific use cases. We\novercome this problem by introducing a novel data synthesis pipeline: First,\ndiverse and creative text prompts that describe the scenes with various\nlighting are automatically generated under a crafted hierarchy using a large\nlanguage model (*e.g.,* ChatGPT). A text-guided image generation model creates\na lighting image that best matches the text. As a condition of the lighting\nimages, we perform image-based relighting for both foreground and background\nusing a single portrait image or a set of OLAT (One-Light-at-A-Time) images\ncaptured from lightstage system. Particularly for the background relighting, we\nrepresent the lighting image as a set of point lights and transfer them to\nother background images. A generative diffusion model learns the synthesized\nlarge-scale data with auxiliary task augmentation (*e.g.,* portrait delighting\nand light positioning) to correlate the latent text and lighting distribution\nfor text-guided portrait relighting.\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition"
  ],
  "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
  "blobId": "z0YGd3DZOtreQqCx0wQuWa--4XAWpfEAyeb0gEBoNoo",
  "pdfSize": "8223972"
}