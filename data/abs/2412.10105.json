{"id":"2412.10105","title":"MALAMUTE: A Multilingual, Highly-granular, Template-free,\n  Education-based Probing Dataset","authors":"Sagi Shaier, George Arthur Baker, Chiranthan Sridhar, Lawrence E\n  Hunter, Katharina von der Wense","authorsParsed":[["Shaier","Sagi",""],["Baker","George Arthur",""],["Sridhar","Chiranthan",""],["Hunter","Lawrence E",""],["von der Wense","Katharina",""]],"versions":[{"version":"v1","created":"Fri, 13 Dec 2024 12:46:33 GMT"}],"updateDate":"2024-12-16","timestamp":1734093993000,"abstract":"  Language models (LMs) have excelled in various broad domains. However, to\nensure their safe and effective integration into real-world educational\nsettings, they must demonstrate proficiency in specific, granular areas of\nknowledge. Existing cloze-style benchmarks, commonly used to evaluate LMs'\nknowledge, have three major limitations. They: 1) do not cover the educational\ndomain; 2) typically focus on low-complexity, generic knowledge or broad\ndomains, which do not adequately assess the models' knowledge in specific\nsubjects; and 3) often rely on templates that can bias model predictions. Here,\nwe introduce MALAMUTE, a multilingual, template-free, and highly granular\nprobing dataset comprising expert-written, peer-reviewed probes from 71\nuniversity-level textbooks across three languages (English, Spanish, and\nPolish). MALAMUTE is the first education-based cloze-style dataset. It covers\neight domains, each with up to 14 subdomains, further broken down into concepts\nand concept-based prompts, totaling 33,361 university curriculum concepts and\n116,887 prompts. MALAMUTE's fine granularity, educational focus, and inclusion\nof both sentence-level and paragraph-level prompts make it an ideal tool for\nevaluating LMs' course-related knowledge. Our evaluation of masked and causal\nLMs on MALAMUTE shows that despite overall proficiency, they have significant\ngaps in knowledge when examined closely on specific subjects, hindering their\nsafe use in classrooms and underscoring the need for further development.\n","subjects":["Computer Science/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"gODXER5wgYuic8nBIXBNo_CSsiopX9RRLb0jD_8_dXo","pdfSize":"714498"}