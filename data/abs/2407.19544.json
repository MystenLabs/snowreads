{"id":"2407.19544","title":"Deep Generative Models-Assisted Automated Labeling for Electron\n  Microscopy Images Segmentation","authors":"Wenhao Yuan, Bingqing Yao, Shengdong Tan, Fengqi You and Qian He","authorsParsed":[["Yuan","Wenhao",""],["Yao","Bingqing",""],["Tan","Shengdong",""],["You","Fengqi",""],["He","Qian",""]],"versions":[{"version":"v1","created":"Sun, 28 Jul 2024 17:35:24 GMT"}],"updateDate":"2024-07-30","timestamp":1722188124000,"abstract":"  The rapid advancement of deep learning has facilitated the automated\nprocessing of electron microscopy (EM) big data stacks. However, designing a\nframework that eliminates manual labeling and adapts to domain gaps remains\nchallenging. Current research remains entangled in the dilemma of pursuing\ncomplete automation while still requiring simulations or slight manual\nannotations. Here we demonstrate tandem generative adversarial network (tGAN),\na fully label-free and simulation-free pipeline capable of generating EM images\nfor computer vision training. The tGAN can assimilate key features from new\ndata stacks, thus producing a tailored virtual dataset for the training of\nautomated EM analysis tools. Using segmenting nanoparticles for analyzing size\ndistribution of supported catalysts as the demonstration, our findings\nshowcased that the recognition accuracy of tGAN even exceeds the\nmanually-labeling method by 5%. It can also be adaptively deployed to various\ndata domains without further manual manipulation, which is verified by transfer\nlearning from HAADF-STEM to BF-TEM. This generalizability may enable it to\nextend its application to a broader range of imaging characterizations,\nliberating microscopists and materials scientists from tedious dataset\nannotations.\n","subjects":["Condensed Matter/Materials Science","Electrical Engineering and Systems Science/Image and Video Processing"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"z443seTA4P7uR8WKBzdCInP8gA-6jetnFRGTm8mupuk","pdfSize":"951732"}