{"id":"2412.19088","title":"Integrating Artificial Open Generative Artificial Intelligence into\n  Software Supply Chain Security","authors":"Vasileios Alevizos, George A Papakostas, Akebu Simasiku, Dimitra\n  Malliarou, Antonis Messinis, Sabrina Edralin, Clark Xu, Zongliang Yue","authorsParsed":[["Alevizos","Vasileios",""],["Papakostas","George A",""],["Simasiku","Akebu",""],["Malliarou","Dimitra",""],["Messinis","Antonis",""],["Edralin","Sabrina",""],["Xu","Clark",""],["Yue","Zongliang",""]],"versions":[{"version":"v1","created":"Thu, 26 Dec 2024 07:03:55 GMT"}],"updateDate":"2025-01-22","timestamp":1735196635000,"abstract":"  While new technologies emerge, human errors always looming. Software supply\nchain is increasingly complex and intertwined, the security of a service has\nbecome paramount to ensuring the integrity of products, safeguarding data\nprivacy, and maintaining operational continuity. In this work, we conducted\nexperiments on the promising open Large Language Models (LLMs) into two main\nsoftware security challenges: source code language errors and deprecated code,\nwith a focus on their potential to replace conventional static and dynamic\nsecurity scanners that rely on predefined rules and patterns. Our findings\nsuggest that while LLMs present some unexpected results, they also encounter\nsignificant limitations, particularly in memory complexity and the management\nof new and unfamiliar data patterns. Despite these challenges, the proactive\napplication of LLMs, coupled with extensive security databases and continuous\nupdates, holds the potential to fortify Software Supply Chain (SSC) processes\nagainst emerging threats.\n","subjects":["Computer Science/Cryptography and Security","Computer Science/Artificial Intelligence","Computer Science/Emerging Technologies"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"WWs6Z3FYSi5ts1YMHVewX29OwfdnbwGqACu0qsXZYZk","pdfSize":"237874"}