{"id":"2412.03621","title":"Network-aided Efficient Large Language Model Services With\n  Denoising-inspired Prompt Compression","authors":"Feiran You, Hongyang Du, Kaibin Huang, and Abbas Jamalipour","authorsParsed":[["You","Feiran",""],["Du","Hongyang",""],["Huang","Kaibin",""],["Jamalipour","Abbas",""]],"versions":[{"version":"v1","created":"Wed, 4 Dec 2024 15:26:10 GMT"}],"updateDate":"2024-12-06","timestamp":1733325970000,"abstract":"  Large Language Models (LLMs) have demonstrated remarkable capabilities in\nvarious tasks, leading to their increasing adoption in diverse services\ndelivered through wireless networks. There is a growing trend toward longer\nprompts to better leverage LLMs' capabilities and address difficult tasks.\nHowever, longer prompts not only increase data transmission costs across\nwireless transmission but also require more computing resources and processing\ntime, impacting the overall system efficiency and user experience. To address\nthis challenge, we propose Joint Power and Prompt Optimization (JPPO), a\nframework that combines Small Language Model (SLM)-based prompt compression\nwith wireless power allocation optimization. By deploying SLM at edge devices\nfor prompt compression and employing Deep Reinforcement Learning (DRL) for\njoint optimization of compression ratio and transmission power, JPPO\neffectively balances service quality with resource efficiency. Furthermore,\ninspired by denoising diffusion models, we design a denoising-inspired prompt\ncompression approach that iteratively compresses prompts by gradually removing\nnon-critical information. Experimental results demonstrate that our framework\nachieves high service fidelity while optimizing power usage in wireless LLM\nservices, reducing the total service response time. With our DRL-based JPPO,\nthe framework maintains fidelity comparable to the no-compression baseline\nwhile still achieving a 17% service time reduction through adaptive\ncompression. When prioritizing compression, our framework achieves up to 16x\ncompression ratio while maintaining acceptable fidelity (within 30% reduction).\nCompared to no compression, baseline single-round compression with a 16x\ncompression ratio reduces the system total response time by approximately\n42.3%, while the denoising-inspired method achieves a 46.5% service\ntime-saving.\n","subjects":["Computer Science/Networking and Internet Architecture"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"n1qfIB_S_u_RKj_qsax0RQ3Lejezozso59f9tpm_QuE","pdfSize":"1549613"}