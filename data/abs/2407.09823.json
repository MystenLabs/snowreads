{"id":"2407.09823","title":"NativQA: Multilingual Culturally-Aligned Natural Query for LLMs","authors":"Md. Arid Hasan, Maram Hasanain, Fatema Ahmad, Sahinur Rahman Laskar,\n  Sunaya Upadhyay, Vrunda N Sukhadia, Mucahid Kutlu, Shammur Absar Chowdhury,\n  Firoj Alam","authorsParsed":[["Hasan","Md. Arid",""],["Hasanain","Maram",""],["Ahmad","Fatema",""],["Laskar","Sahinur Rahman",""],["Upadhyay","Sunaya",""],["Sukhadia","Vrunda N",""],["Kutlu","Mucahid",""],["Chowdhury","Shammur Absar",""],["Alam","Firoj",""]],"versions":[{"version":"v1","created":"Sat, 13 Jul 2024 09:34:00 GMT"}],"updateDate":"2024-07-16","timestamp":1720863240000,"abstract":"  Natural Question Answering (QA) datasets play a crucial role in developing\nand evaluating the capabilities of large language models (LLMs), ensuring their\neffective usage in real-world applications. Despite the numerous QA datasets\nthat have been developed, there is a notable lack of region-specific datasets\ngenerated by native users in their own languages. This gap hinders the\neffective benchmarking of LLMs for regional and cultural specificities. In this\nstudy, we propose a scalable framework, NativQA, to seamlessly construct\nculturally and regionally aligned QA datasets in native languages, for LLM\nevaluation and tuning. Moreover, to demonstrate the efficacy of the proposed\nframework, we designed a multilingual natural QA dataset, MultiNativQA,\nconsisting of ~72K QA pairs in seven languages, ranging from high to extremely\nlow resource, based on queries from native speakers covering 18 topics. We\nbenchmark the MultiNativQA dataset with open- and closed-source LLMs. We made\nboth the framework NativQA and MultiNativQA dataset publicly available for the\ncommunity. (https://nativqa.gitlab.io)\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"e91wECUCPq0ZHAoTDBoNUKKjkKMSSKnh2bzhLR0Uf8o","pdfSize":"2319090"}