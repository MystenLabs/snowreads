{"id":"2407.03239","title":"Solving the inverse problem of microscopy deconvolution with a residual\n  Beylkin-Coifman-Rokhlin neural network","authors":"Rui Li, Mikhail Kudryashev, Artur Yakimovich","authorsParsed":[["Li","Rui",""],["Kudryashev","Mikhail",""],["Yakimovich","Artur",""]],"versions":[{"version":"v1","created":"Wed, 3 Jul 2024 16:09:59 GMT"},{"version":"v2","created":"Mon, 15 Jul 2024 08:53:44 GMT"}],"updateDate":"2024-07-16","timestamp":1720022999000,"abstract":"  Optic deconvolution in light microscopy (LM) refers to recovering the object\ndetails from images, revealing the ground truth of samples. Traditional\nexplicit methods in LM rely on the point spread function (PSF) during image\nacquisition. Yet, these approaches often fall short due to inaccurate PSF\nmodels and noise artifacts, hampering the overall restoration quality. In this\npaper, we approached the optic deconvolution as an inverse problem. Motivated\nby the nonstandard-form compression scheme introduced by Beylkin, Coifman, and\nRokhlin (BCR), we proposed an innovative physics-informed neural network\nMulti-Stage Residual-BCR Net (m-rBCR) to approximate the optic deconvolution.\nWe validated the m-rBCR model on four microscopy datasets - two simulated\nmicroscopy datasets from ImageNet and BioSR, real dSTORM microscopy images, and\nreal widefield microscopy images. In contrast to the explicit deconvolution\nmethods (e.g. Richardson-Lucy) and other state-of-the-art NN models (U-Net,\nDDPM, CARE, DnCNN, ESRGAN, RCAN, Noise2Noise, MPRNet, and MIMO-U-Net), the\nm-rBCR model demonstrates superior performance to other candidates by PSNR and\nSSIM in two real microscopy datasets and the simulated BioSR dataset. In the\nsimulated ImageNet dataset, m-rBCR ranks the second-best place (right after\nMIMO-U-Net). With the backbone from the optical physics, m-rBCR exploits the\ntrainable parameters with better performances (from ~30 times fewer than the\nbenchmark MIMO-U-Net to ~210 times than ESRGAN). This enables m-rBCR to achieve\na shorter runtime (from ~3 times faster than MIMO-U-Net to ~300 times faster\nthan DDPM). To summarize, by leveraging physics constraints our model reduced\npotentially redundant parameters significantly in expertise-oriented NN\ncandidates and achieved high efficiency with superior performance.\n","subjects":["Quantitative Biology/Quantitative Methods","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"ME9gbH3BDNyAxmaVulwHZn4x3ySAImdrRqtHvZKJl18","pdfSize":"20140038"}