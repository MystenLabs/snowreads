{"id":"2407.11668","title":"Learning to Make Keypoints Sub-Pixel Accurate","authors":"Shinjeong Kim, Marc Pollefeys, and Daniel Barath","authorsParsed":[["Kim","Shinjeong",""],["Pollefeys","Marc",""],["Barath","Daniel",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 12:39:56 GMT"}],"updateDate":"2024-07-17","timestamp":1721133596000,"abstract":"  This work addresses the challenge of sub-pixel accuracy in detecting 2D local\nfeatures, a cornerstone problem in computer vision. Despite the advancements\nbrought by neural network-based methods like SuperPoint and ALIKED, these\nmodern approaches lag behind classical ones such as SIFT in keypoint\nlocalization accuracy due to their lack of sub-pixel precision. We propose a\nnovel network that enhances any detector with sub-pixel precision by learning\nan offset vector for detected features, thereby eliminating the need for\ndesigning specialized sub-pixel accurate detectors. This optimization directly\nminimizes test-time evaluation metrics like relative pose error. Through\nextensive testing with both nearest neighbors matching and the recent LightGlue\nmatcher across various real-world datasets, our method consistently outperforms\nexisting methods in accuracy. Moreover, it adds only around 7 ms to the time of\na particular detector. The code is available at\nhttps://github.com/KimSinjeong/keypt2subpx .\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-sa/4.0/","blobId":"R4L7YEwEkJJUD39P0o0LewLJq-UjSKx6eZLPgN7fLRw","pdfSize":"59895707","objectId":"0x65acd266473f99dedfa988fb15542850465f8e012826a1dd650edab196c1b4ab","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
