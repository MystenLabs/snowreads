{"id":"2407.08513","title":"Fine-Tuning Stable Diffusion XL for Stylistic Icon Generation: A\n  Comparison of Caption Size","authors":"Youssef Sultan, Jiangqin Ma, Yu-Ying Liao","authorsParsed":[["Sultan","Youssef",""],["Ma","Jiangqin",""],["Liao","Yu-Ying",""]],"versions":[{"version":"v1","created":"Thu, 11 Jul 2024 13:55:20 GMT"},{"version":"v2","created":"Sat, 13 Jul 2024 22:52:22 GMT"}],"updateDate":"2024-07-16","timestamp":1720706120000,"abstract":"  In this paper, we show different fine-tuning methods for Stable Diffusion XL;\nthis includes inference steps, and caption customization for each image to\nalign with generating images in the style of a commercial 2D icon training set.\nWe also show how important it is to properly define what \"high-quality\" really\nis especially for a commercial-use environment. As generative AI models\ncontinue to gain widespread acceptance and usage, there emerge many different\nways to optimize and evaluate them for various applications. Specifically\ntext-to-image models, such as Stable Diffusion XL and DALL-E 3 require distinct\nevaluation practices to effectively generate high-quality icons according to a\nspecific style. Although some images that are generated based on a certain\nstyle may have a lower FID score (better), we show how this is not absolute in\nand of itself even for rasterized icons. While FID scores reflect the\nsimilarity of generated images to the overall training set, CLIP scores measure\nthe alignment between generated images and their textual descriptions. We show\nhow FID scores miss significant aspects, such as the minority of pixel\ndifferences that matter most in an icon, while CLIP scores result in misjudging\nthe quality of icons. The CLIP model's understanding of \"similarity\" is shaped\nby its own training data; which does not account for feature variation in our\nstyle of choice. Our findings highlight the need for specialized evaluation\nmetrics and fine-tuning approaches when generating high-quality commercial\nicons, potentially leading to more effective and tailored applications of\ntext-to-image models in professional design contexts.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"TBxXrvCCtXUX72xgWBQahrfmI0MvQiRfjGPIYtE1PnI","pdfSize":"16958893"}