{
  "id": "2412.03915",
  "title": "Quantized and Interpretable Learning Scheme for Deep Neural Networks in\n  Classification Task",
  "authors": "Alireza Maleki, Mahsa Lavaei, Mohsen Bagheritabar, Salar Beigzad,\n  Zahra Abadi",
  "authorsParsed": [
    [
      "Maleki",
      "Alireza",
      ""
    ],
    [
      "Lavaei",
      "Mahsa",
      ""
    ],
    [
      "Bagheritabar",
      "Mohsen",
      ""
    ],
    [
      "Beigzad",
      "Salar",
      ""
    ],
    [
      "Abadi",
      "Zahra",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Thu, 5 Dec 2024 06:34:06 GMT"
    }
  ],
  "updateDate": "2024-12-06",
  "timestamp": 1733380446000,
  "abstract": "  Deep learning techniques have proven highly effective in image\nclassification, but their deployment in resourceconstrained environments\nremains challenging due to high computational demands. Furthermore, their\ninterpretability is of high importance which demands even more available\nresources. In this work, we introduce an approach that combines saliency-guided\ntraining with quantization techniques to create an interpretable and\nresource-efficient model without compromising accuracy. We utilize\nParameterized Clipping Activation (PACT) to perform quantization-aware\ntraining, specifically targeting activations and weights to optimize precision\nwhile minimizing resource usage. Concurrently, saliency-guided training is\nemployed to enhance interpretability by iteratively masking features with low\ngradient values, leading to more focused and meaningful saliency maps. This\ntraining procedure helps in mitigating noisy gradients and yields models that\nprovide clearer, more interpretable insights into their decision-making\nprocesses. To evaluate the impact of our approach, we conduct experiments using\nfamous Convolutional Neural Networks (CNN) architecture on the MNIST and\nCIFAR-10 benchmark datasets as two popular datasets. We compare the saliency\nmaps generated by standard and quantized models to assess the influence of\nquantization on both interpretability and classification accuracy. Our results\ndemonstrate that the combined use of saliency-guided training and PACT-based\nquantization not only maintains classification performance but also produces\nmodels that are significantly more efficient and interpretable, making them\nsuitable for deployment in resource-limited settings.\n",
  "subjects": [
    "Computer Science/Machine Learning",
    "Computer Science/Computer Vision and Pattern Recognition"
  ],
  "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
  "blobId": "8VB7s9inV5pn-oQnzfeLfzixlhhlGJTr5UIS5hIkUxE",
  "pdfSize": "345972"
}