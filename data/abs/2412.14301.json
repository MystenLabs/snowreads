{
  "id": "2412.14301",
  "title": "What Has Been Overlooked in Contrastive Source-Free Domain Adaptation:\n  Leveraging Source-Informed Latent Augmentation within Neighborhood Context",
  "authors": "Jing Wang, Wonho Bae, Jiahong Chen, Kuangen Zhang, Leonid Sigal and\n  Clarence W. de Silva",
  "authorsParsed": [
    [
      "Wang",
      "Jing",
      ""
    ],
    [
      "Bae",
      "Wonho",
      ""
    ],
    [
      "Chen",
      "Jiahong",
      ""
    ],
    [
      "Zhang",
      "Kuangen",
      ""
    ],
    [
      "Sigal",
      "Leonid",
      ""
    ],
    [
      "de Silva",
      "Clarence W.",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Wed, 18 Dec 2024 20:09:46 GMT"
    }
  ],
  "updateDate": "2024-12-20",
  "timestamp": 1734552586000,
  "abstract": "  Source-free domain adaptation (SFDA) involves adapting a model originally\ntrained using a labeled dataset ({\\em source domain}) to perform effectively on\nan unlabeled dataset ({\\em target domain}) without relying on any source data\nduring adaptation. This adaptation is especially crucial when significant\ndisparities in data distributions exist between the two domains and when there\nare privacy concerns regarding the source model's training data. The absence of\naccess to source data during adaptation makes it challenging to analytically\nestimate the domain gap. To tackle this issue, various techniques have been\nproposed, such as unsupervised clustering, contrastive learning, and continual\nlearning. In this paper, we first conduct an extensive theoretical analysis of\nSFDA based on contrastive learning, primarily because it has demonstrated\nsuperior performance compared to other techniques. Motivated by the obtained\ninsights, we then introduce a straightforward yet highly effective latent\naugmentation method tailored for contrastive SFDA. This augmentation method\nleverages the dispersion of latent features within the neighborhood of the\nquery sample, guided by the source pre-trained model, to enhance the\ninformativeness of positive keys. Our approach, based on a single InfoNCE-based\ncontrastive loss, outperforms state-of-the-art SFDA methods on widely\nrecognized benchmark datasets.\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition",
    "Computer Science/Machine Learning"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "AJXdCPrkju-l7j1j8E2z5-vIeURV_PDIUZt9sMaMUoM",
  "pdfSize": "2229489"
}