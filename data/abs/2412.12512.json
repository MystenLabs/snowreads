{
  "id": "2412.12512",
  "title": "Libri2Vox Dataset: Target Speaker Extraction with Diverse Speaker\n  Conditions and Synthetic Data",
  "authors": "Yun Liu, Xuechen Liu, Xiaoxiao Miao, Junichi Yamagishi",
  "authorsParsed": [
    [
      "Liu",
      "Yun",
      ""
    ],
    [
      "Liu",
      "Xuechen",
      ""
    ],
    [
      "Miao",
      "Xiaoxiao",
      ""
    ],
    [
      "Yamagishi",
      "Junichi",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Tue, 17 Dec 2024 04:06:53 GMT"
    }
  ],
  "updateDate": "2024-12-18",
  "timestamp": 1734408413000,
  "abstract": "  Target speaker extraction (TSE) is essential in speech processing\napplications, particularly in scenarios with complex acoustic environments.\nCurrent TSE systems face challenges in limited data diversity and a lack of\nrobustness in real-world conditions, primarily because they are trained on\nartificially mixed datasets with limited speaker variability and unrealistic\nnoise profiles. To address these challenges, we propose Libri2Vox, a new\ndataset that combines clean target speech from the LibriTTS dataset with\ninterference speech from the noisy VoxCeleb2 dataset, providing a large and\ndiverse set of speakers under realistic noisy conditions. We also augment\nLibri2Vox with synthetic speakers generated using state-of-the-art speech\ngenerative models to enhance speaker diversity. Additionally, to further\nimprove the effectiveness of incorporating synthetic data, curriculum learning\nis implemented to progressively train TSE models with increasing levels of\ndifficulty. Extensive experiments across multiple TSE architectures reveal\nvarying degrees of improvement, with SpeakerBeam demonstrating the most\nsubstantial gains: a 1.39 dB improvement in signal-to-distortion ratio (SDR) on\nthe Libri2Talker test set compared to baseline training. Building upon these\nresults, we further enhanced performance through our speaker similarity-based\ncurriculum learning approach with the Conformer architecture, achieving an\nadditional 0.78 dB improvement over conventional random sampling methods in\nwhich data samples are randomly selected from the entire dataset. These results\ndemonstrate the complementary benefits of diverse real-world data, synthetic\nspeaker augmentation, and structured training strategies in building robust TSE\nsystems.\n",
  "subjects": [
    "Computer Science/Sound",
    "Electrical Engineering and Systems Science/Audio and Speech Processing"
  ],
  "license": "http://creativecommons.org/licenses/by-sa/4.0/",
  "blobId": "oH4Ea2SN3CECYQzCqVBy_wSacnuMJZDph-xOXEVrClg",
  "pdfSize": "585915"
}