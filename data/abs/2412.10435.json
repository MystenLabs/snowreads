{
  "id": "2412.10435",
  "title": "COEF-VQ: Cost-Efficient Video Quality Understanding through a Cascaded\n  Multimodal LLM Framework",
  "authors": "Xin Dong, Sen Jia, Hongyu Xiong",
  "authorsParsed": [
    [
      "Dong",
      "Xin",
      ""
    ],
    [
      "Jia",
      "Sen",
      ""
    ],
    [
      "Xiong",
      "Hongyu",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Wed, 11 Dec 2024 08:10:32 GMT"
    }
  ],
  "updateDate": "2024-12-17",
  "timestamp": 1733904632000,
  "abstract": "  Recently, with the emergence of recent Multimodal Large Language Model (MLLM)\ntechnology, it has become possible to exploit its video understanding\ncapability on different classification tasks. In practice, we face the\ndifficulty of huge requirements for GPU resource if we need to deploy MLLMs\nonline. In this paper, we propose COEF-VQ, a novel cascaded MLLM framework for\nbetter video quality understanding on TikTok. To this end, we first propose a\nMLLM fusing all visual, textual and audio signals, and then develop a cascade\nframework with a lightweight model as pre-filtering stage and MLLM as\nfine-consideration stage, significantly reducing the need for GPU resource,\nwhile retaining the performance demonstrated solely by MLLM. To demonstrate the\neffectiveness of COEF-VQ, we deployed this new framework onto the video\nmanagement platform (VMP) at TikTok, and performed a series of detailed\nexperiments on two in-house tasks related to video quality understanding. We\nshow that COEF-VQ leads to substantial performance gains with limit resource\nconsumption in these two tasks.\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition",
    "Computer Science/Artificial Intelligence"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "ab_zS-KV0elb2JKvIln1jQvxH4BovcCK9ZEziLKdJvo",
  "pdfSize": "722778"
}