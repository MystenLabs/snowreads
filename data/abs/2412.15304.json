{"id":"2412.15304","title":"TinyLLM: A Framework for Training and Deploying Language Models at the\n  Edge Computers","authors":"Savitha Viswanadh Kandala, Pramuka Medaranga and Ambuj Varshney","authorsParsed":[["Kandala","Savitha Viswanadh",""],["Medaranga","Pramuka",""],["Varshney","Ambuj",""]],"versions":[{"version":"v1","created":"Thu, 19 Dec 2024 12:28:27 GMT"}],"updateDate":"2024-12-23","timestamp":1734611307000,"abstract":"  Language models have gained significant interest due to their general-purpose\ncapabilities, which appear to emerge as models are scaled to increasingly\nlarger parameter sizes. However, these large models impose stringent\nrequirements on computing systems, necessitating significant memory and\nprocessing requirements for inference. This makes performing inference on\nmobile and edge devices challenging, often requiring invocating remotely-hosted\nmodels via network calls. Remote inference, in turn, introduces issues like\nlatency, unreliable network connectivity, and privacy concerns. To address\nthese challenges, we explored the possibility of deviating from the trend of\nincreasing model size. Instead, we hypothesize that much smaller models\n(~30-120M parameters) can outperform their larger counterparts for specific\ntasks by carefully curating the data used for pre-training and fine-tuning. We\ninvestigate this within the context of deploying edge-device models to support\nsensing applications. We trained several foundational models through a\nsystematic study and found that small models can run locally on edge devices,\nachieving high token rates and accuracy. Based on these findings, we developed\na framework that allows users to train foundational models tailored to their\nspecific applications and deploy them at the edge.\n","subjects":["Computer Science/Machine Learning","Computer Science/Distributed, Parallel, and Cluster Computing","Computer Science/Emerging Technologies","Computer Science/Networking and Internet Architecture"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"ECTnSVti1yPJWPTKBIdKXahxlCwbh42xH2jU_vGRlAU","pdfSize":"3095085"}