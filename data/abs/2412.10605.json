{
  "id": "2412.10605",
  "title": "Client-Side Patching against Backdoor Attacks in Federated Learning",
  "authors": "Borja Molina-Coronado",
  "authorsParsed": [
    [
      "Molina-Coronado",
      "Borja",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Fri, 13 Dec 2024 23:17:10 GMT"
    },
    {
      "version": "v2",
      "created": "Fri, 20 Dec 2024 09:59:28 GMT"
    }
  ],
  "updateDate": "2024-12-23",
  "timestamp": 1734131830000,
  "abstract": "  Federated learning is a versatile framework for training models in\ndecentralized environments. However, the trust placed in clients makes\nfederated learning vulnerable to backdoor attacks launched by malicious\nparticipants. While many defenses have been proposed, they often fail short\nwhen facing heterogeneous data distributions among participating clients. In\nthis paper, we propose a novel defense mechanism for federated learning systems\ndesigned to mitigate backdoor attacks on the clients-side. Our approach\nleverages adversarial learning techniques and model patching to neutralize the\nimpact of backdoor attacks. Through extensive experiments on the MNIST and\nFashion-MNIST datasets, we demonstrate that our defense effectively reduces\nbackdoor accuracy, outperforming existing state-of-the-art defenses, such as\nLFighter, FLAME, and RoseAgg, in i.i.d. and non-i.i.d. scenarios, while\nmaintaining competitive or superior accuracy on clean data.\n",
  "subjects": [
    "Computer Science/Cryptography and Security",
    "Computer Science/Artificial Intelligence",
    "Computer Science/Machine Learning"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "zlezkTF6_KYt0D3IM4vy4Fu9JfkjwE8Kb0DAwv5PqT8",
  "pdfSize": "199868"
}