{"id":"2407.08351","title":"AutoBencher: Creating Salient, Novel, Difficult Datasets for Language\n  Models","authors":"Xiang Lisa Li, Evan Zheran Liu, Percy Liang, Tatsunori Hashimoto","authorsParsed":[["Li","Xiang Lisa",""],["Liu","Evan Zheran",""],["Liang","Percy",""],["Hashimoto","Tatsunori",""]],"versions":[{"version":"v1","created":"Thu, 11 Jul 2024 10:03:47 GMT"}],"updateDate":"2024-07-12","timestamp":1720692227000,"abstract":"  Evaluation is critical for assessing capabilities, tracking scientific\nprogress, and informing model selection. In this paper, we present three\ndesiderata for a good benchmark for language models: (i) salience (e.g.,\nknowledge about World War II is more salient than a random day in history),\n(ii) novelty (i.e., the benchmark reveals new trends in model rankings not\nshown by previous benchmarks), and (iii) difficulty (i.e., the benchmark should\nbe difficult for existing models, leaving headroom for future improvement). We\noperationalize these three desiderata and cast benchmark creation as a search\nproblem, that of finding benchmarks that that satisfy all three desiderata. To\ntackle this search problem, we present AutoBencher, which uses a language model\nto automatically search for datasets that meet the three desiderata.\nAutoBencher uses privileged information (e.g. relevant documents) to construct\nreliable datasets, and adaptivity with reranking to optimize for the search\nobjective. We use AutoBencher to create datasets for math, multilingual, and\nknowledge-intensive question answering. The scalability of AutoBencher allows\nit to test fine-grained categories and tail knowledge, creating datasets that\nare on average 27% more novel and 22% more difficult than existing benchmarks.\nA closer investigation of our constructed datasets shows that we can identify\nspecific gaps in LM knowledge in language models that are not captured by\nexisting benchmarks, such as Gemini Pro performing much worse on question\nanswering about the Permian Extinction and Fordism, while OpenAGI-7B performing\nsurprisingly well on QA about COVID-19.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"yNhqguI9RhRV7Ebnqw0UV8Wfv8u7H118nqq5o-aK7Rs","pdfSize":"1333320"}