{
  "id": "2412.17305",
  "title": "Exploiting Label Skewness for Spiking Neural Networks in Federated\n  Learning",
  "authors": "Di Yu, Xin Du, Linshan Jiang, Huijing Zhang, Shunwen Bai, Shuiguang\n  Deng",
  "authorsParsed": [
    [
      "Yu",
      "Di",
      ""
    ],
    [
      "Du",
      "Xin",
      ""
    ],
    [
      "Jiang",
      "Linshan",
      ""
    ],
    [
      "Zhang",
      "Huijing",
      ""
    ],
    [
      "Bai",
      "Shunwen",
      ""
    ],
    [
      "Deng",
      "Shuiguang",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Mon, 23 Dec 2024 05:52:32 GMT"
    },
    {
      "version": "v2",
      "created": "Sun, 19 Jan 2025 06:58:01 GMT"
    }
  ],
  "updateDate": "2025-01-22",
  "timestamp": 1734933152000,
  "abstract": "  The energy efficiency of deep spiking neural networks (SNNs) aligns with the\nconstraints of resource-limited edge devices, positioning SNNs as a promising\nfoundation for intelligent applications leveraging the extensive data collected\nby these devices. To address data privacy concerns when deploying SNNs on edge\ndevices, federated learning (FL) facilitates collaborative model training by\nleveraging data distributed across edge devices without transmitting local data\nto a central server. However, existing FL approaches struggle with label-skewed\ndata across devices, which leads to drift in local SNN models and degrades the\nperformance of the global SNN model. In this paper, we propose a novel\nframework called FedLEC, which incorporates intra-client label weight\ncalibration to balance the learning intensity across local labels and\ninter-client knowledge distillation to mitigate local SNN model bias caused by\nlabel absence. Extensive experiments with three different structured SNNs\nacross five datasets (i.e., three non-neuromorphic and two neuromorphic\ndatasets) demonstrate the efficiency of FedLEC. Compared to eight\nstate-of-the-art FL algorithms, FedLEC achieves an average accuracy improvement\nof approximately 11.59% for the global SNN model under various label skew\ndistribution settings.\n",
  "subjects": [
    "Computer Science/Machine Learning",
    "Computer Science/Computer Vision and Pattern Recognition"
  ],
  "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
  "blobId": "68S7iCtoezeUSA76EQe68YFLYxDer7J_PiAxzISrrxg",
  "pdfSize": "992173"
}