{
  "id": "2412.18727",
  "title": "SAFLITE: Fuzzing Autonomous Systems via Large Language Models",
  "authors": "Taohong Zhu, Adrians Skapars, Fardeen Mackenzie, Declan Kehoe, William\n  Newton, Suzanne Embury, Youcheng Sun",
  "authorsParsed": [
    [
      "Zhu",
      "Taohong",
      ""
    ],
    [
      "Skapars",
      "Adrians",
      ""
    ],
    [
      "Mackenzie",
      "Fardeen",
      ""
    ],
    [
      "Kehoe",
      "Declan",
      ""
    ],
    [
      "Newton",
      "William",
      ""
    ],
    [
      "Embury",
      "Suzanne",
      ""
    ],
    [
      "Sun",
      "Youcheng",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Wed, 25 Dec 2024 01:00:05 GMT"
    }
  ],
  "updateDate": "2024-12-30",
  "timestamp": 1735088405000,
  "abstract": "  Fuzz testing effectively uncovers software vulnerabilities; however, it faces\nchallenges with Autonomous Systems (AS) due to their vast search spaces and\ncomplex state spaces, which reflect the unpredictability and complexity of\nreal-world environments. This paper presents a universal framework aimed at\nimproving the efficiency of fuzz testing for AS. At its core is SaFliTe, a\npredictive component that evaluates whether a test case meets predefined safety\ncriteria. By leveraging the large language model (LLM) with information about\nthe test objective and the AS state, SaFliTe assesses the relevance of each\ntest case. We evaluated SaFliTe by instantiating it with various LLMs,\nincluding GPT-3.5, Mistral-7B, and Llama2-7B, and integrating it into four fuzz\ntesting tools: PGFuzz, DeepHyperion-UAV, CAMBA, and TUMB. These tools are\ndesigned specifically for testing autonomous drone control systems, such as\nArduPilot, PX4, and PX4-Avoidance. The experimental results demonstrate that,\ncompared to PGFuzz, SaFliTe increased the likelihood of selecting operations\nthat triggered bug occurrences in each fuzzing iteration by an average of\n93.1\\%. Additionally, after integrating SaFliTe, the ability of\nDeepHyperion-UAV, CAMBA, and TUMB to generate test cases that caused system\nviolations increased by 234.5\\%, 33.3\\%, and 17.8\\%, respectively. The\nbenchmark for this evaluation was sourced from a UAV Testing Competition.\n",
  "subjects": [
    "Computer Science/Software Engineering",
    "Computer Science/Artificial Intelligence",
    "Computer Science/Systems and Control",
    "Electrical Engineering and Systems Science/Systems and Control"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "aunPWHXAG3VNsYRvgnfu1BgzzuncAyHWEWl-qxOdfAk",
  "pdfSize": "631687"
}