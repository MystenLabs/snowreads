{"id":"2412.04867","title":"MANTA: A Large-Scale Multi-View and Visual-Text Anomaly Detection\n  Dataset for Tiny Objects","authors":"Lei Fan, Dongdong Fan, Zhiguang Hu, Yiwen Ding, Donglin Di, Kai Yi,\n  Maurice Pagnucco, Yang Song","authorsParsed":[["Fan","Lei",""],["Fan","Dongdong",""],["Hu","Zhiguang",""],["Ding","Yiwen",""],["Di","Donglin",""],["Yi","Kai",""],["Pagnucco","Maurice",""],["Song","Yang",""]],"versions":[{"version":"v1","created":"Fri, 6 Dec 2024 09:01:10 GMT"}],"updateDate":"2024-12-09","timestamp":1733475670000,"abstract":"  We present MANTA, a visual-text anomaly detection dataset for tiny objects.\nThe visual component comprises over 137.3K images across 38 object categories\nspanning five typical domains, of which 8.6K images are labeled as anomalous\nwith pixel-level annotations. Each image is captured from five distinct\nviewpoints to ensure comprehensive object coverage. The text component consists\nof two subsets: Declarative Knowledge, including 875 words that describe common\nanomalies across various domains and specific categories, with detailed\nexplanations for < what, why, how>, including causes and visual\ncharacteristics; and Constructivist Learning, providing 2K multiple-choice\nquestions with varying levels of difficulty, each paired with images and\ncorresponded answer explanations. We also propose a baseline for visual-text\ntasks and conduct extensive benchmarking experiments to evaluate advanced\nmethods across different settings, highlighting the challenges and efficacy of\nour dataset.\n","subjects":["Computer Science/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"W-GnLqkgxGpKXU0E7w6ttDC2OJ55vVqIpDwOZB3D468","pdfSize":"3442557"}