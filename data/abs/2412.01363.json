{
  "id": "2412.01363",
  "title": "Exploring the Robustness of AI-Driven Tools in Digital Forensics: A\n  Preliminary Study",
  "authors": "Silvia Lucia Sanna, Leonardo Regano, Davide Maiorca, Giorgio Giacinto",
  "authorsParsed": [
    [
      "Sanna",
      "Silvia Lucia",
      ""
    ],
    [
      "Regano",
      "Leonardo",
      ""
    ],
    [
      "Maiorca",
      "Davide",
      ""
    ],
    [
      "Giacinto",
      "Giorgio",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Mon, 2 Dec 2024 10:48:53 GMT"
    }
  ],
  "updateDate": "2024-12-03",
  "timestamp": 1733136533000,
  "abstract": "  Nowadays, many tools are used to facilitate forensic tasks about data\nextraction and data analysis. In particular, some tools leverage Artificial\nIntelligence (AI) to automatically label examined data into specific categories\n(\\ie, drugs, weapons, nudity). However, this raises a serious concern about the\nrobustness of the employed AI algorithms against adversarial attacks. Indeed,\nsome people may need to hide specific data to AI-based digital forensics tools,\nthus manipulating the content so that the AI system does not recognize the\noffensive/prohibited content and marks it at as suspicious to the analyst. This\ncould be seen as an anti-forensics attack scenario. For this reason, we\nanalyzed two of the most important forensics tools employing AI for data\nclassification: Magnet AI, used by Magnet Axiom, and Excire Photo AI, used by\nX-Ways Forensics. We made preliminary tests using about $200$ images, other\n$100$ sent in $3$ chats about pornography and teenage nudity, drugs and weapons\nto understand how the tools label them. Moreover, we loaded some deepfake\nimages (images generated by AI forging real ones) of some actors to understand\nif they would be classified in the same category as the original images. From\nour preliminary study, we saw that the AI algorithm is not robust enough, as we\nexpected since these topics are still open research problems. For example, some\nsexual images were not categorized as nudity, and some deepfakes were\ncategorized as the same real person, while the human eye can see the clear\nnudity image or catch the difference between the deepfakes. Building on these\nresults and other state-of-the-art works, we provide some suggestions for\nimproving how digital forensics analysis tool leverage AI and their robustness\nagainst adversarial attacks or different scenarios than the trained one.\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "lT4UHb3vdZe7OADE7ZRHvcsXTde2-nJrI7kIVwhQ70Y",
  "pdfSize": "33728355"
}