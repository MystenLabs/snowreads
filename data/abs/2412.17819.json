{
  "id": "2412.17819",
  "title": "Inductive Linguistic Reasoning with Large Language Models",
  "authors": "Raghav Ramji, Keshav Ramji",
  "authorsParsed": [
    [
      "Ramji",
      "Raghav",
      ""
    ],
    [
      "Ramji",
      "Keshav",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Mon, 9 Dec 2024 03:37:11 GMT"
    }
  ],
  "updateDate": "2024-12-25",
  "timestamp": 1733715431000,
  "abstract": "  Evaluating large language models (LLMs) on their linguistic reasoning\ncapabilities is an important task to understand the gaps in their skills that\nmay surface during large-scale adoption. In this work, we investigate the\nabilities of such models to perform abstract multilingual reasoning through the\nlens of linguistic puzzles on extremely low-resource languages. As these\ntranslation tasks involve inductive and deductive reasoning from reference\ninstances, we examine whether diverse auxiliary demonstrations can be\nautomatically induced from seed exemplars, through analogical prompting. We\nemploy a two-stage procedure, first generating analogical exemplars with a\nlanguage model, and then applying them in-context along with provided target\nlanguage exemplars. Our results on the modeLing dataset show that analogical\nprompting is effective in eliciting models' knowledge of language grammar\nsimilarities, boosting the performance of GPT-4o by as much as 8.1% and\nLlama-3.1-405B-Instruct by 5.9% over chain-of-thought approaches. These gains\nare attributable to the analogical demonstrations, both when self-generated as\nwell as when produced by weaker multilingual models. Furthermore, we\ndemonstrate that our method generalizes to other tasks present in Linguistics\nOlympiad competitions, achieving sizable improvements across all problem types\nand difficulty levels included in the LINGOLY dataset with GPT-4o. We also\nreport several findings about interesting phenomena which drive linguistic\nreasoning performance, suggesting that such puzzles are a valuable benchmark\nfor new reasoning methods.\n",
  "subjects": [
    "Computer Science/Computation and Language",
    "Computer Science/Artificial Intelligence"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "nkSSCleThFSRu_jyx_1M2LLNEmDgu1WNaKtWt6VWgWE",
  "pdfSize": "7329680"
}