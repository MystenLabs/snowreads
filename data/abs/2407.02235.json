{"id":"2407.02235","title":"Towards a Holistic Framework for Multimodal Large Language Models in\n  Three-dimensional Brain CT Report Generation","authors":"Cheng-Yi Li, Kao-Jung Chang, Cheng-Fu Yang, Hsin-Yu Wu, Wenting Chen,\n  Hritik Bansal, Ling Chen, Yi-Ping Yang, Yu-Chun Chen, Shih-Pin Chen,\n  Jiing-Feng Lirng, Kai-Wei Chang, Shih-Hwa Chiou","authorsParsed":[["Li","Cheng-Yi",""],["Chang","Kao-Jung",""],["Yang","Cheng-Fu",""],["Wu","Hsin-Yu",""],["Chen","Wenting",""],["Bansal","Hritik",""],["Chen","Ling",""],["Yang","Yi-Ping",""],["Chen","Yu-Chun",""],["Chen","Shih-Pin",""],["Lirng","Jiing-Feng",""],["Chang","Kai-Wei",""],["Chiou","Shih-Hwa",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 12:58:35 GMT"}],"updateDate":"2024-07-03","timestamp":1719925115000,"abstract":"  Multi-modal large language models (MLLMs) have been given free rein to\nexplore exciting medical applications with a primary focus on radiology report\ngeneration. Nevertheless, the preliminary success in 2D radiology captioning is\nincompetent to reflect the real-world diagnostic challenge in the volumetric 3D\nanatomy. To mitigate three crucial limitation aspects in the existing\nliterature, including (1) data complexity, (2) model capacity, and (3)\nevaluation metric fidelity, we collected an 18,885 text-scan pairs 3D-BrainCT\ndataset and applied clinical visual instruction tuning (CVIT) to train BrainGPT\nmodels to generate radiology-adherent 3D brain CT reports. Statistically, our\nBrainGPT scored BLEU-1 = 44.35, BLEU-4 = 20.38, METEOR = 30.13, ROUGE-L = 47.6,\nand CIDEr-R = 211.77 during internal testing and demonstrated an accuracy of\n0.91 in captioning midline shifts on the external validation CQ500 dataset. By\nfurther inspecting the captioned report, we reported that the traditional\nmetrics appeared to measure only the surface text similarity and failed to\ngauge the information density of the diagnostic purpose. To close this gap, we\nproposed a novel Feature-Oriented Radiology Task Evaluation (FORTE) to estimate\nthe report's clinical relevance (lesion feature and landmarks). Notably, the\nBrainGPT model scored an average FORTE F1-score of 0.71 (degree=0.661;\nlandmark=0.706; feature=0.693; impression=0.779). To demonstrate that BrainGPT\nmodels possess objective readiness to generate human-like radiology reports, we\nconducted a Turing test that enrolled 11 physician evaluators, and around 74%\nof the BrainGPT-generated captions were indistinguishable from those written by\nhumans. Our work embodies a holistic framework that showcased the first-hand\nexperience of curating a 3D brain CT dataset, fine-tuning anatomy-sensible\nlanguage models, and proposing robust radiology evaluation metrics.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"qXg4W55uog0q_mK7srbrfQF_y2FntnQEMwz1wy-o2Hs","pdfSize":"9795868"}