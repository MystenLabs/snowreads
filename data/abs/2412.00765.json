{"id":"2412.00765","title":"SelfPrompt: Autonomously Evaluating LLM Robustness via\n  Domain-Constrained Knowledge Guidelines and Refined Adversarial Prompts","authors":"Aihua Pei, Zehua Yang, Shunan Zhu, Ruoxi Cheng, Ju Jia","authorsParsed":[["Pei","Aihua",""],["Yang","Zehua",""],["Zhu","Shunan",""],["Cheng","Ruoxi",""],["Jia","Ju",""]],"versions":[{"version":"v1","created":"Sun, 1 Dec 2024 10:58:53 GMT"}],"updateDate":"2024-12-03","timestamp":1733050733000,"abstract":"  Traditional methods for evaluating the robustness of large language models\n(LLMs) often rely on standardized benchmarks, which can escalate costs and\nlimit evaluations across varied domains. This paper introduces a novel\nframework designed to autonomously evaluate the robustness of LLMs by\nincorporating refined adversarial prompts and domain-constrained knowledge\nguidelines in the form of knowledge graphs. Our method systematically generates\ndescriptive sentences from domain-constrained knowledge graph triplets to\nformulate adversarial prompts, enhancing the relevance and challenge of the\nevaluation. These prompts, generated by the LLM itself and tailored to evaluate\nits own robustness, undergo a rigorous filtering and refinement process,\nensuring that only those with high textual fluency and semantic fidelity are\nused. This self-evaluation mechanism allows the LLM to evaluate its robustness\nwithout the need for external benchmarks. We assess the effectiveness of our\nframework through extensive testing on both proprietary models like ChatGPT and\nopen-source models such as Llama-3.1, Phi-3, and Mistral. Results confirm that\nour approach not only reduces dependency on conventional data but also provides\na targeted and efficient means of evaluating LLM robustness in constrained\ndomains.\n","subjects":["Computer Science/Computation and Language","Computer Science/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"Vj0O3BH-4_N6dwQkTjaNNAZG2_mIIVBCbPAF1-vCNZU","pdfSize":"730790"}