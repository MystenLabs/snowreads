{
  "id": "2412.10675",
  "title": "Chasing Progress, Not Perfection: Revisiting Strategies for End-to-End\n  LLM Plan Generation",
  "authors": "Sukai Huang, Trevor Cohn, Nir Lipovetzky",
  "authorsParsed": [
    [
      "Huang",
      "Sukai",
      ""
    ],
    [
      "Cohn",
      "Trevor",
      ""
    ],
    [
      "Lipovetzky",
      "Nir",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Sat, 14 Dec 2024 04:23:14 GMT"
    }
  ],
  "updateDate": "2024-12-17",
  "timestamp": 1734150194000,
  "abstract": "  The capability of Large Language Models (LLMs) to plan remains a topic of\ndebate. Some critics argue that strategies to boost LLMs' reasoning skills are\nineffective in planning tasks, while others report strong outcomes merely from\ntraining models on a planning corpus. This study reassesses recent strategies\nby developing an end-to-end LLM planner and employing diverse metrics for a\nthorough evaluation. We find that merely fine-tuning LLMs on a corpus of\nplanning instances does not lead to robust planning skills, as indicated by\npoor performance on out-of-distribution test sets. At the same time, we find\nthat various strategies, including Chain-of-Thought, do enhance the probability\nof a plan being executable. This indicates progress towards better plan\nquality, despite not directly enhancing the final validity rate. Among the\nstrategies we evaluated, reinforcement learning with our novel `Longest\nContiguous Common Subsequence' reward emerged as the most effective,\ncontributing to both plan validity and executability. Overall, our research\naddresses key misconceptions in the LLM-planning literature; we validate\nincremental progress in plan executability, although plan validity remains a\nchallenge. Hence, future strategies should focus on both these aspects, drawing\ninsights from our findings.\n",
  "subjects": [
    "Computer Science/Computation and Language",
    "Computer Science/Artificial Intelligence"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "sT1-9wSKYqBHLyV1iqAgIqAuGj0q-RTh-mZyLWw9q9w",
  "pdfSize": "1090446"
}