{"id":"2407.06780","title":"CoLA: Conditional Dropout and Language-driven Robust Dual-modal Salient\n  Object Detection","authors":"Shuang Hao, Chunlin Zhong, He Tang","authorsParsed":[["Hao","Shuang",""],["Zhong","Chunlin",""],["Tang","He",""]],"versions":[{"version":"v1","created":"Tue, 9 Jul 2024 11:49:24 GMT"}],"updateDate":"2024-07-10","timestamp":1720525764000,"abstract":"  The depth/thermal information is beneficial for detecting salient object with\nconventional RGB images. However, in dual-modal salient object detection (SOD)\nmodel, the robustness against noisy inputs and modality missing is crucial but\nrarely studied. To tackle this problem, we introduce \\textbf{Co}nditional\nDropout and \\textbf{LA}nguage-driven(\\textbf{CoLA}) framework comprising two\ncore components. 1) Language-driven Quality Assessment (LQA): Leveraging a\npretrained vision-language model with a prompt learner, the LQA recalibrates\nimage contributions without requiring additional quality annotations. This\napproach effectively mitigates the impact of noisy inputs. 2) Conditional\nDropout (CD): A learning method to strengthen the model's adaptability in\nscenarios with missing modalities, while preserving its performance under\ncomplete modalities. The CD serves as a plug-in training scheme that treats\nmodality-missing as conditions, strengthening the overall robustness of various\ndual-modal SOD models. Extensive experiments demonstrate that the proposed\nmethod outperforms state-of-the-art dual-modal SOD models, under both\nmodality-complete and modality-missing conditions. We will release source code\nupon acceptance.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"VJpXuU1hsbMPZonEYTHASS6V2KYRW3z3fSNGvUDqfiw","pdfSize":"1442574"}
