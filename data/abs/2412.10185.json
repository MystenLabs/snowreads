{"id":"2412.10185","title":"Solving Robust Markov Decision Processes: Generic, Reliable, Efficient","authors":"Tobias Meggendorfer, Maximilian Weininger, Patrick Wienh\\\"oft","authorsParsed":[["Meggendorfer","Tobias",""],["Weininger","Maximilian",""],["Wienh√∂ft","Patrick",""]],"versions":[{"version":"v1","created":"Fri, 13 Dec 2024 14:55:48 GMT"}],"updateDate":"2024-12-16","timestamp":1734101748000,"abstract":"  Markov decision processes (MDP) are a well-established model for sequential\ndecision-making in the presence of probabilities. In robust MDP (RMDP), every\naction is associated with an uncertainty set of probability distributions,\nmodelling that transition probabilities are not known precisely. Based on the\nknown theoretical connection to stochastic games, we provide a framework for\nsolving RMDPs that is generic, reliable, and efficient. It is *generic* both\nwith respect to the model, allowing for a wide range of uncertainty sets,\nincluding but not limited to intervals, $L^1$- or $L^2$-balls, and polytopes;\nand with respect to the objective, including long-run average reward,\nundiscounted total reward, and stochastic shortest path. It is *reliable*, as\nour approach not only converges in the limit, but provides precision guarantees\nat any time during the computation. It is *efficient* because -- in contrast to\nstate-of-the-art approaches -- it avoids explicitly constructing the underlying\nstochastic game. Consequently, our prototype implementation outperforms\nexisting tools by several orders of magnitude and can solve RMDPs with a\nmillion states in under a minute.\n","subjects":["Computer Science/Artificial Intelligence","Computer Science/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"fL3b3B38MWDhf_wHYtbcXcfFarB3SQrPbR9hEAyUKJU","pdfSize":"717044"}