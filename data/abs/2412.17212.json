{
  "id": "2412.17212",
  "title": "Trainingless Adaptation of Pretrained Models for Environmental Sound\n  Classification",
  "authors": "Noriyuki Tonami, Wataru Kohno, Keisuke Imoto, Yoshiyuki Yajima, Sakiko\n  Mishima, Reishi Kondo, Tomoyuki Hino",
  "authorsParsed": [
    [
      "Tonami",
      "Noriyuki",
      ""
    ],
    [
      "Kohno",
      "Wataru",
      ""
    ],
    [
      "Imoto",
      "Keisuke",
      ""
    ],
    [
      "Yajima",
      "Yoshiyuki",
      ""
    ],
    [
      "Mishima",
      "Sakiko",
      ""
    ],
    [
      "Kondo",
      "Reishi",
      ""
    ],
    [
      "Hino",
      "Tomoyuki",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Mon, 23 Dec 2024 01:50:28 GMT"
    }
  ],
  "updateDate": "2024-12-24",
  "timestamp": 1734918628000,
  "abstract": "  Deep neural network (DNN)-based models for environmental sound classification\nare not robust against a domain to which training data do not belong, that is,\nout-of-distribution or unseen data. To utilize pretrained models for the unseen\ndomain, adaptation methods, such as finetuning and transfer learning, are used\nwith rich computing resources, e.g., the graphical processing unit (GPU).\nHowever, it is becoming more difficult to keep up with research trends for\nthose who have poor computing resources because state-of-the-art models are\nbecoming computationally resource-intensive. In this paper, we propose a\ntrainingless adaptation method for pretrained models for environmental sound\nclassification. To introduce the trainingless adaptation method, we first\npropose an operation of recovering time--frequency-ish (TF-ish) structures in\nintermediate layers of DNN models. We then propose the trainingless frequency\nfiltering method for domain adaptation, which is not a gradient-based\noptimization widely used. The experiments conducted using the ESC-50 dataset\nshow that the proposed adaptation method improves the classification accuracy\nby 20.40 percentage points compared with the conventional method.\n",
  "subjects": [
    "Computer Science/Sound",
    "Electrical Engineering and Systems Science/Audio and Speech Processing"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "qlYPwj1dr3HQjciT5GMQHSLUrIR101Dj850vlfsKy9w",
  "pdfSize": "606711"
}