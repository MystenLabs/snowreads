{
  "id": "2412.11365",
  "title": "BiM-VFI: directional Motion Field-Guided Frame Interpolation for Video\n  with Non-uniform Motions",
  "authors": "Wonyong Seo, Jihyong Oh, Munchurl Kim",
  "authorsParsed": [
    [
      "Seo",
      "Wonyong",
      ""
    ],
    [
      "Oh",
      "Jihyong",
      ""
    ],
    [
      "Kim",
      "Munchurl",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Mon, 16 Dec 2024 01:37:51 GMT"
    },
    {
      "version": "v2",
      "created": "Sun, 29 Dec 2024 08:11:31 GMT"
    }
  ],
  "updateDate": "2024-12-31",
  "timestamp": 1734313071000,
  "abstract": "  Existing Video Frame interpolation (VFI) models tend to suffer from\ntime-to-location ambiguity when trained with video of non-uniform motions, such\nas accelerating, decelerating, and changing directions, which often yield\nblurred interpolated frames. In this paper, we propose (i) a novel motion\ndescription map, Bidirectional Motion field (BiM), to effectively describe\nnon-uniform motions; (ii) a BiM-guided Flow Net (BiMFN) with Content-Aware\nUpsampling Network (CAUN) for precise optical flow estimation; and (iii)\nKnowledge Distillation for VFI-centric Flow supervision (KDVCF) to supervise\nthe motion estimation of VFI model with VFI-centric teacher flows. The proposed\nVFI is called a Bidirectional Motion field-guided VFI (BiM-VFI) model.\nExtensive experiments show that our BiM-VFI model significantly surpasses the\nrecent state-of-the-art VFI methods by 26% and 45% improvements in LPIPS and\nSTLPIPS respectively, yielding interpolated frames with much fewer blurs at\narbitrary time instances.\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "3G0QjGNFLsTGsFtDAoUhETaJqMb09aY-w3d-7Tgs5jo",
  "pdfSize": "4922404"
}