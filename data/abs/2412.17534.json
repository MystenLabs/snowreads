{"id":"2412.17534","title":"CiteBART: Learning to Generate Citations for Local Citation\n  Recommendation","authors":"Ege Yi\\u{g}it \\c{C}elik and Selma Tekir","authorsParsed":[["Çelik","Ege Yiğit",""],["Tekir","Selma",""]],"versions":[{"version":"v1","created":"Mon, 23 Dec 2024 12:58:30 GMT"}],"updateDate":"2024-12-24","timestamp":1734958710000,"abstract":"  Citations are essential building blocks in scientific writing. The scientific\ncommunity is longing for support in their generation. Citation generation\ninvolves two complementary subtasks: Determining the citation worthiness of a\ncontext and, if it's worth it, proposing the best candidate papers for the\ncitation placeholder. The latter subtask is called local citation\nrecommendation (LCR). This paper proposes CiteBART, a custom BART pre-training\nbased on citation token masking to generate citations to achieve LCR. In the\nbase scheme, we mask the citation token in the local citation context to make\nthe citation prediction. In the global one, we concatenate the citing paper's\ntitle and abstract to the local citation context to learn to reconstruct the\ncitation token. CiteBART outperforms state-of-the-art approaches on the\ncitation recommendation benchmarks except for the smallest FullTextPeerRead\ndataset. The effect is significant in the larger benchmarks, e.g., Refseer and\nArXiv. We present a qualitative analysis and an ablation study to provide\ninsights into the workings of CiteBART. Our analyses confirm that its\ngenerative nature brings about a zero-shot capability.\n","subjects":["Computer Science/Information Retrieval","Computer Science/Artificial Intelligence","Computer Science/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"fiF-MM1aGPRm29OYzN6LRHg9PjrWK3HOWMpXkcLJ_1g","pdfSize":"1866902"}