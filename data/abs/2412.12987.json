{"id":"2412.12987","title":"Stochastic interior-point methods for smooth conic optimization with\n  applications","authors":"Chuan He, Zhanwang Deng","authorsParsed":[["He","Chuan",""],["Deng","Zhanwang",""]],"versions":[{"version":"v1","created":"Tue, 17 Dec 2024 15:06:44 GMT"}],"updateDate":"2024-12-18","timestamp":1734448004000,"abstract":"  Conic optimization plays a crucial role in many machine learning (ML)\nproblems. However, practical algorithms for conic constrained ML problems with\nlarge datasets are often limited to specific use cases, as stochastic\nalgorithms for general conic optimization remain underdeveloped. To fill this\ngap, we introduce a stochastic interior-point method (SIPM) framework for\ngeneral conic optimization, along with four novel SIPM variants leveraging\ndistinct stochastic gradient estimators. Under mild assumptions, we establish\nthe global convergence rates of our proposed SIPMs, which, up to a logarithmic\nfactor, match the best-known rates in stochastic unconstrained optimization.\nFinally, our numerical experiments on robust linear regression, multi-task\nrelationship learning, and clustering data streams demonstrate the\neffectiveness and efficiency of our approach.\n","subjects":["Mathematics/Optimization and Control","Computer Science/Artificial Intelligence","Computer Science/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"JW7HyDEKFNPQjwJPFeaveGLAMuy026Ocm09g_AYacTI","pdfSize":"1763863"}