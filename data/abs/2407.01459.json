{"id":"2407.01459","title":"On Implications of Scaling Laws on Feature Superposition","authors":"Pavan Katta","authorsParsed":[["Katta","Pavan",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 16:54:07 GMT"}],"updateDate":"2024-07-02","timestamp":1719852847000,"abstract":"  Using results from scaling laws, this theoretical note argues that the\nfollowing two statements cannot be simultaneously true: 1. Superposition\nhypothesis where sparse features are linearly represented across a layer is a\ncomplete theory of feature representation. 2. Features are universal, meaning\ntwo models trained on the same data and achieving equal performance will learn\nidentical features.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"xz5dBklvzcoqlVqndEFLrhWArIZjAzMFHrZKQb7rLv0","pdfSize":"217399"}