{"id":"2412.19707","title":"Toward Adaptive Reasoning in Large Language Models with Thought Rollback","authors":"Sijia Chen, Baochun Li","authorsParsed":[["Chen","Sijia",""],["Li","Baochun",""]],"versions":[{"version":"v1","created":"Fri, 27 Dec 2024 16:02:34 GMT"}],"updateDate":"2024-12-30","timestamp":1735315354000,"abstract":"  Large language models (LLMs) have been routinely used to solve various tasks\nusing step-by-step reasoning. However, the structure of intermediate reasoning\nsteps, or thoughts, is rigid and unidirectional, such as chains, trees, or\nacyclic-directed graphs. Consequently, the resulting inflexible and\nforward-only reasoning may not address challenging tasks and fail when the LLM\nfrequently gives false responses, i.e., ``hallucinations''. This paper proposes\na new reasoning framework, called Thought Rollback (TR), allowing LLMs to\nadaptively build thought structure while maintaining effective reasoning toward\nproblem-solving under ``hallucinations''. The core mechanism of TR is rolling\nback thoughts, which allows LLMs to perform error analysis on thoughts, and\nthus roll back to any previously mistaken thought for revision. Subsequently,\nby including such trial-and-error in the prompt to guide the LLM, each rollback\nleads to one more reliable reasoning path. Therefore, starting with a simple\nprompt without human annotations, LLM with TR adaptively and gradually explores\nthoughts for a correct solution. Comprehensive experiments on mathematical\nproblems and multi-task reasoning demonstrate the state-of-the-art performance\nof TR in terms of problem-solving rate and interaction cost. For instance, the\nsolving rate of GPT-4 with TR outperforms the current best by $9\\%$ on the MATH\ndataset.\n","subjects":["Computer Science/Artificial Intelligence","Computer Science/Computation and Language","Computer Science/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"GcMj3ClAM-UrLn-TA9wPmuw--I_dXS7vzgQxua6C4Ng","pdfSize":"2364968"}