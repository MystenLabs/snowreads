{"id":"2407.21047","title":"PAV: Personalized Head Avatar from Unstructured Video Collection","authors":"Akin Caliskan, Berkay Kicanaoglu, Hyeongwoo Kim","authorsParsed":[["Caliskan","Akin",""],["Kicanaoglu","Berkay",""],["Kim","Hyeongwoo",""]],"versions":[{"version":"v1","created":"Mon, 22 Jul 2024 23:34:46 GMT"}],"updateDate":"2024-08-01","timestamp":1721691286000,"abstract":"  We propose PAV, Personalized Head Avatar for the synthesis of human faces\nunder arbitrary viewpoints and facial expressions. PAV introduces a method that\nlearns a dynamic deformable neural radiance field (NeRF), in particular from a\ncollection of monocular talking face videos of the same character under various\nappearance and shape changes. Unlike existing head NeRF methods that are\nlimited to modeling such input videos on a per-appearance basis, our method\nallows for learning multi-appearance NeRFs, introducing appearance embedding\nfor each input video via learnable latent neural features attached to the\nunderlying geometry. Furthermore, the proposed appearance-conditioned density\nformulation facilitates the shape variation of the character, such as facial\nhair and soft tissues, in the radiance field prediction. To the best of our\nknowledge, our approach is the first dynamic deformable NeRF framework to model\nappearance and shape variations in a single unified network for\nmulti-appearances of the same subject. We demonstrate experimentally that PAV\noutperforms the baseline method in terms of visual rendering quality in our\nquantitative and qualitative studies on various subjects.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"wkKuYuNv2Qb5dd8I5KVaoXV_C3UL-2OMESGTUnMbnx4","pdfSize":"10222183","objectId":"0xa1204850d64cc37a68df762dfb387f681bc013bb9e10cd2ed7ed351339fad7d4","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
