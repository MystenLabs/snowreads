{"id":"2407.14993","title":"Lower Bounds for Nonparametric Estimation of Ordinary Differential\n  Equations","authors":"Christof Sch\\\"otz, Maximilian Siebel","authorsParsed":[["Sch√∂tz","Christof",""],["Siebel","Maximilian",""]],"versions":[{"version":"v1","created":"Sat, 20 Jul 2024 21:59:06 GMT"}],"updateDate":"2024-07-23","timestamp":1721512746000,"abstract":"  We noisily observe solutions of an ordinary differential equation $\\dot u =\nf(u)$ at given times, where $u$ lives in a $d$-dimensional state space. The\nmodel function $f$ is unknown and belongs to a H\\\"older-type smoothness class\nwith parameter $\\beta$. For the nonparametric problem of estimating $f$, we\nprovide lower bounds on the error in two complementary model specifications:\nthe snake model with few, long observed solutions and the stubble model with\nmany short ones. The lower bounds are minimax optimal in some settings. They\ndepend on various parameters, which in the optimal asymptotic regime leads to\nthe same rate for the squared error in both models: it is characterized by the\nexponent $-2\\beta/(2(\\beta+1)+d)$ for the total number of observations $n$. To\nderive these results, we establish a master theorem for lower bounds in general\nnonparametric regression problems, which makes the proofs more comparable and\nseems to be a useful tool for future use.\n","subjects":["Mathematics/Statistics Theory","Statistics/Statistics Theory"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"ZG-McJxC5N4u1hKvovUb8puEsPS430cSCiaqN6zlPxI","pdfSize":"12775971"}