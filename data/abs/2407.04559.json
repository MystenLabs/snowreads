{"id":"2407.04559","title":"Not (yet) the whole story: Evaluating Visual Storytelling Requires More\n  than Measuring Coherence, Grounding, and Repetition","authors":"Aditya K Surikuchi, Raquel Fern\\'andez, Sandro Pezzelle","authorsParsed":[["Surikuchi","Aditya K",""],["Fern√°ndez","Raquel",""],["Pezzelle","Sandro",""]],"versions":[{"version":"v1","created":"Fri, 5 Jul 2024 14:48:15 GMT"},{"version":"v2","created":"Thu, 29 Aug 2024 15:58:09 GMT"}],"updateDate":"2024-08-30","timestamp":1720190895000,"abstract":"  Visual storytelling consists in generating a natural language story given a\ntemporally ordered sequence of images. This task is not only challenging for\nmodels, but also very difficult to evaluate with automatic metrics since there\nis no consensus about what makes a story 'good'. In this paper, we introduce a\nnovel method that measures story quality in terms of human likeness regarding\nthree key aspects highlighted in previous work: visual grounding, coherence,\nand repetitiveness. We then use this method to evaluate the stories generated\nby several models, showing that the foundation model LLaVA obtains the best\nresult, but only slightly so compared to TAPM, a 50-times smaller visual\nstorytelling model. Upgrading the visual and language components of TAPM\nresults in a model that yields competitive performance with a relatively low\nnumber of parameters. Finally, we carry out a human evaluation study, whose\nresults suggest that a 'good' story may require more than a human-like level of\nvisual grounding, coherence, and repetition.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"kpLqKyeOfwZ02VuQHkva7xgZoTmyU2PpH8Q-KDVvyTE","pdfSize":"1281490"}
