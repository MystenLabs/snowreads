{"id":"2412.01212","title":"First numerical observation of the Berezinskii-Kosterlitz-Thouless\n  transition in language models","authors":"Yuma Toji, Jun Takahashi, Vwani Roychowdhury, and Hideyuki Miyahara","authorsParsed":[["Toji","Yuma",""],["Takahashi","Jun",""],["Roychowdhury","Vwani",""],["Miyahara","Hideyuki",""]],"versions":[{"version":"v1","created":"Mon, 2 Dec 2024 07:32:32 GMT"}],"updateDate":"2024-12-03","timestamp":1733124752000,"abstract":"  Several power-law critical properties involving different statistics in\nnatural languages -- reminiscent of scaling properties of physical systems at\nor near phase transitions -- have been documented for decades.\n  The recent rise of large language models (LLMs) has added further evidence\nand excitement by providing intriguing similarities with notions in physics\nsuch as scaling laws and emergent abilities.\n  However, specific instances of classes of generative language models that\nexhibit phase transitions, as understood by the statistical physics community,\nare lacking.\n  In this work, inspired by the one-dimensional Potts model in statistical\nphysics we construct a simple probabilistic language model that falls under the\nclass of context sensitive grammars (CSG), and numerically demonstrate an\nunambiguous phase transition in the framework of a natural language model.\n  We explicitly show that a precisely defined order parameter -- that captures\nsymbol frequency biases in the sentences generated by the language model --\nchanges from strictly 0 to a strictly nonzero value (in the infinite-length\nlimit of sentences), implying a mathematical singularity arising when tuning\nthe parameter of the stochastic language model we consider.\n  Furthermore, we identify the phase transition as a variant of the\nBerezinskii-Kosterlitz-Thouless (BKT) transition, which is known to exhibit\ncritical properties not only at the transition point but also in the entire\nphase.\n  This finding leads to the possibility that critical properties in natural\nlanguages may not require careful fine-tuning nor self-organized criticality,\nbut is generically explained by the underlying connection between language\nstructures and the BKT phases.\n","subjects":["Statistics/Machine Learning","Condensed Matter/Statistical Mechanics","Computer Science/Computation and Language","Computer Science/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"Zcnedz9agBGDq9PJi1IWbE4AaXovJJoNot9VLPWqOqY","pdfSize":"12634636"}