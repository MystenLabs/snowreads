{
  "id": "2412.00539",
  "title": "TextClass Benchmark: A Continuous Elo Rating of LLMs in Social Sciences",
  "authors": "Basti\\'an Gonz\\'alez-Bustamante",
  "authorsParsed": [
    [
      "González-Bustamante",
      "Bastián",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Sat, 30 Nov 2024 17:09:49 GMT"
    },
    {
      "version": "v2",
      "created": "Sat, 7 Dec 2024 00:00:28 GMT"
    }
  ],
  "updateDate": "2024-12-10",
  "timestamp": 1732986589000,
  "abstract": "  The TextClass Benchmark project is an ongoing, continuous benchmarking\nprocess that aims to provide a comprehensive, fair, and dynamic evaluation of\nLLMs and transformers for text classification tasks. This evaluation spans\nvarious domains and languages in social sciences disciplines engaged in NLP and\ntext-as-data approach. The leaderboards present performance metrics and\nrelative ranking using a tailored Elo rating system. With each leaderboard\ncycle, novel models are added, fixed test sets can be replaced for unseen,\nequivalent data to test generalisation power, ratings are updated, and a\nMeta-Elo leaderboard combines and weights domain-specific leaderboards. This\narticle presents the rationale and motivation behind the project, explains the\nElo rating system in detail, and estimates Meta-Elo across different\nclassification tasks in social science disciplines. We also present a snapshot\nof the first cycle of classification tasks on incivility data in Chinese,\nEnglish, German and Russian. This ongoing benchmarking process includes not\nonly additional languages such as Arabic, Hindi, and Spanish but also a\nclassification of policy agenda topics, misinformation, among others.\n",
  "subjects": [
    "Computer Science/Computation and Language",
    "Computer Science/Artificial Intelligence"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "2OqoIq3j3SfFkszzIR_HiugbQfifuZ84-cqjX1YOWJs",
  "pdfSize": "1073594"
}