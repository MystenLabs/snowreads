{
  "id": "2412.02830",
  "title": "RARE: Retrieval-Augmented Reasoning Enhancement for Large Language\n  Models",
  "authors": "Hieu Tran, Zonghai Yao, Junda Wang, Yifan Zhang, Zhichao Yang, Hong Yu",
  "authorsParsed": [
    [
      "Tran",
      "Hieu",
      ""
    ],
    [
      "Yao",
      "Zonghai",
      ""
    ],
    [
      "Wang",
      "Junda",
      ""
    ],
    [
      "Zhang",
      "Yifan",
      ""
    ],
    [
      "Yang",
      "Zhichao",
      ""
    ],
    [
      "Yu",
      "Hong",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Tue, 3 Dec 2024 20:52:35 GMT"
    },
    {
      "version": "v2",
      "created": "Thu, 5 Dec 2024 14:51:35 GMT"
    },
    {
      "version": "v3",
      "created": "Mon, 9 Dec 2024 16:26:09 GMT"
    }
  ],
  "updateDate": "2024-12-10",
  "timestamp": 1733259155000,
  "abstract": "  This work introduces RARE (Retrieval-Augmented Reasoning Enhancement), a\nversatile extension to the mutual reasoning framework (rStar), aimed at\nenhancing reasoning accuracy and factual integrity across large language models\n(LLMs) for complex, knowledge-intensive tasks such as commonsense and medical\nreasoning. RARE incorporates two innovative actions within the Monte Carlo Tree\nSearch (MCTS) framework: A6, which generates search queries based on the\ninitial problem statement, performs information retrieval using those queries,\nand augments reasoning with the retrieved data to formulate the final answer;\nand A7, which leverages information retrieval specifically for generated\nsub-questions and re-answers these sub-questions with the relevant contextual\ninformation. Additionally, a Retrieval-Augmented Factuality Scorer is proposed\nto replace the original discriminator, prioritizing reasoning paths that meet\nhigh standards of factuality. Experimental results with LLaMA 3.1 show that\nRARE enables open-source LLMs to achieve competitive performance with top\nopen-source models like GPT-4 and GPT-4o. This research establishes RARE as a\nscalable solution for improving LLMs in domains where logical coherence and\nfactual integrity are critical.\n",
  "subjects": [
    "Computer Science/Computation and Language"
  ],
  "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
  "blobId": "j_hePW_S5LhR3EoU4kTcyYJrhv3kRyyZpXRvfIzmoZ0",
  "pdfSize": "616849"
}