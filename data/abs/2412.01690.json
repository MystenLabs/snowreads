{
  "id": "2412.01690",
  "title": "Can We Afford The Perfect Prompt? Balancing Cost and Accuracy with the\n  Economical Prompting Index",
  "authors": "Tyler McDonald, Anthony Colosimo, Yifeng Li, and Ali Emami",
  "authorsParsed": [
    [
      "McDonald",
      "Tyler",
      ""
    ],
    [
      "Colosimo",
      "Anthony",
      ""
    ],
    [
      "Li",
      "Yifeng",
      ""
    ],
    [
      "Emami",
      "Ali",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Mon, 2 Dec 2024 16:34:18 GMT"
    }
  ],
  "updateDate": "2024-12-03",
  "timestamp": 1733157258000,
  "abstract": "  As prompt engineering research rapidly evolves, evaluations beyond accuracy\nare crucial for developing cost-effective techniques. We present the Economical\nPrompting Index (EPI), a novel metric that combines accuracy scores with token\nconsumption, adjusted by a user-specified cost concern level to reflect\ndifferent resource constraints. Our study examines 6 advanced prompting\ntechniques, including Chain-of-Thought, Self-Consistency, and Tree of Thoughts,\nacross 10 widely-used language models and 4 diverse datasets. We demonstrate\nthat approaches such as Self-Consistency often provide statistically\ninsignificant gains while becoming cost-prohibitive. For example, on\nhigh-performing models like Claude 3.5 Sonnet, the EPI of simpler techniques\nlike Chain-of-Thought (0.72) surpasses more complex methods like\nSelf-Consistency (0.64) at slight cost concern levels. Our findings suggest a\nreevaluation of complex prompting strategies in resource-constrained scenarios,\npotentially reshaping future research priorities and improving\ncost-effectiveness for end-users.\n",
  "subjects": [
    "Computer Science/Computation and Language"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "txMl1KbbioFMAJYogA0BavDnESdphkPRVbh10Frb9KQ",
  "pdfSize": "1155142"
}