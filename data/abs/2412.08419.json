{"id":"2412.08419","title":"Robustness of Graph Classification: failure modes, causes, and\n  noise-resistant loss in Graph Neural Networks","authors":"Farooq Ahmad Wani, Maria Sofia Bucarelli, Andrea Giuseppe Di\n  Francesco, Oleksandr Pryymak, Fabrizio Silvestri","authorsParsed":[["Wani","Farooq Ahmad",""],["Bucarelli","Maria Sofia",""],["Di Francesco","Andrea Giuseppe",""],["Pryymak","Oleksandr",""],["Silvestri","Fabrizio",""]],"versions":[{"version":"v1","created":"Wed, 11 Dec 2024 14:35:37 GMT"}],"updateDate":"2024-12-12","timestamp":1733927737000,"abstract":"  Graph Neural Networks (GNNs) are powerful at solving graph classification\ntasks, yet applied problems often contain noisy labels. In this work, we study\nGNN robustness to label noise, demonstrate GNN failure modes when models\nstruggle to generalise on low-order graphs, low label coverage, or when a model\nis over-parameterized. We establish both empirical and theoretical links\nbetween GNN robustness and the reduction of the total Dirichlet Energy of\nlearned node representations, which encapsulates the hypothesized GNN\nsmoothness inductive bias. Finally, we introduce two training strategies to\nenhance GNN robustness: (1) by incorporating a novel inductive bias in the\nweight matrices through the removal of negative eigenvalues, connected to\nDirichlet Energy minimization; (2) by extending to GNNs a loss penalty that\npromotes learned smoothness. Importantly, neither approach negatively impacts\nperformance in noise-free settings, supporting our hypothesis that the source\nof GNNs robustness is their smoothness inductive bias.\n","subjects":["Computer Science/Machine Learning"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"EMnvK9sx2iHZkBchD9GlhJHBEXA9rulr-eBZVH48U3g","pdfSize":"1287357"}