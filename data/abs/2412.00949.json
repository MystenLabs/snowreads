{"id":"2412.00949","title":"STEVE-Audio: Expanding the Goal Conditioning Modalities of Embodied\n  Agents in Minecraft","authors":"Nicholas Lenzen, Amogh Raut, Andrew Melnik","authorsParsed":[["Lenzen","Nicholas",""],["Raut","Amogh",""],["Melnik","Andrew",""]],"versions":[{"version":"v1","created":"Sun, 1 Dec 2024 19:48:57 GMT"}],"updateDate":"2024-12-03","timestamp":1733082537000,"abstract":"  Recently, the STEVE-1 approach has been introduced as a method for training\ngenerative agents to follow instructions in the form of latent CLIP embeddings.\nIn this work, we present a methodology to extend the control modalities by\nlearning a mapping from new input modalities to the latent goal space of the\nagent. We apply our approach to the challenging Minecraft domain, and extend\nthe goal conditioning to include the audio modality. The resulting\naudio-conditioned agent is able to perform on a comparable level to the\noriginal text-conditioned and visual-conditioned agents. Specifically, we\ncreate an Audio-Video CLIP foundation model for Minecraft and an audio prior\nnetwork which together map audio samples to the latent goal space of the\nSTEVE-1 policy. Additionally, we highlight the tradeoffs that occur when\nconditioning on different modalities. Our training code, evaluation code, and\nAudio-Video CLIP foundation model for Minecraft are made open-source to help\nfoster further research into multi-modal generalist sequential decision-making\nagents.\n","subjects":["Computer Science/Machine Learning","Computer Science/Artificial Intelligence","Computer Science/Robotics"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"i_mYj0ZiTY2ZZTVmnMfxP7wuAYYL5aDD4K43FtRLacc","pdfSize":"1604402"}