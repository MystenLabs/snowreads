{"id":"2412.08948","title":"Mojito: Motion Trajectory and Intensity Control for Video Generation","authors":"Xuehai He, Shuohang Wang, Jianwei Yang, Xiaoxia Wu, Yiping Wang, Kuan\n  Wang, Zheng Zhan, Olatunji Ruwase, Yelong Shen, Xin Eric Wang","authorsParsed":[["He","Xuehai",""],["Wang","Shuohang",""],["Yang","Jianwei",""],["Wu","Xiaoxia",""],["Wang","Yiping",""],["Wang","Kuan",""],["Zhan","Zheng",""],["Ruwase","Olatunji",""],["Shen","Yelong",""],["Wang","Xin Eric",""]],"versions":[{"version":"v1","created":"Thu, 12 Dec 2024 05:26:43 GMT"},{"version":"v2","created":"Wed, 5 Feb 2025 08:06:37 GMT"}],"updateDate":"2025-02-06","timestamp":1733981203000,"abstract":"  Recent advancements in diffusion models have shown great promise in producing\nhigh-quality video content. However, efficiently training video diffusion\nmodels capable of integrating directional guidance and controllable motion\nintensity remains a challenging and under-explored area. To tackle these\nchallenges, this paper introduces Mojito, a diffusion model that incorporates\nboth motion trajectory and intensity control for text-to-video generation.\nSpecifically, Mojito features a Directional Motion Control (DMC) module that\nleverages cross-attention to efficiently direct the generated object's motion\nwithout training, alongside a Motion Intensity Modulator (MIM) that uses\noptical flow maps generated from videos to guide varying levels of motion\nintensity. Extensive experiments demonstrate Mojito's effectiveness in\nachieving precise trajectory and intensity control with high computational\nefficiency, generating motion patterns that closely match specified directions\nand intensities, providing realistic dynamics that align well with natural\nmotion in real-world scenarios.\n","subjects":["Computer Science/Computer Vision and Pattern Recognition","Computer Science/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"hwTFTeIqYJZnxp5PM8cgbn6A0ORaxXOVqSVIhkVZAOk","pdfSize":"41316824"}