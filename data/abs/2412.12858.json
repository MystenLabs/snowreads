{"id":"2412.12858","title":"Efficient Speech Command Recognition Leveraging Spiking Neural Network\n  and Curriculum Learning-based Knowledge Distillation","authors":"Jiaqi Wang, Liutao Yu, Liwei Huang, Chenlin Zhou, Han Zhang, Zhenxi\n  Song, Min Zhang, Zhengyu Ma, Zhiguo Zhang","authorsParsed":[["Wang","Jiaqi",""],["Yu","Liutao",""],["Huang","Liwei",""],["Zhou","Chenlin",""],["Zhang","Han",""],["Song","Zhenxi",""],["Zhang","Min",""],["Ma","Zhengyu",""],["Zhang","Zhiguo",""]],"versions":[{"version":"v1","created":"Tue, 17 Dec 2024 12:38:45 GMT"}],"updateDate":"2024-12-18","timestamp":1734439125000,"abstract":"  The intrinsic dynamics and event-driven nature of spiking neural networks\n(SNNs) make them excel in processing temporal information by naturally\nutilizing embedded time sequences as time steps. Recent studies adopting this\napproach have demonstrated SNNs' effectiveness in speech command recognition,\nachieving high performance by employing large time steps for long time\nsequences. However, the large time steps lead to increased deployment burdens\nfor edge computing applications. Thus, it is important to balance high\nperformance and low energy consumption when detecting temporal patterns in edge\ndevices. Our solution comprises two key components. 1). We propose a\nhigh-performance fully spike-driven framework termed SpikeSCR, characterized by\na global-local hybrid structure for efficient representation learning, which\nexhibits long-term learning capabilities with extended time steps. 2). To\nfurther fully embrace low energy consumption, we propose an effective knowledge\ndistillation method based on curriculum learning (KDCL), where valuable\nrepresentations learned from the easy curriculum are progressively transferred\nto the hard curriculum with minor loss, striking a trade-off between power\nefficiency and high performance. We evaluate our method on three benchmark\ndatasets: the Spiking Heidelberg Dataset (SHD), the Spiking Speech Commands\n(SSC), and the Google Speech Commands (GSC) V2. Our experimental results\ndemonstrate that SpikeSCR outperforms current state-of-the-art (SOTA) methods\nacross these three datasets with the same time steps. Furthermore, by executing\nKDCL, we reduce the number of time steps by 60% and decrease energy consumption\nby 54.8% while maintaining comparable performance to recent SOTA results.\nTherefore, this work offers valuable insights for tackling temporal processing\nchallenges with long time sequences in edge neuromorphic computing systems.\n","subjects":["Computer Science/Machine Learning","Computer Science/Artificial Intelligence","Computer Science/Human-Computer Interaction"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"05igxMgAMNgQ7dPVKat5uKt2sLQtczLB30nxfj-YJfg","pdfSize":"1038659"}