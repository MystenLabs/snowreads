{"id":"2407.02004","title":"SAVE: Segment Audio-Visual Easy way using Segment Anything Model","authors":"Khanh-Binh Nguyen and Chae Jung Park","authorsParsed":[["Nguyen","Khanh-Binh",""],["Park","Chae Jung",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 07:22:28 GMT"},{"version":"v2","created":"Wed, 3 Jul 2024 23:49:36 GMT"}],"updateDate":"2024-07-08","timestamp":1719904948000,"abstract":"  The primary aim of Audio-Visual Segmentation (AVS) is to precisely identify\nand locate auditory elements within visual scenes by accurately predicting\nsegmentation masks at the pixel level. Achieving this involves comprehensively\nconsidering data and model aspects to address this task effectively. This study\npresents a lightweight approach, SAVE, which efficiently adapts the pre-trained\nsegment anything model (SAM) to the AVS task. By incorporating an image encoder\nadapter into the transformer blocks to better capture the distinct dataset\ninformation and proposing a residual audio encoder adapter to encode the audio\nfeatures as a sparse prompt, our proposed model achieves effective audio-visual\nfusion and interaction during the encoding stage. Our proposed method\naccelerates the training and inference speed by reducing the input resolution\nfrom 1024 to 256 pixels while achieving higher performance compared with the\nprevious SOTA. Extensive experimentation validates our approach, demonstrating\nthat our proposed model outperforms other SOTA methods significantly. Moreover,\nleveraging the pre-trained model on synthetic data enhances performance on real\nAVSBench data, achieving 84.59 mIoU on the S4 (V1S) subset and 70.28 mIoU on\nthe MS3 (V1M) set with only 256 pixels for input images. This increases up to\n86.16 mIoU on the S4 (V1S) and 70.83 mIoU on the MS3 (V1M) with inputs of 1024\npixels.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Sound","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"CjWtVNgupn4qPojmUUrn-4ZXL5ZTnogKgfE4PZNGYcg","pdfSize":"1822174"}