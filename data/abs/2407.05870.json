{"id":"2407.05870","title":"Cervical Auscultation Machine Learning for Dysphagia Assessment","authors":"An An Chia, Stacy Lum, Michelle Boo, Rex Tan, Balamurali B T, Jer-Ming\n  Chen","authorsParsed":[["Chia","An An",""],["Lum","Stacy",""],["Boo","Michelle",""],["Tan","Rex",""],["T","Balamurali B",""],["Chen","Jer-Ming",""]],"versions":[{"version":"v1","created":"Mon, 8 Jul 2024 12:31:49 GMT"}],"updateDate":"2024-07-09","timestamp":1720441909000,"abstract":"  This study evaluates the use of machine learning, specifically the Random\nForest Classifier, to differentiate normal and pathological swallowing sounds.\nEmploying a commercially available wearable stethoscope, we recorded swallows\nfrom both healthy adults and patients with dysphagia. The analysis revealed\nstatistically significant differences in acoustic features, such as spectral\ncrest, and zero-crossing rate between normal and pathological swallows, while\nno discriminating differences were demonstrated between different fluidand diet\nconsistencies. The system demonstrated fair sensitivity (mean plus or minus SD:\n74% plus or minus 8%) and specificity (89% plus or minus 6%) for dysphagic\nswallows. The model attained an overall accuracy of 83% plus or minus 3%, and\nF1 score of 78% plus or minus 5%. These results demonstrate that machine\nlearning can be a valuable tool in non-invasive dysphagia assessment, although\nchallenges such as sampling rate limitations and variability in sensitivity and\nspecificity in discriminating between normal and pathological sounds are noted.\nThe study underscores the need for further research to optimize these\ntechniques for clinical use.\n","subjects":["Computing Research Repository/Sound","Computing Research Repository/Human-Computer Interaction","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"1IzYmtRUJPrG2s7JpViPPtM7xb79Urz-mFLSJZDFOx0","pdfSize":"539157"}