{"id":"2412.13801","title":"A Comprehensive Evaluation of Parameter-Efficient Fine-Tuning on\n  Method-Level Code Smell Detection","authors":"Beiqi Zhang, Peng Liang, Xin Zhou, Xiyu Zhou, David Lo, Qiong Feng,\n  Zengyang Li, Lin Li","authorsParsed":[["Zhang","Beiqi",""],["Liang","Peng",""],["Zhou","Xin",""],["Zhou","Xiyu",""],["Lo","David",""],["Feng","Qiong",""],["Li","Zengyang",""],["Li","Lin",""]],"versions":[{"version":"v1","created":"Wed, 18 Dec 2024 12:48:36 GMT"}],"updateDate":"2024-12-19","timestamp":1734526116000,"abstract":"  Code smells are suboptimal coding practices that negatively impact the\nquality of software systems. Existing detection methods, relying on heuristics\nor Machine Learning (ML) and Deep Learning (DL) techniques, often face\nlimitations such as unsatisfactory performance. Parameter-Efficient Fine-Tuning\n(PEFT) methods have emerged as a resource-efficient approach for adapting LLMs\nto specific tasks, but their effectiveness for method-level code smell\ndetection remains underexplored. In this regard, this study evaluates\nstate-of-the-art PEFT methods on both small and large Language Models (LMs) for\ndetecting two types of method-level code smells: Complex Conditional and\nComplex Method. Using high-quality datasets sourced from GitHub, we fine-tuned\nfour small LMs and six LLMs with PEFT techniques, including prompt tuning,\nprefix tuning, LoRA, and (IA)3. Results show that PEFT methods achieve\ncomparable or better performance than full fine-tuning while consuming less GPU\nmemory. Notably, LLMs did not outperform small LMs, suggesting smaller models'\nsuitability for this task. Additionally, increasing training dataset size\nsignificantly boosted performance, while increasing trainable parameters did\nnot. Our findings highlight PEFT methods as effective and scalable solutions,\noutperforming existing heuristic-based and DL-based detectors.\n","subjects":["Computer Science/Software Engineering"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"RAfXR2SQoWHb7lSA3t4FmKOib_I-nykJajLVJt_G9Ro","pdfSize":"1872885"}