{"id":"2407.07174","title":"CamFreeDiff: Camera-free Image to Panorama Generation with Diffusion\n  Model","authors":"Xiaoding Yuan, Shitao Tang, Kejie Li, Alan Yuille, Peng Wang","authorsParsed":[["Yuan","Xiaoding",""],["Tang","Shitao",""],["Li","Kejie",""],["Yuille","Alan",""],["Wang","Peng",""]],"versions":[{"version":"v1","created":"Tue, 9 Jul 2024 18:41:12 GMT"}],"updateDate":"2024-07-11","timestamp":1720550472000,"abstract":"  This paper introduces Camera-free Diffusion (CamFreeDiff) model for\n360-degree image outpainting from a single camera-free image and text\ndescription. This method distinguishes itself from existing strategies, such as\nMVDiffusion, by eliminating the requirement for predefined camera poses.\nInstead, our model incorporates a mechanism for predicting homography directly\nwithin the multi-view diffusion framework. The core of our approach is to\nformulate camera estimation by predicting the homography transformation from\nthe input view to a predefined canonical view. The homography provides\npoint-level correspondences between the input image and targeting panoramic\nimages, allowing connections enforced by correspondence-aware attention in a\nfully differentiable manner. Qualitative and quantitative experimental results\ndemonstrate our model's strong robustness and generalization ability for\n360-degree image outpainting in the challenging context of camera-free inputs.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"eUSWyZyFDLj5NyXY_26xnBbLGdbwigfYlNK0iMcJSYE","pdfSize":"11823641"}