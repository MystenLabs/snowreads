{"id":"2407.05921","title":"TAPVid-3D: A Benchmark for Tracking Any Point in 3D","authors":"Skanda Koppula, Ignacio Rocco, Yi Yang, Joe Heyward, Jo\\~ao Carreira,\n  Andrew Zisserman, Gabriel Brostow, Carl Doersch","authorsParsed":[["Koppula","Skanda",""],["Rocco","Ignacio",""],["Yang","Yi",""],["Heyward","Joe",""],["Carreira","Jo√£o",""],["Zisserman","Andrew",""],["Brostow","Gabriel",""],["Doersch","Carl",""]],"versions":[{"version":"v1","created":"Mon, 8 Jul 2024 13:28:47 GMT"},{"version":"v2","created":"Tue, 27 Aug 2024 17:14:16 GMT"}],"updateDate":"2024-08-28","timestamp":1720445327000,"abstract":"  We introduce a new benchmark, TAPVid-3D, for evaluating the task of\nlong-range Tracking Any Point in 3D (TAP-3D). While point tracking in two\ndimensions (TAP) has many benchmarks measuring performance on real-world\nvideos, such as TAPVid-DAVIS, three-dimensional point tracking has none. To\nthis end, leveraging existing footage, we build a new benchmark for 3D point\ntracking featuring 4,000+ real-world videos, composed of three different data\nsources spanning a variety of object types, motion patterns, and indoor and\noutdoor environments. To measure performance on the TAP-3D task, we formulate a\ncollection of metrics that extend the Jaccard-based metric used in TAP to\nhandle the complexities of ambiguous depth scales across models, occlusions,\nand multi-track spatio-temporal smoothness. We manually verify a large sample\nof trajectories to ensure correct video annotations, and assess the current\nstate of the TAP-3D task by constructing competitive baselines using existing\ntracking models. We anticipate this benchmark will serve as a guidepost to\nimprove our ability to understand precise 3D motion and surface deformation\nfrom monocular video. Code for dataset download, generation, and model\nevaluation is available at https://tapvid3d.github.io\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"Iy3BIXYDobSuM-HMmLGCocvPUBWr7ULl-i3H71BNLQQ","pdfSize":"22169698"}
