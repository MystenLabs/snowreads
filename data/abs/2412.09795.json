{"id":"2412.09795","title":"Is it the model or the metric -- On robustness measures of deeplearning\n  models","authors":"Zhijin Lyu, Yutong Jin, Sneha Das","authorsParsed":[["Lyu","Zhijin",""],["Jin","Yutong",""],["Das","Sneha",""]],"versions":[{"version":"v1","created":"Fri, 13 Dec 2024 02:26:58 GMT"}],"updateDate":"2024-12-16","timestamp":1734056818000,"abstract":"  Determining the robustness of deep learning models is an established and\nongoing challenge within automated decision-making systems. With the advent and\nsuccess of techniques that enable advanced deep learning (DL), these models are\nbeing used in widespread applications, including high-stake ones like\nhealthcare, education, border-control. Therefore, it is critical to understand\nthe limitations of these models and predict their regions of failures, in order\nto create the necessary guardrails for their successful and safe deployment. In\nthis work, we revisit robustness, specifically investigating the sufficiency of\nrobust accuracy (RA), within the context of deepfake detection. We present\nrobust ratio (RR) as a complementary metric, that can quantify the changes to\nthe normalized or probability outcomes under input perturbation. We present a\ncomparison of RA and RR and demonstrate that despite similar RA between models,\nthe models show varying RR under different tolerance (perturbation) levels.\n","subjects":["Computer Science/Machine Learning","Computer Science/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"fPE8hc9SJ4sbfQwww0WH_MKZcIwQYUavnjGwRyleaVc","pdfSize":"523640"}