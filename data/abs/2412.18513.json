{"id":"2412.18513","title":"FedGIG: Graph Inversion from Gradient in Federated Learning","authors":"Tianzhe Xiao, Yichen Li, Yining Qi, Haozhao Wang, Ruixuan Li","authorsParsed":[["Xiao","Tianzhe",""],["Li","Yichen",""],["Qi","Yining",""],["Wang","Haozhao",""],["Li","Ruixuan",""]],"versions":[{"version":"v1","created":"Tue, 24 Dec 2024 15:52:21 GMT"}],"updateDate":"2024-12-25","timestamp":1735055541000,"abstract":"  Recent studies have shown that Federated learning (FL) is vulnerable to\nGradient Inversion Attacks (GIA), which can recover private training data from\nshared gradients. However, existing methods are designed for dense, continuous\ndata such as images or vectorized texts, and cannot be directly applied to\nsparse and discrete graph data. This paper first explores GIA's impact on\nFederated Graph Learning (FGL) and introduces Graph Inversion from Gradient in\nFederated Learning (FedGIG), a novel GIA method specifically designed for\ngraph-structured data. FedGIG includes the adjacency matrix constraining\nmodule, which ensures the sparsity and discreteness of the reconstructed graph\ndata, and the subgraph reconstruction module, which is designed to complete\nmissing common subgraph structures. Extensive experiments on molecular datasets\ndemonstrate FedGIG's superior accuracy over existing GIA techniques.\n","subjects":["Computer Science/Machine Learning","Computer Science/Cryptography and Security"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"P8j-9n9_bALOdy6UMnFDni7UO0J0KIxOEA6cm6hp6C8","pdfSize":"1417635"}