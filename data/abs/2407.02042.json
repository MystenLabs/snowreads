{"id":"2407.02042","title":"Fake News Detection and Manipulation Reasoning via Large Vision-Language\n  Models","authors":"Ruihan Jin, Ruibo Fu, Zhengqi Wen, Shuai Zhang, Yukun Liu, Jianhua Tao","authorsParsed":[["Jin","Ruihan",""],["Fu","Ruibo",""],["Wen","Zhengqi",""],["Zhang","Shuai",""],["Liu","Yukun",""],["Tao","Jianhua",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 08:16:43 GMT"}],"updateDate":"2024-07-03","timestamp":1719908203000,"abstract":"  Fake news becomes a growing threat to information security and public opinion\nwith the rapid sprawl of media manipulation. Therefore, fake news detection\nattracts widespread attention from academic community. Traditional fake news\ndetection models demonstrate remarkable performance on authenticity binary\nclassification but their ability to reason detailed faked traces based on the\nnews content remains under-explored. Furthermore, due to the lack of external\nknowledge, the performance of existing methods on fact-related news is\nquestionable, leaving their practical implementation unclear. In this paper, we\npropose a new multi-media research topic, namely manipulation reasoning.\nManipulation reasoning aims to reason manipulations based on news content. To\nsupport the research, we introduce a benchmark for fake news detection and\nmanipulation reasoning, referred to as Human-centric and Fact-related Fake News\n(HFFN). The benchmark highlights the centrality of human and the high factual\nrelevance, with detailed manual annotations. HFFN encompasses four realistic\ndomains with fake news samples generated through three manipulation approaches.\nMoreover, a Multi-modal news Detection and Reasoning langUage Model (M-DRUM) is\npresented not only to judge on the authenticity of multi-modal news, but also\nraise analytical reasoning about potential manipulations. On the feature\nextraction level, a cross-attention mechanism is employed to extract\nfine-grained fusion features from multi-modal inputs. On the reasoning level, a\nlarge vision-language model (LVLM) serves as the backbone to facilitate\nfact-related reasoning. A two-stage training framework is deployed to better\nactivate the capacity of identification and reasoning. Comprehensive\nexperiments demonstrate that our model outperforms state-of-the-art (SOTA) fake\nnews detection models and powerful LVLMs like GPT-4 and LLaVA.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"7ycUTMPT6_qo5cRH2p8GQrIqOj2OgwEKSM6V-JQ9Y-I","pdfSize":"6118750"}