{"id":"2407.07636","title":"MoVEInt: Mixture of Variational Experts for Learning Human-Robot\n  Interactions from Demonstrations","authors":"Vignesh Prasad, Alap Kshirsagar, Dorothea Koert, Ruth Stock-Homburg,\n  Jan Peters, Georgia Chalvatzaki","authorsParsed":[["Prasad","Vignesh",""],["Kshirsagar","Alap",""],["Koert","Dorothea",""],["Stock-Homburg","Ruth",""],["Peters","Jan",""],["Chalvatzaki","Georgia",""]],"versions":[{"version":"v1","created":"Wed, 10 Jul 2024 13:16:12 GMT"}],"updateDate":"2024-07-11","timestamp":1720617372000,"abstract":"  Shared dynamics models are important for capturing the complexity and\nvariability inherent in Human-Robot Interaction (HRI). Therefore, learning such\nshared dynamics models can enhance coordination and adaptability to enable\nsuccessful reactive interactions with a human partner. In this work, we propose\na novel approach for learning a shared latent space representation for HRIs\nfrom demonstrations in a Mixture of Experts fashion for reactively generating\nrobot actions from human observations. We train a Variational Autoencoder (VAE)\nto learn robot motions regularized using an informative latent space prior that\ncaptures the multimodality of the human observations via a Mixture Density\nNetwork (MDN). We show how our formulation derives from a Gaussian Mixture\nRegression formulation that is typically used approaches for learning HRI from\ndemonstrations such as using an HMM/GMM for learning a joint distribution over\nthe actions of the human and the robot. We further incorporate an additional\nregularization to prevent \"mode collapse\", a common phenomenon when using\nlatent space mixture models with VAEs. We find that our approach of using an\ninformative MDN prior from human observations for a VAE generates more accurate\nrobot motions compared to previous HMM-based or recurrent approaches of\nlearning shared latent representations, which we validate on various HRI\ndatasets involving interactions such as handshakes, fistbumps, waving, and\nhandovers. Further experiments in a real-world human-to-robot handover scenario\nshow the efficacy of our approach for generating successful interactions with\nfour different human interaction partners.\n","subjects":["Computing Research Repository/Robotics","Computing Research Repository/Human-Computer Interaction","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"R7XiDe4CRJlYSMhEGx0DcSy9CZgx0LqM1mnAa0R9q0Y","pdfSize":"3548472"}