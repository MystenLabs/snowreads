{"id":"2407.04947","title":"FreeCompose: Generic Zero-Shot Image Composition with Diffusion Prior","authors":"Zhekai Chen, Wen Wang, Zhen Yang, Zeqing Yuan, Hao Chen, Chunhua Shen","authorsParsed":[["Chen","Zhekai",""],["Wang","Wen",""],["Yang","Zhen",""],["Yuan","Zeqing",""],["Chen","Hao",""],["Shen","Chunhua",""]],"versions":[{"version":"v1","created":"Sat, 6 Jul 2024 03:35:43 GMT"}],"updateDate":"2024-07-09","timestamp":1720236943000,"abstract":"  We offer a novel approach to image composition, which integrates multiple\ninput images into a single, coherent image. Rather than concentrating on\nspecific use cases such as appearance editing (image harmonization) or semantic\nediting (semantic image composition), we showcase the potential of utilizing\nthe powerful generative prior inherent in large-scale pre-trained diffusion\nmodels to accomplish generic image composition applicable to both scenarios. We\nobserve that the pre-trained diffusion models automatically identify simple\ncopy-paste boundary areas as low-density regions during denoising. Building on\nthis insight, we propose to optimize the composed image towards high-density\nregions guided by the diffusion prior. In addition, we introduce a novel\nmaskguided loss to further enable flexible semantic image composition.\nExtensive experiments validate the superiority of our approach in achieving\ngeneric zero-shot image composition. Additionally, our approach shows promising\npotential in various tasks, such as object removal and multiconcept\ncustomization.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"4P_b356dnqc0NHSGuUteLXywxmxZzfp0PGImEuE8PmE","pdfSize":"17560791"}