{"id":"2407.10694","title":"Features Reconstruction Disentanglement Cloth-Changing Person\n  Re-Identification","authors":"Zhihao Chen, Yiyuan Ge, Qing Yue","authorsParsed":[["Chen","Zhihao",""],["Ge","Yiyuan",""],["Yue","Qing",""]],"versions":[{"version":"v1","created":"Mon, 15 Jul 2024 13:08:42 GMT"}],"updateDate":"2024-07-16","timestamp":1721048922000,"abstract":"  Cloth-changing person re-identification (CC-ReID) aims to retrieve specific\npedestrians in a cloth-changing scenario. Its main challenge is to disentangle\nthe clothing-related and clothing-unrelated features. Most existing approaches\nforce the model to learn clothing-unrelated features by changing the color of\nthe clothes. However, due to the lack of ground truth, these methods inevitably\nintroduce noise, which destroys the discriminative features and leads to an\nuncontrollable disentanglement process. In this paper, we propose a new person\nre-identification network called features reconstruction disentanglement ReID\n(FRD-ReID), which can controllably decouple the clothing-unrelated and\nclothing-related features. Specifically, we first introduce the human parsing\nmask as the ground truth of the reconstruction process. At the same time, we\npropose the far away attention (FAA) mechanism and the person contour attention\n(PCA) mechanism for clothing-unrelated features and pedestrian contour features\nto improve the feature reconstruction efficiency. In the testing phase, we\ndirectly discard the clothing-related features for inference,which leads to a\ncontrollable disentanglement process. We conducted extensive experiments on the\nPRCC, LTCC, and Vc-Clothes datasets and demonstrated that our method\noutperforms existing state-of-the-art methods.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"5507Tn-mVHgjU9ONOa5bRF3RTAzWEOjOKqPXkqXtfRo","pdfSize":"11861944"}