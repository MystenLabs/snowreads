{
  "id": "2412.16783",
  "title": "SubData: A Python Library to Collect and Combine Datasets for Evaluating\n  LLM Alignment on Downstream Tasks",
  "authors": "Leon Fr\\\"ohling, Pietro Bernardelle, Gianluca Demartini",
  "authorsParsed": [
    [
      "Fr√∂hling",
      "Leon",
      ""
    ],
    [
      "Bernardelle",
      "Pietro",
      ""
    ],
    [
      "Demartini",
      "Gianluca",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Sat, 21 Dec 2024 21:40:31 GMT"
    }
  ],
  "updateDate": "2024-12-24",
  "timestamp": 1734817231000,
  "abstract": "  With the release of ever more capable large language models (LLMs),\nresearchers in NLP and related disciplines have started to explore the\nusability of LLMs for a wide variety of different annotation tasks. Very\nrecently, a lot of this attention has shifted to tasks that are subjective in\nnature. Given that the latest generations of LLMs have digested and encoded\nextensive knowledge about different human subpopulations and individuals, the\nhope is that these models can be trained, tuned or prompted to align with a\nwide range of different human perspectives. While researchers already evaluate\nthe success of this alignment via surveys and tests, there is a lack of\nresources to evaluate the alignment on what oftentimes matters the most in NLP;\nthe actual downstream tasks. To fill this gap we present SubData, a Python\nlibrary that offers researchers working on topics related to subjectivity in\nannotation tasks a convenient way of collecting, combining and using a range of\nsuitable datasets.\n",
  "subjects": [
    "Computer Science/Computation and Language"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "_DfNQK_v6TkNSVLrDde32L_yiFN_lArtEPx6Zufo4fU",
  "pdfSize": "861157"
}