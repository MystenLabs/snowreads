{"id":"2407.02409","title":"Effective Context Selection in LLM-based Leaderboard Generation: An\n  Empirical Study","authors":"Salomon Kabongo, Jennifer D'Souza, S\\\"oren Auer","authorsParsed":[["Kabongo","Salomon",""],["D'Souza","Jennifer",""],["Auer","SÃ¶ren",""]],"versions":[{"version":"v1","created":"Thu, 6 Jun 2024 06:05:39 GMT"}],"updateDate":"2024-07-03","timestamp":1717653939000,"abstract":"  This paper explores the impact of context selection on the efficiency of\nLarge Language Models (LLMs) in generating Artificial Intelligence (AI)\nresearch leaderboards, a task defined as the extraction of (Task, Dataset,\nMetric, Score) quadruples from scholarly articles. By framing this challenge as\na text generation objective and employing instruction finetuning with the\nFLAN-T5 collection, we introduce a novel method that surpasses traditional\nNatural Language Inference (NLI) approaches in adapting to new developments\nwithout a predefined taxonomy. Through experimentation with three distinct\ncontext types of varying selectivity and length, our study demonstrates the\nimportance of effective context selection in enhancing LLM accuracy and\nreducing hallucinations, providing a new pathway for the reliable and efficient\ngeneration of AI leaderboards. This contribution not only advances the state of\nthe art in leaderboard generation but also sheds light on strategies to\nmitigate common challenges in LLM-based information extraction.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"8voOXitTIRfJccu8eUhbu5Df1ZO_N62vGSs1vAHHRPQ","pdfSize":"578876"}