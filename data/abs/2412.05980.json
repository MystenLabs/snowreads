{"id":"2412.05980","title":"Anti-Reference: Universal and Immediate Defense Against Reference-Based\n  Generation","authors":"Yiren Song, Shengtao Lou, Xiaokang Liu, Hai Ci, Pei Yang, Jiaming Liu,\n  Mike Zheng Shou","authorsParsed":[["Song","Yiren",""],["Lou","Shengtao",""],["Liu","Xiaokang",""],["Ci","Hai",""],["Yang","Pei",""],["Liu","Jiaming",""],["Shou","Mike Zheng",""]],"versions":[{"version":"v1","created":"Sun, 8 Dec 2024 16:04:45 GMT"}],"updateDate":"2024-12-10","timestamp":1733673885000,"abstract":"  Diffusion models have revolutionized generative modeling with their\nexceptional ability to produce high-fidelity images. However, misuse of such\npotent tools can lead to the creation of fake news or disturbing content\ntargeting individuals, resulting in significant social harm. In this paper, we\nintroduce Anti-Reference, a novel method that protects images from the threats\nposed by reference-based generation techniques by adding imperceptible\nadversarial noise to the images. We propose a unified loss function that\nenables joint attacks on fine-tuning-based customization methods,\nnon-fine-tuning customization methods, and human-centric driving methods. Based\non this loss, we train a Adversarial Noise Encoder to predict the noise or\ndirectly optimize the noise using the PGD method. Our method shows certain\ntransfer attack capabilities, effectively challenging both gray-box models and\nsome commercial APIs. Extensive experiments validate the performance of\nAnti-Reference, establishing a new benchmark in image security.\n","subjects":["Computer Science/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"kT6n3Udo6M3h0TtPhz8UUltKdxbHOlVRtMcoLg9GZfA","pdfSize":"21958504"}