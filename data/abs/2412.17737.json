{"id":"2412.17737","title":"Contextual Feedback Loops: Amplifying Deep Reasoning with Iterative\n  Top-Down Feedback","authors":"Jacob Fein-Ashley, Rajgopal Kannan, Viktor Prasanna","authorsParsed":[["Fein-Ashley","Jacob",""],["Kannan","Rajgopal",""],["Prasanna","Viktor",""]],"versions":[{"version":"v1","created":"Mon, 23 Dec 2024 17:36:51 GMT"},{"version":"v2","created":"Tue, 24 Dec 2024 15:24:32 GMT"},{"version":"v3","created":"Sat, 28 Dec 2024 14:00:45 GMT"},{"version":"v4","created":"Sun, 19 Jan 2025 17:15:27 GMT"},{"version":"v5","created":"Mon, 27 Jan 2025 17:14:45 GMT"}],"updateDate":"2025-01-28","timestamp":1734975411000,"abstract":"  Conventional deep networks rely on one-way backpropagation that overlooks\nreconciling high-level predictions with lower-level representations. We propose\n\\emph{Contextual Feedback Loops} (CFLs), a lightweight mechanism that\nre-injects top-down context into earlier layers for iterative refinement.\nConcretely, CFLs map the network's prediction to a compact \\emph{context\nvector}, which is fused back into each layer via gating adapters. Unrolled over\nmultiple feedback steps, CFLs unify feed-forward and feedback-driven inference,\nletting top-level outputs continually refine lower-level features. Despite\nminimal overhead, CFLs yield consistent gains on tasks including CIFAR-10,\nImageNet-1k, SpeechCommands, and GLUE SST-2. Moreover, by a Banach Fixed Point\nargument under mild Lipschitz conditions, these updates converge stably.\nOverall, CFLs show that even modest top-down feedback can substantially improve\ndeep models, aligning with cognitive theories of iterative perception.\n","subjects":["Computer Science/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"_EfF2SchhRXnGZxK3KMon7ftZhOjznWXbJ5_iTcsMQs","pdfSize":"1623995"}