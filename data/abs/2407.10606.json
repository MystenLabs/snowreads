{"id":"2407.10606","title":"Visual-tactile manipulation to collect household waste in outdoor","authors":"Julio Casta\\~no-Amor\\'os, Ignacio de Loyola P\\'aez-Ubieta, Pablo Gil\n  and Santiago Timoteo Puente","authorsParsed":[["Castaño-Amorós","Julio",""],["Páez-Ubieta","Ignacio de Loyola",""],["Gil","Pablo",""],["Puente","Santiago Timoteo",""]],"versions":[{"version":"v1","created":"Mon, 15 Jul 2024 10:31:57 GMT"}],"updateDate":"2024-07-16","timestamp":1721039517000,"abstract":"  This work presents a perception system applied to robotic manipulation, that\nis able to assist in navigation, household waste classification and collection\nin outdoor environments. This system is made up of optical tactile sensors,\nRGBD cameras and a LiDAR. These sensors are integrated on a mobile platform\nwith a robot manipulator and a robotic gripper. Our system is divided in three\nsoftware modules, two of them are vision-based and the last one is\ntactile-based. The vision-based modules use CNNs to localize and recognize\nsolid household waste, together with the grasping points estimation. The\ntactile-based module, which also uses CNNs and image processing, adjusts the\ngripper opening to control the grasping from touch data. Our proposal achieves\nlocalization errors around 6 %, a recognition accuracy of 98% and ensures the\ngrasping stability the 91% of the attempts. The sum of runtimes of the three\nmodules is less than 750 ms.\n","subjects":["Computing Research Repository/Robotics"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"jqZabvDbyf2d1fEqKxf8W4LvOlfmub9E-pbAmHhgsxU","pdfSize":"30770048"}