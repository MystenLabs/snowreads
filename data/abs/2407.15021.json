{"id":"2407.15021","title":"Enhancing Incremental Summarization with Structured Representations","authors":"EunJeong Hwang, Yichao Zhou, James Bradley Wendt, Beliz Gunel, Nguyen\n  Vo, Jing Xie, Sandeep Tata","authorsParsed":[["Hwang","EunJeong",""],["Zhou","Yichao",""],["Wendt","James Bradley",""],["Gunel","Beliz",""],["Vo","Nguyen",""],["Xie","Jing",""],["Tata","Sandeep",""]],"versions":[{"version":"v1","created":"Sun, 21 Jul 2024 00:23:33 GMT"}],"updateDate":"2024-07-23","timestamp":1721521413000,"abstract":"  Large language models (LLMs) often struggle with processing extensive input\ncontexts, which can lead to redundant, inaccurate, or incoherent summaries.\nRecent methods have used unstructured memory to incrementally process these\ncontexts, but they still suffer from information overload due to the volume of\nunstructured data handled. In our study, we introduce structured knowledge\nrepresentations ($GU_{json}$), which significantly improve summarization\nperformance by 40% and 14% across two public datasets. Most notably, we propose\nthe Chain-of-Key strategy ($CoK_{json}$) that dynamically updates or augments\nthese representations with new information, rather than recreating the\nstructured memory for each new source. This method further enhances performance\nby 7% and 4% on the datasets.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"0MDaUaOTCeegOsEq7pOmwU9-8wrJSSKSgzjEMe2FdAg","pdfSize":"588037"}