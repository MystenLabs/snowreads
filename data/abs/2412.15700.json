{
  "id": "2412.15700",
  "title": "AIR: Unifying Individual and Collective Exploration in Cooperative\n  Multi-Agent Reinforcement Learning",
  "authors": "Guangchong Zhou, Zeren Zhang, Guoliang Fan",
  "authorsParsed": [
    [
      "Zhou",
      "Guangchong",
      ""
    ],
    [
      "Zhang",
      "Zeren",
      ""
    ],
    [
      "Fan",
      "Guoliang",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Fri, 20 Dec 2024 09:18:30 GMT"
    },
    {
      "version": "v2",
      "created": "Mon, 30 Dec 2024 09:00:55 GMT"
    }
  ],
  "updateDate": "2024-12-31",
  "timestamp": 1734686310000,
  "abstract": "  Exploration in cooperative multi-agent reinforcement learning (MARL) remains\nchallenging for value-based agents due to the absence of an explicit policy.\nExisting approaches include individual exploration based on uncertainty towards\nthe system and collective exploration through behavioral diversity among\nagents. However, the introduction of additional structures often leads to\nreduced training efficiency and infeasible integration of these methods. In\nthis paper, we propose Adaptive exploration via Identity Recognition~(AIR),\nwhich consists of two adversarial components: a classifier that recognizes\nagent identities from their trajectories, and an action selector that\nadaptively adjusts the mode and degree of exploration. We theoretically prove\nthat AIR can facilitate both individual and collective exploration during\ntraining, and experiments also demonstrate the efficiency and effectiveness of\nAIR across various tasks.\n",
  "subjects": [
    "Computer Science/Artificial Intelligence",
    "Computer Science/Machine Learning",
    "Computer Science/Multiagent Systems"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "vgUtZv_wmiMDZvwPHrERB3rBMUmxSodmlZeTyXUvnu8",
  "pdfSize": "1967362"
}