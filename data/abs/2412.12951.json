{"id":"2412.12951","title":"FineGates: LLMs Finetuning with Compression using Stochastic Gates","authors":"Jonathan Svirsky, Yehonathan Refael, Ofir Lindenbaum","authorsParsed":[["Svirsky","Jonathan",""],["Refael","Yehonathan",""],["Lindenbaum","Ofir",""]],"versions":[{"version":"v1","created":"Tue, 17 Dec 2024 14:33:05 GMT"}],"updateDate":"2024-12-18","timestamp":1734445985000,"abstract":"  Large Language Models (LLMs), with billions of parameters, present\nsignificant challenges for full finetuning due to the high computational\ndemands, memory requirements, and impracticality of many real-world\napplications. When faced with limited computational resources or small\ndatasets, updating all model parameters can often result in overfitting. To\naddress this, lightweight finetuning techniques have been proposed, like\nlearning low-rank adapter layers. These methods aim to train only a few\nadditional parameters combined with the base model, which remains frozen,\nreducing resource usage and mitigating overfitting risks. In this work, we\npropose an adaptor model based on stochastic gates that simultaneously sparsify\nthe frozen base model with task-specific adaptation. Our method comes with a\nsmall number of trainable parameters and allows us to speed up the base model\ninference with competitive accuracy. We evaluate it in additional variants by\nequipping it with additional low-rank parameters and comparing it to several\nrecent baselines. Our results show that the proposed method improves the\nfinetuned model accuracy comparatively to the several baselines and allows the\nremoval of up to 20-40\\% without significant accuracy loss.\n","subjects":["Computer Science/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"uhd03h7wbCpYId2XL3BhUfrm-4O2M4Idbx_hCTatAac","pdfSize":"717445"}