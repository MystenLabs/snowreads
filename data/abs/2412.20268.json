{"id":"2412.20268","title":"Evaluation of Bfloat16, Posit, and Takum Arithmetics in Sparse Linear\n  Solvers","authors":"Laslo Hunhold, James Quinlan","authorsParsed":[["Hunhold","Laslo",""],["Quinlan","James",""]],"versions":[{"version":"v1","created":"Sat, 28 Dec 2024 20:49:46 GMT"}],"updateDate":"2024-12-31","timestamp":1735418986000,"abstract":"  Solving sparse linear systems lies at the core of numerous computational\napplications. Consequently, understanding the performance of recently proposed\nalternatives to the established IEEE 754 floating-point numbers, such as\nbfloat16 and the tapered-precision posit and takum machine number formats, is\nof significant interest. This paper examines these formats in the context of\nwidely used solvers, namely LU, QR, and GMRES, with incomplete LU\npreconditioning and mixed precision iterative refinement (MPIR). This contrasts\nwith the prevailing emphasis on designing specialized algorithms tailored to\nnew arithmetic formats.\n  This paper presents an extensive and unprecedented evaluation based on the\nSuiteSparse Matrix Collection -- a dataset of real-world matrices with diverse\nsizes and condition numbers. A key contribution is the faithful reproduction of\nSuiteSparse's UMFPACK multifrontal LU factorization and SPQR multifrontal QR\nfactorization for machine number formats beyond single and double-precision\nIEEE 754. Tapered-precision posit and takum formats show better accuracy in\ndirect solvers and reduced iteration counts in indirect solvers. Takum\narithmetic, in particular, exhibits exceptional stability, even at low\nprecision.\n","subjects":["Mathematics/Numerical Analysis","Computer Science/Numerical Analysis"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"Ueph_zkT5utRp5NpfM2qvN2WtJKxA5j1XP4gVwNsuuI","pdfSize":"213914"}