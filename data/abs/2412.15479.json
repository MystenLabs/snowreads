{"id":"2412.15479","title":"Continual Learning Using Only Large Language Model Prompting","authors":"Jiabao Qiu, Zixuan Ke, Bing Liu","authorsParsed":[["Qiu","Jiabao",""],["Ke","Zixuan",""],["Liu","Bing",""]],"versions":[{"version":"v1","created":"Fri, 20 Dec 2024 01:21:57 GMT"}],"updateDate":"2024-12-23","timestamp":1734657717000,"abstract":"  We introduce CLOB, a novel continual learning (CL) paradigm wherein a large\nlanguage model (LLM) is regarded as a black box. Learning is done incrementally\nvia only verbal prompting. CLOB does not fine-tune any part of the LLM or add\nany trainable parameters to it. It is particularly suitable for LLMs that are\naccessible via APIs. We also propose a new CL technique, called CIS, based on\nincremental summarization that also overcomes the LLM's input length limit.\nExperiments show CIS outperforms baselines by a very large margin.\n","subjects":["Computer Science/Computation and Language","Computer Science/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"8AxGrfTgxUelpJB-WYmoV-RcDOI4Xv_LMkyRt5tu8lI","pdfSize":"576012"}