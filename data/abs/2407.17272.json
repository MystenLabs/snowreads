{"id":"2407.17272","title":"DenseTrack: Drone-based Crowd Tracking via Density-aware\n  Motion-appearance Synergy","authors":"Yi Lei, Huilin Zhu, Jingling Yuan, Guangli Xiang, Xian Zhong,\n  Shengfeng He","authorsParsed":[["Lei","Yi",""],["Zhu","Huilin",""],["Yuan","Jingling",""],["Xiang","Guangli",""],["Zhong","Xian",""],["He","Shengfeng",""]],"versions":[{"version":"v1","created":"Wed, 24 Jul 2024 13:39:07 GMT"},{"version":"v2","created":"Fri, 26 Jul 2024 07:40:47 GMT"}],"updateDate":"2024-07-29","timestamp":1721828347000,"abstract":"  Drone-based crowd tracking faces difficulties in accurately identifying and\nmonitoring objects from an aerial perspective, largely due to their small size\nand close proximity to each other, which complicates both localization and\ntracking. To address these challenges, we present the Density-aware Tracking\n(DenseTrack) framework. DenseTrack capitalizes on crowd counting to precisely\ndetermine object locations, blending visual and motion cues to improve the\ntracking of small-scale objects. It specifically addresses the problem of\ncross-frame motion to enhance tracking accuracy and dependability. DenseTrack\nemploys crowd density estimates as anchors for exact object localization within\nvideo frames. These estimates are merged with motion and position information\nfrom the tracking network, with motion offsets serving as key tracking cues.\nMoreover, DenseTrack enhances the ability to distinguish small-scale objects\nusing insights from the visual-language model, integrating appearance with\nmotion cues. The framework utilizes the Hungarian algorithm to ensure the\naccurate matching of individuals across frames. Demonstrated on DroneCrowd\ndataset, our approach exhibits superior performance, confirming its\neffectiveness in scenarios captured by drones.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"FXTACwdsEDeuuZL9_6lw8lbtRlKyArvvNTWFIdxHQuQ","pdfSize":"3810863"}