{"id":"2407.02092","title":"Algorithm-independent bounds on complex optimization through the\n  statistics of marginal optima","authors":"Jaron Kent-Dobias","authorsParsed":[["Kent-Dobias","Jaron",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 09:28:11 GMT"},{"version":"v2","created":"Wed, 24 Jul 2024 14:14:51 GMT"}],"updateDate":"2024-07-25","timestamp":1719912491000,"abstract":"  Optimization seeks extremal points in a function. When there are\nsuperextensively many optima, optimization algorithms are liable to get stuck.\nUnder these conditions, generic algorithms tend to find marginal optima, which\nhave many nearly flat directions. In a companion paper, we introduce a\ntechnique to count marginal optima in random landscapes. Here, we use the\nstatistics of marginal optima calculated using this technique to produce\ngeneric bounds on optimization, based on the simple principle that algorithms\nwill overwhelmingly tend to get stuck only where marginal optima are found. We\ndemonstrate the idea on a simple non-Gaussian problem of maximizing the sum of\nsquared random functions on a compact space. Numeric experiments using both\ngradient descent and generalized approximate message passing algorithms fall\ninside the expected bounds.\n","subjects":["Condensed Matter/Disordered Systems and Neural Networks","Condensed Matter/Statistical Mechanics"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"kxE9zh9yzhws04psZ2q7eocoufjXwzyaqacTEtEOFC4","pdfSize":"398325"}