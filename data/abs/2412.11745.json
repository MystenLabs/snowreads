{"id":"2412.11745","title":"Beyond Dataset Creation: Critical View of Annotation Variation and Bias\n  Probing of a Dataset for Online Radical Content Detection","authors":"Arij Riabi, Virginie Mouilleron, Menel Mahamdi, Wissam Antoun, Djam\\'e\n  Seddah","authorsParsed":[["Riabi","Arij",""],["Mouilleron","Virginie",""],["Mahamdi","Menel",""],["Antoun","Wissam",""],["Seddah","Djam√©",""]],"versions":[{"version":"v1","created":"Mon, 16 Dec 2024 13:03:43 GMT"},{"version":"v2","created":"Thu, 19 Dec 2024 15:55:45 GMT"}],"updateDate":"2024-12-20","timestamp":1734354223000,"abstract":"  The proliferation of radical content on online platforms poses significant\nrisks, including inciting violence and spreading extremist ideologies. Despite\nongoing research, existing datasets and models often fail to address the\ncomplexities of multilingual and diverse data. To bridge this gap, we introduce\na publicly available multilingual dataset annotated with radicalization levels,\ncalls for action, and named entities in English, French, and Arabic. This\ndataset is pseudonymized to protect individual privacy while preserving\ncontextual information. Beyond presenting our freely available dataset, we\nanalyze the annotation process, highlighting biases and disagreements among\nannotators and their implications for model performance. Additionally, we use\nsynthetic data to investigate the influence of socio-demographic traits on\nannotation patterns and model predictions. Our work offers a comprehensive\nexamination of the challenges and opportunities in building robust datasets for\nradical content detection, emphasizing the importance of fairness and\ntransparency in model development.\n","subjects":["Computer Science/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"_Bl4sofVRYhxz3FvGDCbtwZQYLKEOb0WEonCnk6wQq0","pdfSize":"1082897"}