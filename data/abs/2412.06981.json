{"id":"2412.06981","title":"Diffusing Differentiable Representations","authors":"Yash Savani, Marc Finzi, J. Zico Kolter","authorsParsed":[["Savani","Yash",""],["Finzi","Marc",""],["Kolter","J. Zico",""]],"versions":[{"version":"v1","created":"Mon, 9 Dec 2024 20:42:58 GMT"}],"updateDate":"2024-12-11","timestamp":1733776978000,"abstract":"  We introduce a novel, training-free method for sampling differentiable\nrepresentations (diffreps) using pretrained diffusion models. Rather than\nmerely mode-seeking, our method achieves sampling by \"pulling back\" the\ndynamics of the reverse-time process--from the image space to the diffrep\nparameter space--and updating the parameters according to this pulled-back\nprocess. We identify an implicit constraint on the samples induced by the\ndiffrep and demonstrate that addressing this constraint significantly improves\nthe consistency and detail of the generated objects. Our method yields diffreps\nwith substantially improved quality and diversity for images, panoramas, and 3D\nNeRFs compared to existing techniques. Our approach is a general-purpose method\nfor sampling diffreps, expanding the scope of problems that diffusion models\ncan tackle.\n","subjects":["Computer Science/Computer Vision and Pattern Recognition","Computer Science/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"_vygcrDJEHnupvG94aMsMPZy00NM76gIpDeqQ14TCro","pdfSize":"15819552"}