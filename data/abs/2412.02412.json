{
  "id": "2412.02412",
  "title": "VISTA: A Panoramic View of Neural Representations",
  "authors": "Tom White",
  "authorsParsed": [
    [
      "White",
      "Tom",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Tue, 3 Dec 2024 12:12:03 GMT"
    }
  ],
  "updateDate": "2024-12-04",
  "timestamp": 1733227923000,
  "abstract": "  We present VISTA (Visualization of Internal States and Their Associations), a\nnovel pipeline for visually exploring and interpreting neural network\nrepresentations. VISTA addresses the challenge of analyzing vast\nmultidimensional spaces in modern machine learning models by mapping\nrepresentations into a semantic 2D space. The resulting collages visually\nreveal patterns and relationships within internal representations. We\ndemonstrate VISTA's utility by applying it to sparse autoencoder latents\nuncovering new properties and interpretations. We review the VISTA methodology,\npresent findings from our case study ( https://got.drib.net/latents/ ), and\ndiscuss implications for neural network interpretability across various domains\nof machine learning.\n",
  "subjects": [
    "Computer Science/Machine Learning",
    "Computer Science/Artificial Intelligence",
    "Computer Science/Computer Vision and Pattern Recognition"
  ],
  "license": "http://creativecommons.org/publicdomain/zero/1.0/",
  "blobId": "nn8LEJxib8YUxcmSvsMIjwp1nuULDgJLES3ROWpzPQo",
  "pdfSize": "31356553"
}