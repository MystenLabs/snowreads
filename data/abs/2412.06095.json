{
  "id": "2412.06095",
  "title": "Measuring Grammatical Diversity from Small Corpora: Derivational Entropy\n  Rates, Mean Length of Utterances, and Annotation Invariance",
  "authors": "Fermin Moscoso del Prado Martin",
  "authorsParsed": [
    [
      "Martin",
      "Fermin Moscoso del Prado",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Sun, 8 Dec 2024 22:54:57 GMT"
    }
  ],
  "updateDate": "2024-12-10",
  "timestamp": 1733698497000,
  "abstract": "  In many fields, such as language acquisition, neuropsychology of language,\nthe study of aging, and historical linguistics, corpora are used for estimating\nthe diversity of grammatical structures that are produced during a period by an\nindividual, community, or type of speakers. In these cases, treebanks are taken\nas representative samples of the syntactic structures that might be\nencountered. Generalizing the potential syntactic diversity from the structures\ndocumented in a small corpus requires careful extrapolation whose accuracy is\nconstrained by the limited size of representative sub-corpora. In this article,\nI demonstrate -- theoretically, and empirically -- that a grammar's\nderivational entropy and the mean length of the utterances (MLU) it generates\nare fundamentally linked, giving rise to a new measure, the derivational\nentropy rate. The mean length of utterances becomes the most practical index of\nsyntactic complexity; I demonstrate that MLU is not a mere proxy, but a\nfundamental measure of syntactic diversity. In combination with the new\nderivational entropy rate measure, it provides a theory-free assessment of\ngrammatical complexity. The derivational entropy rate indexes the rate at which\ndifferent grammatical annotation frameworks determine the grammatical\ncomplexity of treebanks. I introduce the Smoothed Induced Treebank Entropy\n(SITE) as a tool for estimating these measures accurately, even from very small\ntreebanks. I conclude by discussing important implications of these results for\nboth NLP and human language processing.\n",
  "subjects": [
    "Computer Science/Computation and Language",
    "Computer Science/Formal Languages and Automata Theory",
    "Computer Science/Information Theory",
    "Mathematics/Information Theory"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "GfueDxHIvghzkSGOK7rA51iKZTI1nQhpZg59_kGof_o",
  "pdfSize": "3037159"
}