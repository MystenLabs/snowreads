{"id":"2407.07011","title":"Induction Heads as an Essential Mechanism for Pattern Matching in\n  In-context Learning","authors":"J. Crosbie and E. Shutova","authorsParsed":[["Crosbie","J.",""],["Shutova","E.",""]],"versions":[{"version":"v1","created":"Tue, 9 Jul 2024 16:29:21 GMT"}],"updateDate":"2024-07-10","timestamp":1720542561000,"abstract":"  Large language models (LLMs) have shown a remarkable ability to learn and\nperform complex tasks through in-context learning (ICL). However, a\ncomprehensive understanding of its internal mechanisms is still lacking. This\npaper explores the role of induction heads in a few-shot ICL setting. We\nanalyse two state-of-the-art models, Llama-3-8B and InternLM2-20B on abstract\npattern recognition and NLP tasks. Our results show that even a minimal\nablation of induction heads leads to ICL performance decreases of up to ~32%\nfor abstract pattern recognition tasks, bringing the performance close to\nrandom. For NLP tasks, this ablation substantially decreases the model's\nability to benefit from examples, bringing few-shot ICL performance close to\nthat of zero-shot prompts. We further use attention knockout to disable\nspecific induction patterns, and present fine-grained evidence for the role\nthat the induction mechanism plays in ICL.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"fw22waWZoEE5Jv2K-rJ1fYcTXTI2S0DE4IcYBfqNaYk","pdfSize":"9094380"}
