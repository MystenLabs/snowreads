{"id":"2407.05557","title":"$R^2$-Guard: Robust Reasoning Enabled LLM Guardrail via\n  Knowledge-Enhanced Logical Reasoning","authors":"Mintong Kang and Bo Li","authorsParsed":[["Kang","Mintong",""],["Li","Bo",""]],"versions":[{"version":"v1","created":"Mon, 8 Jul 2024 02:15:29 GMT"}],"updateDate":"2024-07-09","timestamp":1720404929000,"abstract":"  As LLMs become increasingly prevalent across various applications, it is\ncritical to establish safety guardrails to moderate input/output content of\nLLMs. Existing guardrail models treat various safety categories independently\nand fail to explicitly capture the intercorrelations among them. This has led\nto limitations such as ineffectiveness due to inadequate training on long-tail\ndata from correlated safety categories, susceptibility to jailbreaking attacks,\nand inflexibility regarding new safety categories. To address these\nlimitations, we propose $R^2$-Guard, a robust reasoning enabled LLM guardrail\nvia knowledge-enhanced logical reasoning. Specifically, $R^2$-Guard comprises\ntwo parts: data-driven category-specific learning and reasoning components. The\ndata-driven guardrail models provide unsafety probabilities of moderated\ncontent on different safety categories. We then encode safety knowledge among\ndifferent categories as first-order logical rules and embed them into a\nprobabilistic graphic model (PGM) based reasoning component. The unsafety\nprobabilities of different categories from data-driven guardrail models are\nsent to the reasoning component for final inference. We employ two types of\nPGMs: Markov logic networks (MLNs) and probabilistic circuits (PCs), and\noptimize PCs to achieve precision-efficiency balance via improved graph\nstructure. To further perform stress tests for guardrail models, we employ a\npairwise construction method to construct a new safety benchmark TwinSafety,\nwhich features principled categories. We demonstrate the effectiveness of\n$R^2$-Guard by comparisons with eight strong guardrail models on six safety\nbenchmarks, and demonstrate the robustness of $R^2$-Guard against four SOTA\njailbreaking attacks. $R^2$-Guard significantly surpasses SOTA method\nLlamaGuard by 30.2% on ToxicChat and by 59.5% against jailbreaking attacks.\n","subjects":["Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"9sVdQhnrJCC4F7-C1Dt0htOzQ8mmdU54uCkqKJML_P8","pdfSize":"831585"}