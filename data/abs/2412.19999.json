{
  "id": "2412.19999",
  "title": "Comprehensive Review of EEG-to-Output Research: Decoding Neural Signals\n  into Images, Videos, and Audio",
  "authors": "Yashvir Sabharwal and Balaji Rama",
  "authorsParsed": [
    [
      "Sabharwal",
      "Yashvir",
      ""
    ],
    [
      "Rama",
      "Balaji",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Sat, 28 Dec 2024 03:50:56 GMT"
    }
  ],
  "updateDate": "2024-12-31",
  "timestamp": 1735357856000,
  "abstract": "  Electroencephalography (EEG) is an invaluable tool in neuroscience, offering\ninsights into brain activity with high temporal resolution. Recent advancements\nin machine learning and generative modeling have catalyzed the application of\nEEG in reconstructing perceptual experiences, including images, videos, and\naudio. This paper systematically reviews EEG-to-output research, focusing on\nstate-of-the-art generative methods, evaluation metrics, and data challenges.\nUsing PRISMA guidelines, we analyze 1800 studies and identify key trends,\nchallenges, and opportunities in the field. The findings emphasize the\npotential of advanced models such as Generative Adversarial Networks (GANs),\nVariational Autoencoders (VAEs), and Transformers, while highlighting the\npressing need for standardized datasets and cross-subject generalization. A\nroadmap for future research is proposed that aims to improve decoding accuracy\nand broadening real-world applications.\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition",
    "Computer Science/Artificial Intelligence",
    "Quantitative Biology/Neurons and Cognition"
  ],
  "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
  "blobId": "7G_6eMH5vDNu-f_j6qEx5Js7tXfaUO1Wq8625fgFA4E",
  "pdfSize": "188894"
}