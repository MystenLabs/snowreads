{
  "id": "2412.16311",
  "title": "HybGRAG: Hybrid Retrieval-Augmented Generation on Textual and Relational\n  Knowledge Bases",
  "authors": "Meng-Chieh Lee, Qi Zhu, Costas Mavromatis, Zhen Han, Soji Adeshina,\n  Vassilis N. Ioannidis, Huzefa Rangwala, Christos Faloutsos",
  "authorsParsed": [
    [
      "Lee",
      "Meng-Chieh",
      ""
    ],
    [
      "Zhu",
      "Qi",
      ""
    ],
    [
      "Mavromatis",
      "Costas",
      ""
    ],
    [
      "Han",
      "Zhen",
      ""
    ],
    [
      "Adeshina",
      "Soji",
      ""
    ],
    [
      "Ioannidis",
      "Vassilis N.",
      ""
    ],
    [
      "Rangwala",
      "Huzefa",
      ""
    ],
    [
      "Faloutsos",
      "Christos",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Fri, 20 Dec 2024 19:49:12 GMT"
    }
  ],
  "updateDate": "2024-12-24",
  "timestamp": 1734724152000,
  "abstract": "  Given a semi-structured knowledge base (SKB), where text documents are\ninterconnected by relations, how can we effectively retrieve relevant\ninformation to answer user questions? Retrieval-Augmented Generation (RAG)\nretrieves documents to assist large language models (LLMs) in question\nanswering; while Graph RAG (GRAG) uses structured knowledge bases as its\nknowledge source. However, many questions require both textual and relational\ninformation from SKB - referred to as \"hybrid\" questions - which complicates\nthe retrieval process and underscores the need for a hybrid retrieval method\nthat leverages both information. In this paper, through our empirical analysis,\nwe identify key insights that show why existing methods may struggle with\nhybrid question answering (HQA) over SKB. Based on these insights, we propose\nHybGRAG for HQA consisting of a retriever bank and a critic module, with the\nfollowing advantages: (1) Agentic, it automatically refines the output by\nincorporating feedback from the critic module, (2) Adaptive, it solves hybrid\nquestions requiring both textual and relational information with the retriever\nbank, (3) Interpretable, it justifies decision making with intuitive refinement\npath, and (4) Effective, it surpasses all baselines on HQA benchmarks. In\nexperiments on the STaRK benchmark, HybGRAG achieves significant performance\ngains, with an average relative improvement in Hit@1 of 51%.\n",
  "subjects": [
    "Computer Science/Machine Learning",
    "Computer Science/Artificial Intelligence",
    "Computer Science/Information Retrieval"
  ],
  "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
  "blobId": "o3f9b3Bkv2fticl4w2K95AGS4bKWEh5X37fusB1JkqM",
  "pdfSize": "618700"
}