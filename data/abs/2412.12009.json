{"id":"2412.12009","title":"SpeechPrune: Context-aware Token Pruning for Speech Information\n  Retrieval","authors":"Yueqian Lin, Yuzhe Fu, Jingyang Zhang, Yudong Liu, Jianyi Zhang,\n  Jingwei Sun, Hai \"Helen\" Li, Yiran Chen","authorsParsed":[["Lin","Yueqian",""],["Fu","Yuzhe",""],["Zhang","Jingyang",""],["Liu","Yudong",""],["Zhang","Jianyi",""],["Sun","Jingwei",""],["Li","Hai \"Helen\"",""],["Chen","Yiran",""]],"versions":[{"version":"v1","created":"Mon, 16 Dec 2024 17:36:02 GMT"}],"updateDate":"2024-12-17","timestamp":1734370562000,"abstract":"  We introduce Speech Information Retrieval (SIR), a new long-context task for\nSpeech Large Language Models (Speech LLMs), and present SPIRAL, a 1,012-sample\nbenchmark testing models' ability to extract critical details from\napproximately 90-second spoken inputs. While current Speech LLMs excel at\nshort-form tasks, they struggle with the computational and representational\ndemands of longer audio sequences. To address this limitation, we propose\nSpeechPrune, a training-free token pruning strategy that uses speech-text\nsimilarity and approximated attention scores to efficiently discard irrelevant\ntokens. In SPIRAL, SpeechPrune achieves accuracy improvements of 29% and up to\n47% over the original model and the random pruning model at a pruning rate of\n20%, respectively. SpeechPrune can maintain network performance even at a\npruning level of 80%. This approach highlights the potential of token-level\npruning for efficient and scalable long-form speech understanding.\n","subjects":["Electrical Engineering and Systems Science/Audio and Speech Processing","Computer Science/Artificial Intelligence","Computer Science/Computation and Language","Computer Science/Sound"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"nrbDLml9IhAt-4Dz8tYwn07aaAnV1w1o_J7RsrMBj2M","pdfSize":"3367678"}