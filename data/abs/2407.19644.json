{"id":"2407.19644","title":"Realizing Unaligned Block-wise Pruning for DNN Acceleration on Mobile\n  Devices","authors":"Hayun Lee, Dongkun Shin","authorsParsed":[["Lee","Hayun",""],["Shin","Dongkun",""]],"versions":[{"version":"v1","created":"Mon, 29 Jul 2024 01:59:06 GMT"}],"updateDate":"2024-07-30","timestamp":1722218346000,"abstract":"  With the recent proliferation of on-device AI, there is an increasing need to\nrun computationally intensive DNNs directly on mobile devices. However, the\nlimited computing and memory resources of these devices necessitate effective\npruning techniques. Block-wise pruning is promising due to its low accuracy\ndrop tradeoff for speedup gains, but it requires block positions to be aligned\nwith block size, hindering optimal position selection to minimize model\naccuracy drop. Unaligned block pruning (UBP) addresses this by allowing blocks\nto be selected at arbitrary positions, yet its practical use is limited by a\ntime-consuming optimal block selection algorithm and lack of efficient\ninference kernels. In this paper, we propose a pseudo-optimal yet fast block\nselection algorithm called Block Expansion and Division (BED), which can be\nintegrated into an iterative model training process. Additionally, we introduce\nan efficient inference kernel implementation for mobile devices, enabling a\nUBP-based model to achieve similar latency to a DNN model compressed by aligned\nblock pruning. We demonstrate the superiority of our techniques on a real\nmobile phone with MobileNet and ResNet models.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"xIp3a7HxPtt5p3KKIZoNi8-u_eQ3HaqqHfIOjY5tDAM","pdfSize":"519325"}