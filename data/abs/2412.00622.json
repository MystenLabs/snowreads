{"id":"2412.00622","title":"Visual Modality Prompt for Adapting Vision-Language Object Detectors","authors":"Heitor R. Medeiros, Atif Belal, Srikanth Muralidharan, Eric Granger\n  and Marco Pedersoli","authorsParsed":[["Medeiros","Heitor R.",""],["Belal","Atif",""],["Muralidharan","Srikanth",""],["Granger","Eric",""],["Pedersoli","Marco",""]],"versions":[{"version":"v1","created":"Sun, 1 Dec 2024 00:19:59 GMT"}],"updateDate":"2024-12-03","timestamp":1733012399000,"abstract":"  The zero-shot performance of object detectors degrades when tested on\ndifferent modalities, such as infrared and depth. While recent work has\nexplored image translation techniques to adapt detectors to new modalities,\nthese methods are limited to a single modality and apply only to traditional\ndetectors. Recently, vision-language detectors, such as YOLO-World and\nGrounding DINO, have shown promising zero-shot capabilities, however, they have\nnot yet been adapted for other visual modalities. Traditional fine-tuning\napproaches tend to compromise the zero-shot capabilities of the detectors. The\nvisual prompt strategies commonly used for classification with vision-language\nmodels apply the same linear prompt translation to each image making them less\neffective. To address these limitations, we propose ModPrompt, a visual prompt\nstrategy to adapt vision-language detectors to new modalities without degrading\nzero-shot performance. In particular, an encoder-decoder visual prompt strategy\nis proposed, further enhanced by the integration of inference-friendly task\nresiduals, facilitating more robust adaptation. Empirically, we benchmark our\nmethod for modality adaptation on two vision-language detectors, YOLO-World and\nGrounding DINO, and on challenging infrared (LLVIP, FLIR) and depth (NYUv2)\ndata, achieving performance comparable to full fine-tuning while preserving the\nmodel's zero-shot capability. Our code is available at:\nhttps://github.com/heitorrapela/ModPrompt\n","subjects":["Computer Science/Computer Vision and Pattern Recognition","Computer Science/Artificial Intelligence","Computer Science/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"_U-cpjymW40k00ko2cOMkUKUz-YzV5G9mo37muG_Yh8","pdfSize":"43857368"}