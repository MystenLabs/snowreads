{
  "id": "2412.14479",
  "title": "Frenzy: A Memory-Aware Serverless LLM Training System for Heterogeneous\n  GPU Clusters",
  "authors": "Zihan Chang, Sheng Xiao, Shuibing He, Siling Yang, Zhe Pan and Dong Li",
  "authorsParsed": [
    [
      "Chang",
      "Zihan",
      ""
    ],
    [
      "Xiao",
      "Sheng",
      ""
    ],
    [
      "He",
      "Shuibing",
      ""
    ],
    [
      "Yang",
      "Siling",
      ""
    ],
    [
      "Pan",
      "Zhe",
      ""
    ],
    [
      "Li",
      "Dong",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Thu, 19 Dec 2024 03:03:06 GMT"
    }
  ],
  "updateDate": "2024-12-20",
  "timestamp": 1734577386000,
  "abstract": "  Existing work only effective on a given number of GPUs, often neglecting the\ncomplexities involved in manually determining the specific types and quantities\nof GPUs needed, which can be a significant burden for developers. To address\nthis issue, we propose Frenzy, a memory-aware serverless computing method for\nheterogeneous GPU clusters. Frenzy allows users to submit models without\nworrying about underlying hardware resources. First, Frenzy predicts the\nrequired number and type of GPUs by estimating the GPU memory usage of the LLM.\nThen, it employs a low-overhead heterogeneity-aware scheduling method to\noptimize training efficiency. We validated Frenzy's performance by conducting\nmulti-task LLM training tests on a heterogeneous GPU cluster with three\ndifferent GPU types. The results show that Frenzy's memory usage prediction\naccuracy exceeds 92\\%, the scheduling overhead is reduced by 10 times, and it\nreduces the average job completion time by 12\\% to 18\\% compared to\nstate-of-the-art methods.\n",
  "subjects": [
    "Computer Science/Distributed, Parallel, and Cluster Computing"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "KO2zDM5QmlAg6E9oJGhGofaPOc_KcO5w1ZRyfeQTpWs",
  "pdfSize": "774340"
}