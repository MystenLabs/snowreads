{
  "id": "2412.01120",
  "title": "Reliable and scalable variable importance estimation via warm-start and\n  early stopping",
  "authors": "Zexuan Sun, Garvesh Raskutti",
  "authorsParsed": [
    [
      "Sun",
      "Zexuan",
      ""
    ],
    [
      "Raskutti",
      "Garvesh",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Mon, 2 Dec 2024 04:45:10 GMT"
    }
  ],
  "updateDate": "2024-12-03",
  "timestamp": 1733114710000,
  "abstract": "  As opaque black-box predictive models become more prevalent, the need to\ndevelop interpretations for these models is of great interest. The concept of\nvariable importance and Shapley values are interpretability measures that\napplies to any predictive model and assesses how much a variable or set of\nvariables improves prediction performance. When the number of variables is\nlarge, estimating variable importance presents a significant computational\nchallenge because re-training neural networks or other black-box algorithms\nrequires significant additional computation. In this paper, we address this\nchallenge for algorithms using gradient descent and gradient boosting (e.g.\nneural networks, gradient-boosted decision trees). By using the ideas of early\nstopping of gradient-based methods in combination with warm-start using the\ndropout method, we develop a scalable method to estimate variable importance\nfor any algorithm that can be expressed as an iterative kernel update equation.\nImportantly, we provide theoretical guarantees by using the theory for early\nstopping of kernel-based methods for neural networks with sufficiently large\n(but not necessarily infinite) width and gradient-boosting decision trees that\nuse symmetric trees as a weaker learner. We also demonstrate the efficacy of\nour methods through simulations and a real data example which illustrates the\ncomputational benefit of early stopping rather than fully re-training the model\nas well as the increased accuracy of our approach.\n",
  "subjects": [
    "Statistics/Machine Learning",
    "Computer Science/Machine Learning"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "XVpgo8JAWO0cmW8bZAYdCyXAOazfkrRFjTZni0t2OWs",
  "pdfSize": "3358483"
}