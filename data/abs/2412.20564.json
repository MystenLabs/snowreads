{"id":"2412.20564","title":"Self-Disclosure to AI: The Paradox of Trust and Vulnerability in\n  Human-Machine Interactions","authors":"Zoe Zhiqiu Jiang","authorsParsed":[["Jiang","Zoe Zhiqiu",""]],"versions":[{"version":"v1","created":"Sun, 29 Dec 2024 20:23:18 GMT"}],"updateDate":"2024-12-31","timestamp":1735503798000,"abstract":"  In this paper, we explore the paradox of trust and vulnerability in\nhuman-machine interactions, inspired by Alexander Reben's BlabDroid project.\nThis project used small, unassuming robots that actively engaged with people,\nsuccessfully eliciting personal thoughts or secrets from individuals, often\nmore effectively than human counterparts. This phenomenon raises intriguing\nquestions about how trust and self-disclosure operate in interactions with\nmachines, even in their simplest forms. We study the change of trust in\ntechnology through analyzing the psychological processes behind such\nencounters. The analysis applies theories like Social Penetration Theory and\nCommunication Privacy Management Theory to understand the balance between\nperceived security and the risk of exposure when personal information and\nsecrets are shared with machines or AI. Additionally, we draw on philosophical\nperspectives, such as posthumanism and phenomenology, to engage with broader\nquestions about trust, privacy, and vulnerability in the digital age. Rapid\nincorporation of AI into our most private areas challenges us to rethink and\nredefine our ethical responsibilities.\n","subjects":["Computer Science/Human-Computer Interaction","Computer Science/Robotics"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"wtlJZ1n-Fxknq6lBuWBV4U1BloP4twu41Fr8SEGnIeM","pdfSize":"502290"}