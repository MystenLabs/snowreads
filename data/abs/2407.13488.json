{"id":"2407.13488","title":"Similarity over Factuality: Are we making progress on multimodal\n  out-of-context misinformation detection?","authors":"Stefanos-Iordanis Papadopoulos, Christos Koutlis, Symeon Papadopoulos,\n  Panagiotis C. Petrantonakis","authorsParsed":[["Papadopoulos","Stefanos-Iordanis",""],["Koutlis","Christos",""],["Papadopoulos","Symeon",""],["Petrantonakis","Panagiotis C.",""]],"versions":[{"version":"v1","created":"Thu, 18 Jul 2024 13:08:55 GMT"}],"updateDate":"2024-07-19","timestamp":1721308135000,"abstract":"  Out-of-context (OOC) misinformation poses a significant challenge in\nmultimodal fact-checking, where images are paired with texts that misrepresent\ntheir original context to support false narratives. Recent research in\nevidence-based OOC detection has seen a trend towards increasingly complex\narchitectures, incorporating Transformers, foundation models, and large\nlanguage models. In this study, we introduce a simple yet robust baseline,\nwhich assesses MUltimodal SimilaritiEs (MUSE), specifically the similarity\nbetween image-text pairs and external image and text evidence. Our results\ndemonstrate that MUSE, when used with conventional classifiers like Decision\nTree, Random Forest, and Multilayer Perceptron, can compete with and even\nsurpass the state-of-the-art on the NewsCLIPpings and VERITE datasets.\nFurthermore, integrating MUSE in our proposed \"Attentive Intermediate\nTransformer Representations\" (AITR) significantly improved performance, by 3.3%\nand 7.5% on NewsCLIPpings and VERITE, respectively. Nevertheless, the success\nof MUSE, relying on surface-level patterns and shortcuts, without examining\nfactuality and logical inconsistencies, raises critical questions about how we\ndefine the task, construct datasets, collect external evidence and overall, how\nwe assess progress in the field. We release our code at:\nhttps://github.com/stevejpapad/outcontext-misinfo-progress\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Multimedia"],"license":"http://creativecommons.org/licenses/by-sa/4.0/","blobId":"cIxA1UhSLTzbGVo6TMBdjRWKFoG_KjgoBaE5Et6Ihl0","pdfSize":"1546960"}