{
  "id": "2412.13641",
  "title": "Learning to Control an Android Robot Head for Facial Animation",
  "authors": "Marcel Heisler and Christian Becker-Asano",
  "authorsParsed": [
    [
      "Heisler",
      "Marcel",
      ""
    ],
    [
      "Becker-Asano",
      "Christian",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Wed, 18 Dec 2024 09:20:20 GMT"
    }
  ],
  "updateDate": "2024-12-19",
  "timestamp": 1734513620000,
  "abstract": "  The ability to display rich facial expressions is crucial for human-like\nrobotic heads. While manually defining such expressions is intricate, there\nalready exist approaches to automatically learn them. In this work one such\napproach is applied to evaluate and control a robot head different from the one\nin the original study. To improve the mapping of facial expressions from human\nactors onto a robot head, it is proposed to use 3D landmarks and their pairwise\ndistances as input to the learning algorithm instead of the previously used\nfacial action units. Participants of an online survey preferred mappings from\nour proposed approach in most cases, though there are still further\nimprovements required.\n",
  "subjects": [
    "Computer Science/Robotics"
  ],
  "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
  "blobId": "G8I51oa_9UYq7tLqBu0eAbXz0HKmBrGgWbB5X4wdM20",
  "pdfSize": "2784284"
}