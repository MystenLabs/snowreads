{
  "id": "2412.01617",
  "title": "If Eleanor Rigby Had Met ChatGPT: A Study on Loneliness in a Post-LLM\n  World",
  "authors": "Adrian de Wynter",
  "authorsParsed": [
    [
      "de Wynter",
      "Adrian",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Mon, 2 Dec 2024 15:39:00 GMT"
    }
  ],
  "updateDate": "2024-12-03",
  "timestamp": 1733153940000,
  "abstract": "  Loneliness, or the lack of fulfilling relationships, significantly impacts a\nperson's mental and physical well-being and is prevalent worldwide. Previous\nresearch suggests that large language models (LLMs) may help mitigate\nloneliness. However, we argue that the use of widespread LLMs like ChatGPT is\nmore prevalent--and riskier, as they are not designed for this purpose. To\nexplore this, we analysed user interactions with ChatGPT, particularly those\noutside of its marketed use as task-oriented assistant. In dialogues classified\nas lonely, users frequently (37%) sought advice or validation, and received\ngood engagement. However, ChatGPT failed in sensitive scenarios, like\nresponding appropriately to suicidal ideation or trauma. We also observed a 35%\nhigher incidence of toxic content, with women being 22 times more likely to be\ntargeted than men. Our findings underscore ethical and legal questions about\nthis technology, and note risks like radicalisation or further isolation. We\nconclude with recommendations for research and industry to address loneliness.\n",
  "subjects": [
    "Computer Science/Computation and Language",
    "Computer Science/Artificial Intelligence",
    "Computer Science/Computers and Society",
    "Computer Science/Human-Computer Interaction"
  ],
  "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
  "blobId": "OYiOeoDacPPtR7j3-WNxuzjU_wbGrD-utQoCP2pCs0Q",
  "pdfSize": "344708"
}