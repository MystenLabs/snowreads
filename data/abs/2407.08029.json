{"id":"2407.08029","title":"A Critical Review of Causal Reasoning Benchmarks for Large Language\n  Models","authors":"Linying Yang, Vik Shirvaikar, Oscar Clivio, Fabian Falck","authorsParsed":[["Yang","Linying",""],["Shirvaikar","Vik",""],["Clivio","Oscar",""],["Falck","Fabian",""]],"versions":[{"version":"v1","created":"Wed, 10 Jul 2024 20:11:51 GMT"}],"updateDate":"2024-07-12","timestamp":1720642311000,"abstract":"  Numerous benchmarks aim to evaluate the capabilities of Large Language Models\n(LLMs) for causal inference and reasoning. However, many of them can likely be\nsolved through the retrieval of domain knowledge, questioning whether they\nachieve their purpose. In this review, we present a comprehensive overview of\nLLM benchmarks for causality. We highlight how recent benchmarks move towards a\nmore thorough definition of causal reasoning by incorporating interventional or\ncounterfactual reasoning. We derive a set of criteria that a useful benchmark\nor set of benchmarks should aim to satisfy. We hope this work will pave the way\ntowards a general framework for the assessment of causal understanding in LLMs\nand the design of novel benchmarks.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"XH6SLcVuJD0skcYIqMGxTU9Iy_qwHZxR6C8VPQi-aiA","pdfSize":"499524","objectId":"0x288474a2e979e2c9fb5d6690f9cded4e0344a29e757023dd65c75aa50647c45b","registeredEpoch":"1","certifiedEpoch":"1","startEpoch":"1","endEpoch":"201"}
