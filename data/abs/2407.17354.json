{"id":"2407.17354","title":"Deep Spherical Superpixels","authors":"R\\'emi Giraud, Micha\\\"el Cl\\'ement","authorsParsed":[["Giraud","Rémi",""],["Clément","Michaël",""]],"versions":[{"version":"v1","created":"Wed, 24 Jul 2024 15:27:21 GMT"}],"updateDate":"2024-07-25","timestamp":1721834841000,"abstract":"  Over the years, the use of superpixel segmentation has become very popular in\nvarious applications, serving as a preprocessing step to reduce data size by\nadapting to the content of the image, regardless of its semantic content. While\nthe superpixel segmentation of standard planar images, captured with a 90{\\deg}\nfield of view, has been extensively studied, there has been limited focus on\ndedicated methods to omnidirectional or spherical images, captured with a\n360{\\deg} field of view. In this study, we introduce the first deep\nlearning-based superpixel segmentation approach tailored for omnidirectional\nimages called DSS (for Deep Spherical Superpixels). Our methodology leverages\non spherical CNN architectures and the differentiable K-means clustering\nparadigm for superpixels, to generate superpixels that follow the spherical\ngeometry. Additionally, we propose to use data augmentation techniques\nspecifically designed for 360{\\deg} images, enabling our model to efficiently\nlearn from a limited set of annotated omnidirectional data. Our extensive\nvalidation across two datasets demonstrates that taking into account the\ninherent circular geometry of such images into our framework improves the\nsegmentation performance over traditional and deep learning-based superpixel\nmethods. Our code is available online.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"--aReMSvj7RkMEQh-PmqfSscO3XWtg0l6uMH5YH1nts","pdfSize":"15696267","objectId":"0x240e71b578549cfbb0a0108ef918bbd4c84f115940af0a45d36130c98f47a051","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
