{"id":"2407.11309","title":"Gaussian Splatting LK","authors":"Liuyue Xie, Joel Julin, Koichiro Niinuma, Laszlo A. Jeni","authorsParsed":[["Xie","Liuyue",""],["Julin","Joel",""],["Niinuma","Koichiro",""],["Jeni","Laszlo A.",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 01:50:43 GMT"}],"updateDate":"2024-07-17","timestamp":1721094643000,"abstract":"  Reconstructing dynamic 3D scenes from 2D images and generating diverse views\nover time presents a significant challenge due to the inherent complexity and\ntemporal dynamics involved. While recent advancements in neural implicit models\nand dynamic Gaussian Splatting have shown promise, limitations persist,\nparticularly in accurately capturing the underlying geometry of highly dynamic\nscenes. Some approaches address this by incorporating strong semantic and\ngeometric priors through diffusion models. However, we explore a different\navenue by investigating the potential of regularizing the native warp field\nwithin the dynamic Gaussian Splatting framework. Our method is grounded on the\nkey intuition that an accurate warp field should produce continuous space-time\nmotions. While enforcing the motion constraints on warp fields is non-trivial,\nwe show that we can exploit knowledge innate to the forward warp field network\nto derive an analytical velocity field, then time integrate for scene flows to\neffectively constrain both the 2D motion and 3D positions of the Gaussians.\nThis derived Lucas-Kanade style analytical regularization enables our method to\nachieve superior performance in reconstructing highly dynamic scenes, even\nunder minimal camera movement, extending the boundaries of what existing\ndynamic Gaussian Splatting frameworks can achieve.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Graphics"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"Cmk8glMFGB6EGwPhfbCDI8z98cjj29E8vft8OZjsrCI","pdfSize":"15164224"}