{"id":"2407.11211","title":"Unconstrained Open Vocabulary Image Classification: Zero-Shot Transfer\n  from Text to Image via CLIP Inversion","authors":"Philipp Allgeuer and Kyra Ahrens and Stefan Wermter","authorsParsed":[["Allgeuer","Philipp",""],["Ahrens","Kyra",""],["Wermter","Stefan",""]],"versions":[{"version":"v1","created":"Mon, 15 Jul 2024 19:53:02 GMT"},{"version":"v2","created":"Wed, 17 Jul 2024 22:23:42 GMT"}],"updateDate":"2024-07-19","timestamp":1721073182000,"abstract":"  We introduce NOVIC, an innovative uNconstrained Open Vocabulary Image\nClassifier that uses an autoregressive transformer to generatively output\nclassification labels as language. Leveraging the extensive knowledge of CLIP\nmodels, NOVIC harnesses the embedding space to enable zero-shot transfer from\npure text to images. Traditional CLIP models, despite their ability for open\nvocabulary classification, require an exhaustive prompt of potential class\nlabels, restricting their application to images of known content or context. To\naddress this, we propose an \"object decoder\" model that is trained on a\nlarge-scale 92M-target dataset of templated object noun sets and LLM-generated\ncaptions to always output the object noun in question. This effectively inverts\nthe CLIP text encoder and allows textual object labels to be generated directly\nfrom image-derived embedding vectors, without requiring any a priori knowledge\nof the potential content of an image. The trained decoders are tested on a mix\nof manually and web-curated datasets, as well as standard image classification\nbenchmarks, and achieve fine-grained prompt-free prediction scores of up to\n87.5%, a strong result considering the model must work for any conceivable\nimage and without any contextual clues.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"EneCj9AUAtA_l5f0oNNZmS2SDOa78QoZBxk1GICPxws","pdfSize":"4542388"}