{"id":"2407.14573","title":"Trading Devil Final: Backdoor attack via Stock market and Bayesian\n  Optimization","authors":"Orson Mengara","authorsParsed":[["Mengara","Orson",""]],"versions":[{"version":"v1","created":"Sun, 21 Jul 2024 06:27:45 GMT"},{"version":"v2","created":"Wed, 7 Aug 2024 08:22:35 GMT"},{"version":"v3","created":"Fri, 16 Aug 2024 07:30:29 GMT"},{"version":"v4","created":"Sat, 24 Aug 2024 04:07:40 GMT"},{"version":"v5","created":"Thu, 12 Sep 2024 16:22:52 GMT"}],"updateDate":"2024-09-13","timestamp":1721543265000,"abstract":"  Since the advent of generative artificial intelligence, every company and\nresearcher has been rushing to develop their own generative models, whether\ncommercial or not. Given the large number of users of these powerful new tools,\nthere is currently no intrinsically verifiable way to explain from the ground\nup what happens when LLMs (large language models) learn. For example, those\nbased on automatic speech recognition systems, which have to rely on huge and\nastronomical amounts of data collected from all over the web to produce fast\nand efficient results, In this article, we develop a backdoor attack called\nMarketBackFinal 2.0, based on acoustic data poisoning, MarketBackFinal 2.0 is\nmainly based on modern stock market models. In order to show the possible\nvulnerabilities of speech-based transformers that may rely on LLMs.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Cryptography and Security","Quantitative Finance/Computational Finance","Quantitative Finance/Pricing of Securities","Quantitative Finance/Statistical Finance"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"ebMZbnevcBTo5Yncug5CgVmgYCh8ZNnnEF7z7fAfPw4","pdfSize":"20483063"}