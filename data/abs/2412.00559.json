{"id":"2412.00559","title":"Polish Medical Exams: A new dataset for cross-lingual medical knowledge\n  transfer assessment","authors":"{\\L}ukasz Grzybowski, Jakub Pokrywka, Micha{\\l} Ciesi\\'o{\\l}ka, Jeremi\n  I. Kaczmarek, Marek Kubis","authorsParsed":[["Grzybowski","Łukasz",""],["Pokrywka","Jakub",""],["Ciesiółka","Michał",""],["Kaczmarek","Jeremi I.",""],["Kubis","Marek",""]],"versions":[{"version":"v1","created":"Sat, 30 Nov 2024 19:02:34 GMT"}],"updateDate":"2024-12-03","timestamp":1732993354000,"abstract":"  Large Language Models (LLMs) have demonstrated significant potential in\nhandling specialized tasks, including medical problem-solving. However, most\nstudies predominantly focus on English-language contexts. This study introduces\na novel benchmark dataset based on Polish medical licensing and specialization\nexams (LEK, LDEK, PES) taken by medical doctor candidates and practicing\ndoctors pursuing specialization. The dataset was web-scraped from publicly\navailable resources provided by the Medical Examination Center and the Chief\nMedical Chamber. It comprises over 24,000 exam questions, including a subset of\nparallel Polish-English corpora, where the English portion was professionally\ntranslated by the examination center for foreign candidates. By creating a\nstructured benchmark from these existing exam questions, we systematically\nevaluate state-of-the-art LLMs, including general-purpose, domain-specific, and\nPolish-specific models, and compare their performance against human medical\nstudents. Our analysis reveals that while models like GPT-4o achieve near-human\nperformance, significant challenges persist in cross-lingual translation and\ndomain-specific understanding. These findings underscore disparities in model\nperformance across languages and medical specialties, highlighting the\nlimitations and ethical considerations of deploying LLMs in clinical practice.\n","subjects":["Computer Science/Computation and Language","Computer Science/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"RKLKkf6A49CL_TZaS86XDEHx-g-3YeNEUG48FKv5_Jk","pdfSize":"2342584"}