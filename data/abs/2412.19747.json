{
  "id": "2412.19747",
  "title": "Enhancing Adversarial Robustness of Deep Neural Networks Through\n  Supervised Contrastive Learning",
  "authors": "Longwei Wang, Navid Nayyem, Abdullah Rakin",
  "authorsParsed": [
    [
      "Wang",
      "Longwei",
      ""
    ],
    [
      "Nayyem",
      "Navid",
      ""
    ],
    [
      "Rakin",
      "Abdullah",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Fri, 27 Dec 2024 17:14:52 GMT"
    }
  ],
  "updateDate": "2024-12-30",
  "timestamp": 1735319692000,
  "abstract": "  Adversarial attacks exploit the vulnerabilities of convolutional neural\nnetworks by introducing imperceptible perturbations that lead to\nmisclassifications, exposing weaknesses in feature representations and decision\nboundaries. This paper presents a novel framework combining supervised\ncontrastive learning and margin-based contrastive loss to enhance adversarial\nrobustness. Supervised contrastive learning improves the structure of the\nfeature space by clustering embeddings of samples within the same class and\nseparating those from different classes. Margin-based contrastive loss,\ninspired by support vector machines, enforces explicit constraints to create\nrobust decision boundaries with well-defined margins. Experiments on the\nCIFAR-100 dataset with a ResNet-18 backbone demonstrate robustness performance\nimprovements in adversarial accuracy under Fast Gradient Sign Method attacks.\n",
  "subjects": [
    "Computer Science/Machine Learning",
    "Computer Science/Artificial Intelligence"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "RDPIIbusQBtqLz3OLQJmMzrFaCLYi2LKMFc0xSbD_aM",
  "pdfSize": "612493"
}