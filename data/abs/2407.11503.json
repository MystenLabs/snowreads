{"id":"2407.11503","title":"Beyond Mask: Rethinking Guidance Types in Few-shot Segmentation","authors":"Shijie Chang, Youwei Pang, Xiaoqi Zhao, Lihe Zhang, Huchuan Lu","authorsParsed":[["Chang","Shijie",""],["Pang","Youwei",""],["Zhao","Xiaoqi",""],["Zhang","Lihe",""],["Lu","Huchuan",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 08:41:01 GMT"}],"updateDate":"2024-07-17","timestamp":1721119261000,"abstract":"  Existing few-shot segmentation (FSS) methods mainly focus on prototype\nfeature generation and the query-support matching mechanism. As a crucial\nprompt for generating prototype features, the pair of image-mask types in the\nsupport set has become the default setting. However, various types such as\nimage, text, box, and mask all can provide valuable information regarding the\nobjects in context, class, localization, and shape appearance. Existing work\nfocuses on specific combinations of guidance, leading FSS into different\nresearch branches. Rethinking guidance types in FSS is expected to explore the\nefficient joint representation of the coupling between the support set and\nquery set, giving rise to research trends in the weakly or strongly annotated\nguidance to meet the customized requirements of practical users. In this work,\nwe provide the generalized FSS with seven guidance paradigms and develop a\nuniversal vision-language framework (UniFSS) to integrate prompts from text,\nmask, box, and image. Leveraging the advantages of large-scale pre-training\nvision-language models in textual and visual embeddings, UniFSS proposes\nhigh-level spatial correction and embedding interactive units to overcome the\nsemantic ambiguity drawbacks typically encountered by pure visual matching\nmethods when facing intra-class appearance diversities. Extensive experiments\nshow that UniFSS significantly outperforms the state-of-the-art methods.\nNotably, the weakly annotated class-aware box paradigm even surpasses the\nfinely annotated mask paradigm.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"GJ4FrTJCplcf-mOWP4Z_herg-in9DobcGgfy8WC5d74","pdfSize":"4089962"}