{"id":"2412.12641","title":"Lagrangian Index Policy for Restless Bandits with Average Reward","authors":"Konstantin Avrachenkov, Vivek S. Borkar, Pratik Shah","authorsParsed":[["Avrachenkov","Konstantin",""],["Borkar","Vivek S.",""],["Shah","Pratik",""]],"versions":[{"version":"v1","created":"Tue, 17 Dec 2024 08:03:53 GMT"}],"updateDate":"2024-12-18","timestamp":1734422633000,"abstract":"  We study the Lagrangian Index Policy (LIP) for restless multi-armed bandits\nwith long-run average reward. In particular, we compare the performance of LIP\nwith the performance of the Whittle Index Policy (WIP), both heuristic policies\nknown to be asymptotically optimal under certain natural conditions. Even\nthough in most cases their performances are very similar, in the cases when WIP\nshows bad performance, LIP continues to perform very well. We then propose\nreinforcement learning algorithms, both tabular and NN-based, to obtain online\nlearning schemes for LIP in the model-free setting. The proposed reinforcement\nlearning schemes for LIP requires significantly less memory than the analogous\nscheme for WIP. We calculate analytically the Lagrangian index for the restart\nmodel, which describes the optimal web crawling and the minimization of the\nweighted age of information. We also give a new proof of asymptotic optimality\nin case of homogeneous bandits as the number of arms goes to infinity, based on\nexchangeability and de Finetti's theorem.\n","subjects":["Computer Science/Machine Learning","Computer Science/Artificial Intelligence","Mathematics/Optimization and Control","Mathematics/Probability"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"7M6TG-5gapKB3FHWvfr11Ltgiu9ROupxcd2NqL-ugu4","pdfSize":"652005"}