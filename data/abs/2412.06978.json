{
  "id": "2412.06978",
  "title": "Edge-SD-SR: Low Latency and Parameter Efficient On-device\n  Super-Resolution with Stable Diffusion via Bidirectional Conditioning",
  "authors": "Mehdi Noroozi, Isma Hadji, Victor Escorcia, Anestis Zaganidis, Brais\n  Martinez, Georgios Tzimiropoulos",
  "authorsParsed": [
    [
      "Noroozi",
      "Mehdi",
      ""
    ],
    [
      "Hadji",
      "Isma",
      ""
    ],
    [
      "Escorcia",
      "Victor",
      ""
    ],
    [
      "Zaganidis",
      "Anestis",
      ""
    ],
    [
      "Martinez",
      "Brais",
      ""
    ],
    [
      "Tzimiropoulos",
      "Georgios",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Mon, 9 Dec 2024 20:38:44 GMT"
    }
  ],
  "updateDate": "2024-12-11",
  "timestamp": 1733776724000,
  "abstract": "  There has been immense progress recently in the visual quality of Stable\nDiffusion-based Super Resolution (SD-SR). However, deploying large diffusion\nmodels on computationally restricted devices such as mobile phones remains\nimpractical due to the large model size and high latency. This is compounded\nfor SR as it often operates at high res (e.g. 4Kx3K). In this work, we\nintroduce Edge-SD-SR, the first parameter efficient and low latency diffusion\nmodel for image super-resolution. Edge-SD-SR consists of ~169M parameters,\nincluding UNet, encoder and decoder, and has a complexity of only ~142 GFLOPs.\nTo maintain a high visual quality on such low compute budget, we introduce a\nnumber of training strategies: (i) A novel conditioning mechanism on the low\nresolution input, coined bidirectional conditioning, which tailors the SD model\nfor the SR task. (ii) Joint training of the UNet and encoder, while decoupling\nthe encodings of the HR and LR images and using a dedicated schedule. (iii)\nFinetuning the decoder using the UNet's output to directly tailor the decoder\nto the latents obtained at inference time. Edge-SD-SR runs efficiently on\ndevice, e.g. it can upscale a 128x128 patch to 512x512 in 38 msec while running\non a Samsung S24 DSP, and of a 512x512 to 2048x2048 (requiring 25 model\nevaluations) in just ~1.1 sec. Furthermore, we show that Edge-SD-SR matches or\neven outperforms state-of-the-art SR approaches on the most established SR\nbenchmarks.\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition"
  ],
  "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
  "blobId": "GCjlwP-vy1Lv8Vt7tN4j675e_W8y2iWFpQQJ25g0Uaw",
  "pdfSize": "23683012"
}