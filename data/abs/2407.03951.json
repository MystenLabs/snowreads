{"id":"2407.03951","title":"Uncertainty-Guided Optimization on Large Language Model Search Trees","authors":"Julia Grosse, Ruotian Wu, Ahmad Rashid, Philipp Hennig, Pascal\n  Poupart, Agustinus Kristiadi","authorsParsed":[["Grosse","Julia",""],["Wu","Ruotian",""],["Rashid","Ahmad",""],["Hennig","Philipp",""],["Poupart","Pascal",""],["Kristiadi","Agustinus",""]],"versions":[{"version":"v1","created":"Thu, 4 Jul 2024 14:08:50 GMT"}],"updateDate":"2024-07-08","timestamp":1720102130000,"abstract":"  Beam search is a standard tree search algorithm when it comes to finding\nsequences of maximum likelihood, for example, in the decoding processes of\nlarge language models. However, it is myopic since it does not take the whole\npath from the root to a leaf into account. Moreover, it is agnostic to prior\nknowledge available about the process: For example, it does not consider that\nthe objective being maximized is a likelihood and thereby has specific\nproperties, like being bound in the unit interval. Taking a probabilistic\napproach, we define a prior belief over the LLMs' transition probabilities and\nobtain a posterior belief over the most promising paths in each iteration.\nThese beliefs are helpful to define a non-myopic Bayesian-optimization-like\nacquisition function that allows for a more data-efficient exploration scheme\nthan standard beam search. We discuss how to select the prior and demonstrate\nin on- and off-model experiments with recent large language models, including\nLlama-2-7b, that our method achieves higher efficiency than beam search: Our\nmethod achieves the same or a higher likelihood while expanding fewer nodes\nthan beam search.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"3maS6C4tyjumE-KnM4PiKR91T4HAb48706r1v8dhhLQ","pdfSize":"821354"}