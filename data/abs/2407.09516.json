{"id":"2407.09516","title":"An Actionability Assessment Tool for Explainable AI","authors":"Ronal Singh, Tim Miller, Liz Sonenberg, Eduardo Velloso, Frank Vetere,\n  Piers Howe, Paul Dourish","authorsParsed":[["Singh","Ronal",""],["Miller","Tim",""],["Sonenberg","Liz",""],["Velloso","Eduardo",""],["Vetere","Frank",""],["Howe","Piers",""],["Dourish","Paul",""]],"versions":[{"version":"v1","created":"Wed, 19 Jun 2024 02:20:29 GMT"}],"updateDate":"2024-07-16","timestamp":1718763629000,"abstract":"  In this paper, we introduce and evaluate a tool for researchers and\npractitioners to assess the actionability of information provided to users to\nsupport algorithmic recourse. While there are clear benefits of recourse from\nthe user's perspective, the notion of actionability in explainable AI research\nremains vague, and claims of `actionable' explainability techniques are based\non the researchers' intuition. Inspired by definitions and instruments for\nassessing actionability in other domains, we construct a seven-question tool\nand evaluate its effectiveness through two user studies. We show that the tool\ndiscriminates actionability across explanation types and that the distinctions\nalign with human judgements. We show the impact of context on actionability\nassessments, suggesting that domain-specific tool adaptations may foster more\nhuman-centred algorithmic systems. This is a significant step forward for\nresearch and practices into actionable explainability and algorithmic recourse,\nproviding the first clear human-centred definition and tool for assessing\nactionability in explainable AI.\n","subjects":["Computing Research Repository/Human-Computer Interaction"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"fICvlAYjJY_l_WRhu0qQhbHdpZ5imCGo65og_GnWcb4","pdfSize":"559012"}