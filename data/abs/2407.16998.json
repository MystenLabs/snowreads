{"id":"2407.16998","title":"Proximal Projection Method for Stable Linearly Constrained Optimization","authors":"Howard Heaton","authorsParsed":[["Heaton","Howard",""]],"versions":[{"version":"v1","created":"Wed, 24 Jul 2024 04:46:05 GMT"}],"updateDate":"2024-07-25","timestamp":1721796365000,"abstract":"  Many applications using large datasets require efficient methods for\nminimizing a proximable convex function subject to satisfying a set of linear\nconstraints within a specified tolerance. For this task, we present a proximal\nprojection (PP) algorithm, which is an instance of Douglas-Rachford splitting\nthat directly uses projections onto the set of constraints. Formal guarantees\nare presented to prove convergence of PP estimates to optimizers. Unlike many\nmethods that obtain feasibility asymptotically, each PP iterate is feasible.\nNumerically, we show PP either matches or outperforms alternatives (e.g.\nlinearized Bregman, primal dual hybrid gradient, proximal augmented Lagrangian,\nproximal gradient) on problems in basis pursuit, stable matrix completion,\nstable principal component pursuit, and the computation of earth mover's\ndistances.\n","subjects":["Mathematics/Optimization and Control"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"4KUruLuWM5gTLuzngXIM9CycY4tRT3m6GdJjJlH-Aps","pdfSize":"2028774","objectId":"0x63e816d62a4f4b87d490bfd7c609c24829232e8cfe76d8069dd655a15296a4f3","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
