{
  "id": "2412.00744",
  "title": "A Cross-Scene Benchmark for Open-World Drone Active Tracking",
  "authors": "Haowei Sun, Jinwu Hu, Zhirui Zhang, Haoyuan Tian, Xinze Xie, Yufeng\n  Wang, Zhuliang Yu, Xiaohua Xie, Mingkui Tan",
  "authorsParsed": [
    [
      "Sun",
      "Haowei",
      ""
    ],
    [
      "Hu",
      "Jinwu",
      ""
    ],
    [
      "Zhang",
      "Zhirui",
      ""
    ],
    [
      "Tian",
      "Haoyuan",
      ""
    ],
    [
      "Xie",
      "Xinze",
      ""
    ],
    [
      "Wang",
      "Yufeng",
      ""
    ],
    [
      "Yu",
      "Zhuliang",
      ""
    ],
    [
      "Xie",
      "Xiaohua",
      ""
    ],
    [
      "Tan",
      "Mingkui",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Sun, 1 Dec 2024 09:37:46 GMT"
    }
  ],
  "updateDate": "2024-12-03",
  "timestamp": 1733045866000,
  "abstract": "  Drone Visual Active Tracking aims to autonomously follow a target object by\ncontrolling the motion system based on visual observations, providing a more\npractical solution for effective tracking in dynamic environments. However,\naccurate Drone Visual Active Tracking using reinforcement learning remains\nchallenging due to the absence of a unified benchmark, the complexity of\nopen-world environments with frequent interference, and the diverse motion\nbehavior of dynamic targets. To address these issues, we propose a unified\ncross-scene cross-domain benchmark for open-world drone active tracking called\nDAT. The DAT benchmark provides 24 visually complex environments to assess the\nalgorithms' cross-scene and cross-domain generalization abilities, and\nhigh-fidelity modeling of realistic robot dynamics. Additionally, we propose a\nreinforcement learning-based drone tracking method called R-VAT, which aims to\nimprove the performance of drone tracking targets in complex scenarios.\nSpecifically, inspired by curriculum learning, we introduce a Curriculum-Based\nTraining strategy that progressively enhances the agent tracking performance in\nvast environments with complex interference. We design a goal-centered reward\nfunction to provide precise feedback to the drone agent, preventing targets\nfarther from the center of view from receiving higher rewards than closer ones.\nThis allows the drone to adapt to the diverse motion behavior of open-world\ntargets. Experiments demonstrate that the R-VAT has about 400% improvement over\nthe SOTA method in terms of the cumulative reward metric.\n",
  "subjects": [
    "Computer Science/Robotics",
    "Computer Science/Artificial Intelligence"
  ],
  "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
  "blobId": "uHOxgwDbFPwHfSy5RgHtQEU7dUGJxNZuSF3iCFq93vQ",
  "pdfSize": "5992528"
}