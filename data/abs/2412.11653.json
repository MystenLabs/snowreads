{"id":"2412.11653","title":"Self-Adaptive Paraphrasing and Preference Learning for Improved Claim\n  Verifiability","authors":"Amelie W\\\"uhrl and Roman Klinger","authorsParsed":[["WÃ¼hrl","Amelie",""],["Klinger","Roman",""]],"versions":[{"version":"v1","created":"Mon, 16 Dec 2024 10:54:57 GMT"}],"updateDate":"2024-12-17","timestamp":1734346497000,"abstract":"  In fact-checking, structure and phrasing of claims critically influence a\nmodel's ability to predict verdicts accurately. Social media content in\nparticular rarely serves as optimal input for verification systems, which\nnecessitates pre-processing to extract the claim from noisy context before fact\nchecking. Prior work suggests extracting a claim representation that humans\nfind to be checkworthy and verifiable. This has two limitations: (1) the format\nmay not be optimal for a fact-checking model, and (2), it requires annotated\ndata to learn the extraction task from. We address both issues and propose a\nmethod to extract claims that is not reliant on labeled training data. Instead,\nour self-adaptive approach only requires a black-box fact checking model and a\ngenerative language model (LM). Given a tweet, we iteratively optimize the LM\nto generate a claim paraphrase that increases the performance of a fact\nchecking model. By learning from preference pairs, we align the LM to the fact\nchecker using direct preference optimization. We show that this novel setup\nextracts a claim paraphrase that is more verifiable than their original social\nmedia formulations, and is on par with competitive baselines. For refuted\nclaims, our method consistently outperforms all baselines.\n","subjects":["Computer Science/Computation and Language"],"license":"http://creativecommons.org/licenses/by-sa/4.0/","blobId":"zv58B4_gzkc7lwk8_jUrsPGjIN2PkMJ7FbMqifxD_d4","pdfSize":"353663"}