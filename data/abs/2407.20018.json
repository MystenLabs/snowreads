{"id":"2407.20018","title":"Efficient Training of Large Language Models on Distributed\n  Infrastructures: A Survey","authors":"Jiangfei Duan, Shuo Zhang, Zerui Wang, Lijuan Jiang, Wenwen Qu,\n  Qinghao Hu, Guoteng Wang, Qizhen Weng, Hang Yan, Xingcheng Zhang, Xipeng Qiu,\n  Dahua Lin, Yonggang Wen, Xin Jin, Tianwei Zhang and Peng Sun","authorsParsed":[["Duan","Jiangfei",""],["Zhang","Shuo",""],["Wang","Zerui",""],["Jiang","Lijuan",""],["Qu","Wenwen",""],["Hu","Qinghao",""],["Wang","Guoteng",""],["Weng","Qizhen",""],["Yan","Hang",""],["Zhang","Xingcheng",""],["Qiu","Xipeng",""],["Lin","Dahua",""],["Wen","Yonggang",""],["Jin","Xin",""],["Zhang","Tianwei",""],["Sun","Peng",""]],"versions":[{"version":"v1","created":"Mon, 29 Jul 2024 13:53:27 GMT"}],"updateDate":"2024-07-30","timestamp":1722261207000,"abstract":"  Large Language Models (LLMs) like GPT and LLaMA are revolutionizing the AI\nindustry with their sophisticated capabilities. Training these models requires\nvast GPU clusters and significant computing time, posing major challenges in\nterms of scalability, efficiency, and reliability. This survey explores recent\nadvancements in training systems for LLMs, including innovations in training\ninfrastructure with AI accelerators, networking, storage, and scheduling.\nAdditionally, the survey covers parallelism strategies, as well as\noptimizations for computation, communication, and memory in distributed LLM\ntraining. It also includes approaches of maintaining system reliability over\nextended training periods. By examining current innovations and future\ndirections, this survey aims to provide valuable insights towards improving LLM\ntraining systems and tackling ongoing challenges. Furthermore, traditional\ndigital circuit-based computing systems face significant constraints in meeting\nthe computational demands of LLMs, highlighting the need for innovative\nsolutions such as optical computing and optical networks.\n","subjects":["Computing Research Repository/Distributed, Parallel, and Cluster Computing"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"Tsjr8468z1pOSJoi98gqo3iciK10LTMPnUywTt4l4vY","pdfSize":"1866434"}