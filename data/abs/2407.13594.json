{"id":"2407.13594","title":"Mechanistically Interpreting a Transformer-based 2-SAT Solver: An\n  Axiomatic Approach","authors":"Nils Palumbo, Ravi Mangal, Zifan Wang, Saranya Vijayakumar, Corina S.\n  Pasareanu, Somesh Jha","authorsParsed":[["Palumbo","Nils",""],["Mangal","Ravi",""],["Wang","Zifan",""],["Vijayakumar","Saranya",""],["Pasareanu","Corina S.",""],["Jha","Somesh",""]],"versions":[{"version":"v1","created":"Thu, 18 Jul 2024 15:32:44 GMT"}],"updateDate":"2024-07-19","timestamp":1721316764000,"abstract":"  Mechanistic interpretability aims to reverse engineer the computation\nperformed by a neural network in terms of its internal components. Although\nthere is a growing body of research on mechanistic interpretation of neural\nnetworks, the notion of a mechanistic interpretation itself is often ad-hoc.\nInspired by the notion of abstract interpretation from the program analysis\nliterature that aims to develop approximate semantics for programs, we give a\nset of axioms that formally characterize a mechanistic interpretation as a\ndescription that approximately captures the semantics of the neural network\nunder analysis in a compositional manner. We use these axioms to guide the\nmechanistic interpretability analysis of a Transformer-based model trained to\nsolve the well-known 2-SAT problem. We are able to reverse engineer the\nalgorithm learned by the model -- the model first parses the input formulas and\nthen evaluates their satisfiability via enumeration of different possible\nvaluations of the Boolean input variables. We also present evidence to support\nthat the mechanistic interpretation of the analyzed model indeed satisfies the\nstated axioms.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"1tVELzc2wviecC10-_s5tl5M7E0f0K8XqZ5dqXRQppc","pdfSize":"760766"}