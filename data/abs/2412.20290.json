{
  "id": "2412.20290",
  "title": "Transformer-Based Contrastive Meta-Learning For Low-Resource\n  Generalizable Activity Recognition",
  "authors": "Junyao Wang, Mohammad Abdullah Al Faruque",
  "authorsParsed": [
    [
      "Wang",
      "Junyao",
      ""
    ],
    [
      "Faruque",
      "Mohammad Abdullah Al",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Sat, 28 Dec 2024 21:57:12 GMT"
    }
  ],
  "updateDate": "2024-12-31",
  "timestamp": 1735423032000,
  "abstract": "  Deep learning has been widely adopted for human activity recognition (HAR)\nwhile generalizing a trained model across diverse users and scenarios remains\nchallenging due to distribution shifts. The inherent low-resource challenge in\nHAR, i.e., collecting and labeling adequate human-involved data can be\nprohibitively costly, further raising the difficulty of tackling DS. We propose\nTACO, a novel transformer-based contrastive meta-learning approach for\ngeneralizable HAR. TACO addresses DS by synthesizing virtual target domains in\ntraining with explicit consideration of model generalizability. Additionally,\nwe extract expressive feature with the attention mechanism of Transformer and\nincorporate the supervised contrastive loss function within our\nmeta-optimization to enhance representation learning. Our evaluation\ndemonstrates that TACO achieves notably better performance across various\nlow-resource DS scenarios.\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition",
    "Computer Science/Artificial Intelligence",
    "Computer Science/Machine Learning"
  ],
  "license": "http://creativecommons.org/publicdomain/zero/1.0/",
  "blobId": "WzqqYDGWc9roNTwIedrk0Y2zHZ050QgLhOAHlpQV0qw",
  "pdfSize": "658240"
}