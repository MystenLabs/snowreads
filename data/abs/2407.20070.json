{"id":"2407.20070","title":"An Interpretable Rule Creation Method for Black-Box Models based on\n  Surrogate Trees -- SRules","authors":"Mario Parr\\'on Verdasco and Esteban Garc\\'ia-Cuesta","authorsParsed":[["Verdasco","Mario Parrón",""],["García-Cuesta","Esteban",""]],"versions":[{"version":"v1","created":"Mon, 29 Jul 2024 14:56:56 GMT"}],"updateDate":"2024-07-30","timestamp":1722265016000,"abstract":"  As artificial intelligence (AI) systems become increasingly integrated into\ncritical decision-making processes, the need for transparent and interpretable\nmodels has become paramount. In this article we present a new ruleset creation\nmethod based on surrogate decision trees (SRules), designed to improve the\ninterpretability of black-box machine learning models. SRules balances the\naccuracy, coverage, and interpretability of machine learning models by\nrecursively creating surrogate interpretable decision tree models that\napproximate the decision boundaries of a complex model. We propose a systematic\nframework for generating concise and meaningful rules from these surrogate\nmodels, allowing stakeholders to understand and trust the AI system's\ndecision-making process. Our approach not only provides interpretable rules,\nbut also quantifies the confidence and coverage of these rules. The proposed\nmodel allows to adjust its parameters to counteract the lack of\ninterpretability by precision and coverage by allowing a near perfect fit and\nhigh interpretability of some parts of the model . The results show that SRules\nimproves on other state-of-the-art techniques and introduces the possibility of\ncreating highly interpretable specific rules for specific sub-parts of the\nmodel.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"CD3CxLjnIcLkMOE2Kj3MCJGFiO-gbanO6RTo1TA3PPg","pdfSize":"219265"}