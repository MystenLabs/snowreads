{
  "id": "2412.13163",
  "title": "C-FedRAG: A Confidential Federated Retrieval-Augmented Generation System",
  "authors": "Parker Addison, Minh-Tuan H. Nguyen, Tomislav Medan, Jinali Shah,\n  Mohammad T. Manzari, Brendan McElrone, Laksh Lalwani, Aboli More, Smita\n  Sharma, Holger R. Roth, Isaac Yang, Chester Chen, Daguang Xu, Yan Cheng,\n  Andrew Feng, Ziyue Xu",
  "authorsParsed": [
    [
      "Addison",
      "Parker",
      ""
    ],
    [
      "Nguyen",
      "Minh-Tuan H.",
      ""
    ],
    [
      "Medan",
      "Tomislav",
      ""
    ],
    [
      "Shah",
      "Jinali",
      ""
    ],
    [
      "Manzari",
      "Mohammad T.",
      ""
    ],
    [
      "McElrone",
      "Brendan",
      ""
    ],
    [
      "Lalwani",
      "Laksh",
      ""
    ],
    [
      "More",
      "Aboli",
      ""
    ],
    [
      "Sharma",
      "Smita",
      ""
    ],
    [
      "Roth",
      "Holger R.",
      ""
    ],
    [
      "Yang",
      "Isaac",
      ""
    ],
    [
      "Chen",
      "Chester",
      ""
    ],
    [
      "Xu",
      "Daguang",
      ""
    ],
    [
      "Cheng",
      "Yan",
      ""
    ],
    [
      "Feng",
      "Andrew",
      ""
    ],
    [
      "Xu",
      "Ziyue",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Tue, 17 Dec 2024 18:42:21 GMT"
    },
    {
      "version": "v2",
      "created": "Wed, 18 Dec 2024 21:26:14 GMT"
    }
  ],
  "updateDate": "2024-12-20",
  "timestamp": 1734460941000,
  "abstract": "  Organizations seeking to utilize Large Language Models (LLMs) for knowledge\nquerying and analysis often encounter challenges in maintaining an LLM\nfine-tuned on targeted, up-to-date information that keeps answers relevant and\ngrounded. Retrieval Augmented Generation (RAG) has quickly become a feasible\nsolution for organizations looking to overcome the challenges of maintaining\nproprietary models and to help reduce LLM hallucinations in their query\nresponses. However, RAG comes with its own issues regarding scaling data\npipelines across tiered-access and disparate data sources. In many scenarios,\nit is necessary to query beyond a single data silo to provide richer and more\nrelevant context for an LLM. Analyzing data sources within and across\norganizational trust boundaries is often limited by complex data-sharing\npolicies that prohibit centralized data storage, therefore, inhibit the fast\nand effective setup and scaling of RAG solutions. In this paper, we introduce\nConfidential Computing (CC) techniques as a solution for secure Federated\nRetrieval Augmented Generation (FedRAG). Our proposed Confidential FedRAG\nsystem (C-FedRAG) enables secure connection and scaling of a RAG workflows\nacross a decentralized network of data providers by ensuring context\nconfidentiality. We also demonstrate how to implement a C-FedRAG system using\nthe NVIDIA FLARE SDK and assess its performance using the MedRAG toolkit and\nMIRAGE benchmarking dataset.\n",
  "subjects": [
    "Computer Science/Distributed, Parallel, and Cluster Computing",
    "Computer Science/Information Retrieval"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "uOj8VBxr8o8d3EUB6lUYiBisZDMhgb2p6fZMkTsjZIU",
  "pdfSize": "894159"
}