{
  "id": "2412.16135",
  "title": "Can LLMs Obfuscate Code? A Systematic Analysis of Large Language Models\n  into Assembly Code Obfuscation",
  "authors": "Seyedreza Mohseni, Seyedali Mohammadi, Deepa Tilwani, Yash Saxena,\n  Gerald Ketu Ndawula, Sriram Vema, Edward Raff, Manas Gaur",
  "authorsParsed": [
    [
      "Mohseni",
      "Seyedreza",
      ""
    ],
    [
      "Mohammadi",
      "Seyedali",
      ""
    ],
    [
      "Tilwani",
      "Deepa",
      ""
    ],
    [
      "Saxena",
      "Yash",
      ""
    ],
    [
      "Ndawula",
      "Gerald Ketu",
      ""
    ],
    [
      "Vema",
      "Sriram",
      ""
    ],
    [
      "Raff",
      "Edward",
      ""
    ],
    [
      "Gaur",
      "Manas",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Fri, 20 Dec 2024 18:31:24 GMT"
    },
    {
      "version": "v2",
      "created": "Tue, 24 Dec 2024 17:50:01 GMT"
    },
    {
      "version": "v3",
      "created": "Wed, 29 Jan 2025 13:52:31 GMT"
    }
  ],
  "updateDate": "2025-01-30",
  "timestamp": 1734719484000,
  "abstract": "  Malware authors often employ code obfuscations to make their malware harder\nto detect. Existing tools for generating obfuscated code often require access\nto the original source code (e.g., C++ or Java), and adding new obfuscations is\na non-trivial, labor-intensive process. In this study, we ask the following\nquestion: Can Large Language Models (LLMs) potentially generate a new\nobfuscated assembly code? If so, this poses a risk to anti-virus engines and\npotentially increases the flexibility of attackers to create new obfuscation\npatterns. We answer this in the affirmative by developing the MetamorphASM\nbenchmark comprising MetamorphASM Dataset (MAD) along with three code\nobfuscation techniques: dead code, register substitution, and control flow\nchange. The MetamorphASM systematically evaluates the ability of LLMs to\ngenerate and analyze obfuscated code using MAD, which contains 328,200\nobfuscated assembly code samples. We release this dataset and analyze the\nsuccess rate of various LLMs (e.g., GPT-3.5/4, GPT-4o-mini, Starcoder,\nCodeGemma, CodeLlama, CodeT5, and LLaMA 3.1) in generating obfuscated assembly\ncode. The evaluation was performed using established information-theoretic\nmetrics and manual human review to ensure correctness and provide the\nfoundation for researchers to study and develop remediations to this risk.\n",
  "subjects": [
    "Computer Science/Cryptography and Security",
    "Computer Science/Artificial Intelligence",
    "Computer Science/Computation and Language"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "CxS1r61QVGtV4xgjneiV7Hk-TEHkMZUfPrNneZ4px-k",
  "pdfSize": "627794"
}