{
  "id": "2412.14672",
  "title": "FiVL: A Framework for Improved Vision-Language Alignment",
  "authors": "Estelle Aflalo, Gabriela Ben Melech Stan, Tiep Le, Man Luo, Shachar\n  Rosenman, Sayak Paul, Shao-Yen Tseng, Vasudev Lal",
  "authorsParsed": [
    [
      "Aflalo",
      "Estelle",
      ""
    ],
    [
      "Stan",
      "Gabriela Ben Melech",
      ""
    ],
    [
      "Le",
      "Tiep",
      ""
    ],
    [
      "Luo",
      "Man",
      ""
    ],
    [
      "Rosenman",
      "Shachar",
      ""
    ],
    [
      "Paul",
      "Sayak",
      ""
    ],
    [
      "Tseng",
      "Shao-Yen",
      ""
    ],
    [
      "Lal",
      "Vasudev",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Thu, 19 Dec 2024 09:24:10 GMT"
    }
  ],
  "updateDate": "2024-12-20",
  "timestamp": 1734600250000,
  "abstract": "  Large Vision Language Models (LVLMs) have achieved significant progress in\nintegrating visual and textual inputs for multimodal reasoning. However, a\nrecurring challenge is ensuring these models utilize visual information as\neffectively as linguistic content when both modalities are necessary to\nformulate an accurate answer. We hypothesize that hallucinations arise due to\nthe lack of effective visual grounding in current LVLMs. This issue extends to\nvision-language benchmarks, where it is difficult to make the image\nindispensable for accurate answer generation, particularly in vision\nquestion-answering tasks. In this work, we introduce FiVL, a novel method for\nconstructing datasets designed to train LVLMs for enhanced visual grounding and\nto evaluate their effectiveness in achieving it. These datasets can be utilized\nfor both training and assessing an LVLM's ability to use image content as\nsubstantive evidence rather than relying solely on linguistic priors, providing\ninsights into the model's reliance on visual information. To demonstrate the\nutility of our dataset, we introduce an innovative training task that\noutperforms baselines alongside a validation method and application for\nexplainability. The code is available at https://github.com/IntelLabs/fivl.\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition",
    "Computer Science/Artificial Intelligence"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "96WSMmft1jCpG5tBcm4kht6mxsrhi8FdCQvZ5oxZso4",
  "pdfSize": "5460904"
}