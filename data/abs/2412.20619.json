{"id":"2412.20619","title":"Audiopedia: Audio QA with Knowledge","authors":"Abhirama Subramanyam Penamakuri, Kiran Chhatre, Akshat Jain","authorsParsed":[["Penamakuri","Abhirama Subramanyam",""],["Chhatre","Kiran",""],["Jain","Akshat",""]],"versions":[{"version":"v1","created":"Sun, 29 Dec 2024 23:48:35 GMT"}],"updateDate":"2024-12-31","timestamp":1735516115000,"abstract":"  In this paper, we introduce Audiopedia, a novel task called Audio Question\nAnswering with Knowledge, which requires both audio comprehension and external\nknowledge reasoning. Unlike traditional Audio Question Answering (AQA)\nbenchmarks that focus on simple queries answerable from audio alone, Audiopedia\ntargets knowledge-intensive questions. We define three sub-tasks: (i) Single\nAudio Question Answering (s-AQA), where questions are answered based on a\nsingle audio sample, (ii) Multi-Audio Question Answering (m-AQA), which\nrequires reasoning over multiple audio samples, and (iii) Retrieval-Augmented\nAudio Question Answering (r-AQA), which involves retrieving relevant audio to\nanswer the question. We benchmark large audio language models (LALMs) on these\nsub-tasks and observe suboptimal performance. To address this, we propose a\ngeneric framework that can be adapted to any LALM, equipping them with\nknowledge reasoning capabilities. Our framework has two components: (i) Audio\nEntity Linking (AEL) and (ii) Knowledge-Augmented Audio Large Multimodal Model\n(KA2LM), which together improve performance on knowledge-intensive AQA tasks.\nTo our knowledge, this is the first work to address advanced audio\nunderstanding via knowledge-intensive tasks like Audiopedia.\n","subjects":["Computer Science/Machine Learning","Computer Science/Multimedia","Computer Science/Sound","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"VV8x2nCQzEOuV_jHtQwcwnpB-aFKy2m_1IO9iRoYga4","pdfSize":"649580"}