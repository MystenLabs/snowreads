{"id":"2407.09732","title":"Speech Slytherin: Examining the Performance and Efficiency of Mamba for\n  Speech Separation, Recognition, and Synthesis","authors":"Xilin Jiang, Yinghao Aaron Li, Adrian Nicolas Florea, Cong Han, Nima\n  Mesgarani","authorsParsed":[["Jiang","Xilin",""],["Li","Yinghao Aaron",""],["Florea","Adrian Nicolas",""],["Han","Cong",""],["Mesgarani","Nima",""]],"versions":[{"version":"v1","created":"Sat, 13 Jul 2024 00:35:21 GMT"}],"updateDate":"2024-07-16","timestamp":1720830921000,"abstract":"  It is too early to conclude that Mamba is a better alternative to\ntransformers for speech before comparing Mamba with transformers in terms of\nboth performance and efficiency in multiple speech-related tasks. To reach this\nconclusion, we propose and evaluate three models for three tasks: Mamba-TasNet\nfor speech separation, ConMamba for speech recognition, and VALL-M for speech\nsynthesis. We compare them with transformers of similar sizes in performance,\nmemory, and speed. Our Mamba or Mamba-transformer hybrid models show comparable\nor higher performance than their transformer counterparts: Sepformer,\nConformer, and VALL-E. They are more efficient than transformers in memory and\nspeed for speech longer than a threshold duration, inversely related to the\nresolution of a speech token. Mamba for separation is the most efficient, and\nMamba for recognition is the least. Further, we show that Mamba is not more\nefficient than transformer for speech shorter than the threshold duration and\nperforms worse in models that require joint modeling of text and speech, such\nas cross or masked attention of two inputs. Therefore, we argue that the\nsuperiority of Mamba or transformer depends on particular problems and models.\nCode available at https://github.com/xi-j/Mamba-TasNet and\nhttps://github.com/xi-j/Mamba-ASR.\n","subjects":["Electrical Engineering and Systems Science/Audio and Speech Processing","Computing Research Repository/Machine Learning","Computing Research Repository/Sound"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"1I-ryqjkFRlAGFZUsQC2waECA3oNvySSyc86cf12rAg","pdfSize":"6403238"}