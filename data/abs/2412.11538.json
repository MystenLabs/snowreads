{
  "id": "2412.11538",
  "title": "MERaLiON-SpeechEncoder: Towards a Speech Foundation Model for Singapore\n  and Beyond",
  "authors": "Muhammad Huzaifah, Geyu Lin, Tianchi Liu, Hardik B. Sailor, Kye Min\n  Tan, Tarun K. Vangani, Qiongqiong Wang, Jeremy H. M. Wong, Nancy F. Chen, Ai\n  Ti Aw",
  "authorsParsed": [
    [
      "Huzaifah",
      "Muhammad",
      ""
    ],
    [
      "Lin",
      "Geyu",
      ""
    ],
    [
      "Liu",
      "Tianchi",
      ""
    ],
    [
      "Sailor",
      "Hardik B.",
      ""
    ],
    [
      "Tan",
      "Kye Min",
      ""
    ],
    [
      "Vangani",
      "Tarun K.",
      ""
    ],
    [
      "Wang",
      "Qiongqiong",
      ""
    ],
    [
      "Wong",
      "Jeremy H. M.",
      ""
    ],
    [
      "Chen",
      "Nancy F.",
      ""
    ],
    [
      "Aw",
      "Ai Ti",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Mon, 16 Dec 2024 08:15:19 GMT"
    },
    {
      "version": "v2",
      "created": "Fri, 20 Dec 2024 09:12:47 GMT"
    }
  ],
  "updateDate": "2024-12-23",
  "timestamp": 1734336919000,
  "abstract": "  This technical report describes the MERaLiON-SpeechEncoder, a foundation\nmodel designed to support a wide range of downstream speech applications.\nDeveloped as part of Singapore's National Multimodal Large Language Model\nProgramme, the MERaLiON-SpeechEncoder is tailored to address the speech\nprocessing needs in Singapore and the surrounding Southeast Asian region. The\nmodel currently supports mainly English, including the variety spoken in\nSingapore. We are actively expanding our datasets to gradually cover other\nlanguages in subsequent releases. The MERaLiON-SpeechEncoder was pre-trained\nfrom scratch on 200,000 hours of unlabelled speech data using a self-supervised\nlearning approach based on masked language modelling. We describe our training\nprocedure and hyperparameter tuning experiments in detail below. Our evaluation\ndemonstrates improvements to spontaneous and Singapore speech benchmarks for\nspeech recognition, while remaining competitive to other state-of-the-art\nspeech encoders across ten other speech tasks. We commit to releasing our\nmodel, supporting broader research endeavours, both in Singapore and beyond.\n",
  "subjects": [
    "Computer Science/Computation and Language",
    "Computer Science/Artificial Intelligence",
    "Electrical Engineering and Systems Science/Audio and Speech Processing"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "UNWeUTs3xhk0wERTMnHBkXX-c1-UDkxBbZvvc23oAgc",
  "pdfSize": "1380154"
}