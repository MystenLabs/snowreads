{"id":"2407.19389","title":"FIARSE: Model-Heterogeneous Federated Learning via Importance-Aware\n  Submodel Extraction","authors":"Feijie Wu, Xingchen Wang, Yaqing Wang, Tianci Liu, Lu Su, Jing Gao","authorsParsed":[["Wu","Feijie",""],["Wang","Xingchen",""],["Wang","Yaqing",""],["Liu","Tianci",""],["Su","Lu",""],["Gao","Jing",""]],"versions":[{"version":"v1","created":"Sun, 28 Jul 2024 04:10:11 GMT"}],"updateDate":"2024-07-30","timestamp":1722139811000,"abstract":"  In federated learning (FL), accommodating clients' varied computational\ncapacities poses a challenge, often limiting the participation of those with\nconstrained resources in global model training. To address this issue, the\nconcept of model heterogeneity through submodel extraction has emerged,\noffering a tailored solution that aligns the model's complexity with each\nclient's computational capacity. In this work, we propose Federated\nImportance-Aware Submodel Extraction (FIARSE), a novel approach that\ndynamically adjusts submodels based on the importance of model parameters,\nthereby overcoming the limitations of previous static and dynamic submodel\nextraction methods. Compared to existing works, the proposed method offers a\ntheoretical foundation for the submodel extraction and eliminates the need for\nadditional information beyond the model parameters themselves to determine\nparameter importance, significantly reducing the overhead on clients. Extensive\nexperiments are conducted on various datasets to showcase superior performance\nof the proposed FIARSE.\n","subjects":["Computing Research Repository/Distributed, Parallel, and Cluster Computing","Computing Research Repository/Machine Learning","Mathematics/Optimization and Control"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"AWOWRTqqyG-HYGzwMgAA-QqKG0SUpm7VeCF8BaYEiL0","pdfSize":"985319"}