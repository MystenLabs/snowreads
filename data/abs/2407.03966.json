{"id":"2407.03966","title":"Serialized Output Training by Learned Dominance","authors":"Ying Shi, Lantian Li, Shi Yin, Dong Wang, Jiqing Han","authorsParsed":[["Shi","Ying",""],["Li","Lantian",""],["Yin","Shi",""],["Wang","Dong",""],["Han","Jiqing",""]],"versions":[{"version":"v1","created":"Thu, 4 Jul 2024 14:36:02 GMT"}],"updateDate":"2024-07-08","timestamp":1720103762000,"abstract":"  Serialized Output Training (SOT) has showcased state-of-the-art performance\nin multi-talker speech recognition by sequentially decoding the speech of\nindividual speakers. To address the challenging label-permutation issue, prior\nmethods have relied on either the Permutation Invariant Training (PIT) or the\ntime-based First-In-First-Out (FIFO) rule. This study presents a model-based\nserialization strategy that incorporates an auxiliary module into the Attention\nEncoder-Decoder architecture, autonomously identifying the crucial factors to\norder the output sequence of the speech components in multi-talker speech.\nExperiments conducted on the LibriSpeech and LibriMix databases reveal that our\napproach significantly outperforms the PIT and FIFO baselines in both 2-mix and\n3-mix scenarios. Further analysis shows that the serialization module\nidentifies dominant speech components in a mixture by factors including\nloudness and gender, and orders speech components based on the dominance score.\n","subjects":["Computing Research Repository/Sound","Computing Research Repository/Artificial Intelligence","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"2YD6pz5qbaICuuJVZJNsqALOFVg5vjP-8gM_WdIa2lI","pdfSize":"593956"}