{
  "id": "2412.18806",
  "title": "FOR: Finetuning for Object Level Open Vocabulary Image Retrieval",
  "authors": "Hila Levi, Guy Heller, Dan Levi",
  "authorsParsed": [
    [
      "Levi",
      "Hila",
      ""
    ],
    [
      "Heller",
      "Guy",
      ""
    ],
    [
      "Levi",
      "Dan",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Wed, 25 Dec 2024 07:08:51 GMT"
    }
  ],
  "updateDate": "2024-12-30",
  "timestamp": 1735110531000,
  "abstract": "  As working with large datasets becomes standard, the task of accurately\nretrieving images containing objects of interest by an open set textual query\ngains practical importance. The current leading approach utilizes a pre-trained\nCLIP model without any adaptation to the target domain, balancing accuracy and\nefficiency through additional post-processing. In this work, we propose FOR:\nFinetuning for Object-centric Open-vocabulary Image Retrieval, which allows\nfinetuning on a target dataset using closed-set labels while keeping the\nvisual-language association crucial for open vocabulary retrieval. FOR is based\non two design elements: a specialized decoder variant of the CLIP head\ncustomized for the intended task, and its coupling within a multi-objective\ntraining framework. Together, these design choices result in a significant\nincrease in accuracy, showcasing improvements of up to 8 mAP@50 points over\nSoTA across three datasets. Additionally, we demonstrate that FOR is also\neffective in a semi-supervised setting, achieving impressive results even when\nonly a small portion of the dataset is labeled.\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition",
    "Computer Science/Information Retrieval",
    "Computer Science/Machine Learning"
  ],
  "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
  "blobId": "gg2HC5RjUa8MB8ngutPy9Dyj4RHUukUvCOP-9N6fZ9Y",
  "pdfSize": "7459626"
}