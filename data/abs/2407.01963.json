{"id":"2407.01963","title":"Towards Unsupervised Speaker Diarization System for Multilingual\n  Telephone Calls Using Pre-trained Whisper Model and Mixture of Sparse\n  Autoencoders","authors":"Phat Lam, Lam Pham, Truong Nguyen, Dat Ngo, Thinh Pham, Tin Nguyen,\n  Loi Khanh Nguyen, Alexander Schindler","authorsParsed":[["Lam","Phat",""],["Pham","Lam",""],["Nguyen","Truong",""],["Ngo","Dat",""],["Pham","Thinh",""],["Nguyen","Tin",""],["Nguyen","Loi Khanh",""],["Schindler","Alexander",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 05:42:32 GMT"},{"version":"v2","created":"Mon, 8 Jul 2024 02:21:30 GMT"},{"version":"v3","created":"Thu, 12 Sep 2024 15:40:02 GMT"}],"updateDate":"2024-09-13","timestamp":1719898952000,"abstract":"  Existing speaker diarization systems typically rely on large amounts of\nmanually annotated data, which is labor-intensive and difficult to obtain,\nespecially in real-world scenarios. Additionally, language-specific constraints\nin these systems significantly hinder their effectiveness and scalability in\nmultilingual settings. In this paper, we propose a cluster-based speaker\ndiarization system designed for multilingual telephone call applications. Our\nproposed system supports multiple languages and eliminates the need for\nlarge-scale annotated data during training by utilizing the multilingual\nWhisper model to extract speaker embeddings. Additionally, we introduce a\nnetwork architecture called Mixture of Sparse Autoencoders (Mix-SAE) for\nunsupervised speaker clustering. Experimental results on the evaluation dataset\nderived from two-speaker subsets of benchmark CALLHOME and CALLFRIEND\ntelephonic speech corpora demonstrate the superior performance of the proposed\nMix-SAE network to other autoencoder-based clustering methods. The overall\nperformance of our proposed system also highlights the promising potential for\ndeveloping unsupervised, multilingual speaker diarization systems within the\ncontext of limited annotated data. It also indicates the system's capability\nfor integration into multi-task speech analysis applications based on\ngeneral-purpose models such as those that combine speech-to-text, language\ndetection, and speaker diarization.\n","subjects":["Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"TyggdluZ64rJK6QQkQZrwz2o6u1JgjsUEiJ3IvwAcYY","pdfSize":"1032932"}