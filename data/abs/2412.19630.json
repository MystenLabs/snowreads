{"id":"2412.19630","title":"IMTP: Search-based Code Generation for In-memory Tensor Programs","authors":"Yongwon Shin, Dookyung Kang, Hyojin Sung","authorsParsed":[["Shin","Yongwon",""],["Kang","Dookyung",""],["Sung","Hyojin",""]],"versions":[{"version":"v1","created":"Fri, 27 Dec 2024 13:19:35 GMT"}],"updateDate":"2024-12-30","timestamp":1735305575000,"abstract":"  Processing-in-DRAM (DRAM-PIM) has emerged as a promising technology for\naccelerating memory-intensive operations in modern applications, such as Large\nLanguage Models (LLMs). Despite its potential, current software stacks for\nDRAM-PIM face significant challenges, including reliance on hand-tuned\nlibraries that hinder programmability, limited support for high-level\nabstractions, and the lack of systematic optimization frameworks. To address\nthese limitations, we present IMTP, a search-based optimizing tensor compiler\nfor UPMEM. Key features of IMTP include: (1) automated searches of the joint\nsearch space for host and kernel tensor programs, (2) PIM-aware optimizations\nfor efficiently handling boundary conditions, and (3) improved search\nalgorithms for the expanded search space of UPMEM systems. Our experimental\nresults on UPMEM hardware demonstrate performance gains of up to 8.21x for\nvarious UPMEM benchmark kernels and 5.33x for GPT-J layers. To the best of our\nknowledge, IMTP is the first tensor compiler to provide fully automated,\nautotuning-integrated code generation support for a DRAM-PIM system. By\nbridging the gap between high-level tensor computation abstractions and\nlow-level hardware-specific requirements, IMTP establishes a foundation for\nadvancing DRAM-PIM programmability and enabling streamlined optimization.\n","subjects":["Computer Science/Hardware Architecture"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"fGjlX3g3k6AZOAJaAFUDuKXnKTgpyUi9Nw-robikEx0","pdfSize":"1872211"}