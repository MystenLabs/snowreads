{
  "id": "2412.17888",
  "title": "Stability Bounds for the Unfolded Forward-Backward Algorithm",
  "authors": "Emilie Chouzenoux, Cecile Della Valle, Jean-Christophe Pesquet",
  "authorsParsed": [
    [
      "Chouzenoux",
      "Emilie",
      ""
    ],
    [
      "Della Valle",
      "Cecile",
      ""
    ],
    [
      "Pesquet",
      "Jean-Christophe",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Mon, 23 Dec 2024 11:55:41 GMT"
    }
  ],
  "updateDate": "2024-12-25",
  "timestamp": 1734954941000,
  "abstract": "  We consider a neural network architecture designed to solve inverse problems\nwhere the degradation operator is linear and known. This architecture is\nconstructed by unrolling a forward-backward algorithm derived from the\nminimization of an objective function that combines a data-fidelity term, a\nTikhonov-type regularization term, and a potentially nonsmooth convex penalty.\nThe robustness of this inversion method to input perturbations is analyzed\ntheoretically. Ensuring robustness complies with the principles of inverse\nproblem theory, as it ensures both the continuity of the inversion method and\nthe resilience to small noise - a critical property given the known\nvulnerability of deep neural networks to adversarial perturbations. A key\nnovelty of our work lies in examining the robustness of the proposed network to\nperturbations in its bias, which represents the observed data in the inverse\nproblem. Additionally, we provide numerical illustrations of the analytical\nLipschitz bounds derived in our analysis.\n",
  "subjects": [
    "Mathematics/Optimization and Control",
    "Computer Science/Artificial Intelligence"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "wn-W7_0nP8G9cD7lyVOWoofzmavdVGRoSVDLVI8JKWA",
  "pdfSize": "1402809"
}