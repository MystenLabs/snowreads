{
  "id": "2412.00980",
  "title": "Incentivizing Truthful Collaboration in Heterogeneous Federated Learning",
  "authors": "Dimitar Chakarov, Nikita Tsoy, Kristian Minchev, Nikola Konstantinov",
  "authorsParsed": [
    [
      "Chakarov",
      "Dimitar",
      ""
    ],
    [
      "Tsoy",
      "Nikita",
      ""
    ],
    [
      "Minchev",
      "Kristian",
      ""
    ],
    [
      "Konstantinov",
      "Nikola",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Sun, 1 Dec 2024 22:04:12 GMT"
    }
  ],
  "updateDate": "2024-12-03",
  "timestamp": 1733090652000,
  "abstract": "  It is well-known that Federated Learning (FL) is vulnerable to manipulated\nupdates from clients. In this work we study the impact of data heterogeneity on\nclients' incentives to manipulate their updates. We formulate a game in which\nclients may upscale their gradient updates in order to ``steer'' the server\nmodel to their advantage. We develop a payment rule that disincentivizes\nsending large gradient updates, and steers the clients towards truthfully\nreporting their gradients. We also derive explicit bounds on the clients'\npayments and the convergence rate of the global model, which allows us to study\nthe trade-off between heterogeneity, payments and convergence.\n",
  "subjects": [
    "Computer Science/Machine Learning",
    "Computer Science/Computer Science and Game Theory",
    "Statistics/Machine Learning"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "4wdFEUlilkAtiDdk7BjGGJu5gtL82irwsSgVxEWKq2s",
  "pdfSize": "269276"
}