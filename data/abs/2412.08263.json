{"id":"2412.08263","title":"Discrete Subgraph Sampling for Interpretable Graph based Visual Question\n  Answering","authors":"Pascal Tilli and Ngoc Thang Vu","authorsParsed":[["Tilli","Pascal",""],["Vu","Ngoc Thang",""]],"versions":[{"version":"v1","created":"Wed, 11 Dec 2024 10:18:37 GMT"}],"updateDate":"2024-12-12","timestamp":1733912317000,"abstract":"  Explainable artificial intelligence (XAI) aims to make machine learning\nmodels more transparent. While many approaches focus on generating explanations\npost-hoc, interpretable approaches, which generate the explanations\nintrinsically alongside the predictions, are relatively rare. In this work, we\nintegrate different discrete subset sampling methods into a graph-based visual\nquestion answering system to compare their effectiveness in generating\ninterpretable explanatory subgraphs intrinsically. We evaluate the methods on\nthe GQA dataset and show that the integrated methods effectively mitigate the\nperformance trade-off between interpretability and answer accuracy, while also\nachieving strong co-occurrences between answer and question tokens.\nFurthermore, we conduct a human evaluation to assess the interpretability of\nthe generated subgraphs using a comparative setting with the extended\nBradley-Terry model, showing that the answer and question token co-occurrence\nmetrics strongly correlate with human preferences. Our source code is publicly\navailable.\n","subjects":["Computer Science/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"X4jXqB8FdSBMzbOWB14sUj7ClviO_5RGz9LmMyh_2Xw","pdfSize":"2847275"}