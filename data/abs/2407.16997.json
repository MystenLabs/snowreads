{"id":"2407.16997","title":"Revisiting Who's Harry Potter: Towards Targeted Unlearning from a Causal\n  Intervention Perspective","authors":"Yujian Liu, Yang Zhang, Tommi Jaakkola, Shiyu Chang","authorsParsed":[["Liu","Yujian",""],["Zhang","Yang",""],["Jaakkola","Tommi",""],["Chang","Shiyu",""]],"versions":[{"version":"v1","created":"Wed, 24 Jul 2024 04:39:24 GMT"}],"updateDate":"2024-07-25","timestamp":1721795964000,"abstract":"  This paper investigates Who's Harry Potter (WHP), a pioneering yet\ninsufficiently understood method for LLM unlearning. We explore it in two\nsteps. First, we introduce a new task of LLM targeted unlearning, where given\nan unlearning target (e.g., a person) and some unlearning documents, we aim to\nunlearn only the information about the target, rather than everything in the\nunlearning documents. We further argue that a successful unlearning should\nsatisfy criteria such as not outputting gibberish, not fabricating facts about\nthe unlearning target, and not releasing factual information under jailbreak\nattacks. Second, we construct a causal intervention framework for targeted\nunlearning, where the knowledge of the unlearning target is modeled as a\nconfounder between LLM input and output, and the unlearning process as a\ndeconfounding process. This framework justifies and extends WHP, deriving a\nsimple unlearning algorithm that includes WHP as a special case. Experiments on\nexisting and new datasets show that our approach, without explicitly optimizing\nfor the aforementioned criteria, achieves competitive performance in all of\nthem. Our code is available at\nhttps://github.com/UCSB-NLP-Chang/causal_unlearn.git.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"MdQM-GPlMgWU1S0J9cgy05Esi5crr4filYr0t97KYlw","pdfSize":"1011487"}