{
  "id": "2412.15177",
  "title": "Critical-Questions-of-Thought: Steering LLM reasoning with Argumentative\n  Querying",
  "authors": "Federico Castagna, Isabel Sassoon, Simon Parsons",
  "authorsParsed": [
    [
      "Castagna",
      "Federico",
      ""
    ],
    [
      "Sassoon",
      "Isabel",
      ""
    ],
    [
      "Parsons",
      "Simon",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Thu, 19 Dec 2024 18:51:30 GMT"
    }
  ],
  "updateDate": "2024-12-20",
  "timestamp": 1734634290000,
  "abstract": "  Studies have underscored how, regardless of the recent breakthrough and swift\nadvances in AI research, even state-of-the-art Large Language models (LLMs)\ncontinue to struggle when performing logical and mathematical reasoning. The\nresults seem to suggest that LLMs still work as (highly advanced) data pattern\nidentifiers, scoring poorly when attempting to generalise and solve reasoning\nproblems the models have never previously seen or that are not close to samples\npresented in their training data. To address this compelling concern, this\npaper makes use of the notion of critical questions from the literature on\nargumentation theory, focusing in particular on Toulmin's model of\nargumentation. We show that employing these critical questions can improve the\nreasoning capabilities of LLMs. By probing the rationale behind the models'\nreasoning process, the LLM can assess whether some logical mistake is occurring\nand correct it before providing the final reply to the user prompt. The\nunderlying idea is drawn from the gold standard of any valid argumentative\nprocedure: the conclusion is valid if it is entailed by accepted premises. Or,\nto paraphrase such Aristotelian principle in a real-world approximation,\ncharacterised by incomplete information and presumptive logic, the conclusion\nis valid if not proved otherwise. This approach successfully steers the models'\noutput through a reasoning pipeline, resulting in better performance against\nthe baseline and its Chain-of-Thought (CoT) implementation. To this end, an\nextensive evaluation of the proposed approach on the MT-Bench Reasoning and\nMath tasks across a range of LLMs is provided.\n",
  "subjects": [
    "Computer Science/Artificial Intelligence",
    "Computer Science/Computation and Language"
  ],
  "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
  "blobId": "AqYkP0i3pA736d_IU-JBY01i_DjPZ-XCTzm0N0nnOQ8",
  "pdfSize": "1223176"
}