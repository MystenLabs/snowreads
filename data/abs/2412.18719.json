{"id":"2412.18719","title":"Using Large Language Models for Automated Grading of Student Writing\n  about Science","authors":"Chris Impey, Matthew Wenger, Nikhil Garuda, Shahriar Golchin and Sarah\n  Stamer","authorsParsed":[["Impey","Chris",""],["Wenger","Matthew",""],["Garuda","Nikhil",""],["Golchin","Shahriar",""],["Stamer","Sarah",""]],"versions":[{"version":"v1","created":"Wed, 25 Dec 2024 00:31:53 GMT"}],"updateDate":"2025-01-24","timestamp":1735086713000,"abstract":"  Assessing writing in large classes for formal or informal learners presents a\nsignificant challenge. Consequently, most large classes, particularly in\nscience, rely on objective assessment tools such as multiple-choice quizzes,\nwhich have a single correct answer. The rapid development of AI has introduced\nthe possibility of using large language models (LLMs) to evaluate student\nwriting. An experiment was conducted using GPT-4 to determine if machine\nlearning methods based on LLMs can match or exceed the reliability of\ninstructor grading in evaluating short writing assignments on topics in\nastronomy. The audience consisted of adult learners in three massive open\nonline courses (MOOCs) offered through Coursera. One course was on astronomy,\nthe second was on astrobiology, and the third was on the history and philosophy\nof astronomy. The results should also be applicable to non-science majors in\nuniversity settings, where the content and modes of evaluation are similar. The\ndata comprised answers from 120 students to 12 questions across the three\ncourses. GPT-4 was provided with total grades, model answers, and rubrics from\nan instructor for all three courses. In addition to evaluating how reliably the\nLLM reproduced instructor grades, the LLM was also tasked with generating its\nown rubrics. Overall, the LLM was more reliable than peer grading, both in\naggregate and by individual student, and approximately matched instructor\ngrades for all three online courses. The implication is that LLMs may soon be\nused for automated, reliable, and scalable grading of student science writing.\n","subjects":["Computer Science/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"j9sMhRUt_VewYDojFXtDH9-WITJps_stOYX5DNt2HCs","pdfSize":"2431456"}