{
  "id": "2412.09220",
  "title": "USDRL: Unified Skeleton-Based Dense Representation Learning with\n  Multi-Grained Feature Decorrelation",
  "authors": "Wanjiang Weng, Hongsong Wang, Junbo Wang, Lei He, Guosen Xie",
  "authorsParsed": [
    [
      "Weng",
      "Wanjiang",
      ""
    ],
    [
      "Wang",
      "Hongsong",
      ""
    ],
    [
      "Wang",
      "Junbo",
      ""
    ],
    [
      "He",
      "Lei",
      ""
    ],
    [
      "Xie",
      "Guosen",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Thu, 12 Dec 2024 12:20:27 GMT"
    },
    {
      "version": "v2",
      "created": "Sat, 14 Dec 2024 05:42:51 GMT"
    }
  ],
  "updateDate": "2024-12-17",
  "timestamp": 1734006027000,
  "abstract": "  Contrastive learning has achieved great success in skeleton-based\nrepresentation learning recently. However, the prevailing methods are\npredominantly negative-based, necessitating additional momentum encoder and\nmemory bank to get negative samples, which increases the difficulty of model\ntraining. Furthermore, these methods primarily concentrate on learning a global\nrepresentation for recognition and retrieval tasks, while overlooking the rich\nand detailed local representations that are crucial for dense prediction tasks.\nTo alleviate these issues, we introduce a Unified Skeleton-based Dense\nRepresentation Learning framework based on feature decorrelation, called USDRL,\nwhich employs feature decorrelation across temporal, spatial, and instance\ndomains in a multi-grained manner to reduce redundancy among dimensions of the\nrepresentations to maximize information extraction from features. Additionally,\nwe design a Dense Spatio-Temporal Encoder (DSTE) to capture fine-grained action\nrepresentations effectively, thereby enhancing the performance of dense\nprediction tasks. Comprehensive experiments, conducted on the benchmarks\nNTU-60, NTU-120, PKU-MMD I, and PKU-MMD II, across diverse downstream tasks\nincluding action recognition, action retrieval, and action detection,\nconclusively demonstrate that our approach significantly outperforms the\ncurrent state-of-the-art (SOTA) approaches. Our code and models are available\nat https://github.com/wengwanjiang/USDRL.\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "Vqsfdti57EG7kyZwsFaIIsboxVJVPK8sIpKrlb9hRlw",
  "pdfSize": "3154262"
}