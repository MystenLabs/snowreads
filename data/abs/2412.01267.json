{"id":"2412.01267","title":"EdgeOAR: Real-time Online Action Recognition On Edge Devices","authors":"Wei Luo, Deyu Zhang, Ying Tang, Fan Wu, Yaoxue Zhang","authorsParsed":[["Luo","Wei",""],["Zhang","Deyu",""],["Tang","Ying",""],["Wu","Fan",""],["Zhang","Yaoxue",""]],"versions":[{"version":"v1","created":"Mon, 2 Dec 2024 08:35:22 GMT"}],"updateDate":"2024-12-03","timestamp":1733128522000,"abstract":"  This paper addresses the challenges of Online Action Recognition (OAR), a\nframework that involves instantaneous analysis and classification of behaviors\nin video streams. OAR must operate under stringent latency constraints, making\nit an indispensable component for real-time feedback for edge computing.\nExisting methods, which typically rely on the processing of entire video clips,\nfall short in scenarios requiring immediate recognition. To address this, we\ndesigned EdgeOAR, a novel framework specifically designed for OAR on edge\ndevices. EdgeOAR includes the Early Exit-oriented Task-specific Feature\nEnhancement Module (TFEM), which comprises lightweight submodules to optimize\nfeatures in both temporal and spatial dimensions. We design an iterative\ntraining method to enable TFEM learning features from the beginning of the\nvideo. Additionally, EdgeOAR includes an Inverse Information Entropy (IIE) and\nModality Consistency (MC)-driven fusion module to fuse features and make better\nexit decisions. This design overcomes the two main challenges: robust modeling\nof spatio-temporal action representations with limited initial frames in online\nvideo streams and balancing accuracy and efficiency on resource-constrained\nedge devices. Experiments show that on the UCF-101 dataset, our method EdgeOAR\nreduces latency by 99.23% and energy consumption by 99.28% compared to\nstate-of-the-art (SOTA) method. And achieves an adequate accuracy on edge\ndevices.\n","subjects":["Computer Science/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"BAxTx6rIW-volVc-ZqY_FWsmmq86kjMWK_WWJi6kBsI","pdfSize":"2508114"}