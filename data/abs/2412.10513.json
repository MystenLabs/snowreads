{"id":"2412.10513","title":"Extracting PAC Decision Trees from Black Box Binary Classifiers: The\n  Gender Bias Study Case on BERT-based Language Models","authors":"Ana Ozaki, Roberto Confalonieri, Ricardo Guimar\\~aes, Anders Imenes","authorsParsed":[["Ozaki","Ana",""],["Confalonieri","Roberto",""],["Guimar√£es","Ricardo",""],["Imenes","Anders",""]],"versions":[{"version":"v1","created":"Fri, 13 Dec 2024 19:14:08 GMT"}],"updateDate":"2024-12-17","timestamp":1734117248000,"abstract":"  Decision trees are a popular machine learning method, known for their\ninherent explainability. In Explainable AI, decision trees can be used as\nsurrogate models for complex black box AI models or as approximations of parts\nof such models. A key challenge of this approach is determining how accurately\nthe extracted decision tree represents the original model and to what extent it\ncan be trusted as an approximation of their behavior. In this work, we\ninvestigate the use of the Probably Approximately Correct (PAC) framework to\nprovide a theoretical guarantee of fidelity for decision trees extracted from\nAI models. Based on theoretical results from the PAC framework, we adapt a\ndecision tree algorithm to ensure a PAC guarantee under certain conditions. We\nfocus on binary classification and conduct experiments where we extract\ndecision trees from BERT-based language models with PAC guarantees. Our results\nindicate occupational gender bias in these models.\n","subjects":["Computer Science/Artificial Intelligence","Computer Science/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"Y8oKok8YeMJwt_AQpR_9v8Jc1boRA7hvVirGAAGimmY","pdfSize":"1321360"}