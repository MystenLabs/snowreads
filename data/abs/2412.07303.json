{"id":"2412.07303","title":"Filipino Benchmarks for Measuring Sexist and Homophobic Bias in\n  Multilingual Language Models from Southeast Asia","authors":"Lance Calvin Lim Gamboa, Mark Lee","authorsParsed":[["Gamboa","Lance Calvin Lim",""],["Lee","Mark",""]],"versions":[{"version":"v1","created":"Tue, 10 Dec 2024 08:31:52 GMT"},{"version":"v2","created":"Wed, 11 Dec 2024 14:43:31 GMT"}],"updateDate":"2024-12-12","timestamp":1733819512000,"abstract":"  Bias studies on multilingual models confirm the presence of gender-related\nstereotypes in masked models processing languages with high NLP resources. We\nexpand on this line of research by introducing Filipino CrowS-Pairs and\nFilipino WinoQueer: benchmarks that assess both sexist and anti-queer biases in\npretrained language models (PLMs) handling texts in Filipino, a low-resource\nlanguage from the Philippines. The benchmarks consist of 7,074 new challenge\npairs resulting from our cultural adaptation of English bias evaluation\ndatasets, a process that we document in detail to guide similar forthcoming\nefforts. We apply the Filipino benchmarks on masked and causal multilingual\nmodels, including those pretrained on Southeast Asian data, and find that they\ncontain considerable amounts of bias. We also find that for multilingual\nmodels, the extent of bias learned for a particular language is influenced by\nhow much pretraining data in that language a model was exposed to. Our\nbenchmarks and insights can serve as a foundation for future work analyzing and\nmitigating bias in multilingual models.\n","subjects":["Computer Science/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"kZqOVIOGNjauGlibaRz3bSWqnzGZ9Ih_CuL-cS0xv4E","pdfSize":"339066"}