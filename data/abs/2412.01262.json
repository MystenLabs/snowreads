{"id":"2412.01262","title":"Do Large Language Models with Reasoning and Acting Meet the Needs of\n  Task-Oriented Dialogue?","authors":"Michelle Elizabeth, Morgan Veyret, Miguel Couceiro, Ondrej Dusek and\n  Lina M. Rojas-Barahona","authorsParsed":[["Elizabeth","Michelle",""],["Veyret","Morgan",""],["Couceiro","Miguel",""],["Dusek","Ondrej",""],["Rojas-Barahona","Lina M.",""]],"versions":[{"version":"v1","created":"Mon, 2 Dec 2024 08:30:22 GMT"}],"updateDate":"2024-12-03","timestamp":1733128222000,"abstract":"  Large language models (LLMs) gained immense popularity due to their\nimpressive capabilities in unstructured conversations. However, they\nunderperform compared to previous approaches in task-oriented dialogue (TOD),\nwherein reasoning and accessing external information are crucial. Empowering\nLLMs with advanced prompting strategies such as reasoning and acting (ReAct)\nhas shown promise in solving complex tasks traditionally requiring\nreinforcement learning. In this work, we apply the ReAct strategy to guide LLMs\nperforming TOD. We evaluate ReAct-based LLMs (ReAct-LLMs) both in simulation\nand with real users. While ReAct-LLMs seem to underperform state-of-the-art\napproaches in simulation, human evaluation indicates higher user satisfaction\nrate compared to handcrafted systems despite having a lower success rate.\n","subjects":["Computer Science/Computation and Language","Computer Science/Artificial Intelligence","Computer Science/Human-Computer Interaction"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"yJwN-6G8z1fwYFRpc0tBNO3SYATNsV5HgFP6X4_FeiE","pdfSize":"276504"}