{
  "id": "2412.13488",
  "title": "Refining Salience-Aware Sparse Fine-Tuning Strategies for Language\n  Models",
  "authors": "Xinxin Liu, Aaron Thomas, Cheng Zhang, Jianyi Cheng, Yiren Zhao,\n  Xitong Gao",
  "authorsParsed": [
    [
      "Liu",
      "Xinxin",
      ""
    ],
    [
      "Thomas",
      "Aaron",
      ""
    ],
    [
      "Zhang",
      "Cheng",
      ""
    ],
    [
      "Cheng",
      "Jianyi",
      ""
    ],
    [
      "Zhao",
      "Yiren",
      ""
    ],
    [
      "Gao",
      "Xitong",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Wed, 18 Dec 2024 04:14:35 GMT"
    }
  ],
  "updateDate": "2024-12-19",
  "timestamp": 1734495275000,
  "abstract": "  Parameter-Efficient Fine-Tuning (PEFT) has gained prominence through low-rank\nadaptation methods like LoRA. In this paper, we focus on sparsity-based PEFT\n(SPEFT), which introduces trainable sparse adaptations to the weight matrices\nin the model, offering greater flexibility in selecting fine-tuned parameters\ncompared to low-rank methods. We conduct the first systematic evaluation of\nsalience metrics for SPEFT, inspired by zero-cost NAS proxies, and identify\nsimple gradient-based metrics is reliable, and results are on par with the best\nalternatives, offering both computational efficiency and robust performance.\nAdditionally, we compare static and dynamic masking strategies, finding that\nstatic masking, which predetermines non-zero entries before training, delivers\nefficiency without sacrificing performance, while dynamic masking offers no\nsubstantial benefits. Across NLP tasks, a simple gradient-based, static SPEFT\nconsistently outperforms other fine-tuning methods for LLMs, providing a simple\nyet effective baseline for SPEFT. Our work challenges the notion that\ncomplexity is necessary for effective PEFT. Our work is open source and\navailable to the community at [https://github.com/0-ml/speft].\n",
  "subjects": [
    "Computer Science/Computation and Language",
    "Computer Science/Artificial Intelligence"
  ],
  "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
  "blobId": "KJ-xBFnjqSk6mqzukszc0KDFlwyrp6UPsKpGRubStTI",
  "pdfSize": "1497264"
}