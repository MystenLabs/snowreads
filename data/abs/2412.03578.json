{"id":"2412.03578","title":"PerfCodeGen: Improving Performance of LLM Generated Code with Execution\n  Feedback","authors":"Yun Peng, Akhilesh Deepak Gotmare, Michael Lyu, Caiming Xiong, Silvio\n  Savarese, Doyen Sahoo","authorsParsed":[["Peng","Yun",""],["Gotmare","Akhilesh Deepak",""],["Lyu","Michael",""],["Xiong","Caiming",""],["Savarese","Silvio",""],["Sahoo","Doyen",""]],"versions":[{"version":"v1","created":"Mon, 18 Nov 2024 06:22:38 GMT"}],"updateDate":"2024-12-06","timestamp":1731910958000,"abstract":"  Large Language Models (LLMs) are widely adopted for assisting in software\ndevelopment tasks, yet their performance evaluations have narrowly focused on\nthe functional correctness of generated code. Human programmers, however,\nrequire LLM-generated code to be not only correct but also optimally efficient.\nWe propose PerfCodeGen, a training-free framework that enhances the performance\nof LLM-generated code by incorporating feedback based on runtime during test\ncase execution into the self-refinement iterations. With PerfCodeGen, we\nachieve speedups for a significantly higher proportion of problems compared to\nusing the base LLM with sophisticated prompting techniques. Applied to open\nlanguage models like Phi-3-mini, PerfCodeGen achieves runtime efficiency\ncomparable to prompting powerful closed models like GPT-4. We achieve\nstate-of-the-art runtime efficiency on benchmarks such as HumanEval, MBPP, and\nAPPS, frequently surpassing the ground truth reference solutions with\nPerfCodeGen using GPT-3.5 and GPT-4. Additionally, we demonstrate the\neffectiveness of our approach in enhancing code quality across a range of open\nLLMs of varying sizes including Phi-3-mini, Llama 3 8B, Mixtral 8x7B, Command\nR, and Llama 3 70B.\n","subjects":["Computer Science/Software Engineering","Computer Science/Artificial Intelligence","Computer Science/Computation and Language","Computer Science/Programming Languages"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"Wsf3ukXD7_q0aYP__d0HRsXgt__3xjN5l7INj8WkFaQ","pdfSize":"513008"}