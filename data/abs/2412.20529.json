{
  "id": "2412.20529",
  "title": "Attacks on the neural network and defense methods",
  "authors": "A. Korenev, G. Belokrylov, B. Lodonova, A. Novokhrestov",
  "authorsParsed": [
    [
      "Korenev",
      "A.",
      ""
    ],
    [
      "Belokrylov",
      "G.",
      ""
    ],
    [
      "Lodonova",
      "B.",
      ""
    ],
    [
      "Novokhrestov",
      "A.",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Sun, 29 Dec 2024 17:33:04 GMT"
    }
  ],
  "updateDate": "2024-12-31",
  "timestamp": 1735493584000,
  "abstract": "  This article will discuss the use of attacks on a neural network trained on\naudio data, as well as possible methods of protection against these attacks.\nFGSM, PGD and CW attacks, as well as data poisoning, will be considered. Within\nthe framework of protection, Art-IBM and advertorch libraries will be\nconsidered. The obtained accuracy metrics within the framework of attack\napplications are presented\n",
  "subjects": [
    "Computer Science/Cryptography and Security",
    "Computer Science/Artificial Intelligence"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "a31URZ_E_xbgMco5dd-60aH5IkywZPx_EncSx2EE2l8",
  "pdfSize": "130792"
}