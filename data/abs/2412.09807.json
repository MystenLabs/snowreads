{
  "id": "2412.09807",
  "title": "LLM Distillation for Efficient Few-Shot Multiple Choice Question\n  Answering",
  "authors": "Patrick Sutanto, Joan Santoso, Esther Irawati Setiawan, Aji Prasetya\n  Wibawa",
  "authorsParsed": [
    [
      "Sutanto",
      "Patrick",
      ""
    ],
    [
      "Santoso",
      "Joan",
      ""
    ],
    [
      "Setiawan",
      "Esther Irawati",
      ""
    ],
    [
      "Wibawa",
      "Aji Prasetya",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Fri, 13 Dec 2024 02:48:36 GMT"
    },
    {
      "version": "v2",
      "created": "Mon, 30 Dec 2024 16:45:50 GMT"
    }
  ],
  "updateDate": "2024-12-31",
  "timestamp": 1734058116000,
  "abstract": "  Multiple Choice Question Answering (MCQA) is an important problem with\nnumerous real-world applications, such as medicine, law, and education. The\nhigh cost of building MCQA datasets makes few-shot learning pivotal in this\ndomain. While Large Language Models (LLMs) can enable few-shot learning, their\ndirect application in real-world scenarios is often hindered by their high\ncomputational cost. To address this challenge, we propose a simple yet\neffective approach that uses LLMs for data generation and scoring. Our approach\nutilizes LLMs to create MCQA data which contains questions and choices, and to\nassign probability scores to the generated choices. We then use the generated\ndata and LLM-assigned scores to finetune a smaller and more efficient\nencoder-only model, DeBERTa-v3-base by leveraging distillation loss. Extensive\nexperiments on the Massive Multitask Language Understanding (MMLU) benchmark\ndemonstrate that our method improves accuracy from 28.9% to 39.3%, representing\na gain of over 10% compared to a baseline finetuned directly on 5-shot\nexamples. This shows the effectiveness of LLM-driven data generation and\nknowledge distillation for few-shot MCQA.\n",
  "subjects": [
    "Computer Science/Computation and Language"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "-21PSKuDs506RFlF6Mpwa952on5WTNBh9OUFw_nGETU",
  "pdfSize": "478706"
}