{"id":"2407.09336","title":"Guidelines for Augmentation Selection in Contrastive Learning for Time\n  Series Classification","authors":"Ziyu Liu, Azadeh Alavi, Minyi Li, Xiang Zhang","authorsParsed":[["Liu","Ziyu",""],["Alavi","Azadeh",""],["Li","Minyi",""],["Zhang","Xiang",""]],"versions":[{"version":"v1","created":"Fri, 12 Jul 2024 15:13:16 GMT"}],"updateDate":"2024-07-15","timestamp":1720797196000,"abstract":"  Self-supervised contrastive learning has become a key technique in deep\nlearning, particularly in time series analysis, due to its ability to learn\nmeaningful representations without explicit supervision. Augmentation is a\ncritical component in contrastive learning, where different augmentations can\ndramatically impact performance, sometimes influencing accuracy by over 30%.\nHowever, the selection of augmentations is predominantly empirical which can be\nsuboptimal, or grid searching that is time-consuming. In this paper, we\nestablish a principled framework for selecting augmentations based on dataset\ncharacteristics such as trend and seasonality. Specifically, we construct 12\nsynthetic datasets incorporating trend, seasonality, and integration weights.\nWe then evaluate the effectiveness of 8 different augmentations across these\nsynthetic datasets, thereby inducing generalizable associations between time\nseries characteristics and augmentation efficiency. Additionally, we evaluated\nthe induced associations across 6 real-world datasets encompassing domains such\nas activity recognition, disease diagnosis, traffic monitoring, electricity\nusage, mechanical fault prognosis, and finance. These real-world datasets are\ndiverse, covering a range from 1 to 12 channels, 2 to 10 classes, sequence\nlengths of 14 to 1280, and data frequencies from 250 Hz to daily intervals. The\nexperimental results show that our proposed trend-seasonality-based\naugmentation recommendation algorithm can accurately identify the effective\naugmentations for a given time series dataset, achieving an average Recall@3 of\n0.667, outperforming baselines. Our work provides guidance for studies\nemploying contrastive learning in time series analysis, with wide-ranging\napplications. All the code, datasets, and analysis results will be released at\nhttps://github.com/DL4mHealth/TS-Contrastive-Augmentation-Recommendation.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"vlBb87hdgF3Q04gyBa-R4PlpHgH5NbSX_WhDGLJxV3U","pdfSize":"2829928"}