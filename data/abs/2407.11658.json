{"id":"2407.11658","title":"Exciting Action: Investigating Efficient Exploration for Learning\n  Musculoskeletal Humanoid Locomotion","authors":"Henri-Jacques Gei{\\ss}, Firas Al-Hafez, Andre Seyfarth, Jan Peters,\n  Davide Tateo","authorsParsed":[["Gei√ü","Henri-Jacques",""],["Al-Hafez","Firas",""],["Seyfarth","Andre",""],["Peters","Jan",""],["Tateo","Davide",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 12:27:55 GMT"}],"updateDate":"2024-07-17","timestamp":1721132875000,"abstract":"  Learning a locomotion controller for a musculoskeletal system is challenging\ndue to over-actuation and high-dimensional action space. While many\nreinforcement learning methods attempt to address this issue, they often\nstruggle to learn human-like gaits because of the complexity involved in\nengineering an effective reward function. In this paper, we demonstrate that\nadversarial imitation learning can address this issue by analyzing key problems\nand providing solutions using both current literature and novel techniques. We\nvalidate our methodology by learning walking and running gaits on a simulated\nhumanoid model with 16 degrees of freedom and 92 Muscle-Tendon Units, achieving\nnatural-looking gaits with only a few demonstrations.\n","subjects":["Computing Research Repository/Robotics","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by-sa/4.0/","blobId":"OTcjOAFfZmv9iZQPDi6nES9omG-iZAcPjecXN9TkHm8","pdfSize":"1774295","objectId":"0xf8dab5dd210385777d28f8629c04aa8cb9ef94f50ba590fe01bfd989b77a29e7","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
