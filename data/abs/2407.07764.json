{"id":"2407.07764","title":"PosFormer: Recognizing Complex Handwritten Mathematical Expression with\n  Position Forest Transformer","authors":"Tongkun Guan, Chengyu Lin, Wei Shen, and Xiaokang Yang","authorsParsed":[["Guan","Tongkun",""],["Lin","Chengyu",""],["Shen","Wei",""],["Yang","Xiaokang",""]],"versions":[{"version":"v1","created":"Wed, 10 Jul 2024 15:42:58 GMT"}],"updateDate":"2024-07-11","timestamp":1720626178000,"abstract":"  Handwritten Mathematical Expression Recognition (HMER) has wide applications\nin human-machine interaction scenarios, such as digitized education and\nautomated offices. Recently, sequence-based models with encoder-decoder\narchitectures have been commonly adopted to address this task by directly\npredicting LaTeX sequences of expression images. However, these methods only\nimplicitly learn the syntax rules provided by LaTeX, which may fail to describe\nthe position and hierarchical relationship between symbols due to complex\nstructural relations and diverse handwriting styles. To overcome this\nchallenge, we propose a position forest transformer (PosFormer) for HMER, which\njointly optimizes two tasks: expression recognition and position recognition,\nto explicitly enable position-aware symbol feature representation learning.\nSpecifically, we first design a position forest that models the mathematical\nexpression as a forest structure and parses the relative position relationships\nbetween symbols. Without requiring extra annotations, each symbol is assigned a\nposition identifier in the forest to denote its relative spatial position.\nSecond, we propose an implicit attention correction module to accurately\ncapture attention for HMER in the sequence-based decoder architecture.\nExtensive experiments validate the superiority of PosFormer, which consistently\noutperforms the state-of-the-art methods 2.03%/1.22%/2.00%, 1.83%, and 4.62%\ngains on the single-line CROHME 2014/2016/2019, multi-line M2E, and complex MNE\ndatasets, respectively, with no additional latency or computational cost. Code\nis available at https://github.com/SJTU-DeepVisionLab/PosFormer.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"qz39l4pfx1qgsgtc95whClZ7pDmfDr-xWLHUVUKXzJI","pdfSize":"1531904"}