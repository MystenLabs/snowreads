{
  "id": "2412.07646",
  "title": "Searching for Structure: Investigating Emergent Communication with Large\n  Language Models",
  "authors": "Tom Kouwenhoven, Max Peeperkorn, Tessa Verhoef",
  "authorsParsed": [
    [
      "Kouwenhoven",
      "Tom",
      ""
    ],
    [
      "Peeperkorn",
      "Max",
      ""
    ],
    [
      "Verhoef",
      "Tessa",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Tue, 10 Dec 2024 16:32:19 GMT"
    },
    {
      "version": "v2",
      "created": "Wed, 11 Dec 2024 12:50:03 GMT"
    },
    {
      "version": "v3",
      "created": "Fri, 13 Dec 2024 12:35:21 GMT"
    }
  ],
  "updateDate": "2024-12-16",
  "timestamp": 1733848339000,
  "abstract": "  Human languages have evolved to be structured through repeated language\nlearning and use. These processes introduce biases that operate during language\nacquisition and shape linguistic systems toward communicative efficiency. In\nthis paper, we investigate whether the same happens if artificial languages are\noptimised for implicit biases of Large Language Models (LLMs). To this end, we\nsimulate a classical referential game in which LLMs learn and use artificial\nlanguages. Our results show that initially unstructured holistic languages are\nindeed shaped to have some structural properties that allow two LLM agents to\ncommunicate successfully. Similar to observations in human experiments,\ngenerational transmission increases the learnability of languages, but can at\nthe same time result in non-humanlike degenerate vocabularies. Taken together,\nthis work extends experimental findings, shows that LLMs can be used as tools\nin simulations of language evolution, and opens possibilities for future\nhuman-machine experiments in this field.\n",
  "subjects": [
    "Computer Science/Computation and Language"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "aaekdXLGhEdYxQ3oWtlyjmArhEt-6cBw_E9n73NFpwY",
  "pdfSize": "1222244"
}