{"id":"2412.07231","title":"Adversarial Filtering Based Evasion and Backdoor Attacks to EEG-Based\n  Brain-Computer Interfaces","authors":"Lubin Meng, Xue Jiang, Xiaoqing Chen, Wenzhong Liu, Hanbin Luo,\n  Dongrui Wu","authorsParsed":[["Meng","Lubin",""],["Jiang","Xue",""],["Chen","Xiaoqing",""],["Liu","Wenzhong",""],["Luo","Hanbin",""],["Wu","Dongrui",""]],"versions":[{"version":"v1","created":"Tue, 10 Dec 2024 06:42:46 GMT"}],"updateDate":"2024-12-11","timestamp":1733812966000,"abstract":"  A brain-computer interface (BCI) enables direct communication between the\nbrain and an external device. Electroencephalogram (EEG) is a common input\nsignal for BCIs, due to its convenience and low cost. Most research on\nEEG-based BCIs focuses on the accurate decoding of EEG signals, while ignoring\ntheir security. Recent studies have shown that machine learning models in BCIs\nare vulnerable to adversarial attacks. This paper proposes adversarial\nfiltering based evasion and backdoor attacks to EEG-based BCIs, which are very\neasy to implement. Experiments on three datasets from different BCI paradigms\ndemonstrated the effectiveness of our proposed attack approaches. To our\nknowledge, this is the first study on adversarial filtering for EEG-based BCIs,\nraising a new security concern and calling for more attention on the security\nof BCIs.\n","subjects":["Computer Science/Human-Computer Interaction","Computer Science/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"p2I5NHeLJim_gYZuyN3Y99GwpktOp7aiB4ZZDazdrik","pdfSize":"1653589"}