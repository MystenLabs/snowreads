{"id":"2412.15588","title":"NeSyCoCo: A Neuro-Symbolic Concept Composer for Compositional\n  Generalization","authors":"Danial Kamali, Elham J. Barezi, Parisa Kordjamshidi","authorsParsed":[["Kamali","Danial",""],["Barezi","Elham J.",""],["Kordjamshidi","Parisa",""]],"versions":[{"version":"v1","created":"Fri, 20 Dec 2024 05:48:58 GMT"}],"updateDate":"2024-12-23","timestamp":1734673738000,"abstract":"  Compositional generalization is crucial for artificial intelligence agents to\nsolve complex vision-language reasoning tasks. Neuro-symbolic approaches have\ndemonstrated promise in capturing compositional structures, but they face\ncritical challenges: (a) reliance on predefined predicates for symbolic\nrepresentations that limit adaptability, (b) difficulty in extracting\npredicates from raw data, and (c) using non-differentiable operations for\ncombining primitive concepts. To address these issues, we propose NeSyCoCo, a\nneuro-symbolic framework that leverages large language models (LLMs) to\ngenerate symbolic representations and map them to differentiable neural\ncomputations. NeSyCoCo introduces three innovations: (a) augmenting natural\nlanguage inputs with dependency structures to enhance the alignment with\nsymbolic representations, (b) employing distributed word representations to\nlink diverse, linguistically motivated logical predicates to neural modules,\nand (c) using the soft composition of normalized predicate scores to align\nsymbolic and differentiable reasoning. Our framework achieves state-of-the-art\nresults on the ReaSCAN and CLEVR-CoGenT compositional generalization benchmarks\nand demonstrates robust performance with novel concepts in the CLEVR-SYN\nbenchmark.\n","subjects":["Computer Science/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"k0syhlDJQaMkMAnUZosWClLkv27xE1AdPIdioSkMhR4","pdfSize":"520954"}