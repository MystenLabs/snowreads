{"id":"2412.00545","title":"Optimal Particle-based Approximation of Discrete Distributions (OPAD)","authors":"Hadi Mohasel Afshar, Gilad Francis, Sally Cripps","authorsParsed":[["Afshar","Hadi Mohasel",""],["Francis","Gilad",""],["Cripps","Sally",""]],"versions":[{"version":"v1","created":"Sat, 30 Nov 2024 17:36:59 GMT"}],"updateDate":"2024-12-03","timestamp":1732988219000,"abstract":"  Particle-based methods include a variety of techniques, such as Markov Chain\nMonte Carlo (MCMC) and Sequential Monte Carlo (SMC), for approximating a\nprobabilistic target distribution with a set of weighted particles. In this\npaper, we prove that for any set of particles, there is a unique weighting\nmechanism that minimizes the Kullback-Leibler (KL) divergence of the\n(particle-based) approximation from the target distribution, when that\ndistribution is discrete -- any other weighting mechanism (e.g. MCMC weighting\nthat is based on particles' repetitions in the Markov chain) is sub-optimal\nwith respect to this divergence measure. Our proof does not require any\nrestrictions either on the target distribution, or the process by which the\nparticles are generated, other than the discreteness of the target. We show\nthat the optimal weights can be determined based on values that any existing\nparticle-based method already computes; As such, with minimal modifications and\nno extra computational costs, the performance of any particle-based method can\nbe improved. Our empirical evaluations are carried out on important\napplications of discrete distributions including Bayesian Variable Selection\nand Bayesian Structure Learning. The results illustrate that our proposed\nreweighting of the particles improves any particle-based approximation to the\ntarget distribution consistently and often substantially.\n","subjects":["Statistics/Machine Learning","Computer Science/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"JEmQd4Z6uguuG68V3k0RUf88Xm9_ICFrJSClyt1-s3Q","pdfSize":"938530"}