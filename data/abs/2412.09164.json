{"id":"2412.09164","title":"$(\\epsilon, \\delta)$-Differentially Private Partial Least Squares\n  Regression","authors":"Ramin Nikzad-Langerodi, Mohit Kumar, Du Nguyen Duy, Mahtab Alghasi","authorsParsed":[["Nikzad-Langerodi","Ramin",""],["Kumar","Mohit",""],["Duy","Du Nguyen",""],["Alghasi","Mahtab",""]],"versions":[{"version":"v1","created":"Thu, 12 Dec 2024 10:49:55 GMT"}],"updateDate":"2024-12-13","timestamp":1734000595000,"abstract":"  As data-privacy requirements are becoming increasingly stringent and\nstatistical models based on sensitive data are being deployed and used more\nroutinely, protecting data-privacy becomes pivotal. Partial Least Squares (PLS)\nregression is the premier tool for building such models in analytical\nchemistry, yet it does not inherently provide privacy guarantees, leaving\nsensitive (training) data vulnerable to privacy attacks. To address this gap,\nwe propose an $(\\epsilon, \\delta)$-differentially private PLS (edPLS)\nalgorithm, which integrates well-studied and theoretically motivated Gaussian\nnoise-adding mechanisms into the PLS algorithm to ensure the privacy of the\ndata underlying the model. Our approach involves adding carefully calibrated\nGaussian noise to the outputs of four key functions in the PLS algorithm: the\nweights, scores, $X$-loadings, and $Y$-loadings. The noise variance is\ndetermined based on the global sensitivity of each function, ensuring that the\nprivacy loss is controlled according to the $(\\epsilon, \\delta)$-differential\nprivacy framework. Specifically, we derive the sensitivity bounds for each\nfunction and use these bounds to calibrate the noise added to the model\ncomponents. Experimental results demonstrate that edPLS effectively renders\nprivacy attacks, aimed at recovering unique sources of variability in the\ntraining data, ineffective. Application of edPLS to the NIR corn benchmark\ndataset shows that the root mean squared error of prediction (RMSEP) remains\ncompetitive even at strong privacy levels (i.e., $\\epsilon=1$), given proper\npre-processing of the corresponding spectra. These findings highlight the\npractical utility of edPLS in creating privacy-preserving multivariate\ncalibrations and for the analysis of their privacy-utility trade-offs.\n","subjects":["Statistics/Machine Learning","Computer Science/Machine Learning"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"OCeBhPIAz3NG1iYK-adm_Q-oth8zNX7eNqNBqkf5_1w","pdfSize":"748758"}