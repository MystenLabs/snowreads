{"id":"2407.07249","title":"Few-Shot Image Generation by Conditional Relaxing Diffusion Inversion","authors":"Yu Cao, Shaogang Gong","authorsParsed":[["Cao","Yu",""],["Gong","Shaogang",""]],"versions":[{"version":"v1","created":"Tue, 9 Jul 2024 21:58:26 GMT"}],"updateDate":"2024-07-11","timestamp":1720562306000,"abstract":"  In the field of Few-Shot Image Generation (FSIG) using Deep Generative Models\n(DGMs), accurately estimating the distribution of target domain with minimal\nsamples poses a significant challenge. This requires a method that can both\ncapture the broad diversity and the true characteristics of the target domain\ndistribution. We present Conditional Relaxing Diffusion Inversion (CRDI), an\ninnovative `training-free' approach designed to enhance distribution diversity\nin synthetic image generation. Distinct from conventional methods, CRDI does\nnot rely on fine-tuning based on only a few samples. Instead, it focuses on\nreconstructing each target image instance and expanding diversity through\nfew-shot learning. The approach initiates by identifying a Sample-wise Guidance\nEmbedding (SGE) for the diffusion model, which serves a purpose analogous to\nthe explicit latent codes in certain Generative Adversarial Network (GAN)\nmodels. Subsequently, the method involves a scheduler that progressively\nintroduces perturbations to the SGE, thereby augmenting diversity.\nComprehensive experiments demonstrates that our method surpasses GAN-based\nreconstruction techniques and equals state-of-the-art (SOTA) FSIG methods in\nperformance. Additionally, it effectively mitigates overfitting and\ncatastrophic forgetting, common drawbacks of fine-tuning approaches.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"eS_AFTQJa2zYyQPU7fHsWd5X5CRAy14_34HFhVW9hIc","pdfSize":"6595415"}
