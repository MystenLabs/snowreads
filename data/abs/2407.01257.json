{"id":"2407.01257","title":"uDistil-Whisper: Label-Free Data Filtering for Knowledge Distillation\n  via Large-Scale Pseudo Labelling","authors":"Abdul Waheed, Karima Kadaoui, Muhammad Abdul-Mageed","authorsParsed":[["Waheed","Abdul",""],["Kadaoui","Karima",""],["Abdul-Mageed","Muhammad",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 13:07:01 GMT"},{"version":"v2","created":"Wed, 3 Jul 2024 09:54:08 GMT"}],"updateDate":"2024-07-04","timestamp":1719839221000,"abstract":"  Recent work on distilling Whisper's knowledge into small models using\npseudo-labels shows promising performance while reducing the size by up to\n50\\%. This results in small, efficient, and dedicated models. However, a\ncritical step of distillation from pseudo-labels involves filtering\nhigh-quality predictions and using only those during training. This step\nrequires ground truth to compare and filter bad examples making the whole\nprocess supervised. In addition to that, the distillation process requires a\nlarge amount of data thereby limiting the ability to distil models in\nlow-resource settings. To address this challenge, we propose an unsupervised or\nlabel-free framework for distillation, thus eliminating the requirement for\nlabeled data altogether. Through experimentation, we show that our\nbest-distilled models outperform the teacher model by 5-7 points in terms of\nWER. Additionally, our models are on par with or better than similar supervised\ndata filtering setup. When we scale the data, our models significantly\noutperform all zero-shot and supervised models. We demonstrate that it is\npossible to distill large Whisper models into relatively small models without\nusing any labeled data. Our distilled models are 25-50\\% more compute and\nmemory efficient while maintaining performance equal to or better than the\nteacher model.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Sound","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"tzYXsTd9RFWR-FyK4TepcRe82IGfqvEYHoyS9-Snu8A","pdfSize":"397066"}