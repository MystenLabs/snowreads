{"id":"2412.02177","title":"Anatomically-Grounded Fact Checking of Automated Chest X-ray Reports","authors":"R. Mahmood, K.C.L. Wong, D. M. Reyes, N. D'Souza, L. Shi, J. Wu, P.\n  Kaviani, M. Kalra, G. Wang, P. Yan, T. Syeda-Mahmood","authorsParsed":[["Mahmood","R.",""],["Wong","K. C. L.",""],["Reyes","D. M.",""],["D'Souza","N.",""],["Shi","L.",""],["Wu","J.",""],["Kaviani","P.",""],["Kalra","M.",""],["Wang","G.",""],["Yan","P.",""],["Syeda-Mahmood","T.",""]],"versions":[{"version":"v1","created":"Tue, 3 Dec 2024 05:21:42 GMT"}],"updateDate":"2024-12-04","timestamp":1733203302000,"abstract":"  With the emergence of large-scale vision-language models, realistic radiology\nreports may be generated using only medical images as input guided by simple\nprompts. However, their practical utility has been limited due to the factual\nerrors in their description of findings. In this paper, we propose a novel\nmodel for explainable fact-checking that identifies errors in findings and\ntheir locations indicated through the reports. Specifically, we analyze the\ntypes of errors made by automated reporting methods and derive a new synthetic\ndataset of images paired with real and fake descriptions of findings and their\nlocations from a ground truth dataset. A new multi-label cross-modal\ncontrastive regression network is then trained on this datsaset. We evaluate\nthe resulting fact-checking model and its utility in correcting reports\ngenerated by several SOTA automated reporting tools on a variety of benchmark\ndatasets with results pointing to over 40\\% improvement in report quality\nthrough such error detection and correction.\n","subjects":["Computer Science/Computer Vision and Pattern Recognition","Computer Science/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"5ZtjW_whXAk-tBKyOB4FnYdE8GtYStoZyNHSJh4hUeU","pdfSize":"3181260"}