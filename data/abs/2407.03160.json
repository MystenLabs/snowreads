{"id":"2407.03160","title":"SOS! Soft Prompt Attack Against Open-Source Large Language Models","authors":"Ziqing Yang, Michael Backes, Yang Zhang, Ahmed Salem","authorsParsed":[["Yang","Ziqing",""],["Backes","Michael",""],["Zhang","Yang",""],["Salem","Ahmed",""]],"versions":[{"version":"v1","created":"Wed, 3 Jul 2024 14:35:16 GMT"}],"updateDate":"2024-07-04","timestamp":1720017316000,"abstract":"  Open-source large language models (LLMs) have become increasingly popular\namong both the general public and industry, as they can be customized,\nfine-tuned, and freely used. However, some open-source LLMs require approval\nbefore usage, which has led to third parties publishing their own easily\naccessible versions. Similarly, third parties have been publishing fine-tuned\nor quantized variants of these LLMs. These versions are particularly appealing\nto users because of their ease of access and reduced computational resource\ndemands. This trend has increased the risk of training time attacks,\ncompromising the integrity and security of LLMs. In this work, we present a new\ntraining time attack, SOS, which is designed to be low in computational demand\nand does not require clean data or modification of the model weights, thereby\nmaintaining the model's utility intact. The attack addresses security issues in\nvarious scenarios, including the backdoor attack, jailbreak attack, and prompt\nstealing attack. Our experimental findings demonstrate that the proposed attack\nis effective across all evaluated targets. Furthermore, we present the other\nside of our SOS technique, namely the copyright token -- a novel technique that\nenables users to mark their copyrighted content and prevent models from using\nit.\n","subjects":["Computing Research Repository/Cryptography and Security","Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"kOW5Xg7-3WMajcjYIUQic7n-tEN_6e2bZwaSidsQQY4","pdfSize":"3414427"}