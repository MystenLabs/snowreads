{"id":"2412.14304","title":"Multi-OphthaLingua: A Multilingual Benchmark for Assessing and Debiasing\n  LLM Ophthalmological QA in LMICs","authors":"David Restrepo, Chenwei Wu, Zhengxu Tang, Zitao Shuai, Thao Nguyen\n  Minh Phan, Jun-En Ding, Cong-Tinh Dao, Jack Gallifant, Robyn Gayle Dychiao,\n  Jose Carlo Artiaga, Andr\\'e Hiroshi Bando, Carolina Pelegrini Barbosa\n  Gracitelli, Vincenz Ferrer, Leo Anthony Celi, Danielle Bitterman, Michael G\n  Morley, Luis Filipe Nakayama","authorsParsed":[["Restrepo","David",""],["Wu","Chenwei",""],["Tang","Zhengxu",""],["Shuai","Zitao",""],["Phan","Thao Nguyen Minh",""],["Ding","Jun-En",""],["Dao","Cong-Tinh",""],["Gallifant","Jack",""],["Dychiao","Robyn Gayle",""],["Artiaga","Jose Carlo",""],["Bando","Andr√© Hiroshi",""],["Gracitelli","Carolina Pelegrini Barbosa",""],["Ferrer","Vincenz",""],["Celi","Leo Anthony",""],["Bitterman","Danielle",""],["Morley","Michael G",""],["Nakayama","Luis Filipe",""]],"versions":[{"version":"v1","created":"Wed, 18 Dec 2024 20:18:03 GMT"}],"updateDate":"2024-12-20","timestamp":1734553083000,"abstract":"  Current ophthalmology clinical workflows are plagued by over-referrals, long\nwaits, and complex and heterogeneous medical records. Large language models\n(LLMs) present a promising solution to automate various procedures such as\ntriaging, preliminary tests like visual acuity assessment, and report\nsummaries. However, LLMs have demonstrated significantly varied performance\nacross different languages in natural language question-answering tasks,\npotentially exacerbating healthcare disparities in Low and Middle-Income\nCountries (LMICs). This study introduces the first multilingual\nophthalmological question-answering benchmark with manually curated questions\nparallel across languages, allowing for direct cross-lingual comparisons. Our\nevaluation of 6 popular LLMs across 7 different languages reveals substantial\nbias across different languages, highlighting risks for clinical deployment of\nLLMs in LMICs. Existing debiasing methods such as Translation Chain-of-Thought\nor Retrieval-augmented generation (RAG) by themselves fall short of closing\nthis performance gap, often failing to improve performance across all languages\nand lacking specificity for the medical domain. To address this issue, We\npropose CLARA (Cross-Lingual Reflective Agentic system), a novel inference time\nde-biasing method leveraging retrieval augmented generation and\nself-verification. Our approach not only improves performance across all\nlanguages but also significantly reduces the multilingual bias gap,\nfacilitating equitable LLM application across the globe.\n","subjects":["Computer Science/Computation and Language","Computer Science/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"KDXqHE9fX8b_qV4xoOaJlsHLA8OxtCAett_6ZRXUBjs","pdfSize":"1694831"}