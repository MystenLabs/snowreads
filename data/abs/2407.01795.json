{"id":"2407.01795","title":"Honor Among Bandits: No-Regret Learning for Online Fair Division","authors":"Ariel D. Procaccia, Benjamin Schiffer, and Shirley Zhang","authorsParsed":[["Procaccia","Ariel D.",""],["Schiffer","Benjamin",""],["Zhang","Shirley",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 20:44:52 GMT"},{"version":"v2","created":"Sat, 17 Aug 2024 01:53:00 GMT"}],"updateDate":"2024-08-20","timestamp":1719866692000,"abstract":"  We consider the problem of online fair division of indivisible goods to\nplayers when there are a finite number of types of goods and player values are\ndrawn from distributions with unknown means. Our goal is to maximize social\nwelfare subject to allocating the goods fairly in expectation. When a player's\nvalue for an item is unknown at the time of allocation, we show that this\nproblem reduces to a variant of (stochastic) multi-armed bandits, where there\nexists an arm for each player's value for each type of good. At each time step,\nwe choose a distribution over arms which determines how the next item is\nallocated. We consider two sets of fairness constraints for this problem:\nenvy-freeness in expectation and proportionality in expectation. Our main\nresult is the design of an explore-then-commit algorithm that achieves\n$\\tilde{O}(T^{2/3})$ regret while maintaining either fairness constraint. This\nresult relies on unique properties fundamental to fair-division constraints\nthat allow faster rates of learning, despite the restricted action space. We\nalso prove a lower bound of $\\tilde{\\Omega}(T^{2/3})$ regret for our setting,\nshowing that our results are tight.\n","subjects":["Computing Research Repository/Computer Science and Game Theory","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"qZefqGda_fjqjCIdm8n_GclHXFDXJsel7BchcE82pgU","pdfSize":"657444"}