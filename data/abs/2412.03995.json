{
  "id": "2412.03995",
  "title": "Blind Underwater Image Restoration using Co-Operational Regressor\n  Networks",
  "authors": "Ozer Can Devecioglu, Serkan Kiranyaz, Turker Ince, and Moncef Gabbouj",
  "authorsParsed": [
    [
      "Devecioglu",
      "Ozer Can",
      ""
    ],
    [
      "Kiranyaz",
      "Serkan",
      ""
    ],
    [
      "Ince",
      "Turker",
      ""
    ],
    [
      "Gabbouj",
      "Moncef",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Thu, 5 Dec 2024 09:15:21 GMT"
    }
  ],
  "updateDate": "2024-12-06",
  "timestamp": 1733390121000,
  "abstract": "  The exploration of underwater environments is essential for applications such\nas biological research, archaeology, and infrastructure maintenanceHowever,\nunderwater imaging is challenging due to the waters unique properties,\nincluding scattering, absorption, color distortion, and reduced visibility. To\naddress such visual degradations, a variety of approaches have been proposed\ncovering from basic signal processing methods to deep learning models; however,\nnone of them has proven to be consistently successful. In this paper, we\npropose a novel machine learning model, Co-Operational Regressor Networks\n(CoRe-Nets), designed to achieve the best possible underwater image\nrestoration. A CoRe-Net consists of two co-operating networks: the Apprentice\nRegressor (AR), responsible for image transformation, and the Master Regressor\n(MR), which evaluates the Peak Signal-to-Noise Ratio (PSNR) of the images\ngenerated by the AR and feeds it back to AR. CoRe-Nets are built on\nSelf-Organized Operational Neural Networks (Self-ONNs), which offer a superior\nlearning capability by modulating nonlinearity in kernel transformations. The\neffectiveness of the proposed model is demonstrated on the benchmark Large\nScale Underwater Image (LSUI) dataset. Leveraging the joint learning\ncapabilities of the two cooperating networks, the proposed model achieves the\nstate-of-art restoration performance with significantly reduced computational\ncomplexity and often presents such results that can even surpass the visual\nquality of the ground truth with a 2-pass application. Our results and the\noptimized PyTorch implementation of the proposed approach are now publicly\nshared on GitHub.\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition",
    "Computer Science/Machine Learning",
    "Electrical Engineering and Systems Science/Image and Video Processing"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "d0CVcSZWioBIXtLSAoAk0zKb9VEemhtvkPTmOm0v1e4",
  "pdfSize": "2405801"
}