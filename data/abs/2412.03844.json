{
  "id": "2412.03844",
  "title": "HybridGS: Decoupling Transients and Statics with 2D and 3D Gaussian\n  Splatting",
  "authors": "Jingyu Lin, Jiaqi Gu, Lubin Fan, Bojian Wu, Yujing Lou, Renjie Chen,\n  Ligang Liu, Jieping Ye",
  "authorsParsed": [
    [
      "Lin",
      "Jingyu",
      ""
    ],
    [
      "Gu",
      "Jiaqi",
      ""
    ],
    [
      "Fan",
      "Lubin",
      ""
    ],
    [
      "Wu",
      "Bojian",
      ""
    ],
    [
      "Lou",
      "Yujing",
      ""
    ],
    [
      "Chen",
      "Renjie",
      ""
    ],
    [
      "Liu",
      "Ligang",
      ""
    ],
    [
      "Ye",
      "Jieping",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Thu, 5 Dec 2024 03:20:35 GMT"
    },
    {
      "version": "v2",
      "created": "Tue, 10 Dec 2024 04:59:24 GMT"
    },
    {
      "version": "v3",
      "created": "Thu, 27 Feb 2025 02:48:54 GMT"
    }
  ],
  "updateDate": "2025-02-28",
  "timestamp": 1733368835000,
  "abstract": "  Generating high-quality novel view renderings of 3D Gaussian Splatting (3DGS)\nin scenes featuring transient objects is challenging. We propose a novel hybrid\nrepresentation, termed as HybridGS, using 2D Gaussians for transient objects\nper image and maintaining traditional 3D Gaussians for the whole static scenes.\nNote that, the 3DGS itself is better suited for modeling static scenes that\nassume multi-view consistency, but the transient objects appear occasionally\nand do not adhere to the assumption, thus we model them as planar objects from\na single view, represented with 2D Gaussians. Our novel representation\ndecomposes the scene from the perspective of fundamental viewpoint consistency,\nmaking it more reasonable. Additionally, we present a novel multi-view\nregulated supervision method for 3DGS that leverages information from\nco-visible regions, further enhancing the distinctions between the transients\nand statics. Then, we propose a straightforward yet effective multi-stage\ntraining strategy to ensure robust training and high-quality view synthesis\nacross various settings. Experiments on benchmark datasets show our\nstate-of-the-art performance of novel view synthesis in both indoor and outdoor\nscenes, even in the presence of distracting elements.\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition",
    "Computer Science/Artificial Intelligence"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "IL1DMwoF3XMm--mNlXGu10t33yKDK4G_Edv21k3R88o",
  "pdfSize": "11117319"
}