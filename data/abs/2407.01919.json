{"id":"2407.01919","title":"A Method to Facilitate Membership Inference Attacks in Deep Learning\n  Models","authors":"Zitao Chen, Karthik Pattabiraman","authorsParsed":[["Chen","Zitao",""],["Pattabiraman","Karthik",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 03:33:42 GMT"}],"updateDate":"2024-07-03","timestamp":1719891222000,"abstract":"  Modern machine learning (ML) ecosystems offer a surging number of ML\nframeworks and code repositories that can greatly facilitate the development of\nML models. Today, even ordinary data holders who are not ML experts can apply\noff-the-shelf codebase to build high-performance ML models on their data, many\nof which are sensitive in nature (e.g., clinical records).\n  In this work, we consider a malicious ML provider who supplies model-training\ncode to the data holders, does not have access to the training process, and has\nonly black-box query access to the resulting model. In this setting, we\ndemonstrate a new form of membership inference attack that is strictly more\npowerful than prior art. Our attack empowers the adversary to reliably\nde-identify all the training samples (average >99% attack TPR@0.1% FPR), and\nthe compromised models still maintain competitive performance as their\nuncorrupted counterparts (average <1% accuracy drop). Moreover, we show that\nthe poisoned models can effectively disguise the amplified membership leakage\nunder common membership privacy auditing, which can only be revealed by a set\nof secret samples known by the adversary.\n  Overall, our study not only points to the worst-case membership privacy\nleakage, but also unveils a common pitfall underlying existing privacy auditing\nmethods, which calls for future efforts to rethink the current practice of\nauditing membership privacy in machine learning models.\n","subjects":["Computing Research Repository/Cryptography and Security","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"TxYxqOhq9CniY8yrLtsPvMe0KyfUuLXzbRAzdSSYXtc","pdfSize":"1772339"}