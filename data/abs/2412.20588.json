{"id":"2412.20588","title":"Kryptonite-N: Machine Learning Strikes Back","authors":"Albus Li, Nathan Bailey, Will Sumerfield, Kira Kim","authorsParsed":[["Li","Albus",""],["Bailey","Nathan",""],["Sumerfield","Will",""],["Kim","Kira",""]],"versions":[{"version":"v1","created":"Sun, 29 Dec 2024 21:23:09 GMT"},{"version":"v2","created":"Sun, 26 Jan 2025 18:22:57 GMT"}],"updateDate":"2025-01-28","timestamp":1735507389000,"abstract":"  Quinn et al propose challenge datasets in their work called ``Kryptonite-N\".\nThese datasets aim to counter the universal function approximation argument of\nmachine learning, breaking the notation that machine learning can ``approximate\nany continuous function\" \\cite{original_paper}. Our work refutes this claim and\nshows that universal function approximations can be applied successfully; the\nKryptonite datasets are constructed predictably, allowing logistic regression\nwith sufficient polynomial expansion and L1 regularization to solve for any\ndimension N.\n","subjects":["Computer Science/Machine Learning","Computer Science/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"p2kmc-2vYcAUR4Q7DOWxeFyxQ_L5dlwaPMqEIlz7ZSo","pdfSize":"1421909"}