{"id":"2407.09924","title":"Region-aware Image-based Human Action Retrieval with Transformers","authors":"Hongsong Wang, Jianhua Zhao, Jie Gui","authorsParsed":[["Wang","Hongsong",""],["Zhao","Jianhua",""],["Gui","Jie",""]],"versions":[{"version":"v1","created":"Sat, 13 Jul 2024 15:34:54 GMT"},{"version":"v2","created":"Mon, 29 Jul 2024 03:18:35 GMT"}],"updateDate":"2024-07-30","timestamp":1720884894000,"abstract":"  Human action understanding is a fundamental and challenging task in computer\nvision. Although there exists tremendous research on this area, most works\nfocus on action recognition, while action retrieval has received less\nattention. In this paper, we focus on the neglected but important task of\nimage-based action retrieval which aims to find images that depict the same\naction as a query image. We establish benchmarks for this task and set up\nimportant baseline methods for fair comparison. We present an end-to-end model\nthat learns rich action representations from three aspects: the anchored\nperson, contextual regions, and the global image. A novel fusion transformer\nmodule is designed to model the relationships among different features and\neffectively fuse them into an action representation. Experiments on the\nStanford-40 and PASCAL VOC 2012 Action datasets show that the proposed method\nsignificantly outperforms previous approaches for image-based action retrieval.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"1dNLGFfIJ65gW5cAR4_yKYhXVDJKlw150CAdNfY6HVU","pdfSize":"4937370"}