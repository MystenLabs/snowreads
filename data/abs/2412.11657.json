{
  "id": "2412.11657",
  "title": "CNNtention: Can CNNs do better with Attention?",
  "authors": "Nikhil Kapila, Julian Glattki and Tejas Rathi",
  "authorsParsed": [
    [
      "Kapila",
      "Nikhil",
      ""
    ],
    [
      "Glattki",
      "Julian",
      ""
    ],
    [
      "Rathi",
      "Tejas",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Mon, 16 Dec 2024 11:00:02 GMT"
    },
    {
      "version": "v2",
      "created": "Wed, 18 Dec 2024 15:56:51 GMT"
    },
    {
      "version": "v3",
      "created": "Mon, 30 Dec 2024 14:39:08 GMT"
    }
  ],
  "updateDate": "2024-12-31",
  "timestamp": 1734346802000,
  "abstract": "  Convolutional Neural Networks (CNNs) have been the standard for image\nclassification tasks for a long time, but more recently attention-based\nmechanisms have gained traction. This project aims to compare traditional CNNs\nwith attention-augmented CNNs across an image classification task. By\nevaluating and comparing their performance, accuracy and computational\nefficiency, the project will highlight benefits and trade-off of the localized\nfeature extraction of traditional CNNs and the global context capture in\nattention-augmented CNNs. By doing this, we can reveal further insights into\ntheir respective strengths and weaknesses, guide the selection of models based\non specific application needs and ultimately, enhance understanding of these\narchitectures in the deep learning community.\n  This was our final project for CS7643 Deep Learning course at Georgia Tech.\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition",
    "Computer Science/Machine Learning"
  ],
  "license": "http://creativecommons.org/licenses/by-sa/4.0/",
  "blobId": "4atNTegrkQRvwv4DHczCNMEcxisTA3MjvaXfeuiLvlo",
  "pdfSize": "2398969"
}