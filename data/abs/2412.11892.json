{"id":"2412.11892","title":"From 2D CAD Drawings to 3D Parametric Models: A Vision-Language Approach","authors":"Xilin Wang and Jia Zheng and Yuanchao Hu and Hao Zhu and Qian Yu and\n  Zihan Zhou","authorsParsed":[["Wang","Xilin",""],["Zheng","Jia",""],["Hu","Yuanchao",""],["Zhu","Hao",""],["Yu","Qian",""],["Zhou","Zihan",""]],"versions":[{"version":"v1","created":"Mon, 16 Dec 2024 15:41:14 GMT"},{"version":"v2","created":"Tue, 17 Dec 2024 04:38:28 GMT"}],"updateDate":"2024-12-18","timestamp":1734363674000,"abstract":"  In this paper, we present CAD2Program, a new method for reconstructing 3D\nparametric models from 2D CAD drawings. Our proposed method is inspired by\nrecent successes in vision-language models (VLMs), and departs from traditional\nmethods which rely on task-specific data representations and/or algorithms.\nSpecifically, on the input side, we simply treat the 2D CAD drawing as a raster\nimage, regardless of its original format, and encode the image with a standard\nViT model. We show that such an encoding scheme achieves competitive\nperformance against existing methods that operate on vector-graphics inputs,\nwhile imposing substantially fewer restrictions on the 2D drawings. On the\noutput side, our method auto-regressively predicts a general-purpose language\ndescribing 3D parametric models in text form. Compared to other sequence\nmodeling methods for CAD which use domain-specific sequence representations\nwith fixed-size slots, our text-based representation is more flexible, and can\nbe easily extended to arbitrary geometric entities and semantic or functional\nproperties. Experimental results on a large-scale dataset of cabinet models\ndemonstrate the effectiveness of our method.\n","subjects":["Computer Science/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"QK0Et7_Lg1blhQJMqcYVouOBmbq2zlQCzdxXor3VQo0","pdfSize":"3019671"}