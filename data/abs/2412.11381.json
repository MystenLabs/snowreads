{
  "id": "2412.11381",
  "title": "Adapting Segment Anything Model (SAM) to Experimental Datasets via\n  Fine-Tuning on GAN-based Simulation: A Case Study in Additive Manufacturing",
  "authors": "Anika Tabassum, Amirkoushyar Ziabari",
  "authorsParsed": [
    [
      "Tabassum",
      "Anika",
      ""
    ],
    [
      "Ziabari",
      "Amirkoushyar",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Mon, 16 Dec 2024 02:11:19 GMT"
    }
  ],
  "updateDate": "2024-12-17",
  "timestamp": 1734315079000,
  "abstract": "  Industrial X-ray computed tomography (XCT) is a powerful tool for\nnon-destructive characterization of materials and manufactured components. XCT\ncommonly accompanied by advanced image analysis and computer vision algorithms\nto extract relevant information from the images. Traditional computer vision\nmodels often struggle due to noise, resolution variability, and complex\ninternal structures, particularly in scientific imaging applications.\nState-of-the-art foundational models, like the Segment Anything Model\n(SAM)-designed for general-purpose image segmentation-have revolutionized image\nsegmentation across various domains, yet their application in specialized\nfields like materials science remains under-explored. In this work, we explore\nthe application and limitations of SAM for industrial X-ray CT inspection of\nadditive manufacturing components. We demonstrate that while SAM shows promise,\nit struggles with out-of-distribution data, multiclass segmentation, and\ncomputational efficiency during fine-tuning. To address these issues, we\npropose a fine-tuning strategy utilizing parameter-efficient techniques,\nspecifically Conv-LoRa, to adapt SAM for material-specific datasets.\nAdditionally, we leverage generative adversarial network (GAN)-generated data\nto enhance the training process and improve the model's segmentation\nperformance on complex X-ray CT data. Our experimental results highlight the\nimportance of tailored segmentation models for accurate inspection, showing\nthat fine-tuning SAM on domain-specific scientific imaging data significantly\nimproves performance. However, despite improvements, the model's ability to\ngeneralize across diverse datasets remains limited, highlighting the need for\nfurther research into robust, scalable solutions for domain-specific\nsegmentation tasks.\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition",
    "Computer Science/Artificial Intelligence",
    "Electrical Engineering and Systems Science/Image and Video Processing"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "CP-2WWfmCAGIwZnJrUvII4mIshSncx8ZHcndVCO4AQQ",
  "pdfSize": "6109428"
}