{"id":"2412.18004","title":"Correctness is not Faithfulness in RAG Attributions","authors":"Jonas Wallat, Maria Heuss, Maarten de Rijke, Avishek Anand","authorsParsed":[["Wallat","Jonas",""],["Heuss","Maria",""],["de Rijke","Maarten",""],["Anand","Avishek",""]],"versions":[{"version":"v1","created":"Mon, 23 Dec 2024 21:57:11 GMT"}],"updateDate":"2024-12-25","timestamp":1734991031000,"abstract":"  Retrieving relevant context is a common approach to reduce hallucinations and\nenhance answer reliability. Explicitly citing source documents allows users to\nverify generated responses and increases trust. Prior work largely evaluates\ncitation correctness - whether cited documents support the corresponding\nstatements. But citation correctness alone is insufficient. To establish trust\nin attributed answers, we must examine both citation correctness and citation\nfaithfulness. In this work, we first disentangle the notions of citation\ncorrectness and faithfulness, which have been applied inconsistently in\nprevious studies. Faithfulness ensures that the model's reliance on cited\ndocuments is genuine, reflecting actual reference use rather than superficial\nalignment with prior beliefs, which we call post-rationalization. We design an\nexperiment that reveals the prevalent issue of post-rationalization, which\nundermines reliable attribution and may result in misplaced trust. Our findings\nsuggest that current attributed answers often lack citation faithfulness (up to\n57 percent of the citations), highlighting the need to evaluate correctness and\nfaithfulness for trustworthy attribution in language models.\n","subjects":["Computer Science/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"EbpI_fH04OsdiiH5OTh5AuqoM1sdrwhXhzlTmI4k8fU","pdfSize":"253295"}