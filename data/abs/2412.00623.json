{
  "id": "2412.00623",
  "title": "A Lesson in Splats: Teacher-Guided Diffusion for 3D Gaussian Splats\n  Generation with 2D Supervision",
  "authors": "Chensheng Peng, Ido Sobol, Masayoshi Tomizuka, Kurt Keutzer, Chenfeng\n  Xu, Or Litany",
  "authorsParsed": [
    [
      "Peng",
      "Chensheng",
      ""
    ],
    [
      "Sobol",
      "Ido",
      ""
    ],
    [
      "Tomizuka",
      "Masayoshi",
      ""
    ],
    [
      "Keutzer",
      "Kurt",
      ""
    ],
    [
      "Xu",
      "Chenfeng",
      ""
    ],
    [
      "Litany",
      "Or",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Sun, 1 Dec 2024 00:29:57 GMT"
    },
    {
      "version": "v2",
      "created": "Sat, 7 Dec 2024 07:21:01 GMT"
    }
  ],
  "updateDate": "2024-12-10",
  "timestamp": 1733012997000,
  "abstract": "  We introduce a diffusion model for Gaussian Splats, SplatDiffusion, to enable\ngeneration of three-dimensional structures from single images, addressing the\nill-posed nature of lifting 2D inputs to 3D. Existing methods rely on\ndeterministic, feed-forward predictions, which limit their ability to handle\nthe inherent ambiguity of 3D inference from 2D data. Diffusion models have\nrecently shown promise as powerful generative models for 3D data, including\nGaussian splats; however, standard diffusion frameworks typically require the\ntarget signal and denoised signal to be in the same modality, which is\nchallenging given the scarcity of 3D data. To overcome this, we propose a novel\ntraining strategy that decouples the denoised modality from the supervision\nmodality. By using a deterministic model as a noisy teacher to create the\nnoised signal and transitioning from single-step to multi-step denoising\nsupervised by an image rendering loss, our approach significantly enhances\nperformance compared to the deterministic teacher. Additionally, our method is\nflexible, as it can learn from various 3D Gaussian Splat (3DGS) teachers with\nminimal adaptation; we demonstrate this by surpassing the performance of two\ndifferent deterministic models as teachers, highlighting the potential\ngeneralizability of our framework. Our approach further incorporates a guidance\nmechanism to aggregate information from multiple views, enhancing\nreconstruction quality when more than one view is available. Experimental\nresults on object-level and scene-level datasets demonstrate the effectiveness\nof our framework.\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "Py8GsS2pPn91_Uh4hJkFeIggDQx15klu4-pkwfhnxUU",
  "pdfSize": "17128724"
}