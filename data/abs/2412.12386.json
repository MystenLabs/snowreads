{
  "id": "2412.12386",
  "title": "Interpretable LLM-based Table Question Answering",
  "authors": "Giang (Dexter) Nguyen, Ivan Brugere, Shubham Sharma, Sanjay Kariyappa,\n  Anh Totti Nguyen, Freddy Lecue",
  "authorsParsed": [
    [
      "Giang",
      "",
      "",
      "Dexter"
    ],
    [
      "Nguyen",
      "",
      ""
    ],
    [
      "Brugere",
      "Ivan",
      ""
    ],
    [
      "Sharma",
      "Shubham",
      ""
    ],
    [
      "Kariyappa",
      "Sanjay",
      ""
    ],
    [
      "Nguyen",
      "Anh Totti",
      ""
    ],
    [
      "Lecue",
      "Freddy",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Mon, 16 Dec 2024 22:44:31 GMT"
    }
  ],
  "updateDate": "2024-12-18",
  "timestamp": 1734389071000,
  "abstract": "  Interpretability for Table Question Answering (Table QA) is critical,\nparticularly in high-stakes industries like finance or healthcare. Although\nrecent approaches using Large Language Models (LLMs) have significantly\nimproved Table QA performance, their explanations for how the answers are\ngenerated are ambiguous. To fill this gap, we introduce Plan-of-SQLs ( or POS),\nan interpretable, effective, and efficient approach to Table QA that answers an\ninput query solely with SQL executions. Through qualitative and quantitative\nevaluations with human and LLM judges, we show that POS is most preferred among\nexplanation methods, helps human users understand model decision boundaries,\nand facilitates model success and error identification. Furthermore, when\nevaluated in standard benchmarks (TabFact, WikiTQ, and FetaQA), POS achieves\ncompetitive or superior accuracy compared to existing methods, while\nmaintaining greater efficiency by requiring significantly fewer LLM calls and\ndatabase queries.\n",
  "subjects": [
    "Computer Science/Computation and Language",
    "Computer Science/Machine Learning"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "iHq9abYnClnxL0eQyAKow8hHxkWtJam3JpC8ru8NzpM",
  "pdfSize": "2056725"
}