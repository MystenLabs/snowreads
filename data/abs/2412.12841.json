{"id":"2412.12841","title":"Benchmarking and Understanding Compositional Relational Reasoning of\n  LLMs","authors":"Ruikang Ni, Da Xiao, Qingye Meng, Xiangyu Li, Shihui Zheng, Hongliang\n  Liang","authorsParsed":[["Ni","Ruikang",""],["Xiao","Da",""],["Meng","Qingye",""],["Li","Xiangyu",""],["Zheng","Shihui",""],["Liang","Hongliang",""]],"versions":[{"version":"v1","created":"Tue, 17 Dec 2024 12:10:38 GMT"}],"updateDate":"2024-12-18","timestamp":1734437438000,"abstract":"  Compositional relational reasoning (CRR) is a hallmark of human intelligence,\nbut we lack a clear understanding of whether and how existing transformer large\nlanguage models (LLMs) can solve CRR tasks. To enable systematic exploration of\nthe CRR capability of LLMs, we first propose a new synthetic benchmark called\nGeneralized Associative Recall (GAR) by integrating and generalizing the\nessence of several tasks in mechanistic interpretability (MI) study in a\nunified framework. Evaluation shows that GAR is challenging enough for existing\nLLMs, revealing their fundamental deficiency in CRR. Meanwhile, it is easy\nenough for systematic MI study. Then, to understand how LLMs solve GAR tasks,\nwe use attribution patching to discover the core circuits reused by Vicuna-33B\nacross different tasks and a set of vital attention heads. Intervention\nexperiments show that the correct functioning of these heads significantly\nimpacts task performance. Especially, we identify two classes of heads whose\nactivations represent the abstract notion of true and false in GAR tasks\nrespectively. They play a fundamental role in CRR across various models and\ntasks. The dataset and code are available at https://github.com/Caiyun-AI/GAR.\n","subjects":["Computer Science/Computation and Language","Computer Science/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"lpFbqUalaB6mWpNqMoeyVtpbwVYpasIDk7kR4l8XY5M","pdfSize":"3660846"}