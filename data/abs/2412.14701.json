{
  "id": "2412.14701",
  "title": "Taming the Memory Beast: Strategies for Reliable ML Training on\n  Kubernetes",
  "authors": "Jaideep Ray",
  "authorsParsed": [
    [
      "Ray",
      "Jaideep",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Thu, 19 Dec 2024 10:10:57 GMT"
    },
    {
      "version": "v2",
      "created": "Wed, 25 Dec 2024 06:36:22 GMT"
    }
  ],
  "updateDate": "2024-12-30",
  "timestamp": 1734603057000,
  "abstract": "  Kubernetes offers a powerful orchestration platform for machine learning\ntraining, but memory management can be challenging due to specialized needs and\nresource constraints. This paper outlines how Kubernetes handles memory\nrequests, limits, Quality of Service classes, and eviction policies for ML\nworkloads, with special focus on GPU memory and ephemeral storage. Common\npitfalls such as overcommitment, memory leaks, and ephemeral volume exhaustion\nare examined. We then provide best practices for stable, scalable memory\nutilization to help ML practitioners prevent out-of-memory events and ensure\nhigh-performance ML training pipelines.\n",
  "subjects": [
    "Computer Science/Distributed, Parallel, and Cluster Computing",
    "Computer Science/Machine Learning"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "RVL1nw7mczgxOpN0U9nagrnTIjvEEciwEhldLo3pvLg",
  "pdfSize": "174580"
}