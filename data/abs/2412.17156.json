{"id":"2412.17156","title":"LLM-based relevance assessment still can't replace human relevance\n  assessment","authors":"Charles L. A. Clarke, Laura Dietz","authorsParsed":[["Clarke","Charles L. A.",""],["Dietz","Laura",""]],"versions":[{"version":"v1","created":"Sun, 22 Dec 2024 20:45:15 GMT"}],"updateDate":"2024-12-24","timestamp":1734900315000,"abstract":"  The use of large language models (LLMs) for relevance assessment in\ninformation retrieval has gained significant attention, with recent studies\nsuggesting that LLM-based judgments provide comparable evaluations to human\njudgments. Notably, based on TREC 2024 data, Upadhyay et al. make a bold claim\nthat LLM-based relevance assessments, such as those generated by the UMBRELA\nsystem, can fully replace traditional human relevance assessments in TREC-style\nevaluations. This paper critically examines this claim, highlighting practical\nand theoretical limitations that undermine the validity of this conclusion.\nFirst, we question whether the evidence provided by Upadhyay et al. really\nsupports their claim, particularly if a test collection is used asa benchmark\nfor future improvements. Second, through a submission deliberately intended to\ndo so, we demonstrate the ease with which automatic evaluation metrics can be\nsubverted, showing that systems designed to exploit these evaluations can\nachieve artificially high scores. Theoretical challenges -- such as the\ninherent narcissism of LLMs, the risk of overfitting to LLM-based metrics, and\nthe potential degradation of future LLM performance -- must be addressed before\nLLM-based relevance assessments can be considered a viable replacement for\nhuman judgments.\n","subjects":["Computer Science/Information Retrieval"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"gEGVfIY-UW-sUD_MAytq9N738nVJrsFWJC0k79yKbjo","pdfSize":"1221799"}