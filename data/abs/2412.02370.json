{"id":"2412.02370","title":"Trajectory-based Road Autolabeling with Lidar-Camera Fusion in Winter\n  Conditions","authors":"Eerik Alamikkotervo, Henrik Toikka, Kari Tammi, Risto Ojala","authorsParsed":[["Alamikkotervo","Eerik",""],["Toikka","Henrik",""],["Tammi","Kari",""],["Ojala","Risto",""]],"versions":[{"version":"v1","created":"Tue, 3 Dec 2024 10:54:37 GMT"}],"updateDate":"2024-12-04","timestamp":1733223277000,"abstract":"  Robust road segmentation in all road conditions is required for safe\nautonomous driving and advanced driver assistance systems. Supervised deep\nlearning methods provide accurate road segmentation in the domain of their\ntraining data but cannot be trusted in out-of-distribution scenarios. Including\nthe whole distribution in the trainset is challenging as each sample must be\nlabeled by hand. Trajectory-based self-supervised methods offer a potential\nsolution as they can learn from the traversed route without manual labels.\nHowever, existing trajectory-based methods use learning schemes that rely only\non the camera or only on the lidar. In this paper, trajectory-based learning is\nimplemented jointly with lidar and camera for increased performance. Our method\noutperforms recent standalone camera- and lidar-based methods when evaluated\nwith a challenging winter driving dataset including countryside and suburb\ndriving scenes. The source code is available at\nhttps://github.com/eerik98/lidar-camera-road-autolabeling.git\n","subjects":["Computer Science/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"Vspma_HrLLv48bBUAIU-laezAq97L3bhy0r1s_v9zbk","pdfSize":"25532485"}