{"id":"2407.07848","title":"Uncovering Layer-Dependent Activation Sparsity Patterns in ReLU\n  Transformers","authors":"Cody Wild, Jesper Anderson","authorsParsed":[["Wild","Cody",""],["Anderson","Jesper",""]],"versions":[{"version":"v1","created":"Wed, 10 Jul 2024 17:10:10 GMT"}],"updateDate":"2024-07-11","timestamp":1720631410000,"abstract":"  Previous work has demonstrated that MLPs within ReLU Transformers exhibit\nhigh levels of sparsity, with many of their activations equal to zero for any\ngiven token. We build on that work to more deeply explore how token-level\nsparsity evolves over the course of training, and how it connects to broader\nsparsity patterns over the course of a sequence or batch, demonstrating that\nthe different layers within small transformers exhibit distinctly\nlayer-specific patterns on both of these fronts. In particular, we demonstrate\nthat the first and last layer of the network have distinctive and in many ways\ninverted relationships to sparsity, and explore implications for the structure\nof feature representations being learned at different depths of the model. We\nadditionally explore the phenomenon of ReLU dimensions \"turning off\", and show\nevidence suggesting that \"neuron death\" is being primarily driven by the\ndynamics of training, rather than simply occurring randomly or accidentally as\na result of outliers.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"ip1RkTHKjKTO-QEwG1DFl2k4k3Qfd3K5SHqQQrTPEQc","pdfSize":"6427467","objectId":"0x7b40ce8aab30b8f3567ee8548dd58a15444aabd6977ce8dbf6faa0769297ef5b","registeredEpoch":"1","certifiedEpoch":"1","startEpoch":"1","endEpoch":"201"}
