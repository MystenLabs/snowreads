{"id":"2412.10402","title":"TANGO: Training-free Embodied AI Agents for Open-world Tasks","authors":"Filippo Ziliotto, Tommaso Campari, Luciano Serafini, Lamberto Ballan","authorsParsed":[["Ziliotto","Filippo",""],["Campari","Tommaso",""],["Serafini","Luciano",""],["Ballan","Lamberto",""]],"versions":[{"version":"v1","created":"Thu, 5 Dec 2024 21:52:20 GMT"}],"updateDate":"2024-12-17","timestamp":1733435540000,"abstract":"  Large Language Models (LLMs) have demonstrated excellent capabilities in\ncomposing various modules together to create programs that can perform complex\nreasoning tasks on images. In this paper, we propose TANGO, an approach that\nextends the program composition via LLMs already observed for images, aiming to\nintegrate those capabilities into embodied agents capable of observing and\nacting in the world. Specifically, by employing a simple PointGoal Navigation\nmodel combined with a memory-based exploration policy as a foundational\nprimitive for guiding an agent through the world, we show how a single model\ncan address diverse tasks without additional training. We task an LLM with\ncomposing the provided primitives to solve a specific task, using only a few\nin-context examples in the prompt. We evaluate our approach on three key\nEmbodied AI tasks: Open-Set ObjectGoal Navigation, Multi-Modal Lifelong\nNavigation, and Open Embodied Question Answering, achieving state-of-the-art\nresults without any specific fine-tuning in challenging zero-shot scenarios.\n","subjects":["Computer Science/Artificial Intelligence","Computer Science/Robotics"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"MHpn7lAdMsFBPLofEo9ZzO-WNQHSG3JGIk109NUoKlg","pdfSize":"10486790"}