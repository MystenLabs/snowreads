{"id":"2407.14340","title":"Large Kernel Distillation Network for Efficient Single Image\n  Super-Resolution","authors":"Chengxing Xie, Xiaoming Zhang, Linze Li, Haiteng Meng, Tianlin Zhang,\n  Tianrui Li, Xiaole Zhao","authorsParsed":[["Xie","Chengxing",""],["Zhang","Xiaoming",""],["Li","Linze",""],["Meng","Haiteng",""],["Zhang","Tianlin",""],["Li","Tianrui",""],["Zhao","Xiaole",""]],"versions":[{"version":"v1","created":"Fri, 19 Jul 2024 14:21:56 GMT"}],"updateDate":"2024-07-22","timestamp":1721398916000,"abstract":"  Efficient and lightweight single-image super-resolution (SISR) has achieved\nremarkable performance in recent years. One effective approach is the use of\nlarge kernel designs, which have been shown to improve the performance of SISR\nmodels while reducing their computational requirements. However, current\nstate-of-the-art (SOTA) models still face problems such as high computational\ncosts. To address these issues, we propose the Large Kernel Distillation\nNetwork (LKDN) in this paper. Our approach simplifies the model structure and\nintroduces more efficient attention modules to reduce computational costs while\nalso improving performance. Specifically, we employ the reparameterization\ntechnique to enhance model performance without adding extra cost. We also\nintroduce a new optimizer from other tasks to SISR, which improves training\nspeed and performance. Our experimental results demonstrate that LKDN\noutperforms existing lightweight SR methods and achieves SOTA performance.\n","subjects":["Electrical Engineering and Systems Science/Image and Video Processing","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"4nQppJlF85bBl8SwUYztUXkmyluPOwfI_S_4mrzDhkw","pdfSize":"1326050"}