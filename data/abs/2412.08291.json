{"id":"2412.08291","title":"Code LLMs: A Taxonomy-based Survey","authors":"Nishat Raihan, Christian Newman, Marcos Zampieri","authorsParsed":[["Raihan","Nishat",""],["Newman","Christian",""],["Zampieri","Marcos",""]],"versions":[{"version":"v1","created":"Wed, 11 Dec 2024 11:07:50 GMT"}],"updateDate":"2024-12-12","timestamp":1733915270000,"abstract":"  Large language models (LLMs) have demonstrated remarkable capabilities across\nvarious NLP tasks and have recently expanded their impact to coding tasks,\nbridging the gap between natural languages (NL) and programming languages (PL).\nThis taxonomy-based survey provides a comprehensive analysis of LLMs in the\nNL-PL domain, investigating how these models are utilized in coding tasks and\nexamining their methodologies, architectures, and training processes. We\npropose a taxonomy-based framework that categorizes relevant concepts,\nproviding a unified classification system to facilitate a deeper understanding\nof this rapidly evolving field. This survey offers insights into the current\nstate and future directions of LLMs in coding tasks, including their\napplications and limitations.\n","subjects":["Computer Science/Computation and Language"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"DCSoVvvCv68i1U-gW3mxADi7Rs9HYO6W3y50f-M8sYQ","pdfSize":"358395"}