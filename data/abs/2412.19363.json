{"id":"2412.19363","title":"Large Language Models for Market Research: A Data-augmentation Approach","authors":"Mengxin Wang (Naveen Jindal School of Management, The University of\n  Texas at Dallas), Dennis J. Zhang (Olin School of Business, Washington\n  University in St. Louis), Heng Zhang (W. P. Carey School of Business, Arizona\n  State University)","authorsParsed":[["Wang","Mengxin","","Naveen Jindal School of Management, The University of\n  Texas at Dallas"],["Zhang","Dennis J.","","Olin School of Business, Washington\n  University in St. Louis"],["Zhang","Heng","","W. P. Carey School of Business, Arizona\n  State University"]],"versions":[{"version":"v1","created":"Thu, 26 Dec 2024 22:06:29 GMT"},{"version":"v2","created":"Mon, 6 Jan 2025 17:33:20 GMT"}],"updateDate":"2025-01-07","timestamp":1735250789000,"abstract":"  Large Language Models (LLMs) have transformed artificial intelligence by\nexcelling in complex natural language processing tasks. Their ability to\ngenerate human-like text has opened new possibilities for market research,\nparticularly in conjoint analysis, where understanding consumer preferences is\nessential but often resource-intensive. Traditional survey-based methods face\nlimitations in scalability and cost, making LLM-generated data a promising\nalternative. However, while LLMs have the potential to simulate real consumer\nbehavior, recent studies highlight a significant gap between LLM-generated and\nhuman data, with biases introduced when substituting between the two. In this\npaper, we address this gap by proposing a novel statistical data augmentation\napproach that efficiently integrates LLM-generated data with real data in\nconjoint analysis. Our method leverages transfer learning principles to debias\nthe LLM-generated data using a small amount of human data. This results in\nstatistically robust estimators with consistent and asymptotically normal\nproperties, in contrast to naive approaches that simply substitute human data\nwith LLM-generated data, which can exacerbate bias. We validate our framework\nthrough an empirical study on COVID-19 vaccine preferences, demonstrating its\nsuperior ability to reduce estimation error and save data and costs by 24.9% to\n79.8%. In contrast, naive approaches fail to save data due to the inherent\nbiases in LLM-generated data compared to human data. Another empirical study on\nsports car choices validates the robustness of our results. Our findings\nsuggest that while LLM-generated data is not a direct substitute for human\nresponses, it can serve as a valuable complement when used within a robust\nstatistical framework.\n","subjects":["Computer Science/Artificial Intelligence","Computer Science/Machine Learning","Statistics/Methodology","Statistics/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"0mJ47n5ir_pH9wvQ6nUIidECGoHNCu_X48AOJyIgNeM","pdfSize":"1702417"}