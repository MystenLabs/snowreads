{"id":"2407.17524","title":"StreamTinyNet: video streaming analysis with spatial-temporal TinyML","authors":"Hazem Hesham Yousef Shalby, Massimo Pavan, Manuel Roveri","authorsParsed":[["Shalby","Hazem Hesham Yousef",""],["Pavan","Massimo",""],["Roveri","Manuel",""]],"versions":[{"version":"v1","created":"Mon, 22 Jul 2024 07:08:03 GMT"}],"updateDate":"2024-09-17","timestamp":1721632083000,"abstract":"  Tiny Machine Learning (TinyML) is a branch of Machine Learning (ML) that\nconstitutes a bridge between the ML world and the embedded system ecosystem\n(i.e., Internet of Things devices, embedded devices, and edge computing units),\nenabling the execution of ML algorithms on devices constrained in terms of\nmemory, computational capabilities, and power consumption. Video Streaming\nAnalysis (VSA), one of the most interesting tasks of TinyML, consists in\nscanning a sequence of frames in a streaming manner, with the goal of\nidentifying interesting patterns. Given the strict constraints of these tiny\ndevices, all the current solutions rely on performing a frame-by-frame\nanalysis, hence not exploiting the temporal component in the stream of data. In\nthis paper, we present StreamTinyNet, the first TinyML architecture to perform\nmultiple-frame VSA, enabling a variety of use cases that requires\nspatial-temporal analysis that were previously impossible to be carried out at\na TinyML level. Experimental results on public-available datasets show the\neffectiveness and efficiency of the proposed solution. Finally, StreamTinyNet\nhas been ported and tested on the Arduino Nicla Vision, showing the feasibility\nof what proposed.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by-sa/4.0/","blobId":"9tNKuXF-ypiLTEJOfce4f1FllpFHje0jGWk1nFBo_ik","pdfSize":"804082"}