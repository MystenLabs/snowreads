{"id":"2412.10649","title":"Hidden Echoes Survive Training in Audio To Audio Generative Instrument\n  Models","authors":"Christopher J. Tralie and Matt Amery and Benjamin Douglas and Ian Utz","authorsParsed":[["Tralie","Christopher J.",""],["Amery","Matt",""],["Douglas","Benjamin",""],["Utz","Ian",""]],"versions":[{"version":"v1","created":"Sat, 14 Dec 2024 02:36:45 GMT"}],"updateDate":"2024-12-17","timestamp":1734143805000,"abstract":"  As generative techniques pervade the audio domain, there has been increasing\ninterest in tracing back through these complicated models to understand how\nthey draw on their training data to synthesize new examples, both to ensure\nthat they use properly licensed data and also to elucidate their black box\nbehavior. In this paper, we show that if imperceptible echoes are hidden in the\ntraining data, a wide variety of audio to audio architectures (differentiable\ndigital signal processing (DDSP), Realtime Audio Variational autoEncoder\n(RAVE), and ``Dance Diffusion'') will reproduce these echoes in their outputs.\nHiding a single echo is particularly robust across all architectures, but we\nalso show promising results hiding longer time spread echo patterns for an\nincreased information capacity. We conclude by showing that echoes make their\nway into fine tuned models, that they survive mixing/demixing, and that they\nsurvive pitch shift augmentation during training. Hence, this simple, classical\nidea in watermarking shows significant promise for tagging generative audio\nmodels.\n","subjects":["Computer Science/Sound","Computer Science/Artificial Intelligence","Computer Science/Multimedia","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"80tkzmHt8cNLvF2FBJ0Fs9Ks_cSbEOad3HShfQ-7s7s","pdfSize":"2406946"}