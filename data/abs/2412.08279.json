{"id":"2412.08279","title":"Y-NQ: English-Yor\\`ub\\'a Evaluation dataset for Open-Book Reading\n  Comprehension and Text Generation","authors":"Marta R. Costa-juss\\`a, Joy Chen, Ifeoluwanimi Adebara, Joe Chuang,\n  Christophe Ropers, Eduardo S\\'anchez","authorsParsed":[["Costa-jussà","Marta R.",""],["Chen","Joy",""],["Adebara","Ifeoluwanimi",""],["Chuang","Joe",""],["Ropers","Christophe",""],["Sánchez","Eduardo",""]],"versions":[{"version":"v1","created":"Wed, 11 Dec 2024 10:52:29 GMT"}],"updateDate":"2024-12-12","timestamp":1733914349000,"abstract":"  The purpose of this work is to share an English-Yor\\`ub\\'a evaluation dataset\nfor open-book reading comprehension and text generation to assess the\nperformance of models both in a high- and a low- resource language. The dataset\ncontains 358 questions and answers on 338 English documents and 208 Yor\\`ub\\'a\ndocuments. The average document length is ~ 10k words for English and 430 words\nfor Yor\\`ub\\'a. Experiments show a consistent disparity in performance between\nthe two languages, with Yor\\`ub\\'a falling behind English for automatic metrics\neven if documents are much shorter for this language. For a small set of\ndocuments with comparable length, performance of Yor\\`ub\\'a drops by x2.5\ntimes. When analyzing performance by length, we observe that Yor\\`ub\\'a\ndecreases performance dramatically for documents that reach 1500 words while\nEnglish performance is barely affected at that length. Our dataset opens the\ndoor to showcasing if English LLM reading comprehension capabilities extend to\nYor\\`ub\\'a, which for the evaluated LLMs is not the case.\n","subjects":["Computer Science/Computation and Language"],"license":"http://creativecommons.org/licenses/by-sa/4.0/","blobId":"68IBwAgEnJU1HI57zMWdgYomDiPemPlVO9gzzUNtNm4","pdfSize":"366943"}