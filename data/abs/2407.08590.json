{"id":"2407.08590","title":"A Review of Nine Physics Engines for Reinforcement Learning Research","authors":"Michael Kaup, Cornelius Wolff, Hyerim Hwang, Julius Mayer, Elia Bruni","authorsParsed":[["Kaup","Michael",""],["Wolff","Cornelius",""],["Hwang","Hyerim",""],["Mayer","Julius",""],["Bruni","Elia",""]],"versions":[{"version":"v1","created":"Thu, 11 Jul 2024 15:13:28 GMT"},{"version":"v2","created":"Fri, 23 Aug 2024 07:16:52 GMT"}],"updateDate":"2024-08-26","timestamp":1720710808000,"abstract":"  We present a review of popular simulation engines and frameworks used in\nreinforcement learning (RL) research, aiming to guide researchers in selecting\ntools for creating simulated physical environments for RL and training setups.\nIt evaluates nine frameworks (Brax, Chrono, Gazebo, MuJoCo, ODE, PhysX,\nPyBullet, Webots, and Unity) based on their popularity, feature range, quality,\nusability, and RL capabilities. We highlight the challenges in selecting and\nutilizing physics engines for RL research, including the need for detailed\ncomparisons and an understanding of each framework's capabilities. Key findings\nindicate MuJoCo as the leading framework due to its performance and\nflexibility, despite usability challenges. Unity is noted for its ease of use\nbut lacks scalability and simulation fidelity. The study calls for further\ndevelopment to improve simulation engines' usability and performance and\nstresses the importance of transparency and reproducibility in RL research.\nThis review contributes to the RL community by offering insights into the\nselection process for simulation engines, facilitating informed\ndecision-making.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning","Computing Research Repository/Multiagent Systems"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"P5jvK5xPHnuS_bd6-ROiFTv4Sjb0cVpNXcjEfaRlnnk","pdfSize":"362988"}