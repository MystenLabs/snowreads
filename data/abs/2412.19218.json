{
  "id": "2412.19218",
  "title": "Transformer-Based Wireless Capsule Endoscopy Bleeding Tissue Detection\n  and Classification",
  "authors": "Basit Alawode, Shibani Hamza, Adarsh Ghimire, and Divya Velayudhan",
  "authorsParsed": [
    [
      "Alawode",
      "Basit",
      ""
    ],
    [
      "Hamza",
      "Shibani",
      ""
    ],
    [
      "Ghimire",
      "Adarsh",
      ""
    ],
    [
      "Velayudhan",
      "Divya",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Thu, 26 Dec 2024 13:49:39 GMT"
    }
  ],
  "updateDate": "2024-12-30",
  "timestamp": 1735220979000,
  "abstract": "  Informed by the success of the transformer model in various computer vision\ntasks, we design an end-to-end trainable model for the automatic detection and\nclassification of bleeding and non-bleeding frames extracted from Wireless\nCapsule Endoscopy (WCE) videos. Based on the DETR model, our model uses the\nResnet50 for feature extraction, the transformer encoder-decoder for bleeding\nand non-bleeding region detection, and a feedforward neural network for\nclassification. Trained in an end-to-end approach on the Auto-WCEBleedGen\nVersion 1 challenge training set, our model performs both detection and\nclassification tasks as a single unit. Our model achieves an accuracy, recall,\nand F1-score classification percentage score of 98.28, 96.79, and 98.37\nrespectively, on the Auto-WCEBleedGen version 1 validation set. Further, we\nrecord an average precision (AP @ 0.5), mean-average precision (mAP) of 0.7447\nand 0.7328 detection results. This earned us a 3rd place position in the\nchallenge. Our code is publicly available via\nhttps://github.com/BasitAlawode/WCEBleedGen.\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "UvW1MjiATf3z4wgiYn5KM_C_DNpKSmCTtwGT9GIXAo8",
  "pdfSize": "38060745"
}