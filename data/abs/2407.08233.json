{"id":"2407.08233","title":"Differentially Private Neural Network Training under Hidden State\n  Assumption","authors":"Ding Chen, Chen Liu","authorsParsed":[["Chen","Ding",""],["Liu","Chen",""]],"versions":[{"version":"v1","created":"Thu, 11 Jul 2024 07:14:40 GMT"}],"updateDate":"2024-07-12","timestamp":1720682080000,"abstract":"  We present a novel approach called differentially private stochastic block\ncoordinate descent (DP-SBCD) for training neural networks with provable\nguarantees of differential privacy under the hidden state assumption. Our\nmethodology incorporates Lipschitz neural networks and decomposes the training\nprocess of the neural network into sub-problems, each corresponding to the\ntraining of a specific layer. By doing so, we extend the analysis of\ndifferential privacy under the hidden state assumption to encompass non-convex\nproblems and algorithms employing proximal gradient descent. Furthermore, in\ncontrast to existing methods, we adopt a novel approach by utilizing calibrated\nnoise sampled from adaptive distributions, yielding improved empirical\ntrade-offs between utility and privacy.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"UJzoggq8TFBNZ02yabsIZOfaFQN8jurTuUEO6Jbdghc","pdfSize":"612613"}