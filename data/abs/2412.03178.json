{
  "id": "2412.03178",
  "title": "Towards Understanding and Quantifying Uncertainty for Text-to-Image\n  Generation",
  "authors": "Gianni Franchi, Dat Nguyen Trong, Nacim Belkhir, Guoxuan Xia, Andrea\n  Pilzer",
  "authorsParsed": [
    [
      "Franchi",
      "Gianni",
      ""
    ],
    [
      "Trong",
      "Dat Nguyen",
      ""
    ],
    [
      "Belkhir",
      "Nacim",
      ""
    ],
    [
      "Xia",
      "Guoxuan",
      ""
    ],
    [
      "Pilzer",
      "Andrea",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Wed, 4 Dec 2024 10:03:52 GMT"
    }
  ],
  "updateDate": "2024-12-05",
  "timestamp": 1733306632000,
  "abstract": "  Uncertainty quantification in text-to-image (T2I) generative models is\ncrucial for understanding model behavior and improving output reliability. In\nthis paper, we are the first to quantify and evaluate the uncertainty of T2I\nmodels with respect to the prompt. Alongside adapting existing approaches\ndesigned to measure uncertainty in the image space, we also introduce\nPrompt-based UNCertainty Estimation for T2I models (PUNC), a novel method\nleveraging Large Vision-Language Models (LVLMs) to better address uncertainties\narising from the semantics of the prompt and generated images. PUNC utilizes a\nLVLM to caption a generated image, and then compares the caption with the\noriginal prompt in the more semantically meaningful text space. PUNC also\nenables the disentanglement of both aleatoric and epistemic uncertainties via\nprecision and recall, which image-space approaches are unable to do. Extensive\nexperiments demonstrate that PUNC outperforms state-of-the-art uncertainty\nestimation techniques across various settings. Uncertainty quantification in\ntext-to-image generation models can be used on various applications including\nbias detection, copyright protection, and OOD detection. We also introduce a\ncomprehensive dataset of text prompts and generation pairs to foster further\nresearch in uncertainty quantification for generative models. Our findings\nillustrate that PUNC not only achieves competitive performance but also enables\nnovel applications in evaluating and improving the trustworthiness of\ntext-to-image models.\n",
  "subjects": [
    "Computer Science/Artificial Intelligence",
    "Computer Science/Computer Vision and Pattern Recognition",
    "Computer Science/Machine Learning"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "HsTiRVyPTCKDVL-Tf_qmTTkYQvaRSO6-VcDNRSqA6S8",
  "pdfSize": "15112893"
}