{
  "id": "2412.03567",
  "title": "Streaming Detection of Queried Event Start",
  "authors": "Cristobal Eyzaguirre, Eric Tang, Shyamal Buch, Adrien Gaidon, Jiajun\n  Wu, Juan Carlos Niebles",
  "authorsParsed": [
    [
      "Eyzaguirre",
      "Cristobal",
      ""
    ],
    [
      "Tang",
      "Eric",
      ""
    ],
    [
      "Buch",
      "Shyamal",
      ""
    ],
    [
      "Gaidon",
      "Adrien",
      ""
    ],
    [
      "Wu",
      "Jiajun",
      ""
    ],
    [
      "Niebles",
      "Juan Carlos",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Wed, 4 Dec 2024 18:58:27 GMT"
    }
  ],
  "updateDate": "2024-12-05",
  "timestamp": 1733338707000,
  "abstract": "  Robotics, autonomous driving, augmented reality, and many embodied computer\nvision applications must quickly react to user-defined events unfolding in real\ntime. We address this setting by proposing a novel task for multimodal video\nunderstanding-Streaming Detection of Queried Event Start (SDQES). The goal of\nSDQES is to identify the beginning of a complex event as described by a natural\nlanguage query, with high accuracy and low latency. We introduce a new\nbenchmark based on the Ego4D dataset, as well as new task-specific metrics to\nstudy streaming multimodal detection of diverse events in an egocentric video\nsetting. Inspired by parameter-efficient fine-tuning methods in NLP and for\nvideo tasks, we propose adapter-based baselines that enable image-to-video\ntransfer learning, allowing for efficient online video modeling. We evaluate\nthree vision-language backbones and three adapter architectures on both\nshort-clip and untrimmed video settings.\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "g4NHIwOz4y9K1qzBVBmShWeRRHHHJ1NoeP9rPO8yF04",
  "pdfSize": "6004140"
}