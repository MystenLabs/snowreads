{"id":"2407.09976","title":"Automated detection of gibbon calls from passive acoustic monitoring\n  data using convolutional neural networks in the \"torch for R\" ecosystem","authors":"Dena J. Clink, Jinsung Kim, Hope Cross-Jaya, Abdul Hamid Ahmad, Moeurk\n  Hong, Roeun Sala, H\\'el\\`ene Birot, Cain Agger, Thinh Tien Vu, Hoa Nguyen\n  Thi, Thanh Nguyen Chi, and Holger Klinck","authorsParsed":[["Clink","Dena J.",""],["Kim","Jinsung",""],["Cross-Jaya","Hope",""],["Ahmad","Abdul Hamid",""],["Hong","Moeurk",""],["Sala","Roeun",""],["Birot","Hélène",""],["Agger","Cain",""],["Vu","Thinh Tien",""],["Thi","Hoa Nguyen",""],["Chi","Thanh Nguyen",""],["Klinck","Holger",""]],"versions":[{"version":"v1","created":"Sat, 13 Jul 2024 18:44:04 GMT"},{"version":"v2","created":"Fri, 26 Jul 2024 16:06:08 GMT"}],"updateDate":"2024-07-29","timestamp":1720896244000,"abstract":"  Automated detection of acoustic signals is crucial for effective monitoring\nof vocal animals and their habitats across ecologically-relevant spatial and\ntemporal scales. Recent advances in deep learning have made these approaches\nmore accessible. However, there are few deep learning approaches that can be\nimplemented natively in the R programming environment; approaches that run\nnatively in R may be more accessible for ecologists. The \"torch for R\"\necosystem has made the use of transfer learning with convolutional neural\nnetworks accessible for R users. Here, we evaluate a workflow that uses\ntransfer learning for the automated detection of acoustic signals from passive\nacoustic monitoring (PAM) data. Our specific goals include: 1) present a method\nfor automated detection of gibbon calls from PAM data using the \"torch for R\"\necosystem; 2) compare the results of transfer learning for six pretrained CNN\narchitectures; and 3) investigate how well the different architectures perform\non datasets of the female calls from two different gibbon species: the northern\ngrey gibbon (Hylobates funereus) and the southern yellow-cheeked crested gibbon\n(Nomascus gabriellae). We found that the highest performing architecture\ndepended on the test dataset. We successfully deployed the top performing model\nfor each gibbon species to investigate spatial of variation in gibbon calling\nbehavior across two grids of autonomous recording units in Danum Valley\nConservation Area, Malaysia and Keo Seima Wildlife Sanctuary, Cambodia. The\nfields of deep learning and automated detection are rapidly evolving, and we\nprovide the methods and datasets as benchmarks for future work.\n","subjects":["Quantitative Biology/Quantitative Methods"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"8cebLTSVWq0LUk1DHVQa4D_cdrtOb2yGMqU9rNLn-LA","pdfSize":"3247709"}