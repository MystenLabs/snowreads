{"id":"2407.16516","title":"Assessing In-context Learning and Fine-tuning for Topic Classification\n  of German Web Data","authors":"Julian Schelb, Roberto Ulloa, Andreas Spitz","authorsParsed":[["Schelb","Julian",""],["Ulloa","Roberto",""],["Spitz","Andreas",""]],"versions":[{"version":"v1","created":"Tue, 23 Jul 2024 14:31:59 GMT"}],"updateDate":"2024-07-24","timestamp":1721745119000,"abstract":"  Researchers in the political and social sciences often rely on classification\nmodels to analyze trends in information consumption by examining browsing\nhistories of millions of webpages. Automated scalable methods are necessary due\nto the impracticality of manual labeling. In this paper, we model the detection\nof topic-related content as a binary classification task and compare the\naccuracy of fine-tuned pre-trained encoder models against in-context learning\nstrategies. Using only a few hundred annotated data points per topic, we detect\ncontent related to three German policies in a database of scraped webpages. We\ncompare multilingual and monolingual models, as well as zero and few-shot\napproaches, and investigate the impact of negative sampling strategies and the\ncombination of URL & content-based features. Our results show that a small\nsample of annotated data is sufficient to train an effective classifier.\nFine-tuning encoder-based models yields better results than in-context\nlearning. Classifiers using both URL & content-based features perform best,\nwhile using URLs alone provides adequate results when content is unavailable.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"-kWOGlyBKWj5nBaef4djJ3YGmJi0kHcTztvno5QghyA","pdfSize":"469833"}