{"id":"2412.08029","title":"NeRF-NQA: No-Reference Quality Assessment for Scenes Generated by NeRF\n  and Neural View Synthesis Methods","authors":"Qiang Qu, Hanxue Liang, Xiaoming Chen, Yuk Ying Chung, and Yiran Shen","authorsParsed":[["Qu","Qiang",""],["Liang","Hanxue",""],["Chen","Xiaoming",""],["Chung","Yuk Ying",""],["Shen","Yiran",""]],"versions":[{"version":"v1","created":"Wed, 11 Dec 2024 02:17:33 GMT"}],"updateDate":"2024-12-12","timestamp":1733883453000,"abstract":"  Neural View Synthesis (NVS) has demonstrated efficacy in generating\nhigh-fidelity dense viewpoint videos using a image set with sparse views.\nHowever, existing quality assessment methods like PSNR, SSIM, and LPIPS are not\ntailored for the scenes with dense viewpoints synthesized by NVS and NeRF\nvariants, thus, they often fall short in capturing the perceptual quality,\nincluding spatial and angular aspects of NVS-synthesized scenes. Furthermore,\nthe lack of dense ground truth views makes the full reference quality\nassessment on NVS-synthesized scenes challenging. For instance, datasets such\nas LLFF provide only sparse images, insufficient for complete full-reference\nassessments. To address the issues above, we propose NeRF-NQA, the first\nno-reference quality assessment method for densely-observed scenes synthesized\nfrom the NVS and NeRF variants. NeRF-NQA employs a joint quality assessment\nstrategy, integrating both viewwise and pointwise approaches, to evaluate the\nquality of NVS-generated scenes. The viewwise approach assesses the spatial\nquality of each individual synthesized view and the overall inter-views\nconsistency, while the pointwise approach focuses on the angular qualities of\nscene surface points and their compound inter-point quality. Extensive\nevaluations are conducted to compare NeRF-NQA with 23 mainstream visual quality\nassessment methods (from fields of image, video, and light-field assessment).\nThe results demonstrate NeRF-NQA outperforms the existing assessment methods\nsignificantly and it shows substantial superiority on assessing NVS-synthesized\nscenes without references. An implementation of this paper are available at\nhttps://github.com/VincentQQu/NeRF-NQA.\n","subjects":["Computer Science/Computer Vision and Pattern Recognition","Computer Science/Artificial Intelligence","Computer Science/Human-Computer Interaction","Computer Science/Multimedia","Electrical Engineering and Systems Science/Image and Video Processing"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"n4pvPSwGIgro-gK8BS9n-v-Emy07kXbNfzbLvpKROhA","pdfSize":"12662670"}