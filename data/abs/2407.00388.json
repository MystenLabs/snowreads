{"id":"2407.00388","title":"Weighted mesh algorithms for general Markov decision processes:\n  Convergence and tractability","authors":"Denis Belomestny, John Schoenmakers","authorsParsed":[["Belomestny","Denis",""],["Schoenmakers","John",""]],"versions":[{"version":"v1","created":"Sat, 29 Jun 2024 10:08:23 GMT"}],"updateDate":"2024-07-02","timestamp":1719655703000,"abstract":"  We introduce a mesh-type approach for tackling discrete-time, finite-horizon\nMarkov Decision Processes (MDPs) characterized by state and action spaces that\nare general, encompassing both finite and infinite (yet suitably regular)\nsubsets of Euclidean space. In particular, for bounded state and action spaces,\nour algorithm achieves a computational complexity that is tractable in the\nsense of Novak and Wozniakowski, and is polynomial in the time horizon. For\nunbounded state space the algorithm is \"semi-tractable\" in the sense that the\ncomplexity is proportional to $\\epsilon^{-c}$ with some dimension independent\n$c\\geq2$, for achieving an accuracy $\\epsilon$, and polynomial in the time\nhorizon with degree linear in the underlying dimension. As such the proposed\napproach has some flavor of the randomization method by Rust which deals with\ninfinite horizon MDPs and uniform sampling in compact state space. However, the\npresent approach is essentially different due to the finite horizon and a\nsimulation procedure due to general transition distributions, and more general\nin the sense that it encompasses unbounded state space. To demonstrate the\neffectiveness of our algorithm, we provide illustrations based on\nLinear-Quadratic Gaussian (LQG) control problems.\n","subjects":["Mathematics/Optimization and Control","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"lk5ddRgp3niYcsg-PhvWwtbpO1bHLKtp6crWIooJaGM","pdfSize":"671256"}