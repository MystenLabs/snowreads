{"id":"2407.04811","title":"Simplifying Deep Temporal Difference Learning","authors":"Matteo Gallici, Mattie Fellows, Benjamin Ellis, Bartomeu Pou, Ivan\n  Masmitja, Jakob Nicolaus Foerster, Mario Martin","authorsParsed":[["Gallici","Matteo",""],["Fellows","Mattie",""],["Ellis","Benjamin",""],["Pou","Bartomeu",""],["Masmitja","Ivan",""],["Foerster","Jakob Nicolaus",""],["Martin","Mario",""]],"versions":[{"version":"v1","created":"Fri, 5 Jul 2024 18:49:07 GMT"}],"updateDate":"2024-07-09","timestamp":1720205347000,"abstract":"  Q-learning played a foundational role in the field reinforcement learning\n(RL). However, TD algorithms with off-policy data, such as Q-learning, or\nnonlinear function approximation like deep neural networks require several\nadditional tricks to stabilise training, primarily a replay buffer and target\nnetworks. Unfortunately, the delayed updating of frozen network parameters in\nthe target network harms the sample efficiency and, similarly, the replay\nbuffer introduces memory and implementation overheads. In this paper, we\ninvestigate whether it is possible to accelerate and simplify TD training while\nmaintaining its stability. Our key theoretical result demonstrates for the\nfirst time that regularisation techniques such as LayerNorm can yield provably\nconvergent TD algorithms without the need for a target network, even with\noff-policy data. Empirically, we find that online, parallelised sampling\nenabled by vectorised environments stabilises training without the need of a\nreplay buffer. Motivated by these findings, we propose PQN, our simplified deep\nonline Q-Learning algorithm. Surprisingly, this simple algorithm is competitive\nwith more complex methods like: Rainbow in Atari, R2D2 in Hanabi, QMix in Smax,\nPPO-RNN in Craftax, and can be up to 50x faster than traditional DQN without\nsacrificing sample efficiency. In an era where PPO has become the go-to RL\nalgorithm, PQN reestablishes Q-learning as a viable alternative. We make our\ncode available at: https://github.com/mttga/purejaxql.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"ec76l90oDIb1rZUI1NoKo2MmZfqB8QSd49Ocb960cBY","pdfSize":"18259266"}
