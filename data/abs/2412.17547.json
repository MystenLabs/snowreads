{"id":"2412.17547","title":"Probability-density-aware Semi-supervised Learning","authors":"Shuyang Liu, Ruiqiu Zheng, Yunhang Shen, Ke Li, Xing Sun, Zhou Yu,\n  Shaohui Lin","authorsParsed":[["Liu","Shuyang",""],["Zheng","Ruiqiu",""],["Shen","Yunhang",""],["Li","Ke",""],["Sun","Xing",""],["Yu","Zhou",""],["Lin","Shaohui",""]],"versions":[{"version":"v1","created":"Mon, 23 Dec 2024 13:08:23 GMT"},{"version":"v2","created":"Tue, 7 Jan 2025 17:23:55 GMT"}],"updateDate":"2025-01-08","timestamp":1734959303000,"abstract":"  Semi-supervised learning (SSL) assumes that neighbor points lie in the same\ncategory (neighbor assumption), and points in different clusters belong to\nvarious categories (cluster assumption). Existing methods usually rely on\nsimilarity measures to retrieve the similar neighbor points, ignoring cluster\nassumption, which may not utilize unlabeled information sufficiently and\neffectively. This paper first provides a systematical investigation into the\nsignificant role of probability density in SSL and lays a solid theoretical\nfoundation for cluster assumption. To this end, we introduce a\nProbability-Density-Aware Measure (PM) to discern the similarity between\nneighbor points. To further improve Label Propagation, we also design a\nProbability-Density-Aware Measure Label Propagation (PMLP) algorithm to fully\nconsider the cluster assumption in label propagation. Last but not least, we\nprove that traditional pseudo-labeling could be viewed as a particular case of\nPMLP, which provides a comprehensive theoretical understanding of PMLP's\nsuperior performance. Extensive experiments demonstrate that PMLP achieves\noutstanding performance compared with other recent methods.\n","subjects":["Statistics/Machine Learning","Computer Science/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"bM_9457xfupxFhvMtfJBMnZCUXXnM00LkwsmdMYLn1A","pdfSize":"1351962"}