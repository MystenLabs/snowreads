{"id":"2412.04576","title":"Show, Don't Tell: Uncovering Implicit Character Portrayal using LLMs","authors":"Brandon Jaipersaud, Zining Zhu, Frank Rudzicz, Elliot Creager","authorsParsed":[["Jaipersaud","Brandon",""],["Zhu","Zining",""],["Rudzicz","Frank",""],["Creager","Elliot",""]],"versions":[{"version":"v1","created":"Thu, 5 Dec 2024 19:46:53 GMT"}],"updateDate":"2024-12-09","timestamp":1733428013000,"abstract":"  Tools for analyzing character portrayal in fiction are valuable for writers\nand literary scholars in developing and interpreting compelling stories.\nExisting tools, such as visualization tools for analyzing fictional characters,\nprimarily rely on explicit textual indicators of character attributes. However,\nportrayal is often implicit, revealed through actions and behaviors rather than\nexplicit statements. We address this gap by leveraging large language models\n(LLMs) to uncover implicit character portrayals. We start by generating a\ndataset for this task with greater cross-topic similarity, lexical diversity,\nand narrative lengths than existing narrative text corpora such as TinyStories\nand WritingPrompts. We then introduce LIIPA (LLMs for Inferring Implicit\nPortrayal for Character Analysis), a framework for prompting LLMs to uncover\ncharacter portrayals. LIIPA can be configured to use various types of\nintermediate computation (character attribute word lists, chain-of-thought) to\ninfer how fictional characters are portrayed in the source text. We find that\nLIIPA outperforms existing approaches, and is more robust to increasing\ncharacter counts (number of unique persons depicted) due to its ability to\nutilize full narrative context. Lastly, we investigate the sensitivity of\nportrayal estimates to character demographics, identifying a fairness-accuracy\ntradeoff among methods in our LIIPA framework -- a phenomenon familiar within\nthe algorithmic fairness literature. Despite this tradeoff, all LIIPA variants\nconsistently outperform non-LLM baselines in both fairness and accuracy. Our\nwork demonstrates the potential benefits of using LLMs to analyze complex\ncharacters and to better understand how implicit portrayal biases may manifest\nin narrative texts.\n","subjects":["Computer Science/Computation and Language","Computer Science/Artificial Intelligence","Computer Science/Computers and Society"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"VBRQAvK2bi8-wTCoS8nsrJFaJvMc9TcEYWCxpdWr99E","pdfSize":"653174"}