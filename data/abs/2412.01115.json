{
  "id": "2412.01115",
  "title": "DIR: Retrieval-Augmented Image Captioning with Comprehensive\n  Understanding",
  "authors": "Hao Wu, Zhihang Zhong, Xiao Sun",
  "authorsParsed": [
    [
      "Wu",
      "Hao",
      ""
    ],
    [
      "Zhong",
      "Zhihang",
      ""
    ],
    [
      "Sun",
      "Xiao",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Mon, 2 Dec 2024 04:39:17 GMT"
    }
  ],
  "updateDate": "2024-12-03",
  "timestamp": 1733114357000,
  "abstract": "  Image captioning models often suffer from performance degradation when\napplied to novel datasets, as they are typically trained on domain-specific\ndata. To enhance generalization in out-of-domain scenarios, retrieval-augmented\napproaches have garnered increasing attention. However, current methods face\ntwo key challenges: (1) image features used for retrieval are often optimized\nbased on ground-truth (GT) captions, which represent the image from a specific\nperspective and are influenced by annotator biases, and (2) they underutilize\nthe full potential of retrieved text, typically relying on raw captions or\nparsed objects, which fail to capture the full semantic richness of the data.\nIn this paper, we propose Dive Into Retrieval (DIR), a method designed to\nenhance both the image-to-text retrieval process and the utilization of\nretrieved text to achieve a more comprehensive understanding of the visual\ncontent. Our approach introduces two key innovations: (1) diffusion-guided\nretrieval enhancement, where a pretrained diffusion model guides image feature\nlearning by reconstructing noisy images, allowing the model to capture more\ncomprehensive and fine-grained visual information beyond standard annotated\ncaptions; and (2) a high-quality retrieval database, which provides\ncomprehensive semantic information to enhance caption generation, especially in\nout-of-domain scenarios. Extensive experiments demonstrate that DIR not only\nmaintains competitive in-domain performance but also significantly improves\nout-of-domain generalization, all without increasing inference costs.\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "HlDEF5QboYH5zxHtBCgVf4jDlkyOdDNBCNPCFgQWq2I",
  "pdfSize": "2841429"
}