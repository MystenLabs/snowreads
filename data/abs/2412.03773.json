{
  "id": "2412.03773",
  "title": "Modular addition without black-boxes: Compressing explanations of MLPs\n  that compute numerical integration",
  "authors": "Chun Hei Yip, Rajashree Agrawal, Lawrence Chan, Jason Gross",
  "authorsParsed": [
    [
      "Yip",
      "Chun Hei",
      ""
    ],
    [
      "Agrawal",
      "Rajashree",
      ""
    ],
    [
      "Chan",
      "Lawrence",
      ""
    ],
    [
      "Gross",
      "Jason",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Wed, 4 Dec 2024 23:29:07 GMT"
    }
  ],
  "updateDate": "2024-12-06",
  "timestamp": 1733354947000,
  "abstract": "  The goal of mechanistic interpretability is discovering simpler, low-rank\nalgorithms implemented by models. While we can compress activations into\nfeatures, compressing nonlinear feature-maps -- like MLP layers -- is an open\nproblem. In this work, we present the first case study in rigorously\ncompressing nonlinear feature-maps, which are the leading asymptotic bottleneck\nto compressing small transformer models. We work in the classic setting of the\nmodular addition models, and target a non-vacuous bound on the behaviour of the\nReLU MLP in time linear in the parameter-count of the circuit. To study the\nReLU MLP analytically, we use the infinite-width lens, which turns\npost-activation matrix multiplications into approximate integrals. We discover\na novel interpretation of} the MLP layer in one-layer transformers implementing\nthe ``pizza'' algorithm: the MLP can be understood as evaluating a quadrature\nscheme, where each neuron computes the area of a rectangle under the curve of a\ntrigonometric integral identity. Our code is available at\nhttps://tinyurl.com/mod-add-integration.\n",
  "subjects": [
    "Computer Science/Machine Learning",
    "Computer Science/Artificial Intelligence"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "kPywXUm4mXsH5gglNAqVqV3g4hWEZ-rWqCodOt9p8WQ",
  "pdfSize": "2197309"
}