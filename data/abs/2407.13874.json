{"id":"2407.13874","title":"Optimal high-precision shadow estimation","authors":"Sitan Chen, Jerry Li, Allen Liu","authorsParsed":[["Chen","Sitan",""],["Li","Jerry",""],["Liu","Allen",""]],"versions":[{"version":"v1","created":"Thu, 18 Jul 2024 19:42:49 GMT"}],"updateDate":"2024-07-22","timestamp":1721331769000,"abstract":"  We give the first tight sample complexity bounds for shadow tomography and\nclassical shadows in the regime where the target error is below some\nsufficiently small inverse polynomial in the dimension of the Hilbert space.\nFormally we give a protocol that, given any $m\\in\\mathbb{N}$ and $\\epsilon \\le\nO(d^{-12})$, measures $O(\\log(m)/\\epsilon^2)$ copies of an unknown mixed state\n$\\rho\\in\\mathbb{C}^{d\\times d}$ and outputs a classical description of $\\rho$\nwhich can then be used to estimate any collection of $m$ observables to within\nadditive accuracy $\\epsilon$. Previously, even for the simpler task of shadow\ntomography -- where the $m$ observables are known in advance -- the best known\nrates either scaled benignly but suboptimally in all of $m, d, \\epsilon$, or\nscaled optimally in $\\epsilon, m$ but had additional polynomial factors in $d$\nfor general observables. Intriguingly, we also show via dimensionality\nreduction, that we can rescale $\\epsilon$ and $d$ to reduce to the regime where\n$\\epsilon \\le O(d^{-1/2})$. Our algorithm draws upon representation-theoretic\ntools recently developed in the context of full state tomography.\n","subjects":["Physics/Quantum Physics","Computing Research Repository/Data Structures and Algorithms","Computing Research Repository/Information Theory","Computing Research Repository/Machine Learning","Mathematics/Information Theory"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"yogj_ZumwJkRC8IB_17fsD44lWoklaBkzJheHZ2PlfE","pdfSize":"786426"}