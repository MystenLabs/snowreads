{
  "id": "2412.11360",
  "title": "Visual IRL for Human-Like Robotic Manipulation",
  "authors": "Ehsan Asali, Prashant Doshi",
  "authorsParsed": [
    [
      "Asali",
      "Ehsan",
      ""
    ],
    [
      "Doshi",
      "Prashant",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Mon, 16 Dec 2024 01:23:13 GMT"
    }
  ],
  "updateDate": "2024-12-17",
  "timestamp": 1734312193000,
  "abstract": "  We present a novel method for collaborative robots (cobots) to learn\nmanipulation tasks and perform them in a human-like manner. Our method falls\nunder the learn-from-observation (LfO) paradigm, where robots learn to perform\ntasks by observing human actions, which facilitates quicker integration into\nindustrial settings compared to programming from scratch. We introduce Visual\nIRL that uses the RGB-D keypoints in each frame of the observed human task\nperformance directly as state features, which are input to inverse\nreinforcement learning (IRL). The inversely learned reward function, which maps\nkeypoints to reward values, is transferred from the human to the cobot using a\nnovel neuro-symbolic dynamics model, which maps human kinematics to the cobot\narm. This model allows similar end-effector positioning while minimizing joint\nadjustments, aiming to preserve the natural dynamics of human motion in robotic\nmanipulation. In contrast with previous techniques that focus on end-effector\nplacement only, our method maps multiple joint angles of the human arm to the\ncorresponding cobot joints. Moreover, it uses an inverse kinematics model to\nthen minimally adjust the joint angles, for accurate end-effector positioning.\nWe evaluate the performance of this approach on two different realistic\nmanipulation tasks. The first task is produce processing, which involves\npicking, inspecting, and placing onions based on whether they are blemished.\nThe second task is liquid pouring, where the robot picks up bottles, pours the\ncontents into designated containers, and disposes of the empty bottles. Our\nresults demonstrate advances in human-like robotic manipulation, leading to\nmore human-robot compatibility in manufacturing applications.\n",
  "subjects": [
    "Computer Science/Robotics",
    "Computer Science/Artificial Intelligence",
    "Computer Science/Computer Vision and Pattern Recognition"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "NovBs4xOrSZs7AsbxtQiu4KWbypmGQ9ylqebfIAy6bg",
  "pdfSize": "5805958"
}