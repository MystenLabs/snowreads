{"id":"2412.09023","title":"STEAM: Squeeze and Transform Enhanced Attention Module","authors":"Rishabh Sabharwal, Ram Samarth B B, Parikshit Singh Rathore, Punit\n  Rathore","authorsParsed":[["Sabharwal","Rishabh",""],["B","Ram Samarth B",""],["Rathore","Parikshit Singh",""],["Rathore","Punit",""]],"versions":[{"version":"v1","created":"Thu, 12 Dec 2024 07:38:10 GMT"}],"updateDate":"2024-12-13","timestamp":1733989090000,"abstract":"  Channel and spatial attention mechanisms introduced by earlier works enhance\nthe representation abilities of deep convolutional neural networks (CNNs) but\noften lead to increased parameter and computation costs. While recent\napproaches focus solely on efficient feature context modeling for channel\nattention, we aim to model both channel and spatial attention comprehensively\nwith minimal parameters and reduced computation. Leveraging the principles of\nrelational modeling in graphs, we introduce a constant-parameter module, STEAM:\nSqueeze and Transform Enhanced Attention Module, which integrates channel and\nspatial attention to enhance the representation power of CNNs. To our\nknowledge, we are the first to propose a graph-based approach for modeling both\nchannel and spatial attention, utilizing concepts from multi-head graph\ntransformers. Additionally, we introduce Output Guided Pooling (OGP), which\nefficiently captures spatial context to further enhance spatial attention. We\nextensively evaluate STEAM for large-scale image classification, object\ndetection and instance segmentation on standard benchmark datasets. STEAM\nachieves a 2% increase in accuracy over the standard ResNet-50 model with only\na meager increase in GFLOPs. Furthermore, STEAM outperforms leading modules ECA\nand GCT in terms of accuracy while achieving a three-fold reduction in GFLOPs.\n","subjects":["Computer Science/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"QDk109hUMoOyNJAGaRZowv5lI2TvQI3qDVsRP1EiIVQ","pdfSize":"1706856"}