{"id":"2407.18333","title":"AutoVCoder: A Systematic Framework for Automated Verilog Code Generation\n  using LLMs","authors":"Mingzhe Gao and Jieru Zhao and Zhe Lin and Wenchao Ding and Xiaofeng\n  Hou and Yu Feng and Chao Li and Minyi Guo","authorsParsed":[["Gao","Mingzhe",""],["Zhao","Jieru",""],["Lin","Zhe",""],["Ding","Wenchao",""],["Hou","Xiaofeng",""],["Feng","Yu",""],["Li","Chao",""],["Guo","Minyi",""]],"versions":[{"version":"v1","created":"Sun, 21 Jul 2024 16:42:45 GMT"}],"updateDate":"2024-07-29","timestamp":1721580165000,"abstract":"  Recently, the use of large language models (LLMs) for software code\ngeneration, e.g., C/C++ and Python, has proven a great success. However, LLMs\nstill suffer from low syntactic and functional correctness when it comes to the\ngeneration of register-transfer level (RTL) code, such as Verilog. To address\nthis issue, in this paper, we develop AutoVCoder, a systematic open-source\nframework that significantly improves the LLMs' correctness of generating\nVerilog code and enhances the quality of its output at the same time. Our\nframework integrates three novel techniques, including a high-quality hardware\ndataset generation approach, a two-round LLM fine-tuning method and a\ndomain-specific retrieval-augmented generation (RAG) mechanism. Experimental\nresults demonstrate that AutoVCoder outperforms both industrial and academic\nLLMs in Verilog code generation. Specifically, AutoVCoder shows a 0.5% and 2.2%\nimprovement in functional correctness on the EvalMachine and EvalHuman\nbenchmarks compared with BetterV, and also achieves a 3.4% increase in syntax\ncorrectness and a 3.4% increase in functional correctness on the RTLLM\nbenchmark compared with RTLCoder.\n","subjects":["Computing Research Repository/Hardware Architecture","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"hU7dCqAQH7vRcnC4ZCO-Q-c__BIkqYS3lCwDtiEPsaE","pdfSize":"537274","objectId":"0xa4142ac5cd63d98d56107e2ea7019af6a0102cef3ded7090e6331f9a0cb9875a","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
