{"id":"2407.04841","title":"Associative Recurrent Memory Transformer","authors":"Ivan Rodkin, Yuri Kuratov, Aydar Bulatov and Mikhail Burtsev","authorsParsed":[["Rodkin","Ivan",""],["Kuratov","Yuri",""],["Bulatov","Aydar",""],["Burtsev","Mikhail",""]],"versions":[{"version":"v1","created":"Fri, 5 Jul 2024 19:57:49 GMT"}],"updateDate":"2024-07-09","timestamp":1720209469000,"abstract":"  This paper addresses the challenge of creating a neural architecture for very\nlong sequences that requires constant time for processing new information at\neach time step. Our approach, Associative Recurrent Memory Transformer (ARMT),\nis based on transformer self-attention for local context and segment-level\nrecurrence for storage of task specific information distributed over a long\ncontext. We demonstrate that ARMT outperfors existing alternatives in\nassociative retrieval tasks and sets a new performance record in the recent\nBABILong multi-task long-context benchmark by answering single-fact questions\nover 50 million tokens with an accuracy of 79.9%. The source code for training\nand evaluation is available on github.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"85Llh8ypHzqWleBpEPdsBUzegLB_IVX9hmIpF4lSMSA","pdfSize":"1182411"}