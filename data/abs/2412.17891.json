{
  "id": "2412.17891",
  "title": "The Power of Adaptation: Boosting In-Context Learning through Adaptive\n  Prompting",
  "authors": "Shuzhang Cai, Twumasi Mensah-Boateng, Xander Kuksov, Jing Yuan,\n  Shaojie Tang",
  "authorsParsed": [
    [
      "Cai",
      "Shuzhang",
      ""
    ],
    [
      "Mensah-Boateng",
      "Twumasi",
      ""
    ],
    [
      "Kuksov",
      "Xander",
      ""
    ],
    [
      "Yuan",
      "Jing",
      ""
    ],
    [
      "Tang",
      "Shaojie",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Mon, 23 Dec 2024 15:49:43 GMT"
    }
  ],
  "updateDate": "2024-12-25",
  "timestamp": 1734968983000,
  "abstract": "  Large Language Models (LLMs) have demonstrated exceptional abilities across a\nbroad range of language-related tasks, including generating solutions to\ncomplex reasoning problems. An effective technique to enhance LLM performance\nis in-context learning, which encourages a step-by-step reasoning process by\nincluding explanatory examples to guide the model's responses. However,\nselecting appropriate exemplars for the model poses a challenge, as each\ndataset demands a distinct set of exemplars to enable the LLM to learn\neffectively and perform well on the test set. Current studies often rely on\nuncertainty- or diversity-based selection strategies to select exemplars for\nannotation and to improve model learning. However, these studies typically\nemploy a non-adaptive approach, selecting a set of exemplars all at once. We\nargue that this non-adaptive strategy may result in a set of exemplars with\nhigh redundancy in terms of the knowledge covered, ultimately reducing their\noverall informativeness. To address this limitation, we propose\n\\textsc{Adaptive-Prompt}, a novel method that adaptively selects exemplars by\nleveraging model feedback from previously chosen exemplars. Experimental\nresults show that \\textsc{Adaptive-Prompt} significantly enhances LLM\nperformance across a variety of reasoning tasks.\n",
  "subjects": [
    "Computer Science/Computation and Language",
    "Computer Science/Artificial Intelligence"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "YJwWxQAJnqg_VVk72umKLuvv32hUMRQiv3Gcp7Vci8o",
  "pdfSize": "675154"
}