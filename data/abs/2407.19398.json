{"id":"2407.19398","title":"IDEA: A Flexible Framework of Certified Unlearning for Graph Neural\n  Networks","authors":"Yushun Dong, Binchi Zhang, Zhenyu Lei, Na Zou, Jundong Li","authorsParsed":[["Dong","Yushun",""],["Zhang","Binchi",""],["Lei","Zhenyu",""],["Zou","Na",""],["Li","Jundong",""]],"versions":[{"version":"v1","created":"Sun, 28 Jul 2024 04:59:59 GMT"}],"updateDate":"2024-07-30","timestamp":1722142799000,"abstract":"  Graph Neural Networks (GNNs) have been increasingly deployed in a plethora of\napplications. However, the graph data used for training may contain sensitive\npersonal information of the involved individuals. Once trained, GNNs typically\nencode such information in their learnable parameters. As a consequence,\nprivacy leakage may happen when the trained GNNs are deployed and exposed to\npotential attackers. Facing such a threat, machine unlearning for GNNs has\nbecome an emerging technique that aims to remove certain personal information\nfrom a trained GNN. Among these techniques, certified unlearning stands out, as\nit provides a solid theoretical guarantee of the information removal\neffectiveness. Nevertheless, most of the existing certified unlearning methods\nfor GNNs are only designed to handle node and edge unlearning requests.\nMeanwhile, these approaches are usually tailored for either a specific design\nof GNN or a specially designed training objective. These disadvantages\nsignificantly jeopardize their flexibility. In this paper, we propose a\nprincipled framework named IDEA to achieve flexible and certified unlearning\nfor GNNs. Specifically, we first instantiate four types of unlearning requests\non graphs, and then we propose an approximation approach to flexibly handle\nthese unlearning requests over diverse GNNs. We further provide theoretical\nguarantee of the effectiveness for the proposed approach as a certification.\nDifferent from existing alternatives, IDEA is not designed for any specific\nGNNs or optimization objectives to perform certified unlearning, and thus can\nbe easily generalized. Extensive experiments on real-world datasets demonstrate\nthe superiority of IDEA in multiple key perspectives.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"k8xa0RAxtk3BIFNfWvtWwTOkY9i25r4TOFqVE-kEOtc","pdfSize":"1934037"}