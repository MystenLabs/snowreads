{
  "id": "2412.03825",
  "title": "Residual Hyperbolic Graph Convolution Networks",
  "authors": "Yangkai Xue, Jindou Dai, Zhipeng Lu, Yuwei Wu, Yunde Jia",
  "authorsParsed": [
    [
      "Xue",
      "Yangkai",
      ""
    ],
    [
      "Dai",
      "Jindou",
      ""
    ],
    [
      "Lu",
      "Zhipeng",
      ""
    ],
    [
      "Wu",
      "Yuwei",
      ""
    ],
    [
      "Jia",
      "Yunde",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Thu, 5 Dec 2024 02:38:45 GMT"
    }
  ],
  "updateDate": "2024-12-06",
  "timestamp": 1733366325000,
  "abstract": "  Hyperbolic graph convolutional networks (HGCNs) have demonstrated\nrepresentational capabilities of modeling hierarchical-structured graphs.\nHowever, as in general GCNs, over-smoothing may occur as the number of model\nlayers increases, limiting the representation capabilities of most current HGCN\nmodels. In this paper, we propose residual hyperbolic graph convolutional\nnetworks (R-HGCNs) to address the over-smoothing problem. We introduce a\nhyperbolic residual connection function to overcome the over-smoothing problem,\nand also theoretically prove the effectiveness of the hyperbolic residual\nfunction. Moreover, we use product manifolds and HyperDrop to facilitate the\nR-HGCNs. The distinctive features of the R-HGCNs are as follows: (1) The\nhyperbolic residual connection preserves the initial node information in each\nlayer and adds a hyperbolic identity mapping to prevent node features from\nbeing indistinguishable. (2) Product manifolds in R-HGCNs have been set up with\ndifferent origin points in different components to facilitate the extraction of\nfeature information from a wider range of perspectives, which enhances the\nrepresenting capability of R-HGCNs. (3) HyperDrop adds multiplicative Gaussian\nnoise into hyperbolic representations, such that perturbations can be added to\nalleviate the over-fitting problem without deconstructing the hyperbolic\ngeometry. Experiment results demonstrate the effectiveness of R-HGCNs under\nvarious graph convolution layers and different structures of product manifolds.\n",
  "subjects": [
    "Computer Science/Machine Learning"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "goAFj4aupaEyNEIwA5g5B188DWrzvvspHjjsghJCnVs",
  "pdfSize": "163340"
}