{"id":"2407.21635","title":"MART: MultiscAle Relational Transformer Networks for Multi-agent\n  Trajectory Prediction","authors":"Seongju Lee, Junseok Lee, Yeonguk Yu, Taeri Kim, Kyoobin Lee","authorsParsed":[["Lee","Seongju",""],["Lee","Junseok",""],["Yu","Yeonguk",""],["Kim","Taeri",""],["Lee","Kyoobin",""]],"versions":[{"version":"v1","created":"Wed, 31 Jul 2024 14:31:49 GMT"}],"updateDate":"2024-08-01","timestamp":1722436309000,"abstract":"  Multi-agent trajectory prediction is crucial to autonomous driving and\nunderstanding the surrounding environment. Learning-based approaches for\nmulti-agent trajectory prediction, such as primarily relying on graph neural\nnetworks, graph transformers, and hypergraph neural networks, have demonstrated\noutstanding performance on real-world datasets in recent years. However, the\nhypergraph transformer-based method for trajectory prediction is yet to be\nexplored. Therefore, we present a MultiscAle Relational Transformer (MART)\nnetwork for multi-agent trajectory prediction. MART is a hypergraph transformer\narchitecture to consider individual and group behaviors in transformer\nmachinery. The core module of MART is the encoder, which comprises a Pair-wise\nRelational Transformer (PRT) and a Hyper Relational Transformer (HRT). The\nencoder extends the capabilities of a relational transformer by introducing\nHRT, which integrates hyperedge features into the transformer mechanism,\npromoting attention weights to focus on group-wise relations. In addition, we\npropose an Adaptive Group Estimator (AGE) designed to infer complex group\nrelations in real-world environments. Extensive experiments on three real-world\ndatasets (NBA, SDD, and ETH-UCY) demonstrate that our method achieves\nstate-of-the-art performance, enhancing ADE/FDE by 3.9%/11.8% on the NBA\ndataset. Code is available at https://github.com/gist-ailab/MART.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"4klxBPkJtx_IArD_JwJaZ_5wtGklIhSLKxLh6z5ceiw","pdfSize":"9592158"}