{"id":"2407.02408","title":"CEB: Compositional Evaluation Benchmark for Fairness in Large Language\n  Models","authors":"Song Wang, Peng Wang, Tong Zhou, Yushun Dong, Zhen Tan, Jundong Li","authorsParsed":[["Wang","Song",""],["Wang","Peng",""],["Zhou","Tong",""],["Dong","Yushun",""],["Tan","Zhen",""],["Li","Jundong",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 16:31:37 GMT"}],"updateDate":"2024-07-03","timestamp":1719937897000,"abstract":"  As Large Language Models (LLMs) are increasingly deployed to handle various\nnatural language processing (NLP) tasks, concerns regarding the potential\nnegative societal impacts of LLM-generated content have also arisen. To\nevaluate the biases exhibited by LLMs, researchers have recently proposed a\nvariety of datasets. However, existing bias evaluation efforts often focus on\nonly a particular type of bias and employ inconsistent evaluation metrics,\nleading to difficulties in comparison across different datasets and LLMs. To\naddress these limitations, we collect a variety of datasets designed for the\nbias evaluation of LLMs, and further propose CEB, a Compositional Evaluation\nBenchmark that covers different types of bias across different social groups\nand tasks. The curation of CEB is based on our newly proposed compositional\ntaxonomy, which characterizes each dataset from three dimensions: bias types,\nsocial groups, and tasks. By combining the three dimensions, we develop a\ncomprehensive evaluation strategy for the bias in LLMs. Our experiments\ndemonstrate that the levels of bias vary across these dimensions, thereby\nproviding guidance for the development of specific bias mitigation methods.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"qophw-UjpddwZNhMX6zf7xlJwJb8oUP0nPlKyErb6g0","pdfSize":"4012360"}