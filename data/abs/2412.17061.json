{
  "id": "2412.17061",
  "title": "Multi-Agent Sampling: Scaling Inference Compute for Data Synthesis with\n  Tree Search-Based Agentic Collaboration",
  "authors": "Hai Ye, Mingbao Lin, Hwee Tou Ng, Shuicheng Yan",
  "authorsParsed": [
    [
      "Ye",
      "Hai",
      ""
    ],
    [
      "Lin",
      "Mingbao",
      ""
    ],
    [
      "Ng",
      "Hwee Tou",
      ""
    ],
    [
      "Yan",
      "Shuicheng",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Sun, 22 Dec 2024 15:16:44 GMT"
    }
  ],
  "updateDate": "2024-12-24",
  "timestamp": 1734880604000,
  "abstract": "  Scaling laws for inference compute in multi-agent systems remain\nunder-explored compared to single-agent scenarios. This work aims to bridge\nthis gap by investigating the problem of data synthesis through multi-agent\nsampling, where synthetic responses are generated by sampling from multiple\ndistinct language models. Effective model coordination is crucial for\nsuccessful multi-agent collaboration. Unlike previous approaches that rely on\nfixed workflows, we treat model coordination as a multi-step decision-making\nprocess, optimizing generation structures dynamically for each input question.\nWe introduce Tree Search-based Orchestrated Agents~(TOA), where the workflow\nevolves iteratively during the sequential sampling process. To achieve this, we\nleverage Monte Carlo Tree Search (MCTS), integrating a reward model to provide\nreal-time feedback and accelerate exploration. Our experiments on alignment,\nmachine translation, and mathematical reasoning demonstrate that multi-agent\nsampling significantly outperforms single-agent sampling as inference compute\nscales. TOA is the most compute-efficient approach, achieving SOTA performance\non WMT and a 71.8\\% LC win rate on AlpacaEval. Moreover, fine-tuning with our\nsynthesized alignment data surpasses strong preference learning methods on\nchallenging benchmarks such as Arena-Hard and AlpacaEval.\n",
  "subjects": [
    "Computer Science/Computation and Language"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "LcgbvtmveLPydjlTMXS3KULvQouB-SmQbXOJ4DRcD-I",
  "pdfSize": "3956599"
}