{
  "id": "2412.12226",
  "title": "Apollo-Forecast: Overcoming Aliasing and Inference Speed Challenges in\n  Language Models for Time Series Forecasting",
  "authors": "Tianyi Yin, Jingwei Wang, Yunlong Ma, Han Wang, Chenze Wang, Yukai\n  Zhao, Min Liu, Weiming Shen, Yufeng Chen",
  "authorsParsed": [
    [
      "Yin",
      "Tianyi",
      ""
    ],
    [
      "Wang",
      "Jingwei",
      ""
    ],
    [
      "Ma",
      "Yunlong",
      ""
    ],
    [
      "Wang",
      "Han",
      ""
    ],
    [
      "Wang",
      "Chenze",
      ""
    ],
    [
      "Zhao",
      "Yukai",
      ""
    ],
    [
      "Liu",
      "Min",
      ""
    ],
    [
      "Shen",
      "Weiming",
      ""
    ],
    [
      "Chen",
      "Yufeng",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Mon, 16 Dec 2024 11:01:20 GMT"
    }
  ],
  "updateDate": "2024-12-18",
  "timestamp": 1734346880000,
  "abstract": "  Encoding time series into tokens and using language models for processing has\nbeen shown to substantially augment the models' ability to generalize to unseen\ntasks. However, existing language models for time series forecasting encounter\nseveral obstacles, including aliasing distortion and prolonged inference times,\nprimarily due to the limitations of quantization processes and the\ncomputational demands of large models. This paper introduces Apollo-Forecast, a\nnovel framework that tackles these challenges with two key innovations: the\nAnti-Aliasing Quantization Module (AAQM) and the Race Decoding (RD) technique.\nAAQM adeptly encodes sequences into tokens while mitigating high-frequency\nnoise in the original signals, thus enhancing both signal fidelity and overall\nquantization efficiency. RD employs a draft model to enable parallel processing\nand results integration, which markedly accelerates the inference speed for\nlong-term predictions, particularly in large-scale models. Extensive\nexperiments on various real-world datasets show that Apollo-Forecast\noutperforms state-of-the-art methods by 35.41\\% and 18.99\\% in WQL and MASE\nmetrics, respectively, in zero-shot scenarios. Furthermore, our method achieves\na 1.9X-2.7X acceleration in inference speed over baseline methods.\n",
  "subjects": [
    "Computer Science/Machine Learning",
    "Computer Science/Artificial Intelligence"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "Gs7YcZJfoXhrPJqIV5Jc7jg2qvyUbrgrCTb_g1Tabow",
  "pdfSize": "12048800"
}