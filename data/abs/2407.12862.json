{"id":"2407.12862","title":"Analyzing Large language models chatbots: An experimental approach using\n  a probability test","authors":"Melise Peruchini, Julio Monteiro Teixeira","authorsParsed":[["Peruchini","Melise",""],["Teixeira","Julio Monteiro",""]],"versions":[{"version":"v1","created":"Wed, 10 Jul 2024 15:49:40 GMT"}],"updateDate":"2024-07-19","timestamp":1720626580000,"abstract":"  This study consists of qualitative empirical research, conducted through\nexploratory tests with two different Large Language Models (LLMs) chatbots:\nChatGPT and Gemini. The methodological procedure involved exploratory tests\nbased on prompts designed with a probability question. The \"Linda Problem\",\nwidely recognized in cognitive psychology, was used as a basis to create the\ntests, along with the development of a new problem specifically for this\nexperiment, the \"Mary Problem\". The object of analysis is the dataset with the\noutputs provided by each chatbot interaction. The purpose of the analysis is to\nverify whether the chatbots mainly employ logical reasoning that aligns with\nprobability theory or if they are more frequently affected by the stereotypical\ntextual descriptions in the prompts. The findings provide insights about the\napproach each chatbot employs in handling logic and textual constructions,\nsuggesting that, while the analyzed chatbots perform satisfactorily on a\nwell-known probabilistic problem, they exhibit significantly lower performance\non new tests that require direct application of probabilistic logic.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"HHFI-xzFdWhw1Dtte43TPVvE0UGWRoRr7Sp5s2v_PT8","pdfSize":"1107537"}