{
  "id": "2412.13989",
  "title": "What makes a good metric? Evaluating automatic metrics for text-to-image\n  consistency",
  "authors": "Candace Ross, Melissa Hall, Adriana Romero Soriano, Adina Williams",
  "authorsParsed": [
    [
      "Ross",
      "Candace",
      ""
    ],
    [
      "Hall",
      "Melissa",
      ""
    ],
    [
      "Soriano",
      "Adriana Romero",
      ""
    ],
    [
      "Williams",
      "Adina",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Wed, 18 Dec 2024 16:09:42 GMT"
    }
  ],
  "updateDate": "2024-12-19",
  "timestamp": 1734538182000,
  "abstract": "  Language models are increasingly being incorporated as components in larger\nAI systems for various purposes, from prompt optimization to automatic\nevaluation. In this work, we analyze the construct validity of four recent,\ncommonly used methods for measuring text-to-image consistency - CLIPScore,\nTIFA, VPEval, and DSG - which rely on language models and/or VQA models as\ncomponents. We define construct validity for text-image consistency metrics as\na set of desiderata that text-image consistency metrics should have, and find\nthat no tested metric satisfies all of them. We find that metrics lack\nsufficient sensitivity to language and visual properties. Next, we find that\nTIFA, VPEval and DSG contribute novel information above and beyond CLIPScore,\nbut also that they correlate highly with each other. We also ablate different\naspects of the text-image consistency metrics and find that not all model\ncomponents are strictly necessary, also a symptom of insufficient sensitivity\nto visual information. Finally, we show that all three VQA-based metrics likely\nrely on familiar text shortcuts (such as yes-bias in QA) that call their\naptitude as quantitative evaluations of model performance into question.\n",
  "subjects": [
    "Computer Science/Computation and Language"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "Wo05LriskirUg_jICxB9zBUU5guxtVnippHeOvis2PE",
  "pdfSize": "1279680"
}