{
  "id": "2412.15176",
  "title": "Rethinking Uncertainty Estimation in Natural Language Generation",
  "authors": "Lukas Aichberger, Kajetan Schweighofer, Sepp Hochreiter",
  "authorsParsed": [
    [
      "Aichberger",
      "Lukas",
      ""
    ],
    [
      "Schweighofer",
      "Kajetan",
      ""
    ],
    [
      "Hochreiter",
      "Sepp",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Thu, 19 Dec 2024 18:51:06 GMT"
    }
  ],
  "updateDate": "2024-12-20",
  "timestamp": 1734634266000,
  "abstract": "  Large Language Models (LLMs) are increasingly employed in real-world\napplications, driving the need to evaluate the trustworthiness of their\ngenerated text. To this end, reliable uncertainty estimation is essential.\nSince current LLMs generate text autoregressively through a stochastic process,\nthe same prompt can lead to varying outputs. Consequently, leading uncertainty\nestimation methods generate and analyze multiple output sequences to determine\nthe LLM's uncertainty. However, generating output sequences is computationally\nexpensive, making these methods impractical at scale. In this work, we inspect\nthe theoretical foundations of the leading methods and explore new directions\nto enhance their computational efficiency. Building on the framework of proper\nscoring rules, we find that the negative log-likelihood of the most likely\noutput sequence constitutes a theoretically grounded uncertainty measure. To\napproximate this alternative measure, we propose G-NLL, which has the advantage\nof being obtained using only a single output sequence generated by greedy\ndecoding. This makes uncertainty estimation more efficient and straightforward,\nwhile preserving theoretical rigor. Empirical results demonstrate that G-NLL\nachieves state-of-the-art performance across various LLMs and tasks. Our work\nlays the foundation for efficient and reliable uncertainty estimation in\nnatural language generation, challenging the necessity of more computationally\ninvolved methods currently leading the field.\n",
  "subjects": [
    "Computer Science/Machine Learning"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "rzp9G1-1iV-FVSfZBwumkdN1cwoOTf-7UMoNQ7Hw990",
  "pdfSize": "573812"
}