{"id":"2412.20322","title":"GreenLLM: Disaggregating Large Language Model Serving on Heterogeneous\n  GPUs for Lower Carbon Emissions","authors":"Tianyao Shi, Yanran Wu, Sihang Liu, Yi Ding","authorsParsed":[["Shi","Tianyao",""],["Wu","Yanran",""],["Liu","Sihang",""],["Ding","Yi",""]],"versions":[{"version":"v1","created":"Sun, 29 Dec 2024 02:20:33 GMT"}],"updateDate":"2024-12-31","timestamp":1735438833000,"abstract":"  LLMs have been widely adopted across many real-world applications. However,\ntheir widespread use comes with significant environmental costs due to their\nhigh computational intensity and resource demands. Specifically, this has\ndriven the development of new generations of high-performing GPUs, exacerbating\nthe problem of electronic waste and accelerating the premature disposal of\ndevices. To address this problem, this paper focuses on reducing the carbon\nemissions of LLM serving by reusing older, low-performing GPUs. We present\nGreenLLM, an SLO-aware LLM serving framework designed to minimize carbon\nemissions by reusing older GPUs. GreenLLM builds on two identified use cases\nthat disaggregate specific computations onto older GPUs, reducing carbon\nemissions while meeting performance goals. To deepen our understanding of the\npotential carbon savings from disaggregation, we also provide a theoretical\nanalysis of its relationship with carbon intensity and GPU lifetime. Our\nevaluations show that GreenLLM reduces carbon emissions by up to 40.6% compared\nto running standard LLM serving on new GPU only, meeting latency SLOs for over\n90% of requests across various applications, latency requirements, carbon\nintensities, and GPU lifetimes.\n","subjects":["Computer Science/Hardware Architecture","Computer Science/Distributed, Parallel, and Cluster Computing"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"ukkoSZ2H7mqOpcP07065UA0KWPzOsmNZa3ugLIY5R5E","pdfSize":"814692"}