{"id":"2407.01697","title":"NLPGuard: A Framework for Mitigating the Use of Protected Attributes by\n  NLP Classifiers","authors":"Salvatore Greco, Ke Zhou, Licia Capra, Tania Cerquitelli, Daniele\n  Quercia","authorsParsed":[["Greco","Salvatore",""],["Zhou","Ke",""],["Capra","Licia",""],["Cerquitelli","Tania",""],["Quercia","Daniele",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 18:08:17 GMT"}],"updateDate":"2024-07-03","timestamp":1719857297000,"abstract":"  AI regulations are expected to prohibit machine learning models from using\nsensitive attributes during training. However, the latest Natural Language\nProcessing (NLP) classifiers, which rely on deep learning, operate as black-box\nsystems, complicating the detection and remediation of such misuse. Traditional\nbias mitigation methods in NLP aim for comparable performance across different\ngroups based on attributes like gender or race but fail to address the\nunderlying issue of reliance on protected attributes. To partly fix that, we\nintroduce NLPGuard, a framework for mitigating the reliance on protected\nattributes in NLP classifiers. NLPGuard takes an unlabeled dataset, an existing\nNLP classifier, and its training data as input, producing a modified training\ndataset that significantly reduces dependence on protected attributes without\ncompromising accuracy. NLPGuard is applied to three classification tasks:\nidentifying toxic language, sentiment analysis, and occupation classification.\nOur evaluation shows that current NLP classifiers heavily depend on protected\nattributes, with up to $23\\%$ of the most predictive words associated with\nthese attributes. However, NLPGuard effectively reduces this reliance by up to\n$79\\%$, while slightly improving accuracy.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Human-Computer Interaction"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"ZULLRM90mLVtktsny1mY7LwaGDl6BbBcAz9APM6b3O4","pdfSize":"1734294"}