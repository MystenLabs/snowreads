{"id":"2407.10725","title":"CLAVE: An Adaptive Framework for Evaluating Values of LLM Generated\n  Responses","authors":"Jing Yao, Xiaoyuan Yi, Xing Xie","authorsParsed":[["Yao","Jing",""],["Yi","Xiaoyuan",""],["Xie","Xing",""]],"versions":[{"version":"v1","created":"Mon, 15 Jul 2024 13:51:37 GMT"}],"updateDate":"2024-07-16","timestamp":1721051497000,"abstract":"  The rapid progress in Large Language Models (LLMs) poses potential risks such\nas generating unethical content. Assessing LLMs' values can help expose their\nmisalignment, but relies on reference-free evaluators, e.g., fine-tuned LLMs or\nclose-source ones like GPT-4, to identify values reflected in generated\nresponses. Nevertheless, these evaluators face two challenges in open-ended\nvalue evaluation: they should align with changing human value definitions with\nminimal annotation, against their own bias (adaptability), and detect varying\nvalue expressions and scenarios robustly (generalizability). To handle these\nchallenges, we introduce CLAVE, a novel framework which integrates two\ncomplementary LLMs, a large one to extract high-level value concepts from a few\nhuman labels, leveraging its extensive knowledge and generalizability, and a\nsmaller one fine-tuned on such concepts to better align with human value\nunderstanding. This dual-model approach enables calibration with any value\nsystems using <100 human-labeled samples per value type. Then we present\nValEval, a comprehensive dataset comprising 13k+ (text,value,label) tuples\nacross diverse domains, covering three major value systems. We benchmark the\ncapabilities of 12+ popular LLM evaluators and analyze their strengths and\nweaknesses. Our findings reveal that combining fine-tuned small models and\nprompt-based large ones serves as a superior balance in value evaluation.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"Luhb9qxxeXMjQMVqY2oEHnchx_DXrj2mL0C74wtZuRY","pdfSize":"2751631"}