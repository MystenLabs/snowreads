{"id":"2412.14744","title":"A parametric algorithm is optimal for non-parametric regression of\n  smooth functions","authors":"Davide Maran, Marcello Restelli","authorsParsed":[["Maran","Davide",""],["Restelli","Marcello",""]],"versions":[{"version":"v1","created":"Thu, 19 Dec 2024 11:22:52 GMT"}],"updateDate":"2024-12-20","timestamp":1734607372000,"abstract":"  We address the regression problem for a general function $f:[-1,1]^d\\to\n\\mathbb R$ when the learner selects the training points $\\{x_i\\}_{i=1}^n$ to\nachieve a uniform error bound across the entire domain. In this setting, known\nhistorically as nonparametric regression, we aim to establish a sample\ncomplexity bound that depends solely on the function's degree of smoothness.\nAssuming periodicity at the domain boundaries, we introduce PADUA, an algorithm\nthat, with high probability, provides performance guarantees optimal up to\nconstant or logarithmic factors across all problem parameters. Notably, PADUA\nis the first parametric algorithm with optimal sample complexity for this\nsetting. Due to this feature, we prove that, differently from the\nnon-parametric state of the art, PADUA enjoys optimal space complexity in the\nprediction phase. To validate these results, we perform numerical experiments\nover functions coming from real audio data, where PADUA shows comparable\nperformance to state-of-the-art methods, while requiring only a fraction of the\ncomputational time.\n","subjects":["Computer Science/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"lCytQ9_G0-R6FRgu-BdIgBQchHxQomq10Aeh8u9k_BM","pdfSize":"677562"}