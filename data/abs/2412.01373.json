{"id":"2412.01373","title":"Hierarchical VAE with a Diffusion-based VampPrior","authors":"Anna Kuzina, Jakub M. Tomczak","authorsParsed":[["Kuzina","Anna",""],["Tomczak","Jakub M.",""]],"versions":[{"version":"v1","created":"Mon, 2 Dec 2024 10:58:09 GMT"}],"updateDate":"2024-12-03","timestamp":1733137089000,"abstract":"  Deep hierarchical variational autoencoders (VAEs) are powerful latent\nvariable generative models. In this paper, we introduce Hierarchical VAE with\nDiffusion-based Variational Mixture of the Posterior Prior (VampPrior). We\napply amortization to scale the VampPrior to models with many stochastic\nlayers. The proposed approach allows us to achieve better performance compared\nto the original VampPrior work and other deep hierarchical VAEs, while using\nfewer parameters. We empirically validate our method on standard benchmark\ndatasets (MNIST, OMNIGLOT, CIFAR10) and demonstrate improved training stability\nand latent space utilization.\n","subjects":["Computer Science/Machine Learning","Statistics/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"ngnS0CcRuTwYllXaIBEWoZ25lyFOmvSvW6vJj_AchgQ","pdfSize":"7863039"}