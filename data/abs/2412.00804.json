{"id":"2412.00804","title":"Examining Identity Drift in Conversations of LLM Agents","authors":"Junhyuk Choi, Yeseon Hong, Minju Kim, Bugeun Kim","authorsParsed":[["Choi","Junhyuk",""],["Hong","Yeseon",""],["Kim","Minju",""],["Kim","Bugeun",""]],"versions":[{"version":"v1","created":"Sun, 1 Dec 2024 13:19:32 GMT"},{"version":"v2","created":"Mon, 17 Feb 2025 03:11:38 GMT"}],"updateDate":"2025-02-18","timestamp":1733059172000,"abstract":"  Large Language Models (LLMs) show impressive conversational abilities but\nsometimes show identity drift problems, where their interaction patterns or\nstyles change over time. As the problem has not been thoroughly examined yet,\nthis study examines identity consistency across nine LLMs. Specifically, we (1)\ninvestigate whether LLMs could maintain consistent patterns (or identity) and\n(2) analyze the effect of the model family, parameter sizes, and provided\npersona types. Our experiments involve multi-turn conversations on personal\nthemes, analyzed in qualitative and quantitative ways. Experimental results\nindicate three findings. (1) Larger models experience greater identity drift.\n(2) Model differences exist, but their effect is not stronger than parameter\nsizes. (3) Assigning a persona may not help to maintain identity. We hope these\nthree findings can help to improve persona stability in AI-driven dialogue\nsystems, particularly in long-term conversations.\n","subjects":["Computer Science/Computers and Society","Computer Science/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"n1SbRtVNp3MffDDjJf3ojMoPaJEmVzLEA0PFgsj2YpY","pdfSize":"383465"}