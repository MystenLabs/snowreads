{"id":"2412.18053","title":"Neuron Empirical Gradient: Discovering and Quantifying Neurons Global\n  Linear Controllability","authors":"Xin Zhao, Zehui Jiang, Naoki Yoshinaga","authorsParsed":[["Zhao","Xin",""],["Jiang","Zehui",""],["Yoshinaga","Naoki",""]],"versions":[{"version":"v1","created":"Tue, 24 Dec 2024 00:01:24 GMT"},{"version":"v2","created":"Mon, 17 Feb 2025 03:19:24 GMT"}],"updateDate":"2025-02-18","timestamp":1734998484000,"abstract":"  Although feed-forward neurons in pre-trained language models (PLMs) can store\nknowledge and their importance in influencing model outputs has been studied,\nexisting work focuses on finding a limited set of neurons and analyzing their\nrelative importance. However, the global quantitative role of activation values\nin shaping outputs remains unclear, hindering further advancements in\napplications like knowledge editing. Our study first investigates the numerical\nrelationship between neuron activations and model output and discovers the\nglobal linear relationship between them through neuron interventions on a\nknowledge probing dataset. We refer to the gradient of this linear relationship\nas neuron empirical gradient (NEG), and introduce NeurGrad, an accurate and\nefficient method for computing NEG. NeurGrad enables quantitative analysis of\nall neurons in PLMs, advancing our understanding of neurons' controllability.\nFurthermore, we explore NEG's ability to represent language skills across\ndiverse prompts via skill neuron probing. Experiments on MCEval8k, a\nmulti-choice knowledge benchmark spanning various genres, validate NEG's\nrepresentational ability. The data and code are released.\n","subjects":["Computer Science/Computation and Language","Computer Science/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by-sa/4.0/","blobId":"waEt9qxB9A6XXHKmCNu90MzuUsQt2w2Ks4Lc7ox3IFg","pdfSize":"5166467"}