{
  "id": "2412.11983",
  "title": "Cost-Effective Label-free Node Classification with LLMs",
  "authors": "Taiyan Zhang, Renchi Yang, Mingyu Yan, Xiaochun Ye, Dongrui Fan, Yurui\n  Lai",
  "authorsParsed": [
    [
      "Zhang",
      "Taiyan",
      ""
    ],
    [
      "Yang",
      "Renchi",
      ""
    ],
    [
      "Yan",
      "Mingyu",
      ""
    ],
    [
      "Ye",
      "Xiaochun",
      ""
    ],
    [
      "Fan",
      "Dongrui",
      ""
    ],
    [
      "Lai",
      "Yurui",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Mon, 16 Dec 2024 17:04:40 GMT"
    }
  ],
  "updateDate": "2024-12-17",
  "timestamp": 1734368680000,
  "abstract": "  Graph neural networks (GNNs) have emerged as go-to models for node\nclassification in graph data due to their powerful abilities in fusing graph\nstructures and attributes. However, such models strongly rely on adequate\nhigh-quality labeled data for training, which are expensive to acquire in\npractice. With the advent of large language models (LLMs), a promising way is\nto leverage their superb zero-shot capabilities and massive knowledge for node\nlabeling. Despite promising results reported, this methodology either demands\nconsiderable queries to LLMs, or suffers from compromised performance caused by\nnoisy labels produced by LLMs.\n  To remedy these issues, this work presents Cella, an active self-training\nframework that integrates LLMs into GNNs in a cost-effective manner. The design\nrecipe of Cella is to iteratively identify small sets of \"critical\" samples\nusing GNNs and extract informative pseudo-labels for them with both LLMs and\nGNNs as additional supervision signals to enhance model training. Particularly,\nCella includes three major components: (i) an effective active node selection\nstrategy for initial annotations; (ii) a judicious sample selection scheme to\nsift out the \"critical\" nodes based on label disharmonicity and entropy; and\n(iii) a label refinement module combining LLMs and GNNs with rewired topology.\nOur extensive experiments over five benchmark text-attributed graph datasets\ndemonstrate that Cella significantly outperforms the state of the arts under\nthe same query budget to LLMs in terms of label-free node classification. In\nparticular, on the DBLP dataset with 14.3k nodes, Cella is able to achieve an\n8.08% conspicuous improvement in accuracy over the state-of-the-art at a cost\nof less than one cent.\n",
  "subjects": [
    "Computer Science/Machine Learning",
    "Computer Science/Artificial Intelligence"
  ],
  "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
  "blobId": "t35waJGL2DwWw4_ZvQ_KwqlZwUW4stnFctpWc8XKaHo",
  "pdfSize": "1183918"
}