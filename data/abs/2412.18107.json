{"id":"2412.18107","title":"SongGLM: Lyric-to-Melody Generation with 2D Alignment Encoding and\n  Multi-Task Pre-Training","authors":"Jiaxing Yu, Xinda Wu, Yunfei Xu, Tieyao Zhang, Songruoyao Wu, Le Ma,\n  Kejun Zhang","authorsParsed":[["Yu","Jiaxing",""],["Wu","Xinda",""],["Xu","Yunfei",""],["Zhang","Tieyao",""],["Wu","Songruoyao",""],["Ma","Le",""],["Zhang","Kejun",""]],"versions":[{"version":"v1","created":"Tue, 24 Dec 2024 02:30:07 GMT"}],"updateDate":"2024-12-25","timestamp":1735007407000,"abstract":"  Lyric-to-melody generation aims to automatically create melodies based on\ngiven lyrics, requiring the capture of complex and subtle correlations between\nthem. However, previous works usually suffer from two main challenges: 1)\nlyric-melody alignment modeling, which is often simplified to\none-syllable/word-to-one-note alignment, while others have the problem of low\nalignment accuracy; 2) lyric-melody harmony modeling, which usually relies\nheavily on intermediates or strict rules, limiting model's capabilities and\ngenerative diversity. In this paper, we propose SongGLM, a lyric-to-melody\ngeneration system that leverages 2D alignment encoding and multi-task\npre-training based on the General Language Model (GLM) to guarantee the\nalignment and harmony between lyrics and melodies. Specifically, 1) we\nintroduce a unified symbolic song representation for lyrics and melodies with\nword-level and phrase-level (2D) alignment encoding to capture the lyric-melody\nalignment; 2) we design a multi-task pre-training framework with hierarchical\nblank infilling objectives (n-gram, phrase, and long span), and incorporate\nlyric-melody relationships into the extraction of harmonized n-grams to ensure\nthe lyric-melody harmony. We also construct a large-scale lyric-melody paired\ndataset comprising over 200,000 English song pieces for pre-training and\nfine-tuning. The objective and subjective results indicate that SongGLM can\ngenerate melodies from lyrics with significant improvements in both alignment\nand harmony, outperforming all the previous baseline methods.\n","subjects":["Electrical Engineering and Systems Science/Audio and Speech Processing","Computer Science/Artificial Intelligence","Computer Science/Sound"],"license":"http://creativecommons.org/licenses/by-sa/4.0/","blobId":"VOywdlGWFRxWJL9m2TCVUNSJszs44siheYfPQ1gKOEE","pdfSize":"1695097"}