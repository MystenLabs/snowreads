{
  "id": "2412.13486",
  "title": "T$^3$-S2S: Training-free Triplet Tuning for Sketch to Scene Generation",
  "authors": "Zhenhong Sun, Yifu Wang, Yonhon Ng, Yunfei Duan, Daoyi Dong, Hongdong\n  Li, Pan Ji",
  "authorsParsed": [
    [
      "Sun",
      "Zhenhong",
      ""
    ],
    [
      "Wang",
      "Yifu",
      ""
    ],
    [
      "Ng",
      "Yonhon",
      ""
    ],
    [
      "Duan",
      "Yunfei",
      ""
    ],
    [
      "Dong",
      "Daoyi",
      ""
    ],
    [
      "Li",
      "Hongdong",
      ""
    ],
    [
      "Ji",
      "Pan",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Wed, 18 Dec 2024 04:01:32 GMT"
    }
  ],
  "updateDate": "2024-12-19",
  "timestamp": 1734494492000,
  "abstract": "  Scene generation is crucial to many computer graphics applications. Recent\nadvances in generative AI have streamlined sketch-to-image workflows, easing\nthe workload for artists and designers in creating scene concept art. However,\nthese methods often struggle for complex scenes with multiple detailed objects,\nsometimes missing small or uncommon instances. In this paper, we propose a\nTraining-free Triplet Tuning for Sketch-to-Scene (T3-S2S) generation after\nreviewing the entire cross-attention mechanism. This scheme revitalizes the\nexisting ControlNet model, enabling effective handling of multi-instance\ngenerations, involving prompt balance, characteristics prominence, and dense\ntuning. Specifically, this approach enhances keyword representation via the\nprompt balance module, reducing the risk of missing critical instances. It also\nincludes a characteristics prominence module that highlights TopK indices in\neach channel, ensuring essential features are better represented based on token\nsketches. Additionally, it employs dense tuning to refine contour details in\nthe attention map, compensating for instance-related regions. Experiments\nvalidate that our triplet tuning approach substantially improves the\nperformance of existing sketch-to-image models. It consistently generates\ndetailed, multi-instance 2D images, closely adhering to the input prompts and\nenhancing visual quality in complex multi-instance scenes. Code is available at\nhttps://github.com/chaos-sun/t3s2s.git.\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition",
    "Computer Science/Computation and Language",
    "Computer Science/Graphics"
  ],
  "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
  "blobId": "aZsMqfkS0_FjvvdXTQqT7p-0rxMEJUp24a9HcJa0rq0",
  "pdfSize": "39296801"
}