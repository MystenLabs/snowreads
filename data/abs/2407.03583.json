{"id":"2407.03583","title":"Loki: A System for Serving ML Inference Pipelines with Hardware and\n  Accuracy Scaling","authors":"Sohaib Ahmad, Hui Guan, Ramesh K. Sitaraman","authorsParsed":[["Ahmad","Sohaib",""],["Guan","Hui",""],["Sitaraman","Ramesh K.",""]],"versions":[{"version":"v1","created":"Thu, 4 Jul 2024 02:23:58 GMT"}],"updateDate":"2024-07-08","timestamp":1720059838000,"abstract":"  The rapid adoption of machine learning (ML) has underscored the importance of\nserving ML models with high throughput and resource efficiency. Traditional\napproaches to managing increasing query demands have predominantly focused on\nhardware scaling, which involves increasing server count or computing power.\nHowever, this strategy can often be impractical due to limitations in the\navailable budget or compute resources. As an alternative, accuracy scaling\noffers a promising solution by adjusting the accuracy of ML models to\naccommodate fluctuating query demands. Yet, existing accuracy scaling\ntechniques target independent ML models and tend to underperform while managing\ninference pipelines. Furthermore, they lack integration with hardware scaling,\nleading to potential resource inefficiencies during low-demand periods. To\naddress the limitations, this paper introduces Loki, a system designed for\nserving inference pipelines effectively with both hardware and accuracy\nscaling. Loki incorporates an innovative theoretical framework for optimal\nresource allocation and an effective query routing algorithm, aimed at\nimproving system accuracy and minimizing latency deadline violations. Our\nempirical evaluation demonstrates that through accuracy scaling, the effective\ncapacity of a fixed-size cluster can be enhanced by more than $2.7\\times$\ncompared to relying solely on hardware scaling. When compared with\nstate-of-the-art inference-serving systems, Loki achieves up to a $10\\times$\nreduction in Service Level Objective (SLO) violations, with minimal compromises\non accuracy and while fulfilling throughput demands.\n","subjects":["Computing Research Repository/Distributed, Parallel, and Cluster Computing"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"qghwLyeqBBK2OdSbpbVUPIEL0Q4J-eHOk3oD3URnsvc","pdfSize":"987518"}
