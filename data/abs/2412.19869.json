{
  "id": "2412.19869",
  "title": "A Fully Hardware Implemented Accelerator Design in ReRAM Analog\n  Computing without ADCs",
  "authors": "Peng Dang, Huawei Li, Wei Wang",
  "authorsParsed": [
    [
      "Dang",
      "Peng",
      ""
    ],
    [
      "Li",
      "Huawei",
      ""
    ],
    [
      "Wang",
      "Wei",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Fri, 27 Dec 2024 09:38:19 GMT"
    }
  ],
  "updateDate": "2024-12-31",
  "timestamp": 1735292299000,
  "abstract": "  Emerging ReRAM-based accelerators process neural networks via analog\nComputing-in-Memory (CiM) for ultra-high energy efficiency. However,\nsignificant overhead in peripheral circuits and complex nonlinear activation\nmodes constrain system energy efficiency improvements. This work explores the\nhardware implementation of the Sigmoid and SoftMax activation functions of\nneural networks with stochastically binarized neurons by utilizing sampled\nnoise signals from ReRAM devices to achieve a stochastic effect. We propose a\ncomplete ReRAM-based Analog Computing Accelerator (RACA) that accelerates\nneural network computation by leveraging stochastically binarized neurons in\ncombination with ReRAM crossbars. The novel circuit design removes significant\nsources of energy/area efficiency degradation, i.e., the Digital-to-Analog and\nAnalog-to-Digital Converters (DACs and ADCs) as well as the components to\nexplicitly calculate the activation functions. Experimental results show that\nour proposed design outperforms traditional architectures across all overall\nperformance metrics without compromising inference accuracy.\n",
  "subjects": [
    "Computer Science/Hardware Architecture",
    "Computer Science/Artificial Intelligence"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "tEW9jMmbVdQUL5c5ebVAzCyaDC0Qjk-S_NUHBBrCvwg",
  "pdfSize": "1504581"
}