{"id":"2407.10020","title":"Causality extraction from medical text using Large Language Models\n  (LLMs)","authors":"Seethalakshmi Gopalakrishnan, Luciana Garbayo, Wlodek Zadrozny","authorsParsed":[["Gopalakrishnan","Seethalakshmi",""],["Garbayo","Luciana",""],["Zadrozny","Wlodek",""]],"versions":[{"version":"v1","created":"Sat, 13 Jul 2024 22:33:29 GMT"}],"updateDate":"2024-07-16","timestamp":1720910009000,"abstract":"  This study explores the potential of natural language models, including large\nlanguage models, to extract causal relations from medical texts, specifically\nfrom Clinical Practice Guidelines (CPGs). The outcomes causality extraction\nfrom Clinical Practice Guidelines for gestational diabetes are presented,\nmarking a first in the field. We report on a set of experiments using variants\nof BERT (BioBERT, DistilBERT, and BERT) and using Large Language Models (LLMs),\nnamely GPT-4 and LLAMA2. Our experiments show that BioBERT performed better\nthan other models, including the Large Language Models, with an average\nF1-score of 0.72. GPT-4 and LLAMA2 results show similar performance but less\nconsistency. We also release the code and an annotated a corpus of causal\nstatements within the Clinical Practice Guidelines for gestational diabetes.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Information Retrieval"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"ngnBBdwGzsB7HE1bGvHcwigFwoIBI5nPwqZnlo8wzKg","pdfSize":"614648"}