{
  "id": "2412.11949",
  "title": "Coconut Palm Tree Counting on Drone Images with Deep Object Detection\n  and Synthetic Training Data",
  "authors": "Tobias Rohe, Barbara B\\\"ohm, Michael K\\\"olle, Jonas Stein, Robert\n  M\\\"uller, Claudia Linnhoff-Popien",
  "authorsParsed": [
    [
      "Rohe",
      "Tobias",
      ""
    ],
    [
      "Böhm",
      "Barbara",
      ""
    ],
    [
      "Kölle",
      "Michael",
      ""
    ],
    [
      "Stein",
      "Jonas",
      ""
    ],
    [
      "Müller",
      "Robert",
      ""
    ],
    [
      "Linnhoff-Popien",
      "Claudia",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Mon, 16 Dec 2024 16:33:28 GMT"
    }
  ],
  "updateDate": "2024-12-17",
  "timestamp": 1734366808000,
  "abstract": "  Drones have revolutionized various domains, including agriculture. Recent\nadvances in deep learning have propelled among other things object detection in\ncomputer vision. This study utilized YOLO, a real-time object detector, to\nidentify and count coconut palm trees in Ghanaian farm drone footage. The farm\npresented has lost track of its trees due to different planting phases. While\nmanual counting would be very tedious and error-prone, accurately determining\nthe number of trees is crucial for efficient planning and management of\nagricultural processes, especially for optimizing yields and predicting\nproduction. We assessed YOLO for palm detection within a semi-automated\nframework, evaluated accuracy augmentations, and pondered its potential for\nfarmers. Data was captured in September 2022 via drones. To optimize YOLO with\nscarce data, synthetic images were created for model training and validation.\nThe YOLOv7 model, pretrained on the COCO dataset (excluding coconut palms), was\nadapted using tailored data. Trees from footage were repositioned on synthetic\nimages, with testing on distinct authentic images. In our experiments, we\nadjusted hyperparameters, improving YOLO's mean average precision (mAP). We\nalso tested various altitudes to determine the best drone height. From an\ninitial mAP@.5 of $0.65$, we achieved 0.88, highlighting the value of synthetic\nimages in agricultural scenarios.\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "oznUeXLLpMyIxSlOQ_ZyHEwlNW98x6_JOMIfGausz_M",
  "pdfSize": "6164318"
}