{
  "id": "2412.13631",
  "title": "Mind Your Theory: Theory of Mind Goes Deeper Than Reasoning",
  "authors": "Eitan Wagner and Nitay Alon and Joseph M. Barnby and Omri Abend",
  "authorsParsed": [
    [
      "Wagner",
      "Eitan",
      ""
    ],
    [
      "Alon",
      "Nitay",
      ""
    ],
    [
      "Barnby",
      "Joseph M.",
      ""
    ],
    [
      "Abend",
      "Omri",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Wed, 18 Dec 2024 09:06:48 GMT"
    },
    {
      "version": "v2",
      "created": "Sun, 16 Feb 2025 10:15:14 GMT"
    }
  ],
  "updateDate": "2025-02-18",
  "timestamp": 1734512808000,
  "abstract": "  Theory of Mind (ToM) capabilities in LLMs have recently become a central\nobject of investigation. Cognitive science distinguishes between two steps\nrequired for ToM tasks: 1) determine whether to invoke ToM, which includes the\nappropriate Depth of Mentalizing (DoM), or level of recursion required to\ncomplete a task; and 2) applying the correct inference given the DoM. In this\nposition paper, we first identify several lines of work in different\ncommunities in AI, including LLM benchmarking, ToM add-ons, ToM probing, and\nformal models for ToM. We argue that recent work in AI tends to focus\nexclusively on the second step which are typically framed as static logic\nproblems. We conclude with suggestions for improved evaluation of ToM\ncapabilities inspired by dynamic environments used in cognitive tasks.\n",
  "subjects": [
    "Computer Science/Artificial Intelligence",
    "Computer Science/Computation and Language"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "-iQ8If1G3Cu4jlGBEfEoreDisQthnyJc0ri0mdUT6S4",
  "pdfSize": "353521"
}