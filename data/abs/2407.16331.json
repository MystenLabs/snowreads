{"id":"2407.16331","title":"AutoLegend: A User Feedback-Driven Adaptive Legend Generator for\n  Visualizations","authors":"Can Liu, Xiyao Mei, Zhibang Jiang, Shaocong Tan, Xiaoru Yuan","authorsParsed":[["Liu","Can",""],["Mei","Xiyao",""],["Jiang","Zhibang",""],["Tan","Shaocong",""],["Yuan","Xiaoru",""]],"versions":[{"version":"v1","created":"Tue, 23 Jul 2024 09:29:17 GMT"}],"updateDate":"2024-07-24","timestamp":1721726957000,"abstract":"  We propose AutoLegend to generate interactive visualization legends using\nonline learning with user feedback. AutoLegend accurately extracts symbols and\nchannels from visualizations and then generates quality legends. AutoLegend\nenables a two-way interaction between legends and interactions, including\nhighlighting, filtering, data retrieval, and retargeting. After analyzing\nvisualization legends from IEEE VIS papers over the past 20 years, we\nsummarized the design space and evaluation metrics for legend design in\nvisualizations, particularly charts. The generation process consists of three\ninterrelated components: a legend search agent, a feedback model, and an\nadversarial loss model. The search agent determines suitable legend solutions\nby exploring the design space and receives guidance from the feedback model\nthrough scalar scores. The feedback model is continuously updated by the\nadversarial loss model based on user input. The user study revealed that\nAutoLegend can learn users' preferences through legend editing.\n","subjects":["Computing Research Repository/Human-Computer Interaction"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"O16V0uD47cKAWLM-k7jdWCGiYNLbkRBe7pQlZTM-BkA","pdfSize":"3341011"}