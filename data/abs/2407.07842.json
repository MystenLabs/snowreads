{"id":"2407.07842","title":"Study on Aspect Ratio Variability toward Robustness of Vision\n  Transformer-based Vehicle Re-identification","authors":"Mei Qiu, Lauren Christopher, and Lingxi Li","authorsParsed":[["Qiu","Mei",""],["Christopher","Lauren",""],["Li","Lingxi",""]],"versions":[{"version":"v1","created":"Wed, 10 Jul 2024 17:02:42 GMT"}],"updateDate":"2024-07-11","timestamp":1720630962000,"abstract":"  Vision Transformers (ViTs) have excelled in vehicle re-identification (ReID)\ntasks. However, non-square aspect ratios of image or video input might\nsignificantly affect the re-identification performance. To address this issue,\nwe propose a novel ViT-based ReID framework in this paper, which fuses models\ntrained on a variety of aspect ratios. Our main contributions are threefold:\n(i) We analyze aspect ratio performance on VeRi-776 and VehicleID datasets,\nguiding input settings based on aspect ratios of original images. (ii) We\nintroduce patch-wise mixup intra-image during ViT patchification (guided by\nspatial attention scores) and implement uneven stride for better object aspect\nratio matching. (iii) We propose a dynamic feature fusing ReID network,\nenhancing model robustness. Our ReID method achieves a significantly improved\nmean Average Precision (mAP) of 91.0\\% compared to the the closest\nstate-of-the-art (CAL) result of 80.9\\% on VehicleID dataset.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-sa/4.0/","blobId":"5fatV4mieHaCVITbS_khGFPghPe3VH37mAb_XOsDJqs","pdfSize":"1058530"}