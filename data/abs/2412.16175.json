{"id":"2412.16175","title":"Mean--Variance Portfolio Selection by Continuous-Time Reinforcement\n  Learning: Algorithms, Regret Analysis, and Empirical Study","authors":"Yilie Huang, Yanwei Jia, Xun Yu Zhou","authorsParsed":[["Huang","Yilie",""],["Jia","Yanwei",""],["Zhou","Xun Yu",""]],"versions":[{"version":"v1","created":"Sun, 8 Dec 2024 15:31:10 GMT"}],"updateDate":"2024-12-24","timestamp":1733671870000,"abstract":"  We study continuous-time mean--variance portfolio selection in markets where\nstock prices are diffusion processes driven by observable factors that are also\ndiffusion processes yet the coefficients of these processes are unknown. Based\non the recently developed reinforcement learning (RL) theory for diffusion\nprocesses, we present a general data-driven RL algorithm that learns the\npre-committed investment strategy directly without attempting to learn or\nestimate the market coefficients. For multi-stock Black--Scholes markets\nwithout factors, we further devise a baseline algorithm and prove its\nperformance guarantee by deriving a sublinear regret bound in terms of Sharpe\nratio. For performance enhancement and practical implementation, we modify the\nbaseline algorithm into four variants, and carry out an extensive empirical\nstudy to compare their performance, in terms of a host of common metrics, with\na large number of widely used portfolio allocation strategies on S\\&P 500\nconstituents. The results demonstrate that the continuous-time RL strategies\nare consistently among the best especially in a volatile bear market, and\ndecisively outperform the model-based continuous-time counterparts by\nsignificant margins.\n","subjects":["Quantitative Finance/Portfolio Management","Computer Science/Machine Learning","Computer Science/Systems and Control","Electrical Engineering and Systems Science/Systems and Control","Mathematics/Optimization and Control"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"zudwr5PVMBgWHAm4KCH_K6ID6vQWT9oeJMlXnqPKge8","pdfSize":"1867159"}