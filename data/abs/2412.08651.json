{"id":"2412.08651","title":"Enhancing Code-Switching ASR Leveraging Non-Peaky CTC Loss and Deep\n  Language Posterior Injection","authors":"Tzu-Ting Yang, Hsin-Wei Wang, Yi-Cheng Wang and Berlin Chen","authorsParsed":[["Yang","Tzu-Ting",""],["Wang","Hsin-Wei",""],["Wang","Yi-Cheng",""],["Chen","Berlin",""]],"versions":[{"version":"v1","created":"Tue, 26 Nov 2024 06:49:05 GMT"}],"updateDate":"2024-12-13","timestamp":1732603745000,"abstract":"  Code-switching-where multilingual speakers alternately switch between\nlanguages during conversations-still poses significant challenges to end-to-end\n(E2E) automatic speech recognition (ASR) systems due to phenomena of both\nacoustic and semantic confusion. This issue arises because ASR systems struggle\nto handle the rapid alternation of languages effectively, which often leads to\nsignificant performance degradation. Our main contributions are at least\nthreefold: First, we incorporate language identification (LID) information into\nseveral intermediate layers of the encoder, aiming to enrich output embeddings\nwith more detailed language information. Secondly, through the novel\napplication of language boundary alignment loss, the subsequent ASR modules are\nenabled to more effectively utilize the knowledge of internal language\nposteriors. Third, we explore the feasibility of using language posteriors to\nfacilitate deep interaction between shared encoder and language-specific\nencoders. Through comprehensive experiments on the SEAME corpus, we have\nverified that our proposed method outperforms the prior-art method, disentangle\nbased mixture-of-experts (D-MoE), further enhancing the acuity of the encoder\nto languages.\n","subjects":["Electrical Engineering and Systems Science/Audio and Speech Processing","Computer Science/Computation and Language","Computer Science/Machine Learning","Computer Science/Sound"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"gXB16lTaukRQIfZdxvIi2Nk0p614sx-Ri6vkkEtarAw","pdfSize":"477641"}