{
  "id": "2412.17707",
  "title": "SMAC-Hard: Enabling Mixed Opponent Strategy Script and Self-play on SMAC",
  "authors": "Yue Deng, Yan Yu, Weiyu Ma, Zirui Wang, Wenhui Zhu, Jian Zhao, Yin\n  Zhang",
  "authorsParsed": [
    [
      "Deng",
      "Yue",
      ""
    ],
    [
      "Yu",
      "Yan",
      ""
    ],
    [
      "Ma",
      "Weiyu",
      ""
    ],
    [
      "Wang",
      "Zirui",
      ""
    ],
    [
      "Zhu",
      "Wenhui",
      ""
    ],
    [
      "Zhao",
      "Jian",
      ""
    ],
    [
      "Zhang",
      "Yin",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Mon, 23 Dec 2024 16:36:21 GMT"
    },
    {
      "version": "v2",
      "created": "Tue, 24 Dec 2024 16:16:34 GMT"
    }
  ],
  "updateDate": "2024-12-25",
  "timestamp": 1734971781000,
  "abstract": "  The availability of challenging simulation environments is pivotal for\nadvancing the field of Multi-Agent Reinforcement Learning (MARL). In\ncooperative MARL settings, the StarCraft Multi-Agent Challenge (SMAC) has\ngained prominence as a benchmark for algorithms following centralized training\nwith decentralized execution paradigm. However, with continual advancements in\nSMAC, many algorithms now exhibit near-optimal performance, complicating the\nevaluation of their true effectiveness. To alleviate this problem, in this\nwork, we highlight a critical issue: the default opponent policy in these\nenvironments lacks sufficient diversity, leading MARL algorithms to overfit and\nexploit unintended vulnerabilities rather than learning robust strategies. To\novercome these limitations, we propose SMAC-HARD, a novel benchmark designed to\nenhance training robustness and evaluation comprehensiveness. SMAC-HARD\nsupports customizable opponent strategies, randomization of adversarial\npolicies, and interfaces for MARL self-play, enabling agents to generalize to\nvarying opponent behaviors and improve model stability. Furthermore, we\nintroduce a black-box testing framework wherein agents are trained without\nexposure to the edited opponent scripts but are tested against these scripts to\nevaluate the policy coverage and adaptability of MARL algorithms. We conduct\nextensive evaluations of widely used and state-of-the-art algorithms on\nSMAC-HARD, revealing the substantial challenges posed by edited and mixed\nstrategy opponents. Additionally, the black-box strategy tests illustrate the\ndifficulty of transferring learned policies to unseen adversaries. We envision\nSMAC-HARD as a critical step toward benchmarking the next generation of MARL\nalgorithms, fostering progress in self-play methods for multi-agent systems.\nOur code is available at https://github.com/devindeng94/smac-hard.\n",
  "subjects": [
    "Computer Science/Artificial Intelligence"
  ],
  "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
  "blobId": "agEmrwP8BE82HMdtgVL6Ipsu0MPaWEDPl8705cZZlOs",
  "pdfSize": "6462220"
}