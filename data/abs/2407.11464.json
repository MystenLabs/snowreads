{"id":"2407.11464","title":"Crowd-SAM: SAM as a Smart Annotator for Object Detection in Crowded\n  Scenes","authors":"Zhi Cai, Yingjie Gao, Yaoyan Zheng, Nan Zhou, Di Huang","authorsParsed":[["Cai","Zhi",""],["Gao","Yingjie",""],["Zheng","Yaoyan",""],["Zhou","Nan",""],["Huang","Di",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 08:00:01 GMT"},{"version":"v2","created":"Fri, 19 Jul 2024 01:00:41 GMT"}],"updateDate":"2024-07-22","timestamp":1721116801000,"abstract":"  In computer vision, object detection is an important task that finds its\napplication in many scenarios. However, obtaining extensive labels can be\nchallenging, especially in crowded scenes. Recently, the Segment Anything Model\n(SAM) has been proposed as a powerful zero-shot segmenter, offering a novel\napproach to instance segmentation tasks. However, the accuracy and efficiency\nof SAM and its variants are often compromised when handling objects in crowded\nand occluded scenes. In this paper, we introduce Crowd-SAM, a SAM-based\nframework designed to enhance SAM's performance in crowded and occluded scenes\nwith the cost of few learnable parameters and minimal labeled images. We\nintroduce an efficient prompt sampler (EPS) and a part-whole discrimination\nnetwork (PWD-Net), enhancing mask selection and accuracy in crowded scenes.\nDespite its simplicity, Crowd-SAM rivals state-of-the-art (SOTA)\nfully-supervised object detection methods on several benchmarks including\nCrowdHuman and CityPersons. Our code is available at\nhttps://github.com/FelixCaae/CrowdSAM.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"P928NQgpIXyBpHLLAaXj_DgX7juUh-W1jBg8FLtt-B4","pdfSize":"5460878"}