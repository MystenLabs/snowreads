{"id":"2407.07296","title":"Large Language Model-Augmented Auto-Delineation of Treatment Target\n  Volume in Radiation Therapy","authors":"Praveenbalaji Rajendran, Yong Yang, Thomas R. Niedermayr, Michael\n  Gensheimer, Beth Beadle, Quynh-Thu Le, Lei Xing, and Xianjin Dai","authorsParsed":[["Rajendran","Praveenbalaji",""],["Yang","Yong",""],["Niedermayr","Thomas R.",""],["Gensheimer","Michael",""],["Beadle","Beth",""],["Le","Quynh-Thu",""],["Xing","Lei",""],["Dai","Xianjin",""]],"versions":[{"version":"v1","created":"Wed, 10 Jul 2024 01:32:55 GMT"}],"updateDate":"2024-07-11","timestamp":1720575175000,"abstract":"  Radiation therapy (RT) is one of the most effective treatments for cancer,\nand its success relies on the accurate delineation of targets. However, target\ndelineation is a comprehensive medical decision that currently relies purely on\nmanual processes by human experts. Manual delineation is time-consuming,\nlaborious, and subject to interobserver variations. Although the advancements\nin artificial intelligence (AI) techniques have significantly enhanced the\nauto-contouring of normal tissues, accurate delineation of RT target volumes\nremains a challenge. In this study, we propose a visual language model-based RT\ntarget volume auto-delineation network termed Radformer. The Radformer utilizes\na hierarichal vision transformer as the backbone and incorporates large\nlanguage models to extract text-rich features from clinical data. We introduce\na visual language attention module (VLAM) for integrating visual and linguistic\nfeatures for language-aware visual encoding (LAVE). The Radformer has been\nevaluated on a dataset comprising 2985 patients with head-and-neck cancer who\nunderwent RT. Metrics, including the Dice similarity coefficient (DSC),\nintersection over union (IOU), and 95th percentile Hausdorff distance (HD95),\nwere used to evaluate the performance of the model quantitatively. Our results\ndemonstrate that the Radformer has superior segmentation performance compared\nto other state-of-the-art models, validating its potential for adoption in RT\npractice.\n","subjects":["Physics/Medical Physics","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"LtsccXMpq-7dCwN1fkCWRk7NavgChgzsbnOyyIbN30g","pdfSize":"1189330"}
