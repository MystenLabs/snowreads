{"id":"2407.20382","title":"What if Red Can Talk? Dynamic Dialogue Generation Using Large Language\n  Models","authors":"Navapat Nananukul, Wichayaporn Wongkamjan","authorsParsed":[["Nananukul","Navapat",""],["Wongkamjan","Wichayaporn",""]],"versions":[{"version":"v1","created":"Mon, 29 Jul 2024 19:12:18 GMT"}],"updateDate":"2024-07-31","timestamp":1722280338000,"abstract":"  Role-playing games (RPGs) provide players with a rich, interactive world to\nexplore. Dialogue serves as the primary means of communication between\ndevelopers and players, manifesting in various forms such as guides, NPC\ninteractions, and storytelling. While most games rely on written scripts to\ndefine the main story and character personalities, player immersion can be\nsignificantly enhanced through casual interactions between characters. With the\nadvent of large language models (LLMs), we introduce a dialogue filler\nframework that utilizes LLMs enhanced by knowledge graphs to generate dynamic\nand contextually appropriate character interactions. We test this framework\nwithin the environments of Final Fantasy VII Remake and Pokemon, providing\nqualitative and quantitative evidence that demonstrates GPT-4's capability to\nact with defined personalities and generate dialogue. However, some flaws\nremain, such as GPT-4 being overly positive or more subtle personalities, such\nas maturity, tend to be of lower quality compared to more overt traits like\ntimidity. This study aims to assist developers in crafting more nuanced filler\ndialogues, thereby enriching player immersion and enhancing the overall RPG\nexperience.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"PcgLO35M-PLFXU1g0W9yXjSvYWKNw36888b5mU31X3g","pdfSize":"2079561"}