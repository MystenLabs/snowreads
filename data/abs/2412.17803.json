{"id":"2412.17803","title":"Examining Imbalance Effects on Performance and Demographic Fairness of\n  Clinical Language Models","authors":"Precious Jones, Weisi Liu, I-Chan Huang, Xiaolei Huang","authorsParsed":[["Jones","Precious",""],["Liu","Weisi",""],["Huang","I-Chan",""],["Huang","Xiaolei",""]],"versions":[{"version":"v1","created":"Mon, 23 Dec 2024 18:58:11 GMT"},{"version":"v2","created":"Thu, 13 Feb 2025 21:28:17 GMT"}],"updateDate":"2025-02-17","timestamp":1734980291000,"abstract":"  Data imbalance is a fundamental challenge in applying language models to\nbiomedical applications, particularly in ICD code prediction tasks where label\nand demographic distributions are uneven. While state-of-the-art language\nmodels have been increasingly adopted in biomedical tasks, few studies have\nsystematically examined how data imbalance affects model performance and\nfairness across demographic groups. This study fills the gap by statistically\nprobing the relationship between data imbalance and model performance in ICD\ncode prediction. We analyze imbalances in a standard benchmark data across\ngender, age, ethnicity, and social determinants of health by state-of-the-art\nbiomedical language models. By deploying diverse performance metrics and\nstatistical analyses, we explore the influence of data imbalance on performance\nvariations and demographic fairness. Our study shows that data imbalance\nsignificantly impacts model performance and fairness, but feature similarity to\nthe majority class may be a more critical factor. We believe this study\nprovides valuable insights for developing more equitable and robust language\nmodels in healthcare applications.\n","subjects":["Computer Science/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"ibbLKj93Z0taNASBO9oFojDpaO8evZOyRHAGeRKQdyk","pdfSize":"330284"}