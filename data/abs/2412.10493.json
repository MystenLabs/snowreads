{
  "id": "2412.10493",
  "title": "SafetyDPO: Scalable Safety Alignment for Text-to-Image Generation",
  "authors": "Runtao Liu, Chen I Chieh, Jindong Gu, Jipeng Zhang, Renjie Pi, Qifeng\n  Chen, Philip Torr, Ashkan Khakzar, Fabio Pizzati",
  "authorsParsed": [
    [
      "Liu",
      "Runtao",
      ""
    ],
    [
      "Chieh",
      "Chen I",
      ""
    ],
    [
      "Gu",
      "Jindong",
      ""
    ],
    [
      "Zhang",
      "Jipeng",
      ""
    ],
    [
      "Pi",
      "Renjie",
      ""
    ],
    [
      "Chen",
      "Qifeng",
      ""
    ],
    [
      "Torr",
      "Philip",
      ""
    ],
    [
      "Khakzar",
      "Ashkan",
      ""
    ],
    [
      "Pizzati",
      "Fabio",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Fri, 13 Dec 2024 18:59:52 GMT"
    }
  ],
  "updateDate": "2024-12-17",
  "timestamp": 1734116392000,
  "abstract": "  Text-to-image (T2I) models have become widespread, but their limited safety\nguardrails expose end users to harmful content and potentially allow for model\nmisuse. Current safety measures are typically limited to text-based filtering\nor concept removal strategies, able to remove just a few concepts from the\nmodel's generative capabilities. In this work, we introduce SafetyDPO, a method\nfor safety alignment of T2I models through Direct Preference Optimization\n(DPO). We enable the application of DPO for safety purposes in T2I models by\nsynthetically generating a dataset of harmful and safe image-text pairs, which\nwe call CoProV2. Using a custom DPO strategy and this dataset, we train safety\nexperts, in the form of low-rank adaptation (LoRA) matrices, able to guide the\ngeneration process away from specific safety-related concepts. Then, we merge\nthe experts into a single LoRA using a novel merging strategy for optimal\nscaling performance. This expert-based approach enables scalability, allowing\nus to remove 7 times more harmful concepts from T2I models compared to\nbaselines. SafetyDPO consistently outperforms the state-of-the-art on many\nbenchmarks and establishes new practices for safety alignment in T2I networks.\nCode and data will be shared at https://safetydpo.github.io/.\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition",
    "Computer Science/Artificial Intelligence",
    "Computer Science/Machine Learning"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "ZT5nVUNKzqHFmh-JZztFH_11Bq-8dZff-2q9uBX9tWM",
  "pdfSize": "11387634"
}