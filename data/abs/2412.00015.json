{"id":"2412.00015","title":"On Rank Aggregating Test Prioritizations","authors":"Shouvick Mondal, Tse-Hsun Chen (Peter)","authorsParsed":[["Mondal","Shouvick","","Peter"],["Chen","Tse-Hsun","","Peter"]],"versions":[{"version":"v1","created":"Fri, 15 Nov 2024 11:17:37 GMT"}],"updateDate":"2024-12-03","timestamp":1731669457000,"abstract":"  Test case prioritization (TCP) has been an effective strategy to optimize\nregression testing. Traditionally, test cases are ordered based on some\nheuristic and rerun against the version under test with the goal of yielding a\nhigh failure throughput. Almost four decades of TCP research has seen extensive\ncontributions in the light of individual prioritization strategies. However,\ntest case prioritization via preference aggregation has largely been\nunexplored. We envision this methodology as an opportunity to obtain robust\nprioritizations by consolidating multiple standalone ranked lists, i.e.,\nperforming a consensus. In this work, we propose Ensemble Test Prioritization\n(EnTP) as a three stage pipeline involving: (i) ensemble selection, (ii) rank\naggregation, and (iii) test case execution. We evaluate EnTP on 20 open-source\nC projects from the Software-artifact Infrastructure Repository and GitHub\n(totaling: 694,512 SLOC, 280 versions, and 69,305 system level test-cases). We\nemploy an ensemble of 16 standalone prioritization plans, four of which are\nimposed due to respective state-of-the-art approaches. We build EnTP on the\nfoundations of Hansie, an existing framework on consensus prioritization and\nshow that EnTP's diversity based ensemble selection budget of top-75% followed\nby rank aggregation can outperform Hansie, and the employed standalone\nprioritization approaches.\n","subjects":["Computer Science/Software Engineering"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"aM82f0188XoTNyz5KTqPUzQ2GI-VhrnREdjFVtg0CKo","pdfSize":"1604763"}