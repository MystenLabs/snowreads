{"id":"2407.09292","title":"Counterfactual Explainable Incremental Prompt Attack Analysis on Large\n  Language Models","authors":"Dong Shu, Mingyu Jin, Tianle Chen, Chong Zhang, Yongfeng Zhang","authorsParsed":[["Shu","Dong",""],["Jin","Mingyu",""],["Chen","Tianle",""],["Zhang","Chong",""],["Zhang","Yongfeng",""]],"versions":[{"version":"v1","created":"Fri, 12 Jul 2024 14:26:14 GMT"},{"version":"v2","created":"Wed, 17 Jul 2024 16:23:28 GMT"}],"updateDate":"2024-07-18","timestamp":1720794374000,"abstract":"  This study sheds light on the imperative need to bolster safety and privacy\nmeasures in large language models (LLMs), such as GPT-4 and LLaMA-2, by\nidentifying and mitigating their vulnerabilities through explainable analysis\nof prompt attacks. We propose Counterfactual Explainable Incremental Prompt\nAttack (CEIPA), a novel technique where we guide prompts in a specific manner\nto quantitatively measure attack effectiveness and explore the embedded defense\nmechanisms in these models. Our approach is distinctive for its capacity to\nelucidate the reasons behind the generation of harmful responses by LLMs\nthrough an incremental counterfactual methodology. By organizing the prompt\nmodification process into four incremental levels: (word, sentence, character,\nand a combination of character and word) we facilitate a thorough examination\nof the susceptibilities inherent to LLMs. The findings from our study not only\nprovide counterfactual explanation insight but also demonstrate that our\nframework significantly enhances the effectiveness of attack prompts.\n","subjects":["Computing Research Repository/Cryptography and Security"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"KjNMWoiof1tlnurYNBKi0tJG2MElenwHAjCje_dT28w","pdfSize":"2469364","objectId":"0x659196127cb0bb0529b12ae57f09d2d562af8b5524ef86442bdee013e0842466","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
