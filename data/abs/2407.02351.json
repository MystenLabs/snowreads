{"id":"2407.02351","title":"Generative Large Language Models in Automated Fact-Checking: A Survey","authors":"Ivan Vykopal, Mat\\'u\\v{s} Pikuliak, Simon Ostermann, Mari\\'an\n  \\v{S}imko","authorsParsed":[["Vykopal","Ivan",""],["Pikuliak","Matúš",""],["Ostermann","Simon",""],["Šimko","Marián",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 15:16:46 GMT"}],"updateDate":"2024-07-03","timestamp":1719933406000,"abstract":"  The dissemination of false information across online platforms poses a\nserious societal challenge, necessitating robust measures for information\nverification. While manual fact-checking efforts are still instrumental, the\ngrowing volume of false information requires automated methods. Large language\nmodels (LLMs) offer promising opportunities to assist fact-checkers, leveraging\nLLM's extensive knowledge and robust reasoning capabilities. In this survey\npaper, we investigate the utilization of generative LLMs in the realm of\nfact-checking, illustrating various approaches that have been employed and\ntechniques for prompting or fine-tuning LLMs. By providing an overview of\nexisting approaches, this survey aims to improve the understanding of utilizing\nLLMs in fact-checking and to facilitate further progress in LLMs' involvement\nin this process.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"_8uxQqFpj0uM9lcz8q07Ur306at7CZMtE_hxjcdRAOQ","pdfSize":"547869"}