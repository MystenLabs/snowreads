{
  "id": "2412.15689",
  "title": "DOLLAR: Few-Step Video Generation via Distillation and Latent Reward\n  Optimization",
  "authors": "Zihan Ding, Chi Jin, Difan Liu, Haitian Zheng, Krishna Kumar Singh,\n  Qiang Zhang, Yan Kang, Zhe Lin, Yuchen Liu",
  "authorsParsed": [
    [
      "Ding",
      "Zihan",
      ""
    ],
    [
      "Jin",
      "Chi",
      ""
    ],
    [
      "Liu",
      "Difan",
      ""
    ],
    [
      "Zheng",
      "Haitian",
      ""
    ],
    [
      "Singh",
      "Krishna Kumar",
      ""
    ],
    [
      "Zhang",
      "Qiang",
      ""
    ],
    [
      "Kang",
      "Yan",
      ""
    ],
    [
      "Lin",
      "Zhe",
      ""
    ],
    [
      "Liu",
      "Yuchen",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Fri, 20 Dec 2024 09:07:36 GMT"
    }
  ],
  "updateDate": "2024-12-23",
  "timestamp": 1734685656000,
  "abstract": "  Diffusion probabilistic models have shown significant progress in video\ngeneration; however, their computational efficiency is limited by the large\nnumber of sampling steps required. Reducing sampling steps often compromises\nvideo quality or generation diversity. In this work, we introduce a\ndistillation method that combines variational score distillation and\nconsistency distillation to achieve few-step video generation, maintaining both\nhigh quality and diversity. We also propose a latent reward model fine-tuning\napproach to further enhance video generation performance according to any\nspecified reward metric. This approach reduces memory usage and does not\nrequire the reward to be differentiable. Our method demonstrates\nstate-of-the-art performance in few-step generation for 10-second videos (128\nframes at 12 FPS). The distilled student model achieves a score of 82.57 on\nVBench, surpassing the teacher model as well as baseline models Gen-3,\nT2V-Turbo, and Kling. One-step distillation accelerates the teacher model's\ndiffusion sampling by up to 278.6 times, enabling near real-time generation.\nHuman evaluations further validate the superior performance of our 4-step\nstudent models compared to teacher model using 50-step DDIM sampling.\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "z2JncuA9Rkh619BbtuGVqmrHmtwUJGYc_sJMJRUtu-Y",
  "pdfSize": "26428497"
}