{"id":"2407.15810","title":"Breaking the Global North Stereotype: A Global South-centric Benchmark\n  Dataset for Auditing and Mitigating Biases in Facial Recognition Systems","authors":"Siddharth D Jaiswal, Animesh Ganai, Abhisek Dash, Saptarshi Ghosh,\n  Animesh Mukherjee","authorsParsed":[["Jaiswal","Siddharth D",""],["Ganai","Animesh",""],["Dash","Abhisek",""],["Ghosh","Saptarshi",""],["Mukherjee","Animesh",""]],"versions":[{"version":"v1","created":"Mon, 22 Jul 2024 17:22:04 GMT"},{"version":"v2","created":"Fri, 26 Jul 2024 13:57:32 GMT"}],"updateDate":"2024-07-29","timestamp":1721668924000,"abstract":"  Facial Recognition Systems (FRSs) are being developed and deployed globally\nat unprecedented rates. Most platforms are designed in a limited set of\ncountries but deployed in worldwide, without adequate checkpoints. This is\nespecially problematic for Global South countries which lack strong legislation\nto safeguard persons facing disparate performance of these systems. A\ncombination of unavailability of datasets, lack of understanding of FRS\nfunctionality and low-resource bias mitigation measures accentuate the problem.\nIn this work, we propose a new face dataset composed of 6,579 unique male and\nfemale sportspersons from eight countries around the world. More than 50% of\nthe dataset comprises individuals from the Global South countries and is\ndemographically diverse. To aid adversarial audits and robust model training,\neach image has four adversarial variants, totaling over 40,000 images. We also\nbenchmark five popular FRSs, both commercial and open-source, for the task of\ngender prediction (and country prediction for one of the open-source models as\nan example of red-teaming). Experiments on industrial FRSs reveal accuracies\nranging from 98.2%--38.1%, with a large disparity between males and females in\nthe Global South (max difference of 38.5%). Biases are also observed in all\nFRSs between females of the Global North and South (max difference of ~50%).\nGrad-CAM analysis identifies the nose, forehead and mouth as the regions of\ninterest on one of the open-source FRSs. Utilizing this insight, we design\nsimple, low-resource bias mitigation solutions using few-shot and novel\ncontrastive learning techniques significantly improving the accuracy with\ndisparity between males and females reducing from 50% to 1.5% in one of the\nsettings. In the red-teaming experiment with the open-source Deepface model,\ncontrastive learning proves more effective than simple fine-tuning.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Computers and Society"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"PENJ8DzBHQJKWoN8uJOStwGwZKQmB9hjtaYDVTrShI4","pdfSize":"933284"}