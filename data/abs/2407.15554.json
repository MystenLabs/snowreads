{"id":"2407.15554","title":"Decomposition of Neural Discrete Representations for Large-Scale 3D\n  Mapping","authors":"Minseong Park, Suhan Woo, Euntai Kim","authorsParsed":[["Park","Minseong",""],["Woo","Suhan",""],["Kim","Euntai",""]],"versions":[{"version":"v1","created":"Mon, 22 Jul 2024 11:32:33 GMT"}],"updateDate":"2024-07-23","timestamp":1721647953000,"abstract":"  Learning efficient representations of local features is a key challenge in\nfeature volume-based 3D neural mapping, especially in large-scale environments.\nIn this paper, we introduce Decomposition-based Neural Mapping (DNMap), a\nstorage-efficient large-scale 3D mapping method that employs a discrete\nrepresentation based on a decomposition strategy. This decomposition strategy\naims to efficiently capture repetitive and representative patterns of shapes by\ndecomposing each discrete embedding into component vectors that are shared\nacross the embedding space. Our DNMap optimizes a set of component vectors,\nrather than entire discrete embeddings, and learns composition rather than\nindexing the discrete embeddings. Furthermore, to complement the mapping\nquality, we additionally learn low-resolution continuous embeddings that\nrequire tiny storage space. By combining these representations with a shallow\nneural network and an efficient octree-based feature volume, our DNMap\nsuccessfully approximates signed distance functions and compresses the feature\nvolume while preserving mapping quality. Our source code is available at\nhttps://github.com/minseong-p/dnmap.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"EhJgnHKKWDTQHlKS9t6Z9iIrnef4lkywM96O3Iy-M84","pdfSize":"3357007"}