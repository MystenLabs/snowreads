{"id":"2407.05434","title":"LTLBench: Towards Benchmarks for Evaluating Temporal Logic Reasoning in\n  Large Language Models","authors":"Weizhi Tang, Vaishak Belle","authorsParsed":[["Tang","Weizhi",""],["Belle","Vaishak",""]],"versions":[{"version":"v1","created":"Sun, 7 Jul 2024 16:37:06 GMT"}],"updateDate":"2024-07-09","timestamp":1720370226000,"abstract":"  Temporal reasoning (TR) is a critical component of artificial intelligence,\nencompassing understanding and processing temporal information and\nrelationships between events. To discover and study the TR ability in Large\nLanguage Models (LLMs), various datasets have been constructed in different\nways for evaluating various aspects of TR ability. Our work proposes a novel\napproach to design and develop a pipeline for constructing datasets to evaluate\nthe TR ability of LLMs by leveraging random directed graph generation, LTL\nformula, and the NuSMV model checker. Based on the pipeline, we have also\nconstructed a dataset as a benchmark, namely LTLBench, consisting of 2,000 TR\nchallenges and evaluated six LLMs with it. Furthermore, we have conducted\nadditional experiments to discover the impact of increasing the number of\nevents and formula operators on the complexity of TR problems and the\nperformance of LLMs. We have demonstrated that although LLMs exhibit some\npromise in handling TR challenges, they still struggle with complex TR. We\nexpect this work can offer insights into TR ability in LLMs while also\nproviding a valuable tool for future TR evaluations.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"KUoaYJA0riXX6N4Zbn-js8744ZDuFkcHXfWmb3aGh6w","pdfSize":"1152422"}