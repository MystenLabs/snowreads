{"id":"2407.20871","title":"Co-Neighbor Encoding Schema: A Light-cost Structure Encoding Method for\n  Dynamic Link Prediction","authors":"Ke Cheng, Linzhi Peng, Junchen Ye, Leilei Sun and Bowen Du","authorsParsed":[["Cheng","Ke",""],["Peng","Linzhi",""],["Ye","Junchen",""],["Sun","Leilei",""],["Du","Bowen",""]],"versions":[{"version":"v1","created":"Tue, 30 Jul 2024 14:45:40 GMT"}],"updateDate":"2024-07-31","timestamp":1722350740000,"abstract":"  Structure encoding has proven to be the key feature to distinguishing links\nin a graph. However, Structure encoding in the temporal graph keeps changing as\nthe graph evolves, repeatedly computing such features can be time-consuming due\nto the high-order subgraph construction. We develop the Co-Neighbor Encoding\nSchema (CNES) to address this issue. Instead of recomputing the feature by the\nlink, CNES stores information in the memory to avoid redundant calculations.\nBesides, unlike the existing memory-based dynamic graph learning method that\nstores node hidden states, we introduce a hashtable-based memory to compress\nthe adjacency matrix for efficient structure feature construction and updating\nwith vector computation in parallel. Furthermore, CNES introduces a\nTemporal-Diverse Memory to generate long-term and short-term structure encoding\nfor neighbors with different structural information. A dynamic graph learning\nframework, Co-Neighbor Encoding Network (CNE-N), is proposed using the\naforementioned techniques. Extensive experiments on thirteen public datasets\nverify the effectiveness and efficiency of the proposed method.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"h47UKvvHXQM8WNHe0cgk850rfYoMDy0LzU8GGOdSjxc","pdfSize":"1200732"}