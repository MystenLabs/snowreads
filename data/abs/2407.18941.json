{"id":"2407.18941","title":"LEMoN: Label Error Detection using Multimodal Neighbors","authors":"Haoran Zhang, Aparna Balagopalan, Nassim Oufattole, Hyewon Jeong, Yan\n  Wu, Jiacheng Zhu, Marzyeh Ghassemi","authorsParsed":[["Zhang","Haoran",""],["Balagopalan","Aparna",""],["Oufattole","Nassim",""],["Jeong","Hyewon",""],["Wu","Yan",""],["Zhu","Jiacheng",""],["Ghassemi","Marzyeh",""]],"versions":[{"version":"v1","created":"Wed, 10 Jul 2024 19:36:30 GMT"}],"updateDate":"2024-07-30","timestamp":1720640190000,"abstract":"  Large repositories of image-caption pairs are essential for the development\nof vision-language models. However, these datasets are often extracted from\nnoisy data scraped from the web, and contain many mislabeled examples. In order\nto improve the reliability of downstream models, it is important to identify\nand filter images with incorrect captions. However, beyond filtering based on\nimage-caption embedding similarity, no prior works have proposed other methods\nto filter noisy multimodal data, or concretely assessed the impact of noisy\ncaptioning data on downstream training. In this work, we propose LEMoN, a\nmethod to automatically identify label errors in multimodal datasets. Our\nmethod leverages the multimodal neighborhood of image-caption pairs in the\nlatent space of contrastively pretrained multimodal models. We find that our\nmethod outperforms the baselines in label error identification, and that\ntraining on datasets filtered using our method improves downstream\nclassification and captioning performance.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"CVOIaJV1YE3znlwMxwNfp7VfRLvlnEBSJxaOplDIYsw","pdfSize":"8455913"}