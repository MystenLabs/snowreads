{"id":"2407.11398","title":"Animate3D: Animating Any 3D Model with Multi-view Video Diffusion","authors":"Yanqin Jiang, Chaohui Yu, Chenjie Cao, Fan Wang, Weiming Hu, Jin Gao","authorsParsed":[["Jiang","Yanqin",""],["Yu","Chaohui",""],["Cao","Chenjie",""],["Wang","Fan",""],["Hu","Weiming",""],["Gao","Jin",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 05:35:57 GMT"},{"version":"v2","created":"Mon, 9 Sep 2024 06:21:21 GMT"}],"updateDate":"2024-09-10","timestamp":1721108157000,"abstract":"  Recent advances in 4D generation mainly focus on generating 4D content by\ndistilling pre-trained text or single-view image-conditioned models. It is\ninconvenient for them to take advantage of various off-the-shelf 3D assets with\nmulti-view attributes, and their results suffer from spatiotemporal\ninconsistency owing to the inherent ambiguity in the supervision signals. In\nthis work, we present Animate3D, a novel framework for animating any static 3D\nmodel. The core idea is two-fold: 1) We propose a novel multi-view video\ndiffusion model (MV-VDM) conditioned on multi-view renderings of the static 3D\nobject, which is trained on our presented large-scale multi-view video dataset\n(MV-Video). 2) Based on MV-VDM, we introduce a framework combining\nreconstruction and 4D Score Distillation Sampling (4D-SDS) to leverage the\nmulti-view video diffusion priors for animating 3D objects. Specifically, for\nMV-VDM, we design a new spatiotemporal attention module to enhance spatial and\ntemporal consistency by integrating 3D and video diffusion models.\nAdditionally, we leverage the static 3D model's multi-view renderings as\nconditions to preserve its identity. For animating 3D models, an effective\ntwo-stage pipeline is proposed: we first reconstruct motions directly from\ngenerated multi-view videos, followed by the introduced 4D-SDS to refine both\nappearance and motion. Benefiting from accurate motion learning, we could\nachieve straightforward mesh animation. Qualitative and quantitative\nexperiments demonstrate that Animate3D significantly outperforms previous\napproaches. Data, code, and models will be open-released.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"ax6kxnzQ3E2m38yKjpePYzwu4JKqOwrsAe-Kr_qTE2g","pdfSize":"12415117","objectId":"0x7a4f9c0f43ebbcca37b77f7707ade14f23411c50eaf6c890e9263668792548d9","registeredEpoch":"3","certifiedEpoch":"3","startEpoch":"3","endEpoch":"203"}
