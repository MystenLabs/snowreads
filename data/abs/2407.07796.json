{"id":"2407.07796","title":"Evaluating Large Language Models with Grid-Based Game Competitions: An\n  Extensible LLM Benchmark and Leaderboard","authors":"Oguzhan Topsakal, Colby Jacob Edell, Jackson Bailey Harper","authorsParsed":[["Topsakal","Oguzhan",""],["Edell","Colby Jacob",""],["Harper","Jackson Bailey",""]],"versions":[{"version":"v1","created":"Wed, 10 Jul 2024 16:14:34 GMT"},{"version":"v2","created":"Thu, 11 Jul 2024 03:46:35 GMT"}],"updateDate":"2024-07-12","timestamp":1720628074000,"abstract":"  We introduce a novel and extensible benchmark for large language models\n(LLMs) through grid-based games such as Tic-Tac-Toe, Connect Four, and Gomoku.\nThe open-source game simulation code, available on GitHub, allows LLMs to\ncompete and generates detailed data files in JSON, CSV, TXT, and PNG formats\nfor leaderboard rankings and further analysis. We present the results of games\namong leading LLMs, including Claude 3.5 Sonnet and Claude 3 Sonnet by\nAnthropic, Gemini 1.5 Pro and Gemini 1.5 Flash by Google, GPT-4 Turbo and\nGPT-4o by OpenAI, and Llama3-70B by Meta. We also encourage submissions of\nresults from other LLMs. In total, we simulated 2,310 matches (5 sessions for\neach pair among 7 LLMs and a random player) across three types of games, using\nthree distinct prompt types: list, illustration, and image. The results\nrevealed significant variations in LLM performance across different games and\nprompt types, with analysis covering win and disqualification rates, missed\nopportunity analysis, and invalid move analysis. The details of the leaderboard\nand result matrix data are available as open-access data on GitHub. This study\nenhances our understanding of LLMs' capabilities in playing games they were not\nspecifically trained for, helping to assess their rule comprehension and\nstrategic thinking. On the path to Artificial General Intelligence (AGI), this\nstudy lays the groundwork for future exploration into their utility in complex\ndecision-making scenarios, illuminating their strategic thinking abilities and\noffering directions for further inquiry into the limits of LLMs within\ngame-based frameworks.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning","Computing Research Repository/Neural and Evolutionary Computing"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"O3z5jTgjAkWHwVjnSaA4PDCQbGx9bsg_4AmaLJ7JuLk","pdfSize":"10555419","objectId":"0xb8b1556cda9bcc7ababf843aad07c5a3b88184c32c0c3885f7ba469159aa78b3","registeredEpoch":"1","certifiedEpoch":"1","startEpoch":"1","endEpoch":"201"}
