{
  "id": "2412.15235",
  "title": "OG-RAG: Ontology-Grounded Retrieval-Augmented Generation For Large\n  Language Models",
  "authors": "Kartik Sharma, Peeyush Kumar, Yunqing Li",
  "authorsParsed": [
    [
      "Sharma",
      "Kartik",
      ""
    ],
    [
      "Kumar",
      "Peeyush",
      ""
    ],
    [
      "Li",
      "Yunqing",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Thu, 12 Dec 2024 01:21:03 GMT"
    }
  ],
  "updateDate": "2024-12-23",
  "timestamp": 1733966463000,
  "abstract": "  This paper presents OG-RAG, an Ontology-Grounded Retrieval Augmented\nGeneration method designed to enhance LLM-generated responses by anchoring\nretrieval processes in domain-specific ontologies. While LLMs are widely used\nfor tasks like question answering and search, they struggle to adapt to\nspecialized knowledge, such as industrial workflows or knowledge work, without\nexpensive fine-tuning or sub-optimal retrieval methods. Existing\nretrieval-augmented models, such as RAG, offer improvements but fail to account\nfor structured domain knowledge, leading to suboptimal context generation.\nOntologies, which conceptually organize domain knowledge by defining entities\nand their interrelationships, offer a structured representation to address this\ngap. OG-RAG constructs a hypergraph representation of domain documents, where\neach hyperedge encapsulates clusters of factual knowledge grounded using\ndomain-specific ontology. An optimization algorithm then retrieves the minimal\nset of hyperedges that constructs a precise, conceptually grounded context for\nthe LLM. This method enables efficient retrieval while preserving the complex\nrelationships between entities. OG-RAG applies to domains where fact-based\nreasoning is essential, particularly in tasks that require workflows or\ndecision-making steps to follow predefined rules and procedures. These include\nindustrial workflows in healthcare, legal, and agricultural sectors, as well as\nknowledge-driven tasks such as news journalism, investigative research,\nconsulting and more. Our evaluations demonstrate that OG-RAG increases the\nrecall of accurate facts by 55% and improves response correctness by 40% across\nfour different LLMs. Additionally, OG-RAG enables 30% faster attribution of\nresponses to context and boosts fact-based reasoning accuracy by 27% compared\nto baseline methods.\n",
  "subjects": [
    "Computer Science/Computation and Language",
    "Computer Science/Artificial Intelligence"
  ],
  "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
  "blobId": "UFamLYVeXs7_i5xXVVjo16SfGWCWTgpOs5S8g59C1P8",
  "pdfSize": "930901"
}