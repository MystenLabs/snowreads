{
  "id": "2412.01993",
  "title": "Generalized EXTRA stochastic gradient Langevin dynamics",
  "authors": "Mert Gurbuzbalaban, Mohammad Rafiqul Islam, Xiaoyu Wang, Lingjiong Zhu",
  "authorsParsed": [
    [
      "Gurbuzbalaban",
      "Mert",
      ""
    ],
    [
      "Islam",
      "Mohammad Rafiqul",
      ""
    ],
    [
      "Wang",
      "Xiaoyu",
      ""
    ],
    [
      "Zhu",
      "Lingjiong",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Mon, 2 Dec 2024 21:57:30 GMT"
    }
  ],
  "updateDate": "2024-12-04",
  "timestamp": 1733176650000,
  "abstract": "  Langevin algorithms are popular Markov Chain Monte Carlo methods for Bayesian\nlearning, particularly when the aim is to sample from the posterior\ndistribution of a parametric model, given the input data and the prior\ndistribution over the model parameters. Their stochastic versions such as\nstochastic gradient Langevin dynamics (SGLD) allow iterative learning based on\nrandomly sampled mini-batches of large datasets and are scalable to large\ndatasets. However, when data is decentralized across a network of agents\nsubject to communication and privacy constraints, standard SGLD algorithms\ncannot be applied. Instead, we employ decentralized SGLD (DE-SGLD) algorithms,\nwhere Bayesian learning is performed collaboratively by a network of agents\nwithout sharing individual data. Nonetheless, existing DE-SGLD algorithms\ninduce a bias at every agent that can negatively impact performance; this bias\npersists even when using full batches and is attributable to network effects.\nMotivated by the EXTRA algorithm and its generalizations for decentralized\noptimization, we propose the generalized EXTRA stochastic gradient Langevin\ndynamics, which eliminates this bias in the full-batch setting. Moreover, we\nshow that, in the mini-batch setting, our algorithm provides performance bounds\nthat significantly improve upon those of standard DE-SGLD algorithms in the\nliterature. Our numerical results also demonstrate the efficiency of the\nproposed approach.\n",
  "subjects": [
    "Computer Science/Machine Learning",
    "Mathematics/Optimization and Control"
  ],
  "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
  "blobId": "pFlsbWEfGGYrN2EGfHPEX_diJaKP57SxOaDIoKjacYk",
  "pdfSize": "5481934"
}