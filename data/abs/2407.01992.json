{"id":"2407.01992","title":"Is Your Large Language Model Knowledgeable or a Choices-Only Cheater?","authors":"Nishant Balepur, Rachel Rudinger","authorsParsed":[["Balepur","Nishant",""],["Rudinger","Rachel",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 07:06:53 GMT"}],"updateDate":"2024-07-03","timestamp":1719904013000,"abstract":"  Recent work shows that large language models (LLMs) can answer\nmultiple-choice questions using only the choices, but does this mean that MCQA\nleaderboard rankings of LLMs are largely influenced by abilities in\nchoices-only settings? To answer this, we use a contrast set that probes if\nLLMs over-rely on choices-only shortcuts in MCQA. While previous works build\ncontrast sets via expensive human annotations or model-generated data which can\nbe biased, we employ graph mining to extract contrast sets from existing MCQA\ndatasets. We use our method on UnifiedQA, a group of six commonsense reasoning\ndatasets with high choices-only accuracy, to build an 820-question contrast\nset. After validating our contrast set, we test 12 LLMs, finding that these\nmodels do not exhibit reliance on choice-only shortcuts when given both the\nquestion and choices. Thus, despite the susceptibility~of MCQA to high\nchoices-only accuracy, we argue that LLMs are not obtaining high ranks on MCQA\nleaderboards just due to their ability to exploit choices-only shortcuts.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"IsPFq8-GfUyo2rLFuhrhH4NbBdGt-FdtaR_mN7LDwEw","pdfSize":"1437754"}