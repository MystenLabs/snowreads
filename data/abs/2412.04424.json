{"id":"2412.04424","title":"Florence-VL: Enhancing Vision-Language Models with Generative Vision\n  Encoder and Depth-Breadth Fusion","authors":"Jiuhai Chen, Jianwei Yang, Haiping Wu, Dianqi Li, Jianfeng Gao, Tianyi\n  Zhou, Bin Xiao","authorsParsed":[["Chen","Jiuhai",""],["Yang","Jianwei",""],["Wu","Haiping",""],["Li","Dianqi",""],["Gao","Jianfeng",""],["Zhou","Tianyi",""],["Xiao","Bin",""]],"versions":[{"version":"v1","created":"Thu, 5 Dec 2024 18:50:39 GMT"}],"updateDate":"2024-12-06","timestamp":1733424639000,"abstract":"  We present Florence-VL, a new family of multimodal large language models\n(MLLMs) with enriched visual representations produced by Florence-2, a\ngenerative vision foundation model. Unlike the widely used CLIP-style vision\ntransformer trained by contrastive learning, Florence-2 can capture different\nlevels and aspects of visual features, which are more versatile to be adapted\nto diverse downstream tasks. We propose a novel feature-fusion architecture and\nan innovative training recipe that effectively integrates Florence-2's visual\nfeatures into pretrained LLMs, such as Phi 3.5 and LLama 3. In particular, we\npropose \"depth-breath fusion (DBFusion)\" to fuse the visual features extracted\nfrom different depths and under multiple prompts. Our model training is\ncomposed of end-to-end pretraining of the whole model followed by finetuning of\nthe projection layer and the LLM, on a carefully designed recipe of diverse\nopen-source datasets that include high-quality image captions and\ninstruction-tuning pairs. Our quantitative analysis and visualization of\nFlorence-VL's visual features show its advantages over popular vision encoders\non vision-language alignment, where the enriched depth and breath play\nimportant roles. Florence-VL achieves significant improvements over existing\nstate-of-the-art MLLMs across various multi-modal and vision-centric benchmarks\ncovering general VQA, perception, hallucination, OCR, Chart,\nknowledge-intensive understanding, etc. To facilitate future research, our\nmodels and the complete training recipe are open-sourced.\nhttps://github.com/JiuhaiChen/Florence-VL\n","subjects":["Computer Science/Computer Vision and Pattern Recognition","Computer Science/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"40CRLHSppl8xJqnbUZKFlJd_z4yXwWgUJ1tankbV6gc","pdfSize":"1888493"}