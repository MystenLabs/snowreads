{"id":"2407.17667","title":"Tackling the Problem of Distributional Shifts: Correcting Misspecified,\n  High-Dimensional Data-Driven Priors for Inverse Problems","authors":"Gabriel Missael Barco, Alexandre Adam, Connor Stone, Yashar Hezaveh,\n  Laurence Perreault-Levasseur","authorsParsed":[["Barco","Gabriel Missael",""],["Adam","Alexandre",""],["Stone","Connor",""],["Hezaveh","Yashar",""],["Perreault-Levasseur","Laurence",""]],"versions":[{"version":"v1","created":"Wed, 24 Jul 2024 22:39:27 GMT"}],"updateDate":"2024-07-26","timestamp":1721860767000,"abstract":"  Bayesian inference for inverse problems hinges critically on the choice of\npriors. In the absence of specific prior information, population-level\ndistributions can serve as effective priors for parameters of interest. With\nthe advent of machine learning, the use of data-driven population-level\ndistributions (encoded, e.g., in a trained deep neural network) as priors is\nemerging as an appealing alternative to simple parametric priors in a variety\nof inverse problems. However, in many astrophysical applications, it is often\ndifficult or even impossible to acquire independent and identically distributed\nsamples from the underlying data-generating process of interest to train these\nmodels. In these cases, corrupted data or a surrogate, e.g. a simulator, is\noften used to produce training samples, meaning that there is a risk of\nobtaining misspecified priors. This, in turn, can bias the inferred posteriors\nin ways that are difficult to quantify, which limits the potential\napplicability of these models in real-world scenarios. In this work, we propose\naddressing this issue by iteratively updating the population-level\ndistributions by retraining the model with posterior samples from different\nsets of observations and showcase the potential of this method on the problem\nof background image reconstruction in strong gravitational lensing when\nscore-based models are used as data-driven priors. We show that starting from a\nmisspecified prior distribution, the updated distribution becomes progressively\ncloser to the underlying population-level distribution, and the resulting\nposterior samples exhibit reduced bias after several updates.\n","subjects":["Astrophysics/Instrumentation and Methods for Astrophysics","Astrophysics/Cosmology and Nongalactic Astrophysics","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"-tPmx0yqLp5GPnPFV_KzNPMvnkVTovbjAZA88M8LZeU","pdfSize":"3197875","objectId":"0x4720bce5709a34979b9c8a7bee8fd69e8db0977df801be0b2cecdb1c5590d496","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
