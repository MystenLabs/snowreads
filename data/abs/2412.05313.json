{
  "id": "2412.05313",
  "title": "{\\lambda}: A Benchmark for Data-Efficiency in Long-Horizon Indoor Mobile\n  Manipulation Robotics",
  "authors": "Ahmed Jaafar, Shreyas Sundara Raman, Yichen Wei, Sudarshan Harithas,\n  Sofia Juliani, Anneke Wernerfelt, Benedict Quartey, Ifrah Idrees, Jason Xinyu\n  Liu, Stefanie Tellex",
  "authorsParsed": [
    [
      "Jaafar",
      "Ahmed",
      ""
    ],
    [
      "Raman",
      "Shreyas Sundara",
      ""
    ],
    [
      "Wei",
      "Yichen",
      ""
    ],
    [
      "Harithas",
      "Sudarshan",
      ""
    ],
    [
      "Juliani",
      "Sofia",
      ""
    ],
    [
      "Wernerfelt",
      "Anneke",
      ""
    ],
    [
      "Quartey",
      "Benedict",
      ""
    ],
    [
      "Idrees",
      "Ifrah",
      ""
    ],
    [
      "Liu",
      "Jason Xinyu",
      ""
    ],
    [
      "Tellex",
      "Stefanie",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Thu, 28 Nov 2024 19:31:50 GMT"
    },
    {
      "version": "v2",
      "created": "Thu, 2 Jan 2025 15:16:49 GMT"
    },
    {
      "version": "v3",
      "created": "Tue, 7 Jan 2025 18:57:23 GMT"
    },
    {
      "version": "v4",
      "created": "Mon, 27 Jan 2025 18:53:40 GMT"
    },
    {
      "version": "v5",
      "created": "Mon, 3 Feb 2025 18:54:17 GMT"
    }
  ],
  "updateDate": "2025-02-04",
  "timestamp": 1732822310000,
  "abstract": "  Efficiently learning and executing long-horizon mobile manipulation (MoMa)\ntasks is crucial for advancing robotics in household and workplace settings.\nHowever, current MoMa models are data-inefficient, underscoring the need for\nimproved models that require realistic-sized benchmarks to evaluate their\nefficiency, which do not exist. To address this, we introduce the LAMBDA\n({\\lambda}) benchmark (Long-horizon Actions for Mobile-manipulation\nBenchmarking of Directed Activities), which evaluates the data efficiency of\nmodels on language-conditioned, long-horizon, multi-room, multi-floor,\npick-and-place tasks using a dataset of manageable size, more feasible for\ncollection. The benchmark includes 571 human-collected demonstrations that\nprovide realism and diversity in simulated and real-world settings. Unlike\nplanner-generated data, these trajectories offer natural variability and\nreplay-verifiability, ensuring robust learning and evaluation. We benchmark\nseveral models, including learning-based models and a neuro-symbolic modular\napproach combining foundation models with task and motion planning.\nLearning-based models show suboptimal success rates, even when leveraging\npretrained weights, underscoring significant data inefficiencies. However, the\nneuro-symbolic approach performs significantly better while being more data\nefficient. Findings highlight the need for more data-efficient learning-based\nMoMa approaches. {\\lambda} addresses this gap by serving as a key benchmark for\nevaluating the data efficiency of those future models in handling household\nrobotics tasks.\n",
  "subjects": [
    "Computer Science/Robotics",
    "Computer Science/Artificial Intelligence",
    "Computer Science/Machine Learning"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "BhHvk0f-Jk38VHSNiVpCtjA72YoIQQvaq77vIVd0dFA",
  "pdfSize": "710107"
}