{"id":"2407.21596","title":"Evaluating SAM2's Role in Camouflaged Object Detection: From SAM to SAM2","authors":"Lv Tang and Bo Li","authorsParsed":[["Tang","Lv",""],["Li","Bo",""]],"versions":[{"version":"v1","created":"Wed, 31 Jul 2024 13:32:10 GMT"}],"updateDate":"2024-08-01","timestamp":1722432730000,"abstract":"  The Segment Anything Model (SAM), introduced by Meta AI Research as a generic\nobject segmentation model, quickly garnered widespread attention and\nsignificantly influenced the academic community. To extend its application to\nvideo, Meta further develops Segment Anything Model 2 (SAM2), a unified model\ncapable of both video and image segmentation. SAM2 shows notable improvements\nover its predecessor in terms of applicable domains, promptable segmentation\naccuracy, and running speed. However, this report reveals a decline in SAM2's\nability to perceive different objects in images without prompts in its auto\nmode, compared to SAM. Specifically, we employ the challenging task of\ncamouflaged object detection to assess this performance decrease, hoping to\ninspire further exploration of the SAM model family by researchers. The results\nof this paper are provided in \\url{https://github.com/luckybird1994/SAMCOD}.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"tfm0BZbRBDriTOw9KnfpvYhxVvNGV1gUnC6XCzGHa-0","pdfSize":"449700"}