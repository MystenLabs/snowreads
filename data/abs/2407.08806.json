{"id":"2407.08806","title":"HO-FMN: Hyperparameter Optimization for Fast Minimum-Norm Attacks","authors":"Raffaele Mura, Giuseppe Floris, Luca Scionis, Giorgio Piras, Maura\n  Pintor, Ambra Demontis, Giorgio Giacinto, Battista Biggio, Fabio Roli","authorsParsed":[["Mura","Raffaele",""],["Floris","Giuseppe",""],["Scionis","Luca",""],["Piras","Giorgio",""],["Pintor","Maura",""],["Demontis","Ambra",""],["Giacinto","Giorgio",""],["Biggio","Battista",""],["Roli","Fabio",""]],"versions":[{"version":"v1","created":"Thu, 11 Jul 2024 18:30:01 GMT"}],"updateDate":"2024-07-15","timestamp":1720722601000,"abstract":"  Gradient-based attacks are a primary tool to evaluate robustness of\nmachine-learning models. However, many attacks tend to provide\noverly-optimistic evaluations as they use fixed loss functions, optimizers,\nstep-size schedulers, and default hyperparameters. In this work, we tackle\nthese limitations by proposing a parametric variation of the well-known fast\nminimum-norm attack algorithm, whose loss, optimizer, step-size scheduler, and\nhyperparameters can be dynamically adjusted. We re-evaluate 12 robust models,\nshowing that our attack finds smaller adversarial perturbations without\nrequiring any additional tuning. This also enables reporting adversarial\nrobustness as a function of the perturbation budget, providing a more complete\nevaluation than that offered by fixed-budget attacks, while remaining\nefficient. We release our open-source code at https://github.com/pralab/HO-FMN.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"dFDz0Pxg10twqLju3wgBQt-416ynrAlCrZsdyFjLqcE","pdfSize":"1461988","objectId":"0xed7b3feecc762900c194bc2fc2f119e09e552826896fee865261585cc4ef91b6","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
