{
  "id": "2412.07590",
  "title": "Motion Artifact Removal in Pixel-Frequency Domain via Alternate Masks\n  and Diffusion Model",
  "authors": "Jiahua Xu, Dawei Zhou, Lei Hu, Jianfeng Guo, Feng Yang, Zaiyi Liu,\n  Nannan Wang, Xinbo Gao",
  "authorsParsed": [
    [
      "Xu",
      "Jiahua",
      ""
    ],
    [
      "Zhou",
      "Dawei",
      ""
    ],
    [
      "Hu",
      "Lei",
      ""
    ],
    [
      "Guo",
      "Jianfeng",
      ""
    ],
    [
      "Yang",
      "Feng",
      ""
    ],
    [
      "Liu",
      "Zaiyi",
      ""
    ],
    [
      "Wang",
      "Nannan",
      ""
    ],
    [
      "Gao",
      "Xinbo",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Tue, 10 Dec 2024 15:25:18 GMT"
    },
    {
      "version": "v2",
      "created": "Wed, 11 Dec 2024 11:40:15 GMT"
    }
  ],
  "updateDate": "2024-12-12",
  "timestamp": 1733844318000,
  "abstract": "  Motion artifacts present in magnetic resonance imaging (MRI) can seriously\ninterfere with clinical diagnosis. Removing motion artifacts is a\nstraightforward solution and has been extensively studied. However, paired data\nare still heavily relied on in recent works and the perturbations in k-space\n(frequency domain) are not well considered, which limits their applications in\nthe clinical field. To address these issues, we propose a novel unsupervised\npurification method which leverages pixel-frequency information of noisy MRI\nimages to guide a pre-trained diffusion model to recover clean MRI images.\nSpecifically, considering that motion artifacts are mainly concentrated in\nhigh-frequency components in k-space, we utilize the low-frequency components\nas the guide to ensure correct tissue textures. Additionally, given that\nhigh-frequency and pixel information are helpful for recovering shape and\ndetail textures, we design alternate complementary masks to simultaneously\ndestroy the artifact structure and exploit useful information. Quantitative\nexperiments are performed on datasets from different tissues and show that our\nmethod achieves superior performance on several metrics. Qualitative\nevaluations with radiologists also show that our method provides better\nclinical feedback. Our code is available at https://github.com/medcx/PFAD.\n",
  "subjects": [
    "Electrical Engineering and Systems Science/Image and Video Processing",
    "Computer Science/Computer Vision and Pattern Recognition"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "Xr4ISQNF2vssXIFWvKWcs_PM1dF1gBFnzCOcO6xG0rQ",
  "pdfSize": "9536317"
}