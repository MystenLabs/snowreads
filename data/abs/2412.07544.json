{
  "id": "2412.07544",
  "title": "Contractive Dynamical Imitation Policies for Efficient Out-of-Sample\n  Recovery",
  "authors": "Amin Abyaneh, Mahrokh G. Boroujeni, Hsiu-Chin Lin, Giancarlo\n  Ferrari-Trecate",
  "authorsParsed": [
    [
      "Abyaneh",
      "Amin",
      ""
    ],
    [
      "Boroujeni",
      "Mahrokh G.",
      ""
    ],
    [
      "Lin",
      "Hsiu-Chin",
      ""
    ],
    [
      "Ferrari-Trecate",
      "Giancarlo",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Tue, 10 Dec 2024 14:28:18 GMT"
    }
  ],
  "updateDate": "2024-12-11",
  "timestamp": 1733840898000,
  "abstract": "  Imitation learning is a data-driven approach to learning policies from expert\nbehavior, but it is prone to unreliable outcomes in out-of-sample (OOS)\nregions. While previous research relying on stable dynamical systems guarantees\nconvergence to a desired state, it often overlooks transient behavior. We\npropose a framework for learning policies using modeled by contractive\ndynamical systems, ensuring that all policy rollouts converge regardless of\nperturbations, and in turn, enable efficient OOS recovery. By leveraging\nrecurrent equilibrium networks and coupling layers, the policy structure\nguarantees contractivity for any parameter choice, which facilitates\nunconstrained optimization. Furthermore, we provide theoretical upper bounds\nfor worst-case and expected loss terms, rigorously establishing the reliability\nof our method in deployment. Empirically, we demonstrate substantial OOS\nperformance improvements in robotics manipulation and navigation tasks in\nsimulation.\n",
  "subjects": [
    "Computer Science/Machine Learning",
    "Computer Science/Robotics",
    "Statistics/Machine Learning"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "TEDWmjA_OASI5ZNvFenziDgJ0tAEhgn223epWUZhmPo",
  "pdfSize": "28967299"
}