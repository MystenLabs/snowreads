{"id":"2407.06315","title":"Shedding More Light on Robust Classifiers under the lens of Energy-based\n  Models","authors":"Mujtaba Hussain Mirza, Maria Rosaria Briglia, Senad Beadini and Iacopo\n  Masi","authorsParsed":[["Mirza","Mujtaba Hussain",""],["Briglia","Maria Rosaria",""],["Beadini","Senad",""],["Masi","Iacopo",""]],"versions":[{"version":"v1","created":"Mon, 8 Jul 2024 18:31:19 GMT"},{"version":"v2","created":"Thu, 11 Jul 2024 11:11:03 GMT"},{"version":"v3","created":"Tue, 10 Sep 2024 12:59:47 GMT"}],"updateDate":"2024-09-11","timestamp":1720463479000,"abstract":"  By reinterpreting a robust discriminative classifier as Energy-based Model\n(EBM), we offer a new take on the dynamics of adversarial training (AT). Our\nanalysis of the energy landscape during AT reveals that untargeted attacks\ngenerate adversarial images much more in-distribution (lower energy) than the\noriginal data from the point of view of the model. Conversely, we observe the\nopposite for targeted attacks. On the ground of our thorough analysis, we\npresent new theoretical and practical results that show how interpreting AT\nenergy dynamics unlocks a better understanding: (1) AT dynamic is governed by\nthree phases and robust overfitting occurs in the third phase with a drastic\ndivergence between natural and adversarial energies (2) by rewriting the loss\nof TRadeoff-inspired Adversarial DEfense via Surrogate-loss minimization\n(TRADES) in terms of energies, we show that TRADES implicitly alleviates\noverfitting by means of aligning the natural energy with the adversarial one\n(3) we empirically show that all recent state-of-the-art robust classifiers are\nsmoothing the energy landscape and we reconcile a variety of studies about\nunderstanding AT and weighting the loss function under the umbrella of EBMs.\nMotivated by rigorous evidence, we propose Weighted Energy Adversarial Training\n(WEAT), a novel sample weighting scheme that yields robust accuracy matching\nthe state-of-the-art on multiple benchmarks such as CIFAR-10 and SVHN and going\nbeyond in CIFAR-100 and Tiny-ImageNet. We further show that robust classifiers\nvary in the intensity and quality of their generative capabilities, and offer a\nsimple method to push this capability, reaching a remarkable Inception Score\n(IS) and FID using a robust classifier without training for generative\nmodeling. The code to reproduce our results is available at\nhttp://github.com/OmnAI-Lab/Robust-Classifiers-under-the-lens-of-EBM/ .\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"3FL0e1aQcNseJhTCnkzZ-zhmEwjBTvsr3hVWernAQ_M","pdfSize":"19505849"}