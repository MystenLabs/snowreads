{
  "id": "2412.17227",
  "title": "Brain-to-Text Benchmark '24: Lessons Learned",
  "authors": "Francis R. Willett, Jingyuan Li, Trung Le, Chaofei Fan, Mingfei Chen,\n  Eli Shlizerman, Yue Chen, Xin Zheng, Tatsuo S. Okubo, Tyler Benster, Hyun\n  Dong Lee, Maxwell Kounga, E. Kelly Buchanan, David Zoltowski, Scott W.\n  Linderman, Jaimie M. Henderson",
  "authorsParsed": [
    [
      "Willett",
      "Francis R.",
      ""
    ],
    [
      "Li",
      "Jingyuan",
      ""
    ],
    [
      "Le",
      "Trung",
      ""
    ],
    [
      "Fan",
      "Chaofei",
      ""
    ],
    [
      "Chen",
      "Mingfei",
      ""
    ],
    [
      "Shlizerman",
      "Eli",
      ""
    ],
    [
      "Chen",
      "Yue",
      ""
    ],
    [
      "Zheng",
      "Xin",
      ""
    ],
    [
      "Okubo",
      "Tatsuo S.",
      ""
    ],
    [
      "Benster",
      "Tyler",
      ""
    ],
    [
      "Lee",
      "Hyun Dong",
      ""
    ],
    [
      "Kounga",
      "Maxwell",
      ""
    ],
    [
      "Buchanan",
      "E. Kelly",
      ""
    ],
    [
      "Zoltowski",
      "David",
      ""
    ],
    [
      "Linderman",
      "Scott W.",
      ""
    ],
    [
      "Henderson",
      "Jaimie M.",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Mon, 23 Dec 2024 02:44:35 GMT"
    }
  ],
  "updateDate": "2024-12-24",
  "timestamp": 1734921875000,
  "abstract": "  Speech brain-computer interfaces aim to decipher what a person is trying to\nsay from neural activity alone, restoring communication to people with\nparalysis who have lost the ability to speak intelligibly. The Brain-to-Text\nBenchmark '24 and associated competition was created to foster the advancement\nof decoding algorithms that convert neural activity to text. Here, we summarize\nthe lessons learned from the competition ending on June 1, 2024 (the top 4\nentrants also presented their experiences in a recorded webinar). The largest\nimprovements in accuracy were achieved using an ensembling approach, where the\noutput of multiple independent decoders was merged using a fine-tuned large\nlanguage model (an approach used by all 3 top entrants). Performance gains were\nalso found by improving how the baseline recurrent neural network (RNN) model\nwas trained, including by optimizing learning rate scheduling and by using a\ndiphone training objective. Improving upon the model architecture itself proved\nmore difficult, however, with attempts to use deep state space models or\ntransformers not yet appearing to offer a benefit over the RNN baseline. The\nbenchmark will remain open indefinitely to support further work towards\nincreasing the accuracy of brain-to-text algorithms.\n",
  "subjects": [
    "Computer Science/Computation and Language",
    "Computer Science/Machine Learning",
    "Quantitative Biology/Neurons and Cognition"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "vLwkMY4XephrfXRlVaxQwbUAG64njQ6AH2fbbq82X3E",
  "pdfSize": "872218"
}