{"id":"2412.06975","title":"AutoReason: Automatic Few-Shot Reasoning Decomposition","authors":"Arda Sevinc and Abdurrahman Gumus","authorsParsed":[["Sevinc","Arda",""],["Gumus","Abdurrahman",""]],"versions":[{"version":"v1","created":"Mon, 9 Dec 2024 20:35:39 GMT"}],"updateDate":"2024-12-11","timestamp":1733776539000,"abstract":"  Chain of Thought (CoT) was introduced in recent research as a method for\nimproving step-by-step reasoning in Large Language Models. However, CoT has\nlimited applications such as its need for hand-crafted few-shot exemplar\nprompts and no capability to adjust itself to different queries.\n  In this work, we propose a system to automatically generate rationales using\nCoT. Our method improves multi-step implicit reasoning capabilities by\ndecomposing the implicit query into several explicit questions. This provides\ninterpretability for the model, improving reasoning in weaker LLMs. We test our\napproach with two Q\\&A datasets: StrategyQA and HotpotQA. We show an increase\nin accuracy with both, especially on StrategyQA.\n  To facilitate further research in this field, the complete source code for\nthis study has been made publicly available on GitHub:\nhttps://github.com/miralab-ai/autoreason.\n","subjects":["Computer Science/Computation and Language","Computer Science/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"WH8Dux2rG5Vb9yY2qrTWljU-r0HdXMa45J5bojULLg8","pdfSize":"5209577"}