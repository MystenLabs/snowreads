{"id":"2407.09721","title":"Purrfect Pitch: Exploring Musical Interval Learning through Multisensory\n  Interfaces","authors":"Sam Chin, Cathy Mengying Fang, Nikhil Singh, Ibrahim Ibrahim, Joe\n  Paradiso, Pattie Maes","authorsParsed":[["Chin","Sam",""],["Fang","Cathy Mengying",""],["Singh","Nikhil",""],["Ibrahim","Ibrahim",""],["Paradiso","Joe",""],["Maes","Pattie",""]],"versions":[{"version":"v1","created":"Fri, 12 Jul 2024 23:28:49 GMT"}],"updateDate":"2024-07-16","timestamp":1720826929000,"abstract":"  We introduce Purrfect Pitch, a system consisting of a wearable haptic device\nand a custom-designed learning interface for musical ear training. We focus on\nthe ability to identify musical intervals (sequences of two musical notes),\nwhich is a perceptually ambiguous task that usually requires strenuous rote\ntraining. With our system, the user would hear a sequence of two tones while\nsimultaneously receiving two corresponding vibrotactile stimuli on the back.\nProviding haptic feedback along the back makes the auditory distance between\nthe two tones more salient, and the back-worn design is comfortable and\nunobtrusive. During training, the user receives multi-sensory feedback from our\nsystem and inputs their guessed interval value on our web-based learning\ninterface. They see a green (otherwise red) screen for a correct guess with the\ncorrect interval value. Our study with 18 participants shows that our system\nenables novice learners to identify intervals more accurately and consistently\nthan those who only received audio feedback, even after the haptic feedback is\nremoved. We also share further insights on how to design a multisensory\nlearning system.\n","subjects":["Computing Research Repository/Human-Computer Interaction"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"2p6cqjPrnw9vftZvVM2lKEmKR-WXXQt63JZG89Emo3U","pdfSize":"9840669"}