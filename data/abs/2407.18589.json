{"id":"2407.18589","title":"HICEScore: A Hierarchical Metric for Image Captioning Evaluation","authors":"Zequn Zeng, Jianqiao Sun, Hao Zhang, Tiansheng Wen, Yudi Su, Yan Xie,\n  Zhengjue Wang, Bo Chen","authorsParsed":[["Zeng","Zequn",""],["Sun","Jianqiao",""],["Zhang","Hao",""],["Wen","Tiansheng",""],["Su","Yudi",""],["Xie","Yan",""],["Wang","Zhengjue",""],["Chen","Bo",""]],"versions":[{"version":"v1","created":"Fri, 26 Jul 2024 08:24:30 GMT"}],"updateDate":"2024-07-29","timestamp":1721982270000,"abstract":"  Image captioning evaluation metrics can be divided into two categories,\nreference-based metrics and reference-free metrics. However, reference-based\napproaches may struggle to evaluate descriptive captions with abundant visual\ndetails produced by advanced multimodal large language models, due to their\nheavy reliance on limited human-annotated references. In contrast, previous\nreference-free metrics have been proven effective via CLIP cross-modality\nsimilarity. Nonetheless, CLIP-based metrics, constrained by their solution of\nglobal image-text compatibility, often have a deficiency in detecting local\ntextual hallucinations and are insensitive to small visual objects. Besides,\ntheir single-scale designs are unable to provide an interpretable evaluation\nprocess such as pinpointing the position of caption mistakes and identifying\nvisual regions that have not been described. To move forward, we propose a\nnovel reference-free metric for image captioning evaluation, dubbed\nHierarchical Image Captioning Evaluation Score (HICE-S). By detecting local\nvisual regions and textual phrases, HICE-S builds an interpretable hierarchical\nscoring mechanism, breaking through the barriers of the single-scale structure\nof existing reference-free metrics. Comprehensive experiments indicate that our\nproposed metric achieves the SOTA performance on several benchmarks,\noutperforming existing reference-free metrics like CLIP-S and PAC-S, and\nreference-based metrics like METEOR and CIDEr. Moreover, several case studies\nreveal that the assessment process of HICE-S on detailed captions closely\nresembles interpretable human judgments.Our code is available at\nhttps://github.com/joeyz0z/HICE.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"8NcINBXzTfA6w-5NAsKCYsnyywyZa39TU_4QfCZxL-E","pdfSize":"3539033"}