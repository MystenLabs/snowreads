{
  "id": "2412.04773",
  "title": "Robust and Optimal Tensor Estimation via Robust Gradient Descent",
  "authors": "Xiaoyu Zhang, Di Wang, Guodong Li, Defeng Sun",
  "authorsParsed": [
    [
      "Zhang",
      "Xiaoyu",
      ""
    ],
    [
      "Wang",
      "Di",
      ""
    ],
    [
      "Li",
      "Guodong",
      ""
    ],
    [
      "Sun",
      "Defeng",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Fri, 6 Dec 2024 04:34:00 GMT"
    }
  ],
  "updateDate": "2024-12-09",
  "timestamp": 1733459640000,
  "abstract": "  Low-rank tensor models are widely used in statistics and machine learning.\nHowever, most existing methods rely heavily on the assumption that data follows\na sub-Gaussian distribution. To address the challenges associated with\nheavy-tailed distributions encountered in real-world applications, we propose a\nnovel robust estimation procedure based on truncated gradient descent for\ngeneral low-rank tensor models. We establish the computational convergence of\nthe proposed method and derive optimal statistical rates under heavy-tailed\ndistributional settings of both covariates and noise for various low-rank\nmodels. Notably, the statistical error rates are governed by a local moment\ncondition, which captures the distributional properties of tensor variables\nprojected onto certain low-dimensional local regions. Furthermore, we present\nnumerical results to demonstrate the effectiveness of our method.\n",
  "subjects": [
    "Statistics/Methodology"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "chVD07KBXwtKKfhsOSosfrVjNJeGBQtc5e-XoCmi2dg",
  "pdfSize": "715326"
}