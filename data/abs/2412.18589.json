{
  "id": "2412.18589",
  "title": "Text-Driven Tumor Synthesis",
  "authors": "Xinran Li, Yi Shuai, Chen Liu, Qi Chen, Qilong Wu, Pengfei Guo, Dong\n  Yang, Can Zhao, Pedro R. A. S. Bassi, Daguang Xu, Kang Wang, Yang Yang, Alan\n  Yuille, Zongwei Zhou",
  "authorsParsed": [
    [
      "Li",
      "Xinran",
      ""
    ],
    [
      "Shuai",
      "Yi",
      ""
    ],
    [
      "Liu",
      "Chen",
      ""
    ],
    [
      "Chen",
      "Qi",
      ""
    ],
    [
      "Wu",
      "Qilong",
      ""
    ],
    [
      "Guo",
      "Pengfei",
      ""
    ],
    [
      "Yang",
      "Dong",
      ""
    ],
    [
      "Zhao",
      "Can",
      ""
    ],
    [
      "Bassi",
      "Pedro R. A. S.",
      ""
    ],
    [
      "Xu",
      "Daguang",
      ""
    ],
    [
      "Wang",
      "Kang",
      ""
    ],
    [
      "Yang",
      "Yang",
      ""
    ],
    [
      "Yuille",
      "Alan",
      ""
    ],
    [
      "Zhou",
      "Zongwei",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Tue, 24 Dec 2024 18:43:09 GMT"
    }
  ],
  "updateDate": "2024-12-25",
  "timestamp": 1735065789000,
  "abstract": "  Tumor synthesis can generate examples that AI often misses or over-detects,\nimproving AI performance by training on these challenging cases. However,\nexisting synthesis methods, which are typically unconditional -- generating\nimages from random variables -- or conditioned only by tumor shapes, lack\ncontrollability over specific tumor characteristics such as texture,\nheterogeneity, boundaries, and pathology type. As a result, the generated\ntumors may be overly similar or duplicates of existing training data, failing\nto effectively address AI's weaknesses. We propose a new text-driven tumor\nsynthesis approach, termed TextoMorph, that provides textual control over tumor\ncharacteristics. This is particularly beneficial for examples that confuse the\nAI the most, such as early tumor detection (increasing Sensitivity by +8.5%),\ntumor segmentation for precise radiotherapy (increasing DSC by +6.3%), and\nclassification between benign and malignant tumors (improving Sensitivity by\n+8.2%). By incorporating text mined from radiology reports into the synthesis\nprocess, we increase the variability and controllability of the synthetic\ntumors to target AI's failure cases more precisely. Moreover, TextoMorph uses\ncontrastive learning across different texts and CT scans, significantly\nreducing dependence on scarce image-report pairs (only 141 pairs used in this\nstudy) by leveraging a large corpus of 34,035 radiology reports. Finally, we\nhave developed rigorous tests to evaluate synthetic tumors, including\nText-Driven Visual Turing Test and Radiomics Pattern Analysis, showing that our\nsynthetic tumors is realistic and diverse in texture, heterogeneity,\nboundaries, and pathology.\n",
  "subjects": [
    "Electrical Engineering and Systems Science/Image and Video Processing",
    "Computer Science/Computer Vision and Pattern Recognition"
  ],
  "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
  "blobId": "UjejVD5hL16nME6mwFnMY8lJ_5V9B66WmlYQX3lcl4U",
  "pdfSize": "13502437"
}