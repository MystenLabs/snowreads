{"id":"2412.19123","title":"CoheDancers: Enhancing Interactive Group Dance Generation through\n  Music-Driven Coherence Decomposition","authors":"Kaixing Yang, Xulong Tang, Haoyu Wu, Qinliang Xue, Biao Qin, Hongyan\n  Liu, and Zhaoxin Fan","authorsParsed":[["Yang","Kaixing",""],["Tang","Xulong",""],["Wu","Haoyu",""],["Xue","Qinliang",""],["Qin","Biao",""],["Liu","Hongyan",""],["Fan","Zhaoxin",""]],"versions":[{"version":"v1","created":"Thu, 26 Dec 2024 08:47:13 GMT"}],"updateDate":"2024-12-30","timestamp":1735202833000,"abstract":"  Dance generation is crucial and challenging, particularly in domains like\ndance performance and virtual gaming. In the current body of literature, most\nmethodologies focus on Solo Music2Dance. While there are efforts directed\ntowards Group Music2Dance, these often suffer from a lack of coherence,\nresulting in aesthetically poor dance performances. Thus, we introduce\nCoheDancers, a novel framework for Music-Driven Interactive Group Dance\nGeneration. CoheDancers aims to enhance group dance generation coherence by\ndecomposing it into three key aspects: synchronization, naturalness, and\nfluidity. Correspondingly, we develop a Cycle Consistency based Dance\nSynchronization strategy to foster music-dance correspondences, an\nAuto-Regressive-based Exposure Bias Correction strategy to enhance the fluidity\nof the generated dances, and an Adversarial Training Strategy to augment the\nnaturalness of the group dance output. Collectively, these strategies enable\nCohdeDancers to produce highly coherent group dances with superior quality.\nFurthermore, to establish better benchmarks for Group Music2Dance, we construct\nthe most diverse and comprehensive open-source dataset to date, I-Dancers,\nfeaturing rich dancer interactions, and create comprehensive evaluation\nmetrics. Experimental evaluations on I-Dancers and other extant datasets\nsubstantiate that CoheDancers achieves unprecedented state-of-the-art\nperformance. Code will be released.\n","subjects":["Computer Science/Sound","Computer Science/Multimedia","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"u8Q922xMJOFkajEgKMQoaPV-iPr8PzRsA7fLpEczQWQ","pdfSize":"41948527"}