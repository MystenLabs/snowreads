{
  "id": "2412.12101",
  "title": "InterPLM: Discovering Interpretable Features in Protein Language Models\n  via Sparse Autoencoders",
  "authors": "Elana Simon, James Zou",
  "authorsParsed": [
    [
      "Simon",
      "Elana",
      ""
    ],
    [
      "Zou",
      "James",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Wed, 13 Nov 2024 18:51:21 GMT"
    }
  ],
  "updateDate": "2024-12-18",
  "timestamp": 1731523881000,
  "abstract": "  Protein language models (PLMs) have demonstrated remarkable success in\nprotein modeling and design, yet their internal mechanisms for predicting\nstructure and function remain poorly understood. Here we present a systematic\napproach to extract and analyze interpretable features from PLMs using sparse\nautoencoders (SAEs). By training SAEs on embeddings from the PLM ESM-2, we\nidentify up to 2,548 human-interpretable latent features per layer that\nstrongly correlate with up to 143 known biological concepts such as binding\nsites, structural motifs, and functional domains. In contrast, examining\nindividual neurons in ESM-2 reveals up to 46 neurons per layer with clear\nconceptual alignment across 15 known concepts, suggesting that PLMs represent\nmost concepts in superposition. Beyond capturing known annotations, we show\nthat ESM-2 learns coherent concepts that do not map onto existing annotations\nand propose a pipeline using language models to automatically interpret novel\nlatent features learned by the SAEs. As practical applications, we demonstrate\nhow these latent features can fill in missing annotations in protein databases\nand enable targeted steering of protein sequence generation. Our results\ndemonstrate that PLMs encode rich, interpretable representations of protein\nbiology and we propose a systematic framework to extract and analyze these\nlatent features. In the process, we recover both known biology and potentially\nnew protein motifs. As community resources, we introduce InterPLM\n(interPLM.ai), an interactive visualization platform for exploring and\nanalyzing learned PLM features, and release code for training and analysis at\ngithub.com/ElanaPearl/interPLM.\n",
  "subjects": [
    "Quantitative Biology/Biomolecules",
    "Computer Science/Artificial Intelligence",
    "Computer Science/Machine Learning",
    "Quantitative Biology/Quantitative Methods"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "dkKf2x3CPkP6aMEXLddtXL23i6TH51GEm2SG7TT8_8A",
  "pdfSize": "23128229"
}