{
  "id": "2412.20504",
  "title": "ReTaKe: Reducing Temporal and Knowledge Redundancy for Long Video\n  Understanding",
  "authors": "Xiao Wang, Qingyi Si, Jianlong Wu, Shiyu Zhu, Li Cao, and Liqiang Nie",
  "authorsParsed": [
    [
      "Wang",
      "Xiao",
      ""
    ],
    [
      "Si",
      "Qingyi",
      ""
    ],
    [
      "Wu",
      "Jianlong",
      ""
    ],
    [
      "Zhu",
      "Shiyu",
      ""
    ],
    [
      "Cao",
      "Li",
      ""
    ],
    [
      "Nie",
      "Liqiang",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Sun, 29 Dec 2024 15:42:24 GMT"
    },
    {
      "version": "v2",
      "created": "Sun, 5 Jan 2025 14:11:48 GMT"
    }
  ],
  "updateDate": "2025-01-07",
  "timestamp": 1735486944000,
  "abstract": "  Video Large Language Models (VideoLLMs) have achieved remarkable progress in\nvideo understanding. However, existing VideoLLMs often inherit the limitations\nof their backbone LLMs in handling long sequences, leading to challenges for\nlong video understanding. Common solutions either simply uniformly sample\nvideos' frames or compress visual tokens, which focus primarily on low-level\ntemporal visual redundancy, overlooking high-level knowledge redundancy. This\nlimits the achievable compression rate with minimal loss. To this end. we\nintroduce a training-free method, $\\textbf{ReTaKe}$, containing two novel\nmodules DPSelect and PivotKV, to jointly model and reduce both temporal visual\nredundancy and knowledge redundancy for long video understanding. Specifically,\nDPSelect identifies keyframes with local maximum peak distance based on their\nvisual features, which are closely aligned with human video perception. PivotKV\nemploys the obtained keyframes as pivots and conducts KV-Cache compression for\nthe non-pivot tokens with low attention scores, which are derived from the\nlearned prior knowledge of LLMs. Experiments on benchmarks VideoMME, MLVU, and\nLVBench, show that ReTaKe can support 4x longer video sequences with minimal\nperformance loss (<1%) and outperform all similar-size VideoLLMs with 3%-5%,\neven surpassing or on par with much larger ones. Our code is available at\nhttps://github.com/SCZwangxiao/video-ReTaKe\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition",
    "Computer Science/Computation and Language",
    "Computer Science/Multimedia"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "45kSuoBfxSACTZ3oIcxn3dAqq-EllfF-mJljKSIsbuk",
  "pdfSize": "1237632"
}