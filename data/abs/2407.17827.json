{"id":"2407.17827","title":"Unified Lexical Representation for Interpretable Visual-Language\n  Alignment","authors":"Yifan Li, Yikai Wang, Yanwei Fu, Dongyu Ru, Zheng Zhang, Tong He","authorsParsed":[["Li","Yifan",""],["Wang","Yikai",""],["Fu","Yanwei",""],["Ru","Dongyu",""],["Zhang","Zheng",""],["He","Tong",""]],"versions":[{"version":"v1","created":"Thu, 25 Jul 2024 07:35:27 GMT"}],"updateDate":"2024-07-26","timestamp":1721892927000,"abstract":"  Visual-Language Alignment (VLA) has gained a lot of attention since CLIP's\ngroundbreaking work. Although CLIP performs well, the typical direct latent\nfeature alignment lacks clarity in its representation and similarity scores. On\nthe other hand, lexical representation, a vector whose element represents the\nsimilarity between the sample and a word from the vocabulary, is a natural\nsparse representation and interpretable, providing exact matches for individual\nwords. However, lexical representations is difficult to learn due to no\nground-truth supervision and false-discovery issues, and thus requires complex\ndesign to train effectively. In this paper, we introduce LexVLA, a more\ninterpretable VLA framework by learning a unified lexical representation for\nboth modalities without complex design. We use DINOv2 as our visual model for\nits local-inclined features and Llama 2, a generative language model, to\nleverage its in-context lexical prediction ability. To avoid the false\ndiscovery, we propose an overuse penalty to refrain the lexical representation\nfrom falsely frequently activating meaningless words. We demonstrate that these\ntwo pre-trained uni-modal models can be well-aligned by fine-tuning on modest\nmulti-modal dataset and avoid intricate training configurations. On cross-modal\nretrieval benchmarks, LexVLA, trained on the CC-12M multi-modal dataset,\noutperforms baselines fine-tuned on larger datasets (e.g., YFCC15M) and those\ntrained from scratch on even bigger datasets (e.g., 1.1B data, including\nCC-12M). We conduct extensive experiments to analyze LexVLA.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"uAfcOrDZgP21cEmPn3tkrV0IgMAygmVpm5uEMYGNpos","pdfSize":"9601615"}