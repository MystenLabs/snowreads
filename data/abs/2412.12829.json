{"id":"2412.12829","title":"2by2: Weakly-Supervised Learning for Global Action Segmentation","authors":"Elena Bueno-Benito and Mariella Dimiccoli","authorsParsed":[["Bueno-Benito","Elena",""],["Dimiccoli","Mariella",""]],"versions":[{"version":"v1","created":"Tue, 17 Dec 2024 11:49:36 GMT"}],"updateDate":"2024-12-18","timestamp":1734436176000,"abstract":"  This paper presents a simple yet effective approach for the poorly\ninvestigated task of global action segmentation, aiming at grouping frames\ncapturing the same action across videos of different activities. Unlike the\ncase of videos depicting all the same activity, the temporal order of actions\nis not roughly shared among all videos, making the task even more challenging.\nWe propose to use activity labels to learn, in a weakly-supervised fashion,\naction representations suitable for global action segmentation. For this\npurpose, we introduce a triadic learning approach for video pairs, to ensure\nintra-video action discrimination, as well as inter-video and inter-activity\naction association. For the backbone architecture, we use a Siamese network\nbased on sparse transformers that takes as input video pairs and determine\nwhether they belong to the same activity. The proposed approach is validated on\ntwo challenging benchmark datasets: Breakfast and YouTube Instructions,\noutperforming state-of-the-art methods.\n","subjects":["Computer Science/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"55IuicisokK_VpgXDCskbdSuwn8RHsEQHnIIJwD5H84","pdfSize":"7793663"}