{"id":"2412.16602","title":"V\"Mean\"ba: Visual State Space Models only need 1 hidden dimension","authors":"Tien-Yu Chi, Hung-Yueh Chiang, Chi-Chih Chang, Ning-Chi Huang,\n  Kai-Chiang Wu","authorsParsed":[["Chi","Tien-Yu",""],["Chiang","Hung-Yueh",""],["Chang","Chi-Chih",""],["Huang","Ning-Chi",""],["Wu","Kai-Chiang",""]],"versions":[{"version":"v1","created":"Sat, 21 Dec 2024 12:27:07 GMT"}],"updateDate":"2024-12-24","timestamp":1734784027000,"abstract":"  Vision transformers dominate image processing tasks due to their superior\nperformance. However, the quadratic complexity of self-attention limits the\nscalability of these systems and their deployment on resource-constrained\ndevices. State Space Models (SSMs) have emerged as a solution by introducing a\nlinear recurrence mechanism, which reduces the complexity of sequence modeling\nfrom quadratic to linear. Recently, SSMs have been extended to high-resolution\nvision tasks. Nonetheless, the linear recurrence mechanism struggles to fully\nutilize matrix multiplication units on modern hardware, resulting in a\ncomputational bottleneck. We address this issue by introducing\n\\textit{VMeanba}, a training-free compression method that eliminates the\nchannel dimension in SSMs using mean operations. Our key observation is that\nthe output activations of SSM blocks exhibit low variances across channels. Our\n\\textit{VMeanba} leverages this property to optimize computation by averaging\nactivation maps across the channel to reduce the computational overhead without\ncompromising accuracy. Evaluations on image classification and semantic\nsegmentation tasks demonstrate that \\textit{VMeanba} achieves up to a 1.12x\nspeedup with less than a 3\\% accuracy loss. When combined with 40\\%\nunstructured pruning, the accuracy drop remains under 3\\%.\n","subjects":["Computer Science/Computer Vision and Pattern Recognition","Computer Science/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"RKlTrFDHTfGrkP3GGPa2JTIeIKx9yuMPRaZMIpRz45M","pdfSize":"4529690"}