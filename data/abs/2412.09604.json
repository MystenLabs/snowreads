{
  "id": "2412.09604",
  "title": "SynerGen-VL: Towards Synergistic Image Understanding and Generation with\n  Vision Experts and Token Folding",
  "authors": "Hao Li, Changyao Tian, Jie Shao, Xizhou Zhu, Zhaokai Wang, Jinguo Zhu,\n  Wenhan Dou, Xiaogang Wang, Hongsheng Li, Lewei Lu, Jifeng Dai",
  "authorsParsed": [
    [
      "Li",
      "Hao",
      ""
    ],
    [
      "Tian",
      "Changyao",
      ""
    ],
    [
      "Shao",
      "Jie",
      ""
    ],
    [
      "Zhu",
      "Xizhou",
      ""
    ],
    [
      "Wang",
      "Zhaokai",
      ""
    ],
    [
      "Zhu",
      "Jinguo",
      ""
    ],
    [
      "Dou",
      "Wenhan",
      ""
    ],
    [
      "Wang",
      "Xiaogang",
      ""
    ],
    [
      "Li",
      "Hongsheng",
      ""
    ],
    [
      "Lu",
      "Lewei",
      ""
    ],
    [
      "Dai",
      "Jifeng",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Thu, 12 Dec 2024 18:59:26 GMT"
    }
  ],
  "updateDate": "2024-12-13",
  "timestamp": 1734029966000,
  "abstract": "  The remarkable success of Large Language Models (LLMs) has extended to the\nmultimodal domain, achieving outstanding performance in image understanding and\ngeneration. Recent efforts to develop unified Multimodal Large Language Models\n(MLLMs) that integrate these capabilities have shown promising results.\nHowever, existing approaches often involve complex designs in model\narchitecture or training pipeline, increasing the difficulty of model training\nand scaling. In this paper, we propose SynerGen-VL, a simple yet powerful\nencoder-free MLLM capable of both image understanding and generation. To\naddress challenges identified in existing encoder-free unified MLLMs, we\nintroduce the token folding mechanism and the vision-expert-based progressive\nalignment pretraining strategy, which effectively support high-resolution image\nunderstanding while reducing training complexity. After being trained on\nlarge-scale mixed image-text data with a unified next-token prediction\nobjective, SynerGen-VL achieves or surpasses the performance of existing\nencoder-free unified MLLMs with comparable or smaller parameter sizes, and\nnarrows the gap with task-specific state-of-the-art models, highlighting a\npromising path toward future unified MLLMs. Our code and models shall be\nreleased.\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition"
  ],
  "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
  "blobId": "qyJFr4Cg0Sr_XSdBv0ZnOKppfhsqUm9XNPt9yezWRVQ",
  "pdfSize": "5269283"
}