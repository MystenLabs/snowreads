{"id":"2412.09616","title":"V2PE: Improving Multimodal Long-Context Capability of Vision-Language\n  Models with Variable Visual Position Encoding","authors":"Junqi Ge, Ziyi Chen, Jintao Lin, Jinguo Zhu, Xihui Liu, Jifeng Dai,\n  Xizhou Zhu","authorsParsed":[["Ge","Junqi",""],["Chen","Ziyi",""],["Lin","Jintao",""],["Zhu","Jinguo",""],["Liu","Xihui",""],["Dai","Jifeng",""],["Zhu","Xizhou",""]],"versions":[{"version":"v1","created":"Thu, 12 Dec 2024 18:59:46 GMT"},{"version":"v2","created":"Fri, 13 Dec 2024 04:58:33 GMT"}],"updateDate":"2024-12-16","timestamp":1734029986000,"abstract":"  Vision-Language Models (VLMs) have shown promising capabilities in handling\nvarious multimodal tasks, yet they struggle in long-context scenarios,\nparticularly in tasks involving videos, high-resolution images, or lengthy\nimage-text documents. In our work, we first conduct an empirical analysis of\nthe long-context capabilities of VLMs using our augmented long-context\nmultimodal datasets. Our findings reveal that directly applying the positional\nencoding mechanism used for textual tokens to visual tokens is suboptimal, and\nVLM performance degrades sharply when the position encoding exceeds the model's\ncontext window. To address this, we propose Variable Visual Position Encoding\n(V2PE), a novel positional encoding approach that employs variable and smaller\nincrements for visual tokens, enabling more efficient management of long\nmultimodal sequences. Our experiments demonstrate the effectiveness of V2PE to\nenhances VLMs' ability to effectively understand and reason over long\nmultimodal contexts. We further integrate V2PE with our augmented long-context\nmultimodal datasets to fine-tune the open-source VLM, InternVL2. The fine-tuned\nmodel achieves strong performance on both standard and long-context multimodal\ntasks. Notably, when the sequence length of the training dataset is increased\nto 256K tokens, the model is capable of processing multimodal sequences up to\n1M tokens, highlighting its potential for real-world long-context applications.\n","subjects":["Computer Science/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"Ci6VSP10HKeuBx3eUgN3PQfrfR_oF977iyABTRdI5tA","pdfSize":"5009549"}