{
  "id": "2412.04509",
  "title": "Pragmatic Metacognitive Prompting Improves LLM Performance on Sarcasm\n  Detection",
  "authors": "Joshua Lee, Wyatt Fong, Alexander Le, Sur Shah, Kevin Han, Kevin Zhu",
  "authorsParsed": [
    [
      "Lee",
      "Joshua",
      ""
    ],
    [
      "Fong",
      "Wyatt",
      ""
    ],
    [
      "Le",
      "Alexander",
      ""
    ],
    [
      "Shah",
      "Sur",
      ""
    ],
    [
      "Han",
      "Kevin",
      ""
    ],
    [
      "Zhu",
      "Kevin",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Wed, 4 Dec 2024 07:16:30 GMT"
    }
  ],
  "updateDate": "2024-12-09",
  "timestamp": 1733296590000,
  "abstract": "  Sarcasm detection is a significant challenge in sentiment analysis due to the\nnuanced and context-dependent nature of verbiage. We introduce Pragmatic\nMetacognitive Prompting (PMP) to improve the performance of Large Language\nModels (LLMs) in sarcasm detection, which leverages principles from pragmatics\nand reflection helping LLMs interpret implied meanings, consider contextual\ncues, and reflect on discrepancies to identify sarcasm. Using state-of-the-art\nLLMs such as LLaMA-3-8B, GPT-4o, and Claude 3.5 Sonnet, PMP achieves\nstate-of-the-art performance on GPT-4o on MUStARD and SemEval2018. This study\ndemonstrates that integrating pragmatic reasoning and metacognitive strategies\ninto prompting significantly enhances LLMs' ability to detect sarcasm, offering\na promising direction for future research in sentiment analysis.\n",
  "subjects": [
    "Computer Science/Computation and Language"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "-e_LlvkCPaD7hBQ8xig1-ibSVJXnEHZdSOtbrHid3p8",
  "pdfSize": "195308"
}