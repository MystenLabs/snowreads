{"id":"2412.07895","title":"How Should We Represent History in Interpretable Models of Clinical\n  Policies?","authors":"Anton Matsson, Lena Stempfle, Yaochen Rao, Zachary R. Margolin,\n  Heather J. Litman, Fredrik D. Johansson","authorsParsed":[["Matsson","Anton",""],["Stempfle","Lena",""],["Rao","Yaochen",""],["Margolin","Zachary R.",""],["Litman","Heather J.",""],["Johansson","Fredrik D.",""]],"versions":[{"version":"v1","created":"Tue, 10 Dec 2024 20:03:17 GMT"}],"updateDate":"2024-12-12","timestamp":1733860997000,"abstract":"  Modeling policies for sequential clinical decision-making based on\nobservational data is useful for describing treatment practices, standardizing\nfrequent patterns in treatment, and evaluating alternative policies. For each\ntask, it is essential that the policy model is interpretable. Learning accurate\nmodels requires effectively capturing the state of a patient, either through\nsequence representation learning or carefully crafted summaries of their\nmedical history. While recent work has favored the former, it remains a\nquestion as to how histories should best be represented for interpretable\npolicy modeling. Focused on model fit, we systematically compare diverse\napproaches to summarizing patient history for interpretable modeling of\nclinical policies across four sequential decision-making tasks. We illustrate\ndifferences in the policies learned using various representations by breaking\ndown evaluations by patient subgroups, critical states, and stages of\ntreatment, highlighting challenges specific to common use cases. We find that\ninterpretable sequence models using learned representations perform on par with\nblack-box models across all tasks. Interpretable models using hand-crafted\nrepresentations perform substantially worse when ignoring history entirely, but\nare made competitive by incorporating only a few aggregated and recent elements\nof patient history. The added benefits of using a richer representation are\npronounced for subgroups and in specific use cases. This underscores the\nimportance of evaluating policy models in the context of their intended use.\n","subjects":["Computer Science/Machine Learning","Computer Science/Artificial Intelligence","Statistics/Applications"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"7ca8EhCdSbpMNIFMVHmCTBrZCWmzemStu-CoelLIM9I","pdfSize":"920910"}