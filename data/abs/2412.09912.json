{"id":"2412.09912","title":"All-in-One: Transferring Vision Foundation Models into Stereo Matching","authors":"Jingyi Zhou, Haoyu Zhang, Jiakang Yuan, Peng Ye, Tao Chen, Hao Jiang,\n  Meiya Chen, Yangyang Zhang","authorsParsed":[["Zhou","Jingyi",""],["Zhang","Haoyu",""],["Yuan","Jiakang",""],["Ye","Peng",""],["Chen","Tao",""],["Jiang","Hao",""],["Chen","Meiya",""],["Zhang","Yangyang",""]],"versions":[{"version":"v1","created":"Fri, 13 Dec 2024 06:59:17 GMT"}],"updateDate":"2024-12-16","timestamp":1734073157000,"abstract":"  As a fundamental vision task, stereo matching has made remarkable progress.\nWhile recent iterative optimization-based methods have achieved promising\nperformance, their feature extraction capabilities still have room for\nimprovement. Inspired by the ability of vision foundation models (VFMs) to\nextract general representations, in this work, we propose AIO-Stereo which can\nflexibly select and transfer knowledge from multiple heterogeneous VFMs to a\nsingle stereo matching model. To better reconcile features between\nheterogeneous VFMs and the stereo matching model and fully exploit prior\nknowledge from VFMs, we proposed a dual-level feature utilization mechanism\nthat aligns heterogeneous features and transfers multi-level knowledge. Based\non the mechanism, a dual-level selective knowledge transfer module is designed\nto selectively transfer knowledge and integrate the advantages of multiple\nVFMs. Experimental results show that AIO-Stereo achieves start-of-the-art\nperformance on multiple datasets and ranks $1^{st}$ on the Middlebury dataset\nand outperforms all the published work on the ETH3D benchmark.\n","subjects":["Computer Science/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"XQGTlGTnIPXDXG0g1Lcofe38WMZkBUDU8PlKxgNeH6k","pdfSize":"1937305"}