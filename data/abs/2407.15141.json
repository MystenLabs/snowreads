{"id":"2407.15141","title":"Text-Augmented Multimodal LLMs for Chemical Reaction Condition\n  Recommendation","authors":"Yu Zhang, Ruijie Yu, Kaipeng Zeng, Ding Li, Feng Zhu, Xiaokang Yang,\n  Yaohui Jin, Yanyan Xu","authorsParsed":[["Zhang","Yu",""],["Yu","Ruijie",""],["Zeng","Kaipeng",""],["Li","Ding",""],["Zhu","Feng",""],["Yang","Xiaokang",""],["Jin","Yaohui",""],["Xu","Yanyan",""]],"versions":[{"version":"v1","created":"Sun, 21 Jul 2024 12:27:26 GMT"}],"updateDate":"2024-07-23","timestamp":1721564846000,"abstract":"  High-throughput reaction condition (RC) screening is fundamental to chemical\nsynthesis. However, current RC screening suffers from laborious and costly\ntrial-and-error workflows. Traditional computer-aided synthesis planning (CASP)\ntools fail to find suitable RCs due to data sparsity and inadequate reaction\nrepresentations. Nowadays, large language models (LLMs) are capable of tackling\nchemistry-related problems, such as molecule design, and chemical logic Q\\&A\ntasks. However, LLMs have not yet achieved accurate predictions of chemical\nreaction conditions. Here, we present MM-RCR, a text-augmented multimodal LLM\nthat learns a unified reaction representation from SMILES, reaction graphs, and\ntextual corpus for chemical reaction recommendation (RCR). To train MM-RCR, we\nconstruct 1.2 million pair-wised Q\\&A instruction datasets. Our experimental\nresults demonstrate that MM-RCR achieves state-of-the-art performance on two\nopen benchmark datasets and exhibits strong generalization capabilities on\nout-of-domain (OOD) and High-Throughput Experimentation (HTE) datasets. MM-RCR\nhas the potential to accelerate high-throughput condition screening in chemical\nsynthesis.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning","Physics/Chemical Physics"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"Gs4tQv_a8ZD-a7sByc_uCIa_KV04DtJlQX8W9F-gJOI","pdfSize":"5037921"}