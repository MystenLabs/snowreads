{
  "id": "2412.10718",
  "title": "Grid: Omni Visual Generation",
  "authors": "Cong Wan, Xiangyang Luo, Hao Luo, Zijian Cai, Yiren Song, Yunlong\n  Zhao, Yifan Bai, Yuhang He, Yihong Gong",
  "authorsParsed": [
    [
      "Wan",
      "Cong",
      ""
    ],
    [
      "Luo",
      "Xiangyang",
      ""
    ],
    [
      "Luo",
      "Hao",
      ""
    ],
    [
      "Cai",
      "Zijian",
      ""
    ],
    [
      "Song",
      "Yiren",
      ""
    ],
    [
      "Zhao",
      "Yunlong",
      ""
    ],
    [
      "Bai",
      "Yifan",
      ""
    ],
    [
      "He",
      "Yuhang",
      ""
    ],
    [
      "Gong",
      "Yihong",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Sat, 14 Dec 2024 07:22:03 GMT"
    },
    {
      "version": "v2",
      "created": "Tue, 17 Dec 2024 05:24:57 GMT"
    },
    {
      "version": "v3",
      "created": "Fri, 10 Jan 2025 07:20:26 GMT"
    },
    {
      "version": "v4",
      "created": "Tue, 21 Jan 2025 04:00:36 GMT"
    }
  ],
  "updateDate": "2025-01-22",
  "timestamp": 1734160923000,
  "abstract": "  Visual generation has witnessed remarkable progress in single-image tasks,\nyet extending these capabilities to temporal sequences remains challenging.\nCurrent approaches either build specialized video models from scratch with\nenormous computational costs or add separate motion modules to image\ngenerators, both requiring learning temporal dynamics anew. We observe that\nmodern image generation models possess underutilized potential in handling\nstructured layouts with implicit temporal understanding. Building on this\ninsight, we introduce GRID, which reformulates temporal sequences as grid\nlayouts, enabling holistic processing of visual sequences while leveraging\nexisting model capabilities. Through a parallel flow-matching training strategy\nwith coarse-to-fine scheduling, our approach achieves up to 67 faster inference\nspeeds while using <1/1000 of the computational resources compared to\nspecialized models. Extensive experiments demonstrate that GRID not only excels\nin temporal tasks from Text-to-Video to 3D Editing but also preserves strong\nperformance in image generation, establishing itself as an efficient and\nversatile omni-solution for visual generation.\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition"
  ],
  "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
  "blobId": "RcuBr83_sPktfY7TexttLJevPv9hWUEGr0G1Y5zHR48",
  "pdfSize": "13379595"
}