{"id":"2407.08335","title":"Analyzing the Runtime of the Gene-pool Optimal Mixing Evolutionary\n  Algorithm (GOMEA) on the Concatenated Trap Function","authors":"Yukai Qiao and Marcus Gallagher","authorsParsed":[["Qiao","Yukai",""],["Gallagher","Marcus",""]],"versions":[{"version":"v1","created":"Thu, 11 Jul 2024 09:37:21 GMT"}],"updateDate":"2024-07-12","timestamp":1720690641000,"abstract":"  The Gene-pool Optimal Mixing Evolutionary Algorithm (GOMEA) is a state of the\nart evolutionary algorithm that leverages linkage learning to efficiently\nexploit problem structure. By identifying and preserving important building\nblocks during variation, GOMEA has shown promising performance on various\noptimization problems. In this paper, we provide the first runtime analysis of\nGOMEA on the concatenated trap function, a challenging benchmark problem that\nconsists of multiple deceptive subfunctions. We derived an upper bound on the\nexpected runtime of GOMEA with a truthful linkage model, showing that it can\nsolve the problem in $O(m^{3}2^k)$ with high probability, where $m$ is the\nnumber of subfunctions and $k$ is the subfunction length. This is a significant\nspeedup compared to the (1+1) EA, which requires $O(ln{(m)}(mk)^{k})$ expected\nevaluations.\n","subjects":["Computing Research Repository/Neural and Evolutionary Computing"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"lcpt_kZIA2xoQvRK0l9mm6qRi9q1Hfl8njWg8j2g4to","pdfSize":"995656"}