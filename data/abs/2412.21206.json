{"id":"2412.21206","title":"PERSE: Personalized 3D Generative Avatars from A Single Portrait","authors":"Hyunsoo Cha, Inhee Lee, Hanbyul Joo","authorsParsed":[["Cha","Hyunsoo",""],["Lee","Inhee",""],["Joo","Hanbyul",""]],"versions":[{"version":"v1","created":"Mon, 30 Dec 2024 18:59:58 GMT"}],"updateDate":"2024-12-31","timestamp":1735585198000,"abstract":"  We present PERSE, a method for building an animatable personalized generative\navatar from a reference portrait. Our avatar model enables facial attribute\nediting in a continuous and disentangled latent space to control each facial\nattribute, while preserving the individual's identity. To achieve this, our\nmethod begins by synthesizing large-scale synthetic 2D video datasets, where\neach video contains consistent changes in the facial expression and viewpoint,\ncombined with a variation in a specific facial attribute from the original\ninput. We propose a novel pipeline to produce high-quality, photorealistic 2D\nvideos with facial attribute editing. Leveraging this synthetic attribute\ndataset, we present a personalized avatar creation method based on the 3D\nGaussian Splatting, learning a continuous and disentangled latent space for\nintuitive facial attribute manipulation. To enforce smooth transitions in this\nlatent space, we introduce a latent space regularization technique by using\ninterpolated 2D faces as supervision. Compared to previous approaches, we\ndemonstrate that PERSE generates high-quality avatars with interpolated\nattributes while preserving identity of reference person.\n","subjects":["Computer Science/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"OIwVeyUAHDhom3vfUbbsvUmYNSEz-ZnMSgqVjaD6Q34","pdfSize":"20754263"}