{"id":"2412.19677","title":"Deep ReLU networks -- injectivity capacity upper bounds","authors":"Mihailo Stojnic","authorsParsed":[["Stojnic","Mihailo",""]],"versions":[{"version":"v1","created":"Fri, 27 Dec 2024 14:57:40 GMT"}],"updateDate":"2024-12-30","timestamp":1735311460000,"abstract":"  We study deep ReLU feed forward neural networks (NN) and their injectivity\nabilities. The main focus is on \\emph{precisely} determining the so-called\ninjectivity capacity. For any given hidden layers architecture, it is defined\nas the minimal ratio between number of network's outputs and inputs which\nensures unique recoverability of the input from a realizable output. A strong\nrecent progress in precisely studying single ReLU layer injectivity properties\nis here moved to a deep network level. In particular, we develop a program that\nconnects deep $l$-layer net injectivity to an $l$-extension of the $\\ell_0$\nspherical perceptrons, thereby massively generalizing an isomorphism between\nstudying single layer injectivity and the capacity of the so-called\n(1-extension) $\\ell_0$ spherical perceptrons discussed in [82]. \\emph{Random\nduality theory} (RDT) based machinery is then created and utilized to\nstatistically handle properties of the extended $\\ell_0$ spherical perceptrons\nand implicitly of the deep ReLU NNs. A sizeable set of numerical evaluations is\nconducted as well to put the entire RDT machinery in practical use. From these\nwe observe a rapidly decreasing tendency in needed layers' expansions, i.e., we\nobserve a rapid \\emph{expansion saturation effect}. Only $4$ layers of depth\nare sufficient to closely approach level of no needed expansion -- a result\nthat fairly closely resembles observations made in practical experiments and\nthat has so far remained completely untouchable by any of the existing\nmathematical methodologies.\n","subjects":["Statistics/Machine Learning","Condensed Matter/Disordered Systems and Neural Networks","Computer Science/Information Theory","Computer Science/Machine Learning","Mathematics/Information Theory"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"Mho93P2KxFGCh4A5KbVIv9OYeDWBB8k04XpHfdcy7wA","pdfSize":"449619"}