{"id":"2412.00948","title":"Uhura: A Benchmark for Evaluating Scientific Question Answering and\n  Truthfulness in Low-Resource African Languages","authors":"Edward Bayes, Israel Abebe Azime, Jesujoba O. Alabi, Jonas Kgomo, Tyna\n  Eloundou, Elizabeth Proehl, Kai Chen, Imaan Khadir, Naome A. Etori,\n  Shamsuddeen Hassan Muhammad, Choice Mpanza, Igneciah Pocia Thete, Dietrich\n  Klakow, David Ifeoluwa Adelani","authorsParsed":[["Bayes","Edward",""],["Azime","Israel Abebe",""],["Alabi","Jesujoba O.",""],["Kgomo","Jonas",""],["Eloundou","Tyna",""],["Proehl","Elizabeth",""],["Chen","Kai",""],["Khadir","Imaan",""],["Etori","Naome A.",""],["Muhammad","Shamsuddeen Hassan",""],["Mpanza","Choice",""],["Thete","Igneciah Pocia",""],["Klakow","Dietrich",""],["Adelani","David Ifeoluwa",""]],"versions":[{"version":"v1","created":"Sun, 1 Dec 2024 19:46:40 GMT"}],"updateDate":"2024-12-03","timestamp":1733082400000,"abstract":"  Evaluations of Large Language Models (LLMs) on knowledge-intensive tasks and\nfactual accuracy often focus on high-resource languages primarily because\ndatasets for low-resource languages (LRLs) are scarce. In this paper, we\npresent Uhura -- a new benchmark that focuses on two tasks in six\ntypologically-diverse African languages, created via human translation of\nexisting English benchmarks. The first dataset, Uhura-ARC-Easy, is composed of\nmultiple-choice science questions. The second, Uhura-TruthfulQA, is a safety\nbenchmark testing the truthfulness of models on topics including health, law,\nfinance, and politics. We highlight the challenges creating benchmarks with\nhighly technical content for LRLs and outline mitigation strategies. Our\nevaluation reveals a significant performance gap between proprietary models\nsuch as GPT-4o and o1-preview, and Claude models, and open-source models like\nMeta's LLaMA and Google's Gemma. Additionally, all models perform better in\nEnglish than in African languages. These results indicate that LMs struggle\nwith answering scientific questions and are more prone to generating false\nclaims in low-resource African languages. Our findings underscore the necessity\nfor continuous improvement of multilingual LM capabilities in LRL settings to\nensure safe and reliable use in real-world contexts. We open-source the Uhura\nBenchmark and Uhura Platform to foster further research and development in NLP\nfor LRLs.\n","subjects":["Computer Science/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"Cj2e-bE3AWY-3xqsFvSQpijtVO__QZ63kEYcmWi0HEk","pdfSize":"4145898"}