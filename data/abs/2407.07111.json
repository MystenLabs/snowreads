{"id":"2407.07111","title":"Diffusion Model-Based Video Editing: A Survey","authors":"Wenhao Sun, Rong-Cheng Tu, Jingyi Liao and Dacheng Tao","authorsParsed":[["Sun","Wenhao",""],["Tu","Rong-Cheng",""],["Liao","Jingyi",""],["Tao","Dacheng",""]],"versions":[{"version":"v1","created":"Wed, 26 Jun 2024 04:58:39 GMT"}],"updateDate":"2024-07-11","timestamp":1719377919000,"abstract":"  The rapid development of diffusion models (DMs) has significantly advanced\nimage and video applications, making \"what you want is what you see\" a reality.\nAmong these, video editing has gained substantial attention and seen a swift\nrise in research activity, necessitating a comprehensive and systematic review\nof the existing literature. This paper reviews diffusion model-based video\nediting techniques, including theoretical foundations and practical\napplications. We begin by overviewing the mathematical formulation and image\ndomain's key methods. Subsequently, we categorize video editing approaches by\nthe inherent connections of their core technologies, depicting evolutionary\ntrajectory. This paper also dives into novel applications, including\npoint-based editing and pose-guided human video editing. Additionally, we\npresent a comprehensive comparison using our newly introduced V2VBench.\nBuilding on the progress achieved to date, the paper concludes with ongoing\nchallenges and potential directions for future research.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning","Computing Research Repository/Multimedia"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"yeYhagn0RHC5HzmCshSWYtKmKjo-jAJCwzDRWaat7Ic","pdfSize":"4246292"}