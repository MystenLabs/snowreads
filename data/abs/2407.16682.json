{"id":"2407.16682","title":"SAM-CP: Marrying SAM with Composable Prompts for Versatile Segmentation","authors":"Pengfei Chen, Lingxi Xie, Xinyue Huo, Xuehui Yu, Xiaopeng Zhang,\n  Yingfei Sun, Zhenjun Han, Qi Tian","authorsParsed":[["Chen","Pengfei",""],["Xie","Lingxi",""],["Huo","Xinyue",""],["Yu","Xuehui",""],["Zhang","Xiaopeng",""],["Sun","Yingfei",""],["Han","Zhenjun",""],["Tian","Qi",""]],"versions":[{"version":"v1","created":"Tue, 23 Jul 2024 17:47:25 GMT"}],"updateDate":"2024-07-24","timestamp":1721756845000,"abstract":"  The Segment Anything model (SAM) has shown a generalized ability to group\nimage pixels into patches, but applying it to semantic-aware segmentation still\nfaces major challenges. This paper presents SAM-CP, a simple approach that\nestablishes two types of composable prompts beyond SAM and composes them for\nversatile segmentation. Specifically, given a set of classes (in texts) and a\nset of SAM patches, the Type-I prompt judges whether a SAM patch aligns with a\ntext label, and the Type-II prompt judges whether two SAM patches with the same\ntext label also belong to the same instance. To decrease the complexity in\ndealing with a large number of semantic classes and patches, we establish a\nunified framework that calculates the affinity between (semantic and instance)\nqueries and SAM patches and merges patches with high affinity to the query.\nExperiments show that SAM-CP achieves semantic, instance, and panoptic\nsegmentation in both open and closed domains. In particular, it achieves\nstate-of-the-art performance in open-vocabulary segmentation. Our research\noffers a novel and generalized methodology for equipping vision foundation\nmodels like SAM with multi-grained semantic perception abilities.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"SJ0oSUjr1vWUZczouPZPw1579BGqeRotNZ1-MjbksgQ","pdfSize":"6029772","objectId":"0x73d7d20754570f82dee679e19517390a678b88083b3f0158e5a33e58b6c78c8e","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
