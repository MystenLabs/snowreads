{"id":"2407.07331","title":"Learning with Instance-Dependent Noisy Labels by Anchor Hallucination\n  and Hard Sample Label Correction","authors":"Po-Hsuan Huang, Chia-Ching Lin, Chih-Fan Hsu, Ming-Ching Chang,\n  Wei-Chao Chen","authorsParsed":[["Huang","Po-Hsuan",""],["Lin","Chia-Ching",""],["Hsu","Chih-Fan",""],["Chang","Ming-Ching",""],["Chen","Wei-Chao",""]],"versions":[{"version":"v1","created":"Wed, 10 Jul 2024 03:00:14 GMT"}],"updateDate":"2024-07-11","timestamp":1720580414000,"abstract":"  Learning from noisy-labeled data is crucial for real-world applications.\nTraditional Noisy-Label Learning (NLL) methods categorize training data into\nclean and noisy sets based on the loss distribution of training samples.\nHowever, they often neglect that clean samples, especially those with intricate\nvisual patterns, may also yield substantial losses. This oversight is\nparticularly significant in datasets with Instance-Dependent Noise (IDN), where\nmislabeling probabilities correlate with visual appearance. Our approach\nexplicitly distinguishes between clean vs.noisy and easy vs. hard samples. We\nidentify training samples with small losses, assuming they have simple patterns\nand correct labels. Utilizing these easy samples, we hallucinate multiple\nanchors to select hard samples for label correction. Corrected hard samples,\nalong with the easy samples, are used as labeled data in subsequent\nsemi-supervised training. Experiments on synthetic and real-world IDN datasets\ndemonstrate the superior performance of our method over other state-of-the-art\nNLL methods.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"4qZRXNssAM9Cztns05Zl4t4vxVAymRXis-GyhObJtfc","pdfSize":"970034","objectId":"0xb4f8297acff30a4c58199bbd715183eff77f793ca9304a6751089983bef1c95a","registeredEpoch":"1","certifiedEpoch":"1","startEpoch":"1","endEpoch":"201"}
