{"id":"2412.12552","title":"SAModified: A Foundation Model-Based Zero-Shot Approach for Refining\n  Noisy Land-Use Land-Cover Maps","authors":"Sparsh Pekhale, Rakshith Sathish, Sathisha Basavaraju, Divya Sharma","authorsParsed":[["Pekhale","Sparsh",""],["Sathish","Rakshith",""],["Basavaraju","Sathisha",""],["Sharma","Divya",""]],"versions":[{"version":"v1","created":"Tue, 17 Dec 2024 05:23:00 GMT"}],"updateDate":"2024-12-18","timestamp":1734412980000,"abstract":"  Land-use and land cover (LULC) analysis is critical in remote sensing, with\nwide-ranging applications across diverse fields such as agriculture, utilities,\nand urban planning. However, automating LULC map generation using machine\nlearning is rendered challenging due to noisy labels. Typically, the ground\ntruths (e.g. ESRI LULC, MapBioMass) have noisy labels that hamper the model's\nability to learn to accurately classify the pixels. Further, these erroneous\nlabels can significantly distort the performance metrics of a model, leading to\nmisleading evaluations. Traditionally, the ambiguous labels are rectified using\nunsupervised algorithms. These algorithms struggle not only with scalability\nbut also with generalization across different geographies. To overcome these\nchallenges, we propose a zero-shot approach using the foundation model, Segment\nAnything Model (SAM), to automatically delineate different land parcels/regions\nand leverage them to relabel the unsure pixels by using the local label\nstatistics within each detected region. We achieve a significant reduction in\nlabel noise and an improvement in the performance of the downstream\nsegmentation model by $\\approx 5\\%$ when trained with denoised labels.\n","subjects":["Computer Science/Computer Vision and Pattern Recognition","Computer Science/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by-sa/4.0/","blobId":"B9niR9yQIyh-ATXWyB5r4kNwSGcPKU7aZ5fRb7Fj87Q","pdfSize":"3085079"}