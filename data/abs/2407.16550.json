{"id":"2407.16550","title":"A Kernel-Based Conditional Two-Sample Test Using Nearest Neighbors (with\n  Applications to Calibration, Regression Curves, and Simulation-Based\n  Inference)","authors":"Anirban Chatterjee, Ziang Niu and Bhaswar B. Bhattacharya","authorsParsed":[["Chatterjee","Anirban",""],["Niu","Ziang",""],["Bhattacharya","Bhaswar B.",""]],"versions":[{"version":"v1","created":"Tue, 23 Jul 2024 15:04:38 GMT"},{"version":"v2","created":"Thu, 29 Aug 2024 02:06:07 GMT"}],"updateDate":"2024-08-30","timestamp":1721747078000,"abstract":"  In this paper we introduce a kernel-based measure for detecting differences\nbetween two conditional distributions. Using the `kernel trick' and\nnearest-neighbor graphs, we propose a consistent estimate of this measure which\ncan be computed in nearly linear time (for a fixed number of nearest\nneighbors). Moreover, when the two conditional distributions are the same, the\nestimate has a Gaussian limit and its asymptotic variance has a simple form\nthat can be easily estimated from the data. The resulting test attains precise\nasymptotic level and is universally consistent for detecting differences\nbetween two conditional distributions. We also provide a resampling based test\nusing our estimate that applies to the conditional goodness-of-fit problem,\nwhich controls Type I error in finite samples and is asymptotically consistent\nwith only a finite number of resamples. A method to de-randomize the resampling\ntest is also presented. The proposed methods can be readily applied to a broad\nrange of problems, ranging from classical nonparametric statistics to modern\nmachine learning. Specifically, we explore three applications: testing model\ncalibration, regression curve evaluation, and validation of emulator models in\nsimulation-based inference. We illustrate the superior performance of our\nmethod for these tasks, both in simulations as well as on real data. In\nparticular, we apply our method to (1) assess the calibration of neural network\nmodels trained on the CIFAR-10 dataset, (2) compare regression functions for\nwind power generation across two different turbines, and (3) validate emulator\nmodels on benchmark examples with intractable posteriors and for generating\nsynthetic `redshift' associated with galaxy images.\n","subjects":["Statistics/Methodology","Mathematics/Statistics Theory","Statistics/Machine Learning","Statistics/Statistics Theory"],"license":"http://creativecommons.org/publicdomain/zero/1.0/","blobId":"unjlJxtpyuOt5u2buewX28pYBenqeabNil2_s6L07W4","pdfSize":"1288072"}