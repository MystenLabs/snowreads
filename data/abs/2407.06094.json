{"id":"2407.06094","title":"ERR@HRI 2024 Challenge: Multimodal Detection of Errors and Failures in\n  Human-Robot Interactions","authors":"Micol Spitale, Maria Teresa Parreira, Maia Stiber, Minja Axelsson,\n  Neval Kara, Garima Kankariya, Chien-Ming Huang, Malte Jung, Wendy Ju, Hatice\n  Gunes","authorsParsed":[["Spitale","Micol",""],["Parreira","Maria Teresa",""],["Stiber","Maia",""],["Axelsson","Minja",""],["Kara","Neval",""],["Kankariya","Garima",""],["Huang","Chien-Ming",""],["Jung","Malte",""],["Ju","Wendy",""],["Gunes","Hatice",""]],"versions":[{"version":"v1","created":"Mon, 8 Jul 2024 16:34:48 GMT"}],"updateDate":"2024-07-09","timestamp":1720456488000,"abstract":"  Despite the recent advancements in robotics and machine learning (ML), the\ndeployment of autonomous robots in our everyday lives is still an open\nchallenge. This is due to multiple reasons among which are their frequent\nmistakes, such as interrupting people or having delayed responses, as well as\ntheir limited ability to understand human speech, i.e., failure in tasks like\ntranscribing speech to text. These mistakes may disrupt interactions and\nnegatively influence human perception of these robots. To address this problem,\nrobots need to have the ability to detect human-robot interaction (HRI)\nfailures. The ERR@HRI 2024 challenge tackles this by offering a benchmark\nmultimodal dataset of robot failures during human-robot interactions (HRI),\nencouraging researchers to develop and benchmark multimodal machine learning\nmodels to detect these failures. We created a dataset featuring multimodal\nnon-verbal interaction data, including facial, speech, and pose features from\nvideo clips of interactions with a robotic coach, annotated with labels\nindicating the presence or absence of robot mistakes, user awkwardness, and\ninteraction ruptures, allowing for the training and evaluation of predictive\nmodels. Challenge participants have been invited to submit their multimodal ML\nmodels for detection of robot errors and to be evaluated against various\nperformance metrics such as accuracy, precision, recall, F1 score, with and\nwithout a margin of error reflecting the time-sensitivity of these metrics. The\nresults of this challenge will help the research field in better understanding\nthe robot failures in human-robot interactions and designing autonomous robots\nthat can mitigate their own errors after successfully detecting them.\n","subjects":["Computing Research Repository/Robotics"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"i3liybW_B8BpGMwEKZSKia5HsHSIddSTU4pRCbV0hzE","pdfSize":"119116"}