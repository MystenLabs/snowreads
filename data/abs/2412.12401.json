{"id":"2412.12401","title":"Causally Consistent Normalizing Flow","authors":"Qingyang Zhou, Kangjie Lu and Meng Xu","authorsParsed":[["Zhou","Qingyang",""],["Lu","Kangjie",""],["Xu","Meng",""]],"versions":[{"version":"v1","created":"Mon, 16 Dec 2024 23:13:17 GMT"}],"updateDate":"2024-12-18","timestamp":1734390797000,"abstract":"  Causal inconsistency arises when the underlying causal graphs captured by\ngenerative models like \\textit{Normalizing Flows} (NFs) are inconsistent with\nthose specified in causal models like \\textit{Struct Causal Models} (SCMs).\nThis inconsistency can cause unwanted issues including the unfairness problem.\nPrior works to achieve causal consistency inevitably compromise the\nexpressiveness of their models by disallowing hidden layers. In this work, we\nintroduce a new approach: \\textbf{C}ausally \\textbf{C}onsistent\n\\textbf{N}ormalizing \\textbf{F}low (CCNF). To the best of our knowledge, CCNF\nis the first causally consistent generative model that can approximate any\ndistribution with multiple layers. CCNF relies on two novel constructs: a\nsequential representation of SCMs and partial causal transformations. These\nconstructs allow CCNF to inherently maintain causal consistency without\nsacrificing expressiveness. CCNF can handle all forms of causal inference\ntasks, including interventions and counterfactuals. Through experiments, we\nshow that CCNF outperforms current approaches in causal inference. We also\nempirically validate the practical utility of CCNF by applying it to real-world\ndatasets and show how CCNF addresses challenges like unfairness effectively.\n","subjects":["Computer Science/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"eXXXOKbOfB96cWH4UQH9xKN0Av96kURwndN1-7QXxcQ","pdfSize":"461447"}