{"id":"2407.15975","title":"Multilingual Fine-Grained News Headline Hallucination Detection","authors":"Jiaming Shen, Tianqi Liu, Jialu Liu, Zhen Qin, Jay Pavagadhi, Simon\n  Baumgartner, Michael Bendersky","authorsParsed":[["Shen","Jiaming",""],["Liu","Tianqi",""],["Liu","Jialu",""],["Qin","Zhen",""],["Pavagadhi","Jay",""],["Baumgartner","Simon",""],["Bendersky","Michael",""]],"versions":[{"version":"v1","created":"Mon, 22 Jul 2024 18:37:53 GMT"}],"updateDate":"2024-07-24","timestamp":1721673473000,"abstract":"  The popularity of automated news headline generation has surged with\nadvancements in pre-trained language models. However, these models often suffer\nfrom the ``hallucination'' problem, where the generated headline is not fully\nsupported by its source article. Efforts to address this issue have\npredominantly focused on English, using over-simplistic classification schemes\nthat overlook nuanced hallucination types. In this study, we introduce the\nfirst multilingual, fine-grained news headline hallucination detection dataset\nthat contains over 11 thousand pairs in 5 languages, each annotated with\ndetailed hallucination types by experts. We conduct extensive experiments on\nthis dataset under two settings. First, we implement several supervised\nfine-tuning approaches as preparatory solutions and demonstrate this dataset's\nchallenges and utilities. Second, we test various large language models'\nin-context learning abilities and propose two novel techniques,\nlanguage-dependent demonstration selection and coarse-to-fine prompting, to\nboost the few-shot hallucination detection performance in terms of the\nexample-F1 metric. We release this dataset to foster further research in\nmultilingual, fine-grained headline hallucination detection.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"0Ub3Zo9E9WJMDfDQ3rmWemhgyyifZuHCm8E1EL1brWU","pdfSize":"2753480"}