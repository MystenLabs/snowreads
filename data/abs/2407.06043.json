{"id":"2407.06043","title":"Test-time adaptation for geospatial point cloud semantic segmentation\n  with distinct domain shifts","authors":"Puzuo Wang, Wei Yao, Jie Shao, Zhiyi He","authorsParsed":[["Wang","Puzuo",""],["Yao","Wei",""],["Shao","Jie",""],["He","Zhiyi",""]],"versions":[{"version":"v1","created":"Mon, 8 Jul 2024 15:40:28 GMT"}],"updateDate":"2024-07-09","timestamp":1720453228000,"abstract":"  Domain adaptation (DA) techniques help deep learning models generalize across\ndata shifts for point cloud semantic segmentation (PCSS). Test-time adaptation\n(TTA) allows direct adaptation of a pre-trained model to unlabeled data during\ninference stage without access to source data or additional training, avoiding\nprivacy issues and large computational resources. We address TTA for geospatial\nPCSS by introducing three domain shift paradigms: photogrammetric to airborne\nLiDAR, airborne to mobile LiDAR, and synthetic to mobile laser scanning. We\npropose a TTA method that progressively updates batch normalization (BN)\nstatistics with each testing batch. Additionally, a self-supervised learning\nmodule optimizes learnable BN affine parameters. Information maximization and\nreliability-constrained pseudo-labeling improve prediction confidence and\nsupply supervisory signals. Experimental results show our method improves\nclassification accuracy by up to 20\\% mIoU, outperforming other methods. For\nphotogrammetric (SensatUrban) to airborne (Hessigheim 3D) adaptation at the\ninference stage, our method achieves 59.46\\% mIoU and 85.97\\% OA without\nretraining or fine-turning.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"EJSGUCtv8ZWjenxAd4qqQaP_P6FUd2_v0fsCWsjAmww","pdfSize":"7229924"}
