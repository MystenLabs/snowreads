{"id":"2407.18070","title":"CSWin-UNet: Transformer UNet with Cross-Shaped Windows for Medical Image\n  Segmentation","authors":"Xiao Liu, Peng Gao, Tao Yu, Fei Wang, Ru-Yue Yuan","authorsParsed":[["Liu","Xiao",""],["Gao","Peng",""],["Yu","Tao",""],["Wang","Fei",""],["Yuan","Ru-Yue",""]],"versions":[{"version":"v1","created":"Thu, 25 Jul 2024 14:25:17 GMT"},{"version":"v2","created":"Mon, 12 Aug 2024 09:15:04 GMT"},{"version":"v3","created":"Thu, 19 Sep 2024 14:14:35 GMT"}],"updateDate":"2024-09-20","timestamp":1721917517000,"abstract":"  Deep learning, especially convolutional neural networks (CNNs) and\nTransformer architectures, have become the focus of extensive research in\nmedical image segmentation, achieving impressive results. However, CNNs come\nwith inductive biases that limit their effectiveness in more complex, varied\nsegmentation scenarios. Conversely, while Transformer-based methods excel at\ncapturing global and long-range semantic details, they suffer from high\ncomputational demands. In this study, we propose CSWin-UNet, a novel U-shaped\nsegmentation method that incorporates the CSWin self-attention mechanism into\nthe UNet to facilitate horizontal and vertical stripes self-attention. This\nmethod significantly enhances both computational efficiency and receptive field\ninteractions. Additionally, our innovative decoder utilizes a content-aware\nreassembly operator that strategically reassembles features, guided by\npredicted kernels, for precise image resolution restoration. Our extensive\nempirical evaluations on diverse datasets, including synapse multi-organ CT,\ncardiac MRI, and skin lesions, demonstrate that CSWin-UNet maintains low model\ncomplexity while delivering high segmentation accuracy. Codes are available at\nhttps://github.com/eatbeanss/CSWin-UNet.\n","subjects":["Electrical Engineering and Systems Science/Image and Video Processing","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"z2DGLRw8-MaPHiyd9LdqDxzQ862PTk4AID6OaCY_fRw","pdfSize":"4820108"}