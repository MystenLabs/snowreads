{
  "id": "2412.18621",
  "title": "Investigating the Feasibility of Mitigating Potential Copyright\n  Infringement via Large Language Model Unlearning",
  "authors": "Guangyao Dou",
  "authorsParsed": [
    [
      "Dou",
      "Guangyao",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Mon, 16 Dec 2024 20:01:06 GMT"
    }
  ],
  "updateDate": "2025-02-12",
  "timestamp": 1734379266000,
  "abstract": "  Pre-trained Large Language Models (LLMs) have demonstrated remarkable\ncapabilities but also pose risks by learning and generating copyrighted\nmaterial, leading to significant legal and ethical concerns. In a potential\nreal-world scenario, model owners may need to continuously address copyright\ninfringement in order to address requests for content removal that emerge at\ndifferent time points. One potential way of addressing this is via sequential\nunlearning, where copyrighted content is removed sequentially as new requests\narise. Despite its practical relevance, sequential unlearning in the context of\ncopyright infringement has not been rigorously explored in existing literature.\nTo address this gap, we propose Stable Sequential Unlearning (SSU), a novel\nframework designed to unlearn copyrighted content from LLMs over multiple time\nsteps. Our approach works by identifying and removing specific weight updates\nin the model's parameters that correspond to copyrighted content using task\nvectors. We improve unlearning efficacy by introducing random labeling loss and\nensuring the model retains its general-purpose knowledge by adjusting targeted\nparameters with gradient-based weight saliency. Extensive experimental results\nshow that SSU sometimes achieves an effective trade-off between unlearning\nefficacy and general-purpose language abilities, outperforming existing\nbaselines, but it's not a cure-all for unlearning copyrighted material.\n",
  "subjects": [
    "Computer Science/Computation and Language"
  ],
  "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
  "blobId": "boVz5aAmWC9KxKVcXKXtTM1uSZUVnIWg8WJyBGtXCD8",
  "pdfSize": "8611740"
}