{"id":"2407.21441","title":"QuestGen: Effectiveness of Question Generation Methods for Fact-Checking\n  Applications","authors":"Ritvik Setty and Vinay Setty","authorsParsed":[["Setty","Ritvik",""],["Setty","Vinay",""]],"versions":[{"version":"v1","created":"Wed, 31 Jul 2024 08:44:29 GMT"},{"version":"v2","created":"Thu, 1 Aug 2024 10:35:57 GMT"}],"updateDate":"2024-08-02","timestamp":1722415469000,"abstract":"  Verifying fact-checking claims poses a significant challenge, even for\nhumans. Recent approaches have demonstrated that decomposing claims into\nrelevant questions to gather evidence enhances the efficiency of the\nfact-checking process. In this paper, we provide empirical evidence showing\nthat this question decomposition can be effectively automated. We demonstrate\nthat smaller generative models, fine-tuned for the question generation task\nusing data augmentation from various datasets, outperform large language models\nby up to 8%. Surprisingly, in some cases, the evidence retrieved using\nmachine-generated questions proves to be significantly more effective for\nfact-checking than that obtained from human-written questions. We also perform\nmanual evaluation of the decomposed questions to assess the quality of the\nquestions generated.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"-TrZ8sgyuOxrwPu_XzSEdro42G3cm8RXvWC0PDCWsGw","pdfSize":"539264"}