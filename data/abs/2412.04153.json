{"id":"2412.04153","title":"A Dynamic Safety Shield for Safe and Efficient Reinforcement Learning of\n  Navigation Tasks","authors":"Murad Dawood, Ahmed Shokry, Maren Bennewitz","authorsParsed":[["Dawood","Murad",""],["Shokry","Ahmed",""],["Bennewitz","Maren",""]],"versions":[{"version":"v1","created":"Thu, 5 Dec 2024 13:32:02 GMT"}],"updateDate":"2024-12-06","timestamp":1733405522000,"abstract":"  Reinforcement learning (RL) has been successfully applied to a variety of\nrobotics applications, where it outperforms classical methods. However, the\nsafety aspect of RL and the transfer to the real world remain an open\nchallenge. A prominent field for tackling this challenge and ensuring the\nsafety of the agents during training and execution is safe reinforcement\nlearning. Safe RL can be achieved through constrained RL and safe exploration\napproaches. The former learns the safety constraints over the course of\ntraining to achieve a safe behavior by the end of training, at the cost of high\nnumber of collisions at earlier stages of the training. The latter offers\nrobust safety by enforcing the safety constraints as hard constraints, which\nprevents collisions but hinders the exploration of the RL agent, resulting in\nlower rewards and poor performance. To overcome those drawbacks, we propose a\nnovel safety shield, that combines the robustness of the optimization-based\ncontrollers with the long prediction capabilities of the RL agents, allowing\nthe RL agent to adaptively tune the parameters of the controller. Our approach\nis able to improve the exploration of the RL agents for navigation tasks, while\nminimizing the number of collisions. Experiments in simulation show that our\napproach outperforms state-of-the-art baselines in the reached\ngoals-to-collisions ratio in different challenging environments. The\ngoals-to-collisions ratio metrics emphasizes the importance of minimizing the\nnumber of collisions, while learning to accomplish the task. Our approach\nachieves a higher number of reached goals compared to the classic safety\nshields and fewer collisions compared to constrained RL approaches. Finally, we\ndemonstrate the performance of the proposed method in a real-world experiment.\n","subjects":["Computer Science/Robotics","Mathematics/Optimization and Control"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"NzX_XWA7eIelNLlIum9zccbqjTuIgL0TRyGyQrOjvnc","pdfSize":"9022987"}