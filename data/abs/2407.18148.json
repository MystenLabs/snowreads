{"id":"2407.18148","title":"StraightLine: An End-to-End Resource-Aware Scheduler for Machine\n  Learning Application Requests","authors":"Cheng-Wei Ching, Boyuan Guan, Hailu Xu, Liting Hu","authorsParsed":[["Ching","Cheng-Wei",""],["Guan","Boyuan",""],["Xu","Hailu",""],["Hu","Liting",""]],"versions":[{"version":"v1","created":"Thu, 25 Jul 2024 15:58:56 GMT"},{"version":"v2","created":"Fri, 6 Sep 2024 00:02:52 GMT"}],"updateDate":"2024-09-09","timestamp":1721923136000,"abstract":"  The life cycle of machine learning (ML) applications consists of two stages:\nmodel development and model deployment. However, traditional ML systems (e.g.,\ntraining-specific or inference-specific systems) focus on one particular stage\nor phase of the life cycle of ML applications. These systems often aim at\noptimizing model training or accelerating model inference, and they frequently\nassume homogeneous infrastructure, which may not always reflect real-world\nscenarios that include cloud data centers, local servers, containers, and\nserverless platforms. We present StraightLine, an end-to-end resource-aware\nscheduler that schedules the optimal resources (e.g., container, virtual\nmachine, or serverless) for different ML application requests in a hybrid\ninfrastructure. The key innovation is an empirical dynamic placing algorithm\nthat intelligently places requests based on their unique characteristics (e.g.,\nrequest frequency, input data size, and data distribution). In contrast to\nexisting ML systems, StraightLine offers end-to-end resource-aware placement,\nthereby it can significantly reduce response time and failure rate for model\ndeployment when facing different computing resources in the hybrid\ninfrastructure.\n","subjects":["Computing Research Repository/Distributed, Parallel, and Cluster Computing","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"Bm4v1wAu6u47Sb6SA1rVpPVMx_SnCZKJQjcx6Y5i6D8","pdfSize":"1012783"}