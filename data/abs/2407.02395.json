{"id":"2407.02395","title":"Is Your AI-Generated Code Really Safe? Evaluating Large Language Models\n  on Secure Code Generation with CodeSecEval","authors":"Jiexin Wang, Xitong Luo, Liuwen Cao, Hongkui He, Hailin Huang, Jiayuan\n  Xie, Adam Jatowt, Yi Cai","authorsParsed":[["Wang","Jiexin",""],["Luo","Xitong",""],["Cao","Liuwen",""],["He","Hongkui",""],["Huang","Hailin",""],["Xie","Jiayuan",""],["Jatowt","Adam",""],["Cai","Yi",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 16:13:21 GMT"},{"version":"v2","created":"Thu, 4 Jul 2024 08:59:31 GMT"}],"updateDate":"2024-07-08","timestamp":1719936801000,"abstract":"  Large language models (LLMs) have brought significant advancements to code\ngeneration and code repair, benefiting both novice and experienced developers.\nHowever, their training using unsanitized data from open-source repositories,\nlike GitHub, raises the risk of inadvertently propagating security\nvulnerabilities. Despite numerous studies investigating the safety of code\nLLMs, there remains a gap in comprehensively addressing their security\nfeatures. In this work, we aim to present a comprehensive study aimed at\nprecisely evaluating and enhancing the security aspects of code LLMs. To\nsupport our research, we introduce CodeSecEval, a meticulously curated dataset\ndesigned to address 44 critical vulnerability types with 180 distinct samples.\nCodeSecEval serves as the foundation for the automatic evaluation of code\nmodels in two crucial tasks: code generation and code repair, with a strong\nemphasis on security. Our experimental results reveal that current models\nfrequently overlook security issues during both code generation and repair\nprocesses, resulting in the creation of vulnerable code. In response, we\npropose different strategies that leverage vulnerability-aware information and\ninsecure code explanations to mitigate these security vulnerabilities.\nFurthermore, our findings highlight that certain vulnerability types\nparticularly challenge model performance, influencing their effectiveness in\nreal-world applications. Based on these findings, we believe our study will\nhave a positive impact on the software engineering community, inspiring the\ndevelopment of improved methods for training and utilizing LLMs, thereby\nleading to safer and more trustworthy model deployment.\n","subjects":["Computing Research Repository/Software Engineering","Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"zrgQdqIUcb3V5EZOq_28YTgs4y5JQ1GgcSWo6iGSkA0","pdfSize":"1556313"}