{"id":"2412.10683","title":"Adaptive Nonparametric Perturbations of Parametric Bayesian Models","authors":"Bohan Wu, Eli N. Weinstein, Sohrab Salehi, Yixin Wang, David M. Blei","authorsParsed":[["Wu","Bohan",""],["Weinstein","Eli N.",""],["Salehi","Sohrab",""],["Wang","Yixin",""],["Blei","David M.",""]],"versions":[{"version":"v1","created":"Sat, 14 Dec 2024 05:06:38 GMT"},{"version":"v2","created":"Tue, 17 Dec 2024 18:24:35 GMT"}],"updateDate":"2024-12-19","timestamp":1734152798000,"abstract":"  Parametric Bayesian modeling offers a powerful and flexible toolbox for\nscientific data analysis. Yet the model, however detailed, may still be wrong,\nand this can make inferences untrustworthy. In this paper we study\nnonparametrically perturbed parametric (NPP) Bayesian models, in which a\nparametric Bayesian model is relaxed via a distortion of its likelihood. We\nanalyze the properties of NPP models when the target of inference is the true\ndata distribution or some functional of it, such as in causal inference. We\nshow that NPP models can offer the robustness of nonparametric models while\nretaining the data efficiency of parametric models, achieving fast convergence\nwhen the parametric model is close to true. To efficiently analyze data with an\nNPP model, we develop a generalized Bayes procedure to approximate its\nposterior. We demonstrate our method by estimating causal effects of gene\nexpression from single cell RNA sequencing data. NPP modeling offers an\nefficient approach to robust Bayesian inference and can be used to robustify\nany parametric Bayesian model.\n","subjects":["Statistics/Methodology","Statistics/Machine Learning"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"u7gKHbGhwpTYeKbCf8VRzdiOdF6nQp8-2t_G5aAOQs4","pdfSize":"2102073"}