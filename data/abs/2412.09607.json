{"id":"2412.09607","title":"Spectral Image Tokenizer","authors":"Carlos Esteves, Mohammed Suhail, Ameesh Makadia","authorsParsed":[["Esteves","Carlos",""],["Suhail","Mohammed",""],["Makadia","Ameesh",""]],"versions":[{"version":"v1","created":"Thu, 12 Dec 2024 18:59:31 GMT"}],"updateDate":"2024-12-13","timestamp":1734029971000,"abstract":"  Image tokenizers map images to sequences of discrete tokens, and are a\ncrucial component of autoregressive transformer-based image generation. The\ntokens are typically associated with spatial locations in the input image,\narranged in raster scan order, which is not ideal for autoregressive modeling.\nIn this paper, we propose to tokenize the image spectrum instead, obtained from\na discrete wavelet transform (DWT), such that the sequence of tokens represents\nthe image in a coarse-to-fine fashion. Our tokenizer brings several advantages:\n1) it leverages that natural images are more compressible at high frequencies,\n2) it can take and reconstruct images of different resolutions without\nretraining, 3) it improves the conditioning for next-token prediction --\ninstead of conditioning on a partial line-by-line reconstruction of the image,\nit takes a coarse reconstruction of the full image, 4) it enables partial\ndecoding where the first few generated tokens can reconstruct a coarse version\nof the image, 5) it enables autoregressive models to be used for image\nupsampling. We evaluate the tokenizer reconstruction metrics as well as\nmultiscale image generation, text-guided image upsampling and editing.\n","subjects":["Computer Science/Computer Vision and Pattern Recognition","Computer Science/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"SQ3gBaaUGQTm57EKgpB-tW4LWVQAs3lJETfxmzR7zXg","pdfSize":"15854803"}