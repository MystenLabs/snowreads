{"id":"2407.14043","title":"Kinematics-based 3D Human-Object Interaction Reconstruction from Single\n  View","authors":"Yuhang Chen, Chenxing Wang","authorsParsed":[["Chen","Yuhang",""],["Wang","Chenxing",""]],"versions":[{"version":"v1","created":"Fri, 19 Jul 2024 05:44:35 GMT"}],"updateDate":"2024-07-22","timestamp":1721367875000,"abstract":"  Reconstructing 3D human-object interaction (HOI) from single-view RGB images\nis challenging due to the absence of depth information and potential\nocclusions. Existing methods simply predict the body poses merely rely on\nnetwork training on some indoor datasets, which cannot guarantee the\nrationality of the results if some body parts are invisible due to occlusions\nthat appear easily. Inspired by the end-effector localization task in robotics,\nwe propose a kinematics-based method that can drive the joints of human body to\nthe human-object contact regions accurately. After an improved forward\nkinematics algorithm is proposed, the Multi-Layer Perceptron is introduced into\nthe solution of inverse kinematics process to determine the poses of joints,\nwhich achieves precise results than the commonly-used numerical methods in\nrobotics. Besides, a Contact Region Recognition Network (CRRNet) is also\nproposed to robustly determine the contact regions using a single-view video.\nExperimental results demonstrate that our method outperforms the\nstate-of-the-art on benchmark BEHAVE. Additionally, our approach shows good\nportability and can be seamlessly integrated into other methods for\noptimizations.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"eUhcdQwJP-bIrxRILY9_g5twhn96GcPmV9eTX3kp1Aw","pdfSize":"30574664","objectId":"0xbdc37dac1b1c30be2fdd03d4b6bf068e04c471d60cfcd95b4842349d1a1943ff","registeredEpoch":"3","certifiedEpoch":"3","startEpoch":"3","endEpoch":"203"}
