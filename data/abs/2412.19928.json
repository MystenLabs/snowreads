{
  "id": "2412.19928",
  "title": "Assessing Text Classification Methods for Cyberbullying Detection on\n  Social Media Platforms",
  "authors": "Adamu Gaston Philipo, Doreen Sebastian Sarwatt, Jianguo Ding, Mahmoud\n  Daneshmand, Huansheng Ning",
  "authorsParsed": [
    [
      "Philipo",
      "Adamu Gaston",
      ""
    ],
    [
      "Sarwatt",
      "Doreen Sebastian",
      ""
    ],
    [
      "Ding",
      "Jianguo",
      ""
    ],
    [
      "Daneshmand",
      "Mahmoud",
      ""
    ],
    [
      "Ning",
      "Huansheng",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Fri, 27 Dec 2024 21:22:28 GMT"
    }
  ],
  "updateDate": "2024-12-31",
  "timestamp": 1735334548000,
  "abstract": "  Cyberbullying significantly contributes to mental health issues in\ncommunities by negatively impacting the psychology of victims. It is a\nprevalent problem on social media platforms, necessitating effective, real-time\ndetection and monitoring systems to identify harmful messages. However, current\ncyberbullying detection systems face challenges related to performance, dataset\nquality, time efficiency, and computational costs. This research aims to\nconduct a comparative study by adapting and evaluating existing text\nclassification techniques within the cyberbullying detection domain. The study\nspecifically evaluates the effectiveness and performance of these techniques in\nidentifying cyberbullying instances on social media platforms. It focuses on\nleveraging and assessing large language models, including BERT, RoBERTa, XLNet,\nDistilBERT, and GPT-2.0, for their suitability in this domain. The results show\nthat BERT strikes a balance between performance, time efficiency, and\ncomputational resources: Accuracy of 95%, Precision of 95%, Recall of 95%, F1\nScore of 95%, Error Rate of 5%, Inference Time of 0.053 seconds, RAM Usage of\n35.28 MB, CPU/GPU Usage of 0.4%, and Energy Consumption of 0.000263 kWh. The\nfindings demonstrate that generative AI models, while powerful, do not\nconsistently outperform fine-tuned models on the tested benchmarks. However,\nstate-of-the-art performance can still be achieved through strategic adaptation\nand fine-tuning of existing models for specific datasets and tasks.\n",
  "subjects": [
    "Computer Science/Computation and Language",
    "Computer Science/Social and Information Networks"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "uZeQTCpbsaY99pjMFnWItEqPOzXQmgDuzFthK8iSbnc",
  "pdfSize": "1162552"
}