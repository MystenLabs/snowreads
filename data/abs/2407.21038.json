{"id":"2407.21038","title":"Advancing Chart Question Answering with Robust Chart Component\n  Recognition","authors":"Hanwen Zheng, Sijia Wang, Chris Thomas, Lifu Huang","authorsParsed":[["Zheng","Hanwen",""],["Wang","Sijia",""],["Thomas","Chris",""],["Huang","Lifu",""]],"versions":[{"version":"v1","created":"Fri, 19 Jul 2024 20:55:06 GMT"}],"updateDate":"2024-08-01","timestamp":1721422506000,"abstract":"  Chart comprehension presents significant challenges for machine learning\nmodels due to the diverse and intricate shapes of charts. Existing multimodal\nmethods often overlook these visual features or fail to integrate them\neffectively for chart question answering (ChartQA). To address this, we\nintroduce Chartformer, a unified framework that enhances chart component\nrecognition by accurately identifying and classifying components such as bars,\nlines, pies, titles, legends, and axes. Additionally, we propose a novel\nQuestion-guided Deformable Co-Attention (QDCAt) mechanism, which fuses chart\nfeatures encoded by Chartformer with the given question, leveraging the\nquestion's guidance to ground the correct answer. Extensive experiments\ndemonstrate that the proposed approaches significantly outperform baseline\nmodels in chart component recognition and ChartQA tasks, achieving improvements\nof 3.2% in mAP and 15.4% in accuracy, respectively. These results underscore\nthe robustness of our solution for detailed visual data interpretation across\nvarious applications.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Information Retrieval"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"YrwuK3hAymSD7AQTYbW6hFxstfBWavDBd0KUVjbQuO8","pdfSize":"4308122","objectId":"0x4a95099d1dbebb340f9a4992f645274df06cf7975195d2a2c08e55c9d565b0f1","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
