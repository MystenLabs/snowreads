{"id":"2407.04651","title":"SAM Fewshot Finetuning for Anatomical Segmentation in Medical Images","authors":"Weiyi Xie, Nathalie Willems, Shubham Patil, Yang Li and Mayank Kumar","authorsParsed":[["Xie","Weiyi",""],["Willems","Nathalie",""],["Patil","Shubham",""],["Li","Yang",""],["Kumar","Mayank",""]],"versions":[{"version":"v1","created":"Fri, 5 Jul 2024 17:07:25 GMT"}],"updateDate":"2024-07-08","timestamp":1720199245000,"abstract":"  We propose a straightforward yet highly effective few-shot fine-tuning\nstrategy for adapting the Segment Anything (SAM) to anatomical segmentation\ntasks in medical images. Our novel approach revolves around reformulating the\nmask decoder within SAM, leveraging few-shot embeddings derived from a limited\nset of labeled images (few-shot collection) as prompts for querying anatomical\nobjects captured in image embeddings. This innovative reformulation greatly\nreduces the need for time-consuming online user interactions for labeling\nvolumetric images, such as exhaustively marking points and bounding boxes to\nprovide prompts slice by slice. With our method, users can manually segment a\nfew 2D slices offline, and the embeddings of these annotated image regions\nserve as effective prompts for online segmentation tasks. Our method\nprioritizes the efficiency of the fine-tuning process by exclusively training\nthe mask decoder through caching mechanisms while keeping the image encoder\nfrozen. Importantly, this approach is not limited to volumetric medical images,\nbut can generically be applied to any 2D/3D segmentation task. To thoroughly\nevaluate our method, we conducted extensive validation on four datasets,\ncovering six anatomical segmentation tasks across two modalities. Furthermore,\nwe conducted a comparative analysis of different prompting options within SAM\nand the fully-supervised nnU-Net. The results demonstrate the superior\nperformance of our method compared to SAM employing only point prompts\n(approximately 50% improvement in IoU) and performs on-par with fully\nsupervised methods whilst reducing the requirement of labeled data by at least\nan order of magnitude.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"EJo_-LSoWUrPagjsUaxJThrtbv3zHtIAfCrO_n4j9Vs","pdfSize":"3684243"}
