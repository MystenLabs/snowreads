{"id":"2407.05982","title":"MTL-Split: Multi-Task Learning for Edge Devices using Split Computing","authors":"Luigi Capogrosso, Enrico Fraccaroli, Samarjit Chakraborty, Franco\n  Fummi, Marco Cristani","authorsParsed":[["Capogrosso","Luigi",""],["Fraccaroli","Enrico",""],["Chakraborty","Samarjit",""],["Fummi","Franco",""],["Cristani","Marco",""]],"versions":[{"version":"v1","created":"Mon, 8 Jul 2024 14:25:39 GMT"}],"updateDate":"2024-07-09","timestamp":1720448739000,"abstract":"  Split Computing (SC), where a Deep Neural Network (DNN) is intelligently\nsplit with a part of it deployed on an edge device and the rest on a remote\nserver is emerging as a promising approach. It allows the power of DNNs to be\nleveraged for latency-sensitive applications that do not allow the entire DNN\nto be deployed remotely, while not having sufficient computation bandwidth\navailable locally. In many such embedded systems scenarios, such as those in\nthe automotive domain, computational resource constraints also necessitate\nMulti-Task Learning (MTL), where the same DNN is used for multiple inference\ntasks instead of having dedicated DNNs for each task, which would need more\ncomputing bandwidth. However, how to partition such a multi-tasking DNN to be\ndeployed within a SC framework has not been sufficiently studied. This paper\nstudies this problem, and MTL-Split, our novel proposed architecture, shows\nencouraging results on both synthetic and real-world data. The source code is\navailable at https://github.com/intelligolabs/MTL-Split.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Distributed, Parallel, and Cluster Computing"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"T5FkNtk8E11xtuwhUkzz2eI9FuZyen441PNZIcHmkDI","pdfSize":"568620"}
