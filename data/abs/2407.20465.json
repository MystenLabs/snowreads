{"id":"2407.20465","title":"A flexible framework for accurate LiDAR odometry, map manipulation, and\n  localization","authors":"Jos\\'e Luis Blanco-Claraco","authorsParsed":[["Blanco-Claraco","Jos√© Luis",""]],"versions":[{"version":"v1","created":"Mon, 29 Jul 2024 23:47:09 GMT"}],"updateDate":"2024-07-31","timestamp":1722296829000,"abstract":"  LiDAR-based SLAM is a core technology for autonomous vehicles and robots.\nDespite the intense research activity in this field, each proposed system uses\na particular sensor post-processing pipeline and a single map representation\nformat. The present work aims at introducing a revolutionary point of view for\n3D LiDAR SLAM and localization: (1) using view-based maps as the fundamental\nrepresentation of maps (\"simple-maps\"), which can then be used to generate\narbitrary metric maps optimized for particular tasks; and (2) by introducing a\nnew framework in which mapping pipelines can be defined without coding,\ndefining the connections of a network of reusable blocks much like\ndeep-learning networks are designed by connecting layers of standardized\nelements. Moreover, the idea of including the current linear and angular\nvelocity vectors as variables to be optimized within the ICP loop is also\nintroduced, leading to superior robustness against aggressive motion profiles\nwithout an IMU. The presented open-source ecosystem, released to ROS 2,\nincludes tools and prebuilt pipelines covering all the way from data\nacquisition to map editing and visualization, real-time localization,\nloop-closure detection, or map georeferencing from consumer-grade GNSS\nreceivers. Extensive experimental validation reveals that the proposal compares\nwell to, or improves, former state-of-the-art (SOTA) LiDAR odometry systems,\nwhile also successfully mapping some hard sequences where others diverge. A\nproposed self-adaptive configuration has been used, without parameter changes,\nfor all 3D LiDAR datasets with sensors between 16 and 128 rings, extensively\ntested on 83 sequences over more than 250~km of automotive, hand-held,\nairborne, and quadruped LiDAR datasets, both indoors and outdoors. The\nopen-sourced implementation is available online at\nhttps://github.com/MOLAorg/mola\n","subjects":["Computing Research Repository/Robotics"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"L6spKFtg46YCmNm0Laqh7qKU7uygIGXBGGMqCXdFFSE","pdfSize":"11720570","objectId":"0x7d7fa5aa18e3614ce8c014553e05fe39d964707f88fc78dcd097002513aae064","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
