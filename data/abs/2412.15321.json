{
  "id": "2412.15321",
  "title": "Next Patch Prediction for Autoregressive Visual Generation",
  "authors": "Yatian Pang, Peng Jin, Shuo Yang, Bin Lin, Bin Zhu, Zhenyu Tang,\n  Liuhan Chen, Francis E. H. Tay, Ser-Nam Lim, Harry Yang, Li Yuan",
  "authorsParsed": [
    [
      "Pang",
      "Yatian",
      ""
    ],
    [
      "Jin",
      "Peng",
      ""
    ],
    [
      "Yang",
      "Shuo",
      ""
    ],
    [
      "Lin",
      "Bin",
      ""
    ],
    [
      "Zhu",
      "Bin",
      ""
    ],
    [
      "Tang",
      "Zhenyu",
      ""
    ],
    [
      "Chen",
      "Liuhan",
      ""
    ],
    [
      "Tay",
      "Francis E. H.",
      ""
    ],
    [
      "Lim",
      "Ser-Nam",
      ""
    ],
    [
      "Yang",
      "Harry",
      ""
    ],
    [
      "Yuan",
      "Li",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Thu, 19 Dec 2024 18:59:36 GMT"
    },
    {
      "version": "v2",
      "created": "Thu, 2 Jan 2025 12:14:43 GMT"
    }
  ],
  "updateDate": "2025-01-03",
  "timestamp": 1734634776000,
  "abstract": "  Autoregressive models, built based on the Next Token Prediction (NTP)\nparadigm, show great potential in developing a unified framework that\nintegrates both language and vision tasks. In this work, we rethink the NTP for\nautoregressive image generation and propose a novel Next Patch Prediction (NPP)\nparadigm. Our key idea is to group and aggregate image tokens into patch tokens\ncontaining high information density. With patch tokens as a shorter input\nsequence, the autoregressive model is trained to predict the next patch,\nthereby significantly reducing the computational cost. We further propose a\nmulti-scale coarse-to-fine patch grouping strategy that exploits the natural\nhierarchical property of image data. Experiments on a diverse range of models\n(100M-1.4B parameters) demonstrate that the next patch prediction paradigm\ncould reduce the training cost to around 0.6 times while improving image\ngeneration quality by up to 1.0 FID score on the ImageNet benchmark. We\nhighlight that our method retains the original autoregressive model\narchitecture without introducing additional trainable parameters or\nspecifically designing a custom image tokenizer, thus ensuring flexibility and\nseamless adaptation to various autoregressive models for visual generation.\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "3_EkTFTmhYyShXeU-2jHPXKFwNDMu-FC3SD_IHzjZMQ",
  "pdfSize": "7133668"
}