{"id":"2412.07274","title":"A Generative Victim Model for Segmentation","authors":"Aixuan Li, Jing Zhang, Jiawei Shi, Yiran Zhong, Yuchao Dai","authorsParsed":[["Li","Aixuan",""],["Zhang","Jing",""],["Shi","Jiawei",""],["Zhong","Yiran",""],["Dai","Yuchao",""]],"versions":[{"version":"v1","created":"Tue, 10 Dec 2024 08:02:27 GMT"}],"updateDate":"2024-12-11","timestamp":1733817747000,"abstract":"  We find that the well-trained victim models (VMs), against which the attacks\nare generated, serve as fundamental prerequisites for adversarial attacks, i.e.\na segmentation VM is needed to generate attacks for segmentation. In this\ncontext, the victim model is assumed to be robust to achieve effective\nadversarial perturbation generation. Instead of focusing on improving the\nrobustness of the task-specific victim models, we shift our attention to image\ngeneration. From an image generation perspective, we derive a novel VM for\nsegmentation, aiming to generate adversarial perturbations for segmentation\ntasks without requiring models explicitly designed for image segmentation. Our\napproach to adversarial attack generation diverges from conventional white-box\nor black-box attacks, offering a fresh outlook on adversarial attack\nstrategies. Experiments show that our attack method is able to generate\neffective adversarial attacks with good transferability.\n","subjects":["Computer Science/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"jEn2q-45vzZbqKMGgp0s4pSVlkWOSyR0WlSl9J0QQq4","pdfSize":"14172190"}