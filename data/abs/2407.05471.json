{"id":"2407.05471","title":"Fine-Grained and Interpretable Neural Speech Editing","authors":"Max Morrison, Cameron Churchwell, Nathan Pruyne, Bryan Pardo","authorsParsed":[["Morrison","Max",""],["Churchwell","Cameron",""],["Pruyne","Nathan",""],["Pardo","Bryan",""]],"versions":[{"version":"v1","created":"Sun, 7 Jul 2024 19:05:52 GMT"}],"updateDate":"2024-07-09","timestamp":1720379152000,"abstract":"  Fine-grained editing of speech attributes$\\unicode{x2014}$such as prosody\n(i.e., the pitch, loudness, and phoneme durations), pronunciation, speaker\nidentity, and formants$\\unicode{x2014}$is useful for fine-tuning and fixing\nimperfections in human and AI-generated speech recordings for creation of\npodcasts, film dialogue, and video game dialogue. Existing speech synthesis\nsystems use representations that entangle two or more of these attributes,\nprohibiting their use in fine-grained, disentangled editing. In this paper, we\ndemonstrate the first disentangled and interpretable representation of speech\nwith comparable subjective and objective vocoding reconstruction accuracy to\nMel spectrograms. Our interpretable representation, combined with our proposed\ndata augmentation method, enables training an existing neural vocoder to\nperform fast, accurate, and high-quality editing of pitch, duration, volume,\ntimbral correlates of volume, pronunciation, speaker identity, and spectral\nbalance.\n","subjects":["Electrical Engineering and Systems Science/Audio and Speech Processing","Computing Research Repository/Sound"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"WYXPTcoQVUA9myQRn5m2VmezNUr8GaQEWSPSDWJVpFA","pdfSize":"262591"}