{
  "id": "2412.03017",
  "title": "Pixel-level and Semantic-level Adjustable Super-resolution: A Dual-LoRA\n  Approach",
  "authors": "Lingchen Sun, Rongyuan Wu, Zhiyuan Ma, Shuaizheng Liu, Qiaosi Yi, Lei\n  Zhang",
  "authorsParsed": [
    [
      "Sun",
      "Lingchen",
      ""
    ],
    [
      "Wu",
      "Rongyuan",
      ""
    ],
    [
      "Ma",
      "Zhiyuan",
      ""
    ],
    [
      "Liu",
      "Shuaizheng",
      ""
    ],
    [
      "Yi",
      "Qiaosi",
      ""
    ],
    [
      "Zhang",
      "Lei",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Wed, 4 Dec 2024 04:07:49 GMT"
    }
  ],
  "updateDate": "2024-12-05",
  "timestamp": 1733285269000,
  "abstract": "  Diffusion prior-based methods have shown impressive results in real-world\nimage super-resolution (SR). However, most existing methods entangle\npixel-level and semantic-level SR objectives in the training process,\nstruggling to balance pixel-wise fidelity and perceptual quality. Meanwhile,\nusers have varying preferences on SR results, thus it is demanded to develop an\nadjustable SR model that can be tailored to different fidelity-perception\npreferences during inference without re-training. We present Pixel-level and\nSemantic-level Adjustable SR (PiSA-SR), which learns two LoRA modules upon the\npre-trained stable-diffusion (SD) model to achieve improved and adjustable SR\nresults. We first formulate the SD-based SR problem as learning the residual\nbetween the low-quality input and the high-quality output, then show that the\nlearning objective can be decoupled into two distinct LoRA weight spaces: one\nis characterized by the $\\ell_2$-loss for pixel-level regression, and another\nis characterized by the LPIPS and classifier score distillation losses to\nextract semantic information from pre-trained classification and SD models. In\nits default setting, PiSA-SR can be performed in a single diffusion step,\nachieving leading real-world SR results in both quality and efficiency. By\nintroducing two adjustable guidance scales on the two LoRA modules to control\nthe strengths of pixel-wise fidelity and semantic-level details during\ninference, PiSASR can offer flexible SR results according to user preference\nwithout re-training. Codes and models can be found at\nhttps://github.com/csslc/PiSA-SR.\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "4BCxN9K1pGQWXdK31Li_EUl6zHNQK9bOxHE03IP9GTs",
  "pdfSize": "41796022"
}