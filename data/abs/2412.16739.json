{
  "id": "2412.16739",
  "title": "UNEM: UNrolled Generalized EM for Transductive Few-Shot Learning",
  "authors": "Long Zhou, Fereshteh Shakeri, Aymen Sadraoui, Mounir Kaaniche,\n  Jean-Christophe Pesquet, Ismail Ben Ayed",
  "authorsParsed": [
    [
      "Zhou",
      "Long",
      ""
    ],
    [
      "Shakeri",
      "Fereshteh",
      ""
    ],
    [
      "Sadraoui",
      "Aymen",
      ""
    ],
    [
      "Kaaniche",
      "Mounir",
      ""
    ],
    [
      "Pesquet",
      "Jean-Christophe",
      ""
    ],
    [
      "Ayed",
      "Ismail Ben",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Sat, 21 Dec 2024 19:01:57 GMT"
    }
  ],
  "updateDate": "2024-12-24",
  "timestamp": 1734807717000,
  "abstract": "  Transductive few-shot learning has recently triggered wide attention in\ncomputer vision. Yet, current methods introduce key hyper-parameters, which\ncontrol the prediction statistics of the test batches, such as the level of\nclass balance, affecting performances significantly. Such hyper-parameters are\nempirically grid-searched over validation data, and their configurations may\nvary substantially with the target dataset and pre-training model, making such\nempirical searches both sub-optimal and computationally intractable. In this\nwork, we advocate and introduce the unrolling paradigm, also referred to as\n\"learning to optimize\", in the context of few-shot learning, thereby learning\nefficiently and effectively a set of optimized hyper-parameters. Specifically,\nwe unroll a generalization of the ubiquitous Expectation-Maximization (EM)\noptimizer into a neural network architecture, mapping each of its iterates to a\nlayer and learning a set of key hyper-parameters over validation data. Our\nunrolling approach covers various statistical feature distributions and\npre-training paradigms, including recent foundational vision-language models\nand standard vision-only classifiers. We report comprehensive experiments,\nwhich cover a breadth of fine-grained downstream image classification tasks,\nshowing significant gains brought by the proposed unrolled EM algorithm over\niterative variants. The achieved improvements reach up to 10% and 7.5% on\nvision-only and vision-language benchmarks, respectively.\n",
  "subjects": [
    "Computer Science/Computer Vision and Pattern Recognition"
  ],
  "license": "http://creativecommons.org/licenses/by-sa/4.0/",
  "blobId": "I0IZR0-fBR1zjrRdEjsrepQNYD14cfclwxLvOV_FKIc",
  "pdfSize": "4822162"
}