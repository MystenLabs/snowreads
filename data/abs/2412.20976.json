{
  "id": "2412.20976",
  "title": "Hierarchical Pose Estimation and Mapping with Multi-Scale Neural Feature\n  Fields",
  "authors": "Evgenii Kruzhkov, Alena Savinykh, Sven Behnke",
  "authorsParsed": [
    [
      "Kruzhkov",
      "Evgenii",
      ""
    ],
    [
      "Savinykh",
      "Alena",
      ""
    ],
    [
      "Behnke",
      "Sven",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Mon, 30 Dec 2024 14:29:26 GMT"
    }
  ],
  "updateDate": "2024-12-31",
  "timestamp": 1735568966000,
  "abstract": "  Robotic applications require a comprehensive understanding of the scene. In\nrecent years, neural fields-based approaches that parameterize the entire\nenvironment have become popular. These approaches are promising due to their\ncontinuous nature and their ability to learn scene priors. However, the use of\nneural fields in robotics becomes challenging when dealing with unknown sensor\nposes and sequential measurements. This paper focuses on the problem of sensor\npose estimation for large-scale neural implicit SLAM. We investigate implicit\nmapping from a probabilistic perspective and propose hierarchical pose\nestimation with a corresponding neural network architecture. Our method is\nwell-suited for large-scale implicit map representations. The proposed approach\noperates on consecutive outdoor LiDAR scans and achieves accurate pose\nestimation, while maintaining stable mapping quality for both short and long\ntrajectories. We built our method on a structured and sparse implicit\nrepresentation suitable for large-scale reconstruction and evaluated it using\nthe KITTI and MaiCity datasets. Our approach outperforms the baseline in terms\nof mapping with unknown poses and achieves state-of-the-art localization\naccuracy.\n",
  "subjects": [
    "Computer Science/Robotics"
  ],
  "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
  "blobId": "1XGbVu-97fpUpJK8zenveQhavLNSxIXC6CVbMPcJpYk",
  "pdfSize": "2620417"
}