{"id":"2412.07619","title":"DRUM: Learning Demonstration Retriever for Large MUlti-modal Models","authors":"Ellen Yi-Ge, Jiechao Gao, Wei Han, Wei Zhu","authorsParsed":[["Yi-Ge","Ellen",""],["Gao","Jiechao",""],["Han","Wei",""],["Zhu","Wei",""]],"versions":[{"version":"v1","created":"Tue, 10 Dec 2024 15:56:12 GMT"}],"updateDate":"2024-12-11","timestamp":1733846172000,"abstract":"  Recently, large language models (LLMs) have demonstrated impressive\ncapabilities in dealing with new tasks with the help of in-context learning\n(ICL). In the study of Large Vision-Language Models (LVLMs), when implementing\nICL, researchers usually adopts the naive strategies like fixed demonstrations\nacross different samples, or selecting demonstrations directly via a\nvisual-language embedding model. These methods does not guarantee the\nconfigured demonstrations fit the need of the LVLMs. To address this issue, we\nnow propose a novel framework, \\underline{d}emonstration \\underline{r}etriever\nfor large m\\underline{u}lti-modal \\underline{m}odel (DRUM), which fine-tunes\nthe visual-language embedding model to better meet the LVLM's needs. First, we\ndiscuss the retrieval strategies for a visual-language task, assuming an\nembedding model is given. And we propose to concate the image and text\nembeddings to enhance the retrieval performance. Second, we propose to re-rank\nthe demonstrations retrieved by the embedding model via the LVLM's feedbacks,\nand calculate a list-wise ranking loss for training the embedding model. Third,\nwe propose an iterative demonstration mining strategy to improve the training\nof the embedding model. Through extensive experiments on 3 types of\nvisual-language tasks, 7 benchmark datasets, our DRUM framework is proven to be\neffective in boosting the LVLM's in-context learning performance via retrieving\nmore proper demonstrations.\n","subjects":["Computer Science/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"afdxiAcMUydLLnfHoxBaQpjKVu3eBGXf1Q4REc957VY","pdfSize":"1632214"}