{"id":"2407.00927","title":"Learnability of Parameter-Bounded Bayes Nets","authors":"Arnab Bhattacharyya, Davin Choo, Sutanu Gayen, Dimitrios Myrisiotis","authorsParsed":[["Bhattacharyya","Arnab",""],["Choo","Davin",""],["Gayen","Sutanu",""],["Myrisiotis","Dimitrios",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 03:17:34 GMT"},{"version":"v2","created":"Sun, 4 Aug 2024 18:04:50 GMT"}],"updateDate":"2024-08-06","timestamp":1719803854000,"abstract":"  Bayes nets are extensively used in practice to efficiently represent joint\nprobability distributions over a set of random variables and capture dependency\nrelations. In a seminal paper, Chickering et al. (JMLR 2004) showed that given\na distribution $\\mathbb{P}$, that is defined as the marginal distribution of a\nBayes net, it is $\\mathsf{NP}$-hard to decide whether there is a\nparameter-bounded Bayes net that represents $\\mathbb{P}$. They called this\nproblem LEARN. In this work, we extend the $\\mathsf{NP}$-hardness result of\nLEARN and prove the $\\mathsf{NP}$-hardness of a promise search variant of\nLEARN, whereby the Bayes net in question is guaranteed to exist and one is\nasked to find such a Bayes net. We complement our hardness result with a\npositive result about the sample complexity that is sufficient to recover a\nparameter-bounded Bayes net that is close (in TV distance) to a given\ndistribution $\\mathbb{P}$, that is represented by some parameter-bounded Bayes\nnet, generalizing a degree-bounded sample complexity result of Brustle et al.\n(EC 2020).\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Computational Complexity","Statistics/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"lhSjEIYdsrgf9SGYM3GXDKBAEcs6o7_QbJ6CMF6rQO0","pdfSize":"224574"}