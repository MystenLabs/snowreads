{
  "id": "2412.08194",
  "title": "Magneto: Combining Small and Large Language Models for Schema Matching",
  "authors": "Yurong Liu, Eduardo Pena, Aecio Santos, Eden Wu, Juliana Freire",
  "authorsParsed": [
    [
      "Liu",
      "Yurong",
      ""
    ],
    [
      "Pena",
      "Eduardo",
      ""
    ],
    [
      "Santos",
      "Aecio",
      ""
    ],
    [
      "Wu",
      "Eden",
      ""
    ],
    [
      "Freire",
      "Juliana",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Wed, 11 Dec 2024 08:35:56 GMT"
    }
  ],
  "updateDate": "2024-12-12",
  "timestamp": 1733906156000,
  "abstract": "  Recent advances in language models opened new opportunities to address\ncomplex schema matching tasks. Schema matching approaches have been proposed\nthat demonstrate the usefulness of language models, but they have also\nuncovered important limitations: Small language models (SLMs) require training\ndata (which can be both expensive and challenging to obtain), and large\nlanguage models (LLMs) often incur high computational costs and must deal with\nconstraints imposed by context windows. We present Magneto, a cost-effective\nand accurate solution for schema matching that combines the advantages of SLMs\nand LLMs to address their limitations. By structuring the schema matching\npipeline in two phases, retrieval and reranking, Magneto can use\ncomputationally efficient SLM-based strategies to derive candidate matches\nwhich can then be reranked by LLMs, thus making it possible to reduce runtime\nwithout compromising matching accuracy. We propose a self-supervised approach\nto fine-tune SLMs which uses LLMs to generate syntactically diverse training\ndata, and prompting strategies that are effective for reranking. We also\nintroduce a new benchmark, developed in collaboration with domain experts,\nwhich includes real biomedical datasets and presents new challenges to schema\nmatching methods. Through a detailed experimental evaluation, using both our\nnew and existing benchmarks, we show that Magneto is scalable and attains high\naccuracy for datasets from different domains.\n",
  "subjects": [
    "Computer Science/Databases",
    "Computer Science/Machine Learning"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "ovyx0AWeXYUWUko2QABtF5ClgjqXwcOZamwXyaXWeMA",
  "pdfSize": "1250604"
}