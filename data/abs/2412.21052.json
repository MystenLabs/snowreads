{
  "id": "2412.21052",
  "title": "Towards Effective Discrimination Testing for Generative AI",
  "authors": "Thomas P. Zollo, Nikita Rajaneesh, Richard Zemel, Talia B. Gillis,\n  Emily Black",
  "authorsParsed": [
    [
      "Zollo",
      "Thomas P.",
      ""
    ],
    [
      "Rajaneesh",
      "Nikita",
      ""
    ],
    [
      "Zemel",
      "Richard",
      ""
    ],
    [
      "Gillis",
      "Talia B.",
      ""
    ],
    [
      "Black",
      "Emily",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Mon, 30 Dec 2024 16:09:33 GMT"
    }
  ],
  "updateDate": "2024-12-31",
  "timestamp": 1735574973000,
  "abstract": "  Generative AI (GenAI) models present new challenges in regulating against\ndiscriminatory behavior. In this paper, we argue that GenAI fairness research\nstill has not met these challenges; instead, a significant gap remains between\nexisting bias assessment methods and regulatory goals. This leads to\nineffective regulation that can allow deployment of reportedly fair, yet\nactually discriminatory, GenAI systems. Towards remedying this problem, we\nconnect the legal and technical literature around GenAI bias evaluation and\nidentify areas of misalignment. Through four case studies, we demonstrate how\nthis misalignment between fairness testing techniques and regulatory goals can\nresult in discriminatory outcomes in real-world deployments, especially in\nadaptive or complex environments. We offer practical recommendations for\nimproving discrimination testing to better align with regulatory goals and\nenhance the reliability of fairness assessments in future deployments.\n",
  "subjects": [
    "Computer Science/Machine Learning",
    "Computer Science/Artificial Intelligence",
    "Computer Science/Computers and Society"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "6G7qvMfbMhTYhiIdn5sVG1mFsnYq6_3KaYAhbMdLDGc",
  "pdfSize": "3492424"
}