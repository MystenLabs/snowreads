{
  "id": "2412.09341",
  "title": "Training LayoutLM from Scratch for Efficient Named-Entity Recognition in\n  the Insurance Domain",
  "authors": "Benno Uthayasooriyar, Antoine Ly, Franck Vermet, Caio Corro",
  "authorsParsed": [
    [
      "Uthayasooriyar",
      "Benno",
      ""
    ],
    [
      "Ly",
      "Antoine",
      ""
    ],
    [
      "Vermet",
      "Franck",
      ""
    ],
    [
      "Corro",
      "Caio",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Thu, 12 Dec 2024 15:09:44 GMT"
    }
  ],
  "updateDate": "2024-12-13",
  "timestamp": 1734016184000,
  "abstract": "  Generic pre-trained neural networks may struggle to produce good results in\nspecialized domains like finance and insurance. This is due to a domain\nmismatch between training data and downstream tasks, as in-domain data are\noften scarce due to privacy constraints. In this work, we compare different\npre-training strategies for LayoutLM. We show that using domain-relevant\ndocuments improves results on a named-entity recognition (NER) problem using a\nnovel dataset of anonymized insurance-related financial documents called\nPayslips. Moreover, we show that we can achieve competitive results using a\nsmaller and faster model.\n",
  "subjects": [
    "Computer Science/Computation and Language"
  ],
  "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/",
  "blobId": "GF-rtogYk0dqWgMwaoqvbEWMl4NG1RNFmXtbWrtrG1I",
  "pdfSize": "3393574"
}