{"id":"2407.15173","title":"Rethinking Domain Adaptation and Generalization in the Era of CLIP","authors":"Ruoyu Feng, Tao Yu, Xin Jin, Xiaoyuan Yu, Lei Xiao, Zhibo Chen","authorsParsed":[["Feng","Ruoyu",""],["Yu","Tao",""],["Jin","Xin",""],["Yu","Xiaoyuan",""],["Xiao","Lei",""],["Chen","Zhibo",""]],"versions":[{"version":"v1","created":"Sun, 21 Jul 2024 14:09:14 GMT"}],"updateDate":"2024-07-23","timestamp":1721570954000,"abstract":"  In recent studies on domain adaptation, significant emphasis has been placed\non the advancement of learning shared knowledge from a source domain to a\ntarget domain. Recently, the large vision-language pre-trained model, i.e.,\nCLIP has shown strong ability on zero-shot recognition, and parameter efficient\ntuning can further improve its performance on specific tasks. This work\ndemonstrates that a simple domain prior boosts CLIP's zero-shot recognition in\na specific domain. Besides, CLIP's adaptation relies less on source domain data\ndue to its diverse pre-training dataset. Furthermore, we create a benchmark for\nzero-shot adaptation and pseudo-labeling based self-training with CLIP. Last\nbut not least, we propose to improve the task generalization ability of CLIP\nfrom multiple unlabeled domains, which is a more practical and unique scenario.\nWe believe our findings motivate a rethinking of domain adaptation benchmarks\nand the associated role of related algorithms in the era of CLIP.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"J9bstWL_xJaX0nwgUjY537JEn9LA3c1DTzdAHOPXYUs","pdfSize":"413311"}