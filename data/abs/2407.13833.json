{"id":"2407.13833","title":"Phi-3 Safety Post-Training: Aligning Language Models with a \"Break-Fix\"\n  Cycle","authors":"Emman Haider, Daniel Perez-Becker, Thomas Portet, Piyush Madan, Amit\n  Garg, Atabak Ashfaq, David Majercak, Wen Wen, Dongwoo Kim, Ziyi Yang, Jianwen\n  Zhang, Hiteshi Sharma, Blake Bullwinkel, Martin Pouliot, Amanda Minnich,\n  Shiven Chawla, Solianna Herrera, Shahed Warreth, Maggie Engler, Gary Lopez,\n  Nina Chikanov, Raja Sekhar Rao Dheekonda, Bolor-Erdene Jagdagdorj, Roman\n  Lutz, Richard Lundeen, Tori Westerhoff, Pete Bryan, Christian Seifert, Ram\n  Shankar Siva Kumar, Andrew Berkley, Alex Kessler","authorsParsed":[["Haider","Emman",""],["Perez-Becker","Daniel",""],["Portet","Thomas",""],["Madan","Piyush",""],["Garg","Amit",""],["Ashfaq","Atabak",""],["Majercak","David",""],["Wen","Wen",""],["Kim","Dongwoo",""],["Yang","Ziyi",""],["Zhang","Jianwen",""],["Sharma","Hiteshi",""],["Bullwinkel","Blake",""],["Pouliot","Martin",""],["Minnich","Amanda",""],["Chawla","Shiven",""],["Herrera","Solianna",""],["Warreth","Shahed",""],["Engler","Maggie",""],["Lopez","Gary",""],["Chikanov","Nina",""],["Dheekonda","Raja Sekhar Rao",""],["Jagdagdorj","Bolor-Erdene",""],["Lutz","Roman",""],["Lundeen","Richard",""],["Westerhoff","Tori",""],["Bryan","Pete",""],["Seifert","Christian",""],["Kumar","Ram Shankar Siva",""],["Berkley","Andrew",""],["Kessler","Alex",""]],"versions":[{"version":"v1","created":"Thu, 18 Jul 2024 18:06:59 GMT"},{"version":"v2","created":"Fri, 23 Aug 2024 00:04:31 GMT"}],"updateDate":"2024-08-26","timestamp":1721326019000,"abstract":"  Recent innovations in language model training have demonstrated that it is\npossible to create highly performant models that are small enough to run on a\nsmartphone. As these models are deployed in an increasing number of domains, it\nis critical to ensure that they are aligned with human preferences and safety\nconsiderations. In this report, we present our methodology for safety aligning\nthe Phi-3 series of language models. We utilized a \"break-fix\" cycle,\nperforming multiple rounds of dataset curation, safety post-training,\nbenchmarking, red teaming, and vulnerability identification to cover a variety\nof harm areas in both single and multi-turn scenarios. Our results indicate\nthat this approach iteratively improved the performance of the Phi-3 models\nacross a wide range of responsible AI benchmarks. Finally, we include\nadditional red teaming strategies and evaluations that were used to test the\nsafety behavior of Phi-3.5-mini and Phi-3.5-MoE, which were optimized for\nmultilingual capabilities.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"Qoc92c4KqspQWfPeyM2ovbJqFmDfgAXnjMjzaQJqP_Q","pdfSize":"552667"}