{"id":"2407.02773","title":"OpenVNA: A Framework for Analyzing the Behavior of Multimodal Language\n  Understanding System under Noisy Scenarios","authors":"Ziqi Yuan, Baozheng Zhang, Hua Xu, Zhiyun Liang, and Kai Gao","authorsParsed":[["Yuan","Ziqi",""],["Zhang","Baozheng",""],["Xu","Hua",""],["Liang","Zhiyun",""],["Gao","Kai",""]],"versions":[{"version":"v1","created":"Wed, 3 Jul 2024 03:02:59 GMT"}],"updateDate":"2024-07-04","timestamp":1719975779000,"abstract":"  We present OpenVNA, an open-source framework designed for analyzing the\nbehavior of multimodal language understanding systems under noisy conditions.\nOpenVNA serves as an intuitive toolkit tailored for researchers, facilitating\nconvenience batch-level robustness evaluation and on-the-fly instance-level\ndemonstration. It primarily features a benchmark Python library for assessing\nglobal model robustness, offering high flexibility and extensibility, thereby\nenabling customization with user-defined noise types and models. Additionally,\na GUI-based interface has been developed to intuitively analyze local model\nbehavior. In this paper, we delineate the design principles and utilization of\nthe created library and GUI-based web platform. Currently, OpenVNA is publicly\naccessible at \\url{https://github.com/thuiar/OpenVNA}, with a demonstration\nvideo available at \\url{https://youtu.be/0Z9cW7RGct4}.\n","subjects":["Computing Research Repository/Multimedia"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"q_pgY-Uwc1ykERFc2NDY-e_Z1cEfBuj-YqUFhDISYMs","pdfSize":"1070925","objectId":"0xff86a8e401856fb229f693d8c065cb49e63d932299cc84f1686b99f08dd65901","registeredEpoch":"3","certifiedEpoch":"3","startEpoch":"3","endEpoch":"203"}
