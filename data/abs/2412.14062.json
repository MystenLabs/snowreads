{
  "id": "2412.14062",
  "title": "Understanding and Evaluating Trust in Generative AI and Large Language\n  Models for Spreadsheets",
  "authors": "Simon Thorne",
  "authorsParsed": [
    [
      "Thorne",
      "Simon",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Wed, 18 Dec 2024 17:08:18 GMT"
    }
  ],
  "updateDate": "2025-01-20",
  "timestamp": 1734541698000,
  "abstract": "  Generative AI and Large Language Models (LLMs) hold promise for automating\nspreadsheet formula creation. However, due to hallucinations, bias and variable\nuser skill, outputs obtained from generative AI cannot be assumed to be\naccurate or trustworthy. To address these challenges, a trustworthiness\nframework is proposed based on evaluating the transparency and dependability of\nthe formula. The transparency of the formula is explored through explainability\n(understanding the formula's reasoning) and visibility (inspecting the\nunderlying algorithms). The dependability of the generated formula is evaluated\nin terms of reliability (consistency and accuracy) and ethical considerations\n(bias and fairness). The paper also examines the drivers to these metrics in\nthe form of hallucinations, training data bias and poorly constructed prompts.\nFinally, examples of mistrust in technology are considered and the consequences\nexplored.\n",
  "subjects": [
    "Computer Science/Human-Computer Interaction",
    "Computer Science/Computers and Society"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "QBRlak4PkoG4ENz5lyYxHxXhUHY9LMhPuV8LdDjrl_c",
  "pdfSize": "552128"
}