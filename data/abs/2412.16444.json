{"id":"2412.16444","title":"Effective Context Modeling Framework for Emotion Recognition in\n  Conversations","authors":"Cuong Tran Van, Thanh V. T. Tran, Van Nguyen, Truong Son Hy","authorsParsed":[["Van","Cuong Tran",""],["Tran","Thanh V. T.",""],["Nguyen","Van",""],["Hy","Truong Son",""]],"versions":[{"version":"v1","created":"Sat, 21 Dec 2024 02:22:06 GMT"}],"updateDate":"2024-12-24","timestamp":1734747726000,"abstract":"  Emotion Recognition in Conversations (ERC) facilitates a deeper understanding\nof the emotions conveyed by speakers in each utterance within a conversation.\nRecently, Graph Neural Networks (GNNs) have demonstrated their strengths in\ncapturing data relationships, particularly in contextual information modeling\nand multimodal fusion. However, existing methods often struggle to fully\ncapture the complex interactions between multiple modalities and conversational\ncontext, limiting their expressiveness. To overcome these limitations, we\npropose ConxGNN, a novel GNN-based framework designed to capture contextual\ninformation in conversations. ConxGNN features two key parallel modules: a\nmulti-scale heterogeneous graph that captures the diverse effects of utterances\non emotional changes, and a hypergraph that models the multivariate\nrelationships among modalities and utterances. The outputs from these modules\nare integrated into a fusion layer, where a cross-modal attention mechanism is\napplied to produce a contextually enriched representation. Additionally,\nConxGNN tackles the challenge of recognizing minority or semantically similar\nemotion classes by incorporating a re-weighting scheme into the loss functions.\nExperimental results on the IEMOCAP and MELD benchmark datasets demonstrate the\neffectiveness of our method, achieving state-of-the-art performance compared to\nprevious baselines.\n","subjects":["Computer Science/Computation and Language","Computer Science/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"XE4MkEec9XOyrI_67mIYBatSeGswlgIrf0zHc1wbTpQ","pdfSize":"2435964"}