{
  "id": "2412.17121",
  "title": "Scalable Speech Enhancement with Dynamic Channel Pruning",
  "authors": "Riccardo Miccini, Clement Laroche, Tobias Piechowiak, Luca Pezzarossa",
  "authorsParsed": [
    [
      "Miccini",
      "Riccardo",
      ""
    ],
    [
      "Laroche",
      "Clement",
      ""
    ],
    [
      "Piechowiak",
      "Tobias",
      ""
    ],
    [
      "Pezzarossa",
      "Luca",
      ""
    ]
  ],
  "versions": [
    {
      "version": "v1",
      "created": "Sun, 22 Dec 2024 18:21:08 GMT"
    }
  ],
  "updateDate": "2024-12-24",
  "timestamp": 1734891668000,
  "abstract": "  Speech Enhancement (SE) is essential for improving productivity in remote\ncollaborative environments. Although deep learning models are highly effective\nat SE, their computational demands make them impractical for embedded systems.\nFurthermore, acoustic conditions can change significantly in terms of\ndifficulty, whereas neural networks are usually static with regard to the\namount of computation performed. To this end, we introduce Dynamic Channel\nPruning to the audio domain for the first time and apply it to a custom\nconvolutional architecture for SE. Our approach works by identifying\nunnecessary convolutional channels at runtime and saving computational\nresources by not computing the activations for these channels and retrieving\ntheir filters. When trained to only use 25% of channels, we save 29.6% of MACs\nwhile only causing a 0.75% drop in PESQ. Thus, DynCP offers a promising path\ntoward deploying larger and more powerful SE solutions on resource-constrained\ndevices.\n",
  "subjects": [
    "Electrical Engineering and Systems Science/Audio and Speech Processing",
    "Computer Science/Machine Learning",
    "Computer Science/Sound"
  ],
  "license": "http://creativecommons.org/licenses/by/4.0/",
  "blobId": "PCqr6ogvPY0nRN9qEdD1_Y5ZPPUiZSKGOv2g7l-TunQ",
  "pdfSize": "645875"
}