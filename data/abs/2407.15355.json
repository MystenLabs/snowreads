{"id":"2407.15355","title":"Attention Beats Linear for Fast Implicit Neural Representation\n  Generation","authors":"Shuyi Zhang, Ke Liu, Jingjun Gu, Xiaoxu Cai, Zhihua Wang, Jiajun Bu,\n  Haishuai Wang","authorsParsed":[["Zhang","Shuyi",""],["Liu","Ke",""],["Gu","Jingjun",""],["Cai","Xiaoxu",""],["Wang","Zhihua",""],["Bu","Jiajun",""],["Wang","Haishuai",""]],"versions":[{"version":"v1","created":"Mon, 22 Jul 2024 03:52:18 GMT"}],"updateDate":"2024-07-23","timestamp":1721620338000,"abstract":"  Implicit Neural Representation (INR) has gained increasing popularity as a\ndata representation method, serving as a prerequisite for innovative generation\nmodels. Unlike gradient-based methods, which exhibit lower efficiency in\ninference, the adoption of hyper-network for generating parameters in\nMulti-Layer Perceptrons (MLP), responsible for executing INR functions, has\nsurfaced as a promising and efficient alternative. However, as a global\ncontinuous function, MLP is challenging in modeling highly discontinuous\nsignals, resulting in slow convergence during the training phase and inaccurate\nreconstruction performance. Moreover, MLP requires massive representation\nparameters, which implies inefficiencies in data representation. In this paper,\nwe propose a novel Attention-based Localized INR (ANR) composed of a localized\nattention layer (LAL) and a global MLP that integrates coordinate features with\ndata features and converts them to meaningful outputs. Subsequently, we design\nan instance representation framework that delivers a transformer-like\nhyper-network to represent data instances as a compact representation vector.\nWith instance-specific representation vector and instance-agnostic ANR\nparameters, the target signals are well reconstructed as a continuous function.\nWe further address aliasing artifacts with variational coordinates when\nobtaining the super-resolution inference results. Extensive experimentation\nacross four datasets showcases the notable efficacy of our ANR method, e.g.\nenhancing the PSNR value from 37.95dB to 47.25dB on the CelebA dataset. Code is\nreleased at https://github.com/Roninton/ANR.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"t2icSuy4AnbVvyB3uYRQFkDdv1MVyneYNx9FP9UehfU","pdfSize":"18474879","objectId":"0xd238582b265b0178f91dea98951f566802e2925a0ff943b7ede3163e49baccbf","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
