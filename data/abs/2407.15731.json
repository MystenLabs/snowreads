{"id":"2407.15731","title":"Zero-Shot Embeddings Inform Learning and Forgetting with Vision-Language\n  Encoders","authors":"Laura Niss, Kevin Vogt-Lowell, Theodoros Tsiligkaridis","authorsParsed":[["Niss","Laura",""],["Vogt-Lowell","Kevin",""],["Tsiligkaridis","Theodoros",""]],"versions":[{"version":"v1","created":"Mon, 22 Jul 2024 15:35:09 GMT"}],"updateDate":"2024-07-23","timestamp":1721662509000,"abstract":"  Despite the proliferation of large vision-language foundation models,\nestimation of the learning and forgetting outcomes following fine-tuning of\nthese models remains largely unexplored. Inspired by work highlighting the\nsignificance of the modality gap in contrastive dual-encoders, we propose the\nInter-Intra Modal Measure (IIMM). Combining terms quantifying the similarity\nbetween image embeddings and the similarity between incorrect image and label\nembedding pairs, the IIMM functions as a strong predictor of performance\nchanges with fine-tuning. Our extensive empirical analysis across four\nstate-of-the-art vision-language models (CLIP, SigLIP, CoCa, EVA-02-CLIP) and\nfive fine-tuning techniques (full fine-tuning, BitFit, attention-weight tuning,\nLoRA, CLIP-Adapter) demonstrates a strong, statistically significant linear\nrelationship: fine-tuning on tasks with higher IIMM scores produces greater\nin-domain performance gains but also induces more severe out-of-domain\nperformance degradation, with some parameter-efficient fine-tuning (PEFT)\nmethods showing extreme forgetting. We compare our measure against transfer\nscores from state-of-the-art model selection methods and show that the IIMM is\nsignificantly more predictive of accuracy gains. With only a single forward\npass of the target data, practitioners can leverage this key insight to\nheuristically evaluate the degree to which a model can be expected to improve\nfollowing fine-tuning. Given additional knowledge about the model's performance\non a few diverse tasks, this heuristic further evolves into a strong predictor\nof expected performance changes when training for new tasks.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"-wQoIGksk8G06b2mLhShpdfknd3zBT-7Q5STMiXUwkE","pdfSize":"1994713"}