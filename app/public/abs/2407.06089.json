{"id":"2407.06089","title":"Merge, Ensemble, and Cooperate! A Survey on Collaborative Strategies in\n  the Era of Large Language Models","authors":"Jinliang Lu, Ziliang Pang, Min Xiao, Yaochen Zhu, Rui Xia, Jiajun\n  Zhang","authorsParsed":[["Lu","Jinliang",""],["Pang","Ziliang",""],["Xiao","Min",""],["Zhu","Yaochen",""],["Xia","Rui",""],["Zhang","Jiajun",""]],"versions":[{"version":"v1","created":"Mon, 8 Jul 2024 16:29:08 GMT"}],"updateDate":"2024-07-09","timestamp":1720456148000,"abstract":"  The remarkable success of Large Language Models (LLMs) has ushered natural\nlanguage processing (NLP) research into a new era. Despite their diverse\ncapabilities, LLMs trained on different corpora exhibit varying strengths and\nweaknesses, leading to challenges in maximizing their overall efficiency and\nversatility. To address these challenges, recent studies have explored\ncollaborative strategies for LLMs. This paper provides a comprehensive overview\nof this emerging research area, highlighting the motivation behind such\ncollaborations. Specifically, we categorize collaborative strategies into three\nprimary approaches: Merging, Ensemble, and Cooperation. Merging involves\nintegrating multiple LLMs in the parameter space. Ensemble combines the outputs\nof various LLMs. Cooperation} leverages different LLMs to allow full play to\ntheir diverse capabilities for specific tasks. We provide in-depth\nintroductions to these methods from different perspectives and discuss their\npotential applications. Additionally, we outline future research directions,\nhoping this work will catalyze further studies on LLM collaborations and paving\nthe way for advanced NLP applications.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/"}