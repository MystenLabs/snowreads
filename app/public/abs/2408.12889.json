{"id":"2408.12889","title":"Unleashing the Potential of SAM2 for Biomedical Images and Videos: A\n  Survey","authors":"Yichi Zhang, Zhenrong Shen","authorsParsed":[["Zhang","Yichi",""],["Shen","Zhenrong",""]],"versions":[{"version":"v1","created":"Fri, 23 Aug 2024 07:51:10 GMT"}],"updateDate":"2024-08-26","timestamp":1724399470000,"abstract":"  The unprecedented developments in segmentation foundational models have\nbecome a dominant force in the field of computer vision, introducing a\nmultitude of previously unexplored capabilities in a wide range of natural\nimages and videos. Specifically, the Segment Anything Model (SAM) signifies a\nnoteworthy expansion of the prompt-driven paradigm into the domain of image\nsegmentation. The recent introduction of SAM2 effectively extends the original\nSAM to a streaming fashion and demonstrates strong performance in video\nsegmentation. However, due to the substantial distinctions between natural and\nmedical images, the effectiveness of these models on biomedical images and\nvideos is still under exploration. This paper presents an overview of recent\nefforts in applying and adapting SAM2 to biomedical images and videos. The\nfindings indicate that while SAM2 shows promise in reducing annotation burdens\nand enabling zero-shot segmentation, its performance varies across different\ndatasets and tasks. Addressing the domain gap between natural and medical\nimages through adaptation and fine-tuning is essential to fully unleash SAM2's\npotential in clinical applications. To support ongoing research endeavors, we\nmaintain an active repository that contains up-to-date SAM & SAM2-related\npapers and projects at https://github.com/YichiZhang98/SAM4MIS.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}