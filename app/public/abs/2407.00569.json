{"id":"2407.00569","title":"Investigating and Mitigating the Multimodal Hallucination Snowballing in\n  Large Vision-Language Models","authors":"Weihong Zhong, Xiaocheng Feng, Liang Zhao, Qiming Li, Lei Huang,\n  Yuxuan Gu, Weitao Ma, Yuan Xu, Bing Qin","authorsParsed":[["Zhong","Weihong",""],["Feng","Xiaocheng",""],["Zhao","Liang",""],["Li","Qiming",""],["Huang","Lei",""],["Gu","Yuxuan",""],["Ma","Weitao",""],["Xu","Yuan",""],["Qin","Bing",""]],"versions":[{"version":"v1","created":"Sun, 30 Jun 2024 03:04:11 GMT"},{"version":"v2","created":"Sun, 28 Jul 2024 08:08:47 GMT"},{"version":"v3","created":"Wed, 31 Jul 2024 13:08:22 GMT"},{"version":"v4","created":"Sat, 3 Aug 2024 17:52:43 GMT"}],"updateDate":"2024-08-06","timestamp":1719716651000,"abstract":"  Though advanced in understanding visual information with human languages,\nLarge Vision-Language Models (LVLMs) still suffer from multimodal\nhallucinations. A natural concern is that during multimodal interaction, the\ngenerated hallucinations could influence the LVLMs' subsequent generation.\nThus, we raise a question: When presented with a query relevant to the\npreviously generated hallucination, will LVLMs be misled and respond\nincorrectly, even though the ground visual information exists? To answer this,\nwe propose a framework called MMHalSnowball to evaluate LVLMs' behaviors when\nencountering generated hallucinations, where LVLMs are required to answer\nspecific visual questions within a curated hallucinatory conversation.\nCrucially, our experiment shows that the performance of open-source LVLMs drops\nby at least $31\\%$, indicating that LVLMs are prone to accept the generated\nhallucinations and make false claims that they would not have supported without\ndistractions. We term this phenomenon Multimodal Hallucination Snowballing. To\nmitigate this, we further propose a training-free method called Residual Visual\nDecoding, where we revise the output distribution of LVLMs with the one derived\nfrom the residual visual input, providing models with direct access to the\nvisual information. Experiments show that our method can mitigate more than\n$24\\%$ of the snowballed multimodal hallucination while maintaining\ncapabilities.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}