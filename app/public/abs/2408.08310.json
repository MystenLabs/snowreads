{"id":"2408.08310","title":"ScalingFilter: Assessing Data Quality through Inverse Utilization of\n  Scaling Laws","authors":"Ruihang Li, Yixuan Wei, Miaosen Zhang, Nenghai Yu, Han Hu, Houwen Peng","authorsParsed":[["Li","Ruihang",""],["Wei","Yixuan",""],["Zhang","Miaosen",""],["Yu","Nenghai",""],["Hu","Han",""],["Peng","Houwen",""]],"versions":[{"version":"v1","created":"Thu, 15 Aug 2024 17:59:30 GMT"}],"updateDate":"2024-08-16","timestamp":1723744770000,"abstract":"  High-quality data is crucial for the pre-training performance of large\nlanguage models. Unfortunately, existing quality filtering methods rely on a\nknown high-quality dataset as reference, which can introduce potential bias and\ncompromise diversity. In this paper, we propose ScalingFilter, a novel approach\nthat evaluates text quality based on the perplexity difference between two\nlanguage models trained on the same data, thereby eliminating the influence of\nthe reference dataset in the filtering process. An theoretical analysis shows\nthat ScalingFilter is equivalent to an inverse utilization of scaling laws.\nThrough training models with 1.3B parameters on the same data source processed\nby various quality filters, we find ScalingFilter can improve zero-shot\nperformance of pre-trained models in downstream tasks. To assess the bias\nintroduced by quality filtering, we introduce semantic diversity, a metric of\nutilizing text embedding models for semantic representations. Extensive\nexperiments reveal that semantic diversity is a reliable indicator of dataset\ndiversity, and ScalingFilter achieves an optimal balance between downstream\nperformance and semantic diversity.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}