{"id":"2408.11048","title":"RP1M: A Large-Scale Motion Dataset for Piano Playing with Bi-Manual\n  Dexterous Robot Hands","authors":"Yi Zhao, Le Chen, Jan Schneider, Quankai Gao, Juho Kannala, Bernhard\n  Sch\\\"olkopf, Joni Pajarinen, Dieter B\\\"uchler","authorsParsed":[["Zhao","Yi",""],["Chen","Le",""],["Schneider","Jan",""],["Gao","Quankai",""],["Kannala","Juho",""],["Schölkopf","Bernhard",""],["Pajarinen","Joni",""],["Büchler","Dieter",""]],"versions":[{"version":"v1","created":"Tue, 20 Aug 2024 17:56:52 GMT"}],"updateDate":"2024-08-21","timestamp":1724176612000,"abstract":"  It has been a long-standing research goal to endow robot hands with\nhuman-level dexterity. Bi-manual robot piano playing constitutes a task that\ncombines challenges from dynamic tasks, such as generating fast while precise\nmotions, with slower but contact-rich manipulation problems. Although\nreinforcement learning based approaches have shown promising results in\nsingle-task performance, these methods struggle in a multi-song setting. Our\nwork aims to close this gap and, thereby, enable imitation learning approaches\nfor robot piano playing at scale. To this end, we introduce the Robot Piano 1\nMillion (RP1M) dataset, containing bi-manual robot piano playing motion data of\nmore than one million trajectories. We formulate finger placements as an\noptimal transport problem, thus, enabling automatic annotation of vast amounts\nof unlabeled songs. Benchmarking existing imitation learning approaches shows\nthat such approaches reach state-of-the-art robot piano playing performance by\nleveraging RP1M.\n","subjects":["Computing Research Repository/Robotics","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"xM9O6W6AMILE-sELoLm8hJL-fwR886Ssm4HYDUh89iQ","pdfSize":"1997476"}
