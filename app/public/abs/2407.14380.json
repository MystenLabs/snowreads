{"id":"2407.14380","title":"Deep Domain Adaptation Regression for Force Calibration of Optical\n  Tactile Sensors","authors":"Zhuo Chen, Ni Ou, Jiaqi Jiang and Shan Luo","authorsParsed":[["Chen","Zhuo",""],["Ou","Ni",""],["Jiang","Jiaqi",""],["Luo","Shan",""]],"versions":[{"version":"v1","created":"Fri, 19 Jul 2024 15:09:40 GMT"}],"updateDate":"2024-07-22","timestamp":1721401780000,"abstract":"  Optical tactile sensors provide robots with rich force information for robot\ngrasping in unstructured environments. The fast and accurate calibration of\nthree-dimensional contact forces holds significance for new sensors and\nexisting tactile sensors which may have incurred damage or aging. However, the\nconventional neural-network-based force calibration method necessitates a large\nvolume of force-labeled tactile images to minimize force prediction errors,\nwith the need for accurate Force/Torque measurement tools as well as a\ntime-consuming data collection process. To address this challenge, we propose a\nnovel deep domain-adaptation force calibration method, designed to transfer the\nforce prediction ability from a calibrated optical tactile sensor to\nuncalibrated ones with various combinations of domain gaps, including marker\npresence, illumination condition, and elastomer modulus. Experimental results\nshow the effectiveness of the proposed unsupervised force calibration method,\nwith lowest force prediction errors of 0.102N (3.4\\% in full force range) for\nnormal force, and 0.095N (6.3\\%) and 0.062N (4.1\\%) for shear forces along the\nx-axis and y-axis, respectively. This study presents a promising, general force\ncalibration methodology for optical tactile sensors.\n","subjects":["Computing Research Repository/Robotics"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}