{"id":"2408.07059","title":"Model Counting in the Wild","authors":"Arijit Shaw, Kuldeep S. Meel","authorsParsed":[["Shaw","Arijit",""],["Meel","Kuldeep S.",""]],"versions":[{"version":"v1","created":"Tue, 13 Aug 2024 17:49:46 GMT"}],"updateDate":"2024-08-14","timestamp":1723571386000,"abstract":"  Model counting is a fundamental problem in automated reasoning with\napplications in probabilistic inference, network reliability, neural network\nverification, and more. Although model counting is computationally intractable\nfrom a theoretical perspective due to its #P-completeness, the past decade has\nseen significant progress in developing state-of-the-art model counters to\naddress scalability challenges.\n  In this work, we conduct a rigorous assessment of the scalability of model\ncounters in the wild. To this end, we surveyed 11 application domains and\ncollected an aggregate of 2262 benchmarks from these domains. We then evaluated\nsix state-of-the-art model counters on these instances to assess scalability\nand runtime performance.\n  Our empirical evaluation demonstrates that the performance of model counters\nvaries significantly across different application domains, underscoring the\nneed for careful selection by the end user. Additionally, we investigated the\nbehavior of different counters with respect to two parameters suggested by the\nmodel counting community, finding only a weak correlation. Our analysis\nhighlights the challenges and opportunities for portfolio-based approaches in\nmodel counting.\n","subjects":["Computing Research Repository/Logic in Computer Science","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"xs9mZBv6QIvvfJJynl81v4HsX7dPByuCPud2zYHYTLc","pdfSize":"1146456"}
