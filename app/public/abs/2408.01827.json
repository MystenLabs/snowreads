{"id":"2408.01827","title":"ST-SACLF: Style Transfer Informed Self-Attention Classifier for\n  Bias-Aware Painting Classification","authors":"Mridula Vijendran, Frederick W. B. Li, Jingjing Deng, Hubert P. H.\n  Shum","authorsParsed":[["Vijendran","Mridula",""],["Li","Frederick W. B.",""],["Deng","Jingjing",""],["Shum","Hubert P. H.",""]],"versions":[{"version":"v1","created":"Sat, 3 Aug 2024 17:31:58 GMT"}],"updateDate":"2024-08-06","timestamp":1722706318000,"abstract":"  Painting classification plays a vital role in organizing, finding, and\nsuggesting artwork for digital and classic art galleries. Existing methods\nstruggle with adapting knowledge from the real world to artistic images during\ntraining, leading to poor performance when dealing with different datasets. Our\ninnovation lies in addressing these challenges through a two-step process.\nFirst, we generate more data using Style Transfer with Adaptive Instance\nNormalization (AdaIN), bridging the gap between diverse styles. Then, our\nclassifier gains a boost with feature-map adaptive spatial attention modules,\nimproving its understanding of artistic details. Moreover, we tackle the\nproblem of imbalanced class representation by dynamically adjusting augmented\nsamples. Through a dual-stage process involving careful hyperparameter search\nand model fine-tuning, we achieve an impressive 87.24\\% accuracy using the\nResNet-50 backbone over 40 training epochs. Our study explores quantitative\nanalyses that compare different pretrained backbones, investigates model\noptimization through ablation studies, and examines how varying augmentation\nlevels affect model performance. Complementing this, our qualitative\nexperiments offer valuable insights into the model's decision-making process\nusing spatial attention and its ability to differentiate between easy and\nchallenging samples based on confidence ranking.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}