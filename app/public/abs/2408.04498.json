{"id":"2408.04498","title":"Model-Based Transfer Learning for Contextual Reinforcement Learning","authors":"Jung-Hoon Cho, Vindula Jayawardana, Sirui Li, Cathy Wu","authorsParsed":[["Cho","Jung-Hoon",""],["Jayawardana","Vindula",""],["Li","Sirui",""],["Wu","Cathy",""]],"versions":[{"version":"v1","created":"Thu, 8 Aug 2024 14:46:01 GMT"}],"updateDate":"2024-08-09","timestamp":1723128361000,"abstract":"  Deep reinforcement learning is a powerful approach to complex decision\nmaking. However, one issue that limits its practical application is its\nbrittleness, sometimes failing to train in the presence of small changes in the\nenvironment. This work is motivated by the empirical observation that directly\napplying an already trained model to a related task often works remarkably\nwell, also called zero-shot transfer. We take this practical trick one step\nfurther to consider how to systematically select good tasks to train,\nmaximizing overall performance across a range of tasks. Given the high cost of\ntraining, it is critical to choose a small set of training tasks. The key idea\nbehind our approach is to explicitly model the performance loss (generalization\ngap) incurred by transferring a trained model. We hence introduce Model-Based\nTransfer Learning (MBTL) for solving contextual RL problems. In this work, we\nmodel the performance loss as a simple linear function of task context\nsimilarity. Furthermore, we leverage Bayesian optimization techniques to\nefficiently model and estimate the unknown training performance of the task\nspace. We theoretically show that the method exhibits regret that is sublinear\nin the number of training tasks and discuss conditions to further tighten\nregret bounds. We experimentally validate our methods using urban traffic and\nstandard control benchmarks. Despite the conceptual simplicity, the\nexperimental results suggest that MBTL can achieve greater performance than\nstrong baselines, including exhaustive training on all tasks, multi-task\ntraining, and random selection of training tasks. This work lays the\nfoundations for investigating explicit modeling of generalization, thereby\nenabling principled yet effective methods for contextual RL.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}