{"id":"2407.21136","title":"MotionCraft: Crafting Whole-Body Motion with Plug-and-Play Multimodal\n  Controls","authors":"Yuxuan Bian, Ailing Zeng, Xuan Ju, Xian Liu, Zhaoyang Zhang, Wei Liu,\n  Qiang Xu","authorsParsed":[["Bian","Yuxuan",""],["Zeng","Ailing",""],["Ju","Xuan",""],["Liu","Xian",""],["Zhang","Zhaoyang",""],["Liu","Wei",""],["Xu","Qiang",""]],"versions":[{"version":"v1","created":"Tue, 30 Jul 2024 18:57:06 GMT"},{"version":"v2","created":"Sun, 4 Aug 2024 03:32:03 GMT"},{"version":"v3","created":"Sun, 25 Aug 2024 07:35:04 GMT"}],"updateDate":"2024-08-27","timestamp":1722365826000,"abstract":"  Whole-body multimodal motion generation, controlled by text, speech, or\nmusic, has numerous applications including video generation and character\nanimation. However, employing a unified model to achieve various generation\ntasks with different condition modalities presents two main challenges: motion\ndistribution drifts across different tasks (e.g., co-speech gestures and\ntext-driven daily actions) and the complex optimization of mixed conditions\nwith varying granularities (e.g., text and audio). Additionally, inconsistent\nmotion formats across different tasks and datasets hinder effective training\ntoward multimodal motion generation. In this paper, we propose MotionCraft, a\nunified diffusion transformer that crafts whole-body motion with plug-and-play\nmultimodal control. Our framework employs a coarse-to-fine training strategy,\nstarting with the first stage of text-to-motion semantic pre-training, followed\nby the second stage of multimodal low-level control adaptation to handle\nconditions of varying granularities. To effectively learn and transfer motion\nknowledge across different distributions, we design MC-Attn for parallel\nmodeling of static and dynamic human topology graphs. To overcome the motion\nformat inconsistency of existing benchmarks, we introduce MC-Bench, the first\navailable multimodal whole-body motion generation benchmark based on the\nunified SMPL-X format. Extensive experiments show that MotionCraft achieves\nstate-of-the-art performance on various standard motion generation tasks.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}