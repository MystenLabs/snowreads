{"id":"2408.12439","title":"Adapting MIMO video restoration networks to low latency constraints","authors":"Val\\'ery Dewil, Zhe Zheng, Arnaud Barral, Lara Raad, Nao Nicolas,\n  Ioannis Cassagne, Jean-michel Morel, Gabriele Facciolo, Bruno Galerne, Pablo\n  Arias","authorsParsed":[["Dewil","Val√©ry",""],["Zheng","Zhe",""],["Barral","Arnaud",""],["Raad","Lara",""],["Nicolas","Nao",""],["Cassagne","Ioannis",""],["Morel","Jean-michel",""],["Facciolo","Gabriele",""],["Galerne","Bruno",""],["Arias","Pablo",""]],"versions":[{"version":"v1","created":"Thu, 22 Aug 2024 14:36:56 GMT"}],"updateDate":"2024-08-23","timestamp":1724337416000,"abstract":"  MIMO (multiple input, multiple output) approaches are a recent trend in\nneural network architectures for video restoration problems, where each network\nevaluation produces multiple output frames. The video is split into\nnon-overlapping stacks of frames that are processed independently, resulting in\na very appealing trade-off between output quality and computational cost. In\nthis work we focus on the low-latency setting by limiting the number of\navailable future frames. We find that MIMO architectures suffer from problems\nthat have received little attention so far, namely (1) the performance drops\nsignificantly due to the reduced temporal receptive field, particularly for\nframes at the borders of the stack, (2) there are strong temporal\ndiscontinuities at stack transitions which induce a step-wise motion artifact.\nWe propose two simple solutions to alleviate these problems: recurrence across\nMIMO stacks to boost the output quality by implicitly increasing the temporal\nreceptive field, and overlapping of the output stacks to smooth the temporal\ndiscontinuity at stack transitions. These modifications can be applied to any\nMIMO architecture. We test them on three state-of-the-art video denoising\nnetworks with different computational cost. The proposed contributions result\nin a new state-of-the-art for low-latency networks, both in terms of\nreconstruction error and temporal consistency. As an additional contribution,\nwe introduce a new benchmark consisting of drone footage that highlights\ntemporal consistency issues that are not apparent in the standard benchmarks.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}