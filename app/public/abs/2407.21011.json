{"id":"2407.21011","title":"CLEFT: Language-Image Contrastive Learning with Efficient Large Language\n  Model and Prompt Fine-Tuning","authors":"Yuexi Du, Brian Chang, Nicha C. Dvornek","authorsParsed":[["Du","Yuexi",""],["Chang","Brian",""],["Dvornek","Nicha C.",""]],"versions":[{"version":"v1","created":"Tue, 30 Jul 2024 17:57:32 GMT"}],"updateDate":"2024-07-31","timestamp":1722362252000,"abstract":"  Recent advancements in Contrastive Language-Image Pre-training (CLIP) have\ndemonstrated notable success in self-supervised representation learning across\nvarious tasks. However, the existing CLIP-like approaches often demand\nextensive GPU resources and prolonged training times due to the considerable\nsize of the model and dataset, making them poor for medical applications, in\nwhich large datasets are not always common. Meanwhile, the language model\nprompts are mainly manually derived from labels tied to images, potentially\noverlooking the richness of information within training samples. We introduce a\nnovel language-image Contrastive Learning method with an Efficient large\nlanguage model and prompt Fine-Tuning (CLEFT) that harnesses the strengths of\nthe extensive pre-trained language and visual models. Furthermore, we present\nan efficient strategy for learning context-based prompts that mitigates the gap\nbetween informative clinical diagnostic data and simple class labels. Our\nmethod demonstrates state-of-the-art performance on multiple chest X-ray and\nmammography datasets compared with various baselines. The proposed parameter\nefficient framework can reduce the total trainable model size by 39% and reduce\nthe trainable language model to only 4% compared with the current BERT encoder.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}