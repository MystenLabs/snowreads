{"id":"2408.04667","title":"LLM Stability: A detailed analysis with some surprises","authors":"Berk Atil, Alexa Chittams, Liseng Fu, Ferhan Ture, Lixinyu Xu, Breck\n  Baldwin","authorsParsed":[["Atil","Berk",""],["Chittams","Alexa",""],["Fu","Liseng",""],["Ture","Ferhan",""],["Xu","Lixinyu",""],["Baldwin","Breck",""]],"versions":[{"version":"v1","created":"Tue, 6 Aug 2024 16:43:35 GMT"},{"version":"v2","created":"Thu, 12 Sep 2024 19:15:17 GMT"}],"updateDate":"2024-09-16","timestamp":1722962615000,"abstract":"  LLM (large language model) practitioners commonly notice that outputs can\nvary for the same inputs, but we have been unable to find work that evaluates\nLLM stability as the main objective. In our study of 6 deterministically\nconfigured LLMs across 8 common tasks with 5 identical runs, we see accuracy\nvariations up to 10\\%. In addition, no LLM consistently delivers repeatable\naccuracy across all tasks. We also show examples of variation that are not\nnormally distributed and compare configurations with zero-shot/few-shot\nprompting and fine-tuned examples. To better quantify what is going on, we\nintroduce metrics focused on stability: TARr@N for the total agreement rate at\nN runs over raw output, and TARa@N for total agreement over parsed-out answers.\nWe suggest that stability metrics be integrated into leader boards and research\nresults going forward.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning","Computing Research Repository/Software Engineering"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"3krfVyzT5IKPz1LbGvjsT4EwSKf-PRYGSDMIJdmc2lw","pdfSize":"422922"}
