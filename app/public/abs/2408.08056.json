{"id":"2408.08056","title":"DATTA: Towards Diversity Adaptive Test-Time Adaptation in Dynamic Wild\n  World","authors":"Chuyang Ye, Dongyan Wei, Zhendong Liu, Yuanyi Pang, Yixi Lin, Jiarong\n  Liao, Qinting Jiang, Xianghua Fu, Qing Li, and Jingyan Jiang","authorsParsed":[["Ye","Chuyang",""],["Wei","Dongyan",""],["Liu","Zhendong",""],["Pang","Yuanyi",""],["Lin","Yixi",""],["Liao","Jiarong",""],["Jiang","Qinting",""],["Fu","Xianghua",""],["Li","Qing",""],["Jiang","Jingyan",""]],"versions":[{"version":"v1","created":"Thu, 15 Aug 2024 09:50:11 GMT"}],"updateDate":"2024-08-16","timestamp":1723715411000,"abstract":"  Test-time adaptation (TTA) effectively addresses distribution shifts between\ntraining and testing data by adjusting models on test samples, which is crucial\nfor improving model inference in real-world applications. However, traditional\nTTA methods typically follow a fixed pattern to address the dynamic data\npatterns (low-diversity or high-diversity patterns) often leading to\nperformance degradation and consequently a decline in Quality of Experience\n(QoE). The primary issues we observed are:Different scenarios require different\nnormalization methods (e.g., Instance Normalization is optimal in mixed domains\nbut not in static domains). Model fine-tuning can potentially harm the model\nand waste time.Hence, it is crucial to design strategies for effectively\nmeasuring and managing distribution diversity to minimize its negative impact\non model performance. Based on these observations, this paper proposes a new\ngeneral method, named Diversity Adaptive Test-Time Adaptation (DATTA), aimed at\nimproving QoE. DATTA dynamically selects the best batch normalization methods\nand fine-tuning strategies by leveraging the Diversity Score to differentiate\nbetween high and low diversity score batches. It features three key components:\nDiversity Discrimination (DD) to assess batch diversity, Diversity Adaptive\nBatch Normalization (DABN) to tailor normalization methods based on DD\ninsights, and Diversity Adaptive Fine-Tuning (DAFT) to selectively fine-tune\nthe model. Experimental results show that our method achieves up to a 21%\nincrease in accuracy compared to state-of-the-art methodologies, indicating\nthat our method maintains good model performance while demonstrating its\nrobustness. Our code will be released soon.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}