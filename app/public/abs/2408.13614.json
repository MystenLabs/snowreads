{"id":"2408.13614","title":"As Biased as You Measure: Methodological Pitfalls of Bias Evaluations in\n  Speaker Verification Research","authors":"Wiebke Hutiri, Tanvina Patel, Aaron Yi Ding, Odette Scharenborg","authorsParsed":[["Hutiri","Wiebke",""],["Patel","Tanvina",""],["Ding","Aaron Yi",""],["Scharenborg","Odette",""]],"versions":[{"version":"v1","created":"Sat, 24 Aug 2024 16:04:51 GMT"}],"updateDate":"2024-08-27","timestamp":1724515491000,"abstract":"  Detecting and mitigating bias in speaker verification systems is important,\nas datasets, processing choices and algorithms can lead to performance\ndifferences that systematically favour some groups of people while\ndisadvantaging others. Prior studies have thus measured performance differences\nacross groups to evaluate bias. However, when comparing results across studies,\nit becomes apparent that they draw contradictory conclusions, hindering\nprogress in this area. In this paper we investigate how measurement impacts the\noutcomes of bias evaluations. We show empirically that bias evaluations are\nstrongly influenced by base metrics that measure performance, by the choice of\nratio or difference-based bias measure, and by the aggregation of bias measures\ninto meta-measures. Based on our findings, we recommend the use of ratio-based\nbias measures, in particular when the values of base metrics are small, or when\nbase metrics with different orders of magnitude need to be compared.\n","subjects":["Electrical Engineering and Systems Science/Audio and Speech Processing","Computing Research Repository/Computers and Society"],"license":"http://creativecommons.org/licenses/by/4.0/"}