{"id":"2407.10277","title":"Disrupting Diffusion-based Inpainters with Semantic Digression","authors":"Geonho Son, Juhun Lee, Simon S. Woo","authorsParsed":[["Son","Geonho",""],["Lee","Juhun",""],["Woo","Simon S.",""]],"versions":[{"version":"v1","created":"Sun, 14 Jul 2024 17:21:19 GMT"}],"updateDate":"2024-07-16","timestamp":1720977679000,"abstract":"  The fabrication of visual misinformation on the web and social media has\nincreased exponentially with the advent of foundational text-to-image diffusion\nmodels. Namely, Stable Diffusion inpainters allow the synthesis of maliciously\ninpainted images of personal and private figures, and copyrighted contents,\nalso known as deepfakes. To combat such generations, a disruption framework,\nnamely Photoguard, has been proposed, where it adds adversarial noise to the\ncontext image to disrupt their inpainting synthesis. While their framework\nsuggested a diffusion-friendly approach, the disruption is not sufficiently\nstrong and it requires a significant amount of GPU and time to immunize the\ncontext image. In our work, we re-examine both the minimal and favorable\nconditions for a successful inpainting disruption, proposing DDD, a \"Digression\nguided Diffusion Disruption\" framework. First, we identify the most\nadversarially vulnerable diffusion timestep range with respect to the hidden\nspace. Within this scope of noised manifold, we pose the problem as a semantic\ndigression optimization. We maximize the distance between the inpainting\ninstance's hidden states and a semantic-aware hidden state centroid, calibrated\nboth by Monte Carlo sampling of hidden states and a discretely projected\noptimization in the token space. Effectively, our approach achieves stronger\ndisruption and a higher success rate than Photoguard while lowering the GPU\nmemory requirement, and speeding the optimization up to three times faster.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}