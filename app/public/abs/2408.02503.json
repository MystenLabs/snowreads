{"id":"2408.02503","title":"UnifiedMLLM: Enabling Unified Representation for Multi-modal Multi-tasks\n  With Large Language Model","authors":"Zhaowei Li, Wei Wang, YiQing Cai, Xu Qi, Pengyu Wang, Dong Zhang, Hang\n  Song, Botian Jiang, Zhida Huang, Tao Wang","authorsParsed":[["Li","Zhaowei",""],["Wang","Wei",""],["Cai","YiQing",""],["Qi","Xu",""],["Wang","Pengyu",""],["Zhang","Dong",""],["Song","Hang",""],["Jiang","Botian",""],["Huang","Zhida",""],["Wang","Tao",""]],"versions":[{"version":"v1","created":"Mon, 5 Aug 2024 14:27:39 GMT"}],"updateDate":"2024-08-06","timestamp":1722868059000,"abstract":"  Significant advancements has recently been achieved in the field of\nmulti-modal large language models (MLLMs), demonstrating their remarkable\ncapabilities in understanding and reasoning across diverse tasks. However,\nthese models are often trained for specific tasks and rely on task-specific\ninput-output formats, limiting their applicability to a broader range of tasks.\nThis raises a fundamental question: Can we develop a unified approach to\nrepresent and handle different multi-modal tasks to maximize the\ngeneralizability of MLLMs? In this paper, we propose UnifiedMLLM, a\ncomprehensive model designed to represent various tasks using a unified\nrepresentation. Our model exhibits strong capabilities in comprehending the\nimplicit intent of user instructions and preforming reasoning. In addition to\ngenerating textual responses, our model also outputs task tokens and grounding\ntokens, serving as indicators of task types and task granularity. These outputs\nare subsequently routed through the task router and directed to specific expert\nmodels for task completion. To train our model, we construct a task-specific\ndataset and an 100k multi-task dataset encompassing complex scenarios.\nEmploying a three-stage training strategy, we equip our model with robust\nreasoning and task processing capabilities while preserving its generalization\ncapacity and knowledge reservoir. Extensive experiments showcase the impressive\nperformance of our unified representation approach across various tasks,\nsurpassing existing methodologies. Furthermore, our approach exhibits\nexceptional scalability and generality. Our code, model, and dataset will be\navailable at \\url{https://github.com/lzw-lzw/UnifiedMLLM}.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/"}