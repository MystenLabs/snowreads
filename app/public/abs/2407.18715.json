{"id":"2407.18715","title":"BCTR: Bidirectional Conditioning Transformer for Scene Graph Generation","authors":"Peng Hao, Xiaobing Wang, Yingying Jiang, Hanchao Jia, Xiaoshuai Hao","authorsParsed":[["Hao","Peng",""],["Wang","Xiaobing",""],["Jiang","Yingying",""],["Jia","Hanchao",""],["Hao","Xiaoshuai",""]],"versions":[{"version":"v1","created":"Fri, 26 Jul 2024 13:02:48 GMT"}],"updateDate":"2024-07-29","timestamp":1721998968000,"abstract":"  Scene Graph Generation (SGG) remains a challenging task due to its\ncompositional property. Previous approaches improve prediction efficiency by\nlearning in an end-to-end manner. However, these methods exhibit limited\nperformance as they assume unidirectional conditioning between entities and\npredicates, leading to insufficient information interaction. To address this\nlimitation, we propose a novel bidirectional conditioning factorization for\nSGG, introducing efficient interaction between entities and predicates.\nSpecifically, we develop an end-to-end scene graph generation model,\nBidirectional Conditioning Transformer (BCTR), to implement our factorization.\nBCTR consists of two key modules. First, the Bidirectional Conditioning\nGenerator (BCG) facilitates multi-stage interactive feature augmentation\nbetween entities and predicates, enabling mutual benefits between the two\npredictions. Second, Random Feature Alignment (RFA) regularizes the feature\nspace by distilling multi-modal knowledge from pre-trained models, enhancing\nBCTR's ability on tailed categories without relying on statistical priors. We\nconduct a series of experiments on Visual Genome and Open Image V6,\ndemonstrating that BCTR achieves state-of-the-art performance on both\nbenchmarks. The code will be available upon acceptance of the paper.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"0rHvKt590rFDsHdNMOvxtDdy6JaNjDMoa5wGO_l51HQ","pdfSize":"396198"}
