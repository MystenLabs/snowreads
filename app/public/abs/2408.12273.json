{"id":"2408.12273","title":"Geometrical structures of digital fluctuations in parameter space of\n  neural networks trained with adaptive momentum optimization","authors":"Igor V. Netay","authorsParsed":[["Netay","Igor V.",""]],"versions":[{"version":"v1","created":"Thu, 22 Aug 2024 10:14:10 GMT"}],"updateDate":"2024-08-23","timestamp":1724321650000,"abstract":"  We present results of numerical experiments for neural networks with\nstochastic gradient-based optimization with adaptive momentum. This widely\napplied optimization has proved convergence and practical efficiency, but for\nlong-run training becomes numerically unstable. We show that numerical\nartifacts are observable not only for large-scale models and finally lead to\ndivergence also for case of shallow narrow networks. We argue this theory by\nexperiments with more than 1600 neural networks trained for 50000 epochs. Local\nobservations show presence of the same behavior of network parameters in both\nstable and unstable training segments. Geometrical behavior of parameters forms\ndouble twisted spirals in the parameter space and is caused by alternating of\nnumerical perturbations with next relaxation oscillations in values for 1st and\n2nd momentum.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Numerical Analysis","Mathematics/Numerical Analysis"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}