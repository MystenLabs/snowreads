{"id":"2407.15476","title":"MODRL-TA:A Multi-Objective Deep Reinforcement Learning Framework for\n  Traffic Allocation in E-Commerce Search","authors":"Peng Cheng, Huimu Wang, Jinyuan Zhao, Yihao Wang, Enqiang Xu, Yu Zhao,\n  Zhuojian Xiao, Songlin Wang, Guoyu Tang, Lin Liu, Sulong Xu","authorsParsed":[["Cheng","Peng",""],["Wang","Huimu",""],["Zhao","Jinyuan",""],["Wang","Yihao",""],["Xu","Enqiang",""],["Zhao","Yu",""],["Xiao","Zhuojian",""],["Wang","Songlin",""],["Tang","Guoyu",""],["Liu","Lin",""],["Xu","Sulong",""]],"versions":[{"version":"v1","created":"Mon, 22 Jul 2024 08:40:27 GMT"}],"updateDate":"2024-07-23","timestamp":1721637627000,"abstract":"  Traffic allocation is a process of redistributing natural traffic to products\nby adjusting their positions in the post-search phase, aimed at effectively\nfostering merchant growth, precisely meeting customer demands, and ensuring the\nmaximization of interests across various parties within e-commerce platforms.\nExisting methods based on learning to rank neglect the long-term value of\ntraffic allocation, whereas approaches of reinforcement learning suffer from\nbalancing multiple objectives and the difficulties of cold starts within\nrealworld data environments. To address the aforementioned issues, this paper\npropose a multi-objective deep reinforcement learning framework consisting of\nmulti-objective Q-learning (MOQ), a decision fusion algorithm (DFM) based on\nthe cross-entropy method(CEM), and a progressive data augmentation system(PDA).\nSpecifically. MOQ constructs ensemble RL models, each dedicated to an\nobjective, such as click-through rate, conversion rate, etc. These models\nindividually determine the position of items as actions, aiming to estimate the\nlong-term value of multiple objectives from an individual perspective. Then we\nemploy DFM to dynamically adjust weights among objectives to maximize long-term\nvalue, addressing temporal dynamics in objective preferences in e-commerce\nscenarios. Initially, PDA trained MOQ with simulated data from offline logs. As\nexperiments progressed, it strategically integrated real user interaction data,\nultimately replacing the simulated dataset to alleviate distributional shifts\nand the cold start problem. Experimental results on real-world online\ne-commerce systems demonstrate the significant improvements of MODRL-TA, and we\nhave successfully deployed MODRL-TA on an e-commerce search platform.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Information Retrieval"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}