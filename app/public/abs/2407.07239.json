{"id":"2407.07239","title":"RotRNN: Modelling Long Sequences with Rotations","authors":"Rares Dolga, Kai Biegun, Jake Cunningham, David Barber","authorsParsed":[["Dolga","Rares",""],["Biegun","Kai",""],["Cunningham","Jake",""],["Barber","David",""]],"versions":[{"version":"v1","created":"Tue, 9 Jul 2024 21:37:36 GMT"}],"updateDate":"2024-07-11","timestamp":1720561056000,"abstract":"  Linear recurrent models, such as State Space Models (SSMs) and Linear\nRecurrent Units (LRUs), have recently shown state-of-the-art performance on\nlong sequence modelling benchmarks. Despite their success, they come with a\nnumber of drawbacks, most notably their complex initialisation and\nnormalisation schemes. In this work, we address some of these issues by\nproposing RotRNN -- a linear recurrent model which utilises the convenient\nproperties of rotation matrices. We show that RotRNN provides a simple model\nwith fewer theoretical assumptions than prior works, with a practical\nimplementation that remains faithful to its theoretical derivation, achieving\ncomparable scores to the LRU and SSMs on several long sequence modelling\ndatasets.\n","subjects":["Computing Research Repository/Machine Learning","Statistics/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}