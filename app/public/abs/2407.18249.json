{"id":"2407.18249","title":"Trajectory-aligned Space-time Tokens for Few-shot Action Recognition","authors":"Pulkit Kumar, Namitha Padmanabhan, Luke Luo, Sai Saketh Rambhatla,\n  Abhinav Shrivastava","authorsParsed":[["Kumar","Pulkit",""],["Padmanabhan","Namitha",""],["Luo","Luke",""],["Rambhatla","Sai Saketh",""],["Shrivastava","Abhinav",""]],"versions":[{"version":"v1","created":"Thu, 25 Jul 2024 17:59:31 GMT"}],"updateDate":"2024-07-26","timestamp":1721930371000,"abstract":"  We propose a simple yet effective approach for few-shot action recognition,\nemphasizing the disentanglement of motion and appearance representations. By\nharnessing recent progress in tracking, specifically point trajectories and\nself-supervised representation learning, we build trajectory-aligned tokens\n(TATs) that capture motion and appearance information. This approach\nsignificantly reduces the data requirements while retaining essential\ninformation. To process these representations, we use a Masked Space-time\nTransformer that effectively learns to aggregate information to facilitate\nfew-shot action recognition. We demonstrate state-of-the-art results on\nfew-shot action recognition across multiple datasets. Our project page is\navailable at https://www.cs.umd.edu/~pulkit/tats\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"HtoAFLjPC97ydX4-xi15TcJ_MEoATri8teiwnR04ERI","pdfSize":"2008528"}
