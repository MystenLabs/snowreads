{"id":"2407.05128","title":"SCSA: Exploring the Synergistic Effects Between Spatial and Channel\n  Attention","authors":"Yunzhong Si, Huiying Xu, Xinzhong Zhu, Wenhao Zhang, Yao Dong, Yuxing\n  Chen and Hongbo Li","authorsParsed":[["Si","Yunzhong",""],["Xu","Huiying",""],["Zhu","Xinzhong",""],["Zhang","Wenhao",""],["Dong","Yao",""],["Chen","Yuxing",""],["Li","Hongbo",""]],"versions":[{"version":"v1","created":"Sat, 6 Jul 2024 16:34:25 GMT"}],"updateDate":"2024-07-09","timestamp":1720283665000,"abstract":"  Channel and spatial attentions have respectively brought significant\nimprovements in extracting feature dependencies and spatial structure relations\nfor various downstream vision tasks. While their combination is more beneficial\nfor leveraging their individual strengths, the synergy between channel and\nspatial attentions has not been fully explored, lacking in fully harness the\nsynergistic potential of multi-semantic information for feature guidance and\nmitigation of semantic disparities. Our study attempts to reveal the\nsynergistic relationship between spatial and channel attention at multiple\nsemantic levels, proposing a novel Spatial and Channel Synergistic Attention\nmodule (SCSA). Our SCSA consists of two parts: the Shareable Multi-Semantic\nSpatial Attention (SMSA) and the Progressive Channel-wise Self-Attention\n(PCSA). SMSA integrates multi-semantic information and utilizes a progressive\ncompression strategy to inject discriminative spatial priors into PCSA's\nchannel self-attention, effectively guiding channel recalibration.\nAdditionally, the robust feature interactions based on the self-attention\nmechanism in PCSA further mitigate the disparities in multi-semantic\ninformation among different sub-features within SMSA. We conduct extensive\nexperiments on seven benchmark datasets, including classification on\nImageNet-1K, object detection on MSCOCO 2017, segmentation on ADE20K, and four\nother complex scene detection datasets. Our results demonstrate that our\nproposed SCSA not only surpasses the current state-of-the-art attention but\nalso exhibits enhanced generalization capabilities across various task\nscenarios. The code and models are available at:\nhttps://github.com/HZAI-ZJNU/SCSA.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}