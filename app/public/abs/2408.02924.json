{"id":"2408.02924","title":"Evaluation of Segment Anything Model 2: The Role of SAM2 in the\n  Underwater Environment","authors":"Shijie Lian and Hua Li","authorsParsed":[["Lian","Shijie",""],["Li","Hua",""]],"versions":[{"version":"v1","created":"Tue, 6 Aug 2024 03:20:10 GMT"}],"updateDate":"2024-08-07","timestamp":1722914410000,"abstract":"  With breakthroughs in large-scale modeling, the Segment Anything Model (SAM)\nand its extensions have been attempted for applications in various underwater\nvisualization tasks in marine sciences, and have had a significant impact on\nthe academic community. Recently, Meta has further developed the Segment\nAnything Model 2 (SAM2), which significantly improves running speed and\nsegmentation accuracy compared to its predecessor. This report aims to explore\nthe potential of SAM2 in marine science by evaluating it on the underwater\ninstance segmentation benchmark datasets UIIS and USIS10K. The experiments show\nthat the performance of SAM2 is extremely dependent on the type of\nuser-provided prompts. When using the ground truth bounding box as prompt, SAM2\nperformed excellently in the underwater instance segmentation domain. However,\nwhen running in automatic mode, SAM2's ability with point prompts to sense and\nsegment underwater instances is significantly degraded. It is hoped that this\npaper will inspire researchers to further explore the SAM model family in the\nunderwater domain. The results and evaluation codes in this paper are available\nat https://github.com/LiamLian0727/UnderwaterSAM2Eval.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}