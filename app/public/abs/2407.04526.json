{"id":"2407.04526","title":"Peering inside the black box: Learning the relevance of many-body\n  functions in Neural Network potentials","authors":"Klara Bonneau, Jonas Lederer, Clark Templeton, David Rosenberger,\n  Klaus-Robert M\\\"uller, Cecilia Clementi","authorsParsed":[["Bonneau","Klara",""],["Lederer","Jonas",""],["Templeton","Clark",""],["Rosenberger","David",""],["MÃ¼ller","Klaus-Robert",""],["Clementi","Cecilia",""]],"versions":[{"version":"v1","created":"Fri, 5 Jul 2024 14:12:06 GMT"}],"updateDate":"2024-07-08","timestamp":1720188726000,"abstract":"  Machine learned potentials are becoming a popular tool to define an effective\nenergy model for complex systems, either incorporating electronic structure\neffects at the atomistic resolution, or effectively renormalizing part of the\natomistic degrees of freedom at a coarse-grained resolution. One of the main\ncriticisms to machine learned potentials is that the energy inferred by the\nnetwork is not as interpretable as in more traditional approaches where a\nsimpler functional form is used. Here we address this problem by extending\ntools recently proposed in the nascent field of Explainable Artificial\nIntelligence (XAI) to coarse-grained potentials based on graph neural networks\n(GNN). We demonstrate the approach on three different coarse-grained systems\nincluding two fluids (methane and water) and the protein NTL9. On these\nexamples, we show that the neural network potentials can be in practice\ndecomposed in relevance contributions to different orders, that can be directly\ninterpreted and provide physical insights on the systems of interest.\n","subjects":["Physics/Computational Physics"],"license":"http://creativecommons.org/licenses/by/4.0/"}