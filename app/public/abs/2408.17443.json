{"id":"2408.17443","title":"Bridging Episodes and Semantics: A Novel Framework for Long-Form Video\n  Understanding","authors":"Gueter Josmy Faure, Jia-Fong Yeh, Min-Hung Chen, Hung-Ting Su, Winston\n  H. Hsu, Shang-Hong Lai","authorsParsed":[["Faure","Gueter Josmy",""],["Yeh","Jia-Fong",""],["Chen","Min-Hung",""],["Su","Hung-Ting",""],["Hsu","Winston H.",""],["Lai","Shang-Hong",""]],"versions":[{"version":"v1","created":"Fri, 30 Aug 2024 17:52:55 GMT"}],"updateDate":"2024-09-02","timestamp":1725040375000,"abstract":"  While existing research often treats long-form videos as extended short\nvideos, we propose a novel approach that more accurately reflects human\ncognition. This paper introduces BREASE: BRidging Episodes And SEmantics for\nLong-Form Video Understanding, a model that simulates episodic memory\naccumulation to capture action sequences and reinforces them with semantic\nknowledge dispersed throughout the video. Our work makes two key contributions:\nFirst, we develop an Episodic COmpressor (ECO) that efficiently aggregates\ncrucial representations from micro to semi-macro levels. Second, we propose a\nSemantics reTRiever (SeTR) that enhances these aggregated representations with\nsemantic information by focusing on the broader context, dramatically reducing\nfeature dimensionality while preserving relevant macro-level information.\nExtensive experiments demonstrate that BREASE achieves state-of-the-art\nperformance across multiple long video understanding benchmarks in both\nzero-shot and fully-supervised settings. The project page and code are at:\nhttps://joslefaure.github.io/assets/html/hermes.html.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"MIVr0gh7hu7c2vQtOwli_57Ed5aBFqFx8h3enyOvD-w","pdfSize":"1958469"}
