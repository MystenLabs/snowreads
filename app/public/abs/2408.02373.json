{"id":"2408.02373","title":"Operationalizing Contextual Integrity in Privacy-Conscious Assistants","authors":"Sahra Ghalebikesabi, Eugene Bagdasaryan, Ren Yi, Itay Yona, Ilia\n  Shumailov, Aneesh Pappu, Chongyang Shi, Laura Weidinger, Robert Stanforth,\n  Leonard Berrada, Pushmeet Kohli, Po-Sen Huang, Borja Balle","authorsParsed":[["Ghalebikesabi","Sahra",""],["Bagdasaryan","Eugene",""],["Yi","Ren",""],["Yona","Itay",""],["Shumailov","Ilia",""],["Pappu","Aneesh",""],["Shi","Chongyang",""],["Weidinger","Laura",""],["Stanforth","Robert",""],["Berrada","Leonard",""],["Kohli","Pushmeet",""],["Huang","Po-Sen",""],["Balle","Borja",""]],"versions":[{"version":"v1","created":"Mon, 5 Aug 2024 10:53:51 GMT"},{"version":"v2","created":"Fri, 13 Sep 2024 13:09:41 GMT"}],"updateDate":"2024-09-16","timestamp":1722855231000,"abstract":"  Advanced AI assistants combine frontier LLMs and tool access to autonomously\nperform complex tasks on behalf of users. While the helpfulness of such\nassistants can increase dramatically with access to user information including\nemails and documents, this raises privacy concerns about assistants sharing\ninappropriate information with third parties without user supervision. To steer\ninformation-sharing assistants to behave in accordance with privacy\nexpectations, we propose to operationalize contextual integrity (CI), a\nframework that equates privacy with the appropriate flow of information in a\ngiven context. In particular, we design and evaluate a number of strategies to\nsteer assistants' information-sharing actions to be CI compliant. Our\nevaluation is based on a novel form filling benchmark composed of human\nannotations of common webform applications, and it reveals that prompting\nfrontier LLMs to perform CI-based reasoning yields strong results.\n","subjects":["Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"M1FLP8eAxxOrUY_MpV355x13nRML-gHjMHJeJfSzNuk","pdfSize":"1261079"}
