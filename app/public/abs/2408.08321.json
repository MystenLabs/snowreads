{"id":"2408.08321","title":"Can ChatGPT assist visually impaired people with micro-navigation?","authors":"Junxian He, Shrinivas Pundlik, Gang Luo","authorsParsed":[["He","Junxian",""],["Pundlik","Shrinivas",""],["Luo","Gang",""]],"versions":[{"version":"v1","created":"Wed, 31 Jul 2024 21:02:47 GMT"}],"updateDate":"2024-08-19","timestamp":1722459767000,"abstract":"  Objective: Micro-navigation poses challenges for blind and visually impaired\nindividuals. They often need to ask for sighted assistance. We explored the\nfeasibility of utilizing ChatGPT as a virtual assistant to provide navigation\ndirections. Methods: We created a test set of outdoor and indoor\nmicro-navigation scenarios consisting of 113 scene images and their\nhuman-generated text descriptions. A total of 412 way-finding queries and their\nexpected responses were compiled based on the scenarios. Not all queries are\nanswerable based on the information available in the scene image. \"I do not\nknow\"response was expected for unanswerable queries, which served as negative\ncases. High level orientation responses were expected, and step-by-step\nguidance was not required. ChatGPT 4o was evaluated based on sensitivity (SEN)\nand specificity (SPE) under different conditions. Results: The default ChatGPT\n4o, with scene images as inputs, resulted in SEN and SPE values of 64.8% and\n75.9%, respectively. Instruction on how to respond to unanswerable questions\ndid not improve SEN substantially but SPE increased by around 14 percentage\npoints. SEN and SPE both improved substantially, by about 17 and 16 percentage\npoints on average respectively, when human written descriptions of the scenes\nwere provided as input instead of images. Providing further prompt instructions\nto the assistants when the input was text description did not substantially\nchange the SEN and SPE values. Conclusion: Current native ChatGPT 4o is still\nunable to provide correct micro-navigation guidance in some cases, probably\nbecause its scene understanding is not optimized for navigation purposes. If\nmulti-modal chatbots could interpret scenes with a level of clarity comparable\nto humans, and also guided by appropriate prompts, they may have the potential\nto provide assistance to visually impaired for micro-navigation.\n","subjects":["Computing Research Repository/Human-Computer Interaction","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/"}