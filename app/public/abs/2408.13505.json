{"id":"2408.13505","title":"AngleSizer: Enhancing Spatial Scale Perception for the Visually Impaired\n  with an Interactive Smartphone Assistant","authors":"Xiaoqing Jing, Chun Yu, Kun Yue, Liangyou Lu, Nan Gao, Weinan Shi,\n  Mingshan Zhang, Ruolin Wang, Yuanchun Shi","authorsParsed":[["Jing","Xiaoqing",""],["Yu","Chun",""],["Yue","Kun",""],["Lu","Liangyou",""],["Gao","Nan",""],["Shi","Weinan",""],["Zhang","Mingshan",""],["Wang","Ruolin",""],["Shi","Yuanchun",""]],"versions":[{"version":"v1","created":"Sat, 24 Aug 2024 07:37:05 GMT"}],"updateDate":"2024-08-27","timestamp":1724485025000,"abstract":"  Spatial perception, particularly at small and medium scales, is an essential\nhuman sense but poses a significant challenge for the blind and visually\nimpaired (BVI). Traditional learning methods for BVI individuals are often\nconstrained by the limited availability of suitable learning environments and\nhigh associated costs. To tackle these barriers, we conducted comprehensive\nstudies to delve into the real-world challenges faced by the BVI community. We\nhave identified several key factors hindering their spatial perception,\nincluding the high social cost of seeking assistance, inefficient methods of\ninformation intake, cognitive and behavioral disconnects, and a lack of\nopportunities for hands-on exploration. As a result, we developed AngleSizer,\nan innovative teaching assistant that leverages smartphone technology.\nAngleSizer is designed to enable BVI individuals to use natural interaction\ngestures to try, feel, understand, and learn about sizes and angles\neffectively. This tool incorporates dual vibration-audio feedback, carefully\ncrafted teaching processes, and specialized learning modules to enhance the\nlearning experience. Extensive user experiments validated its efficacy and\napplicability with diverse abilities and visual conditions. Ultimately, our\nresearch not only expands the understanding of BVI behavioral patterns but also\ngreatly improves their spatial perception capabilities, in a way that is both\ncost-effective and allows for independent learning.\n","subjects":["Computing Research Repository/Human-Computer Interaction"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}