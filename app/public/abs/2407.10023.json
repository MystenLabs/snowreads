{"id":"2407.10023","title":"Reproducibility of Issues Reported in Stack Overflow Questions:\n  Challenges, Impact & Estimation","authors":"Saikat Mondal and Banani Roy","authorsParsed":[["Mondal","Saikat",""],["Roy","Banani",""]],"versions":[{"version":"v1","created":"Sat, 13 Jul 2024 22:55:35 GMT"}],"updateDate":"2024-07-16","timestamp":1720911335000,"abstract":"  Software developers often submit questions to technical Q&A sites like Stack\nOverflow (SO) to resolve code-level problems. In practice, they include example\ncode snippets with questions to explain the programming issues. Existing\nresearch suggests that users attempt to reproduce the reported issues using\ngiven code snippets when answering questions. Unfortunately, such code snippets\ncould not always reproduce the issues due to several unmet challenges that\nprevent questions from receiving appropriate and prompt solutions. One previous\nstudy investigated reproducibility challenges and produced a catalog. However,\nhow the practitioners perceive this challenge catalog is unknown.\nPractitioners' perspectives are inevitable in validating these challenges and\nestimating their severity. This study first surveyed 53 practitioners to\nunderstand their perspectives on reproducibility challenges. We attempt to (a)\nsee whether they agree with these challenges, (b) determine the impact of each\nchallenge on answering questions, and (c) identify the need for tools to\npromote reproducibility. Survey results show that - (a) about 90% of the\nparticipants agree with the challenges, (b) \"missing an important part of code\"\nmost severely hurt reproducibility, and (c) participants strongly recommend\nintroducing automated tool support to promote reproducibility. Second, we\nextract \\emph{nine} code-based features (e.g., LOC, compilability) and build\nfive Machine Learning (ML) models to predict issue reproducibility. Early\ndetection might help users improve code snippets and their reproducibility. Our\nmodels achieve 84.5% precision, 83.0% recall, 82.8% F1-score, and 82.8% overall\naccuracy, which are highly promising. Third, we systematically interpret the ML\nmodel and explain how code snippets with reproducible issues differ from those\nwith irreproducible issues.\n","subjects":["Computing Research Repository/Software Engineering"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"1uBy2G4cWEQnnsI8RE68rZ6tBo0UhGnUHwyrUXbGUgU","pdfSize":"845734"}
