{"id":"2407.01461","title":"Enhancing the Capability and Robustness of Large Language Models through\n  Reinforcement Learning-Driven Query Refinement","authors":"Zisu Huang, Xiaohua Wang, Feiran Zhang, Zhibo Xu, Cenyuan Zhang,\n  Xiaoqing Zheng, Xuanjing Huang","authorsParsed":[["Huang","Zisu",""],["Wang","Xiaohua",""],["Zhang","Feiran",""],["Xu","Zhibo",""],["Zhang","Cenyuan",""],["Zheng","Xiaoqing",""],["Huang","Xuanjing",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 16:55:28 GMT"}],"updateDate":"2024-07-02","timestamp":1719852928000,"abstract":"  The capacity of large language models (LLMs) to generate honest, harmless,\nand helpful responses heavily relies on the quality of user prompts. However,\nthese prompts often tend to be brief and vague, thereby significantly limiting\nthe full potential of LLMs. Moreover, harmful prompts can be meticulously\ncrafted and manipulated by adversaries to jailbreak LLMs, inducing them to\nproduce potentially toxic content. To enhance the capabilities of LLMs while\nmaintaining strong robustness against harmful jailbreak inputs, this study\nproposes a transferable and pluggable framework that refines user prompts\nbefore they are input into LLMs. This strategy improves the quality of the\nqueries, empowering LLMs to generate more truthful, benign and useful\nresponses. Specifically, a lightweight query refinement model is introduced and\ntrained using a specially designed reinforcement learning approach that\nincorporates multiple objectives to enhance particular capabilities of LLMs.\nExtensive experiments demonstrate that the refinement model not only improves\nthe quality of responses but also strengthens their robustness against\njailbreak attacks. Code is available at:\nhttps://github.com/Huangzisu/query-refinement .\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"Ug2wAquQ--d2qaWUOhYptcs3r2dTUs2yIN5VaBBXAm4","pdfSize":"1167674","objectId":"0x20251d9d36105ad6ab654982aef44088aea1a001bdd598225dd559772de8807e","registeredEpoch":"3","certifiedEpoch":"3","startEpoch":"3","endEpoch":"203"}
