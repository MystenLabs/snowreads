{"id":"2407.04634","title":"A randomized small-block Lanczos method for large-scale null space\n  computations","authors":"Daniel Kressner and Nian Shao","authorsParsed":[["Kressner","Daniel",""],["Shao","Nian",""]],"versions":[{"version":"v1","created":"Fri, 5 Jul 2024 16:46:53 GMT"}],"updateDate":"2024-07-08","timestamp":1720198013000,"abstract":"  Computing the null space of a large sparse matrix $A$ is a challenging\ncomputational problem, especially if the nullity -- the dimension of the null\nspace -- is large. When using a block Lanczos method for this purpose,\nconventional wisdom suggests to use a block size $d$ that is not smaller than\nthe nullity. In this work, we show how randomness can be utilized to allow for\nsmaller $d$ without sacrificing convergence or reliability. Even $d = 1$,\ncorresponding to the standard single-vector Lanczos method, becomes a safe\nchoice. This is achieved by using a small random diagonal perturbation, which\nmoves the zero eigenvalues of $A^{\\mathsf{T}} A$ away from each other, and a\nrandom initial guess. We analyze the effect of the perturbation on the\nattainable quality of the null space and derive convergence results that\nestablish robust convergence for $d=1$. As demonstrated by our numerical\nexperiments, a smaller block size combined with restarting and partial\nreorthogonalization results in reduced memory requirements and computational\neffort. It also allows for the incremental computation of the null space,\nwithout requiring a priori knowledge of the nullity.\n","subjects":["Mathematics/Numerical Analysis","Computing Research Repository/Numerical Analysis"],"license":"http://creativecommons.org/licenses/by/4.0/"}