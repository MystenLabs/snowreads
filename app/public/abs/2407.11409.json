{"id":"2407.11409","title":"Representation Bias in Political Sample Simulations with Large Language\n  Models","authors":"Weihong Qi, Hanjia Lyu, Jiebo Luo","authorsParsed":[["Qi","Weihong",""],["Lyu","Hanjia",""],["Luo","Jiebo",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 05:52:26 GMT"}],"updateDate":"2024-07-17","timestamp":1721109146000,"abstract":"  This study seeks to identify and quantify biases in simulating political\nsamples with Large Language Models, specifically focusing on vote choice and\npublic opinion. Using the GPT-3.5-Turbo model, we leverage data from the\nAmerican National Election Studies, German Longitudinal Election Study, Zuobiao\nDataset, and China Family Panel Studies to simulate voting behaviors and public\nopinions. This methodology enables us to examine three types of representation\nbias: disparities based on the the country's language, demographic groups, and\npolitical regime types. The findings reveal that simulation performance is\ngenerally better for vote choice than for public opinions, more accurate in\nEnglish-speaking countries, more effective in bipartisan systems than in\nmulti-partisan systems, and stronger in democratic settings than in\nauthoritarian regimes. These results contribute to enhancing our understanding\nand developing strategies to mitigate biases in AI applications within the\nfield of computational social science.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}