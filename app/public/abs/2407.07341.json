{"id":"2407.07341","title":"MixSumm: Topic-based Data Augmentation using LLMs for Low-resource\n  Extractive Text Summarization","authors":"Gaurav Sahu, Issam H. Laradji","authorsParsed":[["Sahu","Gaurav",""],["Laradji","Issam H.",""]],"versions":[{"version":"v1","created":"Wed, 10 Jul 2024 03:25:47 GMT"}],"updateDate":"2024-07-11","timestamp":1720581947000,"abstract":"  Low-resource extractive text summarization is a vital but heavily\nunderexplored area of research. Prior literature either focuses on abstractive\ntext summarization or prompts a large language model (LLM) like GPT-3 directly\nto generate summaries. In this work, we propose MixSumm for low-resource\nextractive text summarization. Specifically, MixSumm prompts an open-source\nLLM, LLaMA-3-70b, to generate documents that mix information from multiple\ntopics as opposed to generating documents without mixup, and then trains a\nsummarization model on the generated dataset. We use ROUGE scores and L-Eval, a\nreference-free LLaMA-3-based evaluation method to measure the quality of\ngenerated summaries. We conduct extensive experiments on a challenging text\nsummarization benchmark comprising the TweetSumm, WikiHow, and ArXiv/PubMed\ndatasets and show that our LLM-based data augmentation framework outperforms\nrecent prompt-based approaches for low-resource extractive summarization.\nAdditionally, our results also demonstrate effective knowledge distillation\nfrom LLaMA-3-70b to a small BERT-based extractive summarizer.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"rolwMJYSo2HeA3UqNsk_pcKfrYLEZGb2KKH59V7w-DU","pdfSize":"1060421"}
