{"id":"2408.07637","title":"Hierarchical Working Memory and a New Magic Number","authors":"Weishun Zhong, Mikhail Katkov, Misha Tsodyks","authorsParsed":[["Zhong","Weishun",""],["Katkov","Mikhail",""],["Tsodyks","Misha",""]],"versions":[{"version":"v1","created":"Wed, 14 Aug 2024 16:03:47 GMT"}],"updateDate":"2024-08-15","timestamp":1723651427000,"abstract":"  The extremely limited working memory span, typically around four items,\ncontrasts sharply with our everyday experience of processing much larger\nstreams of sensory information concurrently. This disparity suggests that\nworking memory can organize information into compact representations such as\nchunks, yet the underlying neural mechanisms remain largely unknown. Here, we\npropose a recurrent neural network model for chunking within the framework of\nthe synaptic theory of working memory. We showed that by selectively\nsuppressing groups of stimuli, the network can maintain and retrieve the\nstimuli in chunks, hence exceeding the basic capacity. Moreover, we show that\nour model can dynamically construct hierarchical representations within working\nmemory through hierarchical chunking. A consequence of this proposed mechanism\nis a new limit on the number of items that can be stored and subsequently\nretrieved from working memory, depending only on the basic working memory\ncapacity when chunking is not invoked. Predictions from our model were\nconfirmed by analyzing single-unit responses in epileptic patients and memory\nexperiments with verbal material. Our work provides a novel conceptual and\nanalytical framework for understanding the on-the-fly organization of\ninformation in the brain that is crucial for cognition.\n","subjects":["Quantitative Biology/Neurons and Cognition","Condensed Matter/Disordered Systems and Neural Networks","Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}