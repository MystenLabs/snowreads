{"id":"2408.07340","title":"Towards Few-shot Self-explaining Graph Neural Networks","authors":"Jingyu Peng, Qi Liu, Linan Yue, Zaixi Zhang, Kai Zhang, Yunhao Sha","authorsParsed":[["Peng","Jingyu",""],["Liu","Qi",""],["Yue","Linan",""],["Zhang","Zaixi",""],["Zhang","Kai",""],["Sha","Yunhao",""]],"versions":[{"version":"v1","created":"Wed, 14 Aug 2024 07:31:11 GMT"}],"updateDate":"2024-08-15","timestamp":1723620671000,"abstract":"  Recent advancements in Graph Neural Networks (GNNs) have spurred an upsurge\nof research dedicated to enhancing the explainability of GNNs, particularly in\ncritical domains such as medicine. A promising approach is the self-explaining\nmethod, which outputs explanations along with predictions. However, existing\nself-explaining models require a large amount of training data, rendering them\nunavailable in few-shot scenarios. To address this challenge, in this paper, we\npropose a Meta-learned Self-Explaining GNN (MSE-GNN), a novel framework that\ngenerates explanations to support predictions in few-shot settings. MSE-GNN\nadopts a two-stage self-explaining structure, consisting of an explainer and a\npredictor. Specifically, the explainer first imitates the attention mechanism\nof humans to select the explanation subgraph, whereby attention is naturally\npaid to regions containing important characteristics. Subsequently, the\npredictor mimics the decision-making process, which makes predictions based on\nthe generated explanation. Moreover, with a novel meta-training process and a\ndesigned mechanism that exploits task information, MSE-GNN can achieve\nremarkable performance on new few-shot tasks. Extensive experimental results on\nfour datasets demonstrate that MSE-GNN can achieve superior performance on\nprediction tasks while generating high-quality explanations compared with\nexisting methods. The code is publicly available at\nhttps://github.com/jypeng28/MSE-GNN.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}