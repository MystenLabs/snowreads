{"id":"2407.05237","title":"Privacy of the last iterate in cyclically-sampled DP-SGD on nonconvex\n  composite losses","authors":"Weiwei Kong, M\\'onica Ribero","authorsParsed":[["Kong","Weiwei",""],["Ribero","MÃ³nica",""]],"versions":[{"version":"v1","created":"Sun, 7 Jul 2024 02:35:55 GMT"}],"updateDate":"2024-07-09","timestamp":1720319755000,"abstract":"  Differentially private stochastic gradient descent (DP-SGD) refers to a\nfamily of optimization algorithms that provide a guaranteed level of\ndifferential privacy (DP) through DP accounting techniques. However, current\naccounting techniques make assumptions that diverge significantly from\npractical DP-SGD implementations. For example, they may assume the loss\nfunction is Lipschitz continuous and convex, sample the batches randomly with\nreplacement, or omit the gradient clipping step.\n  In this work, we analyze the most commonly used variant of DP-SGD, in which\nwe sample batches cyclically with replacement, perform gradient clipping, and\nonly release the last DP-SGD iterate. More specifically - without assuming\nconvexity, smoothness, or Lipschitz continuity of the loss function - we\nestablish new R\\'enyi differential privacy (RDP) bounds for the last DP-SGD\niterate under the mild assumption that (i) the DP-SGD stepsize is small\nrelative to the topological constants in the loss function, and (ii) the loss\nfunction is weakly-convex. Moreover, we show that our bounds converge to\npreviously established convex bounds when the weak-convexity parameter of the\nobjective function approaches zero. In the case of non-Lipschitz smooth loss\nfunctions, we provide a weaker bound that scales well in terms of the number of\nDP-SGD iterations.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Cryptography and Security","Computing Research Repository/Data Structures and Algorithms","Mathematics/Optimization and Control","Statistics/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}