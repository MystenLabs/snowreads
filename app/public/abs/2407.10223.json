{"id":"2407.10223","title":"Practical Unlearning for Large Language Models","authors":"Chongyang Gao, Lixu Wang, Chenkai Weng, Xiao Wang, Qi Zhu","authorsParsed":[["Gao","Chongyang",""],["Wang","Lixu",""],["Weng","Chenkai",""],["Wang","Xiao",""],["Zhu","Qi",""]],"versions":[{"version":"v1","created":"Sun, 14 Jul 2024 14:26:17 GMT"}],"updateDate":"2024-07-16","timestamp":1720967177000,"abstract":"  While LLMs have demonstrated impressive performance across various domains\nand tasks, their security issues have become increasingly severe. Machine\nunlearning (MU) has emerged as a promising solution to address these issues by\nremoving the influence of undesired data on the target model without\ncompromising its utility in other aspects. MU typically assumes full access to\nthe original training data to preserve utility, which is difficult to achieve\nin LLM unlearning. Existing LLM unlearning methods often assume access to data\nmost affected by undesired data unlearning. However, this assumption\nunderestimates the entanglement among various LLM capabilities and ignores data\naccess limitations due to various issues. Moreover, these LLM unlearning\nmethods do not sufficiently consider that unlearning requests in real-world\nscenarios are continuously emerging. To overcome these challenges and achieve\npractical LLM unlearning, we propose the O3 framework. The O3 framework\nincludes an Out-Of-Distribution (OOD) detector to measure the similarity\nbetween input and unlearning data, and an Orthogonal low-rank adapter (LoRA)\nfor continuously unlearning requested data. The OOD detector is trained with a\nnovel contrastive entropy loss and utilizes a local-global layer-aggregated\nscoring mechanism. The orthogonal LoRA achieves parameter disentanglement among\ncontinual unlearning requests. During inference, our O3 framework can smartly\ndecide whether and to what extent to load the unlearning LoRA based on the OOD\ndetector's predictions. Notably, O3's effectiveness does not rely on any\nretained data. We conducted extensive experiments on O3 and state-of-the-art\nLLM unlearning methods across three tasks and seven datasets. The results\nindicate that O3 consistently achieves the best trade-off between unlearning\neffectiveness and utility preservation, especially when facing continuous\nunlearning requests.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Cryptography and Security"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}