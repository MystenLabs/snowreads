{"id":"2407.15626","title":"Reinforcement Learning Meets Visual Odometry","authors":"Nico Messikommer and Giovanni Cioffi and Mathias Gehrig and Davide\n  Scaramuzza","authorsParsed":[["Messikommer","Nico",""],["Cioffi","Giovanni",""],["Gehrig","Mathias",""],["Scaramuzza","Davide",""]],"versions":[{"version":"v1","created":"Mon, 22 Jul 2024 13:37:55 GMT"}],"updateDate":"2024-07-23","timestamp":1721655475000,"abstract":"  Visual Odometry (VO) is essential to downstream mobile robotics and\naugmented/virtual reality tasks. Despite recent advances, existing VO methods\nstill rely on heuristic design choices that require several weeks of\nhyperparameter tuning by human experts, hindering generalizability and\nrobustness. We address these challenges by reframing VO as a sequential\ndecision-making task and applying Reinforcement Learning (RL) to adapt the VO\nprocess dynamically. Our approach introduces a neural network, operating as an\nagent within the VO pipeline, to make decisions such as keyframe and grid-size\nselection based on real-time conditions. Our method minimizes reliance on\nheuristic choices using a reward function based on pose error, runtime, and\nother metrics to guide the system. Our RL framework treats the VO system and\nthe image sequence as an environment, with the agent receiving observations\nfrom keypoints, map statistics, and prior poses. Experimental results using\nclassical VO methods and public benchmarks demonstrate improvements in accuracy\nand robustness, validating the generalizability of our RL-enhanced VO approach\nto different scenarios. We believe this paradigm shift advances VO technology\nby eliminating the need for time-intensive parameter tuning of heuristics.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Robotics"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}