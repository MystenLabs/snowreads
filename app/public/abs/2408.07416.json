{"id":"2408.07416","title":"Rethinking Open-Vocabulary Segmentation of Radiance Fields in 3D Space","authors":"Hyunjee Lee, Youngsik Yun, Jeongmin Bae, Seoha Kim, Youngjung Uh","authorsParsed":[["Lee","Hyunjee",""],["Yun","Youngsik",""],["Bae","Jeongmin",""],["Kim","Seoha",""],["Uh","Youngjung",""]],"versions":[{"version":"v1","created":"Wed, 14 Aug 2024 09:50:02 GMT"},{"version":"v2","created":"Sun, 18 Aug 2024 04:22:30 GMT"}],"updateDate":"2024-08-20","timestamp":1723629002000,"abstract":"  Understanding the 3D semantics of a scene is a fundamental problem for\nvarious scenarios such as embodied agents. While NeRFs and 3DGS excel at\nnovel-view synthesis, previous methods for understanding their semantics have\nbeen limited to incomplete 3D understanding: their segmentation results are 2D\nmasks and their supervision is anchored at 2D pixels. This paper revisits the\nproblem set to pursue a better 3D understanding of a scene modeled by NeRFs and\n3DGS as follows. 1) We directly supervise the 3D points to train the language\nembedding field. It achieves state-of-the-art accuracy without relying on\nmulti-scale language embeddings. 2) We transfer the pre-trained language field\nto 3DGS, achieving the first real-time rendering speed without sacrificing\ntraining time or accuracy. 3) We introduce a 3D querying and evaluation\nprotocol for assessing the reconstructed geometry and semantics together. Code,\ncheckpoints, and annotations will be available online. Project page:\nhttps://hyunji12.github.io/Open3DRF\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"GjJs3JMubGwMdkOgIGwmlUCQL2VhrO0klApczyZ3edQ","pdfSize":"12681025"}
