{"id":"2407.20228","title":"FlexAttention for Efficient High-Resolution Vision-Language Models","authors":"Junyan Li, Delin Chen, Tianle Cai, Peihao Chen, Yining Hong, Zhenfang\n  Chen, Yikang Shen, and Chuang Gan","authorsParsed":[["Li","Junyan",""],["Chen","Delin",""],["Cai","Tianle",""],["Chen","Peihao",""],["Hong","Yining",""],["Chen","Zhenfang",""],["Shen","Yikang",""],["Gan","Chuang",""]],"versions":[{"version":"v1","created":"Mon, 29 Jul 2024 17:59:05 GMT"}],"updateDate":"2024-07-30","timestamp":1722275945000,"abstract":"  Current high-resolution vision-language models encode images as\nhigh-resolution image tokens and exhaustively take all these tokens to compute\nattention, which significantly increases the computational cost. To address\nthis problem, we propose FlexAttention, a flexible attention mechanism for\nefficient high-resolution vision-language models. Specifically, a\nhigh-resolution image is encoded both as high-resolution tokens and\nlow-resolution tokens, where only the low-resolution tokens and a few selected\nhigh-resolution tokens are utilized to calculate the attention map, which\ngreatly shrinks the computational cost. The high-resolution tokens are selected\nvia a high-resolution selection module which could retrieve tokens of relevant\nregions based on an input attention map. The selected high-resolution tokens\nare then concatenated to the low-resolution tokens and text tokens, and input\nto a hierarchical self-attention layer which produces an attention map that\ncould be used for the next-step high-resolution token selection. The\nhierarchical self-attention process and high-resolution token selection process\nare performed iteratively for each attention layer. Experiments on multimodal\nbenchmarks prove that our FlexAttention outperforms existing high-resolution\nVLMs (e.g., relatively ~9% in V* Bench, ~7% in TextVQA), while also\nsignificantly reducing the computational cost by nearly 40%.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"Yrrl53Lhrhlu_oJt-ngcVTJWO2pzfSGzOVvXsosE-QE","pdfSize":"1278585","objectId":"0xa7786a38d4efe4c3a29040a4b1d41118f0c4547e609f8b9018a71524abe28efe","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
