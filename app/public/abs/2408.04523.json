{"id":"2408.04523","title":"Depth Any Canopy: Leveraging Depth Foundation Models for Canopy Height\n  Estimation","authors":"Daniele Rege Cambrin, Isaac Corley, Paolo Garza","authorsParsed":[["Cambrin","Daniele Rege",""],["Corley","Isaac",""],["Garza","Paolo",""]],"versions":[{"version":"v1","created":"Thu, 8 Aug 2024 15:24:07 GMT"}],"updateDate":"2024-08-09","timestamp":1723130647000,"abstract":"  Estimating global tree canopy height is crucial for forest conservation and\nclimate change applications. However, capturing high-resolution ground truth\ncanopy height using LiDAR is expensive and not available globally. An efficient\nalternative is to train a canopy height estimator to operate on single-view\nremotely sensed imagery. The primary obstacle to this approach is that these\nmethods require significant training data to generalize well globally and\nacross uncommon edge cases. Recent monocular depth estimation foundation models\nhave show strong zero-shot performance even for complex scenes. In this paper\nwe leverage the representations learned by these models to transfer to the\nremote sensing domain for measuring canopy height. Our findings suggest that\nour proposed Depth Any Canopy, the result of fine-tuning the Depth Anything v2\nmodel for canopy height estimation, provides a performant and efficient\nsolution, surpassing the current state-of-the-art with superior or comparable\nperformance using only a fraction of the computational resources and\nparameters. Furthermore, our approach requires less than \\$1.30 in compute and\nresults in an estimated carbon footprint of 0.14 kgCO2. Code, experimental\nresults, and model checkpoints are openly available at\nhttps://github.com/DarthReca/depth-any-canopy.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}