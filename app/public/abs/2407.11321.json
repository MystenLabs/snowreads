{"id":"2407.11321","title":"TCFormer: Visual Recognition via Token Clustering Transformer","authors":"Wang Zeng, Sheng Jin, Lumin Xu, Wentao Liu, Chen Qian, Wanli Ouyang,\n  Ping Luo, Xiaogang Wang","authorsParsed":[["Zeng","Wang",""],["Jin","Sheng",""],["Xu","Lumin",""],["Liu","Wentao",""],["Qian","Chen",""],["Ouyang","Wanli",""],["Luo","Ping",""],["Wang","Xiaogang",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 02:26:18 GMT"}],"updateDate":"2024-07-17","timestamp":1721096778000,"abstract":"  Transformers are widely used in computer vision areas and have achieved\nremarkable success. Most state-of-the-art approaches split images into regular\ngrids and represent each grid region with a vision token. However, fixed token\ndistribution disregards the semantic meaning of different image regions,\nresulting in sub-optimal performance. To address this issue, we propose the\nToken Clustering Transformer (TCFormer), which generates dynamic vision tokens\nbased on semantic meaning. Our dynamic tokens possess two crucial\ncharacteristics: (1) Representing image regions with similar semantic meanings\nusing the same vision token, even if those regions are not adjacent, and (2)\nconcentrating on regions with valuable details and represent them using fine\ntokens. Through extensive experimentation across various applications,\nincluding image classification, human pose estimation, semantic segmentation,\nand object detection, we demonstrate the effectiveness of our TCFormer. The\ncode and models for this work are available at\nhttps://github.com/zengwang430521/TCFormer.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}