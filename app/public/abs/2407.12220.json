{"id":"2407.12220","title":"Questionable practices in machine learning","authors":"Gavin Leech, Juan J. Vazquez, Misha Yagudin, Niclas Kupper, Laurence\n  Aitchison","authorsParsed":[["Leech","Gavin",""],["Vazquez","Juan J.",""],["Yagudin","Misha",""],["Kupper","Niclas",""],["Aitchison","Laurence",""]],"versions":[{"version":"v1","created":"Wed, 17 Jul 2024 00:06:30 GMT"}],"updateDate":"2024-07-18","timestamp":1721174790000,"abstract":"  Evaluating modern ML models is hard. The strong incentive for researchers and\ncompanies to report a state-of-the-art result on some metric often leads to\nquestionable research practices (QRPs): bad practices which fall short of\noutright research fraud. We describe 43 such practices which can undermine\nreported results, giving examples where possible. Our list emphasises the\nevaluation of large language models (LLMs) on public benchmarks. We also\ndiscuss \"irreproducible research practices\", i.e. decisions that make it\ndifficult or impossible for other researchers to reproduce, build on or audit\nprevious research.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Computation and Language","Computing Research Repository/Computers and Society"],"license":"http://creativecommons.org/licenses/by/4.0/"}