{"id":"2408.11943","title":"Advances in Preference-based Reinforcement Learning: A Review","authors":"Youssef Abdelkareem, Shady Shehata, Fakhri Karray","authorsParsed":[["Abdelkareem","Youssef",""],["Shehata","Shady",""],["Karray","Fakhri",""]],"versions":[{"version":"v1","created":"Wed, 21 Aug 2024 18:57:12 GMT"}],"updateDate":"2024-08-23","timestamp":1724266632000,"abstract":"  Reinforcement Learning (RL) algorithms suffer from the dependency on\naccurately engineered reward functions to properly guide the learning agents to\ndo the required tasks. Preference-based reinforcement learning (PbRL) addresses\nthat by utilizing human preferences as feedback from the experts instead of\nnumeric rewards. Due to its promising advantage over traditional RL, PbRL has\ngained more focus in recent years with many significant advances. In this\nsurvey, we present a unified PbRL framework to include the newly emerging\napproaches that improve the scalability and efficiency of PbRL. In addition, we\ngive a detailed overview of the theoretical guarantees and benchmarking work\ndone in the field, while presenting its recent applications in complex\nreal-world tasks. Lastly, we go over the limitations of the current approaches\nand the proposed future research directions.\n","subjects":["Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/"}