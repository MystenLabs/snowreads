{"id":"2407.19472","title":"Combined CNN and ViT features off-the-shelf: Another astounding baseline\n  for recognition","authors":"Fernando Alonso-Fernandez, Kevin Hernandez-Diaz, Prayag Tiwari, Josef\n  Bigun","authorsParsed":[["Alonso-Fernandez","Fernando",""],["Hernandez-Diaz","Kevin",""],["Tiwari","Prayag",""],["Bigun","Josef",""]],"versions":[{"version":"v1","created":"Sun, 28 Jul 2024 11:52:36 GMT"}],"updateDate":"2024-07-30","timestamp":1722167556000,"abstract":"  We apply pre-trained architectures, originally developed for the ImageNet\nLarge Scale Visual Recognition Challenge, for periocular recognition. These\narchitectures have demonstrated significant success in various computer vision\ntasks beyond the ones for which they were designed. This work builds on our\nprevious study using off-the-shelf Convolutional Neural Network (CNN) and\nextends it to include the more recently proposed Vision Transformers (ViT).\nDespite being trained for generic object classification, middle-layer features\nfrom CNNs and ViTs are a suitable way to recognize individuals based on\nperiocular images. We also demonstrate that CNNs and ViTs are highly\ncomplementary since their combination results in boosted accuracy. In addition,\nwe show that a small portion of these pre-trained models can achieve good\naccuracy, resulting in thinner models with fewer parameters, suitable for\nresource-limited environments such as mobiles. This efficiency improves if\ntraditional handcrafted features are added as well.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}