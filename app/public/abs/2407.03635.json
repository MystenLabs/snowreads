{"id":"2407.03635","title":"MRIR: Integrating Multimodal Insights for Diffusion-based Realistic\n  Image Restoration","authors":"Yuhong Zhang, Hengsheng Zhang, Xinning Chai, Rong Xie, Li Song, Wenjun\n  Zhang","authorsParsed":[["Zhang","Yuhong",""],["Zhang","Hengsheng",""],["Chai","Xinning",""],["Xie","Rong",""],["Song","Li",""],["Zhang","Wenjun",""]],"versions":[{"version":"v1","created":"Thu, 4 Jul 2024 04:55:14 GMT"}],"updateDate":"2024-07-08","timestamp":1720068914000,"abstract":"  Realistic image restoration is a crucial task in computer vision, and the use\nof diffusion-based models for image restoration has garnered significant\nattention due to their ability to produce realistic results. However, the\nquality of the generated images is still a significant challenge due to the\nseverity of image degradation and the uncontrollability of the diffusion model.\nIn this work, we delve into the potential of utilizing pre-trained stable\ndiffusion for image restoration and propose MRIR, a diffusion-based restoration\nmethod with multimodal insights. Specifically, we explore the problem from two\nperspectives: textual level and visual level. For the textual level, we harness\nthe power of the pre-trained multimodal large language model to infer\nmeaningful semantic information from low-quality images. Furthermore, we employ\nthe CLIP image encoder with a designed Refine Layer to capture image details as\na supplement. For the visual level, we mainly focus on the pixel level control.\nThus, we utilize a Pixel-level Processor and ControlNet to control spatial\nstructures. Finally, we integrate the aforementioned control information into\nthe denoising U-Net using multi-level attention mechanisms and realize\ncontrollable image restoration with multimodal insights. The qualitative and\nquantitative results demonstrate our method's superiority over other\nstate-of-the-art methods on both synthetic and real-world datasets.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}