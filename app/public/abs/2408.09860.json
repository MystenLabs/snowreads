{"id":"2408.09860","title":"3D-Aware Instance Segmentation and Tracking in Egocentric Videos","authors":"Yash Bhalgat, Vadim Tschernezki, Iro Laina, Jo\\~ao F. Henriques,\n  Andrea Vedaldi, Andrew Zisserman","authorsParsed":[["Bhalgat","Yash",""],["Tschernezki","Vadim",""],["Laina","Iro",""],["Henriques","Jo√£o F.",""],["Vedaldi","Andrea",""],["Zisserman","Andrew",""]],"versions":[{"version":"v1","created":"Mon, 19 Aug 2024 10:08:25 GMT"}],"updateDate":"2024-08-20","timestamp":1724062105000,"abstract":"  Egocentric videos present unique challenges for 3D scene understanding due to\nrapid camera motion, frequent object occlusions, and limited object visibility.\nThis paper introduces a novel approach to instance segmentation and tracking in\nfirst-person video that leverages 3D awareness to overcome these obstacles. Our\nmethod integrates scene geometry, 3D object centroid tracking, and instance\nsegmentation to create a robust framework for analyzing dynamic egocentric\nscenes. By incorporating spatial and temporal cues, we achieve superior\nperformance compared to state-of-the-art 2D approaches. Extensive evaluations\non the challenging EPIC Fields dataset demonstrate significant improvements\nacross a range of tracking and segmentation consistency metrics. Specifically,\nour method outperforms the next best performing approach by $7$ points in\nAssociation Accuracy (AssA) and $4.5$ points in IDF1 score, while reducing the\nnumber of ID switches by $73\\%$ to $80\\%$ across various object categories.\nLeveraging our tracked instance segmentations, we showcase downstream\napplications in 3D object reconstruction and amodal video object segmentation\nin these egocentric settings.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}