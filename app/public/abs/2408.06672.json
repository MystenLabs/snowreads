{"id":"2408.06672","title":"Leveraging Priors via Diffusion Bridge for Time Series Generation","authors":"Jinseong Park, Seungyun Lee, Woojin Jeong, Yujin Choi, Jaewook Lee","authorsParsed":[["Park","Jinseong",""],["Lee","Seungyun",""],["Jeong","Woojin",""],["Choi","Yujin",""],["Lee","Jaewook",""]],"versions":[{"version":"v1","created":"Tue, 13 Aug 2024 06:47:59 GMT"}],"updateDate":"2024-08-14","timestamp":1723531679000,"abstract":"  Time series generation is widely used in real-world applications such as\nsimulation, data augmentation, and hypothesis test techniques. Recently,\ndiffusion models have emerged as the de facto approach for time series\ngeneration, emphasizing diverse synthesis scenarios based on historical or\ncorrelated time series data streams. Since time series have unique\ncharacteristics, such as fixed time order and data scaling, standard Gaussian\nprior might be ill-suited for general time series generation. In this paper, we\nexploit the usage of diverse prior distributions for synthesis. Then, we\npropose TimeBridge, a framework that enables flexible synthesis by leveraging\ndiffusion bridges to learn the transport between chosen prior and data\ndistributions. Our model covers a wide range of scenarios in time series\ndiffusion models, which leverages (i) data- and time-dependent priors for\nunconditional synthesis, and (ii) data-scale preserving synthesis with a\nconstraint as a prior for conditional generation. Experimentally, our model\nachieves state-of-the-art performance in both unconditional and conditional\ntime series generation tasks.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}