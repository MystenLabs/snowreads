{"id":"2408.02103","title":"Effective Demonstration Annotation for In-Context Learning via Language\n  Model-Based Determinantal Point Process","authors":"Peng Wang, Xiaobin Wang, Chao Lou, Shengyu Mao, Pengjun Xie, Yong\n  Jiang","authorsParsed":[["Wang","Peng",""],["Wang","Xiaobin",""],["Lou","Chao",""],["Mao","Shengyu",""],["Xie","Pengjun",""],["Jiang","Yong",""]],"versions":[{"version":"v1","created":"Sun, 4 Aug 2024 18:08:15 GMT"}],"updateDate":"2024-08-06","timestamp":1722794895000,"abstract":"  In-context learning (ICL) is a few-shot learning paradigm that involves\nlearning mappings through input-output pairs and appropriately applying them to\nnew instances. Despite the remarkable ICL capabilities demonstrated by Large\nLanguage Models (LLMs), existing works are highly dependent on large-scale\nlabeled support sets, not always feasible in practical scenarios. To refine\nthis approach, we focus primarily on an innovative selective annotation\nmechanism, which precedes the standard demonstration retrieval. We introduce\nthe Language Model-based Determinant Point Process (LM-DPP) that simultaneously\nconsiders the uncertainty and diversity of unlabeled instances for optimal\nselection. Consequently, this yields a subset for annotation that strikes a\ntrade-off between the two factors. We apply LM-DPP to various language models,\nincluding GPT-J, LlaMA, and GPT-3. Experimental results on 9 NLU and 2\nGeneration datasets demonstrate that LM-DPP can effectively select canonical\nexamples. Further analysis reveals that LLMs benefit most significantly from\nsubsets that are both low uncertainty and high diversity.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"CAMkwFpst32qe-9ra9qVbXFoeSHzvj0BKXaLaN5PtLA","pdfSize":"2469740"}
