{"id":"2407.19510","title":"EPD: Long-term Memory Extraction, Context-awared Planning and\n  Multi-iteration Decision @ EgoPlan Challenge ICML 2024","authors":"Letian Shi, Qi Lv, Xiang Deng, Liqiang Nie","authorsParsed":[["Shi","Letian",""],["Lv","Qi",""],["Deng","Xiang",""],["Nie","Liqiang",""]],"versions":[{"version":"v1","created":"Sun, 28 Jul 2024 15:14:07 GMT"}],"updateDate":"2024-07-30","timestamp":1722179647000,"abstract":"  In this technical report, we present our solution for the EgoPlan Challenge\nin ICML 2024. To address the real-world egocentric task planning problem, we\nintroduce a novel planning framework which comprises three stages: long-term\nmemory Extraction, context-awared Planning, and multi-iteration Decision, named\nEPD. Given the task goal, task progress, and current observation, the\nextraction model first extracts task-relevant memory information from the\nprogress video, transforming the complex long video into summarized memory\ninformation. The planning model then combines the context of the memory\ninformation with fine-grained visual information from the current observation\nto predict the next action. Finally, through multi-iteration decision-making,\nthe decision model comprehensively understands the task situation and current\nstate to make the most realistic planning decision. On the EgoPlan-Test set,\nEPD achieves a planning accuracy of 53.85% over 1,584 egocentric task planning\nquestions. We have made all codes available at https://github.com/Kkskkkskr/EPD .\n","subjects":["Computing Research Repository/Robotics","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}