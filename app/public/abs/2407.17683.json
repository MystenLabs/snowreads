{"id":"2407.17683","title":"RL-augmented MPC Framework for Agile and Robust Bipedal Footstep\n  Locomotion Planning and Control","authors":"Seung Hyeon Bang, Carlos Arribalzaga Jov\\'e, Luis Sentis","authorsParsed":[["Bang","Seung Hyeon",""],["Jov√©","Carlos Arribalzaga",""],["Sentis","Luis",""]],"versions":[{"version":"v1","created":"Thu, 25 Jul 2024 00:51:19 GMT"}],"updateDate":"2024-07-26","timestamp":1721868679000,"abstract":"  This paper proposes an online bipedal footstep planning strategy that\ncombines model predictive control (MPC) and reinforcement learning (RL) to\nachieve agile and robust bipedal maneuvers. While MPC-based foot placement\ncontrollers have demonstrated their effectiveness in achieving dynamic\nlocomotion, their performance is often limited by the use of simplified models\nand assumptions. To address this challenge, we develop a novel foot placement\ncontroller that leverages a learned policy to bridge the gap between the use of\na simplified model and the more complex full-order robot system. Specifically,\nour approach employs a unique combination of an ALIP-based MPC foot placement\ncontroller for sub-optimal footstep planning and the learned policy for\nrefining footstep adjustments, enabling the resulting footstep policy to\ncapture the robot's whole-body dynamics effectively. This integration\nsynergizes the predictive capability of MPC with the flexibility and\nadaptability of RL. We validate the effectiveness of our framework through a\nseries of experiments using the full-body humanoid robot DRACO 3. The results\ndemonstrate significant improvements in dynamic locomotion performance,\nincluding better tracking of a wide range of walking speeds, enabling reliable\nturning and traversing challenging terrains while preserving the robustness and\nstability of the walking gaits compared to the baseline ALIP-based MPC\napproach.\n","subjects":["Computing Research Repository/Robotics"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}