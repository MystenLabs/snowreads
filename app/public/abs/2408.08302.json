{"id":"2408.08302","title":"Benchmarking the Capabilities of Large Language Models in Transportation\n  System Engineering: Accuracy, Consistency, and Reasoning Behaviors","authors":"Usman Syed, Ethan Light, Xingang Guo, Huan Zhang, Lianhui Qin, Yanfeng\n  Ouyang, Bin Hu","authorsParsed":[["Syed","Usman",""],["Light","Ethan",""],["Guo","Xingang",""],["Zhang","Huan",""],["Qin","Lianhui",""],["Ouyang","Yanfeng",""],["Hu","Bin",""]],"versions":[{"version":"v1","created":"Thu, 15 Aug 2024 17:55:45 GMT"}],"updateDate":"2024-08-16","timestamp":1723744545000,"abstract":"  In this paper, we explore the capabilities of state-of-the-art large language\nmodels (LLMs) such as GPT-4, GPT-4o, Claude 3.5 Sonnet, Claude 3 Opus, Gemini\n1.5 Pro, Llama 3, and Llama 3.1 in solving some selected undergraduate-level\ntransportation engineering problems. We introduce TransportBench, a benchmark\ndataset that includes a sample of transportation engineering problems on a wide\nrange of subjects in the context of planning, design, management, and control\nof transportation systems. This dataset is used by human experts to evaluate\nthe capabilities of various commercial and open-sourced LLMs, especially their\naccuracy, consistency, and reasoning behaviors, in solving transportation\nengineering problems. Our comprehensive analysis uncovers the unique strengths\nand limitations of each LLM, e.g. our analysis shows the impressive accuracy\nand some unexpected inconsistent behaviors of Claude 3.5 Sonnet in solving\nTransportBench problems. Our study marks a thrilling first step toward\nharnessing artificial general intelligence for complex transportation\nchallenges.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}