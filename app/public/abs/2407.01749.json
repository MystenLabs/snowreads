{"id":"2407.01749","title":"Invariant Correlation of Representation with Label","authors":"Gaojie Jin, Ronghui Mu, Xinping Yi, Xiaowei Huang, Lijun Zhang","authorsParsed":[["Jin","Gaojie",""],["Mu","Ronghui",""],["Yi","Xinping",""],["Huang","Xiaowei",""],["Zhang","Lijun",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 19:27:28 GMT"}],"updateDate":"2024-07-03","timestamp":1719862048000,"abstract":"  The Invariant Risk Minimization (IRM) approach aims to address the challenge\nof domain generalization by training a feature representation that remains\ninvariant across multiple environments. However, in noisy environments,\nIRM-related techniques such as IRMv1 and VREx may be unable to achieve the\noptimal IRM solution, primarily due to erroneous optimization directions. To\naddress this issue, we introduce ICorr (an abbreviation for \\textbf{I}nvariant\n\\textbf{Corr}elation), a novel approach designed to surmount the above\nchallenge in noisy settings. Additionally, we dig into a case study to analyze\nwhy previous methods may lose ground while ICorr can succeed. Through a\ntheoretical lens, particularly from a causality perspective, we illustrate that\nthe invariant correlation of representation with label is a necessary condition\nfor the optimal invariant predictor in noisy environments, whereas the\noptimization motivations for other methods may not be. Furthermore, we\nempirically demonstrate the effectiveness of ICorr by comparing it with other\ndomain generalization methods on various noisy datasets.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}