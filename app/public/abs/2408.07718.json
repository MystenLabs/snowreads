{"id":"2408.07718","title":"Impact of Inaccurate Contamination Ratio on Robust Unsupervised Anomaly\n  Detection","authors":"Jordan F. Masakuna, DJeff Kanda Nkashama, Arian Soltani, Marc\n  Frappier, Pierre-Martin Tardif and Froduald Kabanza","authorsParsed":[["Masakuna","Jordan F.",""],["Nkashama","DJeff Kanda",""],["Soltani","Arian",""],["Frappier","Marc",""],["Tardif","Pierre-Martin",""],["Kabanza","Froduald",""]],"versions":[{"version":"v1","created":"Wed, 14 Aug 2024 08:49:41 GMT"}],"updateDate":"2024-08-16","timestamp":1723625381000,"abstract":"  Training data sets intended for unsupervised anomaly detection, typically\npresumed to be anomaly-free, often contain anomalies (or contamination), a\nchallenge that significantly undermines model performance. Most robust\nunsupervised anomaly detection models rely on contamination ratio information\nto tackle contamination. However, in reality, contamination ratio may be\ninaccurate. We investigate on the impact of inaccurate contamination ratio\ninformation in robust unsupervised anomaly detection. We verify whether they\nare resilient to misinformed contamination ratios. Our investigation on 6\nbenchmark data sets reveals that such models are not adversely affected by\nexposure to misinformation. In fact, they can exhibit improved performance when\nprovided with such inaccurate contamination ratios.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/"}