{"id":"2408.06102","title":"Contexts Matter: An Empirical Study on Contextual Influence in Fairness\n  Testing for Deep Learning Systems","authors":"Chengwen Du, Tao Chen","authorsParsed":[["Du","Chengwen",""],["Chen","Tao",""]],"versions":[{"version":"v1","created":"Mon, 12 Aug 2024 12:36:06 GMT"}],"updateDate":"2024-08-13","timestamp":1723466166000,"abstract":"  Background: Fairness testing for deep learning systems has been becoming\nincreasingly important. However, much work assumes perfect context and\nconditions from the other parts: well-tuned hyperparameters for accuracy;\nrectified bias in data, and mitigated bias in the labeling. Yet, these are\noften difficult to achieve in practice due to their resource-/labour-intensive\nnature. Aims: In this paper, we aim to understand how varying contexts affect\nfairness testing outcomes. Method:We conduct an extensive empirical study,\nwhich covers $10,800$ cases, to investigate how contexts can change the\nfairness testing result at the model level against the existing assumptions. We\nalso study why the outcomes were observed from the lens of correlation/fitness\nlandscape analysis. Results: Our results show that different context types and\nsettings generally lead to a significant impact on the testing, which is mainly\ncaused by the shifts of the fitness landscape under varying contexts.\nConclusions: Our findings provide key insights for practitioners to evaluate\nthe test generators and hint at future research directions.\n","subjects":["Computing Research Repository/Software Engineering","Computing Research Repository/Computers and Society","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"CzU8qaHE-XKG1NlO1HgLjOkcK6bSyPQT9RAtGF6zrBo","pdfSize":"1457620"}
