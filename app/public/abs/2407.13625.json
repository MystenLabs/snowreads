{"id":"2407.13625","title":"Distributionally and Adversarially Robust Logistic Regression via\n  Intersecting Wasserstein Balls","authors":"Aras Selvi, Eleonora Kreacic, Mohsen Ghassemi, Vamsi Potluru, Tucker\n  Balch, Manuela Veloso","authorsParsed":[["Selvi","Aras",""],["Kreacic","Eleonora",""],["Ghassemi","Mohsen",""],["Potluru","Vamsi",""],["Balch","Tucker",""],["Veloso","Manuela",""]],"versions":[{"version":"v1","created":"Thu, 18 Jul 2024 15:59:37 GMT"}],"updateDate":"2024-07-19","timestamp":1721318377000,"abstract":"  Empirical risk minimization often fails to provide robustness against\nadversarial attacks in test data, causing poor out-of-sample performance.\nAdversarially robust optimization (ARO) has thus emerged as the de facto\nstandard for obtaining models that hedge against such attacks. However, while\nthese models are robust against adversarial attacks, they tend to suffer\nseverely from overfitting. To address this issue for logistic regression, we\nstudy the Wasserstein distributionally robust (DR) counterpart of ARO and show\nthat this problem admits a tractable reformulation. Furthermore, we develop a\nframework to reduce the conservatism of this problem by utilizing an auxiliary\ndataset (e.g., synthetic, external, or out-of-domain data), whenever available,\nwith instances independently sampled from a nonidentical but related ground\ntruth. In particular, we intersect the ambiguity set of the DR problem with\nanother Wasserstein ambiguity set that is built using the auxiliary dataset. We\nanalyze the properties of the underlying optimization problem, develop\nefficient solution algorithms, and demonstrate that the proposed method\nconsistently outperforms benchmark approaches on real-world datasets.\n","subjects":["Mathematics/Optimization and Control","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}