{"id":"2407.02793","title":"Learning Positional Attention for Sequential Recommendation","authors":"Fan Luo, Juan Zhang, Shenghui Xu","authorsParsed":[["Luo","Fan",""],["Zhang","Juan",""],["Xu","Shenghui",""]],"versions":[{"version":"v1","created":"Wed, 3 Jul 2024 03:42:13 GMT"}],"updateDate":"2024-07-04","timestamp":1719978133000,"abstract":"  Self-attention-based networks have achieved remarkable performance in\nsequential recommendation tasks. A crucial component of these models is\npositional encoding. In this study, we delve into the learned positional\nembedding, demonstrating that it often captures the distance between tokens.\nBuilding on this insight, we introduce novel attention models that directly\nlearn positional relations. Extensive experiments reveal that our proposed\nmodels, \\textbf{PARec} and \\textbf{FPARec} outperform previous\nself-attention-based approaches.Our code is available at the link for anonymous\nreview: https://anonymous.4open.science/ r/FPARec-2C55/\n","subjects":["Computing Research Repository/Information Retrieval","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}