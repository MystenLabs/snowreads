{"id":"2408.04680","title":"Dynamic Fog Computing for Enhanced LLM Execution in Medical Applications","authors":"Philipp Zagar, Vishnu Ravi, Lauren Aalami, Stephan Krusche, Oliver\n  Aalami, Paul Schmiedmayer","authorsParsed":[["Zagar","Philipp",""],["Ravi","Vishnu",""],["Aalami","Lauren",""],["Krusche","Stephan",""],["Aalami","Oliver",""],["Schmiedmayer","Paul",""]],"versions":[{"version":"v1","created":"Thu, 8 Aug 2024 04:49:21 GMT"}],"updateDate":"2024-08-12","timestamp":1723092561000,"abstract":"  The ability of large language models (LLMs) to transform, interpret, and\ncomprehend vast quantities of heterogeneous data presents a significant\nopportunity to enhance data-driven care delivery. However, the sensitive nature\nof protected health information (PHI) raises valid concerns about data privacy\nand trust in remote LLM platforms. In addition, the cost associated with\ncloud-based artificial intelligence (AI) services continues to impede\nwidespread adoption. To address these challenges, we propose a shift in the LLM\nexecution environment from opaque, centralized cloud providers to a\ndecentralized and dynamic fog computing architecture. By executing open-weight\nLLMs in more trusted environments, such as the user's edge device or a fog\nlayer within a local network, we aim to mitigate the privacy, trust, and\nfinancial challenges associated with cloud-based LLMs. We further present\nSpeziLLM, an open-source framework designed to facilitate rapid and seamless\nleveraging of different LLM execution layers and lowering barriers to LLM\nintegration in digital health applications. We demonstrate SpeziLLM's broad\napplicability across six digital health applications, showcasing its\nversatility in various healthcare settings.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Cryptography and Security"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}