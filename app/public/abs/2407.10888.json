{"id":"2407.10888","title":"Leveraging Multimodal CycleGAN for the Generation of Anatomically\n  Accurate Synthetic CT Scans from MRIs","authors":"Leonardo Crespi, Samuele Camnasio, Damiano Dei, Nicola Lambri, Pietro\n  Mancosu, Marta Scorsetti, Daniele Loiacono","authorsParsed":[["Crespi","Leonardo",""],["Camnasio","Samuele",""],["Dei","Damiano",""],["Lambri","Nicola",""],["Mancosu","Pietro",""],["Scorsetti","Marta",""],["Loiacono","Daniele",""]],"versions":[{"version":"v1","created":"Mon, 15 Jul 2024 16:38:59 GMT"}],"updateDate":"2024-07-16","timestamp":1721061539000,"abstract":"  In many clinical settings, the use of both Computed Tomography (CT) and\nMagnetic Resonance (MRI) is necessary to pursue a thorough understanding of the\npatient's anatomy and to plan a suitable therapeutical strategy; this is often\nthe case in MRI-based radiotherapy, where CT is always necessary to prepare the\ndose delivery, as it provides the essential information about the radiation\nabsorption properties of the tissues. Sometimes, MRI is preferred to contour\nthe target volumes. However, this approach is often not the most efficient, as\nit is more expensive, time-consuming and, most importantly, stressful for the\npatients. To overcome this issue, in this work, we analyse the capabilities of\ndifferent configurations of Deep Learning models to generate synthetic CT scans\nfrom MRI, leveraging the power of Generative Adversarial Networks (GANs) and,\nin particular, the CycleGAN architecture, capable of working in an unsupervised\nmanner and without paired images, which were not available. Several CycleGAN\nmodels were trained unsupervised to generate CT scans from different MRI\nmodalities with and without contrast agents. To overcome the problem of not\nhaving a ground truth, distribution-based metrics were used to assess the\nmodel's performance quantitatively, together with a qualitative evaluation\nwhere physicians were asked to differentiate between real and synthetic images\nto understand how realistic the generated images were. The results show how,\ndepending on the input modalities, the models can have very different\nperformances; however, models with the best quantitative results, according to\nthe distribution-based metrics used, can generate very difficult images to\ndistinguish from the real ones, even for physicians, demonstrating the\napproach's potential.\n","subjects":["Electrical Engineering and Systems Science/Image and Video Processing","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}