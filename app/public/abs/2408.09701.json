{"id":"2408.09701","title":"Bridging the Language Gap: Enhancing Multilingual Prompt-Based Code\n  Generation in LLMs via Zero-Shot Cross-Lingual Transfer","authors":"Mingda Li, Abhijit Mishra, Utkarsh Mujumdar","authorsParsed":[["Li","Mingda",""],["Mishra","Abhijit",""],["Mujumdar","Utkarsh",""]],"versions":[{"version":"v1","created":"Mon, 19 Aug 2024 05:11:46 GMT"}],"updateDate":"2024-08-20","timestamp":1724044306000,"abstract":"  The use of Large Language Models (LLMs) for program code generation has\ngained substantial attention, but their biases and limitations with non-English\nprompts challenge global inclusivity. This paper investigates the complexities\nof multilingual prompt-based code generation. Our evaluations of LLMs,\nincluding CodeLLaMa and CodeGemma, reveal significant disparities in code\nquality for non-English prompts; we also demonstrate the inadequacy of simple\napproaches like prompt translation, bootstrapped data augmentation, and\nfine-tuning. To address this, we propose a zero-shot cross-lingual approach\nusing a neural projection technique, integrating a cross-lingual encoder like\nLASER artetxe2019massively to map multilingual embeddings from it into the\nLLM's token space. This method requires training only on English data and\nscales effectively to other languages. Results on a translated and\nquality-checked MBPP dataset show substantial improvements in code quality.\nThis research promotes a more inclusive code generation landscape by empowering\nLLMs with multilingual capabilities to support the diverse linguistic spectrum\nin programming.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/"}