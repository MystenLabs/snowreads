{"id":"2407.13979","title":"Truthfulness of Calibration Measures","authors":"Nika Haghtalab, Mingda Qiao, Kunhe Yang, Eric Zhao","authorsParsed":[["Haghtalab","Nika",""],["Qiao","Mingda",""],["Yang","Kunhe",""],["Zhao","Eric",""]],"versions":[{"version":"v1","created":"Fri, 19 Jul 2024 02:07:55 GMT"}],"updateDate":"2024-07-22","timestamp":1721354875000,"abstract":"  We initiate the study of the truthfulness of calibration measures in\nsequential prediction. A calibration measure is said to be truthful if the\nforecaster (approximately) minimizes the expected penalty by predicting the\nconditional expectation of the next outcome, given the prior distribution of\noutcomes. Truthfulness is an important property of calibration measures,\nensuring that the forecaster is not incentivized to exploit the system with\ndeliberate poor forecasts. This makes it an essential desideratum for\ncalibration measures, alongside typical requirements, such as soundness and\ncompleteness.\n  We conduct a taxonomy of existing calibration measures and their\ntruthfulness. Perhaps surprisingly, we find that all of them are far from being\ntruthful. That is, under existing calibration measures, there are simple\ndistributions on which a polylogarithmic (or even zero) penalty is achievable,\nwhile truthful prediction leads to a polynomial penalty. Our main contribution\nis the introduction of a new calibration measure termed the Subsampled Smooth\nCalibration Error (SSCE) under which truthful prediction is optimal up to a\nconstant multiplicative factor.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Data Structures and Algorithms","Statistics/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}