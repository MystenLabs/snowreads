{"id":"2407.15797","title":"MILAN: Milli-Annotations for Lidar Semantic Segmentation","authors":"Nermin Samet, Gilles Puy, Oriane Sim\\'eoni, Renaud Marlet","authorsParsed":[["Samet","Nermin",""],["Puy","Gilles",""],["Sim√©oni","Oriane",""],["Marlet","Renaud",""]],"versions":[{"version":"v1","created":"Mon, 22 Jul 2024 16:59:49 GMT"}],"updateDate":"2024-07-23","timestamp":1721667589000,"abstract":"  Annotating lidar point clouds for autonomous driving is a notoriously\nexpensive and time-consuming task. In this work, we show that the quality of\nrecent self-supervised lidar scan representations allows a great reduction of\nthe annotation cost. Our method has two main steps. First, we show that\nself-supervised representations allow a simple and direct selection of highly\ninformative lidar scans to annotate: training a network on these selected scans\nleads to much better results than a random selection of scans and, more\ninterestingly, to results on par with selections made by SOTA active learning\nmethods. In a second step, we leverage the same self-supervised representations\nto cluster points in our selected scans. Asking the annotator to classify each\ncluster, with a single click per cluster, then permits us to close the gap with\nfully-annotated training sets, while only requiring one thousandth of the point\nlabels.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}