{"id":"2407.16508","title":"ToDER: Towards Colonoscopy Depth Estimation and Reconstruction with\n  Geometry Constraint Adaptation","authors":"Zhenhua Wu, Yanlin Jin, Liangdong Qiu, Xiaoguang Han, Xiang Wan,\n  Guanbin Li","authorsParsed":[["Wu","Zhenhua",""],["Jin","Yanlin",""],["Qiu","Liangdong",""],["Han","Xiaoguang",""],["Wan","Xiang",""],["Li","Guanbin",""]],"versions":[{"version":"v1","created":"Tue, 23 Jul 2024 14:24:26 GMT"}],"updateDate":"2024-07-24","timestamp":1721744666000,"abstract":"  Visualizing colonoscopy is crucial for medical auxiliary diagnosis to prevent\nundetected polyps in areas that are not fully observed. Traditional\nfeature-based and depth-based reconstruction approaches usually end up with\nundesirable results due to incorrect point matching or imprecise depth\nestimation in realistic colonoscopy videos. Modern deep-based methods often\nrequire a sufficient number of ground truth samples, which are generally hard\nto obtain in optical colonoscopy. To address this issue, self-supervised and\ndomain adaptation methods have been explored. However, these methods neglect\ngeometry constraints and exhibit lower accuracy in predicting detailed depth.\nWe thus propose a novel reconstruction pipeline with a bi-directional\nadaptation architecture named ToDER to get precise depth estimations.\nFurthermore, we carefully design a TNet module in our adaptation architecture\nto yield geometry constraints and obtain better depth quality. Estimated depth\nis finally utilized to reconstruct a reliable colon model for visualization.\nExperimental results demonstrate that our approach can precisely predict depth\nmaps in both realistic and synthetic colonoscopy videos compared with other\nself-supervised and domain adaptation methods. Our method on realistic\ncolonoscopy also shows the great potential for visualizing unobserved regions\nand preventing misdiagnoses.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}