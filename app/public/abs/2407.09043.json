{"id":"2407.09043","title":"Vision Language Model is NOT All You Need: Augmentation Strategies for\n  Molecule Language Models","authors":"Namkyeong Lee, Siddhartha Laghuvarapu, Chanyoung Park, Jimeng Sun","authorsParsed":[["Lee","Namkyeong",""],["Laghuvarapu","Siddhartha",""],["Park","Chanyoung",""],["Sun","Jimeng",""]],"versions":[{"version":"v1","created":"Fri, 12 Jul 2024 07:09:10 GMT"},{"version":"v2","created":"Wed, 17 Jul 2024 01:09:25 GMT"},{"version":"v3","created":"Tue, 23 Jul 2024 07:31:20 GMT"}],"updateDate":"2024-07-24","timestamp":1720768150000,"abstract":"  Recently, there has been a growing interest among researchers in\nunderstanding molecules and their textual descriptions through molecule\nlanguage models (MoLM). However, despite some early promising developments, the\nadvancement of MoLM still trails significantly behind that of vision language\nmodels (VLM). This is because unique challenges exist apart from VLM in the\nfield of MoLM due to 1) a limited amount of molecule-text paired data and 2)\nmissing expertise that occurred due to the specialized areas of focus among the\nexperts. To this end, we propose AMOLE, which 1) augments molecule-text pairs\nwith structural similarity preserving loss, and 2) transfers the expertise\nbetween the molecules. Specifically, AMOLE enriches molecule-text pairs by\nsharing descriptions among structurally similar molecules with a novel\nstructural similarity preserving loss. Moreover, we propose an expertise\nreconstruction loss to transfer knowledge from molecules that have extensive\nexpertise to those with less expertise. Extensive experiments on various\ndownstream tasks demonstrate the superiority of AMOLE in comprehending\nmolecules and their descriptions, highlighting its potential for application in\nreal-world drug discovery. The source code for AMOLE is available at\nhttps://github.com/Namkyeong/AMOLE.\n","subjects":["Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}