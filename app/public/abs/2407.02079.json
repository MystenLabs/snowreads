{"id":"2407.02079","title":"Theseus: Towards High-Efficiency Wafer-Scale Chip Design Space\n  Exploration for Large Language Models","authors":"Jingchen Zhu, Chenhao Xue, Yiqi Chen, Zhao Wang, Guangyu Sun","authorsParsed":[["Zhu","Jingchen",""],["Xue","Chenhao",""],["Chen","Yiqi",""],["Wang","Zhao",""],["Sun","Guangyu",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 09:16:43 GMT"}],"updateDate":"2024-07-03","timestamp":1719911803000,"abstract":"  The emergence of the large language model~(LLM) poses an exponential growth\nof demand for computation throughput, memory capacity, and communication\nbandwidth. Such a demand growth has significantly surpassed the improvement of\ncorresponding chip designs. With the advancement of fabrication and integration\ntechnologies, designers have been developing Wafer-Scale Chips(WSCs) to scale\nup and exploit the limits of computation density, memory capacity, and\ncommunication bandwidth at the level of a single chip. Existing solutions have\ndemonstrated the significant advantages of WSCs over traditional designs,\nshowing potential to effectively support LLM workloads.\n  Despite the benefits, exploring the early-stage design space of WSCs for LLMs\nis a crucial yet challenging task due to the enormous and complicated design\nspace, time-consuming evaluation methods, and inefficient exploration\nstrategies. To address these challenges, we propose Theseus, an efficient WSC\ndesign space exploration framework for LLMs. We construct the design space of\nWSCs with various constraints considering the unique characteristics of WSCs.\nWe propose efficient evaluation methodologies for large-scale NoC-based WSCs\nand introduce multi-fidelity Bayesian optimization to efficiently explore the\ndesign space. Evaluation results demonstrate the efficiency of Theseus that the\nsearched Pareto optimal results outperform GPU cluster and existing WSC designs\nby up to 62.8%/73.7% in performance and 38.6%/42.4% in power consumption for\nLLM training, while improving up to 23.2$\\times$ and 15.7$\\times$ for the\nperformance and power of inference tasks. Furthermore, we conduct case studies\nto address the design tradeoffs in WSCs and provide insights to facilitate WSC\ndesigns for LLMs.\n","subjects":["Computing Research Repository/Hardware Architecture"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}