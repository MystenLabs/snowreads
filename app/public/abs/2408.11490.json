{"id":"2408.11490","title":"DocTabQA: Answering Questions from Long Documents Using Tables","authors":"Haochen Wang, Kai Hu, Haoyu Dong, and Liangcai Gao","authorsParsed":[["Wang","Haochen",""],["Hu","Kai",""],["Dong","Haoyu",""],["Gao","Liangcai",""]],"versions":[{"version":"v1","created":"Wed, 21 Aug 2024 10:01:12 GMT"}],"updateDate":"2024-08-22","timestamp":1724234472000,"abstract":"  We study a new problem setting of question answering (QA), referred to as\nDocTabQA. Within this setting, given a long document, the goal is to respond to\nquestions by organizing the answers into structured tables derived directly\nfrom the document's content. Unlike traditional QA approaches which\npredominantly rely on unstructured text to formulate responses, DocTabQA aims\nto leverage structured tables as answers to convey information clearly and\nsystematically, thereby enhancing user comprehension and highlighting\nrelationships between data points. To the best of our knowledge, this problem\nhas not been previously explored. In this paper, we introduce the QTabA\ndataset, encompassing 300 financial documents, accompanied by manually\nannotated 1.5k question-table pairs. Initially, we leverage Large Language\nModels (LLMs) such as GPT-4 to establish a baseline. However, it is widely\nacknowledged that LLMs encounter difficulties when tasked with generating\nintricate, structured outputs from long input sequences. To overcome these\nchallenges, we present a two-stage framework, called DocTabTalk, which\ninitially retrieves relevant sentences from extensive documents and\nsubsequently generates hierarchical tables based on these identified sentences.\nDocTabTalk incorporates two key technological innovations: AlignLLaMA and\nTabTalk, which are specifically tailored to assist GPT-4 in tackling DocTabQA,\nenabling it to generate well-structured, hierarchical tables with improved\norganization and clarity. Comprehensive experimental evaluations conducted on\nboth QTabA and RotoWire datasets demonstrate that our DocTabTalk significantly\nenhances the performances of the GPT-4 in our proposed DocTabQA task and the\ntable generation task. The code and dataset are available at\nhttps://github.com/SmileWHC/DocTabQA for further research.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}