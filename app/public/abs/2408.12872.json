{"id":"2408.12872","title":"Moral Judgments in Online Discourse are not Biased by Gender","authors":"Lorenzo Betti, Paolo Bajardi, Gianmarco De Francisci Morales","authorsParsed":[["Betti","Lorenzo",""],["Bajardi","Paolo",""],["Morales","Gianmarco De Francisci",""]],"versions":[{"version":"v1","created":"Fri, 23 Aug 2024 07:10:48 GMT"}],"updateDate":"2024-08-26","timestamp":1724397048000,"abstract":"  The interaction between social norms and gender roles prescribes\ngender-specific behaviors that influence moral judgments. Here, we study how\nmoral judgments are biased by the gender of the protagonist of a story. Using\ndata from r/AITA, a Reddit community with 17 million members who share\nfirst-hand experiences seeking community judgment on their behavior, we employ\nmachine learning techniques to match stories describing similar situations that\ndiffer only by the protagonist's gender. We find no direct causal effect of the\nprotagonist's gender on the received moral judgments, except for stories about\n``friendship and relationships'', where male protagonists receive more negative\njudgments. Our findings complement existing correlational studies and suggest\nthat gender roles may exert greater influence in specific social contexts.\nThese results have implications for understanding sociological constructs and\nhighlight potential biases in data used to train large language models.\n","subjects":["Computing Research Repository/Computers and Society"],"license":"http://creativecommons.org/licenses/by/4.0/"}