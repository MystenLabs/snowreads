{"id":"2407.02014","title":"Multi-Grained Contrast for Data-Efficient Unsupervised Representation\n  Learning","authors":"Chengchao Shen, Jianzhong Chen, Jianxin Wang","authorsParsed":[["Shen","Chengchao",""],["Chen","Jianzhong",""],["Wang","Jianxin",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 07:35:21 GMT"}],"updateDate":"2024-07-03","timestamp":1719905721000,"abstract":"  The existing contrastive learning methods mainly focus on single-grained\nrepresentation learning, e.g., part-level, object-level or scene-level ones,\nthus inevitably neglecting the transferability of representations on other\ngranularity levels. In this paper, we aim to learn multi-grained\nrepresentations, which can effectively describe the image on various\ngranularity levels, thus improving generalization on extensive downstream\ntasks. To this end, we propose a novel Multi-Grained Contrast method (MGC) for\nunsupervised representation learning. Specifically, we construct delicate\nmulti-grained correspondences between positive views and then conduct\nmulti-grained contrast by the correspondences to learn more general\nunsupervised representations.\n  Without pretrained on large-scale dataset, our method significantly\noutperforms the existing state-of-the-art methods on extensive downstream\ntasks, including object detection, instance segmentation, scene parsing,\nsemantic segmentation and keypoint detection. Moreover, experimental results\nsupport the data-efficient property and excellent representation\ntransferability of our method. The source code and trained weights are\navailable at \\url{https://github.com/visresearch/mgc}.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}