{"id":"2407.05758","title":"Potential of Multimodal Large Language Models for Data Mining of Medical\n  Images and Free-text Reports","authors":"Yutong Zhang, Yi Pan, Tianyang Zhong, Peixin Dong, Kangni Xie, Yuxiao\n  Liu, Hanqi Jiang, Zhengliang Liu, Shijie Zhao, Tuo Zhang, Xi Jiang, Dinggang\n  Shen, Tianming Liu, Xin Zhang","authorsParsed":[["Zhang","Yutong",""],["Pan","Yi",""],["Zhong","Tianyang",""],["Dong","Peixin",""],["Xie","Kangni",""],["Liu","Yuxiao",""],["Jiang","Hanqi",""],["Liu","Zhengliang",""],["Zhao","Shijie",""],["Zhang","Tuo",""],["Jiang","Xi",""],["Shen","Dinggang",""],["Liu","Tianming",""],["Zhang","Xin",""]],"versions":[{"version":"v1","created":"Mon, 8 Jul 2024 09:08:42 GMT"}],"updateDate":"2024-07-09","timestamp":1720429722000,"abstract":"  Medical images and radiology reports are crucial for diagnosing medical\nconditions, highlighting the importance of quantitative analysis for clinical\ndecision-making. However, the diversity and cross-source heterogeneity of these\ndata challenge the generalizability of current data-mining methods. Multimodal\nlarge language models (MLLMs) have recently transformed many domains,\nsignificantly affecting the medical field. Notably, Gemini-Vision-series\n(Gemini) and GPT-4-series (GPT-4) models have epitomized a paradigm shift in\nArtificial General Intelligence (AGI) for computer vision, showcasing their\npotential in the biomedical domain. In this study, we evaluated the performance\nof the Gemini, GPT-4, and 4 popular large models for an exhaustive evaluation\nacross 14 medical imaging datasets, including 5 medical imaging categories\n(dermatology, radiology, dentistry, ophthalmology, and endoscopy), and 3\nradiology report datasets. The investigated tasks encompass disease\nclassification, lesion segmentation, anatomical localization, disease\ndiagnosis, report generation, and lesion detection. Our experimental results\ndemonstrated that Gemini-series models excelled in report generation and lesion\ndetection but faces challenges in disease classification and anatomical\nlocalization. Conversely, GPT-series models exhibited proficiency in lesion\nsegmentation and anatomical localization but encountered difficulties in\ndisease diagnosis and lesion detection. Additionally, both the Gemini series\nand GPT series contain models that have demonstrated commendable generation\nefficiency. While both models hold promise in reducing physician workload,\nalleviating pressure on limited healthcare resources, and fostering\ncollaboration between clinical practitioners and artificial intelligence\ntechnologies, substantial enhancements and comprehensive validations remain\nimperative before clinical deployment.\n","subjects":["Electrical Engineering and Systems Science/Image and Video Processing","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}