{"id":"2408.10918","title":"CHECKWHY: Causal Fact Verification via Argument Structure","authors":"Jiasheng Si, Yibo Zhao, Yingjie Zhu, Haiyang Zhu, Wenpeng Lu, Deyu\n  Zhou","authorsParsed":[["Si","Jiasheng",""],["Zhao","Yibo",""],["Zhu","Yingjie",""],["Zhu","Haiyang",""],["Lu","Wenpeng",""],["Zhou","Deyu",""]],"versions":[{"version":"v1","created":"Tue, 20 Aug 2024 15:03:35 GMT"}],"updateDate":"2024-08-21","timestamp":1724166215000,"abstract":"  With the growing complexity of fact verification tasks, the concern with\n\"thoughtful\" reasoning capabilities is increasing. However, recent fact\nverification benchmarks mainly focus on checking a narrow scope of semantic\nfactoids within claims and lack an explicit logical reasoning process. In this\npaper, we introduce CheckWhy, a challenging dataset tailored to a novel causal\nfact verification task: checking the truthfulness of the causal relation within\nclaims through rigorous reasoning steps. CheckWhy consists of over 19K \"why\"\nclaim-evidence-argument structure triplets with supports, refutes, and not\nenough info labels. Each argument structure is composed of connected evidence,\nrepresenting the reasoning process that begins with foundational evidence and\nprogresses toward claim establishment. Through extensive experiments on\nstate-of-the-art models, we validate the importance of incorporating the\nargument structure for causal fact verification. Moreover, the automated and\nhuman evaluation of argument structure generation reveals the difficulty in\nproducing satisfying argument structure by fine-tuned models or\nChain-of-Thought prompted LLMs, leaving considerable room for future\nimprovements.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}