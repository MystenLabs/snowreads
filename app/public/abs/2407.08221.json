{"id":"2407.08221","title":"GAURA: Generalizable Approach for Unified Restoration and Rendering of\n  Arbitrary Views","authors":"Vinayak Gupta, Rongali Simhachala Venkata Girish, Mukund Varma T,\n  Ayush Tewari, Kaushik Mitra","authorsParsed":[["Gupta","Vinayak",""],["Girish","Rongali Simhachala Venkata",""],["T","Mukund Varma",""],["Tewari","Ayush",""],["Mitra","Kaushik",""]],"versions":[{"version":"v1","created":"Thu, 11 Jul 2024 06:44:37 GMT"}],"updateDate":"2024-07-12","timestamp":1720680277000,"abstract":"  Neural rendering methods can achieve near-photorealistic image synthesis of\nscenes from posed input images. However, when the images are imperfect, e.g.,\ncaptured in very low-light conditions, state-of-the-art methods fail to\nreconstruct high-quality 3D scenes. Recent approaches have tried to address\nthis limitation by modeling various degradation processes in the image\nformation model; however, this limits them to specific image degradations. In\nthis paper, we propose a generalizable neural rendering method that can perform\nhigh-fidelity novel view synthesis under several degradations. Our method,\nGAURA, is learning-based and does not require any test-time scene-specific\noptimization. It is trained on a synthetic dataset that includes several\ndegradation types. GAURA outperforms state-of-the-art methods on several\nbenchmarks for low-light enhancement, dehazing, deraining, and on-par for\nmotion deblurring. Further, our model can be efficiently fine-tuned to any new\nincoming degradation using minimal data. We thus demonstrate adaptation results\non two unseen degradations, desnowing and removing defocus blur. Code and video\nresults are available at vinayak-vg.github.io/GAURA.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}