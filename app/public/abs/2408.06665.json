{"id":"2408.06665","title":"RW-NSGCN: A Robust Approach to Structural Attacks via Negative Sampling","authors":"Shuqi He, Jun Zhuang, Ding Wang, Jun Song","authorsParsed":[["He","Shuqi",""],["Zhuang","Jun",""],["Wang","Ding",""],["Song","Jun",""]],"versions":[{"version":"v1","created":"Tue, 13 Aug 2024 06:34:56 GMT"}],"updateDate":"2024-08-14","timestamp":1723530896000,"abstract":"  Node classification using Graph Neural Networks (GNNs) has been widely\napplied in various practical scenarios, such as predicting user interests and\ndetecting communities in social networks. However, recent studies have shown\nthat graph-structured networks often contain potential noise and attacks, in\nthe form of topological perturbations and weight disturbances, which can lead\nto decreased classification performance in GNNs. To improve the robustness of\nthe model, we propose a novel method: Random Walk Negative Sampling Graph\nConvolutional Network (RW-NSGCN). Specifically, RW-NSGCN integrates the Random\nWalk with Restart (RWR) and PageRank (PGR) algorithms for negative sampling and\nemploys a Determinantal Point Process (DPP)-based GCN for convolution\noperations. RWR leverages both global and local information to manage noise and\nlocal variations, while PGR assesses node importance to stabilize the\ntopological structure. The DPP-based GCN ensures diversity among negative\nsamples and aggregates their features to produce robust node embeddings,\nthereby improving classification performance. Experimental results demonstrate\nthat the RW-NSGCN model effectively addresses network topology attacks and\nweight instability, increasing the accuracy of anomaly detection and overall\nstability. In terms of classification accuracy, RW-NSGCN significantly\noutperforms existing methods, showing greater resilience across various\nscenarios and effectively mitigating the impact of such vulnerabilities.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}