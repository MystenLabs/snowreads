{"id":"2407.14839","title":"Optimizing over Multiple Distributions under Generalized\n  Quasar-Convexity Condition","authors":"Shihong Ding, Long Yang, Luo Luo, Cong Fang","authorsParsed":[["Ding","Shihong",""],["Yang","Long",""],["Luo","Luo",""],["Fang","Cong",""]],"versions":[{"version":"v1","created":"Sat, 20 Jul 2024 10:47:34 GMT"}],"updateDate":"2024-07-23","timestamp":1721472454000,"abstract":"  We study a typical optimization model where the optimization variable is\ncomposed of multiple probability distributions. Though the model appears\nfrequently in practice, such as for policy problems, it lacks specific analysis\nin the general setting. For this optimization problem, we propose a new\nstructural condition/landscape description named generalized quasar-convexity\n(GQC) beyond the realms of convexity. In contrast to original quasar-convexity\n\\citep{hinder2020near}, GQC allows an individual quasar-convex parameter\n$\\gamma_i$ for each variable block $i$ and the smaller of $\\gamma_i$ implies\nless block-convexity. To minimize the objective function, we consider a\ngeneralized oracle termed as the internal function that includes the standard\ngradient oracle as a special case. We provide optimistic mirror descent (OMD)\nfor multiple distributions and prove that the algorithm can achieve an adaptive\n$\\tilde{\\mathcal{O}}((\\sum_{i=1}^d1/\\gamma_i)\\epsilon^{-1})$ iteration\ncomplexity to find an $epsilon$-suboptimal global solution without pre-known\nthe exact values of $\\gamma_i$ when the objective admits ``polynomial-like''\nstructural. Notably, it achieves iteration complexity that does not explicitly\ndepend on the number of distributions and strictly faster $(\\sum_{i=1}^d\n1/\\gamma_i \\text{ v.s. } d\\max_{i\\in[1:d]} 1/\\gamma_i)$ than mirror decent\nmethods. We also extend GQC to the minimax optimization problem proposing the\ngeneralized quasar-convexity-concavity (GQCC) condition and a decentralized\nvariant of OMD with regularization. Finally, we show the applications of our\nalgorithmic framework on discounted Markov Decision Processes problem and\nMarkov games, which bring new insights on the landscape analysis of\nreinforcement learning.\n","subjects":["Mathematics/Optimization and Control"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}