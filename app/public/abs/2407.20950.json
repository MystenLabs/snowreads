{"id":"2407.20950","title":"dopanim: A Dataset of Doppelganger Animals with Noisy Annotations from\n  Multiple Humans","authors":"Marek Herde, Denis Huseljic, Lukas Rauch, Bernhard Sick","authorsParsed":[["Herde","Marek",""],["Huseljic","Denis",""],["Rauch","Lukas",""],["Sick","Bernhard",""]],"versions":[{"version":"v1","created":"Tue, 30 Jul 2024 16:27:51 GMT"}],"updateDate":"2024-07-31","timestamp":1722356871000,"abstract":"  Human annotators typically provide annotated data for training machine\nlearning models, such as neural networks. Yet, human annotations are subject to\nnoise, impairing generalization performances. Methodological research on\napproaches counteracting noisy annotations requires corresponding datasets for\na meaningful empirical evaluation. Consequently, we introduce a novel benchmark\ndataset, dopanim, consisting of about 15,750 animal images of 15 classes with\nground truth labels. For approximately 10,500 of these images, 20 humans\nprovided over 52,000 annotations with an accuracy of circa 67%. Its key\nattributes include (1) the challenging task of classifying doppelganger\nanimals, (2) human-estimated likelihoods as annotations, and (3) annotator\nmetadata. We benchmark well-known multi-annotator learning approaches using\nseven variants of this dataset and outline further evaluation use cases such as\nlearning beyond hard class labels and active learning. Our dataset and a\ncomprehensive codebase are publicly available to emulate the data collection\nprocess and to reproduce all empirical results.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}