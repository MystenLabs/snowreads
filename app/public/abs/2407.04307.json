{"id":"2407.04307","title":"Crafting Large Language Models for Enhanced Interpretability","authors":"Chung-En Sun, Tuomas Oikarinen, Tsui-Wei Weng","authorsParsed":[["Sun","Chung-En",""],["Oikarinen","Tuomas",""],["Weng","Tsui-Wei",""]],"versions":[{"version":"v1","created":"Fri, 5 Jul 2024 07:22:44 GMT"}],"updateDate":"2024-07-08","timestamp":1720164164000,"abstract":"  We introduce the Concept Bottleneck Large Language Model (CB-LLM), a\npioneering approach to creating inherently interpretable Large Language Models\n(LLMs). Unlike traditional black-box LLMs that rely on post-hoc interpretation\nmethods with limited neuron function insights, CB-LLM sets a new standard with\nits built-in interpretability, scalability, and ability to provide clear,\naccurate explanations. This innovation not only advances transparency in\nlanguage models but also enhances their effectiveness. Our unique Automatic\nConcept Correction (ACC) strategy successfully narrows the performance gap with\nconventional black-box LLMs, positioning CB-LLM as a model that combines the\nhigh accuracy of traditional LLMs with the added benefit of clear\ninterpretability -- a feature markedly absent in existing LLMs.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}