{"id":"2408.02191","title":"Dense Feature Interaction Network for Image Inpainting Localization","authors":"Ye Yao, Tingfeng Han, Shan Jia, Siwei Lyu","authorsParsed":[["Yao","Ye",""],["Han","Tingfeng",""],["Jia","Shan",""],["Lyu","Siwei",""]],"versions":[{"version":"v1","created":"Mon, 5 Aug 2024 02:35:13 GMT"}],"updateDate":"2024-08-06","timestamp":1722825313000,"abstract":"  Image inpainting, which is the task of filling in missing areas in an image,\nis a common image editing technique. Inpainting can be used to conceal or alter\nimage contents in malicious manipulation of images, driving the need for\nresearch in image inpainting detection. Existing methods mostly rely on a basic\nencoder-decoder structure, which often results in a high number of false\npositives or misses the inpainted regions, especially when dealing with targets\nof varying semantics and scales. Additionally, the absence of an effective\napproach to capture boundary artifacts leads to less accurate edge\nlocalization. In this paper, we describe a new method for inpainting detection\nbased on a Dense Feature Interaction Network (DeFI-Net). DeFI-Net uses a novel\nfeature pyramid architecture to capture and amplify multi-scale representations\nacross various stages, thereby improving the detection of image inpainting by\nbetter revealing feature-level interactions. Additionally, the network can\nadaptively direct the lower-level features, which carry edge and shape\ninformation, to refine the localization of manipulated regions while\nintegrating the higher-level semantic features. Using DeFI-Net, we develop a\nmethod combining complementary representations to accurately identify inpainted\nareas. Evaluation on five image inpainting datasets demonstrate the\neffectiveness of our approach, which achieves state-of-the-art performance in\ndetecting inpainting across diverse models.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}