{"id":"2408.14432","title":"Contextual Bandit with Herding Effects: Algorithms and Recommendation\n  Applications","authors":"Luyue Xu, Liming Wang, Hong Xie, Mingqiang Zhou","authorsParsed":[["Xu","Luyue",""],["Wang","Liming",""],["Xie","Hong",""],["Zhou","Mingqiang",""]],"versions":[{"version":"v1","created":"Mon, 26 Aug 2024 17:20:34 GMT"},{"version":"v2","created":"Wed, 28 Aug 2024 12:39:57 GMT"}],"updateDate":"2024-08-29","timestamp":1724692834000,"abstract":"  Contextual bandits serve as a fundamental algorithmic framework for\noptimizing recommendation decisions online. Though extensive attention has been\npaid to tailoring contextual bandits for recommendation applications, the\n\"herding effects\" in user feedback have been ignored. These herding effects\nbias user feedback toward historical ratings, breaking down the assumption of\nunbiased feedback inherent in contextual bandits. This paper develops a novel\nvariant of the contextual bandit that is tailored to address the feedback bias\ncaused by the herding effects. A user feedback model is formulated to capture\nthis feedback bias. We design the TS-Conf (Thompson Sampling under Conformity)\nalgorithm, which employs posterior sampling to balance the exploration and\nexploitation tradeoff. We prove an upper bound for the regret of the algorithm,\nrevealing the impact of herding effects on learning speed. Extensive\nexperiments on datasets demonstrate that TS-Conf outperforms four benchmark\nalgorithms. Analysis reveals that TS-Conf effectively mitigates the negative\nimpact of herding effects, resulting in faster learning and improved\nrecommendation accuracy.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Information Retrieval"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}