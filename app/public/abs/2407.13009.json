{"id":"2407.13009","title":"Fighting Sampling Bias: A Framework for Training and Evaluating Credit\n  Scoring Models","authors":"Nikita Kozodoi, Stefan Lessmann, Morteza Alamgir, Luis Moreira-Matias,\n  Konstantinos Papakonstantinou","authorsParsed":[["Kozodoi","Nikita",""],["Lessmann","Stefan",""],["Alamgir","Morteza",""],["Moreira-Matias","Luis",""],["Papakonstantinou","Konstantinos",""]],"versions":[{"version":"v1","created":"Wed, 17 Jul 2024 20:59:54 GMT"}],"updateDate":"2024-07-19","timestamp":1721249994000,"abstract":"  Scoring models support decision-making in financial institutions. Their\nestimation and evaluation are based on the data of previously accepted\napplicants with known repayment behavior. This creates sampling bias: the\navailable labeled data offers a partial picture of the distribution of\ncandidate borrowers, which the model is supposed to score. The paper addresses\nthe adverse effect of sampling bias on model training and evaluation. To\nimprove scorecard training, we propose bias-aware self-learning - a reject\ninference framework that augments the biased training data by inferring labels\nfor selected rejected applications. For scorecard evaluation, we propose a\nBayesian framework that extends standard accuracy measures to the biased\nsetting and provides a reliable estimate of future scorecard performance.\nExtensive experiments on synthetic and real-world data confirm the superiority\nof our propositions over various benchmarks in predictive performance and\nprofitability. By sensitivity analysis, we also identify boundary conditions\naffecting their performance. Notably, we leverage real-world data from a\nrandomized controlled trial to assess the novel methodologies on holdout data\nthat represent the true borrower population. Our findings confirm that reject\ninference is a difficult problem with modest potential to improve scorecard\nperformance. Addressing sampling bias during scorecard evaluation is a much\nmore promising route to improve scoring practices. For example, our results\nsuggest a profit improvement of about eight percent, when using Bayesian\nevaluation to decide on acceptance rates.\n","subjects":["Statistics/Machine Learning","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}