{"id":"2408.04315","title":"Federated Cubic Regularized Newton Learning with\n  Sparsification-amplified Differential Privacy","authors":"Wei Huo, Changxin Liu, Kemi Ding, Karl Henrik Johansson, Ling Shi","authorsParsed":[["Huo","Wei",""],["Liu","Changxin",""],["Ding","Kemi",""],["Johansson","Karl Henrik",""],["Shi","Ling",""]],"versions":[{"version":"v1","created":"Thu, 8 Aug 2024 08:48:54 GMT"}],"updateDate":"2024-08-09","timestamp":1723106934000,"abstract":"  This paper investigates the use of the cubic-regularized Newton method within\na federated learning framework while addressing two major concerns that\ncommonly arise in federated learning: privacy leakage and communication\nbottleneck. We introduce a federated learning algorithm called Differentially\nPrivate Federated Cubic Regularized Newton (DP-FCRN). By leveraging\nsecond-order techniques, our algorithm achieves lower iteration complexity\ncompared to first-order methods. We also incorporate noise perturbation during\nlocal computations to ensure privacy. Furthermore, we employ sparsification in\nuplink transmission, which not only reduces the communication costs but also\namplifies the privacy guarantee. Specifically, this approach reduces the\nnecessary noise intensity without compromising privacy protection. We analyze\nthe convergence properties of our algorithm and establish the privacy\nguarantee. Finally, we validate the effectiveness of the proposed algorithm\nthrough experiments on a benchmark dataset.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Systems and Control","Electrical Engineering and Systems Science/Systems and Control"],"license":"http://creativecommons.org/licenses/by/4.0/"}