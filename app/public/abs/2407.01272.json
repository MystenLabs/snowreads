{"id":"2407.01272","title":"Show Less, Instruct More: Enriching Prompts with Definitions and\n  Guidelines for Zero-Shot NER","authors":"Andrew Zamai, Andrea Zugarini, Leonardo Rigutini, Marco Ernandes,\n  Marco Maggini","authorsParsed":[["Zamai","Andrew",""],["Zugarini","Andrea",""],["Rigutini","Leonardo",""],["Ernandes","Marco",""],["Maggini","Marco",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 13:25:33 GMT"},{"version":"v2","created":"Tue, 2 Jul 2024 07:55:24 GMT"},{"version":"v3","created":"Wed, 18 Sep 2024 07:58:55 GMT"}],"updateDate":"2024-09-19","timestamp":1719840333000,"abstract":"  Recently, several specialized instruction-tuned Large Language Models (LLMs)\nfor Named Entity Recognition (NER) have emerged. Compared to traditional NER\napproaches, these models have demonstrated strong generalization capabilities.\nExisting LLMs primarily focus on addressing zero-shot NER on Out-of-Domain\ninputs, while fine-tuning on an extensive number of entity classes that often\nhighly or completely overlap with test sets. In this work instead, we propose\nSLIMER, an approach designed to tackle never-seen-before entity tags by\ninstructing the model on fewer examples, and by leveraging a prompt enriched\nwith definition and guidelines. Experiments demonstrate that definition and\nguidelines yield better performance, faster and more robust learning,\nparticularly when labelling unseen named entities. Furthermore, SLIMER performs\ncomparably to state-of-the-art approaches in out-of-domain zero-shot NER, while\nbeing trained in a more fair, though certainly more challenging, setting.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/"}