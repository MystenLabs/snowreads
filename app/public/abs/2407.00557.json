{"id":"2407.00557","title":"Explaining Chest X-ray Pathology Models using Textual Concepts","authors":"Vijay Sadashivaiah, Mannudeep K. Kalra, Pingkun Yan, and James A.\n  Hendler","authorsParsed":[["Sadashivaiah","Vijay",""],["Kalra","Mannudeep K.",""],["Yan","Pingkun",""],["Hendler","James A.",""]],"versions":[{"version":"v1","created":"Sun, 30 Jun 2024 01:31:54 GMT"}],"updateDate":"2024-07-02","timestamp":1719711114000,"abstract":"  Deep learning models have revolutionized medical imaging and diagnostics, yet\ntheir opaque nature poses challenges for clinical adoption and trust. Amongst\napproaches to improve model interpretability, concept-based explanations aim to\nprovide concise and human understandable explanations of any arbitrary\nclassifier. However, such methods usually require a large amount of manually\ncollected data with concept annotation, which is often scarce in the medical\ndomain. In this paper, we propose Conceptual Counterfactual Explanations for\nChest X-ray (CoCoX) that leverage existing vision-language models (VLM) joint\nembedding space to explain black-box classifier outcomes without the need for\nannotated datasets. Specifically, we utilize textual concepts derived from\nchest radiography reports and a pre-trained chest radiography-based VLM to\nexplain three common cardiothoracic pathologies. We demonstrate that the\nexplanations generated by our method are semantically meaningful and faithful\nto underlying pathologies.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}