{"id":"2407.09533","title":"Video Occupancy Models","authors":"Manan Tomar, Philippe Hansen-Estruch, Philip Bachman, Alex Lamb, John\n  Langford, Matthew E. Taylor, Sergey Levine","authorsParsed":[["Tomar","Manan",""],["Hansen-Estruch","Philippe",""],["Bachman","Philip",""],["Lamb","Alex",""],["Langford","John",""],["Taylor","Matthew E.",""],["Levine","Sergey",""]],"versions":[{"version":"v1","created":"Tue, 25 Jun 2024 17:57:38 GMT"}],"updateDate":"2024-07-16","timestamp":1719338258000,"abstract":"  We introduce a new family of video prediction models designed to support\ndownstream control tasks. We call these models Video Occupancy models (VOCs).\nVOCs operate in a compact latent space, thus avoiding the need to make\npredictions about individual pixels. Unlike prior latent-space world models,\nVOCs directly predict the discounted distribution of future states in a single\nstep, thus avoiding the need for multistep roll-outs. We show that both\nproperties are beneficial when building predictive models of video for use in\ndownstream control. Code is available at\n\\href{https://github.com/manantomar/video-occupancy-models}{\\texttt{github.com/manantomar/video-occupancy-models}}.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/"}