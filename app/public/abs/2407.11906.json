{"id":"2407.11906","title":"SegSTRONG-C: Segmenting Surgical Tools Robustly On Non-adversarial\n  Generated Corruptions -- An EndoVis'24 Challenge","authors":"Hao Ding, Tuxun Lu, Yuqian Zhang, Ruixing Liang, Hongchao Shu,\n  Lalithkumar Seenivasan, Yonghao Long, Qi Dou, Cong Gao, Mathias Unberath","authorsParsed":[["Ding","Hao",""],["Lu","Tuxun",""],["Zhang","Yuqian",""],["Liang","Ruixing",""],["Shu","Hongchao",""],["Seenivasan","Lalithkumar",""],["Long","Yonghao",""],["Dou","Qi",""],["Gao","Cong",""],["Unberath","Mathias",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 16:50:43 GMT"}],"updateDate":"2024-07-17","timestamp":1721148643000,"abstract":"  Accurate segmentation of tools in robot-assisted surgery is critical for\nmachine perception, as it facilitates numerous downstream tasks including\naugmented reality feedback. While current feed-forward neural network-based\nmethods exhibit excellent segmentation performance under ideal conditions,\nthese models have proven susceptible to even minor corruptions, significantly\nimpairing the model's performance. This vulnerability is especially problematic\nin surgical settings where predictions might be used to inform high-stakes\ndecisions. To better understand model behavior under non-adversarial\ncorruptions, prior work has explored introducing artificial corruptions, like\nGaussian noise or contrast perturbation to test set images, to assess model\nrobustness. However, these corruptions are either not photo-realistic or\nmodel/task agnostic. Thus, these investigations provide limited insights into\nmodel deterioration under realistic surgical corruptions. To address this\nlimitation, we introduce the SegSTRONG-C challenge that aims to promote the\ndevelopment of algorithms robust to unforeseen but plausible image corruptions\nof surgery, like smoke, bleeding, and low brightness. We collect and release\ncorruption-free mock endoscopic video sequences for the challenge participants\nto train their algorithms and benchmark them on video sequences with\nphoto-realistic non-adversarial corruptions for a binary robot tool\nsegmentation task. This new benchmark will allow us to carefully study neural\nnetwork robustness to non-adversarial corruptions of surgery, thus constituting\nan important first step towards more robust models for surgical computer\nvision. In this paper, we describe the data collection and annotation protocol,\nbaseline evaluations of established segmentation models, and data\naugmentation-based techniques to enhance model robustness.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Robotics"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}