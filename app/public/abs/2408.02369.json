{"id":"2408.02369","title":"The NPU-ASLP System Description for Visual Speech Recognition in CNVSRC\n  2024","authors":"He Wang, Lei Xie","authorsParsed":[["Wang","He",""],["Xie","Lei",""]],"versions":[{"version":"v1","created":"Mon, 5 Aug 2024 10:38:50 GMT"},{"version":"v2","created":"Thu, 8 Aug 2024 04:54:47 GMT"},{"version":"v3","created":"Thu, 12 Sep 2024 15:46:58 GMT"}],"updateDate":"2024-09-13","timestamp":1722854330000,"abstract":"  This paper delineates the visual speech recognition (VSR) system introduced\nby the NPU-ASLP (Team 237) in the second Chinese Continuous Visual Speech\nRecognition Challenge (CNVSRC 2024), engaging in all four tracks, including the\nfixed and open tracks of Single-Speaker VSR Task and Multi-Speaker VSR Task. In\nterms of data processing, we leverage the lip motion extractor from the\nbaseline1 to produce multiscale video data. Besides, various augmentation\ntechniques are applied during training, encompassing speed perturbation, random\nrotation, horizontal flipping, and color transformation. The VSR model adopts\nan end-to-end architecture with joint CTC/attention loss, introducing Enhanced\nResNet3D visual frontend, E-Branchformer encoder, and Bi-directional\nTransformer decoder. Our approach yields a 30.47% CER for the Single-Speaker\nTask and 34.30% CER for the Multi-Speaker Task, securing second place in the\nopen track of the Single-Speaker Task and first place in the other three\ntracks.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/publicdomain/zero/1.0/","blobId":"7BuywFM8a-roaYiZY7LULG9MNWM2X6xzrh5FsIAODJk","pdfSize":"223133"}
