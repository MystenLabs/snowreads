{"id":"2408.08448","title":"Exploring Cross-model Neuronal Correlations in the Context of Predicting\n  Model Performance and Generalizability","authors":"Haniyeh Ehsani Oskouie, Lionel Levine, Majid Sarrafzadeh","authorsParsed":[["Oskouie","Haniyeh Ehsani",""],["Levine","Lionel",""],["Sarrafzadeh","Majid",""]],"versions":[{"version":"v1","created":"Thu, 15 Aug 2024 22:57:39 GMT"},{"version":"v2","created":"Sun, 25 Aug 2024 06:51:29 GMT"},{"version":"v3","created":"Tue, 27 Aug 2024 09:04:35 GMT"},{"version":"v4","created":"Wed, 11 Sep 2024 06:12:17 GMT"}],"updateDate":"2024-09-12","timestamp":1723762659000,"abstract":"  As Artificial Intelligence (AI) models are increasingly integrated into\ncritical systems, the need for a robust framework to establish the\ntrustworthiness of AI is increasingly paramount. While collaborative efforts\nhave established conceptual foundations for such a framework, there remains a\nsignificant gap in developing concrete, technically robust methods for\nassessing AI model quality and performance. A critical drawback in the\ntraditional methods for assessing the validity and generalizability of models\nis their dependence on internal developer datasets, rendering it challenging to\nindependently assess and verify their performance claims. This paper introduces\na novel approach for assessing a newly trained model's performance based on\nanother known model by calculating correlation between neural networks. The\nproposed method evaluates correlations by determining if, for each neuron in\none network, there exists a neuron in the other network that produces similar\noutput. This approach has implications for memory efficiency, allowing for the\nuse of smaller networks when high correlation exists between networks of\ndifferent sizes. Additionally, the method provides insights into robustness,\nsuggesting that if two highly correlated networks are compared and one\ndemonstrates robustness when operating in production environments, the other is\nlikely to exhibit similar robustness. This contribution advances the technical\ntoolkit for responsible AI, supporting more comprehensive and nuanced\nevaluations of AI models to ensure their safe and effective deployment. Code is\navailable at https://github.com/aheldis/Cross-model-correlation.git.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"olJt9M_-IWWXmlIZmn4vd2tel_t3a96ZtwseNX1muh0","pdfSize":"220267"}
