{"id":"2408.09186","title":"EEG-SCMM: Soft Contrastive Masked Modeling for Cross-Corpus EEG-Based\n  Emotion Recognition","authors":"Qile Liu, Weishan Ye, Yulu Liu, Zhen Liang","authorsParsed":[["Liu","Qile",""],["Ye","Weishan",""],["Liu","Yulu",""],["Liang","Zhen",""]],"versions":[{"version":"v1","created":"Sat, 17 Aug 2024 12:35:13 GMT"}],"updateDate":"2024-08-20","timestamp":1723898113000,"abstract":"  Emotion recognition using electroencephalography (EEG) signals has garnered\nwidespread attention in recent years. However, existing studies have struggled\nto develop a sufficiently generalized model suitable for different datasets\nwithout re-training (cross-corpus). This difficulty arises because distribution\ndifferences across datasets far exceed the intra-dataset variability. To solve\nthis problem, we propose a novel Soft Contrastive Masked Modeling (SCMM)\nframework. Inspired by emotional continuity, SCMM integrates soft contrastive\nlearning with a new hybrid masking strategy to effectively mine the \"short-term\ncontinuity\" characteristics inherent in human emotions. During the\nself-supervised learning process, soft weights are assigned to sample pairs,\nenabling adaptive learning of similarity relationships across samples.\nFurthermore, we introduce an aggregator that weightedly aggregates\ncomplementary information from multiple close samples based on pairwise\nsimilarities among samples to enhance fine-grained feature representation,\nwhich is then used for original sample reconstruction. Extensive experiments on\nthe SEED, SEED-IV and DEAP datasets show that SCMM achieves state-of-the-art\n(SOTA) performance, outperforming the second-best method by an average accuracy\nof 4.26% under two types of cross-corpus conditions (same-class and\ndifferent-class) for EEG-based emotion recognition.\n","subjects":["Computing Research Repository/Human-Computer Interaction","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}