{"id":"2407.05425","title":"ClutterGen: A Cluttered Scene Generator for Robot Learning","authors":"Yinsen Jia, Boyuan Chen","authorsParsed":[["Jia","Yinsen",""],["Chen","Boyuan",""]],"versions":[{"version":"v1","created":"Sun, 7 Jul 2024 16:03:36 GMT"}],"updateDate":"2024-07-09","timestamp":1720368216000,"abstract":"  We introduce ClutterGen, a physically compliant simulation scene generator\ncapable of producing highly diverse, cluttered, and stable scenes for robot\nlearning. Generating such scenes is challenging as each object must adhere to\nphysical laws like gravity and collision. As the number of objects increases,\nfinding valid poses becomes more difficult, necessitating significant human\nengineering effort, which limits the diversity of the scenes. To overcome these\nchallenges, we propose a reinforcement learning method that can be trained with\nphysics-based reward signals provided by the simulator. Our experiments\ndemonstrate that ClutterGen can generate cluttered object layouts with up to\nten objects on confined table surfaces. Additionally, our policy design\nexplicitly encourages the diversity of the generated scenes for open-ended\ngeneration. Our real-world robot results show that ClutterGen can be directly\nused for clutter rearrangement and stable placement policy training.\n","subjects":["Computing Research Repository/Robotics"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}