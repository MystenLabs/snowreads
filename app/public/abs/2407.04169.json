{"id":"2407.04169","title":"Solutions to Deepfakes: Can Camera Hardware, Cryptography, and Deep\n  Learning Verify Real Images?","authors":"Alexander Vilesov, Yuan Tian, Nader Sehatbakhsh, Achuta Kadambi","authorsParsed":[["Vilesov","Alexander",""],["Tian","Yuan",""],["Sehatbakhsh","Nader",""],["Kadambi","Achuta",""]],"versions":[{"version":"v1","created":"Thu, 4 Jul 2024 22:01:21 GMT"}],"updateDate":"2024-07-08","timestamp":1720130481000,"abstract":"  The exponential progress in generative AI poses serious implications for the\ncredibility of all real images and videos. There will exist a point in the\nfuture where 1) digital content produced by generative AI will be\nindistinguishable from those created by cameras, 2) high-quality generative\nalgorithms will be accessible to anyone, and 3) the ratio of all synthetic to\nreal images will be large. It is imperative to establish methods that can\nseparate real data from synthetic data with high confidence. We define real\nimages as those that were produced by the camera hardware, capturing a\nreal-world scene. Any synthetic generation of an image or alteration of a real\nimage through generative AI or computer graphics techniques is labeled as a\nsynthetic image. To this end, this document aims to: present known strategies\nin detection and cryptography that can be employed to verify which images are\nreal, weight the strengths and weaknesses of these strategies, and suggest\nadditional improvements to alleviate shortcomings.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Cryptography and Security"],"license":"http://creativecommons.org/licenses/by/4.0/"}