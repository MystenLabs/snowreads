{"id":"2408.08576","title":"Tuning a SAM-Based Model with Multi-Cognitive Visual Adapter to Remote\n  Sensing Instance Segmentation","authors":"Linghao Zheng, Xinyang Pu, Feng Xu","authorsParsed":[["Zheng","Linghao",""],["Pu","Xinyang",""],["Xu","Feng",""]],"versions":[{"version":"v1","created":"Fri, 16 Aug 2024 07:23:22 GMT"}],"updateDate":"2024-08-19","timestamp":1723793002000,"abstract":"  The Segment Anything Model (SAM), a foundational model designed for\npromptable segmentation tasks, demonstrates exceptional generalization\ncapabilities, making it highly promising for natural scene image segmentation.\nHowever, SAM's lack of pretraining on massive remote sensing images and its\ninteractive structure limit its automatic mask prediction capabilities. In this\npaper, a Multi-Cognitive SAM-Based Instance Segmentation Model (MC-SAM SEG) is\nintroduced to employ SAM on remote sensing domain. The SAM-Mona encoder\nutilizing the Multi-cognitive Visual Adapter (Mona) is conducted to facilitate\nSAM's transfer learning in remote sensing applications. The proposed method\nnamed MC-SAM SEG extracts high-quality features by fine-tuning the SAM-Mona\nencoder along with a feature aggregator. Subsequently, a pixel decoder and\ntransformer decoder are designed for prompt-free mask generation and instance\nclassification. The comprehensive experiments are conducted on the HRSID and\nWHU datasets for instance segmentation tasks on Synthetic Aperture Radar (SAR)\nimages and optical remote sensing images respectively. The evaluation results\nindicate the proposed method surpasses other deep learning algorithms and\nverify its effectiveness and generalization.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}