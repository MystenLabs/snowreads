{"id":"2407.11619","title":"Strategic Littlestone Dimension: Improved Bounds on Online Strategic\n  Classification","authors":"Saba Ahmadi, Kunhe Yang, Hanrui Zhang","authorsParsed":[["Ahmadi","Saba",""],["Yang","Kunhe",""],["Zhang","Hanrui",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 11:31:20 GMT"}],"updateDate":"2024-07-17","timestamp":1721129480000,"abstract":"  We study the problem of online binary classification in settings where\nstrategic agents can modify their observable features to receive a positive\nclassification. We model the set of feasible manipulations by a directed graph\nover the feature space, and assume the learner only observes the manipulated\nfeatures instead of the original ones. We introduce the Strategic Littlestone\nDimension, a new combinatorial measure that captures the joint complexity of\nthe hypothesis class and the manipulation graph. We demonstrate that it\ncharacterizes the instance-optimal mistake bounds for deterministic learning\nalgorithms in the realizable setting. We also achieve improved regret in the\nagnostic setting by a refined agnostic-to-realizable reduction that accounts\nfor the additional challenge of not observing agents' original features.\nFinally, we relax the assumption that the learner knows the manipulation graph,\ninstead assuming their knowledge is captured by a family of graphs. We derive\nregret bounds in both the realizable setting where all agents manipulate\naccording to the same graph within the graph family, and the agnostic setting\nwhere the manipulation graphs are chosen adversarially and not consistently\nmodeled by a single graph in the family.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Computer Science and Game Theory"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}