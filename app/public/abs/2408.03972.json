{"id":"2408.03972","title":"Enhancing Output Diversity Improves Conjugate Gradient-based Adversarial\n  Attacks","authors":"Keiichiro Yamamura, Issa Oe, Hiroki Ishikura, Katsuki Fujisawa","authorsParsed":[["Yamamura","Keiichiro",""],["Oe","Issa",""],["Ishikura","Hiroki",""],["Fujisawa","Katsuki",""]],"versions":[{"version":"v1","created":"Wed, 7 Aug 2024 07:07:35 GMT"}],"updateDate":"2024-08-09","timestamp":1723014455000,"abstract":"  Deep neural networks are vulnerable to adversarial examples, and adversarial\nattacks that generate adversarial examples have been studied in this context.\nExisting studies imply that increasing the diversity of model outputs\ncontributes to improving the attack performance. This study focuses on the Auto\nConjugate Gradient (ACG) attack, which is inspired by the conjugate gradient\nmethod and has a high diversification performance. We hypothesized that\nincreasing the distance between two consecutive search points would enhance the\noutput diversity. To test our hypothesis, we propose Rescaling-ACG (ReACG),\nwhich automatically modifies the two components that significantly affect the\ndistance between two consecutive search points, including the search direction\nand step size. ReACG showed higher attack performance than that of ACG, and is\nparticularly effective for ImageNet models with several classification classes.\nExperimental results show that the distance between two consecutive search\npoints enhances the output diversity and may help develop new potent attacks.\nThe code is available at \\url{https://github.com/yamamura-k/ReACG}\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}