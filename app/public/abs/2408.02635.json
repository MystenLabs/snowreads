{"id":"2408.02635","title":"Interactive 3D Medical Image Segmentation with SAM 2","authors":"Chuyun Shen, Wenhao Li, Yuhang Shi, Xiangfeng Wang","authorsParsed":[["Shen","Chuyun",""],["Li","Wenhao",""],["Shi","Yuhang",""],["Wang","Xiangfeng",""]],"versions":[{"version":"v1","created":"Mon, 5 Aug 2024 16:58:56 GMT"}],"updateDate":"2024-08-06","timestamp":1722877136000,"abstract":"  Interactive medical image segmentation (IMIS) has shown significant potential\nin enhancing segmentation accuracy by integrating iterative feedback from\nmedical professionals. However, the limited availability of enough 3D medical\ndata restricts the generalization and robustness of most IMIS methods. The\nSegment Anything Model (SAM), though effective for 2D images, requires\nexpensive semi-auto slice-by-slice annotations for 3D medical images. In this\npaper, we explore the zero-shot capabilities of SAM 2, the next-generation Meta\nSAM model trained on videos, for 3D medical image segmentation. By treating\nsequential 2D slices of 3D images as video frames, SAM 2 can fully\nautomatically propagate annotations from a single frame to the entire 3D\nvolume. We propose a practical pipeline for using SAM 2 in 3D medical image\nsegmentation and present key findings highlighting its efficiency and potential\nfor further optimization. Concretely, numerical experiments on the BraTS2020\nand the medical segmentation decathlon datasets demonstrate that SAM 2 still\nhas a gap with supervised methods but can narrow the gap in specific settings\nand organ types, significantly reducing the annotation burden on medical\nprofessionals. Our code will be open-sourced and available at\nhttps://github.com/Chuyun-Shen/SAM_2_Medical_3D.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}