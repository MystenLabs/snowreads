{"id":"2408.00738","title":"Virchow2: Scaling Self-Supervised Mixed Magnification Models in\n  Pathology","authors":"Eric Zimmermann, Eugene Vorontsov, Julian Viret, Adam Casson, Michal\n  Zelechowski, George Shaikovski, Neil Tenenholtz, James Hall, David Klimstra,\n  Razik Yousfi, Thomas Fuchs, Nicolo Fusi, Siqi Liu, Kristen Severson","authorsParsed":[["Zimmermann","Eric",""],["Vorontsov","Eugene",""],["Viret","Julian",""],["Casson","Adam",""],["Zelechowski","Michal",""],["Shaikovski","George",""],["Tenenholtz","Neil",""],["Hall","James",""],["Klimstra","David",""],["Yousfi","Razik",""],["Fuchs","Thomas",""],["Fusi","Nicolo",""],["Liu","Siqi",""],["Severson","Kristen",""]],"versions":[{"version":"v1","created":"Thu, 1 Aug 2024 17:35:58 GMT"},{"version":"v2","created":"Wed, 14 Aug 2024 21:18:38 GMT"}],"updateDate":"2024-08-16","timestamp":1722533758000,"abstract":"  Foundation models are rapidly being developed for computational pathology\napplications. However, it remains an open question which factors are most\nimportant for downstream performance with data scale and diversity, model size,\nand training algorithm all playing a role. In this work, we propose algorithmic\nmodifications, tailored for pathology, and we present the result of scaling\nboth data and model size, surpassing previous studies in both dimensions. We\nintroduce two new models: Virchow2, a 632 million parameter vision transformer,\nand Virchow2G, a 1.9 billion parameter vision transformer, each trained with\n3.1 million histopathology whole slide images, with diverse tissues,\noriginating institutions, and stains. We achieve state of the art performance\non 12 tile-level tasks, as compared to the top performing competing models. Our\nresults suggest that data diversity and domain-specific methods can outperform\nmodels that only scale in the number of parameters, but, on average,\nperformance benefits from the combination of domain-specific methods, data\nscale, and model scale.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"lD25-m5dClCNnDq9iFYW2qBza1GaYqicICwkVXRltXs","pdfSize":"701751","txDigest":"Gf1yx4jSAzvW2t4mTJMvK7SopRg8EMZnei2QqUmxKEUT","endEpoch":"1","status":"CERTIFIED"}
