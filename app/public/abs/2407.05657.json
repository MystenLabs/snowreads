{"id":"2407.05657","title":"DMSD-CDFSAR: Distillation from Mixed-Source Domain for Cross-Domain\n  Few-shot Action Recognition","authors":"Fei Guo, YiKang Wang, Han Qi, Li Zhu and Jing Sun","authorsParsed":[["Guo","Fei",""],["Wang","YiKang",""],["Qi","Han",""],["Zhu","Li",""],["Sun","Jing",""]],"versions":[{"version":"v1","created":"Mon, 8 Jul 2024 06:32:44 GMT"}],"updateDate":"2024-07-09","timestamp":1720420364000,"abstract":"  Few-shot action recognition is an emerging field in computer vision,\nprimarily focused on meta-learning within the same domain. However, challenges\narise in real-world scenario deployment, as gathering extensive labeled data\nwithin a specific domain is laborious and time-intensive. Thus, attention\nshifts towards cross-domain few-shot action recognition, requiring the model to\ngeneralize across domains with significant deviations. Therefore, we propose a\nnovel approach, ``Distillation from Mixed-Source Domain\", tailored to address\nthis conundrum. Our method strategically integrates insights from both labeled\ndata of the source domain and unlabeled data of the target domain during the\ntraining. The ResNet18 is used as the backbone to extract spatial features from\nthe source and target domains. We design two branches for meta-training: the\noriginal-source and the mixed-source branches. In the first branch, a Domain\nTemporal Encoder is employed to capture temporal features for both the source\nand target domains. Additionally, a Domain Temporal Decoder is employed to\nreconstruct all extracted features. In the other branch, a Domain Mixed Encoder\nis used to handle labeled source domain data and unlabeled target domain data,\ngenerating mixed-source domain features. We incorporate a pre-training stage\nbefore meta-training, featuring a network architecture similar to that of the\nfirst branch. Lastly, we introduce a dual distillation mechanism to refine the\nclassification probabilities of source domain features, aligning them with\nthose of mixed-source domain features. This iterative process enriches the\ninsights of the original-source branch with knowledge from the mixed-source\nbranch, thereby enhancing the model's generalization capabilities. Our code is\navailable at URL: \\url{https://xxxx/xxxx/xxxx.git}\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}