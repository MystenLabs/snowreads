{"id":"2407.09379","title":"FANet: Feature Amplification Network for Semantic Segmentation in\n  Cluttered Background","authors":"Muhammad Ali, Mamoona Javaid, Mubashir Noman, Mustansar Fiaz, Salman\n  Khan","authorsParsed":[["Ali","Muhammad",""],["Javaid","Mamoona",""],["Noman","Mubashir",""],["Fiaz","Mustansar",""],["Khan","Salman",""]],"versions":[{"version":"v1","created":"Fri, 12 Jul 2024 15:57:52 GMT"}],"updateDate":"2024-07-15","timestamp":1720799872000,"abstract":"  Existing deep learning approaches leave out the semantic cues that are\ncrucial in semantic segmentation present in complex scenarios including\ncluttered backgrounds and translucent objects, etc. To handle these challenges,\nwe propose a feature amplification network (FANet) as a backbone network that\nincorporates semantic information using a novel feature enhancement module at\nmulti-stages. To achieve this, we propose an adaptive feature enhancement (AFE)\nblock that benefits from both a spatial context module (SCM) and a feature\nrefinement module (FRM) in a parallel fashion. SCM aims to exploit larger\nkernel leverages for the increased receptive field to handle scale variations\nin the scene. Whereas our novel FRM is responsible for generating semantic cues\nthat can capture both low-frequency and high-frequency regions for better\nsegmentation tasks. We perform experiments over challenging real-world\nZeroWaste-f dataset which contains background-cluttered and translucent\nobjects. Our experimental results demonstrate the state-of-the-art performance\ncompared to existing methods.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}