{"id":"2408.04423","title":"UNMuTe: Unifying Navigation and Multimodal Dialogue-like Text Generation","authors":"Niyati Rawal, Roberto Bigazzi, Lorenzo Baraldi and Rita Cucchiara","authorsParsed":[["Rawal","Niyati",""],["Bigazzi","Roberto",""],["Baraldi","Lorenzo",""],["Cucchiara","Rita",""]],"versions":[{"version":"v1","created":"Thu, 8 Aug 2024 12:47:52 GMT"}],"updateDate":"2024-08-09","timestamp":1723121272000,"abstract":"  Smart autonomous agents are becoming increasingly important in various\nreal-life applications, including robotics and autonomous vehicles. One crucial\nskill that these agents must possess is the ability to interact with their\nsurrounding entities, such as other agents or humans. In this work, we aim at\nbuilding an intelligent agent that can efficiently navigate in an environment\nwhile being able to interact with an oracle (or human) in natural language and\nask for directions when it is unsure about its navigation performance. The\ninteraction is started by the agent that produces a question, which is then\nanswered by the oracle on the basis of the shortest trajectory to the goal. The\nprocess can be performed multiple times during navigation, thus enabling the\nagent to hold a dialogue with the oracle. To this end, we propose a novel\ncomputational model, named UNMuTe, that consists of two main components: a\ndialogue model and a navigator. Specifically, the dialogue model is based on a\nGPT-2 decoder that handles multimodal data consisting of both text and images.\nFirst, the dialogue model is trained to generate question-answer pairs: the\nquestion is generated using the current image, while the answer is produced\nleveraging future images on the path toward the goal. Subsequently, a VLN model\nis trained to follow the dialogue predicting navigation actions or triggering\nthe dialogue model if it needs help. In our experimental analysis, we show that\nUNMuTe achieves state-of-the-art performance on the main navigation tasks\nimplying dialogue, i.e. Cooperative Vision and Dialogue Navigation (CVDN) and\nNavigation from Dialogue History (NDH), proving that our approach is effective\nin generating useful questions and answers to guide navigation.\n","subjects":["Computing Research Repository/Robotics"],"license":"http://creativecommons.org/licenses/by/4.0/"}