{"id":"2407.16160","title":"UniMEL: A Unified Framework for Multimodal Entity Linking with Large\n  Language Models","authors":"Liu Qi, He Yongyi, Lian Defu, Zheng Zhi, Xu Tong, Liu Che, and Chen\n  Enhong","authorsParsed":[["Qi","Liu",""],["Yongyi","He",""],["Defu","Lian",""],["Zhi","Zheng",""],["Tong","Xu",""],["Che","Liu",""],["Enhong","Chen",""]],"versions":[{"version":"v1","created":"Tue, 23 Jul 2024 03:58:08 GMT"},{"version":"v2","created":"Wed, 21 Aug 2024 01:52:02 GMT"}],"updateDate":"2024-08-22","timestamp":1721707088000,"abstract":"  Multimodal Entity Linking (MEL) is a crucial task that aims at linking\nambiguous mentions within multimodal contexts to the referent entities in a\nmultimodal knowledge base, such as Wikipedia. Existing methods focus heavily on\nusing complex mechanisms and extensive model tuning methods to model the\nmultimodal interaction on specific datasets. However, these methods\novercomplicate the MEL task and overlook the visual semantic information, which\nmakes them costly and hard to scale. Moreover, these methods can not solve the\nissues like textual ambiguity, redundancy, and noisy images, which severely\ndegrade their performance. Fortunately, the advent of Large Language Models\n(LLMs) with robust capabilities in text understanding and reasoning,\nparticularly Multimodal Large Language Models (MLLMs) that can process\nmultimodal inputs, provides new insights into addressing this challenge.\nHowever, how to design a universally applicable LLMs-based MEL approach remains\na pressing challenge. To this end, we propose UniMEL, a unified framework which\nestablishes a new paradigm to process multimodal entity linking tasks using\nLLMs. In this framework, we employ LLMs to augment the representation of\nmentions and entities individually by integrating textual and visual\ninformation and refining textual information. Subsequently, we employ the\nembedding-based method for retrieving and re-ranking candidate entities. Then,\nwith only ~0.26% of the model parameters fine-tuned, LLMs can make the final\nselection from the candidate entities. Extensive experiments on three public\nbenchmark datasets demonstrate that our solution achieves state-of-the-art\nperformance, and ablation studies verify the effectiveness of all modules. Our\ncode is available at https://github.com/Javkonline/UniMEL.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}