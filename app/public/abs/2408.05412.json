{"id":"2408.05412","title":"Style-Preserving Lip Sync via Audio-Aware Style Reference","authors":"Weizhi Zhong, Jichang Li, Yinqi Cai, Liang Lin, Guanbin Li","authorsParsed":[["Zhong","Weizhi",""],["Li","Jichang",""],["Cai","Yinqi",""],["Lin","Liang",""],["Li","Guanbin",""]],"versions":[{"version":"v1","created":"Sat, 10 Aug 2024 02:46:11 GMT"}],"updateDate":"2024-08-13","timestamp":1723257971000,"abstract":"  Audio-driven lip sync has recently drawn significant attention due to its\nwidespread application in the multimedia domain. Individuals exhibit distinct\nlip shapes when speaking the same utterance, attributed to the unique speaking\nstyles of individuals, posing a notable challenge for audio-driven lip sync.\nEarlier methods for such task often bypassed the modeling of personalized\nspeaking styles, resulting in sub-optimal lip sync conforming to the general\nstyles. Recent lip sync techniques attempt to guide the lip sync for arbitrary\naudio by aggregating information from a style reference video, yet they can not\npreserve the speaking styles well due to their inaccuracy in style aggregation.\nThis work proposes an innovative audio-aware style reference scheme that\neffectively leverages the relationships between input audio and reference audio\nfrom style reference video to address the style-preserving audio-driven lip\nsync. Specifically, we first develop an advanced Transformer-based model adept\nat predicting lip motion corresponding to the input audio, augmented by the\nstyle information aggregated through cross-attention layers from style\nreference video. Afterwards, to better render the lip motion into realistic\ntalking face video, we devise a conditional latent diffusion model, integrating\nlip motion through modulated convolutional layers and fusing reference facial\nimages via spatial cross-attention layers. Extensive experiments validate the\nefficacy of the proposed approach in achieving precise lip sync, preserving\nspeaking styles, and generating high-fidelity, realistic talking face videos.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Multimedia"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}