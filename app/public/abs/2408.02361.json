{"id":"2408.02361","title":"Dialogue Ontology Relation Extraction via Constrained Chain-of-Thought\n  Decoding","authors":"Renato Vukovic, David Arps, Carel van Niekerk, Benjamin Matthias\n  Ruppik, Hsien-Chin Lin, Michael Heck, Milica Ga\\v{s}i\\'c","authorsParsed":[["Vukovic","Renato",""],["Arps","David",""],["van Niekerk","Carel",""],["Ruppik","Benjamin Matthias",""],["Lin","Hsien-Chin",""],["Heck","Michael",""],["Gašić","Milica",""]],"versions":[{"version":"v1","created":"Mon, 5 Aug 2024 10:10:01 GMT"}],"updateDate":"2024-08-06","timestamp":1722852601000,"abstract":"  State-of-the-art task-oriented dialogue systems typically rely on\ntask-specific ontologies for fulfilling user queries. The majority of\ntask-oriented dialogue data, such as customer service recordings, comes without\nontology and annotation. Such ontologies are normally built manually, limiting\nthe application of specialised systems. Dialogue ontology construction is an\napproach for automating that process and typically consists of two steps: term\nextraction and relation extraction. In this work, we focus on relation\nextraction in a transfer learning set-up. To improve the generalisation, we\npropose an extension to the decoding mechanism of large language models. We\nadapt Chain-of-Thought (CoT) decoding, recently developed for reasoning\nproblems, to generative relation extraction. Here, we generate multiple\nbranches in the decoding space and select the relations based on a confidence\nthreshold. By constraining the decoding to ontology terms and relations, we aim\nto decrease the risk of hallucination. We conduct extensive experimentation on\ntwo widely used datasets and find improvements in performance on target\nontology for source fine-tuned and one-shot prompted large language models.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"TPu3nHFvoX2FeNLEJDAnWnVI2qHaqLbtONWd2PaecCY","pdfSize":"488223","txDigest":"3ABkV7mbyNsD1mzhhLfAhtopNVeNX3TibQcqT2r4BYdF","endEpoch":"1","status":"CERTIFIED"}
