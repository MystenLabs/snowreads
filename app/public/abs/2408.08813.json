{"id":"2408.08813","title":"Retrieval-augmented Few-shot Medical Image Segmentation with Foundation\n  Models","authors":"Lin Zhao, Xiao Chen, Eric Z. Chen, Yikang Liu, Terrence Chen, Shanhui\n  Sun","authorsParsed":[["Zhao","Lin",""],["Chen","Xiao",""],["Chen","Eric Z.",""],["Liu","Yikang",""],["Chen","Terrence",""],["Sun","Shanhui",""]],"versions":[{"version":"v1","created":"Fri, 16 Aug 2024 15:48:07 GMT"}],"updateDate":"2024-08-19","timestamp":1723823287000,"abstract":"  Medical image segmentation is crucial for clinical decision-making, but the\nscarcity of annotated data presents significant challenges. Few-shot\nsegmentation (FSS) methods show promise but often require retraining on the\ntarget domain and struggle to generalize across different modalities.\nSimilarly, adapting foundation models like the Segment Anything Model (SAM) for\nmedical imaging has limitations, including the need for finetuning and\ndomain-specific adaptation. To address these issues, we propose a novel method\nthat adapts DINOv2 and Segment Anything Model 2 (SAM 2) for retrieval-augmented\nfew-shot medical image segmentation. Our approach uses DINOv2's feature as\nquery to retrieve similar samples from limited annotated data, which are then\nencoded as memories and stored in memory bank. With the memory attention\nmechanism of SAM 2, the model leverages these memories as conditions to\ngenerate accurate segmentation of the target image. We evaluated our framework\non three medical image segmentation tasks, demonstrating superior performance\nand generalizability across various modalities without the need for any\nretraining or finetuning. Overall, this method offers a practical and effective\nsolution for few-shot medical image segmentation and holds significant\npotential as a valuable annotation tool in clinical applications.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}