{"id":"2408.10362","title":"Query languages for neural networks","authors":"Martin Grohe, Christoph Standke, Juno Steegmans, Jan Van den Bussche","authorsParsed":[["Grohe","Martin",""],["Standke","Christoph",""],["Steegmans","Juno",""],["Bussche","Jan Van den",""]],"versions":[{"version":"v1","created":"Mon, 19 Aug 2024 18:59:52 GMT"},{"version":"v2","created":"Wed, 21 Aug 2024 12:50:01 GMT"}],"updateDate":"2024-08-22","timestamp":1724093992000,"abstract":"  We lay the foundations for a database-inspired approach to interpreting and\nunderstanding neural network models by querying them using declarative\nlanguages. Towards this end we study different query languages, based on\nfirst-order logic, that mainly differ in their access to the neural network\nmodel. First-order logic over the reals naturally yields a language which views\nthe network as a black box; only the input--output function defined by the\nnetwork can be queried. This is essentially the approach of constraint query\nlanguages. On the other hand, a white-box language can be obtained by viewing\nthe network as a weighted graph, and extending first-order logic with summation\nover weight terms. The latter approach is essentially an abstraction of SQL. In\ngeneral, the two approaches are incomparable in expressive power, as we will\nshow. Under natural circumstances, however, the white-box approach can subsume\nthe black-box approach; this is our main result. We prove the result concretely\nfor linear constraint queries over real functions definable by feedforward\nneural networks with a fixed number of hidden layers and piecewise linear\nactivation functions.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Databases","Computing Research Repository/Logic in Computer Science"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}