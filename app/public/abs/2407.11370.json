{"id":"2407.11370","title":"A Pilot Study of GSLM-based Simulation of Foreign Accentuation Only\n  Using Native Speech Corpora","authors":"Kentaro Onda, Joonyong Park, Nobuaki Minematsu, Daisuke Saito","authorsParsed":[["Onda","Kentaro",""],["Park","Joonyong",""],["Minematsu","Nobuaki",""],["Saito","Daisuke",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 04:29:00 GMT"}],"updateDate":"2024-07-17","timestamp":1721104140000,"abstract":"  We propose a method of simulating the human process of foreign accentuation\nusing Generative Spoken Language Model (GSLM) only with native speech corpora.\nWhen one listens to spoken words of a foreign language and repeats them, the\nrepeated speech is often with the accent of that listener's L1. This is said to\nbe because the spoken words are mentally represented as a sequence of\nphonological units of the L1, and those units are used for oral reproduction.\nWe simulate this process by inputting speech of language A into GSLM of\nlanguage B to add B's accent onto the input speech. The process of running ASR\nof the L1 for foreign input speech and giving the ASR result to TTS of the L1\ncan be viewed as a naive implementation of this approach. The results of our\nexperiments show that the synthesized accent of the output speech is highly\nnatural, compared to real samples of A generated by speakers whose L1 is B, and\nthat the degree of accentuation is controllable.\n","subjects":["Computing Research Repository/Sound","Computing Research Repository/Computation and Language","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}