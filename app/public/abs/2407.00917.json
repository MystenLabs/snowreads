{"id":"2407.00917","title":"From Category to Scenery: An End-to-End Framework for Multi-Person\n  Human-Object Interaction Recognition in Videos","authors":"Tanqiu Qiao, Ruochen Li, Frederick W. B. Li, Hubert P. H. Shum","authorsParsed":[["Qiao","Tanqiu",""],["Li","Ruochen",""],["Li","Frederick W. B.",""],["Shum","Hubert P. H.",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 02:42:55 GMT"},{"version":"v2","created":"Tue, 23 Jul 2024 13:10:28 GMT"}],"updateDate":"2024-07-24","timestamp":1719801775000,"abstract":"  Video-based Human-Object Interaction (HOI) recognition explores the intricate\ndynamics between humans and objects, which are essential for a comprehensive\nunderstanding of human behavior and intentions. While previous work has made\nsignificant strides, effectively integrating geometric and visual features to\nmodel dynamic relationships between humans and objects in a graph framework\nremains a challenge. In this work, we propose a novel end-to-end category to\nscenery framework, CATS, starting by generating geometric features for various\ncategories through graphs respectively, then fusing them with corresponding\nvisual features. Subsequently, we construct a scenery interactive graph with\nthese enhanced geometric-visual features as nodes to learn the relationships\namong human and object categories. This methodological advance facilitates a\ndeeper, more structured comprehension of interactions, bridging\ncategory-specific insights with broad scenery dynamics. Our method demonstrates\nstate-of-the-art performance on two pivotal HOI benchmarks, including the\nMPHOI-72 dataset for multi-person HOIs and the single-person HOI CAD-120\ndataset.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}