{"id":"2407.19853","title":"Online Multi-Source Domain Adaptation through Gaussian Mixtures and\n  Dataset Dictionary Learning","authors":"Eduardo Fernandes Montesuma, Stevan Le Stanc, Fred Ngol\\`e Mboula","authorsParsed":[["Montesuma","Eduardo Fernandes",""],["Stanc","Stevan Le",""],["Mboula","Fred Ngol√®",""]],"versions":[{"version":"v1","created":"Mon, 29 Jul 2024 10:10:40 GMT"}],"updateDate":"2024-07-30","timestamp":1722247840000,"abstract":"  This paper addresses the challenge of online multi-source domain adaptation\n(MSDA) in transfer learning, a scenario where one needs to adapt multiple,\nheterogeneous source domains towards a target domain that comes in a stream. We\nintroduce a novel approach for the online fit of a Gaussian Mixture Model\n(GMM), based on the Wasserstein geometry of Gaussian measures. We build upon\nthis method and recent developments in dataset dictionary learning for\nproposing a novel strategy in online MSDA. Experiments on the challenging\nTennessee Eastman Process benchmark demonstrate that our approach is able to\nadapt \\emph{on the fly} to the stream of target domain data. Furthermore, our\nonline GMM serves as a memory, representing the whole stream of data.\n","subjects":["Computing Research Repository/Machine Learning","Statistics/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}