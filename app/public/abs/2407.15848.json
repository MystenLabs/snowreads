{"id":"2407.15848","title":"BoostMVSNeRFs: Boosting MVS-based NeRFs to Generalizable View Synthesis\n  in Large-scale Scenes","authors":"Chih-Hai Su, Chih-Yao Hu, Shr-Ruei Tsai, Jie-Ying Lee, Chin-Yang Lin,\n  Yu-Lun Liu","authorsParsed":[["Su","Chih-Hai",""],["Hu","Chih-Yao",""],["Tsai","Shr-Ruei",""],["Lee","Jie-Ying",""],["Lin","Chin-Yang",""],["Liu","Yu-Lun",""]],"versions":[{"version":"v1","created":"Mon, 22 Jul 2024 17:59:46 GMT"}],"updateDate":"2024-07-23","timestamp":1721671186000,"abstract":"  While Neural Radiance Fields (NeRFs) have demonstrated exceptional quality,\ntheir protracted training duration remains a limitation. Generalizable and\nMVS-based NeRFs, although capable of mitigating training time, often incur\ntradeoffs in quality. This paper presents a novel approach called BoostMVSNeRFs\nto enhance the rendering quality of MVS-based NeRFs in large-scale scenes. We\nfirst identify limitations in MVS-based NeRF methods, such as restricted\nviewport coverage and artifacts due to limited input views. Then, we address\nthese limitations by proposing a new method that selects and combines multiple\ncost volumes during volume rendering. Our method does not require training and\ncan adapt to any MVS-based NeRF methods in a feed-forward fashion to improve\nrendering quality. Furthermore, our approach is also end-to-end trainable,\nallowing fine-tuning on specific scenes. We demonstrate the effectiveness of\nour method through experiments on large-scale datasets, showing significant\nrendering quality improvements in large-scale scenes and unbounded outdoor\nscenarios. We release the source code of BoostMVSNeRFs at\nhttps://su-terry.github.io/BoostMVSNeRFs/.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"XieLNK5BvNoG-wArlfV_SlyAl5po4qi823ASSj9NiM4","pdfSize":"28696545"}
