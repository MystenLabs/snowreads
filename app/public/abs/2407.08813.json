{"id":"2407.08813","title":"FairDomain: Achieving Fairness in Cross-Domain Medical Image\n  Segmentation and Classification","authors":"Yu Tian and Congcong Wen and Min Shi and Muhammad Muneeb Afzal and Hao\n  Huang and Muhammad Osama Khan and Yan Luo and Yi Fang and Mengyu Wang","authorsParsed":[["Tian","Yu",""],["Wen","Congcong",""],["Shi","Min",""],["Afzal","Muhammad Muneeb",""],["Huang","Hao",""],["Khan","Muhammad Osama",""],["Luo","Yan",""],["Fang","Yi",""],["Wang","Mengyu",""]],"versions":[{"version":"v1","created":"Thu, 11 Jul 2024 18:52:32 GMT"},{"version":"v2","created":"Thu, 18 Jul 2024 20:30:28 GMT"}],"updateDate":"2024-07-22","timestamp":1720723952000,"abstract":"  Addressing fairness in artificial intelligence (AI), particularly in medical\nAI, is crucial for ensuring equitable healthcare outcomes. Recent efforts to\nenhance fairness have introduced new methodologies and datasets in medical AI.\nHowever, the fairness issue under the setting of domain transfer is almost\nunexplored, while it is common that clinics rely on different imaging\ntechnologies (e.g., different retinal imaging modalities) for patient\ndiagnosis. This paper presents FairDomain, a pioneering systemic study into\nalgorithmic fairness under domain shifts, employing state-of-the-art domain\nadaptation (DA) and generalization (DG) algorithms for both medical\nsegmentation and classification tasks to understand how biases are transferred\nbetween different domains. We also introduce a novel plug-and-play fair\nidentity attention (FIA) module that adapts to various DA and DG algorithms to\nimprove fairness by using self-attention to adjust feature importance based on\ndemographic attributes. Additionally, we curate the first fairness-focused\ndataset with two paired imaging modalities for the same patient cohort on\nmedical segmentation and classification tasks, to rigorously assess fairness in\ndomain-shift scenarios. Excluding the confounding impact of demographic\ndistribution variation between source and target domains will allow clearer\nquantification of the performance of domain transfer models. Our extensive\nevaluations reveal that the proposed FIA significantly enhances both model\nperformance accounted for fairness across all domain shift settings (i.e., DA\nand DG) with respect to different demographics, which outperforms existing\nmethods on both segmentation and classification. The code and data can be\naccessed at https://ophai.hms.harvard.edu/datasets/harvard-fairdomain20k.\n","subjects":["Electrical Engineering and Systems Science/Image and Video Processing","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}