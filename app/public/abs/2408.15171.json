{"id":"2408.15171","title":"Measuring text summarization factuality using atomic facts entailment\n  metrics in the context of retrieval augmented generation","authors":"N. E. Kriman","authorsParsed":[["Kriman","N. E.",""]],"versions":[{"version":"v1","created":"Tue, 27 Aug 2024 16:09:56 GMT"}],"updateDate":"2024-08-28","timestamp":1724774996000,"abstract":"  The use of large language models (LLMs) has significantly increased since the\nintroduction of ChatGPT in 2022, demonstrating their value across various\napplications. However, a major challenge for enterprise and commercial adoption\nof LLMs is their tendency to generate inaccurate information, a phenomenon\nknown as \"hallucination.\" This project proposes a method for estimating the\nfactuality of a summary generated by LLMs when compared to a source text. Our\napproach utilizes Naive Bayes classification to assess the accuracy of the\ncontent produced.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/"}