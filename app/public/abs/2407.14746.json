{"id":"2407.14746","title":"Difflare: Removing Image Lens Flare with Latent Diffusion Model","authors":"Tianwen Zhou, Qihao Duan, Zitong Yu","authorsParsed":[["Zhou","Tianwen",""],["Duan","Qihao",""],["Yu","Zitong",""]],"versions":[{"version":"v1","created":"Sat, 20 Jul 2024 04:36:39 GMT"}],"updateDate":"2024-07-23","timestamp":1721450199000,"abstract":"  The recovery of high-quality images from images corrupted by lens flare\npresents a significant challenge in low-level vision. Contemporary deep\nlearning methods frequently entail training a lens flare removing model from\nscratch. However, these methods, despite their noticeable success, fail to\nutilize the generative prior learned by pre-trained models, resulting in\nunsatisfactory performance in lens flare removal. Furthermore, there are only\nfew works considering the physical priors relevant to flare removal. To address\nthese issues, we introduce Difflare, a novel approach designed for lens flare\nremoval. To leverage the generative prior learned by Pre-Trained Diffusion\nModels (PTDM), we introduce a trainable Structural Guidance Injection Module\n(SGIM) aimed at guiding the restoration process with PTDM. Towards more\nefficient training, we employ Difflare in the latent space. To address\ninformation loss resulting from latent compression and the stochastic sampling\nprocess of PTDM, we introduce an Adaptive Feature Fusion Module (AFFM), which\nincorporates the Luminance Gradient Prior (LGP) of lens flare to dynamically\nregulate feature extraction. Extensive experiments demonstrate that our\nproposed Difflare achieves state-of-the-art performance in real-world lens\nflare removal, restoring images corrupted by flare with improved fidelity and\nperceptual quality. The codes will be released soon.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Electrical Engineering and Systems Science/Image and Video Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}