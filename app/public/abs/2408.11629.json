{"id":"2408.11629","title":"A Markovian Model for Learning-to-Optimize","authors":"Michael Sucker and Peter Ochs","authorsParsed":[["Sucker","Michael",""],["Ochs","Peter",""]],"versions":[{"version":"v1","created":"Wed, 21 Aug 2024 14:00:22 GMT"}],"updateDate":"2024-08-22","timestamp":1724248822000,"abstract":"  We present a probabilistic model for stochastic iterative algorithms with the\nuse case of optimization algorithms in mind. Based on this model, we present\nPAC-Bayesian generalization bounds for functions that are defined on the\ntrajectory of the learned algorithm, for example, the expected (non-asymptotic)\nconvergence rate and the expected time to reach the stopping criterion. Thus,\nnot only does this model allow for learning stochastic algorithms based on\ntheir empirical performance, it also yields results about their actual\nconvergence rate and their actual convergence time. We stress that, since the\nmodel is valid in a more general setting than learning-to-optimize, it is of\ninterest for other fields of application, too. Finally, we conduct five\npractically relevant experiments, showing the validity of our claims.\n","subjects":["Computing Research Repository/Machine Learning","Mathematics/Probability"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"1Adwm-4XlrZVDgroIrqUyvE4cZbJv2NZIVNNn8Xo6-M","pdfSize":"3963668"}
