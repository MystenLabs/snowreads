{"id":"2407.21252","title":"Lifelong Person Search","authors":"Jae-Won Yang, Seungbin Hong, and Jae-Young Sim","authorsParsed":[["Yang","Jae-Won",""],["Hong","Seungbin",""],["Sim","Jae-Young",""]],"versions":[{"version":"v1","created":"Wed, 31 Jul 2024 00:19:22 GMT"}],"updateDate":"2024-08-01","timestamp":1722385162000,"abstract":"  Person search is the task to localize a query person in gallery datasets of\nscene images. Existing methods have been mainly developed to handle a single\ntarget dataset only, however diverse datasets are continuously given in\npractical applications of person search. In such cases, they suffer from the\ncatastrophic knowledge forgetting in the old datasets when trained on new\ndatasets. In this paper, we first introduce a novel problem of lifelong person\nsearch (LPS) where the model is incrementally trained on the new datasets while\npreserving the knowledge learned in the old datasets. We propose an end-to-end\nLPS framework that facilitates the knowledge distillation to enforce the\nconsistency learning between the old and new models by utilizing the prototype\nfeatures of the foreground persons as well as the hard background proposals in\nthe old domains. Moreover, we also devise the rehearsal-based instance matching\nto further improve the discrimination ability in the old domains by using the\nunlabeled person instances additionally. Experimental results demonstrate that\nthe proposed method achieves significantly superior performance of both the\ndetection and re-identification to preserve the knowledge learned in the old\ndomains compared with the existing methods.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}