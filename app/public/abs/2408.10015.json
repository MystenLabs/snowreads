{"id":"2408.10015","title":"Deterministic Policy Gradient Primal-Dual Methods for Continuous-Space\n  Constrained MDPs","authors":"Sergio Rozada, Dongsheng Ding, Antonio G. Marques, Alejandro Ribeiro","authorsParsed":[["Rozada","Sergio",""],["Ding","Dongsheng",""],["Marques","Antonio G.",""],["Ribeiro","Alejandro",""]],"versions":[{"version":"v1","created":"Mon, 19 Aug 2024 14:11:04 GMT"}],"updateDate":"2024-08-20","timestamp":1724076664000,"abstract":"  We study the problem of computing deterministic optimal policies for\nconstrained Markov decision processes (MDPs) with continuous state and action\nspaces, which are widely encountered in constrained dynamical systems.\nDesigning deterministic policy gradient methods in continuous state and action\nspaces is particularly challenging due to the lack of enumerable state-action\npairs and the adoption of deterministic policies, hindering the application of\nexisting policy gradient methods for constrained MDPs. To this end, we develop\na deterministic policy gradient primal-dual method to find an optimal\ndeterministic policy with non-asymptotic convergence. Specifically, we leverage\nregularization of the Lagrangian of the constrained MDP to propose a\ndeterministic policy gradient primal-dual (D-PGPD) algorithm that updates the\ndeterministic policy via a quadratic-regularized gradient ascent step and the\ndual variable via a quadratic-regularized gradient descent step. We prove that\nthe primal-dual iterates of D-PGPD converge at a sub-linear rate to an optimal\nregularized primal-dual pair. We instantiate D-PGPD with function approximation\nand prove that the primal-dual iterates of D-PGPD converge at a sub-linear rate\nto an optimal regularized primal-dual pair, up to a function approximation\nerror. Furthermore, we demonstrate the effectiveness of our method in two\ncontinuous control problems: robot navigation and fluid control. To the best of\nour knowledge, this appears to be the first work that proposes a deterministic\npolicy search method for continuous-space constrained MDPs.\n","subjects":["Computing Research Repository/Artificial Intelligence","Mathematics/Optimization and Control"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"2XCl2nfrp6oXGuKzuLm_5I25OsUsZ6NT5wZUZbdeptI","pdfSize":"3917365"}
