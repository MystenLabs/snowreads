{"id":"2408.06333","title":"FastFiD: Improve Inference Efficiency of Open Domain Question Answering\n  via Sentence Selection","authors":"Yufei Huang, Xu Han, Maosong Sun","authorsParsed":[["Huang","Yufei",""],["Han","Xu",""],["Sun","Maosong",""]],"versions":[{"version":"v1","created":"Mon, 12 Aug 2024 17:50:02 GMT"}],"updateDate":"2024-08-13","timestamp":1723485002000,"abstract":"  Open Domain Question Answering (ODQA) has been advancing rapidly in recent\ntimes, driven by significant developments in dense passage retrieval and\npretrained language models. Current models typically incorporate the FiD\nframework, which is composed by a neural retriever alongside an encoder-decoder\nneural reader. In the answer generation process, the retriever will retrieve\nnumerous passages (around 100 for instance), each of which is then individually\nencoded by the encoder. Subsequently, the decoder makes predictions based on\nthese encoded passages. Nevertheless, this framework can be relatively\ntime-consuming, particularly due to the extensive length of the gathered\npassages. To address this, we introduce FastFiD in this paper, a novel approach\nthat executes sentence selection on the encoded passages. This aids in\nretaining valuable sentences while reducing the context length required for\ngenerating answers. Experiments on three commonly used datasets (Natural\nQuestions, TriviaQA and ASQA) demonstrate that our method can enhance the\ninference speed by 2.3X-5.7X, while simultaneously maintaining the model's\nperformance. Moreover, an in-depth analysis of the model's attention reveals\nthat the selected sentences indeed hold a substantial contribution towards the\nfinal answer. The codes are publicly available at\nhttps://github.com/thunlp/FastFiD.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"toGF50Gw5D73oDmaI865xbXkgB6lmgKytDyTHOCVX_4","pdfSize":"513825"}
