{"id":"2408.09478","title":"Mitigating Noise Detriment in Differentially Private Federated Learning\n  with Model Pre-training","authors":"Huitong Jin, Yipeng Zhou, Laizhong Cui, Quan Z. Sheng","authorsParsed":[["Jin","Huitong",""],["Zhou","Yipeng",""],["Cui","Laizhong",""],["Sheng","Quan Z.",""]],"versions":[{"version":"v1","created":"Sun, 18 Aug 2024 13:48:10 GMT"}],"updateDate":"2024-08-20","timestamp":1723988890000,"abstract":"  Pre-training exploits public datasets to pre-train an advanced machine\nlearning model, so that the model can be easily tuned to adapt to various\ndownstream tasks. Pre-training has been extensively explored to mitigate\ncomputation and communication resource consumption. Inspired by these\nadvantages, we are the first to explore how model pre-training can mitigate\nnoise detriment in differentially private federated learning (DPFL). DPFL is\nupgraded from federated learning (FL), the de-facto standard for privacy\npreservation when training the model across multiple clients owning private\ndata. DPFL introduces differentially private (DP) noises to obfuscate model\ngradients exposed in FL, which however can considerably impair model accuracy.\nIn our work, we compare head fine-tuning (HT) and full fine-tuning (FT), which\nare based on pre-training, with scratch training (ST) in DPFL through a\ncomprehensive empirical study. Our experiments tune pre-trained models\n(obtained by pre-training on ImageNet-1K) with CIFAR-10, CHMNIST and\nFashion-MNIST (FMNIST) datasets, respectively. The results demonstrate that HT\nand FT can significantly mitigate noise influence by diminishing gradient\nexposure times. In particular, HT outperforms FT when the privacy budget is\ntight or the model size is large. Visualization and explanation study further\nsubstantiates our findings. Our pioneering study introduces a new perspective\non enhancing DPFL and expanding its practical applications.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Cryptography and Security"],"license":"http://creativecommons.org/licenses/by/4.0/"}