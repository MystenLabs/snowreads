{"id":"2408.05743","title":"Neural Architecture Search based Global-local Vision Mamba for Palm-Vein\n  Recognition","authors":"Huafeng Qin, Yuming Fu, Jing Chen, Mounim A. El-Yacoubi, Xinbo Gao,\n  and Feng Xi","authorsParsed":[["Qin","Huafeng",""],["Fu","Yuming",""],["Chen","Jing",""],["El-Yacoubi","Mounim A.",""],["Gao","Xinbo",""],["Xi","Feng",""]],"versions":[{"version":"v1","created":"Sun, 11 Aug 2024 10:42:22 GMT"},{"version":"v2","created":"Tue, 13 Aug 2024 13:02:23 GMT"},{"version":"v3","created":"Sat, 7 Sep 2024 02:58:43 GMT"},{"version":"v4","created":"Tue, 10 Sep 2024 09:07:35 GMT"}],"updateDate":"2024-09-11","timestamp":1723372942000,"abstract":"  Due to the advantages such as high security, high privacy, and liveness\nrecognition, vein recognition has been received more and more attention in past\nyears. Recently, deep learning models, e.g., Mamba has shown robust feature\nrepresentation with linear computational complexity and successfully applied\nfor visual tasks. However, vision Manba can capture long-distance feature\ndependencies but unfortunately deteriorate local feature details. Besides,\nmanually designing a Mamba architecture based on human priori knowledge is very\ntime-consuming and error-prone. In this paper, first, we propose a hybrid\nnetwork structure named Global-local Vision Mamba (GLVM), to learn the local\ncorrelations in images explicitly and global dependencies among tokens for vein\nfeature representation. Secondly, we design a Multi-head Mamba to learn the\ndependencies along different directions, so as to improve the feature\nrepresentation ability of vision Mamba. Thirdly, to learn the complementary\nfeatures, we propose a ConvMamba block consisting of three branches, named\nMulti-head Mamba branch (MHMamba), Feature Iteration Unit branch (FIU), and\nConvolutional Neural Network (CNN) branch, where the Feature Iteration Unit\nbranch aims to fuse convolutional local features with Mamba-based global\nrepresentations. Finally, a Globallocal Alternate Neural Architecture Search\n(GLNAS) method is proposed to search the optimal architecture of GLVM\nalternately with the evolutionary algorithm, thereby improving the recognition\nperformance for vein recognition tasks. We conduct rigorous experiments on\nthree public palm-vein databases to estimate the performance. The experimental\nresults demonstrate that the proposed method outperforms the representative\napproaches and achieves state-of-the-art recognition accuracy.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}