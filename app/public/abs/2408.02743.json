{"id":"2408.02743","title":"KAN we improve on HEP classification tasks? Kolmogorov-Arnold Networks\n  applied to an LHC physics example","authors":"Johannes Erdmann, Florian Mausolf, Jan Lukas Sp\\\"ah","authorsParsed":[["Erdmann","Johannes",""],["Mausolf","Florian",""],["Sp√§h","Jan Lukas",""]],"versions":[{"version":"v1","created":"Mon, 5 Aug 2024 18:01:07 GMT"}],"updateDate":"2024-08-07","timestamp":1722880867000,"abstract":"  Recently, Kolmogorov-Arnold Networks (KANs) have been proposed as an\nalternative to multilayer perceptrons, suggesting advantages in performance and\ninterpretability. We study a typical binary event classification task in\nhigh-energy physics including high-level features and comment on the\nperformance and interpretability of KANs in this context. We find that the\nlearned activation functions of a one-layer KAN resemble the log-likelihood\nratio of the input features. In deeper KANs, the activations in the first KAN\nlayer differ from those in the one-layer KAN, which indicates that the deeper\nKANs learn more complex representations of the data. We study KANs with\ndifferent depths and widths and we compare them to multilayer perceptrons in\nterms of performance and number of trainable parameters. For the chosen\nclassification task, we do not find that KANs are more parameter efficient.\nHowever, small KANs may offer advantages in terms of interpretability that come\nat the cost of only a moderate loss in performance.\n","subjects":["Physics/High Energy Physics - Phenomenology","Computing Research Repository/Machine Learning","Physics/High Energy Physics - Experiment","Physics/Data Analysis, Statistics and Probability"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"5AQV53mBzbTOx_AZG0UW3Tx5k4POsgeb2HyAjBoG2sY","pdfSize":"815857"}
