{"id":"2408.06546","title":"Misfitting With AI: How Blind People Verify and Contest AI Errors","authors":"Rahaf Alharbi, Pa Lor, Jaylin Herskovitz, Sarita Schoenebeck, Robin\n  Brewer","authorsParsed":[["Alharbi","Rahaf",""],["Lor","Pa",""],["Herskovitz","Jaylin",""],["Schoenebeck","Sarita",""],["Brewer","Robin",""]],"versions":[{"version":"v1","created":"Tue, 13 Aug 2024 00:48:14 GMT"}],"updateDate":"2024-08-14","timestamp":1723510094000,"abstract":"  Blind people use artificial intelligence-enabled visual assistance\ntechnologies (AI VAT) to gain visual access in their everyday lives, but these\ntechnologies are embedded with errors that may be difficult to verify\nnon-visually. Previous studies have primarily explored sighted users'\nunderstanding of AI output and created vision-dependent explainable AI (XAI)\nfeatures. We extend this body of literature by conducting an in-depth\nqualitative study with 26 blind people to understand their verification\nexperiences and preferences. We begin by describing errors blind people\nencounter, highlighting how AI VAT fails to support complex document layouts,\ndiverse languages, and cultural artifacts. We then illuminate how blind people\nmake sense of AI through experimenting with AI VAT, employing non-visual\nskills, strategically including sighted people, and cross-referencing with\nother devices. Participants provided detailed opportunities for designing\naccessible XAI, such as affordances to support contestation. Informed by\ndisability studies framework of misfitting and fitting, we unpacked harmful\nassumptions with AI VAT, underscoring the importance of celebrating disabled\nways of knowing. Lastly, we offer practical takeaways for Responsible AI\npractice to push the field of accessible XAI forward.\n","subjects":["Computing Research Repository/Human-Computer Interaction"],"license":"http://creativecommons.org/licenses/by/4.0/"}