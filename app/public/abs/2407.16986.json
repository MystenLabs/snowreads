{"id":"2407.16986","title":"Cuboid-Net: A Multi-Branch Convolutional Neural Network for Joint\n  Space-Time Video Super Resolution","authors":"Congrui Fu, Hui Yuan, Hongji Xu, Hao Zhang, Liquan Shen","authorsParsed":[["Fu","Congrui",""],["Yuan","Hui",""],["Xu","Hongji",""],["Zhang","Hao",""],["Shen","Liquan",""]],"versions":[{"version":"v1","created":"Wed, 24 Jul 2024 04:05:20 GMT"}],"updateDate":"2024-07-25","timestamp":1721793920000,"abstract":"  The demand for high-resolution videos has been consistently rising across\nvarious domains, propelled by continuous advancements in science, technology,\nand societal. Nonetheless, challenges arising from limitations in imaging\nequipment capabilities, imaging conditions, as well as economic and temporal\nfactors often result in obtaining low-resolution images in particular\nsituations. Space-time video super-resolution aims to enhance the spatial and\ntemporal resolutions of low-resolution and low-frame-rate videos. The currently\navailable space-time video super-resolution methods often fail to fully exploit\nthe abundant information existing within the spatio-temporal domain. To address\nthis problem, we tackle the issue by conceptualizing the input low-resolution\nvideo as a cuboid structure. Drawing on this perspective, we introduce an\ninnovative methodology called \"Cuboid-Net,\" which incorporates a multi-branch\nconvolutional neural network. Cuboid-Net is designed to collectively enhance\nthe spatial and temporal resolutions of videos, enabling the extraction of rich\nand meaningful information across both spatial and temporal dimensions.\nSpecifically, we take the input video as a cuboid to generate different\ndirectional slices as input for different branches of the network. The proposed\nnetwork contains four modules, i.e., a multi-branch-based hybrid feature\nextraction (MBFE) module, a multi-branch-based reconstruction (MBR) module, a\nfirst stage quality enhancement (QE) module, and a second stage cross frame\nquality enhancement (CFQE) module for interpolated frames only. Experimental\nresults demonstrate that the proposed method is not only effective for spatial\nand temporal super-resolution of video but also for spatial and angular\nsuper-resolution of light field.\n","subjects":["Electrical Engineering and Systems Science/Image and Video Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}