{"id":"2407.01069","title":"Deep Domain Specialisation for single-model multi-domain learning to\n  rank","authors":"Paul Missault and Abdelmaseeh Felfel","authorsParsed":[["Missault","Paul",""],["Felfel","Abdelmaseeh",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 08:19:19 GMT"}],"updateDate":"2024-07-02","timestamp":1719821959000,"abstract":"  Information Retrieval (IR) practitioners often train separate ranking models\nfor different domains (geographic regions, languages, stores, websites,...) as\nit is believed that exclusively training on in-domain data yields the best\nperformance when sufficient data is available. Despite their performance gains,\ntraining multiple models comes at a higher cost to train, maintain and update\ncompared to having only a single model responsible for all domains. Our work\nexplores consolidated ranking models that serve multiple domains. Specifically,\nwe propose a novel architecture of Deep Domain Specialisation (DDS) to\nconsolidate multiple domains into a single model. We compare our proposal\nagainst Deep Domain Adaptation (DDA) and a set of baseline for multi-domain\nmodels. In our experiments, DDS performed the best overall while requiring\nfewer parameters per domain as other baselines. We show the efficacy of our\nmethod both with offline experimentation and on a large-scale online experiment\non Amazon customer traffic.\n","subjects":["Computing Research Repository/Information Retrieval"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}