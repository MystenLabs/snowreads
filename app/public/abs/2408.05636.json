{"id":"2408.05636","title":"Speculative Diffusion Decoding: Accelerating Language Generation through\n  Diffusion","authors":"Jacob K Christopher, Brian R Bartoldson, Bhavya Kailkhura, Ferdinando\n  Fioretto","authorsParsed":[["Christopher","Jacob K",""],["Bartoldson","Brian R",""],["Kailkhura","Bhavya",""],["Fioretto","Ferdinando",""]],"versions":[{"version":"v1","created":"Sat, 10 Aug 2024 21:24:25 GMT"},{"version":"v2","created":"Fri, 16 Aug 2024 19:25:46 GMT"}],"updateDate":"2024-08-20","timestamp":1723325065000,"abstract":"  Speculative decoding has emerged as a widely adopted method to accelerate\nlarge language model inference without sacrificing the quality of the model\noutputs. While this technique has facilitated notable speed improvements by\nenabling parallel sequence verification, its efficiency remains inherently\nlimited by the reliance on incremental token generation in existing draft\nmodels. To overcome this limitation, this paper proposes an adaptation of\nspeculative decoding which uses discrete diffusion models to generate draft\nsequences. This allows parallelization of both the drafting and verification\nsteps, providing significant speed-ups to the inference process. Our proposed\napproach, Speculative Diffusion Decoding (SpecDiff), is validated on standard\nlanguage generation benchmarks and empirically demonstrated to provide a up to\n8.7x speed-up over standard generation processes and up to 2.5x speed-up over\nexisting speculative decoding approaches.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}