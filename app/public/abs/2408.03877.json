{"id":"2408.03877","title":"Knowledge Probing for Graph Representation Learning","authors":"Mingyu Zhao, Xingyu Huang, Ziyu Lyu, Yanlin Wang, Lixin Cui and Lu Bai","authorsParsed":[["Zhao","Mingyu",""],["Huang","Xingyu",""],["Lyu","Ziyu",""],["Wang","Yanlin",""],["Cui","Lixin",""],["Bai","Lu",""]],"versions":[{"version":"v1","created":"Wed, 7 Aug 2024 16:27:45 GMT"}],"updateDate":"2024-08-08","timestamp":1723048065000,"abstract":"  Graph learning methods have been extensively applied in diverse application\nareas. However, what kind of inherent graph properties e.g. graph proximity,\ngraph structural information has been encoded into graph representation\nlearning for downstream tasks is still under-explored. In this paper, we\npropose a novel graph probing framework (GraphProbe) to investigate and\ninterpret whether the family of graph learning methods has encoded different\nlevels of knowledge in graph representation learning. Based on the intrinsic\nproperties of graphs, we design three probes to systematically investigate the\ngraph representation learning process from different perspectives, respectively\nthe node-wise level, the path-wise level, and the structural level. We\nconstruct a thorough evaluation benchmark with nine representative graph\nlearning methods from random walk based approaches, basic graph neural networks\nand self-supervised graph methods, and probe them on six benchmark datasets for\nnode classification, link prediction and graph classification. The experimental\nevaluation verify that GraphProbe can estimate the capability of graph\nrepresentation learning. Remaking results have been concluded: GCN and\nWeightedGCN methods are relatively versatile methods achieving better results\nwith respect to different tasks.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}