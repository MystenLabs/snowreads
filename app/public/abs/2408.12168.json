{"id":"2408.12168","title":"FIRST: Teach A Reliable Large Language Model Through Efficient\n  Trustworthy Distillation","authors":"KaShun Shum, Minrui Xu, Jianshu Zhang, Zixin Chen, Shizhe Diao, Hanze\n  Dong, Jipeng Zhang, Muhammad Omer Raza","authorsParsed":[["Shum","KaShun",""],["Xu","Minrui",""],["Zhang","Jianshu",""],["Chen","Zixin",""],["Diao","Shizhe",""],["Dong","Hanze",""],["Zhang","Jipeng",""],["Raza","Muhammad Omer",""]],"versions":[{"version":"v1","created":"Thu, 22 Aug 2024 07:31:00 GMT"}],"updateDate":"2024-08-23","timestamp":1724311860000,"abstract":"  Large language models (LLMs) have become increasingly prevalent in our daily\nlives, leading to an expectation for LLMs to be trustworthy -- - both accurate\nand well-calibrated (the prediction confidence should align with its ground\ntruth correctness likelihood). Nowadays, fine-tuning has become the most\npopular method for adapting a model to practical usage by significantly\nincreasing accuracy on downstream tasks. Despite the great accuracy it\nachieves, we found fine-tuning is still far away from satisfactory\ntrustworthiness due to \"tuning-induced mis-calibration\". In this paper, we\ndelve deeply into why and how mis-calibration exists in fine-tuned models, and\nhow distillation can alleviate the issue. Then we further propose a brand new\nmethod named Efficient Trustworthy Distillation (FIRST), which utilizes a small\nportion of teacher's knowledge to obtain a reliable language model in a\ncost-efficient way. Specifically, we identify the \"concentrated knowledge\"\nphenomenon during distillation, which can significantly reduce the\ncomputational burden. Then we apply a \"trustworthy maximization\" process to\noptimize the utilization of this small portion of concentrated knowledge before\ntransferring it to the student. Experimental results demonstrate the\neffectiveness of our method, where better accuracy (+2.3%) and less\nmis-calibration (-10%) are achieved on average across both in-domain and\nout-of-domain scenarios, indicating better trustworthiness.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}