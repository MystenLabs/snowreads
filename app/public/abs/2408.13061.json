{"id":"2408.13061","title":"General Intelligent Imaging and Uncertainty Quantification by\n  Deterministic Diffusion Model","authors":"Weiru Fan, Xiaobin Tang, Yiyi Liao and Da-Wei Wang","authorsParsed":[["Fan","Weiru",""],["Tang","Xiaobin",""],["Liao","Yiyi",""],["Wang","Da-Wei",""]],"versions":[{"version":"v1","created":"Fri, 23 Aug 2024 13:37:54 GMT"}],"updateDate":"2024-08-26","timestamp":1724420274000,"abstract":"  Computational imaging is crucial in many disciplines from autonomous driving\nto life sciences. However, traditional model-driven and iterative methods\nconsume large computational power and lack scalability for imaging. Deep\nlearning (DL) is effective in processing local-to-local patterns, but it\nstruggles with handling universal global-to-local (nonlocal) patterns under\ncurrent frameworks. To bridge this gap, we propose a novel DL framework that\nemploys a progressive denoising strategy, named the deterministic diffusion\nmodel (DDM), to facilitate general computational imaging at a low cost. We\nexperimentally demonstrate the efficient and faithful image reconstruction\ncapabilities of DDM from nonlocal patterns, such as speckles from multimode\nfiber and intensity patterns of second harmonic generation, surpassing the\ncapability of previous state-of-the-art DL algorithms. By embedding Bayesian\ninference into DDM, we establish a theoretical framework and provide\nexperimental proof of its uncertainty quantification. This advancement ensures\nthe predictive reliability of DDM, avoiding misjudgment in high-stakes\nscenarios. This versatile and integrable DDM framework can readily extend and\nimprove the efficacy of existing DL-based imaging applications.\n","subjects":["Electrical Engineering and Systems Science/Image and Video Processing","Physics/Optics"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}