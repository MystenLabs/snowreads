{"id":"2407.10796","title":"Mammographic Breast Positioning Assessment via Deep Learning","authors":"Toygar Tanyel, Nurper Denizoglu, Mustafa Ege Seker, Deniz Alis, Esma\n  Cerekci, Ercan Karaarslan, Erkin Aribal and Ilkay Oksuz","authorsParsed":[["Tanyel","Toygar",""],["Denizoglu","Nurper",""],["Seker","Mustafa Ege",""],["Alis","Deniz",""],["Cerekci","Esma",""],["Karaarslan","Ercan",""],["Aribal","Erkin",""],["Oksuz","Ilkay",""]],"versions":[{"version":"v1","created":"Mon, 15 Jul 2024 15:14:10 GMT"}],"updateDate":"2024-07-16","timestamp":1721056450000,"abstract":"  Breast cancer remains a leading cause of cancer-related deaths among women\nworldwide, with mammography screening as the most effective method for the\nearly detection. Ensuring proper positioning in mammography is critical, as\npoor positioning can lead to diagnostic errors, increased patient stress, and\nhigher costs due to recalls. Despite advancements in deep learning (DL) for\nbreast cancer diagnostics, limited focus has been given to evaluating\nmammography positioning. This paper introduces a novel DL methodology to\nquantitatively assess mammogram positioning quality, specifically in\nmediolateral oblique (MLO) views using attention and coordinate convolution\nmodules. Our method identifies key anatomical landmarks, such as the nipple and\npectoralis muscle, and automatically draws a posterior nipple line (PNL),\noffering robust and inherently explainable alternative to well-known\nclassification and regression-based approaches. We compare the performance of\nproposed methodology with various regression and classification-based models.\nThe CoordAtt UNet model achieved the highest accuracy of 88.63% $\\pm$ 2.84 and\nspecificity of 90.25% $\\pm$ 4.04, along with a noteworthy sensitivity of 86.04%\n$\\pm$ 3.41. In landmark detection, the same model also recorded the lowest mean\nerrors in key anatomical points and the smallest angular error of 2.42 degrees.\nOur results indicate that models incorporating attention mechanisms and\nCoordConv module increase the accuracy in classifying breast positioning\nquality and detecting anatomical landmarks. Furthermore, we make the labels and\nsource codes available to the community to initiate an open research area for\nmammography, accessible at https://github.com/tanyelai/deep-breast-positioning.\n","subjects":["Electrical Engineering and Systems Science/Image and Video Processing","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"xPERQCfvaEdlnrZWgj2Fan9d_6LJcq8_ZYaN_rM6Q2k","pdfSize":"5595037","objectId":"0x543fdf911e7125aa58a4e281b588e862a47deed6ffb3b92d0a59733f5d8065fc","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
