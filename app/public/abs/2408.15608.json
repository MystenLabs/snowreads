{"id":"2408.15608","title":"Geometry-guided Feature Learning and Fusion for Indoor Scene\n  Reconstruction","authors":"Ruihong Yin, Sezer Karaoglu, Theo Gevers","authorsParsed":[["Yin","Ruihong",""],["Karaoglu","Sezer",""],["Gevers","Theo",""]],"versions":[{"version":"v1","created":"Wed, 28 Aug 2024 08:02:47 GMT"}],"updateDate":"2024-08-29","timestamp":1724832167000,"abstract":"  In addition to color and textural information, geometry provides important\ncues for 3D scene reconstruction. However, current reconstruction methods only\ninclude geometry at the feature level thus not fully exploiting the geometric\ninformation.\n  In contrast, this paper proposes a novel geometry integration mechanism for\n3D scene reconstruction. Our approach incorporates 3D geometry at three levels,\ni.e. feature learning, feature fusion, and network supervision. First,\ngeometry-guided feature learning encodes geometric priors to contain\nview-dependent information. Second, a geometry-guided adaptive feature fusion\nis introduced which utilizes the geometric priors as a guidance to adaptively\ngenerate weights for multiple views. Third, at the supervision level, taking\nthe consistency between 2D and 3D normals into account, a consistent 3D normal\nloss is designed to add local constraints.\n  Large-scale experiments are conducted on the ScanNet dataset, showing that\nvolumetric methods with our geometry integration mechanism outperform\nstate-of-the-art methods quantitatively as well as qualitatively. Volumetric\nmethods with ours also show good generalization on the 7-Scenes and TUM RGB-D\ndatasets.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}