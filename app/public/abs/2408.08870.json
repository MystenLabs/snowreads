{"id":"2408.08870","title":"SAM2-UNet: Segment Anything 2 Makes Strong Encoder for Natural and\n  Medical Image Segmentation","authors":"Xinyu Xiong, Zihuang Wu, Shuangyi Tan, Wenxue Li, Feilong Tang, Ying\n  Chen, Siying Li, Jie Ma, Guanbin Li","authorsParsed":[["Xiong","Xinyu",""],["Wu","Zihuang",""],["Tan","Shuangyi",""],["Li","Wenxue",""],["Tang","Feilong",""],["Chen","Ying",""],["Li","Siying",""],["Ma","Jie",""],["Li","Guanbin",""]],"versions":[{"version":"v1","created":"Fri, 16 Aug 2024 17:55:38 GMT"}],"updateDate":"2024-08-19","timestamp":1723830938000,"abstract":"  Image segmentation plays an important role in vision understanding. Recently,\nthe emerging vision foundation models continuously achieved superior\nperformance on various tasks. Following such success, in this paper, we prove\nthat the Segment Anything Model 2 (SAM2) can be a strong encoder for U-shaped\nsegmentation models. We propose a simple but effective framework, termed\nSAM2-UNet, for versatile image segmentation. Specifically, SAM2-UNet adopts the\nHiera backbone of SAM2 as the encoder, while the decoder uses the classic\nU-shaped design. Additionally, adapters are inserted into the encoder to allow\nparameter-efficient fine-tuning. Preliminary experiments on various downstream\ntasks, such as camouflaged object detection, salient object detection, marine\nanimal segmentation, mirror detection, and polyp segmentation, demonstrate that\nour SAM2-UNet can simply beat existing specialized state-of-the-art methods\nwithout bells and whistles. Project page:\n\\url{https://github.com/WZH0120/SAM2-UNet}.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}