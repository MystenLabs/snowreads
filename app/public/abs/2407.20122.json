{"id":"2407.20122","title":"Tightening the Evaluation of PAC Bounds Using Formal Verification\n  Results","authors":"Thomas Walker, Alessio Lomuscio","authorsParsed":[["Walker","Thomas",""],["Lomuscio","Alessio",""]],"versions":[{"version":"v1","created":"Mon, 29 Jul 2024 15:53:14 GMT"}],"updateDate":"2024-07-30","timestamp":1722268394000,"abstract":"  Probably Approximately Correct (PAC) bounds are widely used to derive\nprobabilistic guarantees for the generalisation of machine learning models.\nThey highlight the components of the model which contribute to its\ngeneralisation capacity. However, current state-of-the-art results are loose in\napproximating the generalisation capacity of deployed machine learning models.\nConsequently, while PAC bounds are theoretically useful, their applicability\nfor evaluating a model's generalisation property in a given operational design\ndomain is limited. The underlying classical theory is supported by the idea\nthat bounds can be tightened when the number of test points available to the\nuser to evaluate the model increases. Yet, in the case of neural networks, the\nnumber of test points required to obtain bounds of interest is often\nimpractical even for small problems.\n  In this paper, we take the novel approach of using the formal verification of\nneural systems to inform the evaluation of PAC bounds. Rather than using\npointwise information obtained from repeated tests, we use verification results\non regions around test points. We show that conditioning existing bounds on\nverification results leads to a tightening proportional to the underlying\nprobability mass of the verified region.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}