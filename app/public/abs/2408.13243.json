{"id":"2408.13243","title":"MCTR: Multi Camera Tracking Transformer","authors":"Alexandru Niculescu-Mizil, Deep Patel, Iain Melvin","authorsParsed":[["Niculescu-Mizil","Alexandru",""],["Patel","Deep",""],["Melvin","Iain",""]],"versions":[{"version":"v1","created":"Fri, 23 Aug 2024 17:37:03 GMT"},{"version":"v2","created":"Wed, 11 Sep 2024 16:41:15 GMT"}],"updateDate":"2024-09-12","timestamp":1724434623000,"abstract":"  Multi-camera tracking plays a pivotal role in various real-world\napplications. While end-to-end methods have gained significant interest in\nsingle-camera tracking, multi-camera tracking remains predominantly reliant on\nheuristic techniques. In response to this gap, this paper introduces\nMulti-Camera Tracking tRansformer (MCTR), a novel end-to-end approach tailored\nfor multi-object detection and tracking across multiple cameras with\noverlapping fields of view. MCTR leverages end-to-end detectors like DEtector\nTRansformer (DETR) to produce detections and detection embeddings independently\nfor each camera view. The framework maintains set of track embeddings that\nencaplusate global information about the tracked objects, and updates them at\nevery frame by integrating the local information from the view-specific\ndetection embeddings. The track embeddings are probabilistically associated\nwith detections in every camera view and frame to generate consistent object\ntracks. The soft probabilistic association facilitates the design of\ndifferentiable losses that enable end-to-end training of the entire system. To\nvalidate our approach, we conduct experiments on MMPTrack and AI City\nChallenge, two recently introduced large-scale multi-camera multi-object\ntracking datasets.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-sa/4.0/","blobId":"HLt0Q7Ome3wNEYK6q_xTXvmDTi1NrYan2JAovIRra2o","pdfSize":"1290786"}
