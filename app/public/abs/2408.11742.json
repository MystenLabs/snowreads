{"id":"2408.11742","title":"CluMo: Cluster-based Modality Fusion Prompt for Continual Learning in\n  Visual Question Answering","authors":"Yuliang Cai, Mohammad Rostami","authorsParsed":[["Cai","Yuliang",""],["Rostami","Mohammad",""]],"versions":[{"version":"v1","created":"Wed, 21 Aug 2024 16:07:49 GMT"}],"updateDate":"2024-08-22","timestamp":1724256469000,"abstract":"  Large vision-language models (VLMs) have shown significant performance boost\nin various application domains. However, adopting them to deal with several\nsequentially encountered tasks has been challenging because finetuning a VLM on\na task normally leads to reducing its generalization power and the capacity of\nlearning new tasks as well as causing catastrophic forgetting on previously\nlearned tasks. Enabling using VLMs in multimodal continual learning (CL)\nsettings can help to address such scenarios. To improve generalization capacity\nand prevent catastrophic forgetting, we propose a novel prompt-based CL method\nfor VLMs, namely $\\textbf{Clu}$ster-based $\\textbf{Mo}$dality Fusion Prompt\n(\\textbf{CluMo}). We design a novel \\textbf{Key-Key-Prompt} pair, where each\nprompt is associated with a visual prompt key and a textual prompt key. We\nadopt a two-stage training strategy. During the first stage, the single-modal\nkeys are trained via $K$-means clustering algorithm to help select the best\nsemantically matched prompt. During the second stage, the prompt keys are\nfrozen, the selected prompt is attached to the input for training the VLM in\nthe CL scenario. Experiments on two benchmarks demonstrate that our method\nachieves SOTA performance.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"WmmX3iLNXcNYr2zbEll9tZoMPsuANLMVOHnR6MB5W_Y","pdfSize":"2967419"}
