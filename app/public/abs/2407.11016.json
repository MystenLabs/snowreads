{"id":"2407.11016","title":"LongLaMP: A Benchmark for Personalized Long-form Text Generation","authors":"Ishita Kumar, Snigdha Viswanathan, Sushrita Yerra, Alireza Salemi,\n  Ryan A. Rossi, Franck Dernoncourt, Hanieh Deilamsalehy, Xiang Chen, Ruiyi\n  Zhang, Shubham Agarwal, Nedim Lipka, Hamed Zamani","authorsParsed":[["Kumar","Ishita",""],["Viswanathan","Snigdha",""],["Yerra","Sushrita",""],["Salemi","Alireza",""],["Rossi","Ryan A.",""],["Dernoncourt","Franck",""],["Deilamsalehy","Hanieh",""],["Chen","Xiang",""],["Zhang","Ruiyi",""],["Agarwal","Shubham",""],["Lipka","Nedim",""],["Zamani","Hamed",""]],"versions":[{"version":"v1","created":"Thu, 27 Jun 2024 01:52:05 GMT"}],"updateDate":"2024-07-17","timestamp":1719453125000,"abstract":"  Long-text generation is seemingly ubiquitous in real-world applications of\nlarge language models such as generating an email or writing a review. Despite\nthe fundamental importance and prevalence of long-text generation in many\npractical applications, existing work on personalized generation has focused on\nthe generation of very short text. To overcome these limitations, we study the\nproblem of personalized long-text generation, that is, generating long-text\nthat is personalized for a specific user while being practically useful for the\nvast majority of real-world applications that naturally require the generation\nof longer text. In this work, we demonstrate the importance of user-specific\npersonalization for long-text generation tasks and develop the Long-text\nLanguage Model Personalization (LongLaMP) Benchmark. LongLaMP provides a\ncomprehensive and diverse evaluation framework for personalized long-text\ngeneration. Extensive experiments on LongLaMP for zero-shot and fine-tuned\nlanguage tasks demonstrate the effectiveness of the proposed benchmark and its\nutility for developing and evaluating techniques for personalized long-text\ngeneration across a wide variety of long-text generation tasks. The results\nhighlight the importance of personalization across a wide variety of long-text\ngeneration tasks. Finally, we release the benchmark for others to use for this\nimportant problem.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}