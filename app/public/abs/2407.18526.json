{"id":"2407.18526","title":"Constructing Enhanced Mutual Information for Online Class-Incremental\n  Learning","authors":"Huan Zhang, Fan Lyu, Shenghua Fan, Yujin Zheng and Dingwen Wang","authorsParsed":[["Zhang","Huan",""],["Lyu","Fan",""],["Fan","Shenghua",""],["Zheng","Yujin",""],["Wang","Dingwen",""]],"versions":[{"version":"v1","created":"Fri, 26 Jul 2024 06:16:11 GMT"}],"updateDate":"2024-07-29","timestamp":1721974571000,"abstract":"  Online Class-Incremental continual Learning (OCIL) addresses the challenge of\ncontinuously learning from a single-channel data stream, adapting to new tasks\nwhile mitigating catastrophic forgetting. Recently, Mutual Information\n(MI)-based methods have shown promising performance in OCIL. However, existing\nMI-based methods treat various knowledge components in isolation, ignoring the\nknowledge confusion across tasks. This narrow focus on simple MI knowledge\nalignment may lead to old tasks being easily forgotten with the introduction of\nnew tasks, risking the loss of common parts between past and present\nknowledge.To address this, we analyze the MI relationships from the\nperspectives of diversity, representativeness, and separability, and propose an\nEnhanced Mutual Information (EMI) method based on knwoledge decoupling. EMI\nconsists of Diversity Mutual Information (DMI), Representativeness Mutual\nInformation (RMI) and Separability Mutual Information (SMI). DMI diversifies\nintra-class sample features by considering the similarity relationships among\ninter-class sample features to enable the network to learn more general\nknowledge. RMI summarizes representative features for each category and aligns\nsample features with these representative features, making the intra-class\nsample distribution more compact. SMI establishes MI relationships for\ninter-class representative features, enhancing the stability of representative\nfeatures while increasing the distinction between inter-class representative\nfeatures, thus creating clear boundaries between class. Extensive experimental\nresults on widely used benchmark datasets demonstrate the superior performance\nof EMI over state-of-the-art baseline methods.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}