{"id":"2408.15038","title":"Interactive Occlusion Boundary Estimation through Exploitation of\n  Synthetic Data","authors":"Lintao Xu and Chaohui Wang","authorsParsed":[["Xu","Lintao",""],["Wang","Chaohui",""]],"versions":[{"version":"v1","created":"Tue, 27 Aug 2024 13:07:09 GMT"}],"updateDate":"2024-08-28","timestamp":1724764029000,"abstract":"  Occlusion boundaries (OBs) geometrically localize the occlusion events in a\n2D image, and contain useful information for addressing various scene\nunderstanding problems. To advance their study, we have led the investigation\nin the following three aspects. Firstly, we have studied interactive estimation\nof OBs, which is the first in the literature, and proposed an efficient\ndeep-network-based method using multiple-scribble intervention, named DNMMSI,\nwhich significantly improves the performance over the state-of-the-art\nfully-automatic methods. Secondly, we propose to exploit the synthetic\nbenchmark for the training process, thanks to the particularity that OBs are\ndetermined geometrically and unambiguously from the 3D scene. To this end, we\nhave developed an efficient tool, named Mesh2OB, for the automatic generation\nof 2D images together with their ground-truth OBs, using which we have\nconstructed a synthetic benchmark, named OB-FUTURE. Abundant experimental\nresults demonstrate that leveraging such a synthetic benchmark for training\nachieves promising performance, even without the use of domain adaptation\ntechniques. Finally, to achieve a more compelling and robust evaluation in\nOB-related research, we have created a real benchmark, named OB-LabName,\nconsisting of 120 high-resolution images together with their ground-truth OBs,\nwith precision surpassing that of previous benchmarks. We will release DNMMSI\nwith pre-trained parameters, Mesh2OB, OB-FUTURE, and OB-LabName to support\nfurther research.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}