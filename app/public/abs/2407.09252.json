{"id":"2407.09252","title":"Context Embeddings for Efficient Answer Generation in RAG","authors":"David Rau, Shuai Wang, Herv\\'e D\\'ejean, St\\'ephane Clinchant","authorsParsed":[["Rau","David",""],["Wang","Shuai",""],["Déjean","Hervé",""],["Clinchant","Stéphane",""]],"versions":[{"version":"v1","created":"Fri, 12 Jul 2024 13:30:44 GMT"},{"version":"v2","created":"Tue, 23 Jul 2024 12:28:31 GMT"}],"updateDate":"2024-07-24","timestamp":1720791044000,"abstract":"  Retrieval-Augmented Generation (RAG) allows overcoming the limited knowledge\nof LLMs by extending the input with external information. As a consequence, the\ncontextual inputs to the model become much longer which slows down decoding\ntime directly translating to the time a user has to wait for an answer. We\naddress this challenge by presenting COCOM, an effective context compression\nmethod, reducing long contexts to only a handful of Context Embeddings speeding\nup the generation time by a large margin. Our method allows for different\ncompression rates trading off decoding time for answer quality. Compared to\nearlier methods, COCOM allows for handling multiple contexts more effectively,\nsignificantly reducing decoding time for long inputs. Our method demonstrates a\nspeed-up of up to 5.69 $\\times$ while achieving higher performance compared to\nexisting efficient context compression methods.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Information Retrieval"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"JKvTNxlrE2GDwJpoJ45_n3lmSEpg1coyaLOb0O1ME00","pdfSize":"818441","objectId":"0x8d3919b779ce1d7b192b3243f1ba049c4bbb1a8300a283cb419ba1c3adeb53ad","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
