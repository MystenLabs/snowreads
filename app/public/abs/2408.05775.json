{"id":"2408.05775","title":"Efficient Test-Time Prompt Tuning for Vision-Language Models","authors":"Yuhan Zhu, Guozhen Zhang, Chen Xu, Haocheng Shen, Xiaoxin Chen,\n  Gangshan Wu, Limin Wang","authorsParsed":[["Zhu","Yuhan",""],["Zhang","Guozhen",""],["Xu","Chen",""],["Shen","Haocheng",""],["Chen","Xiaoxin",""],["Wu","Gangshan",""],["Wang","Limin",""]],"versions":[{"version":"v1","created":"Sun, 11 Aug 2024 13:55:58 GMT"}],"updateDate":"2024-08-13","timestamp":1723384558000,"abstract":"  Vision-language models have showcased impressive zero-shot classification\ncapabilities when equipped with suitable text prompts. Previous studies have\nshown the effectiveness of test-time prompt tuning; however, these methods\ntypically require per-image prompt adaptation during inference, which incurs\nhigh computational budgets and limits scalability and practical deployment. To\novercome this issue, we introduce Self-TPT, a novel framework leveraging\nSelf-supervised learning for efficient Test-time Prompt Tuning. The key aspect\nof Self-TPT is that it turns to efficient predefined class adaptation via\nself-supervised learning, thus avoiding computation-heavy per-image adaptation\nat inference. Self-TPT begins by co-training the self-supervised and the\nclassification task using source data, then applies the self-supervised task\nexclusively for test-time new class adaptation. Specifically, we propose\nContrastive Prompt Learning (CPT) as the key task for self-supervision. CPT is\ndesigned to minimize the intra-class distances while enhancing inter-class\ndistinguishability via contrastive learning. Furthermore, empirical evidence\nsuggests that CPT could closely mimic back-propagated gradients of the\nclassification task, offering a plausible explanation for its effectiveness.\nMotivated by this finding, we further introduce a gradient matching loss to\nexplicitly enhance the gradient similarity. We evaluated Self-TPT across three\nchallenging zero-shot benchmarks. The results consistently demonstrate that\nSelf-TPT not only significantly reduces inference costs but also achieves\nstate-of-the-art performance, effectively balancing the efficiency-efficacy\ntrade-off.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"iF0DE_AZDubBdf29dDcbmxJsR7VSb-VtjQ7xkNyfzOg","pdfSize":"1762117"}
