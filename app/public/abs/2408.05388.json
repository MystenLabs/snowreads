{"id":"2408.05388","title":"Report on the 1st Workshop on Large Language Model for Evaluation in\n  Information Retrieval (LLM4Eval 2024) at SIGIR 2024","authors":"Hossein A. Rahmani, Clemencia Siro, Mohammad Aliannejadi, Nick\n  Craswell, Charles L. A. Clarke, Guglielmo Faggioli, Bhaskar Mitra, Paul\n  Thomas, Emine Yilmaz","authorsParsed":[["Rahmani","Hossein A.",""],["Siro","Clemencia",""],["Aliannejadi","Mohammad",""],["Craswell","Nick",""],["Clarke","Charles L. A.",""],["Faggioli","Guglielmo",""],["Mitra","Bhaskar",""],["Thomas","Paul",""],["Yilmaz","Emine",""]],"versions":[{"version":"v1","created":"Fri, 9 Aug 2024 23:55:58 GMT"}],"updateDate":"2024-08-13","timestamp":1723247758000,"abstract":"  The first edition of the workshop on Large Language Model for Evaluation in\nInformation Retrieval (LLM4Eval 2024) took place in July 2024, co-located with\nthe ACM SIGIR Conference 2024 in the USA (SIGIR 2024). The aim was to bring\ninformation retrieval researchers together around the topic of LLMs for\nevaluation in information retrieval that gathered attention with the\nadvancement of large language models and generative AI. Given the novelty of\nthe topic, the workshop was focused around multi-sided discussions, namely\npanels and poster sessions of the accepted proceedings papers.\n","subjects":["Computing Research Repository/Information Retrieval"],"license":"http://creativecommons.org/licenses/by/4.0/"}