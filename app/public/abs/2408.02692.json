{"id":"2408.02692","title":"Attention is all you need for an improved CNN-based flash flood\n  susceptibility modeling. The case of the ungauged Rheraya watershed, Morocco","authors":"Akram Elghouat, Ahmed Algouti, Abdellah Algouti, Soukaina Baid","authorsParsed":[["Elghouat","Akram",""],["Algouti","Ahmed",""],["Algouti","Abdellah",""],["Baid","Soukaina",""]],"versions":[{"version":"v1","created":"Sat, 3 Aug 2024 16:57:01 GMT"}],"updateDate":"2024-08-07","timestamp":1722704221000,"abstract":"  Effective flood hazard management requires evaluating and predicting flash\nflood susceptibility. Convolutional neural networks (CNNs) are commonly used\nfor this task but face issues like gradient explosion and overfitting. This\nstudy explores the use of an attention mechanism, specifically the\nconvolutional block attention module (CBAM), to enhance CNN models for flash\nflood susceptibility in the ungauged Rheraya watershed, a flood prone region.\nWe used ResNet18, DenseNet121, and Xception as backbone architectures,\nintegrating CBAM at different locations. Our dataset included 16 conditioning\nfactors and 522 flash flood inventory points. Performance was evaluated using\naccuracy, precision, recall, F1-score, and the area under the curve (AUC) of\nthe receiver operating characteristic (ROC). Results showed that CBAM\nsignificantly improved model performance, with DenseNet121 incorporating CBAM\nin each convolutional block achieving the best results (accuracy = 0.95, AUC =\n0.98). Distance to river and drainage density were identified as key factors.\nThese findings demonstrate the effectiveness of the attention mechanism in\nimproving flash flood susceptibility modeling and offer valuable insights for\ndisaster management.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"gxjwyyc0ARx6OuhrIdrmQanqnQeE5B0OOCSDiJmB5EI","pdfSize":"13961695"}
