{"id":"2408.08144","title":"MIDAS: Multi-level Intent, Domain, And Slot Knowledge Distillation for\n  Multi-turn NLU","authors":"Yan Li, So-Eon Kim, Seong-Bae Park, Soyeon Caren Han","authorsParsed":[["Li","Yan",""],["Kim","So-Eon",""],["Park","Seong-Bae",""],["Han","Soyeon Caren",""]],"versions":[{"version":"v1","created":"Thu, 15 Aug 2024 13:28:18 GMT"}],"updateDate":"2024-08-16","timestamp":1723728498000,"abstract":"  Although Large Language Models(LLMs) can generate coherent and contextually\nrelevant text, they often struggle to recognise the intent behind the human\nuser's query. Natural Language Understanding (NLU) models, however, interpret\nthe purpose and key information of user's input to enable responsive\ninteractions. Existing NLU models generally map individual utterances to a\ndual-level semantic frame, involving sentence-level intent and word-level slot\nlabels. However, real-life conversations primarily consist of multi-turn\nconversations, involving the interpretation of complex and extended dialogues.\nResearchers encounter challenges addressing all facets of multi-turn dialogue\nconversations using a unified single NLU model. This paper introduces a novel\napproach, MIDAS, leveraging a multi-level intent, domain, and slot knowledge\ndistillation for multi-turn NLU. To achieve this, we construct distinct\nteachers for varying levels of conversation knowledge, namely, sentence-level\nintent detection, word-level slot filling, and conversation-level domain\nclassification. These teachers are then fine-tuned to acquire specific\nknowledge of their designated levels. A multi-teacher loss is proposed to\nfacilitate the combination of these multi-level teachers, guiding a student\nmodel in multi-turn dialogue tasks. The experimental results demonstrate the\nefficacy of our model in improving the overall multi-turn conversation\nunderstanding, showcasing the potential for advancements in NLU models through\nthe incorporation of multi-level dialogue knowledge distillation techniques.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"kuYGO8xcU-IAVa2UqH_B8xcBkIAHZjVU3NCosj8MUfo","pdfSize":"5058822"}
