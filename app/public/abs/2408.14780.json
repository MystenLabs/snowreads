{"id":"2408.14780","title":"GINN-KAN: Interpretability pipelining with applications in Physics\n  Informed Neural Networks","authors":"Nisal Ranasinghe, Yu Xia, Sachith Seneviratne, Saman Halgamuge","authorsParsed":[["Ranasinghe","Nisal",""],["Xia","Yu",""],["Seneviratne","Sachith",""],["Halgamuge","Saman",""]],"versions":[{"version":"v1","created":"Tue, 27 Aug 2024 04:57:53 GMT"},{"version":"v2","created":"Wed, 28 Aug 2024 15:48:31 GMT"}],"updateDate":"2024-08-29","timestamp":1724734673000,"abstract":"  Neural networks are powerful function approximators, yet their ``black-box\"\nnature often renders them opaque and difficult to interpret. While many\npost-hoc explanation methods exist, they typically fail to capture the\nunderlying reasoning processes of the networks. A truly interpretable neural\nnetwork would be trained similarly to conventional models using techniques such\nas backpropagation, but additionally provide insights into the learned\ninput-output relationships. In this work, we introduce the concept of\ninterpretability pipelineing, to incorporate multiple interpretability\ntechniques to outperform each individual technique. To this end, we first\nevaluate several architectures that promise such interpretability, with a\nparticular focus on two recent models selected for their potential to\nincorporate interpretability into standard neural network architectures while\nstill leveraging backpropagation: the Growing Interpretable Neural Network\n(GINN) and Kolmogorov Arnold Networks (KAN). We analyze the limitations and\nstrengths of each and introduce a novel interpretable neural network GINN-KAN\nthat synthesizes the advantages of both models. When tested on the Feynman\nsymbolic regression benchmark datasets, GINN-KAN outperforms both GINN and KAN.\nTo highlight the capabilities and the generalizability of this approach, we\nposition GINN-KAN as an alternative to conventional black-box networks in\nPhysics-Informed Neural Networks (PINNs). We expect this to have far-reaching\nimplications in the application of deep learning pipelines in the natural\nsciences. Our experiments with this interpretable PINN on 15 different partial\ndifferential equations demonstrate that GINN-KAN augmented PINNs outperform\nPINNs with black-box networks in solving differential equations and surpass the\ncapabilities of both GINN and KAN.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"-KkVx5oVPti9opxVet9tHQk2yldfmVrOhyaNhF4IpaA","pdfSize":"826363"}
