{"id":"2407.19231","title":"Alleviating Over-Smoothing via Aggregation over Compact Manifolds","authors":"Dongzhuoran Zhou, Hui Yang, Bo Xiong, Yue Ma, Evgeny Kharlamov","authorsParsed":[["Zhou","Dongzhuoran",""],["Yang","Hui",""],["Xiong","Bo",""],["Ma","Yue",""],["Kharlamov","Evgeny",""]],"versions":[{"version":"v1","created":"Sat, 27 Jul 2024 11:02:12 GMT"}],"updateDate":"2024-07-30","timestamp":1722078132000,"abstract":"  Graph neural networks (GNNs) have achieved significant success in various\napplications. Most GNNs learn the node features with information aggregation of\nits neighbors and feature transformation in each layer. However, the node\nfeatures become indistinguishable after many layers, leading to performance\ndeterioration: a significant limitation known as over-smoothing. Past work\nadopted various techniques for addressing this issue, such as normalization and\nskip-connection of layer-wise output. After the study, we found that the\ninformation aggregations in existing work are all contracted aggregations, with\nthe intrinsic property that features will inevitably converge to the same\nsingle point after many layers. To this end, we propose the aggregation over\ncompacted manifolds method (ACM) that replaces the existing information\naggregation with aggregation over compact manifolds, a special type of\nmanifold, which avoids contracted aggregations. In this work, we theoretically\nanalyze contracted aggregation and its properties. We also provide an extensive\nempirical evaluation that shows ACM can effectively alleviate over-smoothing\nand outperforms the state-of-the-art. The code can be found in\nhttps://github.com/DongzhuoranZhou/ACM.git.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}