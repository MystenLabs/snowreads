{"id":"2408.07362","title":"BadMerging: Backdoor Attacks Against Model Merging","authors":"Jinghuai Zhang, Jianfeng Chi, Zheng Li, Kunlin Cai, Yang Zhang and\n  Yuan Tian","authorsParsed":[["Zhang","Jinghuai",""],["Chi","Jianfeng",""],["Li","Zheng",""],["Cai","Kunlin",""],["Zhang","Yang",""],["Tian","Yuan",""]],"versions":[{"version":"v1","created":"Wed, 14 Aug 2024 08:19:23 GMT"},{"version":"v2","created":"Mon, 2 Sep 2024 08:28:44 GMT"}],"updateDate":"2024-09-04","timestamp":1723623563000,"abstract":"  Fine-tuning pre-trained models for downstream tasks has led to a\nproliferation of open-sourced task-specific models. Recently, Model Merging\n(MM) has emerged as an effective approach to facilitate knowledge transfer\namong these independently fine-tuned models. MM directly combines multiple\nfine-tuned task-specific models into a merged model without additional\ntraining, and the resulting model shows enhanced capabilities in multiple\ntasks. Although MM provides great utility, it may come with security risks\nbecause an adversary can exploit MM to affect multiple downstream tasks.\nHowever, the security risks of MM have barely been studied. In this paper, we\nfirst find that MM, as a new learning paradigm, introduces unique challenges\nfor existing backdoor attacks due to the merging process. To address these\nchallenges, we introduce BadMerging, the first backdoor attack specifically\ndesigned for MM. Notably, BadMerging allows an adversary to compromise the\nentire merged model by contributing as few as one backdoored task-specific\nmodel. BadMerging comprises a two-stage attack mechanism and a novel\nfeature-interpolation-based loss to enhance the robustness of embedded\nbackdoors against the changes of different merging parameters. Considering that\na merged model may incorporate tasks from different domains, BadMerging can\njointly compromise the tasks provided by the adversary (on-task attack) and\nother contributors (off-task attack) and solve the corresponding unique\nchallenges with novel attack designs. Extensive experiments show that\nBadMerging achieves remarkable attacks against various MM algorithms. Our\nablation study demonstrates that the proposed attack designs can progressively\ncontribute to the attack performance. Finally, we show that prior defense\nmechanisms fail to defend against our attacks, highlighting the need for more\nadvanced defense.\n","subjects":["Computing Research Repository/Cryptography and Security","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}