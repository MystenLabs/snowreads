{"id":"2407.07015","title":"A Framework for Multimodal Medical Image Interaction","authors":"Laura Sch\\\"utz, Sasan Matinfar, Gideon Schafroth, Navid Navab, Merle\n  Fairhurst, Arthur Wagner, Benedikt Wiestler, Ulrich Eck and Nassir Navab","authorsParsed":[["Sch√ºtz","Laura",""],["Matinfar","Sasan",""],["Schafroth","Gideon",""],["Navab","Navid",""],["Fairhurst","Merle",""],["Wagner","Arthur",""],["Wiestler","Benedikt",""],["Eck","Ulrich",""],["Navab","Nassir",""]],"versions":[{"version":"v1","created":"Tue, 9 Jul 2024 16:33:51 GMT"}],"updateDate":"2024-07-10","timestamp":1720542831000,"abstract":"  Medical doctors rely on images of the human anatomy, such as magnetic\nresonance imaging (MRI), to localize regions of interest in the patient during\ndiagnosis and treatment. Despite advances in medical imaging technology, the\ninformation conveyance remains unimodal. This visual representation fails to\ncapture the complexity of the real, multisensory interaction with human tissue.\nHowever, perceiving multimodal information about the patient's anatomy and\ndisease in real-time is critical for the success of medical procedures and\npatient outcome. We introduce a Multimodal Medical Image Interaction (MMII)\nframework to allow medical experts a dynamic, audiovisual interaction with\nhuman tissue in three-dimensional space. In a virtual reality environment, the\nuser receives physically informed audiovisual feedback to improve the spatial\nperception of anatomical structures. MMII uses a model-based sonification\napproach to generate sounds derived from the geometry and physical properties\nof tissue, thereby eliminating the need for hand-crafted sound design. Two user\nstudies involving 34 general and nine clinical experts were conducted to\nevaluate the proposed interaction framework's learnability, usability, and\naccuracy. Our results showed excellent learnability of audiovisual\ncorrespondence as the rate of correct associations significantly improved (p <\n0.001) over the course of the study. MMII resulted in superior brain tumor\nlocalization accuracy (p < 0.05) compared to conventional medical image\ninteraction. Our findings substantiate the potential of this novel framework to\nenhance interaction with medical images, for example, during surgical\nprocedures where immediate and precise feedback is needed.\n","subjects":["Computing Research Repository/Human-Computer Interaction","Computing Research Repository/Multimedia","Computing Research Repository/Sound","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}