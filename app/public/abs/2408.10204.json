{"id":"2408.10204","title":"Criticality Leveraged Adversarial Training (CLAT) for Boosted\n  Performance via Parameter Efficiency","authors":"Bhavna Gopal, Huanrui Yang, Jingyang Zhang, Mark Horton and Yiran Chen","authorsParsed":[["Gopal","Bhavna",""],["Yang","Huanrui",""],["Zhang","Jingyang",""],["Horton","Mark",""],["Chen","Yiran",""]],"versions":[{"version":"v1","created":"Mon, 19 Aug 2024 17:58:03 GMT"},{"version":"v2","created":"Fri, 30 Aug 2024 20:19:10 GMT"}],"updateDate":"2024-09-04","timestamp":1724090283000,"abstract":"  Adversarial training enhances neural network robustness but suffers from a\ntendency to overfit and increased generalization errors on clean data. This\nwork introduces CLAT, an innovative approach that mitigates adversarial\noverfitting by introducing parameter efficiency into the adversarial training\nprocess, improving both clean accuracy and adversarial robustness. Instead of\ntuning the entire model, CLAT identifies and fine-tunes robustness-critical\nlayers - those predominantly learning non-robust features - while freezing the\nremaining model to enhance robustness. It employs dynamic critical layer\nselection to adapt to changes in layer criticality throughout the fine-tuning\nprocess. Empirically, CLAT can be applied on top of existing adversarial\ntraining methods, significantly reduces the number of trainable parameters by\napproximately 95%, and achieves more than a 2% improvement in adversarial\nrobustness compared to baseline methods.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/"}