{"id":"2407.19542","title":"UniVoxel: Fast Inverse Rendering by Unified Voxelization of Scene\n  Representation","authors":"Shuang Wu and Songlin Tang and Guangming Lu and Jianzhuang Liu and\n  Wenjie Pei","authorsParsed":[["Wu","Shuang",""],["Tang","Songlin",""],["Lu","Guangming",""],["Liu","Jianzhuang",""],["Pei","Wenjie",""]],"versions":[{"version":"v1","created":"Sun, 28 Jul 2024 17:24:14 GMT"}],"updateDate":"2024-07-30","timestamp":1722187454000,"abstract":"  Typical inverse rendering methods focus on learning implicit neural scene\nrepresentations by modeling the geometry, materials and illumination\nseparately, which entails significant computations for optimization. In this\nwork we design a Unified Voxelization framework for explicit learning of scene\nrepresentations, dubbed UniVoxel, which allows for efficient modeling of the\ngeometry, materials and illumination jointly, thereby accelerating the inverse\nrendering significantly. To be specific, we propose to encode a scene into a\nlatent volumetric representation, based on which the geometry, materials and\nillumination can be readily learned via lightweight neural networks in a\nunified manner. Particularly, an essential design of UniVoxel is that we\nleverage local Spherical Gaussians to represent the incident light radiance,\nwhich enables the seamless integration of modeling illumination into the\nunified voxelization framework. Such novel design enables our UniVoxel to model\nthe joint effects of direct lighting, indirect lighting and light visibility\nefficiently without expensive multi-bounce ray tracing. Extensive experiments\non multiple benchmarks covering diverse scenes demonstrate that UniVoxel boosts\nthe optimization efficiency significantly compared to other methods, reducing\nthe per-scene training time from hours to 18 minutes, while achieving favorable\nreconstruction quality. Code is available at\nhttps://github.com/freemantom/UniVoxel.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}