{"id":"2407.15439","title":"Merit-based Fair Combinatorial Semi-Bandit with Unrestricted Feedback\n  Delays","authors":"Ziqun Chen, Kechao Cai, Zhuoyue Chen, Jinbei Zhang, John C.S. Lui","authorsParsed":[["Chen","Ziqun",""],["Cai","Kechao",""],["Chen","Zhuoyue",""],["Zhang","Jinbei",""],["Lui","John C. S.",""]],"versions":[{"version":"v1","created":"Mon, 22 Jul 2024 07:36:27 GMT"},{"version":"v2","created":"Fri, 26 Jul 2024 13:02:24 GMT"},{"version":"v3","created":"Mon, 29 Jul 2024 14:42:20 GMT"}],"updateDate":"2024-07-30","timestamp":1721633787000,"abstract":"  We study the stochastic combinatorial semi-bandit problem with unrestricted\nfeedback delays under merit-based fairness constraints. This is motivated by\napplications such as crowdsourcing, and online advertising, where immediate\nfeedback is not immediately available and fairness among different choices (or\narms) is crucial. We consider two types of unrestricted feedback delays:\nreward-independent delays where the feedback delays are independent of the\nrewards, and reward-dependent delays where the feedback delays are correlated\nwith the rewards. Furthermore, we introduce merit-based fairness constraints to\nensure a fair selection of the arms. We define the reward regret and the\nfairness regret and present new bandit algorithms to select arms under\nunrestricted feedback delays based on their merits. We prove that our\nalgorithms all achieve sublinear expected reward regret and expected fairness\nregret, with a dependence on the quantiles of the delay distribution. We also\nconduct extensive experiments using synthetic and real-world data and show that\nour algorithms can fairly select arms with different feedback delays.\n","subjects":["Computing Research Repository/Machine Learning","Statistics/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}