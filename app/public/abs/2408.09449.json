{"id":"2408.09449","title":"Attention Is Not What You Need: Revisiting Multi-Instance Learning for\n  Whole Slide Image Classification","authors":"Xin Liu, Weijia Zhang, Min-Ling Zhang","authorsParsed":[["Liu","Xin",""],["Zhang","Weijia",""],["Zhang","Min-Ling",""]],"versions":[{"version":"v1","created":"Sun, 18 Aug 2024 12:15:22 GMT"}],"updateDate":"2024-08-20","timestamp":1723983322000,"abstract":"  Although attention-based multi-instance learning algorithms have achieved\nimpressive performances on slide-level whole slide image (WSI) classification\ntasks, they are prone to mistakenly focus on irrelevant patterns such as\nstaining conditions and tissue morphology, leading to incorrect patch-level\npredictions and unreliable interpretability. Moreover, these attention-based\nMIL algorithms tend to focus on salient instances and struggle to recognize\nhard-to-classify instances. In this paper, we first demonstrate that\nattention-based WSI classification methods do not adhere to the standard MIL\nassumptions. From the standard MIL assumptions, we propose a surprisingly\nsimple yet effective instance-based MIL method for WSI classification\n(FocusMIL) based on max-pooling and forward amortized variational inference. We\nargue that synergizing the standard MIL assumption with variational inference\nencourages the model to focus on tumour morphology instead of spurious\ncorrelations. Our experimental evaluations show that FocusMIL significantly\noutperforms the baselines in patch-level classification tasks on the Camelyon16\nand TCGA-NSCLC benchmarks. Visualization results show that our method also\nachieves better classification boundaries for identifying hard instances and\nmitigates the effect of spurious correlations between bags and labels.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}