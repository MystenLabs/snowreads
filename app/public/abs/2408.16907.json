{"id":"2408.16907","title":"Ig3D: Integrating 3D Face Representations in Facial Expression Inference","authors":"Lu Dong, Xiao Wang, Srirangaraj Setlur, Venu Govindaraju, Ifeoma Nwogu","authorsParsed":[["Dong","Lu",""],["Wang","Xiao",""],["Setlur","Srirangaraj",""],["Govindaraju","Venu",""],["Nwogu","Ifeoma",""]],"versions":[{"version":"v1","created":"Thu, 29 Aug 2024 21:08:07 GMT"}],"updateDate":"2024-09-02","timestamp":1724965687000,"abstract":"  Reconstructing 3D faces with facial geometry from single images has allowed\nfor major advances in animation, generative models, and virtual reality.\nHowever, this ability to represent faces with their 3D features is not as fully\nexplored by the facial expression inference (FEI) community. This study\ntherefore aims to investigate the impacts of integrating such 3D\nrepresentations into the FEI task, specifically for facial expression\nclassification and face-based valence-arousal (VA) estimation. To accomplish\nthis, we first assess the performance of two 3D face representations (both\nbased on the 3D morphable model, FLAME) for the FEI tasks. We further explore\ntwo fusion architectures, intermediate fusion and late fusion, for integrating\nthe 3D face representations with existing 2D inference frameworks. To evaluate\nour proposed architecture, we extract the corresponding 3D representations and\nperform extensive tests on the AffectNet and RAF-DB datasets. Our experimental\nresults demonstrate that our proposed method outperforms the state-of-the-art\nAffectNet VA estimation and RAF-DB classification tasks. Moreover, our method\ncan act as a complement to other existing methods to boost performance in many\nemotion inference tasks.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}