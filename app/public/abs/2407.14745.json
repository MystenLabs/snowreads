{"id":"2407.14745","title":"Randomized Radial Basis Function Neural Network for Solving Multiscale\n  Elliptic Equations","authors":"Yuhang Wu, Ziyuan Liu, Wenjun Sun, Xu Qian","authorsParsed":[["Wu","Yuhang",""],["Liu","Ziyuan",""],["Sun","Wenjun",""],["Qian","Xu",""]],"versions":[{"version":"v1","created":"Sat, 20 Jul 2024 04:32:08 GMT"}],"updateDate":"2024-07-23","timestamp":1721449928000,"abstract":"  To overcome these obstacles and improve computational accuracy and\nefficiency, this paper presents the Randomized Radial Basis Function Neural\nNetwork (RRNN), an innovative approach explicitly crafted for solving\nmultiscale elliptic equations. The RRNN method commences by decomposing the\ncomputational domain into non-overlapping subdomains. Within each subdomain,\nthe solution to the localized subproblem is approximated by a randomized radial\nbasis function neural network with a Gaussian kernel. This network is\ndistinguished by the random assignment of width and center coefficients for its\nactivation functions, thereby rendering the training process focused solely on\ndetermining the weight coefficients of the output layer. For each subproblem,\nsimilar to the Petrov-Galerkin finite element method, a linear system will be\nformulated on the foundation of a weak formulation. Subsequently, a selection\nof collocation points is stochastically sampled at the boundaries of the\nsubdomain, ensuring satisfying $C^0$ and $C^1$ continuity and boundary\nconditions to couple these localized solutions. The network is ultimately\ntrained using the least squares method to ascertain the output layer weights.\nTo validate the RRNN method's effectiveness, an extensive array of numerical\nexperiments has been executed and the results demonstrate that the proposed\nmethod can improve the accuracy and efficiency well.\n","subjects":["Mathematics/Numerical Analysis","Computing Research Repository/Numerical Analysis"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}