{"id":"2407.17390","title":"CovScore: Evaluation of Multi-Document Abstractive Title Set Generation","authors":"Itamar Trainin, Omri Abend","authorsParsed":[["Trainin","Itamar",""],["Abend","Omri",""]],"versions":[{"version":"v1","created":"Wed, 24 Jul 2024 16:14:15 GMT"}],"updateDate":"2024-07-25","timestamp":1721837655000,"abstract":"  This paper introduces CovScore, an automatic reference-less methodology for\nevaluating thematic title sets, extracted from a corpus of documents. While\nsuch extraction methods are widely used, evaluating their effectiveness remains\nan open question. Moreover, some existing practices heavily rely on slow and\nlaborious human annotation procedures. Inspired by recently introduced\nLLM-based judge methods, we propose a novel methodology that decomposes quality\ninto five main metrics along different aspects of evaluation. This framing\nsimplifies and expedites the manual evaluation process and enables automatic\nand independent LLM-based evaluation. As a test case, we apply our approach to\na corpus of Holocaust survivor testimonies, motivated both by its relevance to\ntitle set extraction and by the moral significance of this pursuit. We validate\nthe methodology by experimenting with naturalistic and synthetic title set\ngeneration systems and compare their performance with the methodology.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/"}