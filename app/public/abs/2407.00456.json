{"id":"2407.00456","title":"Beyond Functional Correctness: Investigating Coding Style\n  Inconsistencies in Large Language Models","authors":"Yanlin Wang, Tianyue Jiang, Mingwei Liu, Jiachi Chen, Zibin Zheng","authorsParsed":[["Wang","Yanlin",""],["Jiang","Tianyue",""],["Liu","Mingwei",""],["Chen","Jiachi",""],["Zheng","Zibin",""]],"versions":[{"version":"v1","created":"Sat, 29 Jun 2024 14:56:11 GMT"}],"updateDate":"2024-07-02","timestamp":1719672971000,"abstract":"  Large language models (LLMs) have brought a paradigm shift to the field of\ncode generation, offering the potential to enhance the software development\nprocess. However, previous research mainly focuses on the accuracy of code\ngeneration, while coding style differences between LLMs and human developers\nremain under-explored. In this paper, we empirically analyze the differences in\ncoding style between the code generated by mainstream Code LLMs and the code\nwritten by human developers, and summarize coding style inconsistency taxonomy.\nSpecifically, we first summarize the types of coding style inconsistencies by\nmanually analyzing a large number of generation results. We then compare the\ncode generated by Code LLMs with the code written by human programmers in terms\nof readability, conciseness, and robustness. The results reveal that LLMs and\ndevelopers have different coding styles. Additionally, we study the possible\ncauses of these inconsistencies and provide some solutions to alleviate the\nproblem.\n","subjects":["Computing Research Repository/Software Engineering","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}