{"id":"2408.05788","title":"Continual Learning of Nonlinear Independent Representations","authors":"Boyang Sun, Ignavier Ng, Guangyi Chen, Yifan Shen, Qirong Ho, Kun\n  Zhang","authorsParsed":[["Sun","Boyang",""],["Ng","Ignavier",""],["Chen","Guangyi",""],["Shen","Yifan",""],["Ho","Qirong",""],["Zhang","Kun",""]],"versions":[{"version":"v1","created":"Sun, 11 Aug 2024 14:33:37 GMT"}],"updateDate":"2024-08-13","timestamp":1723386817000,"abstract":"  Identifying the causal relations between interested variables plays a pivotal\nrole in representation learning as it provides deep insights into the dataset.\nIdentifiability, as the central theme of this approach, normally hinges on\nleveraging data from multiple distributions (intervention, distribution shift,\ntime series, etc.). Despite the exciting development in this field, a practical\nbut often overlooked problem is: what if those distribution shifts happen\nsequentially? In contrast, any intelligence possesses the capacity to abstract\nand refine learned knowledge sequentially -- lifelong learning. In this paper,\nwith a particular focus on the nonlinear independent component analysis (ICA)\nframework, we move one step forward toward the question of enabling models to\nlearn meaningful (identifiable) representations in a sequential manner, termed\ncontinual causal representation learning. We theoretically demonstrate that\nmodel identifiability progresses from a subspace level to a component-wise\nlevel as the number of distributions increases. Empirically, we show that our\nmethod achieves performance comparable to nonlinear ICA methods trained jointly\non multiple offline distributions and, surprisingly, the incoming new\ndistribution does not necessarily benefit the identification of all latent\nvariables.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence","Statistics/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}