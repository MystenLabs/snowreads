{"id":"2407.21054","title":"Sentiment Reasoning for Healthcare","authors":"Khai Le-Duc, Khai-Nguyen Nguyen, Bach Phan Tat, Duy Le, Jerry Ngo,\n  Long Vo-Dang, Anh Totti Nguyen, Truong-Son Hy","authorsParsed":[["Le-Duc","Khai",""],["Nguyen","Khai-Nguyen",""],["Tat","Bach Phan",""],["Le","Duy",""],["Ngo","Jerry",""],["Vo-Dang","Long",""],["Nguyen","Anh Totti",""],["Hy","Truong-Son",""]],"versions":[{"version":"v1","created":"Wed, 24 Jul 2024 12:07:54 GMT"}],"updateDate":"2024-08-01","timestamp":1721822874000,"abstract":"  Transparency in AI decision-making is crucial in healthcare due to the severe\nconsequences of errors, and this is important for building trust among AI and\nusers in sentiment analysis task. Incorporating reasoning capabilities helps\nLarge Language Models (LLMs) understand human emotions within broader contexts,\nhandle nuanced and ambiguous language, and infer underlying sentiments that may\nnot be explicitly stated. In this work, we introduce a new task - Sentiment\nReasoning - for both speech and text modalities, along with our proposed\nmultimodal multitask framework and dataset. Our study showed that\nrationale-augmented training enhances model performance in sentiment\nclassification across both human transcript and ASR settings. Also, we found\nthat the generated rationales typically exhibit different vocabularies compared\nto human-generated rationales, but maintain similar semantics. All code, data\n(English-translated and Vietnamese) and models are published online:\nhttps://github.com/leduckhai/MultiMed\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning","Computing Research Repository/Sound","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"sqEZI9c76AJTXc8bs6vXeg399UNFpeMVOBPnn5KDByo","pdfSize":"744713"}
