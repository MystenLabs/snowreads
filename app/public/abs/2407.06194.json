{"id":"2407.06194","title":"More Distinctively Black and Feminine Faces Lead to Increased\n  Stereotyping in Vision-Language Models","authors":"Messi H.J. Lee, Jacob M. Montgomery, Calvin K. Lai","authorsParsed":[["Lee","Messi H. J.",""],["Montgomery","Jacob M.",""],["Lai","Calvin K.",""]],"versions":[{"version":"v1","created":"Wed, 22 May 2024 00:45:29 GMT"}],"updateDate":"2024-07-10","timestamp":1716338729000,"abstract":"  Vision Language Models (VLMs), exemplified by GPT-4V, adeptly integrate text\nand vision modalities. This integration enhances Large Language Models' ability\nto mimic human perception, allowing them to process image inputs. Despite VLMs'\nadvanced capabilities, however, there is a concern that VLMs inherit biases of\nboth modalities in ways that make biases more pervasive and difficult to\nmitigate. Our study explores how VLMs perpetuate homogeneity bias and trait\nassociations with regards to race and gender. When prompted to write stories\nbased on images of human faces, GPT-4V describes subordinate racial and gender\ngroups with greater homogeneity than dominant groups and relies on distinct,\nyet generally positive, stereotypes. Importantly, VLM stereotyping is driven by\nvisual cues rather than group membership alone such that faces that are rated\nas more prototypically Black and feminine are subject to greater stereotyping.\nThese findings suggest that VLMs may associate subtle visual cues related to\nracial and gender groups with stereotypes in ways that could be challenging to\nmitigate. We explore the underlying reasons behind this behavior and discuss\nits implications and emphasize the importance of addressing these biases as\nVLMs come to mirror human perception.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/"}