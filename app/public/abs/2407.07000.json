{"id":"2407.07000","title":"Etalon: Holistic Performance Evaluation Framework for LLM Inference\n  Systems","authors":"Amey Agrawal, Anmol Agarwal, Nitin Kedia, Jayashree Mohan, Souvik\n  Kundu, Nipun Kwatra, Ramachandran Ramjee, Alexey Tumanov","authorsParsed":[["Agrawal","Amey",""],["Agarwal","Anmol",""],["Kedia","Nitin",""],["Mohan","Jayashree",""],["Kundu","Souvik",""],["Kwatra","Nipun",""],["Ramjee","Ramachandran",""],["Tumanov","Alexey",""]],"versions":[{"version":"v1","created":"Tue, 9 Jul 2024 16:13:26 GMT"},{"version":"v2","created":"Fri, 30 Aug 2024 01:19:42 GMT"}],"updateDate":"2024-09-02","timestamp":1720541606000,"abstract":"  Serving large language models (LLMs) in production can incur substantial\ncosts, which has prompted recent advances in inference system optimizations.\nToday, these systems are evaluated against conventional latency and throughput\nmetrics (eg. TTFT, TBT, Normalised Latency and TPOT). However, these metrics\nfail to fully capture the nuances of LLM inference, leading to an incomplete\nassessment of user-facing performance crucial for real-time applications such\nas chat and translation. In this paper, we first identify the pitfalls of\ncurrent performance metrics in evaluating LLM inference systems. We then\npropose Etalon, a comprehensive performance evaluation framework that includes\nfluidity-index -- a novel metric designed to reflect the intricacies of the LLM\ninference process and its impact on real-time user experience. Finally, we\nevaluate various existing open-source platforms and model-as-a-service\nofferings using Etalon, discussing their strengths and weaknesses. Etalon is\navailable at https://github.com/project-etalon/etalon.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language","Computing Research Repository/Distributed, Parallel, and Cluster Computing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}