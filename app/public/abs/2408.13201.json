{"id":"2408.13201","title":"EAViT: External Attention Vision Transformer for Audio Classification","authors":"Aquib Iqbal, Abid Hasan Zim, Md Asaduzzaman Tonmoy, Limengnan Zhou,\n  Asad Malik, Minoru Kuribayashi","authorsParsed":[["Iqbal","Aquib",""],["Zim","Abid Hasan",""],["Tonmoy","Md Asaduzzaman",""],["Zhou","Limengnan",""],["Malik","Asad",""],["Kuribayashi","Minoru",""]],"versions":[{"version":"v1","created":"Fri, 23 Aug 2024 16:31:06 GMT"}],"updateDate":"2024-08-26","timestamp":1724430666000,"abstract":"  This paper presents the External Attention Vision Transformer (EAViT) model,\na novel approach designed to enhance audio classification accuracy. As digital\naudio resources proliferate, the demand for precise and efficient audio\nclassification systems has intensified, driven by the need for improved\nrecommendation systems and user personalization in various applications,\nincluding music streaming platforms and environmental sound recognition.\nAccurate audio classification is crucial for organizing vast audio libraries\ninto coherent categories, enabling users to find and interact with their\npreferred audio content more effectively. In this study, we utilize the GTZAN\ndataset, which comprises 1,000 music excerpts spanning ten diverse genres. Each\n30-second audio clip is segmented into 3-second excerpts to enhance dataset\nrobustness and mitigate overfitting risks, allowing for more granular feature\nanalysis. The EAViT model integrates multi-head external attention (MEA)\nmechanisms into the Vision Transformer (ViT) framework, effectively capturing\nlong-range dependencies and potential correlations between samples. This\nexternal attention (EA) mechanism employs learnable memory units that enhance\nthe network's capacity to process complex audio features efficiently. The study\ndemonstrates that EAViT achieves a remarkable overall accuracy of 93.99%,\nsurpassing state-of-the-art models.\n","subjects":["Computing Research Repository/Sound","Computing Research Repository/Information Retrieval","Computing Research Repository/Machine Learning","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by/4.0/"}