{"id":"2408.07648","title":"See It All: Contextualized Late Aggregation for 3D Dense Captioning","authors":"Minjung Kim, Hyung Suk Lim, Seung Hwan Kim, Soonyoung Lee, Bumsoo Kim,\n  Gunhee Kim","authorsParsed":[["Kim","Minjung",""],["Lim","Hyung Suk",""],["Kim","Seung Hwan",""],["Lee","Soonyoung",""],["Kim","Bumsoo",""],["Kim","Gunhee",""]],"versions":[{"version":"v1","created":"Wed, 14 Aug 2024 16:19:18 GMT"}],"updateDate":"2024-08-15","timestamp":1723652358000,"abstract":"  3D dense captioning is a task to localize objects in a 3D scene and generate\ndescriptive sentences for each object. Recent approaches in 3D dense captioning\nhave adopted transformer encoder-decoder frameworks from object detection to\nbuild an end-to-end pipeline without hand-crafted components. However, these\napproaches struggle with contradicting objectives where a single query\nattention has to simultaneously view both the tightly localized object regions\nand contextual environment. To overcome this challenge, we introduce SIA\n(See-It-All), a transformer pipeline that engages in 3D dense captioning with a\nnovel paradigm called late aggregation. SIA simultaneously decodes two sets of\nqueries-context query and instance query. The instance query focuses on\nlocalization and object attribute descriptions, while the context query\nversatilely captures the region-of-interest of relationships between multiple\nobjects or with the global scene, then aggregated afterwards (i.e., late\naggregation) via simple distance-based measures. To further enhance the quality\nof contextualized caption generation, we design a novel aggregator to generate\na fully informed caption based on the surrounding context, the global\nenvironment, and object instances. Extensive experiments on two of the most\nwidely-used 3D dense captioning datasets demonstrate that our proposed method\nachieves a significant improvement over prior methods.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}