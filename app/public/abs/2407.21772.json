{"id":"2407.21772","title":"ShieldGemma: Generative AI Content Moderation Based on Gemma","authors":"Wenjun Zeng and Yuchi Liu and Ryan Mullins and Ludovic Peran and Joe\n  Fernandez and Hamza Harkous and Karthik Narasimhan and Drew Proud and Piyush\n  Kumar and Bhaktipriya Radharapu and Olivia Sturman and Oscar Wahltinez","authorsParsed":[["Zeng","Wenjun",""],["Liu","Yuchi",""],["Mullins","Ryan",""],["Peran","Ludovic",""],["Fernandez","Joe",""],["Harkous","Hamza",""],["Narasimhan","Karthik",""],["Proud","Drew",""],["Kumar","Piyush",""],["Radharapu","Bhaktipriya",""],["Sturman","Olivia",""],["Wahltinez","Oscar",""]],"versions":[{"version":"v1","created":"Wed, 31 Jul 2024 17:48:14 GMT"},{"version":"v2","created":"Sun, 4 Aug 2024 22:13:39 GMT"}],"updateDate":"2024-08-06","timestamp":1722448094000,"abstract":"  We present ShieldGemma, a comprehensive suite of LLM-based safety content\nmoderation models built upon Gemma2. These models provide robust,\nstate-of-the-art predictions of safety risks across key harm types (sexually\nexplicit, dangerous content, harassment, hate speech) in both user input and\nLLM-generated output. By evaluating on both public and internal benchmarks, we\ndemonstrate superior performance compared to existing models, such as Llama\nGuard (+10.8\\% AU-PRC on public benchmarks) and WildCard (+4.3\\%).\nAdditionally, we present a novel LLM-based data curation pipeline, adaptable to\na variety of safety-related tasks and beyond. We have shown strong\ngeneralization performance for model trained mainly on synthetic data. By\nreleasing ShieldGemma, we provide a valuable resource to the research\ncommunity, advancing LLM safety and enabling the creation of more effective\ncontent moderation solutions for developers.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}