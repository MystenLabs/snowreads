{"id":"2408.02245","title":"A Two-Stage Progressive Pre-training using Multi-Modal Contrastive\n  Masked Autoencoders","authors":"Muhammad Abdullah Jamal, Omid Mohareri","authorsParsed":[["Jamal","Muhammad Abdullah",""],["Mohareri","Omid",""]],"versions":[{"version":"v1","created":"Mon, 5 Aug 2024 05:33:59 GMT"},{"version":"v2","created":"Mon, 16 Sep 2024 06:40:25 GMT"}],"updateDate":"2024-09-17","timestamp":1722836039000,"abstract":"  In this paper, we propose a new progressive pre-training method for image\nunderstanding tasks which leverages RGB-D datasets. The method utilizes\nMulti-Modal Contrastive Masked Autoencoder and Denoising techniques. Our\nproposed approach consists of two stages. In the first stage, we pre-train the\nmodel using contrastive learning to learn cross-modal representations. In the\nsecond stage, we further pre-train the model using masked autoencoding and\ndenoising/noise prediction used in diffusion models. Masked autoencoding\nfocuses on reconstructing the missing patches in the input modality using local\nspatial correlations, while denoising learns high frequency components of the\ninput data. Moreover, it incorporates global distillation in the second stage\nby leveraging the knowledge acquired in stage one. Our approach is scalable,\nrobust and suitable for pre-training RGB-D datasets. Extensive experiments on\nmultiple datasets such as ScanNet, NYUv2 and SUN RGB-D show the efficacy and\nsuperior performance of our approach. Specifically, we show an improvement of\n+1.3% mIoU against Mask3D on ScanNet semantic segmentation. We further\ndemonstrate the effectiveness of our approach in low-data regime by evaluating\nit for semantic segmentation task against the state-of-the-art methods.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"hHjvI6UMONl3mpl54lQxna-MsD-ofF2iOsaHpzJI6HQ","pdfSize":"2267906","txDigest":"FfhrLGChjtbrsTSiFmU5EXZcDuh7zQ7drPTqXWDy8YGo","endEpoch":"1","status":"CERTIFIED"}
