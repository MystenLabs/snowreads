{"id":"2408.05057","title":"SELD-Mamba: Selective State-Space Model for Sound Event Localization and\n  Detection with Source Distance Estimation","authors":"Da Mu, Zhicheng Zhang, Haobo Yue, Zehao Wang, Jin Tang, Jianqin Yin","authorsParsed":[["Mu","Da",""],["Zhang","Zhicheng",""],["Yue","Haobo",""],["Wang","Zehao",""],["Tang","Jin",""],["Yin","Jianqin",""]],"versions":[{"version":"v1","created":"Fri, 9 Aug 2024 13:26:08 GMT"}],"updateDate":"2024-08-12","timestamp":1723209968000,"abstract":"  In the Sound Event Localization and Detection (SELD) task, Transformer-based\nmodels have demonstrated impressive capabilities. However, the quadratic\ncomplexity of the Transformer's self-attention mechanism results in\ncomputational inefficiencies. In this paper, we propose a network architecture\nfor SELD called SELD-Mamba, which utilizes Mamba, a selective state-space\nmodel. We adopt the Event-Independent Network V2 (EINV2) as the foundational\nframework and replace its Conformer blocks with bidirectional Mamba blocks to\ncapture a broader range of contextual information while maintaining\ncomputational efficiency. Additionally, we implement a two-stage training\nmethod, with the first stage focusing on Sound Event Detection (SED) and\nDirection of Arrival (DoA) estimation losses, and the second stage\nreintroducing the Source Distance Estimation (SDE) loss. Our experimental\nresults on the 2024 DCASE Challenge Task3 dataset demonstrate the effectiveness\nof the selective state-space model in SELD and highlight the benefits of the\ntwo-stage training approach in enhancing SELD performance.\n","subjects":["Computing Research Repository/Sound","Computing Research Repository/Artificial Intelligence","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}