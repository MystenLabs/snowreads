{"id":"2408.13361","title":"NeurCAM: Interpretable Neural Clustering via Additive Models","authors":"Nakul Upadhya and Eldan Cohen","authorsParsed":[["Upadhya","Nakul",""],["Cohen","Eldan",""]],"versions":[{"version":"v1","created":"Fri, 23 Aug 2024 20:32:57 GMT"}],"updateDate":"2024-08-27","timestamp":1724445177000,"abstract":"  Interpretable clustering algorithms aim to group similar data points while\nexplaining the obtained groups to support knowledge discovery and pattern\nrecognition tasks. While most approaches to interpretable clustering construct\nclusters using decision trees, the interpretability of trees often deteriorates\non complex problems where large trees are required. In this work, we introduce\nthe Neural Clustering Additive Model (NeurCAM), a novel approach to the\ninterpretable clustering problem that leverages neural generalized additive\nmodels to provide fuzzy cluster membership with additive explanations of the\nobtained clusters. To promote sparsity in our model's explanations, we\nintroduce selection gates that explicitly limit the number of features and\npairwise interactions leveraged. Additionally, we demonstrate the capacity of\nour model to perform text clustering that considers the contextual\nrepresentation of the texts while providing explanations for the obtained\nclusters based on uni- or bi-word terms. Extensive experiments show that\nNeurCAM achieves performance comparable to black-box methods on tabular\ndatasets while remaining interpretable. Additionally, our approach\nsignificantly outperforms other interpretable clustering approaches when\nclustering on text data.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"5DKcN77ZuCR9CdThZ3QXqnRTyxmewOvRxlG4Ab5yprU","pdfSize":"2130168"}
