{"id":"2408.03539","title":"Deep Reinforcement Learning for Robotics: A Survey of Real-World\n  Successes","authors":"Chen Tang, Ben Abbatematteo, Jiaheng Hu, Rohan Chandra, Roberto\n  Mart\\'in-Mart\\'in, Peter Stone","authorsParsed":[["Tang","Chen",""],["Abbatematteo","Ben",""],["Hu","Jiaheng",""],["Chandra","Rohan",""],["Martín-Martín","Roberto",""],["Stone","Peter",""]],"versions":[{"version":"v1","created":"Wed, 7 Aug 2024 04:35:38 GMT"},{"version":"v2","created":"Thu, 15 Aug 2024 19:17:32 GMT"},{"version":"v3","created":"Mon, 16 Sep 2024 15:41:05 GMT"}],"updateDate":"2024-09-17","timestamp":1723005338000,"abstract":"  Reinforcement learning (RL), particularly its combination with deep neural\nnetworks referred to as deep RL (DRL), has shown tremendous promise across a\nwide range of applications, suggesting its potential for enabling the\ndevelopment of sophisticated robotic behaviors. Robotics problems, however,\npose fundamental difficulties for the application of RL, stemming from the\ncomplexity and cost of interacting with the physical world. This article\nprovides a modern survey of DRL for robotics, with a particular focus on\nevaluating the real-world successes achieved with DRL in realizing several key\nrobotic competencies. Our analysis aims to identify the key factors underlying\nthose exciting successes, reveal underexplored areas, and provide an overall\ncharacterization of the status of DRL in robotics. We highlight several\nimportant avenues for future work, emphasizing the need for stable and\nsample-efficient real-world RL paradigms, holistic approaches for discovering\nand integrating various competencies to tackle complex long-horizon, open-world\ntasks, and principled development and evaluation procedures. This survey is\ndesigned to offer insights for both RL practitioners and roboticists toward\nharnessing RL's power to create generally capable real-world robotic systems.\n","subjects":["Computing Research Repository/Robotics","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}