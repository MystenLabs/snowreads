{"id":"2408.07522","title":"Optimising MFCC parameters for the automatic detection of respiratory\n  diseases","authors":"Yuyang Yan, Sami O. Simons, Loes van Bemmel, Lauren Reinders, Frits\n  M.E. Franssen, and Visara Urovi","authorsParsed":[["Yan","Yuyang",""],["Simons","Sami O.",""],["van Bemmel","Loes",""],["Reinders","Lauren",""],["Franssen","Frits M. E.",""],["Urovi","Visara",""]],"versions":[{"version":"v1","created":"Wed, 14 Aug 2024 12:56:17 GMT"}],"updateDate":"2024-08-15","timestamp":1723640177000,"abstract":"  Voice signals originating from the respiratory tract are utilized as valuable\nacoustic biomarkers for the diagnosis and assessment of respiratory diseases.\nAmong the employed acoustic features, Mel Frequency Cepstral Coefficients\n(MFCC) is widely used for automatic analysis, with MFCC extraction commonly\nrelying on default parameters. However, no comprehensive study has\nsystematically investigated the impact of MFCC extraction parameters on\nrespiratory disease diagnosis. In this study, we address this gap by examining\nthe effects of key parameters, namely the number of coefficients, frame length,\nand hop length between frames, on respiratory condition examination. Our\ninvestigation uses four datasets: the Cambridge COVID-19 Sound database, the\nCoswara dataset, the Saarbrucken Voice Disorders (SVD) database, and a TACTICAS\ndataset. The Support Vector Machine (SVM) is employed as the classifier, given\nits widespread adoption and efficacy. Our findings indicate that the accuracy\nof MFCC decreases as hop length increases, and the optimal number of\ncoefficients is observed to be approximately 30. The performance of MFCC varies\nwith frame length across the datasets: for the COVID-19 datasets (Cambridge\nCOVID-19 Sound database and Coswara dataset), performance declines with longer\nframe lengths, while for the SVD dataset, performance improves with increasing\nframe length (from 50 ms to 500 ms). Furthermore, we investigate the optimized\ncombination of these parameters and observe substantial enhancements in\naccuracy. Compared to the worst combination, the SVM model achieves an accuracy\nof 81.1%, 80.6%, and 71.7%, with improvements of 19.6%, 16.10%, and 14.90% for\nthe Cambridge COVID-19 Sound database, the Coswara dataset, and the SVD dataset\nrespectively.\n","subjects":["Computing Research Repository/Sound","Computing Research Repository/Machine Learning","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"9J_1doKPdOuyt91qplNiRY15RL_FcSbrFPLnwuShq8w","pdfSize":"719242"}
