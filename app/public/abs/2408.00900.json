{"id":"2408.00900","title":"Expressive MIDI-format Piano Performance Generation","authors":"Jingwei Liu","authorsParsed":[["Liu","Jingwei",""]],"versions":[{"version":"v1","created":"Thu, 1 Aug 2024 20:36:37 GMT"}],"updateDate":"2024-08-05","timestamp":1722544597000,"abstract":"  This work presents a generative neural network that's able to generate\nexpressive piano performance in MIDI format. The musical expressivity is\nreflected by vivid micro-timing, rich polyphonic texture, varied dynamics, and\nthe sustain pedal effects. This model is innovative from many aspects of data\nprocessing to neural network design. We claim that this symbolic music\ngeneration model overcame the common critics of symbolic music and is able to\ngenerate expressive music flows as good as, if not better than generations with\nraw audio. One drawback is that, due to the limited time for submission, the\nmodel is not fine-tuned and sufficiently trained, thus the generation may sound\nincoherent and random at certain points. Despite that, this model shows its\npowerful generative ability to generate expressive piano pieces.\n","subjects":["Computing Research Repository/Sound","Computing Research Repository/Artificial Intelligence","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"YPIxr0B0MuBCnMhxgnGjj3OyomERsYuw6E0yGyO_YVk","pdfSize":"839277","txDigest":"6K5xDtYAPxfZwZgrxQ7Dzw3xuRZdoveLnavZ112pED72","endEpoch":"1","status":"CERTIFIED"}
