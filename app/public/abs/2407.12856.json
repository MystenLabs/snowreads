{"id":"2407.12856","title":"AI AI Bias: Large Language Models Favor Their Own Generated Content","authors":"Walter Laurito, Benjamin Davis, Peli Grietzer, Tom\\'a\\v{s}\n  Gaven\\v{c}iak, Ada B\\\"ohm, Jan Kulveit","authorsParsed":[["Laurito","Walter",""],["Davis","Benjamin",""],["Grietzer","Peli",""],["Gavenčiak","Tomáš",""],["Böhm","Ada",""],["Kulveit","Jan",""]],"versions":[{"version":"v1","created":"Tue, 9 Jul 2024 13:15:14 GMT"}],"updateDate":"2024-07-19","timestamp":1720530914000,"abstract":"  Are large language models (LLMs) biased towards text generated by LLMs over\ntext authored by humans, leading to possible anti-human bias? Utilizing a\nclassical experimental design inspired by employment discrimination studies, we\ntested widely-used LLMs, including GPT-3.5 and GPT4, in binary-choice\nscenarios. These involved LLM-based agents selecting between products and\nacademic papers described either by humans or LLMs under identical conditions.\nOur results show a consistent tendency for LLM-based AIs to prefer\nLLM-generated content. This suggests the possibility of AI systems implicitly\ndiscriminating against humans, giving AI agents an unfair advantage.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computers and Society","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"HdlhkZ5vXRkCedXKwXve9f7HuBUCGlrVHJPS4Lc4iEo","pdfSize":"234749","objectId":"0x524ea7101669a1c12265ab5013d6af196bcd0fa22b0739cb76ec2bea914379d4","registeredEpoch":"3","certifiedEpoch":"3","startEpoch":"3","endEpoch":"203"}
