{"id":"2408.13880","title":"On classical advice, sampling advise and complexity assumptions for\n  learning separations","authors":"Jordi P\\'erez-Guijarro","authorsParsed":[["PÃ©rez-Guijarro","Jordi",""]],"versions":[{"version":"v1","created":"Sun, 25 Aug 2024 16:06:18 GMT"}],"updateDate":"2024-08-27","timestamp":1724601978000,"abstract":"  In this paper, we prove the equivalence between sampling advice, i.e., advice\nin the form of a training set, and classical advice. Specifically, our main\nresult demonstrates that BPP/samp is equal to P/poly. Additionally, we delve\ninto the analysis of these relationships under the constraint of a fixed\ndistribution. Notably, we show that under such circumstances, the equality does\nnot hold. This result remains valid when considering quantum advice and a\nquantum generalization of the training set. Finally, leveraging the insights\ngained from these proofs, we identify sufficient and necessary complexity\nassumptions for the existence of concept classes that exhibit a quantum\nlearning speed-up in the worst-case scenario, i.e., when accurate results are\nrequired for all inputs.\n","subjects":["Physics/Quantum Physics","Computing Research Repository/Computational Complexity"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}