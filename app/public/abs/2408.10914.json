{"id":"2408.10914","title":"To Code, or Not To Code? Exploring Impact of Code in Pre-training","authors":"Viraat Aryabumi, Yixuan Su, Raymond Ma, Adrien Morisot, Ivan Zhang,\n  Acyr Locatelli, Marzieh Fadaee, Ahmet \\\"Ust\\\"un, Sara Hooker","authorsParsed":[["Aryabumi","Viraat",""],["Su","Yixuan",""],["Ma","Raymond",""],["Morisot","Adrien",""],["Zhang","Ivan",""],["Locatelli","Acyr",""],["Fadaee","Marzieh",""],["Üstün","Ahmet",""],["Hooker","Sara",""]],"versions":[{"version":"v1","created":"Tue, 20 Aug 2024 14:58:13 GMT"}],"updateDate":"2024-08-21","timestamp":1724165893000,"abstract":"  Including code in the pre-training data mixture, even for models not\nspecifically designed for code, has become a common practice in LLMs\npre-training. While there has been anecdotal consensus among practitioners that\ncode data plays a vital role in general LLMs' performance, there is only\nlimited work analyzing the precise impact of code on non-code tasks. In this\nwork, we systematically investigate the impact of code data on general\nperformance. We ask \"what is the impact of code data used in pre-training on a\nlarge variety of downstream tasks beyond code generation\". We conduct extensive\nablations and evaluate across a broad range of natural language reasoning\ntasks, world knowledge tasks, code benchmarks, and LLM-as-a-judge win-rates for\nmodels with sizes ranging from 470M to 2.8B parameters. Across settings, we\nfind a consistent results that code is a critical building block for\ngeneralization far beyond coding tasks and improvements to code quality have an\noutsized impact across all tasks. In particular, compared to text-only\npre-training, the addition of code results in up to relative increase of 8.2%\nin natural language (NL) reasoning, 4.2% in world knowledge, 6.6% improvement\nin generative win-rates, and a 12x boost in code performance respectively. Our\nwork suggests investments in code quality and preserving code during\npre-training have positive impacts.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/"}