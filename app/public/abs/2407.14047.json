{"id":"2407.14047","title":"OCTrack: Benchmarking the Open-Corpus Multi-Object Tracking","authors":"Zekun Qian, Ruize Han, Wei Feng, Junhui Hou, Linqi Song, Song Wang","authorsParsed":[["Qian","Zekun",""],["Han","Ruize",""],["Feng","Wei",""],["Hou","Junhui",""],["Song","Linqi",""],["Wang","Song",""]],"versions":[{"version":"v1","created":"Fri, 19 Jul 2024 05:58:01 GMT"}],"updateDate":"2024-07-22","timestamp":1721368681000,"abstract":"  We study a novel yet practical problem of open-corpus multi-object tracking\n(OCMOT), which extends the MOT into localizing, associating, and recognizing\ngeneric-category objects of both seen (base) and unseen (novel) classes, but\nwithout the category text list as prompt. To study this problem, the top\npriority is to build a benchmark. In this work, we build OCTrackB, a\nlarge-scale and comprehensive benchmark, to provide a standard evaluation\nplatform for the OCMOT problem. Compared to previous datasets, OCTrackB has\nmore abundant and balanced base/novel classes and the corresponding samples for\nevaluation with less bias. We also propose a new multi-granularity recognition\nmetric to better evaluate the generative object recognition in OCMOT. By\nconducting the extensive benchmark evaluation, we report and analyze the\nresults of various state-of-the-art methods, which demonstrate the rationale of\nOCMOT, as well as the usefulness and advantages of OCTrackB.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}