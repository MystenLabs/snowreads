{"id":"2407.11361","title":"Graph Structure Prompt Learning: A Novel Methodology to Improve\n  Performance of Graph Neural Networks","authors":"Zhenhua Huang, Kunhao Li, Shaojie Wang, Zhaohong Jia, Wentao Zhu,\n  Sharad Mehrotra","authorsParsed":[["Huang","Zhenhua",""],["Li","Kunhao",""],["Wang","Shaojie",""],["Jia","Zhaohong",""],["Zhu","Wentao",""],["Mehrotra","Sharad",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 03:59:18 GMT"}],"updateDate":"2024-07-17","timestamp":1721102358000,"abstract":"  Graph neural networks (GNNs) are widely applied in graph data modeling.\nHowever, existing GNNs are often trained in a task-driven manner that fails to\nfully capture the intrinsic nature of the graph structure, resulting in\nsub-optimal node and graph representations. To address this limitation, we\npropose a novel Graph structure Prompt Learning method (GPL) to enhance the\ntraining of GNNs, which is inspired by prompt mechanisms in natural language\nprocessing. GPL employs task-independent graph structure losses to encourage\nGNNs to learn intrinsic graph characteristics while simultaneously solving\ndownstream tasks, producing higher-quality node and graph representations. In\nextensive experiments on eleven real-world datasets, after being trained by\nGPL, GNNs significantly outperform their original performance on node\nclassification, graph classification, and edge prediction tasks (up to 10.28%,\n16.5%, and 24.15%, respectively). By allowing GNNs to capture the inherent\nstructural prompts of graphs in GPL, they can alleviate the issue of\nover-smooth and achieve new state-of-the-art performances, which introduces a\nnovel and effective direction for GNN research with potential applications in\nvarious domains.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Social and Information Networks"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}