{"id":"2408.10243","title":"TrIM: Triangular Input Movement Systolic Array for Convolutional Neural\n  Networks -- Part II: Architecture and Hardware Implementation","authors":"Cristian Sestito, Shady Agwa, Themis Prodromakis","authorsParsed":[["Sestito","Cristian",""],["Agwa","Shady",""],["Prodromakis","Themis",""]],"versions":[{"version":"v1","created":"Mon, 5 Aug 2024 10:18:00 GMT"}],"updateDate":"2024-08-21","timestamp":1722853080000,"abstract":"  Modern hardware architectures for Convolutional Neural Networks (CNNs), other\nthan targeting high performance, aim at dissipating limited energy. Reducing\nthe data movement cost between the computing cores and the memory is a way to\nmitigate the energy consumption. Systolic arrays are suitable architectures to\nachieve this objective: they use multiple processing elements that communicate\neach other to maximize data utilization, based on proper dataflows like the\nweight stationary and row stationary. Motivated by this, we have proposed TrIM,\nan innovative dataflow based on a triangular movement of inputs, and capable to\nreduce the number of memory accesses by one order of magnitude when compared to\nstate-of-the-art systolic arrays. In this paper, we present a TrIM-based\nhardware architecture for CNNs. As a showcase, the accelerator is implemented\nonto a Field Programmable Gate Array (FPGA) to execute the VGG-16 CNN. The\narchitecture achieves a peak throughput of 453.6 Giga Operations per Second,\noutperforming a state-of-the-art row stationary systolic array by ~5.1x in\nterms of memory accesses, and being up to ~12.2x more energy-efficient than\nother FPGA accelerators.\n","subjects":["Computing Research Repository/Hardware Architecture","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Neural and Evolutionary Computing"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"vixebanvW4zzign1L0CFxCv2-DJL0CqzHv4idI_141c","pdfSize":"1874894"}
