{"id":"2407.11807","title":"Scalable and Reliable Over-the-Air Federated Edge Learning","authors":"Maximilian Egger, Christoph Hofmeister, Cem Kaya, Rawad Bitar, Antonia\n  Wachter-Zeh","authorsParsed":[["Egger","Maximilian",""],["Hofmeister","Christoph",""],["Kaya","Cem",""],["Bitar","Rawad",""],["Wachter-Zeh","Antonia",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 14:58:55 GMT"}],"updateDate":"2024-07-17","timestamp":1721141935000,"abstract":"  Federated edge learning (FEEL) has emerged as a core paradigm for large-scale\noptimization. However, FEEL still suffers from a communication bottleneck due\nto the transmission of high-dimensional model updates from the clients to the\nfederator. Over-the-air computation (AirComp) leverages the additive property\nof multiple-access channels by aggregating the clients' updates over the\nchannel to save communication resources. While analog uncoded transmission can\nbenefit from the increased signal-to-noise ratio (SNR) due to the simultaneous\ntransmission of many clients, potential errors may severely harm the learning\nprocess for small SNRs. To alleviate this problem, channel coding approaches\nwere recently proposed for AirComp in FEEL. However, their error-correction\ncapability degrades with an increasing number of clients. We propose a digital\nlattice-based code construction with constant error-correction capabilities in\nthe number of clients, and compare to nested-lattice codes, well-known for\ntheir optimal rate and power efficiency in the point-to-point AWGN channel.\n","subjects":["Computing Research Repository/Information Theory","Computing Research Repository/Distributed, Parallel, and Cluster Computing","Computing Research Repository/Machine Learning","Mathematics/Information Theory"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}