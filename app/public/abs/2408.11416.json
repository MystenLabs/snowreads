{"id":"2408.11416","title":"Subgoal-based Hierarchical Reinforcement Learning for Multi-Agent\n  Collaboration","authors":"Cheng Xu, Changtian Zhang, Yuchen Shi, Ran Wang, Shihong Duan, Yadong\n  Wan, and Xiaotong Zhang","authorsParsed":[["Xu","Cheng",""],["Zhang","Changtian",""],["Shi","Yuchen",""],["Wang","Ran",""],["Duan","Shihong",""],["Wan","Yadong",""],["Zhang","Xiaotong",""]],"versions":[{"version":"v1","created":"Wed, 21 Aug 2024 08:22:11 GMT"}],"updateDate":"2024-08-22","timestamp":1724228531000,"abstract":"  Recent advancements in reinforcement learning have made significant impacts\nacross various domains, yet they often struggle in complex multi-agent\nenvironments due to issues like algorithm instability, low sampling efficiency,\nand the challenges of exploration and dimensionality explosion. Hierarchical\nreinforcement learning (HRL) offers a structured approach to decompose complex\ntasks into simpler sub-tasks, which is promising for multi-agent settings. This\npaper advances the field by introducing a hierarchical architecture that\nautonomously generates effective subgoals without explicit constraints,\nenhancing both flexibility and stability in training. We propose a dynamic goal\ngeneration strategy that adapts based on environmental changes. This method\nsignificantly improves the adaptability and sample efficiency of the learning\nprocess. Furthermore, we address the critical issue of credit assignment in\nmulti-agent systems by synergizing our hierarchical architecture with a\nmodified QMIX network, thus improving overall strategy coordination and\nefficiency. Comparative experiments with mainstream reinforcement learning\nalgorithms demonstrate the superior convergence speed and performance of our\napproach in both single-agent and multi-agent environments, confirming its\neffectiveness and flexibility in complex scenarios. Our code is open-sourced\nat: \\url{https://github.com/SICC-Group/GMAH}.\n","subjects":["Computing Research Repository/Multiagent Systems","Computing Research Repository/Robotics"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}