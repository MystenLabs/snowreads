{"id":"2407.15224","title":"PUFFLE: Balancing Privacy, Utility, and Fairness in Federated Learning","authors":"Luca Corbucci, Mikko A Heikkila, David Solans Noguero, Anna Monreale,\n  Nicolas Kourtellis","authorsParsed":[["Corbucci","Luca",""],["Heikkila","Mikko A",""],["Noguero","David Solans",""],["Monreale","Anna",""],["Kourtellis","Nicolas",""]],"versions":[{"version":"v1","created":"Sun, 21 Jul 2024 17:22:18 GMT"}],"updateDate":"2024-07-23","timestamp":1721582538000,"abstract":"  Training and deploying Machine Learning models that simultaneously adhere to\nprinciples of fairness and privacy while ensuring good utility poses a\nsignificant challenge. The interplay between these three factors of\ntrustworthiness is frequently underestimated and remains insufficiently\nexplored. Consequently, many efforts focus on ensuring only two of these\nfactors, neglecting one in the process. The decentralization of the datasets\nand the variations in distributions among the clients exacerbate the complexity\nof achieving this ethical trade-off in the context of Federated Learning (FL).\nFor the first time in FL literature, we address these three factors of\ntrustworthiness. We introduce PUFFLE, a high-level parameterised approach that\ncan help in the exploration of the balance between utility, privacy, and\nfairness in FL scenarios. We prove that PUFFLE can be effective across diverse\ndatasets, models, and data distributions, reducing the model unfairness up to\n75%, with a maximum reduction in the utility of 17% in the worst-case scenario,\nwhile maintaining strict privacy guarantees during the FL training.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Cryptography and Security","Computing Research Repository/Computers and Society"],"license":"http://creativecommons.org/licenses/by/4.0/"}