{"id":"2407.07468","title":"Rethinking Few-shot Class-incremental Learning: Learning from Yourself","authors":"Yu-Ming Tang, Yi-Xing Peng, Jingke Meng, Wei-Shi Zheng","authorsParsed":[["Tang","Yu-Ming",""],["Peng","Yi-Xing",""],["Meng","Jingke",""],["Zheng","Wei-Shi",""]],"versions":[{"version":"v1","created":"Wed, 10 Jul 2024 08:52:56 GMT"}],"updateDate":"2024-07-11","timestamp":1720601576000,"abstract":"  Few-shot class-incremental learning (FSCIL) aims to learn sequential classes\nwith limited samples in a few-shot fashion. Inherited from the classical\nclass-incremental learning setting, the popular benchmark of FSCIL uses\naveraged accuracy (aAcc) and last-task averaged accuracy (lAcc) as the\nevaluation metrics. However, we reveal that such evaluation metrics may not\nprovide adequate emphasis on the novel class performance, and the continual\nlearning ability of FSCIL methods could be ignored under this benchmark. In\nthis work, as a complement to existing metrics, we offer a new metric called\ngeneralized average accuracy (gAcc) which is designed to provide an extra\nequitable evaluation by incorporating different perspectives of the performance\nunder the guidance of a parameter $\\alpha$. We also present an overall metric\nin the form of the area under the curve (AUC) along the $\\alpha$. Under the\nguidance of gAcc, we release the potential of intermediate features of the\nvision transformers to boost the novel-class performance. Taking information\nfrom intermediate layers which are less class-specific and more generalizable,\nwe manage to rectify the final features, leading to a more generalizable\ntransformer-based FSCIL framework. Without complex network designs or\ncumbersome training procedures, our method outperforms existing FSCIL methods\nat aAcc and gAcc on three datasets. See codes at\nhttps://github.com/iSEE-Laboratory/Revisting_FSCIL\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}