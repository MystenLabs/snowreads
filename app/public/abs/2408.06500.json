{"id":"2408.06500","title":"Music2Latent: Consistency Autoencoders for Latent Audio Compression","authors":"Marco Pasini, Stefan Lattner, George Fazekas","authorsParsed":[["Pasini","Marco",""],["Lattner","Stefan",""],["Fazekas","George",""]],"versions":[{"version":"v1","created":"Mon, 12 Aug 2024 21:25:19 GMT"}],"updateDate":"2024-08-14","timestamp":1723497919000,"abstract":"  Efficient audio representations in a compressed continuous latent space are\ncritical for generative audio modeling and Music Information Retrieval (MIR)\ntasks. However, some existing audio autoencoders have limitations, such as\nmulti-stage training procedures, slow iterative sampling, or low reconstruction\nquality. We introduce Music2Latent, an audio autoencoder that overcomes these\nlimitations by leveraging consistency models. Music2Latent encodes samples into\na compressed continuous latent space in a single end-to-end training process\nwhile enabling high-fidelity single-step reconstruction. Key innovations\ninclude conditioning the consistency model on upsampled encoder outputs at all\nlevels through cross connections, using frequency-wise self-attention to\ncapture long-range frequency dependencies, and employing frequency-wise learned\nscaling to handle varying value distributions across frequencies at different\nnoise levels. We demonstrate that Music2Latent outperforms existing continuous\naudio autoencoders in sound quality and reconstruction accuracy while achieving\ncompetitive performance on downstream MIR tasks using its latent\nrepresentations. To our knowledge, this represents the first successful attempt\nat training an end-to-end consistency autoencoder model.\n","subjects":["Computing Research Repository/Sound","Computing Research Repository/Machine Learning","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"cTU-8mscepXNGSQZnw6E6d_Eg7NasVlhjEzsUDKYWDk","pdfSize":"552900"}
