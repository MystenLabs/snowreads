{"id":"2407.06537","title":"Efficient and Accurate Memorable Conversation Model using DPO based on\n  sLLM","authors":"Youngkyung Seo, Yoonseok Heo, Jun-Seok Koh, Du-Seong Chang","authorsParsed":[["Seo","Youngkyung",""],["Heo","Yoonseok",""],["Koh","Jun-Seok",""],["Chang","Du-Seong",""]],"versions":[{"version":"v1","created":"Tue, 9 Jul 2024 04:17:39 GMT"},{"version":"v2","created":"Tue, 27 Aug 2024 04:43:59 GMT"}],"updateDate":"2024-08-28","timestamp":1720498659000,"abstract":"  In multi-session dialog system, it is essential to continuously update the\nmemory as the session progresses. Simply accumulating memory can make it\ndifficult to focus on the content of the conversation for inference due to the\nlimited input sentence size. Therefore, efficient and accurate conversation\nmodel that is capable of managing memory to reflect the conversation history\ncontinuously is necessary. This paper presents a conversation model that\nefficiently manages memory as sessions progress and incorporates this into the\nmodel to reflect the conversation history accurately with 3 methodologies: SFT,\nDPO and DPO with SFT model. Our model using DPO algorithm shows an improvement\nabout 0.0591 of BERTScore in memory accuracy, and the rate of responses\nreflecting the memory increased as well. Also, response generation performance\nenhanced about 4.292 in fluency, 3.935 in coherence, and 2.896 in consistency.\nThis paper describes a training method that yields better performance than\nmodels with more than twice the parameter size, even when the model size is\nsmaller. Thus, our model demonstrates efficiency not only in terms of accuracy\nbut also in resource utilization.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}