{"id":"2407.11004","title":"The ALCHEmist: Automated Labeling 500x CHEaper Than LLM Data Annotators","authors":"Tzu-Heng Huang, Catherine Cao, Vaishnavi Bhargava, Frederic Sala","authorsParsed":[["Huang","Tzu-Heng",""],["Cao","Catherine",""],["Bhargava","Vaishnavi",""],["Sala","Frederic",""]],"versions":[{"version":"v1","created":"Tue, 25 Jun 2024 17:58:26 GMT"}],"updateDate":"2024-07-17","timestamp":1719338306000,"abstract":"  Large pretrained models can be used as annotators, helping replace or augment\ncrowdworkers and enabling distilling generalist models into smaller specialist\nmodels. Unfortunately, this comes at a cost: employing top-of-the-line models\noften requires paying thousands of dollars for API calls, while the resulting\ndatasets are static and challenging to audit. To address these challenges, we\npropose a simple alternative: rather than directly querying labels from\npretrained models, we task models to generate programs that can produce labels.\nThese programs can be stored and applied locally, re-used and extended, and\ncost orders of magnitude less. Our system, Alchemist, obtains comparable to or\nbetter performance than large language model-based annotation in a range of\ntasks for a fraction of the cost: on average, improvements amount to a 12.9%\nenhancement while the total labeling costs across all datasets are reduced by a\nfactor of approximately 500x.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"Vxjl8dP15FQ8Ztipl8s43Djo6qMgqX_5jEhpfoI7Fds","pdfSize":"2582906"}
