{"id":"2407.21443","title":"Improving Faithfulness of Large Language Models in Summarization via\n  Sliding Generation and Self-Consistency","authors":"Taiji Li, Zhi Li, Yin Zhang","authorsParsed":[["Li","Taiji",""],["Li","Zhi",""],["Zhang","Yin",""]],"versions":[{"version":"v1","created":"Wed, 31 Jul 2024 08:48:48 GMT"}],"updateDate":"2024-08-01","timestamp":1722415728000,"abstract":"  Despite large language models (LLMs) have demonstrated impressive performance\nin various tasks, they are still suffering from the factual inconsistency\nproblem called hallucinations. For instance, LLMs occasionally generate content\nthat diverges from source article, and prefer to extract information that\nappears at the beginning and end of the context, especially in long document\nsummarization. Inspired by these findings, we propose to improve the\nfaithfulness of LLMs in summarization by impelling them to process the entire\narticle more fairly and faithfully. We present a novel summary generation\nstrategy, namely SliSum, which exploits the ideas of sliding windows and\nself-consistency. Specifically, SliSum divides the source article into\noverlapping windows, and utilizes LLM to generate local summaries for the\ncontent in the windows. Finally, SliSum aggregates all local summaries using\nclustering and majority voting algorithm to produce more faithful summary of\nentire article. Extensive experiments demonstrate that SliSum significantly\nimproves the faithfulness of diverse LLMs including LLaMA-2, Claude-2 and\nGPT-3.5 in both short and long text summarization, while maintaining their\nfluency and informativeness and without additional fine-tuning and resources.\nWe further conduct qualitative and quantitative studies to investigate why\nSliSum works and impacts of hyperparameters in SliSum on performance.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"0KTmqVT9i3mmO85qr3whal3P5uvuiFKBMDtDkAh_Sck","pdfSize":"911882"}
