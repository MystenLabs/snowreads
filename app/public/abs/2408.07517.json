{"id":"2408.07517","title":"Advancing Spatio-Temporal Processing in Spiking Neural Networks through\n  Adaptation","authors":"Maximilian Baronig, Romain Ferrand, Silvester Sabathiel, Robert\n  Legenstein","authorsParsed":[["Baronig","Maximilian",""],["Ferrand","Romain",""],["Sabathiel","Silvester",""],["Legenstein","Robert",""]],"versions":[{"version":"v1","created":"Wed, 14 Aug 2024 12:49:58 GMT"}],"updateDate":"2024-08-15","timestamp":1723639798000,"abstract":"  Efficient implementations of spiking neural networks on neuromorphic hardware\npromise orders of magnitude less power consumption than their non-spiking\ncounterparts. The standard neuron model for spike-based computation on such\nneuromorphic systems has long been the leaky integrate-and-fire (LIF) neuron.\nAs a promising advancement, a computationally light augmentation of the LIF\nneuron model with an adaptation mechanism experienced a recent upswing in\npopularity, caused by demonstrations of its superior performance on\nspatio-temporal processing tasks. The root of the superiority of these\nso-called adaptive LIF neurons however, is not well understood. In this\narticle, we thoroughly analyze the dynamical, computational, and learning\nproperties of adaptive LIF neurons and networks thereof. We find that the\nfrequently observed stability problems during training of such networks can be\novercome by applying an alternative discretization method that results in\nprovably better stability properties than the commonly used Euler-Forward\nmethod. With this discretization, we achieved a new state-of-the-art\nperformance on common event-based benchmark datasets. We also show that the\nsuperiority of networks of adaptive LIF neurons extends to the prediction and\ngeneration of complex time series. Our further analysis of the computational\nproperties of networks of adaptive LIF neurons shows that they are particularly\nwell suited to exploit the spatio-temporal structure of input sequences.\nFurthermore, these networks are surprisingly robust to shifts of the mean input\nstrength and input spike rate, even when these shifts were not observed during\ntraining. As a consequence, high-performance networks can be obtained without\nany normalization techniques such as batch normalization or batch-normalization\nthrough time.\n","subjects":["Computing Research Repository/Neural and Evolutionary Computing"],"license":"http://creativecommons.org/licenses/by-sa/4.0/"}