{"id":"2407.12126","title":"LLMs-in-the-loop Part-1: Expert Small AI Models for Bio-Medical Text\n  Translation","authors":"Bunyamin Keles, Murat Gunay, Serdar I.Caglar","authorsParsed":[["Keles","Bunyamin",""],["Gunay","Murat",""],["Caglar","Serdar I.",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 19:32:23 GMT"},{"version":"v2","created":"Fri, 26 Jul 2024 12:37:58 GMT"}],"updateDate":"2024-07-29","timestamp":1721158343000,"abstract":"  Machine translation is indispensable in healthcare for enabling the global\ndissemination of medical knowledge across languages. However, complex medical\nterminology poses unique challenges to achieving adequate translation quality\nand accuracy. This study introduces a novel \"LLMs-in-the-loop\" approach to\ndevelop supervised neural machine translation models optimized specifically for\nmedical texts. While large language models (LLMs) have demonstrated powerful\ncapabilities, this research shows that small, specialized models trained on\nhigh-quality in-domain (mostly synthetic) data can outperform even vastly\nlarger LLMs.\n  Custom parallel corpora in six languages were compiled from scientific\narticles, synthetically generated clinical documents, and medical texts. Our\nLLMs-in-the-loop methodology employs synthetic data generation, rigorous\nevaluation, and agent orchestration to enhance performance. We developed small\nmedical translation models using the MarianMT base model. We introduce a new\nmedical translation test dataset to standardize evaluation in this domain.\nAssessed using BLEU, METEOR, ROUGE, and BERT scores on this test set, our\nMarianMT-based models outperform Google Translate, DeepL, and GPT-4-Turbo.\n  Results demonstrate that our LLMs-in-the-loop approach, combined with\nfine-tuning high-quality, domain-specific data, enables specialized models to\noutperform general-purpose and some larger systems. This research, part of a\nbroader series on expert small models, paves the way for future\nhealthcare-related AI developments, including deidentification and bio-medical\nentity extraction models. Our study underscores the potential of tailored\nneural translation models and the LLMs-in-the-loop methodology to advance the\nfield through improved data generation, evaluation, agent, and modeling\ntechniques.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/"}