{"id":"2408.11558","title":"GSTran: Joint Geometric and Semantic Coherence for Point Cloud\n  Segmentation","authors":"Abiao Li, Chenlei Lv, Guofeng Mei, Yifan Zuo, Jian Zhang, Yuming Fang","authorsParsed":[["Li","Abiao",""],["Lv","Chenlei",""],["Mei","Guofeng",""],["Zuo","Yifan",""],["Zhang","Jian",""],["Fang","Yuming",""]],"versions":[{"version":"v1","created":"Wed, 21 Aug 2024 12:12:37 GMT"}],"updateDate":"2024-08-23","timestamp":1724242357000,"abstract":"  Learning meaningful local and global information remains a challenge in point\ncloud segmentation tasks. When utilizing local information, prior studies\nindiscriminately aggregates neighbor information from different classes to\nupdate query points, potentially compromising the distinctive feature of query\npoints. In parallel, inaccurate modeling of long-distance contextual\ndependencies when utilizing global information can also impact model\nperformance. To address these issues, we propose GSTran, a novel transformer\nnetwork tailored for the segmentation task. The proposed network mainly\nconsists of two principal components: a local geometric transformer and a\nglobal semantic transformer. In the local geometric transformer module, we\nexplicitly calculate the geometric disparity within the local region. This\nenables amplifying the affinity with geometrically similar neighbor points\nwhile suppressing the association with other neighbors. In the global semantic\ntransformer module, we design a multi-head voting strategy. This strategy\nevaluates semantic similarity across the entire spatial range, facilitating the\nprecise capture of contextual dependencies. Experiments on ShapeNetPart and\nS3DIS benchmarks demonstrate the effectiveness of the proposed method, showing\nits superiority over other algorithms. The code is available at\nhttps://github.com/LAB123-tech/GSTran.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}