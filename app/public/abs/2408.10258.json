{"id":"2408.10258","title":"NeRF-US: Removing Ultrasound Imaging Artifacts from Neural Radiance\n  Fields in the Wild","authors":"Rishit Dagli, Atsuhiro Hibi, Rahul G. Krishnan, and Pascal N. Tyrrell","authorsParsed":[["Dagli","Rishit",""],["Hibi","Atsuhiro",""],["Krishnan","Rahul G.",""],["Tyrrell","Pascal N.",""]],"versions":[{"version":"v1","created":"Tue, 13 Aug 2024 13:21:53 GMT"},{"version":"v2","created":"Wed, 21 Aug 2024 00:52:28 GMT"}],"updateDate":"2024-08-22","timestamp":1723555313000,"abstract":"  Current methods for performing 3D reconstruction and novel view synthesis\n(NVS) in ultrasound imaging data often face severe artifacts when training\nNeRF-based approaches. The artifacts produced by current approaches differ from\nNeRF floaters in general scenes because of the unique nature of ultrasound\ncapture. Furthermore, existing models fail to produce reasonable 3D\nreconstructions when ultrasound data is captured or obtained casually in\nuncontrolled environments, which is common in clinical settings. Consequently,\nexisting reconstruction and NVS methods struggle to handle ultrasound motion,\nfail to capture intricate details, and cannot model transparent and reflective\nsurfaces. In this work, we introduced NeRF-US, which incorporates 3D-geometry\nguidance for border probability and scattering density into NeRF training,\nwhile also utilizing ultrasound-specific rendering over traditional volume\nrendering. These 3D priors are learned through a diffusion model. Through\nexperiments conducted on our new \"Ultrasound in the Wild\" dataset, we observed\naccurate, clinically plausible, artifact-free reconstructions.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}