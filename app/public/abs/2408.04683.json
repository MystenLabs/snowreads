{"id":"2408.04683","title":"Eliminating Backdoors in Neural Code Models via Trigger Inversion","authors":"Weisong Sun and Yuchen Chen and Chunrong Fang and Yebo Feng and Yuan\n  Xiao and An Guo and Quanjun Zhang and Yang Liu and Baowen Xu and Zhenyu Chen","authorsParsed":[["Sun","Weisong",""],["Chen","Yuchen",""],["Fang","Chunrong",""],["Feng","Yebo",""],["Xiao","Yuan",""],["Guo","An",""],["Zhang","Quanjun",""],["Liu","Yang",""],["Xu","Baowen",""],["Chen","Zhenyu",""]],"versions":[{"version":"v1","created":"Thu, 8 Aug 2024 08:23:03 GMT"}],"updateDate":"2024-08-12","timestamp":1723105383000,"abstract":"  Neural code models (NCMs) have been widely used for addressing various code\nunderstanding tasks, such as defect detection and clone detection. However,\nnumerous recent studies reveal that such models are vulnerable to backdoor\nattacks. Backdoored NCMs function normally on normal code snippets, but exhibit\nadversary-expected behavior on poisoned code snippets injected with the\nadversary-crafted trigger. It poses a significant security threat. For example,\na backdoored defect detection model may misclassify user-submitted defective\ncode as non-defective. If this insecure code is then integrated into critical\nsystems, like autonomous driving systems, it could lead to life safety.\nHowever, there is an urgent need for effective defenses against backdoor\nattacks targeting NCMs.\n  To address this issue, in this paper, we innovatively propose a backdoor\ndefense technique based on trigger inversion, called EliBadCode. EliBadCode\nfirst filters the model vocabulary for trigger tokens to reduce the search\nspace for trigger inversion, thereby enhancing the efficiency of the trigger\ninversion. Then, EliBadCode introduces a sample-specific trigger position\nidentification method, which can reduce the interference of adversarial\nperturbations for subsequent trigger inversion, thereby producing effective\ninverted triggers efficiently. Subsequently, EliBadCode employs a Greedy\nCoordinate Gradient algorithm to optimize the inverted trigger and designs a\ntrigger anchoring method to purify the inverted trigger. Finally, EliBadCode\neliminates backdoors through model unlearning. We evaluate the effectiveness of\nEliBadCode in eliminating backdoor attacks against multiple NCMs used for three\nsafety-critical code understanding tasks. The results demonstrate that\nEliBadCode can effectively eliminate backdoors while having minimal adverse\neffects on the normal functionality of the model.\n","subjects":["Computing Research Repository/Cryptography and Security","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Software Engineering"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}