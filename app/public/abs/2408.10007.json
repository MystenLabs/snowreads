{"id":"2408.10007","title":"P3P: Pseudo-3D Pre-training for Scaling 3D Masked Autoencoders","authors":"Xuechao Chen, Ying Chen, Jialin Li, Qiang Nie, Yong Liu, Qixing Huang,\n  Yang Li","authorsParsed":[["Chen","Xuechao",""],["Chen","Ying",""],["Li","Jialin",""],["Nie","Qiang",""],["Liu","Yong",""],["Huang","Qixing",""],["Li","Yang",""]],"versions":[{"version":"v1","created":"Mon, 19 Aug 2024 13:59:53 GMT"}],"updateDate":"2024-08-20","timestamp":1724075993000,"abstract":"  3D pre-training is crucial to 3D perception tasks. However, limited by the\ndifficulties in collecting clean 3D data, 3D pre-training consistently faced\ndata scaling challenges. Inspired by semi-supervised learning leveraging\nlimited labeled data and a large amount of unlabeled data, in this work, we\npropose a novel self-supervised pre-training framework utilizing the real 3D\ndata and the pseudo-3D data lifted from images by a large depth estimation\nmodel. Another challenge lies in the efficiency. Previous methods such as\nPoint-BERT and Point-MAE, employ k nearest neighbors to embed 3D tokens,\nrequiring quadratic time complexity. To efficiently pre-train on such a large\namount of data, we propose a linear-time-complexity token embedding strategy\nand a training-efficient 2D reconstruction target. Our method achieves\nstate-of-the-art performance in 3D classification and few-shot learning while\nmaintaining high pre-training and downstream fine-tuning efficiency.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/"}