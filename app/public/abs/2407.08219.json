{"id":"2407.08219","title":"Generating Contextually-Relevant Navigation Instructions for Blind and\n  Low Vision People","authors":"Zain Merchant, Abrar Anwar, Emily Wang, Souti Chattopadhyay, Jesse\n  Thomason","authorsParsed":[["Merchant","Zain",""],["Anwar","Abrar",""],["Wang","Emily",""],["Chattopadhyay","Souti",""],["Thomason","Jesse",""]],"versions":[{"version":"v1","created":"Thu, 11 Jul 2024 06:40:36 GMT"}],"updateDate":"2024-07-12","timestamp":1720680036000,"abstract":"  Navigating unfamiliar environments presents significant challenges for blind\nand low-vision (BLV) individuals. In this work, we construct a dataset of\nimages and goals across different scenarios such as searching through kitchens\nor navigating outdoors. We then investigate how grounded instruction generation\nmethods can provide contextually-relevant navigational guidance to users in\nthese instances. Through a sighted user study, we demonstrate that large\npretrained language models can produce correct and useful instructions\nperceived as beneficial for BLV users. We also conduct a survey and interview\nwith 4 BLV users and observe useful insights on preferences for different\ninstructions based on the scenario.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Human-Computer Interaction"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}