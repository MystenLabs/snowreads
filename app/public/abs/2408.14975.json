{"id":"2408.14975","title":"MegActor-$\\Sigma$: Unlocking Flexible Mixed-Modal Control in Portrait\n  Animation with Diffusion Transformer","authors":"Shurong Yang, Huadong Li, Juhao Wu, Minhao Jing, Linze Li, Renhe Ji,\n  Jiajun Liang, Haoqiang Fan, Jin Wang","authorsParsed":[["Yang","Shurong",""],["Li","Huadong",""],["Wu","Juhao",""],["Jing","Minhao",""],["Li","Linze",""],["Ji","Renhe",""],["Liang","Jiajun",""],["Fan","Haoqiang",""],["Wang","Jin",""]],"versions":[{"version":"v1","created":"Tue, 27 Aug 2024 11:31:47 GMT"}],"updateDate":"2024-08-28","timestamp":1724758307000,"abstract":"  Diffusion models have demonstrated superior performance in the field of\nportrait animation. However, current approaches relied on either visual or\naudio modality to control character movements, failing to exploit the potential\nof mixed-modal control. This challenge arises from the difficulty in balancing\nthe weak control strength of audio modality and the strong control strength of\nvisual modality. To address this issue, we introduce MegActor-$\\Sigma$: a\nmixed-modal conditional diffusion transformer (DiT), which can flexibly inject\naudio and visual modality control signals into portrait animation.\nSpecifically, we make substantial advancements over its predecessor, MegActor,\nby leveraging the promising model structure of DiT and integrating audio and\nvisual conditions through advanced modules within the DiT framework. To further\nachieve flexible combinations of mixed-modal control signals, we propose a\n``Modality Decoupling Control\" training strategy to balance the control\nstrength between visual and audio modalities, along with the ``Amplitude\nAdjustment\" inference strategy to freely regulate the motion amplitude of each\nmodality. Finally, to facilitate extensive studies in this field, we design\nseveral dataset evaluation metrics to filter out public datasets and solely use\nthis filtered dataset to train MegActor-$\\Sigma$. Extensive experiments\ndemonstrate the superiority of our approach in generating vivid portrait\nanimations, outperforming previous methods trained on private dataset.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}