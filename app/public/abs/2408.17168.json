{"id":"2408.17168","title":"EMHI: A Multimodal Egocentric Human Motion Dataset with HMD and\n  Body-Worn IMUs","authors":"Zhen Fan, Peng Dai, Zhuo Su, Xu Gao, Zheng Lv, Jiarui Zhang, Tianyuan\n  Du, Guidong Wang, Yang Zhang","authorsParsed":[["Fan","Zhen",""],["Dai","Peng",""],["Su","Zhuo",""],["Gao","Xu",""],["Lv","Zheng",""],["Zhang","Jiarui",""],["Du","Tianyuan",""],["Wang","Guidong",""],["Zhang","Yang",""]],"versions":[{"version":"v1","created":"Fri, 30 Aug 2024 10:12:13 GMT"}],"updateDate":"2024-09-02","timestamp":1725012733000,"abstract":"  Egocentric human pose estimation (HPE) using wearable sensors is essential\nfor VR/AR applications. Most methods rely solely on either egocentric-view\nimages or sparse Inertial Measurement Unit (IMU) signals, leading to\ninaccuracies due to self-occlusion in images or the sparseness and drift of\ninertial sensors. Most importantly, the lack of real-world datasets containing\nboth modalities is a major obstacle to progress in this field. To overcome the\nbarrier, we propose EMHI, a multimodal \\textbf{E}gocentric human\n\\textbf{M}otion dataset with \\textbf{H}ead-Mounted Display (HMD) and body-worn\n\\textbf{I}MUs, with all data collected under the real VR product suite.\nSpecifically, EMHI provides synchronized stereo images from downward-sloping\ncameras on the headset and IMU data from body-worn sensors, along with pose\nannotations in SMPL format. This dataset consists of 885 sequences captured by\n58 subjects performing 39 actions, totaling about 28.5 hours of recording. We\nevaluate the annotations by comparing them with optical marker-based SMPL\nfitting results. To substantiate the reliability of our dataset, we introduce\nMEPoser, a new baseline method for multimodal egocentric HPE, which employs a\nmultimodal fusion encoder, temporal feature encoder, and MLP-based regression\nheads. The experiments on EMHI show that MEPoser outperforms existing\nsingle-modal methods and demonstrates the value of our dataset in solving the\nproblem of egocentric HPE. We believe the release of EMHI and the method could\nadvance the research of egocentric HPE and expedite the practical\nimplementation of this technology in VR/AR products.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}