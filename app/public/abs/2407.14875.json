{"id":"2407.14875","title":"Seal: Advancing Speech Language Models to be Few-Shot Learners","authors":"Shuyu Lei, Lingen Liu, Jiaolong Yang, Yasen Jiao, Yuxiang Yang, Yushu\n  Yang and Xiang Guo","authorsParsed":[["Lei","Shuyu",""],["Liu","Lingen",""],["Yang","Jiaolong",""],["Jiao","Yasen",""],["Yang","Yuxiang",""],["Yang","Yushu",""],["Guo","Xiang",""]],"versions":[{"version":"v1","created":"Sat, 20 Jul 2024 13:28:12 GMT"}],"updateDate":"2024-07-23","timestamp":1721482092000,"abstract":"  Existing auto-regressive language models have demonstrated a remarkable\ncapability to perform a new task with just a few examples in prompt, without\nrequiring any additional training. In order to extend this capability to a\nmulti-modal setting (i.e. speech and language), this paper introduces the Seal\nmodel, an abbreviation for speech language model. It incorporates a novel\nalignment method, in which Kullback-Leibler divergence loss is performed to\ntrain a projector that bridges a frozen speech encoder with a frozen language\nmodel decoder. The resulting Seal model exhibits robust performance as a\nfew-shot learner on two speech understanding tasks. Additionally, consistency\nexperiments are conducted to validate its robustness on different pre-trained\nlanguage models.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}