{"id":"2408.14558","title":"A sparsity-aware distributed-memory algorithm for sparse-sparse matrix\n  multiplication","authors":"Yuxi Hong and Aydin Buluc","authorsParsed":[["Hong","Yuxi",""],["Buluc","Aydin",""]],"versions":[{"version":"v1","created":"Mon, 26 Aug 2024 18:18:13 GMT"}],"updateDate":"2024-08-28","timestamp":1724696293000,"abstract":"  Multiplying two sparse matrices (SpGEMM) is a common computational primitive\nused in many areas including graph algorithms, bioinformatics, algebraic\nmultigrid solvers, and randomized sketching. Distributed-memory parallel\nalgorithms for SpGEMM have mainly focused on sparsity-oblivious approaches that\nuse 2D and 3D partitioning. Sparsity-aware 1D algorithms can theoretically\nreduce communication by not fetching nonzeros of the sparse matrices that do\nnot participate in the multiplication.\n  Here, we present a distributed-memory 1D SpGEMM algorithm and implementation.\nIt uses MPI RDMA operations to mitigate the cost of packing/unpacking\nsubmatrices for communication, and it uses a block fetching strategy to avoid\nexcessive fine-grained messaging. Our results show that our 1D implementation\noutperforms state-of-the-art 2D and 3D implementations within CombBLAS for many\nconfigurations, inputs, and use cases, while remaining conceptually simpler.\n","subjects":["Computing Research Repository/Distributed, Parallel, and Cluster Computing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}