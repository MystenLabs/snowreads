{"id":"2407.01702","title":"SeFlow: A Self-Supervised Scene Flow Method in Autonomous Driving","authors":"Qingwen Zhang and Yi Yang and Peizheng Li and Olov Andersson and\n  Patric Jensfelt","authorsParsed":[["Zhang","Qingwen",""],["Yang","Yi",""],["Li","Peizheng",""],["Andersson","Olov",""],["Jensfelt","Patric",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 18:22:54 GMT"},{"version":"v2","created":"Tue, 17 Sep 2024 15:47:53 GMT"}],"updateDate":"2024-09-18","timestamp":1719858174000,"abstract":"  Scene flow estimation predicts the 3D motion at each point in successive\nLiDAR scans. This detailed, point-level, information can help autonomous\nvehicles to accurately predict and understand dynamic changes in their\nsurroundings. Current state-of-the-art methods require annotated data to train\nscene flow networks and the expense of labeling inherently limits their\nscalability. Self-supervised approaches can overcome the above limitations, yet\nface two principal challenges that hinder optimal performance: point\ndistribution imbalance and disregard for object-level motion constraints. In\nthis paper, we propose SeFlow, a self-supervised method that integrates\nefficient dynamic classification into a learning-based scene flow pipeline. We\ndemonstrate that classifying static and dynamic points helps design targeted\nobjective functions for different motion patterns. We also emphasize the\nimportance of internal cluster consistency and correct object point association\nto refine the scene flow estimation, in particular on object details. Our\nreal-time capable method achieves state-of-the-art performance on the\nself-supervised scene flow task on Argoverse 2 and Waymo datasets. The code is\nopen-sourced at https://github.com/KTH-RPL/SeFlow along with trained model\nweights.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Robotics"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/"}