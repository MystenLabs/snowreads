{"id":"2407.17482","title":"Reinforcement Learning from Human Feedback: Whose Culture, Whose Values,\n  Whose Perspectives?","authors":"Kristian Gonz\\'alez Barman, Simon Lohse, and Henk de Regt","authorsParsed":[["Barman","Kristian Gonz√°lez",""],["Lohse","Simon",""],["de Regt","Henk",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 08:07:27 GMT"}],"updateDate":"2024-07-26","timestamp":1719907647000,"abstract":"  We argue for the epistemic and ethical advantages of pluralism in\nReinforcement Learning from Human Feedback (RLHF) in the context of Large\nLanguage Models (LLM). Drawing on social epistemology and pluralist philosophy\nof science, we suggest ways in which RHLF can be made more responsive to human\nneeds and how we can address challenges along the way. The paper concludes with\nan agenda for change, i.e. concrete, actionable steps to improve LLM\ndevelopment.\n","subjects":["Computing Research Repository/Computers and Society","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language","Computing Research Repository/Human-Computer Interaction"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"1DRRyE_4cVVNB-2Infx8h1sVJRtIBnjBFII0PWLFzu0","pdfSize":"427514"}
