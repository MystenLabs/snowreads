{"id":"2408.03504","title":"Sample Complexity of Low-rank Tensor Recovery from Uniformly Random\n  Entries","authors":"Hiroki Hamaguchi and Shin-ichi Tanigawa","authorsParsed":[["Hamaguchi","Hiroki",""],["Tanigawa","Shin-ichi",""]],"versions":[{"version":"v1","created":"Wed, 7 Aug 2024 02:07:14 GMT"}],"updateDate":"2024-08-08","timestamp":1722996434000,"abstract":"  We show that a generic tensor $T\\in \\mathbb{F}^{n\\times n\\times \\dots\\times\nn}$ of order $k$ and CP rank $d$ can be uniquely recovered from $n\\log n+dn\\log\n\\log n +o(n\\log \\log n) $ uniformly random entries with high probability if $d$\nand $k$ are constant and $\\mathbb{F}\\in \\{\\mathbb{R},\\mathbb{C}\\}$. The bound\nis tight up to the coefficient of the second leading term and improves on the\nexisting $O(n^{\\frac{k}{2}}{\\rm polylog}(n))$ upper bound for order $k$\ntensors. The bound is obtained by showing that the projection of the Segre\nvariety to a random axis-parallel linear subspace preserves $d$-identifiability\nwith high probability if the dimension of the subspace is $n\\log n+dn\\log \\log\nn +o(n\\log \\log n) $ and $n$ is sufficiently large.\n","subjects":["Mathematics/Combinatorics","Computing Research Repository/Information Theory","Mathematics/Algebraic Geometry","Mathematics/Information Theory","Mathematics/Probability"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}