{"id":"2407.15831","title":"NV-Retriever: Improving text embedding models with effective\n  hard-negative mining","authors":"Gabriel de Souza P. Moreira, Radek Osmulski, Mengyao Xu, Ronay Ak,\n  Benedikt Schifferer, Even Oldridge","authorsParsed":[["Moreira","Gabriel de Souza P.",""],["Osmulski","Radek",""],["Xu","Mengyao",""],["Ak","Ronay",""],["Schifferer","Benedikt",""],["Oldridge","Even",""]],"versions":[{"version":"v1","created":"Mon, 22 Jul 2024 17:50:31 GMT"}],"updateDate":"2024-07-23","timestamp":1721670631000,"abstract":"  Text embedding models have been popular for information retrieval\napplications such as semantic search and Question-Answering systems based on\nRetrieval-Augmented Generation (RAG). Those models are typically Transformer\nmodels that are fine-tuned with contrastive learning objectives. Many papers\nintroduced new embedding model architectures and training approaches, however,\none of the key ingredients, the process of mining negative passages, remains\npoorly explored or described. One of the challenging aspects of fine-tuning\nembedding models is the selection of high quality hard-negative passages for\ncontrastive learning. In this paper we propose a family of positive-aware\nmining methods that leverage the positive relevance score for more effective\nfalse negatives removal. We also provide a comprehensive ablation study on\nhard-negative mining methods over their configurations, exploring different\nteacher and base models. We demonstrate the efficacy of our proposed methods by\nintroducing the NV-Retriever-v1 model, which scores 60.9 on MTEB Retrieval\n(BEIR) benchmark and 0.65 points higher than previous methods. The model placed\n1st when it was published to MTEB Retrieval on July 07, 2024.\n","subjects":["Computing Research Repository/Information Retrieval","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"L2NVRGCoQ-5b9vnKv5DWBd3pw8Y2R4T7BYL9EITXFFc","pdfSize":"1173687"}
