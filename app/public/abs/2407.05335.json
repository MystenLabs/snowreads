{"id":"2407.05335","title":"Understanding and Addressing Gender Bias in Expert Finding Task","authors":"Maddalena Amendola, Carlos Castillo, Andrea Passarella, Raffaele\n  Perego","authorsParsed":[["Amendola","Maddalena",""],["Castillo","Carlos",""],["Passarella","Andrea",""],["Perego","Raffaele",""]],"versions":[{"version":"v1","created":"Sun, 7 Jul 2024 11:35:23 GMT"}],"updateDate":"2024-07-09","timestamp":1720352123000,"abstract":"  The Expert Finding (EF) task is critical in community Question&Answer (CQ&A)\nplatforms, significantly enhancing user engagement by improving answer quality\nand reducing response times. However, biases, especially gender biases, have\nbeen identified in these platforms. This study investigates gender bias in\nstate-of-the-art EF models and explores methods to mitigate it. Utilizing a\ncomprehensive dataset from StackOverflow, the largest community in the\nStackExchange network, we conduct extensive experiments to analyze how EF\nmodels' candidate identification processes influence gender representation. Our\nfindings reveal that models relying on reputation metrics and activity levels\ndisproportionately favor male users, who are more active on the platform. This\nbias results in the underrepresentation of female experts in the ranking\nprocess. We propose adjustments to EF models that incorporate a more balanced\npreprocessing strategy and leverage content-based and social network-based\ninformation, with the aim to provide a fairer representation of genders among\nidentified experts. Our analysis shows that integrating these methods can\nsignificantly enhance gender balance without compromising model accuracy. To\nthe best of our knowledge, this study is the first to focus on detecting and\nmitigating gender bias in EF methods.\n","subjects":["Computing Research Repository/Information Retrieval"],"license":"http://creativecommons.org/licenses/by/4.0/"}