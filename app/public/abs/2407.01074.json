{"id":"2407.01074","title":"Multimodal Conditional 3D Face Geometry Generation","authors":"Christopher Otto, Prashanth Chandran, Sebastian Weiss, Markus Gross,\n  Gaspard Zoss, Derek Bradley","authorsParsed":[["Otto","Christopher",""],["Chandran","Prashanth",""],["Weiss","Sebastian",""],["Gross","Markus",""],["Zoss","Gaspard",""],["Bradley","Derek",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 08:25:59 GMT"}],"updateDate":"2024-07-02","timestamp":1719822359000,"abstract":"  We present a new method for multimodal conditional 3D face geometry\ngeneration that allows user-friendly control over the output identity and\nexpression via a number of different conditioning signals. Within a single\nmodel, we demonstrate 3D faces generated from artistic sketches, 2D face\nlandmarks, Canny edges, FLAME face model parameters, portrait photos, or text\nprompts. Our approach is based on a diffusion process that generates 3D\ngeometry in a 2D parameterized UV domain. Geometry generation passes each\nconditioning signal through a set of cross-attention layers (IP-Adapter), one\nset for each user-defined conditioning signal. The result is an easy-to-use 3D\nface generation tool that produces high resolution geometry with fine-grain\nuser control.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Graphics"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}