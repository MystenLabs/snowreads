{"id":"2408.06080","title":"Sequential sampling without comparison to boundary through model-free\n  reinforcement learning","authors":"Jamal Esmaily, Rani Moran, Yasser Roudi, and Bahador Bahrami","authorsParsed":[["Esmaily","Jamal",""],["Moran","Rani",""],["Roudi","Yasser",""],["Bahrami","Bahador",""]],"versions":[{"version":"v1","created":"Mon, 12 Aug 2024 11:56:39 GMT"}],"updateDate":"2024-08-13","timestamp":1723463799000,"abstract":"  Although evidence integration to the boundary model has successfully\nexplained a wide range of behavioral and neural data in decision making under\nuncertainty, how animals learn and optimize the boundary remains unresolved.\nHere, we propose a model-free reinforcement learning algorithm for perceptual\ndecisions under uncertainty that dispenses entirely with the concepts of\ndecision boundary and evidence accumulation. Our model learns whether to commit\nto a decision given the available evidence or continue sampling information at\na cost. We reproduced the canonical features of perceptual decision-making such\nas dependence of accuracy and reaction time on evidence strength, modulation of\nspeed-accuracy trade-off by payoff regime, and many others. By unifying\nlearning and decision making within the same framework, this model can account\nfor unstable behavior during training as well as stabilized post-training\nbehavior, opening the door to revisiting the extensive volumes of discarded\ntraining data in the decision science literature.\n","subjects":["Computing Research Repository/Neural and Evolutionary Computing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}