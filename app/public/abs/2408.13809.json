{"id":"2408.13809","title":"On the Robustness of Kolmogorov-Arnold Networks: An Adversarial\n  Perspective","authors":"Tal Alter, Raz Lapid and Moshe Sipper","authorsParsed":[["Alter","Tal",""],["Lapid","Raz",""],["Sipper","Moshe",""]],"versions":[{"version":"v1","created":"Sun, 25 Aug 2024 11:10:15 GMT"}],"updateDate":"2024-08-27","timestamp":1724584215000,"abstract":"  Kolmogorov-Arnold Networks (KANs) have recently emerged as a novel approach\nto function approximation, demonstrating remarkable potential in various\ndomains. Despite their theoretical promise, the robustness of KANs under\nadversarial conditions has yet to be thoroughly examined. In this paper, we\nexplore the adversarial robustness of KANs, with a particular focus on image\nclassification tasks. We assess the performance of KANs against standard\nwhite-box adversarial attacks, comparing their resilience to that of\nestablished neural network architectures. Further, we investigate the\ntransferability of adversarial examples between KANs and Multilayer Perceptron\n(MLPs), deriving critical insights into the unique vulnerabilities of KANs. Our\nexperiments use the MNIST, FashionMNIST, and KMNIST datasets, providing a\ncomprehensive evaluation of KANs in adversarial scenarios. This work offers the\nfirst in-depth analysis of security in KANs, laying the groundwork for future\nresearch in this emerging field.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Cryptography and Security"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}