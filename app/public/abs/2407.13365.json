{"id":"2407.13365","title":"Generative AI and the problem of existential risk","authors":"Lynette Webb and Daniel Sch\\\"onberger","authorsParsed":[["Webb","Lynette",""],["Sch√∂nberger","Daniel",""]],"versions":[{"version":"v1","created":"Thu, 18 Jul 2024 10:16:24 GMT"}],"updateDate":"2024-07-19","timestamp":1721297784000,"abstract":"  Ever since the launch of ChatGPT, Generative AI has been a focal point for\nconcerns about AI's perceived existential risk. Once a niche topic in AI\nresearch and philosophy, AI safety and existential risk has now entered\nmainstream debate among policy makers and leading foundation models developers,\nmuch to the chagrin of those who see it as a distraction from addressing more\npressing nearer-term harms. This chapter aims to demystify the debate by\nhighlighting the key worries that underpin existential risk fears in relation\nto generative AI, and spotlighting the key actions that governments and\nindustry are taking thus far to helping address them.\n","subjects":["Computing Research Repository/Computers and Society"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/"}