{"id":"2407.08940","title":"Large Language Models as Biomedical Hypothesis Generators: A\n  Comprehensive Evaluation","authors":"Biqing Qi, Kaiyan Zhang, Kai Tian, Haoxiang Li, Zhang-Ren Chen, Sihang\n  Zeng, Ermo Hua, Hu Jinfang, Bowen Zhou","authorsParsed":[["Qi","Biqing",""],["Zhang","Kaiyan",""],["Tian","Kai",""],["Li","Haoxiang",""],["Chen","Zhang-Ren",""],["Zeng","Sihang",""],["Hua","Ermo",""],["Jinfang","Hu",""],["Zhou","Bowen",""]],"versions":[{"version":"v1","created":"Fri, 12 Jul 2024 02:55:13 GMT"},{"version":"v2","created":"Mon, 15 Jul 2024 06:27:07 GMT"}],"updateDate":"2024-07-16","timestamp":1720752913000,"abstract":"  The rapid growth of biomedical knowledge has outpaced our ability to\nefficiently extract insights and generate novel hypotheses. Large language\nmodels (LLMs) have emerged as a promising tool to revolutionize knowledge\ninteraction and potentially accelerate biomedical discovery. In this paper, we\npresent a comprehensive evaluation of LLMs as biomedical hypothesis generators.\nWe construct a dataset of background-hypothesis pairs from biomedical\nliterature, carefully partitioned into training, seen, and unseen test sets\nbased on publication date to mitigate data contamination. Using this dataset,\nwe assess the hypothesis generation capabilities of top-tier instructed models\nin zero-shot, few-shot, and fine-tuning settings. To enhance the exploration of\nuncertainty, a crucial aspect of scientific discovery, we incorporate tool use\nand multi-agent interactions in our evaluation framework. Furthermore, we\npropose four novel metrics grounded in extensive literature review to evaluate\nthe quality of generated hypotheses, considering both LLM-based and human\nassessments. Our experiments yield two key findings: 1) LLMs can generate novel\nand validated hypotheses, even when tested on literature unseen during\ntraining, and 2) Increasing uncertainty through multi-agent interactions and\ntool use can facilitate diverse candidate generation and improve zero-shot\nhypothesis generation performance. However, we also observe that the\nintegration of additional knowledge through few-shot learning and tool use may\nnot always lead to performance gains, highlighting the need for careful\nconsideration of the type and scope of external knowledge incorporated. These\nfindings underscore the potential of LLMs as powerful aids in biomedical\nhypothesis generation and provide valuable insights to guide further research\nin this area.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"qwpqPaYlB2J0RgMFsRyscun3I82caDoVCSLkamPL-lk","pdfSize":"3628797"}
