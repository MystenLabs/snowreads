{"id":"2407.00608","title":"Efficient Personalized Text-to-image Generation by Leveraging Textual\n  Subspace","authors":"Shian Du, Xiaotian Cheng, Qi Qian, Henglu Wei, Yi Xu, Xiangyang Ji","authorsParsed":[["Du","Shian",""],["Cheng","Xiaotian",""],["Qian","Qi",""],["Wei","Henglu",""],["Xu","Yi",""],["Ji","Xiangyang",""]],"versions":[{"version":"v1","created":"Sun, 30 Jun 2024 06:41:21 GMT"}],"updateDate":"2024-07-02","timestamp":1719729681000,"abstract":"  Personalized text-to-image generation has attracted unprecedented attention\nin the recent few years due to its unique capability of generating\nhighly-personalized images via using the input concept dataset and novel\ntextual prompt. However, previous methods solely focus on the performance of\nthe reconstruction task, degrading its ability to combine with different\ntextual prompt. Besides, optimizing in the high-dimensional embedding space\nusually leads to unnecessary time-consuming training process and slow\nconvergence. To address these issues, we propose an efficient method to explore\nthe target embedding in a textual subspace, drawing inspiration from the\nself-expressiveness property. Additionally, we propose an efficient selection\nstrategy for determining the basis vectors of the textual subspace. The\nexperimental evaluations demonstrate that the learned embedding can not only\nfaithfully reconstruct input image, but also significantly improves its\nalignment with novel input textual prompt. Furthermore, we observe that\noptimizing in the textual subspace leads to an significant improvement of the\nrobustness to the initial word, relaxing the constraint that requires users to\ninput the most relevant initial word. Our method opens the door to more\nefficient representation learning for personalized text-to-image generation.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}