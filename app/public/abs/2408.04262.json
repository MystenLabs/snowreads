{"id":"2408.04262","title":"CoBooM: Codebook Guided Bootstrapping for Medical Image Representation\n  Learning","authors":"Azad Singh and Deepak Mishra","authorsParsed":[["Singh","Azad",""],["Mishra","Deepak",""]],"versions":[{"version":"v1","created":"Thu, 8 Aug 2024 06:59:32 GMT"}],"updateDate":"2024-08-09","timestamp":1723100372000,"abstract":"  Self-supervised learning (SSL) has emerged as a promising paradigm for\nmedical image analysis by harnessing unannotated data. Despite their potential,\nthe existing SSL approaches overlook the high anatomical similarity inherent in\nmedical images. This makes it challenging for SSL methods to capture diverse\nsemantic content in medical images consistently. This work introduces a novel\nand generalized solution that implicitly exploits anatomical similarities by\nintegrating codebooks in SSL. The codebook serves as a concise and informative\ndictionary of visual patterns, which not only aids in capturing nuanced\nanatomical details but also facilitates the creation of robust and generalized\nfeature representations. In this context, we propose CoBooM, a novel framework\nfor self-supervised medical image learning by integrating continuous and\ndiscrete representations. The continuous component ensures the preservation of\nfine-grained details, while the discrete aspect facilitates coarse-grained\nfeature extraction through the structured embedding space. To understand the\neffectiveness of CoBooM, we conduct a comprehensive evaluation of various\nmedical datasets encompassing chest X-rays and fundus images. The experimental\nresults reveal a significant performance gain in classification and\nsegmentation tasks.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/"}