{"id":"2407.18786","title":"The power of Prompts: Evaluating and Mitigating Gender Bias in MT with\n  LLMs","authors":"Aleix Sant, Carlos Escolano, Audrey Mash, Francesca De Luca\n  Fornaciari, Maite Melero","authorsParsed":[["Sant","Aleix",""],["Escolano","Carlos",""],["Mash","Audrey",""],["Fornaciari","Francesca De Luca",""],["Melero","Maite",""]],"versions":[{"version":"v1","created":"Fri, 26 Jul 2024 14:47:31 GMT"}],"updateDate":"2024-07-29","timestamp":1722005251000,"abstract":"  This paper studies gender bias in machine translation through the lens of\nLarge Language Models (LLMs). Four widely-used test sets are employed to\nbenchmark various base LLMs, comparing their translation quality and gender\nbias against state-of-the-art Neural Machine Translation (NMT) models for\nEnglish to Catalan (En $\\rightarrow$ Ca) and English to Spanish (En\n$\\rightarrow$ Es) translation directions. Our findings reveal pervasive gender\nbias across all models, with base LLMs exhibiting a higher degree of bias\ncompared to NMT models. To combat this bias, we explore prompting engineering\ntechniques applied to an instruction-tuned LLM. We identify a prompt structure\nthat significantly reduces gender bias by up to 12% on the WinoMT evaluation\ndataset compared to more straightforward prompts. These results significantly\nreduce the gender bias accuracy gap between LLMs and traditional NMT systems.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/"}