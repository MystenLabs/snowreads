{"id":"2407.13996","title":"Missile: Fine-Grained, Hardware-Level GPU Resource Isolation for\n  Multi-Tenant DNN Inference","authors":"Yongkang Zhang, Haoxuan Yu, Chenxia Han, Cheng Wang, Baotong Lu, Yang\n  Li, Xiaowen Chu, Huaicheng Li","authorsParsed":[["Zhang","Yongkang",""],["Yu","Haoxuan",""],["Han","Chenxia",""],["Wang","Cheng",""],["Lu","Baotong",""],["Li","Yang",""],["Chu","Xiaowen",""],["Li","Huaicheng",""]],"versions":[{"version":"v1","created":"Fri, 19 Jul 2024 03:01:32 GMT"},{"version":"v2","created":"Sat, 27 Jul 2024 08:52:39 GMT"}],"updateDate":"2024-07-30","timestamp":1721358092000,"abstract":"  Colocating high-priority, latency-sensitive (LS) and low-priority,\nbest-effort (BE) DNN inference services reduces the total cost of ownership\n(TCO) of GPU clusters. Limited by bottlenecks such as VRAM channel conflicts\nand PCIe bus contentions, existing GPU sharing solutions are unable to avoid\nresource conflicts among concurrently executing tasks, failing to achieve both\nlow latency for LS tasks and high throughput for BE tasks. To bridge this gap,\nthis paper presents Missile, a general GPU sharing solution for multi-tenant\nDNN inference on NVIDIA GPUs. Missile approximates fine-grained GPU hardware\nresource isolation between multiple LS and BE DNN tasks at software level.\nThrough comprehensive reverse engineering, Missile first reveals a general VRAM\nchannel hash mapping architecture of NVIDIA GPUs and eliminates VRAM channel\nconflicts using software-level cache coloring. It also isolates the PCIe bus\nand fairly allocates PCIe bandwidth using completely fair scheduler. We\nevaluate 12 mainstream DNNs with synthetic and real-world workloads on four\nGPUs. The results show that compared to the state-of-the-art GPU sharing\nsolutions, Missile reduces tail latency for LS services by up to ~50%, achieves\nup to 6.1x BE job throughput, and allocates PCIe bus bandwidth to tenants\non-demand for optimal performance.\n","subjects":["Computing Research Repository/Distributed, Parallel, and Cluster Computing","Computing Research Repository/Hardware Architecture","Computing Research Repository/Performance"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}