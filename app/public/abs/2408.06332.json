{"id":"2408.06332","title":"Animate, or Inanimate, That is the Question for Large Language Models","authors":"Leonardo Ranaldi, Giulia Pucci, Fabio Massimo Zanzotto","authorsParsed":[["Ranaldi","Leonardo",""],["Pucci","Giulia",""],["Zanzotto","Fabio Massimo",""]],"versions":[{"version":"v1","created":"Mon, 12 Aug 2024 17:48:55 GMT"}],"updateDate":"2024-08-13","timestamp":1723484935000,"abstract":"  The cognitive essence of humans is deeply intertwined with the concept of\nanimacy, which plays an essential role in shaping their memory, vision, and\nmulti-layered language understanding. Although animacy appears in language via\nnuanced constraints on verbs and adjectives, it is also learned and refined\nthrough extralinguistic information. Similarly, we assume that the LLMs'\nlimited abilities to understand natural language when processing animacy are\nmotivated by the fact that these models are trained exclusively on text.\n  Hence, the question this paper aims to answer arises: can LLMs, in their\ndigital wisdom, process animacy in a similar way to what humans would do? We\nthen propose a systematic analysis via prompting approaches. In particular, we\nprobe different LLMs by prompting them using animate, inanimate, usual, and\nstranger contexts. Results reveal that, although LLMs have been trained\npredominantly on textual data, they exhibit human-like behavior when faced with\ntypical animate and inanimate entities in alignment with earlier studies.\nHence, LLMs can adapt to understand unconventional situations by recognizing\noddities as animated without needing to interface with unspoken cognitive\ntriggers humans rely on to break down animations.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"TYi0nwhA2DufJ4YomyAlWr-36e9QUAVeWQSkCgaeUXU","pdfSize":"675832"}
