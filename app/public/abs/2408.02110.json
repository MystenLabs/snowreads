{"id":"2408.02110","title":"AvatarPose: Avatar-guided 3D Pose Estimation of Close Human Interaction\n  from Sparse Multi-view Videos","authors":"Feichi Lu, Zijian Dong, Jie Song, and Otmar Hilliges","authorsParsed":[["Lu","Feichi",""],["Dong","Zijian",""],["Song","Jie",""],["Hilliges","Otmar",""]],"versions":[{"version":"v1","created":"Sun, 4 Aug 2024 18:41:35 GMT"},{"version":"v2","created":"Tue, 20 Aug 2024 07:19:58 GMT"}],"updateDate":"2024-08-21","timestamp":1722796895000,"abstract":"  Despite progress in human motion capture, existing multi-view methods often\nface challenges in estimating the 3D pose and shape of multiple closely\ninteracting people. This difficulty arises from reliance on accurate 2D joint\nestimations, which are hard to obtain due to occlusions and body contact when\npeople are in close interaction. To address this, we propose a novel method\nleveraging the personalized implicit neural avatar of each individual as a\nprior, which significantly improves the robustness and precision of this\nchallenging pose estimation task. Concretely, the avatars are efficiently\nreconstructed via layered volume rendering from sparse multi-view videos. The\nreconstructed avatar prior allows for the direct optimization of 3D poses based\non color and silhouette rendering loss, bypassing the issues associated with\nnoisy 2D detections. To handle interpenetration, we propose a collision loss on\nthe overlapping shape regions of avatars to add penetration constraints.\nMoreover, both 3D poses and avatars are optimized in an alternating manner. Our\nexperimental results demonstrate state-of-the-art performance on several public\ndatasets.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}