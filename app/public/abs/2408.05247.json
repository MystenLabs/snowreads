{"id":"2408.05247","title":"Early-Exit meets Model-Distributed Inference at Edge Networks","authors":"Marco Colocrese, Erdem Koyuncu, Hulya Seferoglu","authorsParsed":[["Colocrese","Marco",""],["Koyuncu","Erdem",""],["Seferoglu","Hulya",""]],"versions":[{"version":"v1","created":"Thu, 8 Aug 2024 11:53:32 GMT"}],"updateDate":"2024-08-13","timestamp":1723118012000,"abstract":"  Distributed inference techniques can be broadly classified into\ndata-distributed and model-distributed schemes. In data-distributed inference\n(DDI), each worker carries the entire deep neural network (DNN) model but\nprocesses only a subset of the data. However, feeding the data to workers\nresults in high communication costs, especially when the data is large. An\nemerging paradigm is model-distributed inference (MDI), where each worker\ncarries only a subset of DNN layers. In MDI, a source device that has data\nprocesses a few layers of DNN and sends the output to a neighboring device,\ni.e., offloads the rest of the layers. This process ends when all layers are\nprocessed in a distributed manner. In this paper, we investigate the design and\ndevelopment of MDI with early-exit, which advocates that there is no need to\nprocess all the layers of a model for some data to reach the desired accuracy,\ni.e., we can exit the model without processing all the layers if target\naccuracy is reached. We design a framework MDI-Exit that adaptively determines\nearly-exit and offloading policies as well as data admission at the source.\nExperimental results on a real-life testbed of NVIDIA Nano edge devices show\nthat MDI-Exit processes more data when accuracy is fixed and results in higher\naccuracy for the fixed data rate.\n","subjects":["Computing Research Repository/Distributed, Parallel, and Cluster Computing","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning","Computing Research Repository/Networking and Internet Architecture"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"CGDkrymVU0JKMw6ZLdW4zhpkACImaYdSBACzNImh1cI","pdfSize":"1176734"}
