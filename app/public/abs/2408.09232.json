{"id":"2408.09232","title":"Intuitive Human-Robot Interface: A 3-Dimensional Action Recognition and\n  UAV Collaboration Framework","authors":"Akash Chaudhary, Tiago Nascimento, Martin Saska","authorsParsed":[["Chaudhary","Akash",""],["Nascimento","Tiago",""],["Saska","Martin",""]],"versions":[{"version":"v1","created":"Sat, 17 Aug 2024 15:46:05 GMT"}],"updateDate":"2024-08-20","timestamp":1723909565000,"abstract":"  Harnessing human movements to command an Unmanned Aerial Vehicle (UAV) holds\nthe potential to revolutionize their deployment, rendering it more intuitive\nand user-centric. In this research, we introduce a novel methodology adept at\nclassifying three-dimensional human actions, leveraging them to coordinate\non-field with a UAV. Utilizing a stereo camera, we derive both RGB and depth\ndata, subsequently extracting three-dimensional human poses from the continuous\nvideo feed. This data is then processed through our proposed k-nearest\nneighbour classifier, the results of which dictate the behaviour of the UAV. It\nalso includes mechanisms ensuring the robot perpetually maintains the human\nwithin its visual purview, adeptly tracking user movements. We subjected our\napproach to rigorous testing involving multiple tests with real robots. The\nensuing results, coupled with comprehensive analysis, underscore the efficacy\nand inherent advantages of our proposed methodology.\n","subjects":["Computing Research Repository/Robotics"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}