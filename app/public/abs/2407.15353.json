{"id":"2407.15353","title":"Customized Retrieval Augmented Generation and Benchmarking for EDA Tool\n  Documentation QA","authors":"Yuan Pu, Zhuolun He, Tairu Qiu, Haoyuan Wu, Bei Yu","authorsParsed":[["Pu","Yuan",""],["He","Zhuolun",""],["Qiu","Tairu",""],["Wu","Haoyuan",""],["Yu","Bei",""]],"versions":[{"version":"v1","created":"Mon, 22 Jul 2024 03:44:27 GMT"},{"version":"v2","created":"Fri, 26 Jul 2024 08:36:25 GMT"}],"updateDate":"2024-07-29","timestamp":1721619867000,"abstract":"  Retrieval augmented generation (RAG) enhances the accuracy and reliability of\ngenerative AI models by sourcing factual information from external databases,\nwhich is extensively employed in document-grounded question-answering (QA)\ntasks. Off-the-shelf RAG flows are well pretrained on general-purpose\ndocuments, yet they encounter significant challenges when being applied to\nknowledge-intensive vertical domains, such as electronic design automation\n(EDA). This paper addresses such issue by proposing a customized RAG framework\nalong with three domain-specific techniques for EDA tool documentation QA,\nincluding a contrastive learning scheme for text embedding model fine-tuning, a\nreranker distilled from proprietary LLM, and a generative LLM fine-tuned with\nhigh-quality domain corpus. Furthermore, we have developed and released a\ndocumentation QA evaluation benchmark, ORD-QA, for OpenROAD, an advanced\nRTL-to-GDSII design platform. Experimental results demonstrate that our\nproposed RAG flow and techniques have achieved superior performance on ORD-QA\nas well as on a commercial tool, compared with state-of-the-arts. The ORD-QA\nbenchmark and the training dataset for our customized RAG flow are open-source\nat https://github.com/lesliepy99/RAG-EDA.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Hardware Architecture"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/"}