{"id":"2408.06302","title":"Finding Patterns in Ambiguity: Interpretable Stress Testing in the\n  Decision~Boundary","authors":"In\\^es Gomes, Lu\\'is F. Teixeira, Jan N. van Rijn, Carlos Soares,\n  Andr\\'e Restivo, Lu\\'is Cunha, Mois\\'es Santos","authorsParsed":[["Gomes","Inês",""],["Teixeira","Luís F.",""],["van Rijn","Jan N.",""],["Soares","Carlos",""],["Restivo","André",""],["Cunha","Luís",""],["Santos","Moisés",""]],"versions":[{"version":"v1","created":"Mon, 12 Aug 2024 17:14:41 GMT"}],"updateDate":"2024-08-13","timestamp":1723482881000,"abstract":"  The increasing use of deep learning across various domains highlights the\nimportance of understanding the decision-making processes of these black-box\nmodels. Recent research focusing on the decision boundaries of deep\nclassifiers, relies on generated synthetic instances in areas of low\nconfidence, uncovering samples that challenge both models and humans. We\npropose a novel approach to enhance the interpretability of deep binary\nclassifiers by selecting representative samples from the decision boundary -\nprototypes - and applying post-model explanation algorithms. We evaluate the\neffectiveness of our approach through 2D visualizations and GradientSHAP\nanalysis. Our experiments demonstrate the potential of the proposed method,\nrevealing distinct and compact clusters and diverse prototypes that capture\nessential features that lead to low-confidence decisions. By offering a more\naggregated view of deep classifiers' decision boundaries, our work contributes\nto the responsible development and deployment of reliable machine learning\nsystems.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/"}