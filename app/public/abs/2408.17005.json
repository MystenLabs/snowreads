{"id":"2408.17005","title":"Efficient Camera Exposure Control for Visual Odometry via Deep\n  Reinforcement Learning","authors":"Shuyang Zhang, Jinhao He, Yilong Zhu, Jin Wu, and Jie Yuan","authorsParsed":[["Zhang","Shuyang",""],["He","Jinhao",""],["Zhu","Yilong",""],["Wu","Jin",""],["Yuan","Jie",""]],"versions":[{"version":"v1","created":"Fri, 30 Aug 2024 04:37:52 GMT"}],"updateDate":"2024-09-02","timestamp":1724992672000,"abstract":"  The stability of visual odometry (VO) systems is undermined by degraded image\nquality, especially in environments with significant illumination changes. This\nstudy employs a deep reinforcement learning (DRL) framework to train agents for\nexposure control, aiming to enhance imaging performance in challenging\nconditions. A lightweight image simulator is developed to facilitate the\ntraining process, enabling the diversification of image exposure and sequence\ntrajectory. This setup enables completely offline training, eliminating the\nneed for direct interaction with camera hardware and the real environments.\nDifferent levels of reward functions are crafted to enhance the VO systems,\nequipping the DRL agents with varying intelligence. Extensive experiments have\nshown that our exposure control agents achieve superior efficiency-with an\naverage inference duration of 1.58 ms per frame on a CPU-and respond more\nquickly than traditional feedback control schemes. By choosing an appropriate\nreward function, agents acquire an intelligent understanding of motion trends\nand anticipate future illumination changes. This predictive capability allows\nVO systems to deliver more stable and precise odometry results. The codes and\ndatasets are available at https://github.com/ShuyangUni/drl_exposure_ctrl.\n","subjects":["Computing Research Repository/Robotics","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}