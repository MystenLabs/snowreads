{"id":"2408.11281","title":"BearLLM: A Prior Knowledge-Enhanced Bearing Health Management Framework\n  with Unified Vibration Signal Representation","authors":"Haotian Peng, Jiawei Liu, Jinsong Du, Jie Gao, Wei Wang","authorsParsed":[["Peng","Haotian",""],["Liu","Jiawei",""],["Du","Jinsong",""],["Gao","Jie",""],["Wang","Wei",""]],"versions":[{"version":"v1","created":"Wed, 21 Aug 2024 02:04:54 GMT"}],"updateDate":"2024-08-22","timestamp":1724205894000,"abstract":"  We propose a bearing health management framework leveraging large language\nmodels (BearLLM), a novel multimodal model that unifies multiple\nbearing-related tasks by processing user prompts and vibration signals.\nSpecifically, we introduce a prior knowledge-enhanced unified vibration signal\nrepresentation to handle various working conditions across multiple datasets.\nThis involves adaptively sampling the vibration signals based on the sampling\nrate of the sensor, incorporating the frequency domain to unify input\ndimensions, and using a fault-free reference signal as an auxiliary input. To\nextract features from vibration signals, we first train a fault classification\nnetwork, then convert and align the extracted features into word embedding, and\nfinally concatenate these with text embedding as input to an LLM. To evaluate\nthe performance of the proposed method, we constructed the first large-scale\nmultimodal bearing health management (MBHM) dataset, including paired vibration\nsignals and textual descriptions. With our unified vibration signal\nrepresentation, BearLLM using one set of pre-trained weights achieves\nstate-of-the-art performance on nine publicly available fault diagnosis\nbenchmarks, outperforming specific methods designed for individual datasets. We\nprovide a dataset, our model, and code to inspire future research on building\nmore capable industrial multimodal models\n(https://github.com/hatton613/BearLLM).\n","subjects":["Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}