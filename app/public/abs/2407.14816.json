{"id":"2407.14816","title":"Blind Image Deconvolution by Generative-based Kernel Prior and\n  Initializer via Latent Encoding","authors":"Jiangtao Zhang, Zongsheng Yue, Hui Wang, Qian Zhao, and Deyu Meng","authorsParsed":[["Zhang","Jiangtao",""],["Yue","Zongsheng",""],["Wang","Hui",""],["Zhao","Qian",""],["Meng","Deyu",""]],"versions":[{"version":"v1","created":"Sat, 20 Jul 2024 09:23:56 GMT"}],"updateDate":"2024-07-23","timestamp":1721467436000,"abstract":"  Blind image deconvolution (BID) is a classic yet challenging problem in the\nfield of image processing. Recent advances in deep image prior (DIP) have\nmotivated a series of DIP-based approaches, demonstrating remarkable success in\nBID. However, due to the high non-convexity of the inherent optimization\nprocess, these methods are notorious for their sensitivity to the initialized\nkernel. To alleviate this issue and further improve their performance, we\npropose a new framework for BID that better considers the prior modeling and\nthe initialization for blur kernels, leveraging a deep generative model. The\nproposed approach pre-trains a generative adversarial network-based kernel\ngenerator that aptly characterizes the kernel priors and a kernel initializer\nthat facilitates a well-informed initialization for the blur kernel through\nlatent space encoding. With the pre-trained kernel generator and initializer,\none can obtain a high-quality initialization of the blur kernel, and enable\noptimization within a compact latent kernel manifold. Such a framework results\nin an evident performance improvement over existing DIP-based BID methods.\nExtensive experiments on different datasets demonstrate the effectiveness of\nthe proposed method.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"2ghs8JftXDuPfYUxQkw1VhejsxK-SbwOBB16H4c2OHE","pdfSize":"41479612"}
