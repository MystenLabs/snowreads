{"id":"2407.16144","title":"Restarted Halpern PDHG for Linear Programming","authors":"Haihao Lu, Jinwen Yang","authorsParsed":[["Lu","Haihao",""],["Yang","Jinwen",""]],"versions":[{"version":"v1","created":"Tue, 23 Jul 2024 03:06:56 GMT"},{"version":"v2","created":"Mon, 9 Sep 2024 21:15:27 GMT"}],"updateDate":"2024-09-11","timestamp":1721704016000,"abstract":"  In this paper, we propose and analyze a new matrix-free primal-dual\nalgorithm, called restarted Halpern primal-dual hybrid gradient (rHPDHG), for\nsolving linear programming (LP). We show that rHPDHG can achieve optimal\naccelerated linear convergence on feasible and bounded LP. Furthermore, we\npresent a refined analysis that demonstrates an accelerated two-stage\nconvergence of rHPDHG over the vanilla PDHG with an improved complexity for\nidentification and an accelerated eventual linear convergence that does not\ndepend on the conservative global Hoffman constant. Regarding infeasible LP, we\nshow that rHPDHG can recover infeasibility certificates with an accelerated\nlinear rate, improving the previous convergence rates. Furthermore, we discuss\nan extension of rHPDHG by adding reflection operation (which is dubbed as\n$\\mathrm{r^2HPDHG}$), and demonstrate that it shares all theoretical guarantees\nof rHPDHG with an additional factor of 2 speedup in the complexity bound.\nLastly, we build up a GPU-based LP solver using rHPDHG/$\\mathrm{r^2HPDHG}$, and\nthe experiments on 383 MIPLIB instances showcase an improved numerical\nperformance compared cuPDLP.jl.\n","subjects":["Mathematics/Optimization and Control"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}