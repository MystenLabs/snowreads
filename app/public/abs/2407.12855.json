{"id":"2407.12855","title":"Large Language Models can impersonate politicians and other public\n  figures","authors":"Steffen Herbold, Alexander Trautsch, Zlata Kikteva, Annette\n  Hautli-Janisz","authorsParsed":[["Herbold","Steffen",""],["Trautsch","Alexander",""],["Kikteva","Zlata",""],["Hautli-Janisz","Annette",""]],"versions":[{"version":"v1","created":"Tue, 9 Jul 2024 11:16:19 GMT"}],"updateDate":"2024-07-19","timestamp":1720523779000,"abstract":"  Modern AI technology like Large language models (LLMs) has the potential to\npollute the public information sphere with made-up content, which poses a\nsignificant threat to the cohesion of societies at large. A wide range of\nresearch has shown that LLMs are capable of generating text of impressive\nquality, including persuasive political speech, text with a pre-defined style,\nand role-specific content. But there is a crucial gap in the literature: We\nlack large-scale and systematic studies of how capable LLMs are in\nimpersonating political and societal representatives and how the general public\njudges these impersonations in terms of authenticity, relevance and coherence.\nWe present the results of a study based on a cross-section of British society\nthat shows that LLMs are able to generate responses to debate questions that\nwere part of a broadcast political debate programme in the UK. The impersonated\nresponses are judged to be more authentic and relevant than the original\nresponses given by people who were impersonated. This shows two things: (1)\nLLMs can be made to contribute meaningfully to the public political debate and\n(2) there is a dire need to inform the general public of the potential harm\nthis can have on society.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}