{"id":"2408.16125","title":"DECAF: a Discrete-Event based Collaborative Human-Robot Framework for\n  Furniture Assembly","authors":"Giulio Giacomuzzo, Matteo Terreran, Siddarth Jain, Diego Romeres","authorsParsed":[["Giacomuzzo","Giulio",""],["Terreran","Matteo",""],["Jain","Siddarth",""],["Romeres","Diego",""]],"versions":[{"version":"v1","created":"Wed, 28 Aug 2024 20:26:32 GMT"}],"updateDate":"2024-08-30","timestamp":1724876792000,"abstract":"  This paper proposes a task planning framework for collaborative Human-Robot\nscenarios, specifically focused on assembling complex systems such as\nfurniture. The human is characterized as an uncontrollable agent, implying for\nexample that the agent is not bound by a pre-established sequence of actions\nand instead acts according to its own preferences. Meanwhile, the task planner\ncomputes reactively the optimal actions for the collaborative robot to\nefficiently complete the entire assembly task in the least time possible. We\nformalize the problem as a Discrete Event Markov Decision Problem (DE-MDP), a\ncomprehensive framework that incorporates a variety of asynchronous behaviors,\nhuman change of mind and failure recovery as stochastic events. Although the\nproblem could theoretically be addressed by constructing a graph of all\npossible actions, such an approach would be constrained by computational\nlimitations. The proposed formulation offers an alternative solution utilizing\nReinforcement Learning to derive an optimal policy for the robot. Experiments\nwhere conducted both in simulation and on a real system with human subjects\nassembling a chair in collaboration with a 7-DoF manipulator.\n","subjects":["Computing Research Repository/Robotics"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}