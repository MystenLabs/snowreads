{"id":"2407.02129","title":"ReliaAvatar: A Robust Real-Time Avatar Animator with Integrated Motion\n  Prediction","authors":"Bo Qian, Zhenhuan Wei, Jiashuo Li, Xing Wei","authorsParsed":[["Qian","Bo",""],["Wei","Zhenhuan",""],["Li","Jiashuo",""],["Wei","Xing",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 10:18:32 GMT"}],"updateDate":"2024-07-03","timestamp":1719915512000,"abstract":"  Efficiently estimating the full-body pose with minimal wearable devices\npresents a worthwhile research direction. Despite significant advancements in\nthis field, most current research neglects to explore full-body avatar\nestimation under low-quality signal conditions, which is prevalent in practical\nusage. To bridge this gap, we summarize three scenarios that may be encountered\nin real-world applications: standard scenario, instantaneous data-loss\nscenario, and prolonged data-loss scenario, and propose a new evaluation\nbenchmark. The solution we propose to address data-loss scenarios is\nintegrating the full-body avatar pose estimation problem with motion\nprediction. Specifically, we present \\textit{ReliaAvatar}, a real-time,\n\\textbf{relia}ble \\textbf{avatar} animator equipped with predictive modeling\ncapabilities employing a dual-path architecture. ReliaAvatar operates\neffectively, with an impressive performance rate of 109 frames per second\n(fps). Extensive comparative evaluations on widely recognized benchmark\ndatasets demonstrate Relia\\-Avatar's superior performance in both standard and\nlow data-quality conditions. The code is available at\n\\url{https://github.com/MIV-XJTU/ReliaAvatar}.\n","subjects":["Computing Research Repository/Human-Computer Interaction"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}