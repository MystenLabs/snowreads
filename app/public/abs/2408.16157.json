{"id":"2408.16157","title":"The Importance of Learning without Constraints: Reevaluating Benchmarks\n  for Invariant and Equivariant Features of Machine Learning Potentials in\n  Generating Free Energy Landscapes","authors":"Gustavo R. P\\'erez-Lemus, Yinan Xu, Yezhi Jin, Pablo F. Zubieta Rico\n  and Juan J. de Pablo","authorsParsed":[["PÃ©rez-Lemus","Gustavo R.",""],["Xu","Yinan",""],["Jin","Yezhi",""],["Rico","Pablo F. Zubieta",""],["de Pablo","Juan J.",""]],"versions":[{"version":"v1","created":"Wed, 28 Aug 2024 22:37:59 GMT"}],"updateDate":"2024-08-30","timestamp":1724884679000,"abstract":"  Machine-learned interatomic potentials (MILPs) are rapidly gaining interest\nfor molecular modeling, as they provide a balance between quantum-mechanical\nlevel descriptions of atomic interactions and reasonable computational\nefficiency. However, questions remain regarding the stability of simulations\nusing these potentials, as well as the extent to which the learned potential\nenergy function can be extrapolated safely. Past studies have reported\nchallenges encountered when MILPs are applied to classical benchmark systems.\nIn this work, we show that some of these challenges are related to the\ncharacteristics of the training datasets, particularly the inclusion of rigid\nconstraints. We demonstrate that long stability in simulations with MILPs can\nbe achieved by generating unconstrained datasets using unbiased classical\nsimulations if the fast modes are correctly sampled. Additionally, we emphasize\nthat in order to achieve precise energy predictions, it is important to resort\nto enhanced sampling techniques for dataset generation, and we demonstrate that\nsafe extrapolation of MILPs depends on judicious choices related to the\nsystem's underlying free energy landscape and the symmetry features embedded\nwithin the machine learning models.\n","subjects":["Physics/Computational Physics"],"license":"http://creativecommons.org/licenses/by/4.0/"}