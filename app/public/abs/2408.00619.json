{"id":"2408.00619","title":"Harnessing Uncertainty-aware Bounding Boxes for Unsupervised 3D Object\n  Detection","authors":"Ruiyang Zhang, Hu Zhang, Hang Yu, Zhedong Zheng","authorsParsed":[["Zhang","Ruiyang",""],["Zhang","Hu",""],["Yu","Hang",""],["Zheng","Zhedong",""]],"versions":[{"version":"v1","created":"Thu, 1 Aug 2024 15:01:07 GMT"}],"updateDate":"2024-08-02","timestamp":1722524467000,"abstract":"  Unsupervised 3D object detection aims to identify objects of interest from\nunlabeled raw data, such as LiDAR points. Recent approaches usually adopt\npseudo 3D bounding boxes (3D bboxes) from clustering algorithm to initialize\nthe model training, and then iteratively updating both pseudo labels and the\ntrained model. However, pseudo bboxes inevitably contain noises, and such\ninaccurate annotation accumulates to the final model, compromising the\nperformance. Therefore, in an attempt to mitigate the negative impact of pseudo\nbboxes, we introduce a new uncertainty-aware framework. In particular, Our\nmethod consists of two primary components: uncertainty estimation and\nuncertainty regularization. (1) In the uncertainty estimation phase, we\nincorporate an extra auxiliary detection branch alongside the primary detector.\nThe prediction disparity between the primary and auxiliary detectors is\nleveraged to estimate uncertainty at the box coordinate level, including\nposition, shape, orientation. (2) Based on the assessed uncertainty, we\nregularize the model training via adaptively adjusting every 3D bboxes\ncoordinates. For pseudo bbox coordinates with high uncertainty, we assign a\nrelatively low loss weight. Experiment verifies that the proposed method is\nrobust against the noisy pseudo bboxes, yielding substantial improvements on\nnuScenes and Lyft compared to existing techniques, with increases of 6.9% in\nAP$_{BEV}$ and 2.5% in AP$_{3D}$ on nuScenes, and 2.2% in AP$_{BEV}$ and 1.0%\nin AP$_{3D}$ on Lyft.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}