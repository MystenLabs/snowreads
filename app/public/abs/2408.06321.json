{"id":"2408.06321","title":"EqNIO: Subequivariant Neural Inertial Odometry","authors":"Royina Karegoudra Jayanth, Yinshuang Xu, Ziyun Wang, Evangelos\n  Chatzipantazis, Daniel Gehrig, Kostas Daniilidis","authorsParsed":[["Jayanth","Royina Karegoudra",""],["Xu","Yinshuang",""],["Wang","Ziyun",""],["Chatzipantazis","Evangelos",""],["Gehrig","Daniel",""],["Daniilidis","Kostas",""]],"versions":[{"version":"v1","created":"Mon, 12 Aug 2024 17:42:46 GMT"},{"version":"v2","created":"Sun, 18 Aug 2024 06:55:31 GMT"}],"updateDate":"2024-08-20","timestamp":1723484566000,"abstract":"  Neural networks are seeing rapid adoption in purely inertial odometry, where\naccelerometer and gyroscope measurements from commodity inertial measurement\nunits (IMU) are used to regress displacements and associated uncertainties.\nThey can learn informative displacement priors, which can be directly fused\nwith the raw data with off-the-shelf non-linear filters. Nevertheless, these\nnetworks do not consider the physical roto-reflective symmetries inherent in\nIMU data, leading to the need to memorize the same priors for every possible\nmotion direction, which hinders generalization. In this work, we characterize\nthese symmetries and show that the IMU data and the resulting displacement and\ncovariance transform equivariantly, when rotated around the gravity vector and\nreflected with respect to arbitrary planes parallel to gravity. We design a\nneural network that respects these symmetries by design through equivariant\nprocessing in three steps: First, it estimates an equivariant gravity-aligned\nframe from equivariant vectors and invariant scalars derived from IMU data,\nleveraging expressive linear and non-linear layers tailored to commute with the\nunderlying symmetry transformation. We then map the IMU data into this frame,\nthereby achieving an invariant canonicalization that can be directly used with\noff-the-shelf inertial odometry networks. Finally, we map these network outputs\nback into the original frame, thereby obtaining equivariant covariances and\ndisplacements. We demonstrate the generality of our framework by applying it to\nthe filter-based approach based on TLIO, and the end-to-end RONIN architecture,\nand show better performance on the TLIO, Aria, RIDI and OxIOD datasets than\nexisting methods.\n","subjects":["Computing Research Repository/Robotics","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}