{"id":"2407.15017","title":"Knowledge Mechanisms in Large Language Models: A Survey and Perspective","authors":"Mengru Wang, Yunzhi Yao, Ziwen Xu, Shuofei Qiao, Shumin Deng, Peng\n  Wang, Xiang Chen, Jia-Chen Gu, Yong Jiang, Pengjun Xie, Fei Huang, Huajun\n  Chen, Ningyu Zhang","authorsParsed":[["Wang","Mengru",""],["Yao","Yunzhi",""],["Xu","Ziwen",""],["Qiao","Shuofei",""],["Deng","Shumin",""],["Wang","Peng",""],["Chen","Xiang",""],["Gu","Jia-Chen",""],["Jiang","Yong",""],["Xie","Pengjun",""],["Huang","Fei",""],["Chen","Huajun",""],["Zhang","Ningyu",""]],"versions":[{"version":"v1","created":"Mon, 22 Jul 2024 06:15:59 GMT"},{"version":"v2","created":"Wed, 31 Jul 2024 09:14:29 GMT"}],"updateDate":"2024-08-01","timestamp":1721628959000,"abstract":"  Understanding knowledge mechanisms in Large Language Models (LLMs) is crucial\nfor advancing towards trustworthy AGI. This paper reviews knowledge mechanism\nanalysis from a novel taxonomy including knowledge utilization and evolution.\nKnowledge utilization delves into the mechanism of memorization, comprehension\nand application, and creation. Knowledge evolution focuses on the dynamic\nprogression of knowledge within individual and group LLMs. Moreover, we discuss\nwhat knowledge LLMs have learned, the reasons for the fragility of parametric\nknowledge, and the potential dark knowledge (hypothesis) that will be\nchallenging to address. We hope this work can help understand knowledge in LLMs\nand provide insights for future research.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Human-Computer Interaction","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}