{"id":"2408.16266","title":"Improving Diffusion-based Data Augmentation with Inversion Spherical\n  Interpolation","authors":"Yanghao Wang, Long Chen","authorsParsed":[["Wang","Yanghao",""],["Chen","Long",""]],"versions":[{"version":"v1","created":"Thu, 29 Aug 2024 05:05:02 GMT"}],"updateDate":"2024-08-30","timestamp":1724907902000,"abstract":"  Data Augmentation (DA), \\ie, synthesizing faithful and diverse samples to\nexpand the original training set, is a prevalent and effective strategy to\nimprove various visual recognition tasks. With the powerful image generation\nability, diffusion-based DA has shown strong performance gains on different\nbenchmarks. In this paper, we analyze today's diffusion-based DA methods, and\nargue that they cannot take account of both faithfulness and diversity, which\nare two critical keys for generating high-quality samples and boosting final\nclassification performance. To this end, we propose a novel Diffusion-based\nInversion Interpolation DA method: Diff-II. Specifically, Diff-II consists of\nthree main steps: 1) Category concepts learning: Learning concept embeddings\nfor each category. 2) Inversion interpolation: Calculating the inversion for\neach image, and conducting spherical interpolation for two randomly sampled\ninversions from the same category. 3) Two-stage denoising: Using different\nprompts to generate synthesized images in a coarse-to-fine manner. Extensive\nexperiments on multiple image classification tasks (\\eg, few-shot, long-tailed,\nand out-of-distribution classification) have demonstrated its effectiveness\nover state-of-the-art diffusion-based DA methods.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}