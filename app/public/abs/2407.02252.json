{"id":"2407.02252","title":"GlyphDraw2: Automatic Generation of Complex Glyph Posters with Diffusion\n  Models and Large Language Models","authors":"Jian Ma, Yonglin Deng, Chen Chen, Haonan Lu, Zhenyu Yang","authorsParsed":[["Ma","Jian",""],["Deng","Yonglin",""],["Chen","Chen",""],["Lu","Haonan",""],["Yang","Zhenyu",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 13:17:49 GMT"},{"version":"v2","created":"Fri, 30 Aug 2024 12:44:44 GMT"}],"updateDate":"2024-09-02","timestamp":1719926269000,"abstract":"  Posters play a crucial role in marketing and advertising by enhancing visual\ncommunication and brand visibility, making significant contributions to\nindustrial design. With the latest advancements in controllable T2I diffusion\nmodels, increasing research has focused on rendering text within synthesized\nimages. Despite improvements in text rendering accuracy, the field of automatic\nposter generation remains underexplored. In this paper, we propose an automatic\nposter generation framework with text rendering capabilities leveraging LLMs,\nutilizing a triple-cross attention mechanism based on alignment learning. This\nframework aims to create precise poster text within a detailed contextual\nbackground. Additionally, the framework supports controllable fonts, adjustable\nimage resolution, and the rendering of posters with descriptions and text in\nboth English and Chinese.Furthermore, we introduce a high-resolution font\ndataset and a poster dataset with resolutions exceeding 1024 pixels. Our\napproach leverages the SDXL architecture. Extensive experiments validate our\nmethod's capability in generating poster images with complex and contextually\nrich backgrounds.Codes is available at\nhttps://github.com/OPPO-Mente-Lab/GlyphDraw2.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}