{"id":"2408.15696","title":"Comparing diversity, negativity, and stereotypes in Chinese-language AI\n  technologies: a case study on Baidu, Ernie and Qwen","authors":"Geng Liu, Carlo Alberto Bono, Francesco Pierri","authorsParsed":[["Liu","Geng",""],["Bono","Carlo Alberto",""],["Pierri","Francesco",""]],"versions":[{"version":"v1","created":"Wed, 28 Aug 2024 10:51:18 GMT"}],"updateDate":"2024-08-29","timestamp":1724842278000,"abstract":"  Large Language Models (LLMs) and search engines have the potential to\nperpetuate biases and stereotypes by amplifying existing prejudices in their\ntraining data and algorithmic processes, thereby influencing public perception\nand decision-making. While most work has focused on Western-centric AI\ntechnologies, we study Chinese-based tools by investigating social biases\nembedded in the major Chinese search engine, Baidu, and two leading LLMs, Ernie\nand Qwen. Leveraging a dataset of 240 social groups across 13 categories\ndescribing Chinese society, we collect over 30k views encoded in the\naforementioned tools by prompting them for candidate words describing such\ngroups. We find that language models exhibit a larger variety of embedded views\ncompared to the search engine, although Baidu and Qwen generate negative\ncontent more often than Ernie. We also find a moderate prevalence of\nstereotypes embedded in the language models, many of which potentially promote\noffensive and derogatory views. Our work highlights the importance of promoting\nfairness and inclusivity in AI technologies with a global perspective.\n","subjects":["Computing Research Repository/Computers and Society"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"fNJrHZk5WLe28J1VeuzdHaHuDAJ0ZTxfpmxrcLBmshE","pdfSize":"4670902"}
