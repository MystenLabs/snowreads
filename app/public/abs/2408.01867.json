{"id":"2408.01867","title":"TrustNavGPT: Modeling Uncertainty to Improve Trustworthiness of\n  Audio-Guided LLM-Based Robot Navigation","authors":"Xingpeng Sun, Yiran Zhang, Xindi Tang, Amrit Singh Bedi, Aniket Bera","authorsParsed":[["Sun","Xingpeng",""],["Zhang","Yiran",""],["Tang","Xindi",""],["Bedi","Amrit Singh",""],["Bera","Aniket",""]],"versions":[{"version":"v1","created":"Sat, 3 Aug 2024 21:32:43 GMT"}],"updateDate":"2024-08-06","timestamp":1722720763000,"abstract":"  While LLMs are proficient at processing text in human conversations, they\noften encounter difficulties with the nuances of verbal instructions and, thus,\nremain prone to hallucinate trust in human command. In this work, we present\nTrustNavGPT, an LLM based audio guided navigation agent that uses affective\ncues in spoken communication elements such as tone and inflection that convey\nmeaning beyond words, allowing it to assess the trustworthiness of human\ncommands and make effective, safe decisions. Our approach provides a\nlightweight yet effective approach that extends existing LLMs to model audio\nvocal features embedded in the voice command and model uncertainty for safe\nrobotic navigation.\n","subjects":["Computing Research Repository/Robotics"],"license":"http://creativecommons.org/licenses/by/4.0/"}