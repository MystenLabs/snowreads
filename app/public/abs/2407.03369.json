{"id":"2407.03369","title":"FOXANN: A Method for Boosting Neural Network Performance","authors":"Mahmood A. Jumaah, Yossra H. Ali, Tarik A. Rashid, S. Vimal","authorsParsed":[["Jumaah","Mahmood A.",""],["Ali","Yossra H.",""],["Rashid","Tarik A.",""],["Vimal","S.",""]],"versions":[{"version":"v1","created":"Sat, 29 Jun 2024 17:00:47 GMT"}],"updateDate":"2024-07-08","timestamp":1719680447000,"abstract":"  Artificial neural networks play a crucial role in machine learning and there\nis a need to improve their performance. This paper presents FOXANN, a novel\nclassification model that combines the recently developed Fox optimizer with\nANN to solve ML problems. Fox optimizer replaces the backpropagation algorithm\nin ANN; optimizes synaptic weights; and achieves high classification accuracy\nwith a minimum loss, improved model generalization, and interpretability. The\nperformance of FOXANN is evaluated on three standard datasets: Iris Flower,\nBreast Cancer Wisconsin, and Wine. The results presented in this paper are\nderived from 100 epochs using 10-fold cross-validation, ensuring that all\ndataset samples are involved in both the training and validation stages.\nMoreover, the results show that FOXANN outperforms traditional ANN and logistic\nregression methods as well as other models proposed in the literature such as\nABC-ANN, ABC-MNN, CROANN, and PSO-DNN, achieving a higher accuracy of 0.9969\nand a lower validation loss of 0.0028. These results demonstrate that FOXANN is\nmore effective than traditional methods and other proposed models across\nstandard datasets. Thus, FOXANN effectively addresses the challenges in ML\nalgorithms and improves classification performance.\n","subjects":["Computing Research Repository/Neural and Evolutionary Computing"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"xhAu9O2dUTa3WpcJ_Caz7ewP7W4luRNWmZuezHtkhUk","pdfSize":"463263"}
