{"id":"2408.15907","title":"Decentralized LLM Inference over Edge Networks with Energy Harvesting","authors":"Aria Khoshsirat, Giovanni Perin, Michele Rossi","authorsParsed":[["Khoshsirat","Aria",""],["Perin","Giovanni",""],["Rossi","Michele",""]],"versions":[{"version":"v1","created":"Wed, 28 Aug 2024 16:20:45 GMT"}],"updateDate":"2024-08-29","timestamp":1724862045000,"abstract":"  Large language models have significantly transformed multiple fields with\ntheir exceptional performance in natural language tasks, but their deployment\nin resource-constrained environments like edge networks presents an ongoing\nchallenge. Decentralized techniques for inference have emerged, distributing\nthe model blocks among multiple devices to improve flexibility and cost\neffectiveness. However, energy limitations remain a significant concern for\nedge devices. We propose a sustainable model for collaborative inference on\ninterconnected, battery-powered edge devices with energy harvesting. A\nsemi-Markov model is developed to describe the states of the devices,\nconsidering processing parameters and average green energy arrivals. This\ninforms the design of scheduling algorithms that aim to minimize device\ndowntimes and maximize network throughput. Through empirical evaluations and\nsimulated runs, we validate the effectiveness of our approach, paving the way\nfor energy-efficient decentralized inference over edge networks.\n","subjects":["Computing Research Repository/Distributed, Parallel, and Cluster Computing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}