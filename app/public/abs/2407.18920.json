{"id":"2407.18920","title":"Optimising Hard Prompts with Few-Shot Meta-Prompting","authors":"Sayash Raaj Hiraou","authorsParsed":[["Hiraou","Sayash Raaj",""]],"versions":[{"version":"v1","created":"Tue, 9 Jul 2024 07:02:57 GMT"}],"updateDate":"2024-07-30","timestamp":1720508577000,"abstract":"  Prompting is a flexible and adaptable way of providing instructions to a\nLarge Language Model (LLM). Contextual prompts include context in the form of a\ndocument or dialogue along with the natural language instructions to the LLM,\noften constraining the LLM to restrict facts to that of the given context while\ncomplying with the instructions. Masking the context, it acts as template for\nprompts. In this paper, we present an iterative method to generate better\ntemplates using an LLM from an existing set of prompt templates without\nrevealing the context to the LLM. Multiple methods of optimising prompts using\nthe LLM itself are explored to check the effect of few shot sampling methods on\niterative propagation while maintaining linguistic styles and syntax on\noptimisation of prompt templates, yielding a 103.87% improvement using the best\nperforming method. Comparison of the results of multiple contextual tasks\ndemonstrate the ability of LLMs to maintain syntax while learning to replicate\nlinguistic styles. Additionally, the effect on the output with different\nmethods of prompt template generation is shown.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"C0oW1S5UmQ0NsBuw4hN9BC4AGIuIdr4CADAYUkDaaqk","pdfSize":"949696","objectId":"0xb27b2ddd147914e37178a1e04cefa8e3eab549108af5e38fcfb29cb9c2e04756","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
