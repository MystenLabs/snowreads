{"id":"2407.01967","title":"Unleash the Power of Local Representations for Few-Shot Classification","authors":"Shi Tang and Guiming Luo and Xinchen Ye and Zhiyi Xia","authorsParsed":[["Tang","Shi",""],["Luo","Guiming",""],["Ye","Xinchen",""],["Xia","Zhiyi",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 05:51:04 GMT"}],"updateDate":"2024-07-03","timestamp":1719899464000,"abstract":"  Generalizing to novel classes unseen during training is a key challenge of\nfew-shot classification. Recent metric-based methods try to address this by\nlocal representations. However, they are unable to take full advantage of them\ndue to (i) improper supervision for pretraining the feature extractor, and (ii)\nlack of adaptability in the metric for handling various possible compositions\nof local feature sets. In this work, we unleash the power of local\nrepresentations in improving novel-class generalization. For the feature\nextractor, we design a novel pretraining paradigm that learns randomly cropped\npatches by soft labels. It utilizes the class-level diversity of patches while\ndiminishing the impact of their semantic misalignments to hard labels. To align\nnetwork output with soft labels, we also propose a UniCon KL-Divergence that\nemphasizes the equal contribution of each base class in describing \"non-base\"\npatches. For the metric, we formulate measuring local feature sets as an\nentropy-regularized optimal transport problem to introduce the ability to\nhandle sets consisting of homogeneous elements. Furthermore, we design a\nModulate Module to endow the metric with the necessary adaptability. Our method\nachieves new state-of-the-art performance on three popular benchmarks.\nMoreover, it exceeds state-of-the-art transductive and cross-modal methods in\nthe fine-grained scenario.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}