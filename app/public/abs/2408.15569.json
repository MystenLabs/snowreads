{"id":"2408.15569","title":"Temporal Attention for Cross-View Sequential Image Localization","authors":"Dong Yuan, Frederic Maire, Feras Dayoub","authorsParsed":[["Yuan","Dong",""],["Maire","Frederic",""],["Dayoub","Feras",""]],"versions":[{"version":"v1","created":"Wed, 28 Aug 2024 06:53:08 GMT"}],"updateDate":"2024-08-29","timestamp":1724827988000,"abstract":"  This paper introduces a novel approach to enhancing cross-view localization,\nfocusing on the fine-grained, sequential localization of street-view images\nwithin a single known satellite image patch, a significant departure from\ntraditional one-to-one image retrieval methods. By expanding to sequential\nimage fine-grained localization, our model, equipped with a novel Temporal\nAttention Module (TAM), leverages contextual information to significantly\nimprove sequential image localization accuracy. Our method shows substantial\nreductions in both mean and median localization errors on the Cross-View Image\nSequence (CVIS) dataset, outperforming current state-of-the-art single-image\nlocalization techniques. Additionally, by adapting the KITTI-CVL dataset into\nsequential image sets, we not only offer a more realistic dataset for future\nresearch but also demonstrate our model's robust generalization capabilities\nacross varying times and areas, evidenced by a 75.3% reduction in mean distance\nerror in cross-view sequential image localization.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}