{"id":"2407.11844","title":"Variational Randomized Smoothing for Sample-Wise Adversarial Robustness","authors":"Ryo Hase, Ye Wang, Toshiaki Koike-Akino, Jing Liu, Kieran Parsons","authorsParsed":[["Hase","Ryo",""],["Wang","Ye",""],["Koike-Akino","Toshiaki",""],["Liu","Jing",""],["Parsons","Kieran",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 15:25:13 GMT"}],"updateDate":"2024-07-17","timestamp":1721143513000,"abstract":"  Randomized smoothing is a defensive technique to achieve enhanced robustness\nagainst adversarial examples which are small input perturbations that degrade\nthe performance of neural network models. Conventional randomized smoothing\nadds random noise with a fixed noise level for every input sample to smooth out\nadversarial perturbations. This paper proposes a new variational framework that\nuses a per-sample noise level suitable for each input by introducing a noise\nlevel selector. Our experimental results demonstrate enhancement of empirical\nrobustness against adversarial attacks. We also provide and analyze the\ncertified robustness for our sample-wise smoothing method.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Cryptography and Security","Statistics/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}