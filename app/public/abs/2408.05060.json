{"id":"2408.05060","title":"GLEAMS: Bridging the Gap Between Local and Global Explanations","authors":"Giorgio Visani, Vincenzo Stanzione and Damien Garreau","authorsParsed":[["Visani","Giorgio",""],["Stanzione","Vincenzo",""],["Garreau","Damien",""]],"versions":[{"version":"v1","created":"Fri, 9 Aug 2024 13:30:37 GMT"}],"updateDate":"2024-08-12","timestamp":1723210237000,"abstract":"  The explainability of machine learning algorithms is crucial, and numerous\nmethods have emerged recently. Local, post-hoc methods assign an attribution\nscore to each feature, indicating its importance for the prediction. However,\nthese methods require recalculating explanations for each example. On the other\nside, while there exist global approaches they often produce explanations that\nare either overly simplistic and unreliable or excessively complex. To bridge\nthis gap, we propose GLEAMS, a novel method that partitions the input space and\nlearns an interpretable model within each sub-region, thereby providing both\nfaithful local and global surrogates. We demonstrate GLEAMS' effectiveness on\nboth synthetic and real-world data, highlighting its desirable properties and\nhuman-understandable insights.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"JsJfiqMbOu98i5TgoEOQidMfvQBWwh1SYQL4Okya_oc","pdfSize":"2079356"}
