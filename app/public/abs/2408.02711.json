{"id":"2408.02711","title":"Text Conditioned Symbolic Drumbeat Generation using Latent Diffusion\n  Models","authors":"Pushkar Jajoria and James McDermott","authorsParsed":[["Jajoria","Pushkar",""],["McDermott","James",""]],"versions":[{"version":"v1","created":"Mon, 5 Aug 2024 13:23:05 GMT"}],"updateDate":"2024-08-07","timestamp":1722864185000,"abstract":"  This study introduces a text-conditioned approach to generating drumbeats\nwith Latent Diffusion Models (LDMs). It uses informative conditioning text\nextracted from training data filenames. By pretraining a text and drumbeat\nencoder through contrastive learning within a multimodal network, aligned\nfollowing CLIP, we align the modalities of text and music closely.\nAdditionally, we examine an alternative text encoder based on multihot text\nencodings. Inspired by musics multi-resolution nature, we propose a novel LSTM\nvariant, MultiResolutionLSTM, designed to operate at various resolutions\nindependently. In common with recent LDMs in the image space, it speeds up the\ngeneration process by running diffusion in a latent space provided by a\npretrained unconditional autoencoder. We demonstrate the originality and\nvariety of the generated drumbeats by measuring distance (both over binary\npianorolls and in the latent space) versus the training dataset and among the\ngenerated drumbeats. We also assess the generated drumbeats through a listening\ntest focused on questions of quality, aptness for the prompt text, and novelty.\nWe show that the generated drumbeats are novel and apt to the prompt text, and\ncomparable in quality to those created by human musicians.\n","subjects":["Computing Research Repository/Sound","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"G8NRNfm31Zx9habUu9b0WpExIqkN4HtmX6McF766Cjc","pdfSize":"347228"}
