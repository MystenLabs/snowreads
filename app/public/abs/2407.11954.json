{"id":"2407.11954","title":"Gated Temporal Diffusion for Stochastic Long-Term Dense Anticipation","authors":"Olga Zatsarynna, Emad Bahrami, Yazan Abu Farha, Gianpiero Francesca,\n  Juergen Gall","authorsParsed":[["Zatsarynna","Olga",""],["Bahrami","Emad",""],["Farha","Yazan Abu",""],["Francesca","Gianpiero",""],["Gall","Juergen",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 17:48:05 GMT"}],"updateDate":"2024-07-17","timestamp":1721152085000,"abstract":"  Long-term action anticipation has become an important task for many\napplications such as autonomous driving and human-robot interaction. Unlike\nshort-term anticipation, predicting more actions into the future imposes a real\nchallenge with the increasing uncertainty in longer horizons. While there has\nbeen a significant progress in predicting more actions into the future, most of\nthe proposed methods address the task in a deterministic setup and ignore the\nunderlying uncertainty. In this paper, we propose a novel Gated Temporal\nDiffusion (GTD) network that models the uncertainty of both the observation and\nthe future predictions. As generator, we introduce a Gated Anticipation Network\n(GTAN) to model both observed and unobserved frames of a video in a mutual\nrepresentation. On the one hand, using a mutual representation for past and\nfuture allows us to jointly model ambiguities in the observation and future,\nwhile on the other hand GTAN can by design treat the observed and unobserved\nparts differently and steer the information flow between them. Our model\nachieves state-of-the-art results on the Breakfast, Assembly101 and 50Salads\ndatasets in both stochastic and deterministic settings. Code:\nhttps://github.com/olga-zats/GTDA .\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}