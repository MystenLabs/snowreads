{"id":"2407.17129","title":"Mapping the individual, social, and biospheric impacts of Foundation\n  Models","authors":"Andr\\'es Dom\\'inguez Hern\\'andez, Shyam Krishna, Antonella Maia\n  Perini, Michael Katell, SJ Bennett, Ann Borda, Youmna Hashem, Semeli\n  Hadjiloizou, Sabeehah Mahomed, Smera Jayadeva, Mhairi Aitken, David Leslie","authorsParsed":[["Hernández","Andrés Domínguez",""],["Krishna","Shyam",""],["Perini","Antonella Maia",""],["Katell","Michael",""],["Bennett","SJ",""],["Borda","Ann",""],["Hashem","Youmna",""],["Hadjiloizou","Semeli",""],["Mahomed","Sabeehah",""],["Jayadeva","Smera",""],["Aitken","Mhairi",""],["Leslie","David",""]],"versions":[{"version":"v1","created":"Wed, 24 Jul 2024 10:05:40 GMT"}],"updateDate":"2024-07-25","timestamp":1721815540000,"abstract":"  Responding to the rapid roll-out and large-scale commercialization of\nfoundation models, large language models, and generative AI, an emerging body\nof work is shedding light on the myriad impacts these technologies are having\nacross society. Such research is expansive, ranging from the production of\ndiscriminatory, fake and toxic outputs, and privacy and copyright violations,\nto the unjust extraction of labor and natural resources. The same has not been\nthe case in some of the most prominent AI governance initiatives in the global\nnorth like the UK's AI Safety Summit and the G7's Hiroshima process, which have\ninfluenced much of the international dialogue around AI governance. Despite the\nwealth of cautionary tales and evidence of algorithmic harm, there has been an\nongoing over-emphasis within the AI governance discourse on technical matters\nof safety and global catastrophic or existential risks. This narrowed focus has\ntended to draw attention away from very pressing social and ethical challenges\nposed by the current brute-force industrialization of AI applications. To\naddress such a visibility gap between real-world consequences and speculative\nrisks, this paper offers a critical framework to account for the social,\npolitical, and environmental dimensions of foundation models and generative AI.\nWe identify 14 categories of risks and harms and map them according to their\nindividual, social, and biospheric impacts. We argue that this novel typology\noffers an integrative perspective to address the most urgent negative impacts\nof foundation models and their downstream applications. We conclude with\nrecommendations on how this typology could be used to inform technical and\nnormative interventions to advance responsible AI.\n","subjects":["Computing Research Repository/Computers and Society"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"oPZwpxsXcpYYGqbPQd5X_Bv17tNVXRaP-jg-6euRBZI","pdfSize":"853147"}
