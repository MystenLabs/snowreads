{"id":"2407.16502","title":"Neural information field filter","authors":"Kairui Hao, Ilias Bilionis","authorsParsed":[["Hao","Kairui",""],["Bilionis","Ilias",""]],"versions":[{"version":"v1","created":"Tue, 23 Jul 2024 14:18:26 GMT"}],"updateDate":"2024-07-24","timestamp":1721744306000,"abstract":"  We introduce neural information field filter, a Bayesian state and parameter\nestimation method for high-dimensional nonlinear dynamical systems given large\nmeasurement datasets. Solving such a problem using traditional methods, such as\nKalman and particle filters, is computationally expensive. Information field\ntheory is a Bayesian approach that can efficiently reconstruct dynamical model\nstate paths and calibrate model parameters from noisy measurement data. To\napply the method, we parameterize the time evolution state path using the span\nof a finite linear basis. The existing method has to reparameterize the state\npath by initial states to satisfy the initial condition. Designing an\nexpressive yet simple linear basis before knowing the true state path is\ncrucial for inference accuracy but challenging. Moreover, reparameterizing the\nstate path using the initial state is easy to perform for a linear basis, but\nis nontrivial for more complex and expressive function parameterizations, such\nas neural networks. The objective of this paper is to simplify and enrich the\nclass of state path parameterizations using neural networks for the information\nfield theory approach. To this end, we propose a generalized physics-informed\nconditional prior using an auxiliary initial state. We show the existing\nreparameterization is a special case. We parameterize the state path using a\nresidual neural network that consists of a linear basis function and a Fourier\nencoding fully connected neural network residual function. The residual\nfunction aims to correct the error of the linear basis function. To sample from\nthe intractable posterior distribution, we develop an optimization algorithm,\nnested stochastic variational inference, and a sampling algorithm, nested\npreconditioned stochastic gradient Langevin dynamics. A series of numerical and\nexperimental examples verify and validate the proposed method.\n","subjects":["Statistics/Machine Learning","Physics/Data Analysis, Statistics and Probability"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}