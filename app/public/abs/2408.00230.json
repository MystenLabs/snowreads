{"id":"2408.00230","title":"Lost in Translation: Latent Concept Misalignment in Text-to-Image\n  Diffusion Models","authors":"Juntu Zhao, Junyu Deng, Yixin Ye, Chongxuan Li, Zhijie Deng, Dequan\n  Wang","authorsParsed":[["Zhao","Juntu",""],["Deng","Junyu",""],["Ye","Yixin",""],["Li","Chongxuan",""],["Deng","Zhijie",""],["Wang","Dequan",""]],"versions":[{"version":"v1","created":"Thu, 1 Aug 2024 01:54:17 GMT"},{"version":"v2","created":"Mon, 5 Aug 2024 08:36:20 GMT"}],"updateDate":"2024-08-06","timestamp":1722477257000,"abstract":"  Advancements in text-to-image diffusion models have broadened extensive\ndownstream practical applications, but such models often encounter misalignment\nissues between text and image. Taking the generation of a combination of two\ndisentangled concepts as an example, say given the prompt \"a tea cup of iced\ncoke\", existing models usually generate a glass cup of iced coke because the\niced coke usually co-occurs with the glass cup instead of the tea one during\nmodel training. The root of such misalignment is attributed to the confusion in\nthe latent semantic space of text-to-image diffusion models, and hence we refer\nto the \"a tea cup of iced coke\" phenomenon as Latent Concept Misalignment\n(LC-Mis). We leverage large language models (LLMs) to thoroughly investigate\nthe scope of LC-Mis, and develop an automated pipeline for aligning the latent\nsemantics of diffusion models to text prompts. Empirical assessments confirm\nthe effectiveness of our approach, substantially reducing LC-Mis errors and\nenhancing the robustness and versatility of text-to-image diffusion models. The\ncode and dataset are here: https://github.com/RossoneriZhao/iced_coke.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}