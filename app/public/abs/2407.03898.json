{"id":"2407.03898","title":"Overflow-Avoiding Memory AMP","authors":"Shunqi Huang, Lei Liu, and Brian M. Kurkoski","authorsParsed":[["Huang","Shunqi",""],["Liu","Lei",""],["Kurkoski","Brian M.",""]],"versions":[{"version":"v1","created":"Thu, 4 Jul 2024 12:44:03 GMT"}],"updateDate":"2024-07-08","timestamp":1720097043000,"abstract":"  Approximate Message Passing (AMP) type algorithms are widely used for signal\nrecovery in high-dimensional noisy linear systems. Recently, a principle called\nMemory AMP (MAMP) was proposed. Leveraging this principle, the gradient descent\nMAMP (GD-MAMP) algorithm was designed, inheriting the strengths of AMP and\nOAMP/VAMP. In this paper, we first provide an overflow-avoiding GD-MAMP\n(OA-GD-MAMP) to address the overflow problem that arises from some intermediate\nvariables exceeding the range of floating point numbers. Second, we develop a\ncomplexity-reduced GD-MAMP (CR-GD-MAMP) to reduce the number of matrix-vector\nproducts per iteration by 1/3 (from 3 to 2) with little to no impact on the\nconvergence speed.\n","subjects":["Computing Research Repository/Information Theory","Mathematics/Information Theory"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}