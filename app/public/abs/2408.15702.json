{"id":"2408.15702","title":"Evaluating Model Robustness Using Adaptive Sparse L0 Regularization","authors":"Weiyou Liu and Zhenyang Li and Weitong Chen","authorsParsed":[["Liu","Weiyou",""],["Li","Zhenyang",""],["Chen","Weitong",""]],"versions":[{"version":"v1","created":"Wed, 28 Aug 2024 11:02:23 GMT"}],"updateDate":"2024-08-29","timestamp":1724842943000,"abstract":"  Deep Neural Networks have demonstrated remarkable success in various domains\nbut remain susceptible to adversarial examples, which are slightly altered\ninputs designed to induce misclassification. While adversarial attacks\ntypically optimize under Lp norm constraints, attacks based on the L0 norm,\nprioritising input sparsity, are less studied due to their complex and non\nconvex nature. These sparse adversarial examples challenge existing defenses by\naltering a minimal subset of features, potentially uncovering more subtle DNN\nweaknesses. However, the current L0 norm attack methodologies face a trade off\nbetween accuracy and efficiency either precise but computationally intense or\nexpedient but imprecise. This paper proposes a novel, scalable, and effective\napproach to generate adversarial examples based on the L0 norm, aimed at\nrefining the robustness evaluation of DNNs against such perturbations.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}