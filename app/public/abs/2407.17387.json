{"id":"2407.17387","title":"PERSONA: A Reproducible Testbed for Pluralistic Alignment","authors":"Louis Castricato, Nathan Lile, Rafael Rafailov, Jan-Philipp Fr\\\"anken,\n  Chelsea Finn","authorsParsed":[["Castricato","Louis",""],["Lile","Nathan",""],["Rafailov","Rafael",""],["Fr√§nken","Jan-Philipp",""],["Finn","Chelsea",""]],"versions":[{"version":"v1","created":"Wed, 24 Jul 2024 16:11:39 GMT"}],"updateDate":"2024-07-25","timestamp":1721837499000,"abstract":"  The rapid advancement of language models (LMs) necessitates robust alignment\nwith diverse user values. However, current preference optimization approaches\noften fail to capture the plurality of user opinions, instead reinforcing\nmajority viewpoints and marginalizing minority perspectives. We introduce\nPERSONA, a reproducible test bed designed to evaluate and improve pluralistic\nalignment of LMs. We procedurally generate diverse user profiles from US census\ndata, resulting in 1,586 synthetic personas with varied demographic and\nidiosyncratic attributes. We then generate a large-scale evaluation dataset\ncontaining 3,868 prompts and 317,200 feedback pairs obtained from our synthetic\npersonas. Leveraging this dataset, we systematically evaluate LM capabilities\nin role-playing diverse users, verified through human judges, and the\nestablishment of both a benchmark, PERSONA Bench, for pluralistic alignment\napproaches as well as an extensive dataset to create new and future benchmarks.\nThe full dataset and benchmarks are available here:\nhttps://www.synthlabs.ai/research/persona.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/"}