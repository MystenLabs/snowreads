{"id":"2407.16945","title":"Affective Behaviour Analysis via Progressive Learning","authors":"Chen Liu, Wei Zhang, Feng Qiu, Lincheng Li, Xin Yu","authorsParsed":[["Liu","Chen",""],["Zhang","Wei",""],["Qiu","Feng",""],["Li","Lincheng",""],["Yu","Xin",""]],"versions":[{"version":"v1","created":"Wed, 24 Jul 2024 02:24:21 GMT"},{"version":"v2","created":"Fri, 26 Jul 2024 02:24:11 GMT"}],"updateDate":"2024-07-29","timestamp":1721787861000,"abstract":"  Affective Behavior Analysis aims to develop emotionally intelligent\ntechnology that can recognize and respond to human emotions. To advance this,\nthe 7th Affective Behavior Analysis in-the-wild (ABAW) competition establishes\ntwo tracks: i.e., the Multi-task Learning (MTL) Challenge and the Compound\nExpression (CE) challenge based on Aff-Wild2 and C-EXPR-DB datasets. In this\npaper, we present our methods and experimental results for the two competition\ntracks. Specifically, it can be summarized in the following four aspects: 1) To\nattain high-quality facial features, we train a Masked-Auto Encoder in a\nself-supervised manner. 2) We devise a temporal convergence module to capture\nthe temporal information between video frames and explore the impact of window\nsize and sequence length on each sub-task. 3) To facilitate the joint\noptimization of various sub-tasks, we explore the impact of sub-task joint\ntraining and feature fusion from individual tasks on each task performance\nimprovement. 4) We utilize curriculum learning to transition the model from\nrecognizing single expressions to recognizing compound expressions, thereby\nimproving the accuracy of compound expression recognition. Extensive\nexperiments demonstrate the superiority of our designs.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-sa/4.0/","blobId":"hoMODW3IUAj7ss1x_Mo3XCID76EvwCJJr7Sqek7ofH4","pdfSize":"665754"}
