{"id":"2407.05061","title":"A Study of Test-time Contrastive Concepts for Open-world,\n  Open-vocabulary Semantic Segmentation","authors":"Monika Wysocza\\'nska, Antonin Vobecky, Amaia Cardiel, Tomasz\n  Trzci\\'nski, Renaud Marlet, Andrei Bursuc, Oriane Sim\\'eoni","authorsParsed":[["Wysoczańska","Monika",""],["Vobecky","Antonin",""],["Cardiel","Amaia",""],["Trzciński","Tomasz",""],["Marlet","Renaud",""],["Bursuc","Andrei",""],["Siméoni","Oriane",""]],"versions":[{"version":"v1","created":"Sat, 6 Jul 2024 12:18:43 GMT"}],"updateDate":"2024-07-09","timestamp":1720268323000,"abstract":"  Recent VLMs, pre-trained on large amounts of image-text pairs to align both\nmodalities, have opened the way to open-vocabulary semantic segmentation. Given\nan arbitrary set of textual queries, image regions are assigned the closest\nquery in feature space. However, the usual setup expects the user to list all\npossible visual concepts that may occur in the image, typically all classes of\nbenchmark datasets, that act as negatives to each other. We consider here the\nmore challenging scenario of segmenting a single concept, given a textual\nprompt and nothing else. To achieve good results, besides contrasting with the\ngeneric 'background' text, we study different ways to generate query-specific\ntest-time contrastive textual concepts, which leverage either the distribution\nof text in the VLM's training set or crafted LLM prompts. We show the relevance\nof our approach using a new, specific metric.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}