{"id":"2408.05345","title":"Explainable AI Reloaded: Challenging the XAI Status Quo in the Era of\n  Large Language Models","authors":"Upol Ehsan, Mark O. Riedl","authorsParsed":[["Ehsan","Upol",""],["Riedl","Mark O.",""]],"versions":[{"version":"v1","created":"Fri, 9 Aug 2024 21:28:31 GMT"},{"version":"v2","created":"Tue, 13 Aug 2024 19:39:52 GMT"}],"updateDate":"2024-08-15","timestamp":1723238911000,"abstract":"  When the initial vision of Explainable (XAI) was articulated, the most\npopular framing was to open the (proverbial) \"black-box\" of AI so that we could\nunderstand the inner workings. With the advent of Large Language Models (LLMs),\nthe very ability to open the black-box is increasingly limited especially when\nit comes to non-AI expert end-users. In this paper, we challenge the assumption\nof \"opening\" the black-box in the LLM era and argue for a shift in our XAI\nexpectations. Highlighting the epistemic blind spots of an algorithm-centered\nXAI view, we argue that a human-centered perspective can be a path forward. We\noperationalize the argument by synthesizing XAI research along three\ndimensions: explainability outside the black-box, explainability around the\nedges of the black box, and explainability that leverages infrastructural\nseams. We conclude with takeaways that reflexively inform XAI as a domain.\n","subjects":["Computing Research Repository/Human-Computer Interaction","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}