{"id":"2407.14358","title":"Stable Audio Open","authors":"Zach Evans, Julian D. Parker, CJ Carr, Zack Zukowski, Josiah Taylor,\n  Jordi Pons","authorsParsed":[["Evans","Zach",""],["Parker","Julian D.",""],["Carr","CJ",""],["Zukowski","Zack",""],["Taylor","Josiah",""],["Pons","Jordi",""]],"versions":[{"version":"v1","created":"Fri, 19 Jul 2024 14:40:23 GMT"},{"version":"v2","created":"Wed, 31 Jul 2024 16:22:42 GMT"}],"updateDate":"2024-08-01","timestamp":1721400023000,"abstract":"  Open generative models are vitally important for the community, allowing for\nfine-tunes and serving as baselines when presenting new models. However, most\ncurrent text-to-audio models are private and not accessible for artists and\nresearchers to build upon. Here we describe the architecture and training\nprocess of a new open-weights text-to-audio model trained with Creative Commons\ndata. Our evaluation shows that the model's performance is competitive with the\nstate-of-the-art across various metrics. Notably, the reported FDopenl3 results\n(measuring the realism of the generations) showcase its potential for\nhigh-quality stereo sound synthesis at 44.1kHz.\n","subjects":["Computing Research Repository/Sound","Computing Research Repository/Artificial Intelligence","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"RH3cnqr85b6jqOrmTyy-p-NKnkrCqPxF33hcm31D0-w","pdfSize":"233101"}
