{"id":"2408.13698","title":"CNN-Transformer Rectified Collaborative Learning for Medical Image\n  Segmentation","authors":"Lanhu Wu, Miao Zhang, Yongri Piao, Zhenyan Yao, Weibing Sun, Feng\n  Tian, and Huchuan Lu","authorsParsed":[["Wu","Lanhu",""],["Zhang","Miao",""],["Piao","Yongri",""],["Yao","Zhenyan",""],["Sun","Weibing",""],["Tian","Feng",""],["Lu","Huchuan",""]],"versions":[{"version":"v1","created":"Sun, 25 Aug 2024 01:27:35 GMT"},{"version":"v2","created":"Tue, 27 Aug 2024 16:11:44 GMT"}],"updateDate":"2024-08-28","timestamp":1724549255000,"abstract":"  Automatic and precise medical image segmentation (MIS) is of vital importance\nfor clinical diagnosis and analysis. Current MIS methods mainly rely on the\nconvolutional neural network (CNN) or self-attention mechanism (Transformer)\nfor feature modeling. However, CNN-based methods suffer from the inaccurate\nlocalization owing to the limited global dependency while Transformer-based\nmethods always present the coarse boundary for the lack of local emphasis.\nAlthough some CNN-Transformer hybrid methods are designed to synthesize the\ncomplementary local and global information for better performance, the\ncombination of CNN and Transformer introduces numerous parameters and increases\nthe computation cost. To this end, this paper proposes a CNN-Transformer\nrectified collaborative learning (CTRCL) framework to learn stronger CNN-based\nand Transformer-based models for MIS tasks via the bi-directional knowledge\ntransfer between them. Specifically, we propose a rectified logit-wise\ncollaborative learning (RLCL) strategy which introduces the ground truth to\nadaptively select and rectify the wrong regions in student soft labels for\naccurate knowledge transfer in the logit space. We also propose a class-aware\nfeature-wise collaborative learning (CFCL) strategy to achieve effective\nknowledge transfer between CNN-based and Transformer-based models in the\nfeature space by granting their intermediate features the similar capability of\ncategory perception. Extensive experiments on three popular MIS benchmarks\ndemonstrate that our CTRCL outperforms most state-of-the-art collaborative\nlearning methods under different evaluation metrics.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}