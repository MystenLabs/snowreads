{"id":"2408.16285","title":"ART: Actually Robust Training","authors":"Sebastian Chwilczy\\'nski, Kacper Tr\\k{e}bacz, Karol Cyganik, Mateusz\n  Ma{\\l}ecki, Dariusz Brzezinski","authorsParsed":[["Chwilczyński","Sebastian",""],["Trębacz","Kacper",""],["Cyganik","Karol",""],["Małecki","Mateusz",""],["Brzezinski","Dariusz",""]],"versions":[{"version":"v1","created":"Thu, 29 Aug 2024 06:30:23 GMT"}],"updateDate":"2024-08-30","timestamp":1724913023000,"abstract":"  Current interest in deep learning captures the attention of many programmers\nand researchers. Unfortunately, the lack of a unified schema for developing\ndeep learning models results in methodological inconsistencies, unclear\ndocumentation, and problems with reproducibility. Some guidelines have been\nproposed, yet currently, they lack practical implementations. Furthermore,\nneural network training often takes on the form of trial and error, lacking a\nstructured and thoughtful process. To alleviate these issues, in this paper, we\nintroduce Art, a Python library designed to help automatically impose rules and\nstandards while developing deep learning pipelines. Art divides model\ndevelopment into a series of smaller steps of increasing complexity, each\nconcluded with a validation check improving the interpretability and robustness\nof the process. The current version of Art comes equipped with nine predefined\nsteps inspired by Andrej Karpathy's Recipe for Training Neural Networks, a\nvisualization dashboard, and integration with loggers such as Neptune. The code\nrelated to this paper is available at:\nhttps://github.com/SebChw/Actually-Robust-Training.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Neural and Evolutionary Computing"],"license":"http://creativecommons.org/licenses/by/4.0/"}