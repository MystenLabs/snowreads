{"id":"2408.09928","title":"DiscoNeRF: Class-Agnostic Object Field for 3D Object Discovery","authors":"Corentin Dumery, Aoxiang Fan, Ren Li, Nicolas Talabot, Pascal Fua","authorsParsed":[["Dumery","Corentin",""],["Fan","Aoxiang",""],["Li","Ren",""],["Talabot","Nicolas",""],["Fua","Pascal",""]],"versions":[{"version":"v1","created":"Mon, 19 Aug 2024 12:07:24 GMT"},{"version":"v2","created":"Fri, 6 Sep 2024 07:20:10 GMT"}],"updateDate":"2024-09-09","timestamp":1724069244000,"abstract":"  Neural Radiance Fields (NeRFs) have become a powerful tool for modeling 3D\nscenes from multiple images. However, NeRFs remain difficult to segment into\nsemantically meaningful regions. Previous approaches to 3D segmentation of\nNeRFs either require user interaction to isolate a single object, or they rely\non 2D semantic masks with a limited number of classes for supervision. As a\nconsequence, they generalize poorly to class-agnostic masks automatically\ngenerated in real scenes. This is attributable to the ambiguity arising from\nzero-shot segmentation, yielding inconsistent masks across views. In contrast,\nwe propose a method that is robust to inconsistent segmentations and\nsuccessfully decomposes the scene into a set of objects of any class. By\nintroducing a limited number of competing object slots against which masks are\nmatched, a meaningful object representation emerges that best explains the 2D\nsupervision and minimizes an additional regularization term. Our experiments\ndemonstrate the ability of our method to generate 3D panoptic segmentations on\ncomplex scenes, and extract high-quality 3D assets from NeRFs that can then be\nused in virtual 3D environments.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Graphics"],"license":"http://creativecommons.org/licenses/by/4.0/"}