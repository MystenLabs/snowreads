{"id":"2407.09958","title":"Partner in Crime: Boosting Targeted Poisoning Attacks against Federated\n  Learning","authors":"Shihua Sun, Shridatt Sugrim, Angelos Stavrou, Haining Wang","authorsParsed":[["Sun","Shihua",""],["Sugrim","Shridatt",""],["Stavrou","Angelos",""],["Wang","Haining",""]],"versions":[{"version":"v1","created":"Sat, 13 Jul 2024 17:59:08 GMT"}],"updateDate":"2024-07-16","timestamp":1720893548000,"abstract":"  Federated Learning (FL) exposes vulnerabilities to targeted poisoning attacks\nthat aim to cause misclassification specifically from the source class to the\ntarget class. However, using well-established defense frameworks, the poisoning\nimpact of these attacks can be greatly mitigated. We introduce a generalized\npre-training stage approach to Boost Targeted Poisoning Attacks against FL,\ncalled BoTPA. Its design rationale is to leverage the model update\ncontributions of all data points, including ones outside of the source and\ntarget classes, to construct an Amplifier set, in which we falsify the data\nlabels before the FL training process, as a means to boost attacks. We\ncomprehensively evaluate the effectiveness and compatibility of BoTPA on\nvarious targeted poisoning attacks. Under data poisoning attacks, our\nevaluations reveal that BoTPA can achieve a median Relative Increase in Attack\nSuccess Rate (RI-ASR) between 15.3% and 36.9% across all possible source-target\nclass combinations, with varying percentages of malicious clients, compared to\nits baseline. In the context of model poisoning, BoTPA attains RI-ASRs ranging\nfrom 13.3% to 94.7% in the presence of the Krum and Multi-Krum defenses, from\n2.6% to 49.2% under the Median defense, and from 2.9% to 63.5% under the Flame\ndefense.\n","subjects":["Computing Research Repository/Cryptography and Security","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}