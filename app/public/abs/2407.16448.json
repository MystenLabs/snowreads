{"id":"2407.16448","title":"MonoWAD: Weather-Adaptive Diffusion Model for Robust Monocular 3D Object\n  Detection","authors":"Youngmin Oh, Hyung-Il Kim, Seong Tae Kim, Jung Uk Kim","authorsParsed":[["Oh","Youngmin",""],["Kim","Hyung-Il",""],["Kim","Seong Tae",""],["Kim","Jung Uk",""]],"versions":[{"version":"v1","created":"Tue, 23 Jul 2024 12:58:49 GMT"}],"updateDate":"2024-07-24","timestamp":1721739529000,"abstract":"  Monocular 3D object detection is an important challenging task in autonomous\ndriving. Existing methods mainly focus on performing 3D detection in ideal\nweather conditions, characterized by scenarios with clear and optimal\nvisibility. However, the challenge of autonomous driving requires the ability\nto handle changes in weather conditions, such as foggy weather, not just clear\nweather. We introduce MonoWAD, a novel weather-robust monocular 3D object\ndetector with a weather-adaptive diffusion model. It contains two components:\n(1) the weather codebook to memorize the knowledge of the clear weather and\ngenerate a weather-reference feature for any input, and (2) the\nweather-adaptive diffusion model to enhance the feature representation of the\ninput feature by incorporating a weather-reference feature. This serves an\nattention role in indicating how much improvement is needed for the input\nfeature according to the weather conditions. To achieve this goal, we introduce\na weather-adaptive enhancement loss to enhance the feature representation under\nboth clear and foggy weather conditions. Extensive experiments under various\nweather conditions demonstrate that MonoWAD achieves weather-robust monocular\n3D object detection. The code and dataset are released at\nhttps://github.com/VisualAIKHU/MonoWAD.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}