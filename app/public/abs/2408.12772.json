{"id":"2408.12772","title":"Symmetric masking strategy enhances the performance of Masked Image\n  Modeling","authors":"Khanh-Binh Nguyen and Chae Jung Park","authorsParsed":[["Nguyen","Khanh-Binh",""],["Park","Chae Jung",""]],"versions":[{"version":"v1","created":"Fri, 23 Aug 2024 00:15:43 GMT"}],"updateDate":"2024-08-26","timestamp":1724372143000,"abstract":"  Masked Image Modeling (MIM) is a technique in self-supervised learning that\nfocuses on acquiring detailed visual representations from unlabeled images by\nestimating the missing pixels in randomly masked sections. It has proven to be\na powerful tool for the preliminary training of Vision Transformers (ViTs),\nyielding impressive results across various tasks. Nevertheless, most MIM\nmethods heavily depend on the random masking strategy to formulate the pretext\ntask. This strategy necessitates numerous trials to ascertain the optimal\ndropping ratio, which can be resource-intensive, requiring the model to be\npre-trained for anywhere between 800 to 1600 epochs. Furthermore, this approach\nmay not be suitable for all datasets. In this work, we propose a new masking\nstrategy that effectively helps the model capture global and local features.\nBased on this masking strategy, SymMIM, our proposed training pipeline for MIM\nis introduced. SymMIM achieves a new SOTA accuracy of 85.9\\% on ImageNet using\nViT-Large and surpasses previous SOTA across downstream tasks such as image\nclassification, semantic segmentation, object detection, instance segmentation\ntasks, and so on.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"PnJIOxGDhXl-ICaX48EZaVY2d8tQ9ldb0hjY-Og8owA","pdfSize":"4211237"}
