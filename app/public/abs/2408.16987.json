{"id":"2408.16987","title":"From Model Explanation to Data Misinterpretation: Uncovering the\n  Pitfalls of Post Hoc Explainers in Business Research","authors":"Ronilo Ragodos, Tong Wang, Lu Feng, Yu (Jeffrey) Hu","authorsParsed":[["Ragodos","Ronilo","","Jeffrey"],["Wang","Tong","","Jeffrey"],["Feng","Lu","","Jeffrey"],["Yu","","","Jeffrey"],["Hu","",""]],"versions":[{"version":"v1","created":"Fri, 30 Aug 2024 03:22:35 GMT"}],"updateDate":"2024-09-02","timestamp":1724988155000,"abstract":"  Machine learning models have been increasingly used in business research.\nHowever, most state-of-the-art machine learning models, such as deep neural\nnetworks and XGBoost, are black boxes in nature. Therefore, post hoc explainers\nthat provide explanations for machine learning models by, for example,\nestimating numerical importance of the input features, have been gaining wide\nusage. Despite the intended use of post hoc explainers being explaining machine\nlearning models, we found a growing trend in business research where post hoc\nexplanations are used to draw inferences about the data. In this work, we\ninvestigate the validity of such use. Specifically, we investigate with\nextensive experiments whether the explanations obtained by the two most popular\npost hoc explainers, SHAP and LIME, provide correct information about the true\nmarginal effects of X on Y in the data, which we call data-alignment. We then\nidentify what factors influence the alignment of explanations. Finally, we\npropose a set of mitigation strategies to improve the data-alignment of\nexplanations and demonstrate their effectiveness with real-world data in an\neconometric context. In spite of this effort, we nevertheless conclude that it\nis often not appropriate to infer data insights from post hoc explanations. We\narticulate appropriate alternative uses, the most important of which is to\nfacilitate the proposition and subsequent empirical investigation of\nhypotheses. The ultimate goal of this paper is to caution business researchers\nagainst translating post hoc explanations of machine learning models into\npotentially false insights and understanding of data.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}