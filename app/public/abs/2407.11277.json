{"id":"2407.11277","title":"Target conversation extraction: Source separation using turn-taking\n  dynamics","authors":"Tuochao Chen, Qirui Wang, Bohan Wu, Malek Itani, Sefik Emre Eskimez,\n  Takuya Yoshioka, Shyamnath Gollakota","authorsParsed":[["Chen","Tuochao",""],["Wang","Qirui",""],["Wu","Bohan",""],["Itani","Malek",""],["Eskimez","Sefik Emre",""],["Yoshioka","Takuya",""],["Gollakota","Shyamnath",""]],"versions":[{"version":"v1","created":"Mon, 15 Jul 2024 22:55:27 GMT"},{"version":"v2","created":"Mon, 29 Jul 2024 19:35:36 GMT"}],"updateDate":"2024-07-31","timestamp":1721084127000,"abstract":"  Extracting the speech of participants in a conversation amidst interfering\nspeakers and noise presents a challenging problem. In this paper, we introduce\nthe novel task of target conversation extraction, where the goal is to extract\nthe audio of a target conversation based on the speaker embedding of one of its\nparticipants. To accomplish this, we propose leveraging temporal patterns\ninherent in human conversations, particularly turn-taking dynamics, which\nuniquely characterize speakers engaged in conversation and distinguish them\nfrom interfering speakers and noise. Using neural networks, we show the\nfeasibility of our approach on English and Mandarin conversation datasets. In\nthe presence of interfering speakers, our results show an 8.19 dB improvement\nin signal-to-noise ratio for 2-speaker conversations and a 7.92 dB improvement\nfor 2-4-speaker conversations. Code, dataset available at\nhttps://github.com/chentuochao/Target-Conversation-Extraction.\n","subjects":["Computing Research Repository/Computation and Language","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by/4.0/"}