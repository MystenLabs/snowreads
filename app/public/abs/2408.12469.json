{"id":"2408.12469","title":"Envisioning Class Entity Reasoning by Large Language Models for Few-shot\n  Learning","authors":"Mushui Liu, Fangtai Wu, Bozheng Li, Ziqian Lu, Yunlong Yu, Xi Li","authorsParsed":[["Liu","Mushui",""],["Wu","Fangtai",""],["Li","Bozheng",""],["Lu","Ziqian",""],["Yu","Yunlong",""],["Li","Xi",""]],"versions":[{"version":"v1","created":"Thu, 22 Aug 2024 15:10:20 GMT"}],"updateDate":"2024-08-23","timestamp":1724339420000,"abstract":"  Few-shot learning (FSL) aims to recognize new concepts using a limited number\nof visual samples. Existing approaches attempt to incorporate semantic\ninformation into the limited visual data for category understanding. However,\nthese methods often enrich class-level feature representations with abstract\ncategory names, failing to capture the nuanced features essential for effective\ngeneralization. To address this issue, we propose a novel framework for FSL,\nwhich incorporates both the abstract class semantics and the concrete class\nentities extracted from Large Language Models (LLMs), to enhance the\nrepresentation of the class prototypes. Specifically, our framework composes a\nSemantic-guided Visual Pattern Extraction (SVPE) module and a\nPrototype-Calibration (PC) module, where the SVPE meticulously extracts\nsemantic-aware visual patterns across diverse scales, while the PC module\nseamlessly integrates these patterns to refine the visual prototype, enhancing\nits representativeness. Extensive experiments on four few-shot classification\nbenchmarks and the BSCD-FSL cross-domain benchmarks showcase remarkable\nadvancements over the current state-of-the-art methods. Notably, for the\nchallenging one-shot setting, our approach, utilizing the ResNet-12 backbone,\nachieves an impressive average improvement of 1.95% over the second-best\ncompetitor.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}