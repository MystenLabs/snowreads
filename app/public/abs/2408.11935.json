{"id":"2408.11935","title":"Explainable Anomaly Detection: Counterfactual driven What-If Analysis","authors":"Logan Cummins, Alexander Sommers, Sudip Mittal, Shahram Rahimi, Maria\n  Seale, Joseph Jaboure and Thomas Arnold","authorsParsed":[["Cummins","Logan",""],["Sommers","Alexander",""],["Mittal","Sudip",""],["Rahimi","Shahram",""],["Seale","Maria",""],["Jaboure","Joseph",""],["Arnold","Thomas",""]],"versions":[{"version":"v1","created":"Wed, 21 Aug 2024 18:38:59 GMT"}],"updateDate":"2024-08-23","timestamp":1724265539000,"abstract":"  There exists three main areas of study inside of the field of predictive\nmaintenance: anomaly detection, fault diagnosis, and remaining useful life\nprediction. Notably, anomaly detection alerts the stakeholder that an anomaly\nis occurring. This raises two fundamental questions: what is causing the fault\nand how can we fix it? Inside of the field of explainable artificial\nintelligence, counterfactual explanations can give that information in the form\nof what changes to make to put the data point into the opposing class, in this\ncase \"healthy\". The suggestions are not always actionable which may raise the\ninterest in asking \"what if we do this instead?\" In this work, we provide a\nproof of concept for utilizing counterfactual explanations as what-if analysis.\nWe perform this on the PRONOSTIA dataset with a temporal convolutional network\nas the anomaly detector. Our method presents the counterfactuals in the form of\na what-if analysis for this base problem to inspire future work for more\ncomplex systems and scenarios.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Human-Computer Interaction"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"_HgwZrTFI4J5lIfhJuKkG461rwks3sRUHc5tHSsGtns","pdfSize":"2086143"}
