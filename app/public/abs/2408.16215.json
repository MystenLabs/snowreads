{"id":"2408.16215","title":"Adversarial Network Optimization under Bandit Feedback: Maximizing\n  Utility in Non-Stationary Multi-Hop Networks","authors":"Yan Dai and Longbo Huang","authorsParsed":[["Dai","Yan",""],["Huang","Longbo",""]],"versions":[{"version":"v1","created":"Thu, 29 Aug 2024 02:18:28 GMT"}],"updateDate":"2024-08-30","timestamp":1724897908000,"abstract":"  Stochastic Network Optimization (SNO) concerns scheduling in stochastic\nqueueing systems. It has been widely studied in network theory. Classical SNO\nalgorithms require network conditions to be stationary with time, which fails\nto capture the non-stationary components in many real-world scenarios. Many\nexisting algorithms also assume knowledge of network conditions before\ndecision, which rules out applications where unpredictability presents.\n  Motivated by these issues, we consider Adversarial Network Optimization (ANO)\nunder bandit feedback. Specifically, we consider the task of *i)* maximizing\nsome unknown and time-varying utility function associated to scheduler's\nactions, where *ii)* the underlying network is a non-stationary multi-hop one\nwhose conditions change arbitrarily with time, and *iii)* only bandit feedback\n(effect of actually deployed actions) is revealed after decisions. Our proposed\n`UMO2` algorithm ensures network stability and also matches the utility\nmaximization performance of any \"mildly varying\" reference policy up to a\npolynomially decaying gap. To our knowledge, no previous ANO algorithm handled\nmulti-hop networks or achieved utility guarantees under bandit feedback,\nwhereas ours can do both.\n  Technically, our method builds upon a novel integration of online learning\ninto Lyapunov analyses: To handle complex inter-dependencies among queues in\nmulti-hop networks, we propose meticulous techniques to balance online learning\nand Lyapunov arguments. To tackle the learning obstacles due to potentially\nunbounded queue sizes, we design a new online linear optimization algorithm\nthat automatically adapts to loss magnitudes. To maximize utility, we propose a\nbandit convex optimization algorithm with novel queue-dependent learning rate\nscheduling that suites drastically varying queue lengths. Our new insights in\nonline learning can be of independent interest.\n","subjects":["Mathematics/Optimization and Control","Computing Research Repository/Machine Learning","Computing Research Repository/Performance","Computing Research Repository/Systems and Control","Electrical Engineering and Systems Science/Systems and Control"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}