{"id":"2408.16502","title":"LLMs vs Established Text Augmentation Techniques for Classification:\n  When do the Benefits Outweight the Costs?","authors":"Jan Cegin, Jakub Simko, Peter Brusilovsky","authorsParsed":[["Cegin","Jan",""],["Simko","Jakub",""],["Brusilovsky","Peter",""]],"versions":[{"version":"v1","created":"Thu, 29 Aug 2024 13:01:42 GMT"}],"updateDate":"2024-08-30","timestamp":1724936502000,"abstract":"  The generative large language models (LLMs) are increasingly being used for\ndata augmentation tasks, where text samples are LLM-paraphrased and then used\nfor classifier fine-tuning. However, a research that would confirm a clear\ncost-benefit advantage of LLMs over more established augmentation methods is\nlargely missing. To study if (and when) is the LLM-based augmentation\nadvantageous, we compared the effects of recent LLM augmentation methods with\nestablished ones on 6 datasets, 3 classifiers and 2 fine-tuning methods. We\nalso varied the number of seeds and collected samples to better explore the\ndownstream model accuracy space. Finally, we performed a cost-benefit analysis\nand show that LLM-based methods are worthy of deployment only when very small\nnumber of seeds is used. Moreover, in many cases, established methods lead to\nsimilar or better model accuracies.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}