{"id":"2408.15641","title":"MMDRFuse: Distilled Mini-Model with Dynamic Refresh for Multi-Modality\n  Image Fusion","authors":"Yanglin Deng, Tianyang Xu, Chunyang Cheng, Xiao-Jun Wu, Josef Kittler","authorsParsed":[["Deng","Yanglin",""],["Xu","Tianyang",""],["Cheng","Chunyang",""],["Wu","Xiao-Jun",""],["Kittler","Josef",""]],"versions":[{"version":"v1","created":"Wed, 28 Aug 2024 08:52:33 GMT"}],"updateDate":"2024-08-29","timestamp":1724835153000,"abstract":"  In recent years, Multi-Modality Image Fusion (MMIF) has been applied to many\nfields, which has attracted many scholars to endeavour to improve the fusion\nperformance. However, the prevailing focus has predominantly been on the\narchitecture design, rather than the training strategies. As a low-level vision\ntask, image fusion is supposed to quickly deliver output images for observation\nand supporting downstream tasks. Thus, superfluous computational and storage\noverheads should be avoided. In this work, a lightweight Distilled Mini-Model\nwith a Dynamic Refresh strategy (MMDRFuse) is proposed to achieve this\nobjective. To pursue model parsimony, an extremely small convolutional network\nwith a total of 113 trainable parameters (0.44 KB) is obtained by three\ncarefully designed supervisions. First, digestible distillation is constructed\nby emphasising external spatial feature consistency, delivering soft\nsupervision with balanced details and saliency for the target network. Second,\nwe develop a comprehensive loss to balance the pixel, gradient, and perception\nclues from the source images. Third, an innovative dynamic refresh training\nstrategy is used to collaborate history parameters and current supervision\nduring training, together with an adaptive adjust function to optimise the\nfusion network. Extensive experiments on several public datasets demonstrate\nthat our method exhibits promising advantages in terms of model efficiency and\ncomplexity, with superior performance in multiple image fusion tasks and\ndownstream pedestrian detection application. The code of this work is publicly\navailable at https://github.com/yanglinDeng/MMDRFuse.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}