{"id":"2407.09136","title":"Stepwise Verification and Remediation of Student Reasoning Errors with\n  Large Language Model Tutors","authors":"Nico Daheim, Jakub Macina, Manu Kapur, Iryna Gurevych, Mrinmaya Sachan","authorsParsed":[["Daheim","Nico",""],["Macina","Jakub",""],["Kapur","Manu",""],["Gurevych","Iryna",""],["Sachan","Mrinmaya",""]],"versions":[{"version":"v1","created":"Fri, 12 Jul 2024 10:11:40 GMT"}],"updateDate":"2024-07-15","timestamp":1720779100000,"abstract":"  Large language models (LLMs) present an opportunity to scale high-quality\npersonalized education to all. A promising approach towards this means is to\nbuild dialog tutoring models that scaffold students' problem-solving. However,\neven though existing LLMs perform well in solving reasoning questions, they\nstruggle to precisely detect student's errors and tailor their feedback to\nthese errors. Inspired by real-world teaching practice where teachers identify\nstudent errors and customize their response based on them, we focus on\nverifying student solutions and show how grounding to such verification\nimproves the overall quality of tutor response generation. We collect a dataset\nof 1K stepwise math reasoning chains with the first error step annotated by\nteachers. We show empirically that finding the mistake in a student solution is\nchallenging for current models. We propose and evaluate several verifiers for\ndetecting these errors. Using both automatic and human evaluation we show that\nthe student solution verifiers steer the generation model towards highly\ntargeted responses to student errors which are more often correct with less\nhallucinations compared to existing baselines.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}