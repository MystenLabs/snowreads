{"id":"2407.08260","title":"SALSA: Swift Adaptive Lightweight Self-Attention for Enhanced LiDAR\n  Place Recognition","authors":"Raktim Gautam Goswami, Naman Patel, Prashanth Krishnamurthy, Farshad\n  Khorrami","authorsParsed":[["Goswami","Raktim Gautam",""],["Patel","Naman",""],["Krishnamurthy","Prashanth",""],["Khorrami","Farshad",""]],"versions":[{"version":"v1","created":"Thu, 11 Jul 2024 08:00:19 GMT"},{"version":"v2","created":"Tue, 30 Jul 2024 12:54:59 GMT"}],"updateDate":"2024-07-31","timestamp":1720684819000,"abstract":"  Large-scale LiDAR mappings and localization leverage place recognition\ntechniques to mitigate odometry drifts, ensuring accurate mapping. These\ntechniques utilize scene representations from LiDAR point clouds to identify\npreviously visited sites within a database. Local descriptors, assigned to each\npoint within a point cloud, are aggregated to form a scene representation for\nthe point cloud. These descriptors are also used to re-rank the retrieved point\nclouds based on geometric fitness scores. We propose SALSA, a novel,\nlightweight, and efficient framework for LiDAR place recognition. It consists\nof a Sphereformer backbone that uses radial window attention to enable\ninformation aggregation for sparse distant points, an adaptive self-attention\nlayer to pool local descriptors into tokens, and a multi-layer-perceptron Mixer\nlayer for aggregating the tokens to generate a scene descriptor. The proposed\nframework outperforms existing methods on various LiDAR place recognition\ndatasets in terms of both retrieval and metric localization while operating in\nreal-time.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Robotics"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}