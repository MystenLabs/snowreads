{"id":"2407.09726","title":"On Mitigating Code LLM Hallucinations with API Documentation","authors":"Nihal Jain, Robert Kwiatkowski, Baishakhi Ray, Murali Krishna\n  Ramanathan, Varun Kumar","authorsParsed":[["Jain","Nihal",""],["Kwiatkowski","Robert",""],["Ray","Baishakhi",""],["Ramanathan","Murali Krishna",""],["Kumar","Varun",""]],"versions":[{"version":"v1","created":"Sat, 13 Jul 2024 00:16:26 GMT"}],"updateDate":"2024-07-17","timestamp":1720829786000,"abstract":"  In this study, we address the issue of API hallucinations in various software\nengineering contexts. We introduce CloudAPIBench, a new benchmark designed to\nmeasure API hallucination occurrences. CloudAPIBench also provides annotations\nfor frequencies of API occurrences in the public domain, allowing us to study\nAPI hallucinations at various frequency levels. Our findings reveal that Code\nLLMs struggle with low frequency APIs: for e.g., GPT-4o achieves only 38.58%\nvalid low frequency API invocations. We demonstrate that Documentation\nAugmented Generation (DAG) significantly improves performance for low frequency\nAPIs (increase to 47.94% with DAG) but negatively impacts high frequency APIs\nwhen using sub-optimal retrievers (a 39.02% absolute drop). To mitigate this,\nwe propose to intelligently trigger DAG where we check against an API index or\nleverage Code LLMs' confidence scores to retrieve only when needed. We\ndemonstrate that our proposed methods enhance the balance between low and high\nfrequency API performance, resulting in more reliable API invocations (8.20%\nabsolute improvement on CloudAPIBench for GPT-4o).\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}