{"id":"2407.13994","title":"Evidential Deep Learning for Interatomic Potentials","authors":"Han Xu, Taoyong Cui, Chenyu Tang, Dongzhan Zhou, Yuqiang Li, Xiang\n  Gao, Xingao Gong, Wanli Ouyang, Shufei Zhang, Mao Su","authorsParsed":[["Xu","Han",""],["Cui","Taoyong",""],["Tang","Chenyu",""],["Zhou","Dongzhan",""],["Li","Yuqiang",""],["Gao","Xiang",""],["Gong","Xingao",""],["Ouyang","Wanli",""],["Zhang","Shufei",""],["Su","Mao",""]],"versions":[{"version":"v1","created":"Fri, 19 Jul 2024 02:54:36 GMT"}],"updateDate":"2024-07-22","timestamp":1721357676000,"abstract":"  Machine learning interatomic potentials (MLIPs) have been widely used to\nfacilitate large scale molecular simulations with ab initio level accuracy.\nHowever, MLIP-based molecular simulations frequently encounter the issue of\ncollapse due to decreased prediction accuracy for out-of-distribution (OOD)\ndata. To mitigate this issue, it is crucial to enrich the training set with\nactive learning, where uncertainty estimation serves as an effective method for\nidentifying and collecting OOD data. Therefore, a feasible method for\nuncertainty estimation in MLIPs is desired. The existing methods either require\nexpensive computations or compromise prediction accuracy. In this work, we\nintroduce evidential deep learning for interatomic potentials (eIP) with a\nphysics-inspired design. Our experiments demonstrate that eIP consistently\ngenerates reliable uncertainties without incurring notable additional\ncomputational costs, while the prediction accuracy remains unchanged.\nFurthermore, we present an eIP-based active learning workflow, where eIP is\nused not only to estimate the uncertainty of molecular data but also to perform\nuncertainty-driven dynamics simulations. Our findings show that eIP enables\nefficient sampling for a more diverse dataset, thereby advancing the\nfeasibility of MLIP-based molecular simulations.\n","subjects":["Physics/Computational Physics"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}