{"id":"2407.01825","title":"Empirical Tests of Optimization Assumptions in Deep Learning","authors":"Hoang Tran, Qinzi Zhang, Ashok Cutkosky","authorsParsed":[["Tran","Hoang",""],["Zhang","Qinzi",""],["Cutkosky","Ashok",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 21:56:54 GMT"}],"updateDate":"2024-07-03","timestamp":1719871014000,"abstract":"  There is a significant gap between our theoretical understanding of\noptimization algorithms used in deep learning and their practical performance.\nTheoretical development usually focuses on proving convergence guarantees under\na variety of different assumptions, which are themselves often chosen based on\na rough combination of intuitive match to practice and analytical convenience.\nThe theory/practice gap may then arise because of the failure to prove a\ntheorem under such assumptions, or because the assumptions do not reflect\nreality. In this paper, we carefully measure the degree to which these\nassumptions are capable of explaining modern optimization algorithms by\ndeveloping new empirical metrics that closely track the key quantities that\nmust be controlled in theoretical analysis. All of our tested assumptions\n(including typical modern assumptions based on bounds on the Hessian) fail to\nreliably capture optimization performance. This highlights a need for new\nempirical verification of analytical assumptions used in theoretical analysis.\n","subjects":["Computing Research Repository/Machine Learning","Mathematics/Optimization and Control"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"2scJBOzqNeQ4Qomq2JcRebj7PQoj7YJNiOfHDRZ_8vY","pdfSize":"8570123"}
