{"id":"2407.05969","title":"Deform-Mamba Network for MRI Super-Resolution","authors":"Zexin Ji, Beiji Zou, Xiaoyan Kui, Pierre Vera, Su Ruan","authorsParsed":[["Ji","Zexin",""],["Zou","Beiji",""],["Kui","Xiaoyan",""],["Vera","Pierre",""],["Ruan","Su",""]],"versions":[{"version":"v1","created":"Mon, 8 Jul 2024 14:07:26 GMT"}],"updateDate":"2024-07-09","timestamp":1720447646000,"abstract":"  In this paper, we propose a new architecture, called Deform-Mamba, for MR\nimage super-resolution. Unlike conventional CNN or Transformer-based\nsuper-resolution approaches which encounter challenges related to the local\nrespective field or heavy computational cost, our approach aims to effectively\nexplore the local and global information of images. Specifically, we develop a\nDeform-Mamba encoder which is composed of two branches, modulated deform block\nand vision Mamba block. We also design a multi-view context module in the\nbottleneck layer to explore the multi-view contextual content. Thanks to the\nextracted features of the encoder, which include content-adaptive local and\nefficient global information, the vision Mamba decoder finally generates\nhigh-quality MR images. Moreover, we introduce a contrastive edge loss to\npromote the reconstruction of edge and contrast related content. Quantitative\nand qualitative experimental results indicate that our approach on IXI and\nfastMRI datasets achieves competitive performance.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}