{"id":"2408.13438","title":"Explainable Concept Generation through Vision-Language Preference\n  Learning","authors":"Aditya Taparia, Som Sagar, Ransalu Senanayake","authorsParsed":[["Taparia","Aditya",""],["Sagar","Som",""],["Senanayake","Ransalu",""]],"versions":[{"version":"v1","created":"Sat, 24 Aug 2024 02:26:42 GMT"}],"updateDate":"2024-08-27","timestamp":1724466402000,"abstract":"  Concept-based explanations have become a popular choice for explaining deep\nneural networks post-hoc because, unlike most other explainable AI techniques,\nthey can be used to test high-level visual \"concepts\" that are not directly\nrelated to feature attributes. For instance, the concept of \"stripes\" is\nimportant to classify an image as a zebra. Concept-based explanation methods,\nhowever, require practitioners to guess and collect multiple candidate concept\nimage sets, which can often be imprecise and labor-intensive. Addressing this\nlimitation, in this paper, we frame concept image set creation as an image\ngeneration problem. However, since naively using a generative model does not\nresult in meaningful concepts, we devise a reinforcement learning-based\npreference optimization algorithm that fine-tunes the vision-language\ngenerative model from approximate textual descriptions of concepts. Through a\nseries of experiments, we demonstrate the capability of our method to\narticulate complex, abstract concepts that are otherwise challenging to craft\nmanually. In addition to showing the efficacy and reliability of our method, we\nshow how our method can be used as a diagnostic tool for analyzing neural\nnetworks.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}