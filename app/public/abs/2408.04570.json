{"id":"2408.04570","title":"Mathematical Programming For Adaptive Experiments","authors":"Ethan Che, Daniel R. Jiang, Hongseok Namkoong, Jimmy Wang","authorsParsed":[["Che","Ethan",""],["Jiang","Daniel R.",""],["Namkoong","Hongseok",""],["Wang","Jimmy",""]],"versions":[{"version":"v1","created":"Thu, 8 Aug 2024 16:29:09 GMT"}],"updateDate":"2024-08-09","timestamp":1723134549000,"abstract":"  Adaptive experimentation can significantly improve statistical power, but\nstandard algorithms overlook important practical issues including batched and\ndelayed feedback, personalization, non-stationarity, multiple objectives, and\nconstraints. To address these issues, the current algorithm design paradigm\ncrafts tailored methods for each problem instance. Since it is infeasible to\ndevise novel algorithms for every real-world instance, practitioners often have\nto resort to suboptimal approximations that do not address all of their\nchallenges. Moving away from developing bespoke algorithms for each setting, we\npresent a mathematical programming view of adaptive experimentation that can\nflexibly incorporate a wide range of objectives, constraints, and statistical\nprocedures. By formulating a dynamic program in the batched limit, our modeling\nframework enables the use of scalable optimization methods (e.g., SGD and\nauto-differentiation) to solve for treatment allocations. We evaluate our\nframework on benchmarks modeled after practical challenges such as\nnon-stationarity, personalization, multi-objectives, and constraints. Unlike\nbespoke algorithms such as modified variants of Thomson sampling, our\nmathematical programming approach provides remarkably robust performance across\ninstances.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}