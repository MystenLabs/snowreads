{"id":"2407.03275","title":"Policy-guided Monte Carlo on general state spaces: Application to\n  glass-forming mixtures","authors":"Leonardo Galliano, Riccardo Rende, Daniele Coslovich","authorsParsed":[["Galliano","Leonardo",""],["Rende","Riccardo",""],["Coslovich","Daniele",""]],"versions":[{"version":"v1","created":"Wed, 3 Jul 2024 17:00:59 GMT"},{"version":"v2","created":"Thu, 22 Aug 2024 15:53:14 GMT"}],"updateDate":"2024-08-23","timestamp":1720026059000,"abstract":"  Policy-guided Monte Carlo is an adaptive method to simulate classical\ninteracting systems. It adjusts the proposal distribution of the\nMetropolis-Hastings algorithm to maximize the sampling efficiency, using a\nformalism inspired by reinforcement learning. In this work, we first extend the\npolicy-guided method to deal with a general state space, comprising, for\ninstance, both discrete and continuous degrees of freedom, and then apply it to\na few paradigmatic models of glass-forming mixtures. We assess the efficiency\nof a set of physically inspired moves whose proposal distributions are\noptimized through on-policy learning. Compared to conventional Monte Carlo\nmethods, the optimized proposals are two orders of magnitude faster for an\nadditive soft sphere mixture but yield a much more limited speed-up for the\nwell-studied Kob-Andersen model. We discuss the current limitations of the\nmethod and suggest possible ways to improve it.\n","subjects":["Condensed Matter/Soft Condensed Matter","Condensed Matter/Statistical Mechanics"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}