{"id":"2408.10819","title":"Exploiting Large Language Models Capabilities for Question Answer-Driven\n  Knowledge Graph Completion Across Static and Temporal Domains","authors":"Rui Yang and Jiahao Zhu and Jianping Man and Li Fang and Yi Zhou","authorsParsed":[["Yang","Rui",""],["Zhu","Jiahao",""],["Man","Jianping",""],["Fang","Li",""],["Zhou","Yi",""]],"versions":[{"version":"v1","created":"Tue, 20 Aug 2024 13:13:41 GMT"}],"updateDate":"2024-08-21","timestamp":1724159621000,"abstract":"  Knowledge graph completion (KGC) aims to identify missing triples in a\nknowledge graph (KG). This is typically achieved through tasks such as link\nprediction and instance completion. However, these methods often focus on\neither static knowledge graphs (SKGs) or temporal knowledge graphs (TKGs),\naddressing only within-scope triples. This paper introduces a new generative\ncompletion framework called Generative Subgraph-based KGC (GS-KGC). GS-KGC\nemploys a question-answering format to directly generate target entities,\naddressing the challenge of questions having multiple possible answers. We\npropose a strategy that extracts subgraphs centered on entities and\nrelationships within the KG, from which negative samples and neighborhood\ninformation are separately obtained to address the one-to-many problem. Our\nmethod generates negative samples using known facts to facilitate the discovery\nof new information. Furthermore, we collect and refine neighborhood path data\nof known entities, providing contextual information to enhance reasoning in\nlarge language models (LLMs). Our experiments evaluated the proposed method on\nfour SKGs and two TKGs, achieving state-of-the-art Hits@1 metrics on five\ndatasets. Analysis of the results shows that GS-KGC can discover new triples\nwithin existing KGs and generate new facts beyond the closed KG, effectively\nbridging the gap between closed-world and open-world KGC.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}