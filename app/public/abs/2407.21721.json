{"id":"2407.21721","title":"Open-Vocabulary Audio-Visual Semantic Segmentation","authors":"Ruohao Guo, Liao Qu, Dantong Niu, Yanyu Qi, Wenzhen Yue, Ji Shi, Bowei\n  Xing, Xianghua Ying","authorsParsed":[["Guo","Ruohao",""],["Qu","Liao",""],["Niu","Dantong",""],["Qi","Yanyu",""],["Yue","Wenzhen",""],["Shi","Ji",""],["Xing","Bowei",""],["Ying","Xianghua",""]],"versions":[{"version":"v1","created":"Wed, 31 Jul 2024 16:14:09 GMT"}],"updateDate":"2024-08-01","timestamp":1722442449000,"abstract":"  Audio-visual semantic segmentation (AVSS) aims to segment and classify\nsounding objects in videos with acoustic cues. However, most approaches operate\non the close-set assumption and only identify pre-defined categories from\ntraining data, lacking the generalization ability to detect novel categories in\npractical applications. In this paper, we introduce a new task: open-vocabulary\naudio-visual semantic segmentation, extending AVSS task to open-world scenarios\nbeyond the annotated label space. This is a more challenging task that requires\nrecognizing all categories, even those that have never been seen nor heard\nduring training. Moreover, we propose the first open-vocabulary AVSS framework,\nOV-AVSS, which mainly consists of two parts: 1) a universal sound source\nlocalization module to perform audio-visual fusion and locate all potential\nsounding objects and 2) an open-vocabulary classification module to predict\ncategories with the help of the prior knowledge from large-scale pre-trained\nvision-language models. To properly evaluate the open-vocabulary AVSS, we split\nzero-shot training and testing subsets based on the AVSBench-semantic\nbenchmark, namely AVSBench-OV. Extensive experiments demonstrate the strong\nsegmentation and zero-shot generalization ability of our model on all\ncategories. On the AVSBench-OV dataset, OV-AVSS achieves 55.43% mIoU on base\ncategories and 29.14% mIoU on novel categories, exceeding the state-of-the-art\nzero-shot method by 41.88%/20.61% and open-vocabulary method by 10.2%/11.6%.\nThe code is available at https://github.com/ruohaoguo/ovavss.\n","subjects":["Computing Research Repository/Multimedia","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/"}