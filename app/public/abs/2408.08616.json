{"id":"2408.08616","title":"Reference-free Axial Super-resolution of 3D Microscopy Images using\n  Implicit Neural Representation with a 2D Diffusion Prior","authors":"Kyungryun Lee, Won-Ki Jeong","authorsParsed":[["Lee","Kyungryun",""],["Jeong","Won-Ki",""]],"versions":[{"version":"v1","created":"Fri, 16 Aug 2024 09:14:12 GMT"}],"updateDate":"2024-08-19","timestamp":1723799652000,"abstract":"  Analysis and visualization of 3D microscopy images pose challenges due to\nanisotropic axial resolution, demanding volumetric super-resolution along the\naxial direction. While training a learning-based 3D super-resolution model\nseems to be a straightforward solution, it requires ground truth isotropic\nvolumes and suffers from the curse of dimensionality. Therefore, existing\nmethods utilize 2D neural networks to reconstruct each axial slice, eventually\npiecing together the entire volume. However, reconstructing each slice in the\npixel domain fails to give consistent reconstruction in all directions leading\nto misalignment artifacts. In this work, we present a reconstruction framework\nbased on implicit neural representation (INR), which allows 3D coherency even\nwhen optimized by independent axial slices in a batch-wise manner. Our method\noptimizes a continuous volumetric representation from low-resolution axial\nslices, using a 2D diffusion prior trained on high-resolution lateral slices\nwithout requiring isotropic volumes. Through experiments on real and synthetic\nanisotropic microscopy images, we demonstrate that our method surpasses other\nstate-of-the-art reconstruction methods. The source code is available on\nGitHub: https://github.com/hvcl/INR-diffusion.\n","subjects":["Electrical Engineering and Systems Science/Image and Video Processing","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"ABASQQY9x9kSy00Ok46kf09PMZZ0ddGwJHNNIz98dgE","pdfSize":"729029"}
