{"id":"2407.05464","title":"Experiments with truth using Machine Learning: Spectral analysis and\n  explainable classification of synthetic, false, and genuine information","authors":"Vishnu S. Pendyala and Madhulika Dutta","authorsParsed":[["Pendyala","Vishnu S.",""],["Dutta","Madhulika",""]],"versions":[{"version":"v1","created":"Sun, 7 Jul 2024 18:31:09 GMT"}],"updateDate":"2024-07-09","timestamp":1720377069000,"abstract":"  Misinformation is still a major societal problem and the arrival of Large\nLanguage Models (LLMs) only added to it. This paper analyzes synthetic, false,\nand genuine information in the form of text from spectral analysis,\nvisualization, and explainability perspectives to find the answer to why the\nproblem is still unsolved despite multiple years of research and a plethora of\nsolutions in the literature. Various embedding techniques on multiple datasets\nare used to represent information for the purpose. The diverse spectral and\nnon-spectral methods used on these embeddings include t-distributed Stochastic\nNeighbor Embedding (t-SNE), Principal Component Analysis (PCA), and Variational\nAutoencoders (VAEs). Classification is done using multiple machine learning\nalgorithms. Local Interpretable Model-Agnostic Explanations (LIME), SHapley\nAdditive exPlanations (SHAP), and Integrated Gradients are used for the\nexplanation of the classification. The analysis and the explanations generated\nshow that misinformation is quite closely intertwined with genuine information\nand the machine learning algorithms are not as effective in separating the two\ndespite the claims in the literature.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/"}