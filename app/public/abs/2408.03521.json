{"id":"2408.03521","title":"SwinShadow: Shifted Window for Ambiguous Adjacent Shadow Detection","authors":"Yonghui Wang, Shaokai Liu, Li Li, Wengang Zhou, Houqiang Li","authorsParsed":[["Wang","Yonghui",""],["Liu","Shaokai",""],["Li","Li",""],["Zhou","Wengang",""],["Li","Houqiang",""]],"versions":[{"version":"v1","created":"Wed, 7 Aug 2024 03:16:33 GMT"}],"updateDate":"2024-08-08","timestamp":1723000593000,"abstract":"  Shadow detection is a fundamental and challenging task in many computer\nvision applications. Intuitively, most shadows come from the occlusion of light\nby the object itself, resulting in the object and its shadow being contiguous\n(referred to as the adjacent shadow in this paper). In this case, when the\ncolor of the object is similar to that of the shadow, existing methods struggle\nto achieve accurate detection. To address this problem, we present SwinShadow,\na transformer-based architecture that fully utilizes the powerful shifted\nwindow mechanism for detecting adjacent shadows. The mechanism operates in two\nsteps. Initially, it applies local self-attention within a single window,\nenabling the network to focus on local details. Subsequently, it shifts the\nattention windows to facilitate inter-window attention, enabling the capture of\na broader range of adjacent information. These combined steps significantly\nimprove the network's capacity to distinguish shadows from nearby objects. And\nthe whole process can be divided into three parts: encoder, decoder, and\nfeature integration. During encoding, we adopt Swin Transformer to acquire\nhierarchical features. Then during decoding, for shallow layers, we propose a\ndeep supervision (DS) module to suppress the false positives and boost the\nrepresentation capability of shadow features for subsequent processing, while\nfor deep layers, we leverage a double attention (DA) module to integrate local\nand shifted window in one stage to achieve a larger receptive field and enhance\nthe continuity of information. Ultimately, a new multi-level aggregation (MLA)\nmechanism is applied to fuse the decoded features for mask prediction.\nExtensive experiments on three shadow detection benchmark datasets, SBU, UCF,\nand ISTD, demonstrate that our network achieves good performance in terms of\nbalance error rate (BER).\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}