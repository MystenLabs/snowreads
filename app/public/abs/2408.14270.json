{"id":"2408.14270","title":"Reliable Multi-modal Medical Image-to-image Translation Independent of\n  Pixel-wise Aligned Data","authors":"Langrui Zhou, Guang Li","authorsParsed":[["Zhou","Langrui",""],["Li","Guang",""]],"versions":[{"version":"v1","created":"Mon, 26 Aug 2024 13:45:58 GMT"}],"updateDate":"2024-08-27","timestamp":1724679958000,"abstract":"  The current mainstream multi-modal medical image-to-image translation methods\nface a contradiction. Supervised methods with outstanding performance rely on\npixel-wise aligned training data to constrain the model optimization. However,\nobtaining pixel-wise aligned multi-modal medical image datasets is challenging.\nUnsupervised methods can be trained without paired data, but their reliability\ncannot be guaranteed. At present, there is no ideal multi-modal medical\nimage-to-image translation method that can generate reliable translation\nresults without the need for pixel-wise aligned data. This work aims to develop\na novel medical image-to-image translation model that is independent of\npixel-wise aligned data (MITIA), enabling reliable multi-modal medical\nimage-to-image translation under the condition of misaligned training data. The\nproposed MITIA model utilizes a prior extraction network composed of a\nmulti-modal medical image registration module and a multi-modal misalignment\nerror detection module to extract pixel-level prior information from training\ndata with misalignment errors to the largest extent. The extracted prior\ninformation is then used to construct a regularization term to constrain the\noptimization of the unsupervised cycle-consistent GAN model, restricting its\nsolution space and thereby improving the performance and reliability of the\ngenerator. We trained the MITIA model using six datasets containing different\nmisalignment errors and two well-aligned datasets. Subsequently, we compared\nthe proposed method with six other state-of-the-art image-to-image translation\nmethods. The results of both quantitative analysis and qualitative visual\ninspection indicate that MITIA achieves superior performance compared to the\ncompeting state-of-the-art methods, both on misaligned data and aligned data.\n","subjects":["Electrical Engineering and Systems Science/Image and Video Processing","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}