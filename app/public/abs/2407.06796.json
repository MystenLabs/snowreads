{"id":"2407.06796","title":"Countermeasures Against Adversarial Examples in Radio Signal\n  Classification","authors":"Lu Zhang, Sangarapillai Lambotharan, Gan Zheng, Basil AsSadhan, Fabio\n  Roli","authorsParsed":[["Zhang","Lu",""],["Lambotharan","Sangarapillai",""],["Zheng","Gan",""],["AsSadhan","Basil",""],["Roli","Fabio",""]],"versions":[{"version":"v1","created":"Tue, 9 Jul 2024 12:08:50 GMT"}],"updateDate":"2024-07-10","timestamp":1720526930000,"abstract":"  Deep learning algorithms have been shown to be powerful in many communication\nnetwork design problems, including that in automatic modulation classification.\nHowever, they are vulnerable to carefully crafted attacks called adversarial\nexamples. Hence, the reliance of wireless networks on deep learning algorithms\nposes a serious threat to the security and operation of wireless networks. In\nthis letter, we propose for the first time a countermeasure against adversarial\nexamples in modulation classification. Our countermeasure is based on a neural\nrejection technique, augmented by label smoothing and Gaussian noise injection,\nthat allows to detect and reject adversarial examples with high accuracy. Our\nresults demonstrate that the proposed countermeasure can protect deep-learning\nbased modulation classification systems against adversarial examples.\n","subjects":["Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}