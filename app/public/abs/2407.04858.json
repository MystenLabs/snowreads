{"id":"2407.04858","title":"Question Answering with Texts and Tables through Deep Reinforcement\n  Learning","authors":"Marcos M. Jos\\'e, Fl\\'avio N. Ca\\c{c}\\~ao, Maria F. Ribeiro, Rafael M.\n  Cheang, Paulo Pirozelli, Fabio G. Cozman","authorsParsed":[["José","Marcos M.",""],["Cação","Flávio N.",""],["Ribeiro","Maria F.",""],["Cheang","Rafael M.",""],["Pirozelli","Paulo",""],["Cozman","Fabio G.",""]],"versions":[{"version":"v1","created":"Fri, 5 Jul 2024 20:44:01 GMT"}],"updateDate":"2024-07-09","timestamp":1720212241000,"abstract":"  This paper proposes a novel architecture to generate multi-hop answers to\nopen domain questions that require information from texts and tables, using the\nOpen Table-and-Text Question Answering dataset for validation and training. One\nof the most common ways to generate answers in this setting is to retrieve\ninformation sequentially, where a selected piece of data helps searching for\nthe next piece. As different models can have distinct behaviors when called in\nthis sequential information search, a challenge is how to select models at each\nstep. Our architecture employs reinforcement learning to choose between\ndifferent state-of-the-art tools sequentially until, in the end, a desired\nanswer is generated. This system achieved an F1-score of 19.03, comparable to\niterative systems in the literature.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/"}