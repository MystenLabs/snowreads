{"id":"2407.13782","title":"Self-supervised ASR Models and Features For Dysarthric and Elderly\n  Speech Recognition","authors":"Shujie Hu, Xurong Xie, Mengzhe Geng, Zengrui Jin, Jiajun Deng, Guinan\n  Li, Yi Wang, Mingyu Cui, Tianzi Wang, Helen Meng, Xunying Liu","authorsParsed":[["Hu","Shujie",""],["Xie","Xurong",""],["Geng","Mengzhe",""],["Jin","Zengrui",""],["Deng","Jiajun",""],["Li","Guinan",""],["Wang","Yi",""],["Cui","Mingyu",""],["Wang","Tianzi",""],["Meng","Helen",""],["Liu","Xunying",""]],"versions":[{"version":"v1","created":"Wed, 3 Jul 2024 08:33:39 GMT"}],"updateDate":"2024-07-22","timestamp":1719995619000,"abstract":"  Self-supervised learning (SSL) based speech foundation models have been\napplied to a wide range of ASR tasks. However, their application to dysarthric\nand elderly speech via data-intensive parameter fine-tuning is confronted by\nin-domain data scarcity and mismatch. To this end, this paper explores a series\nof approaches to integrate domain fine-tuned SSL pre-trained models and their\nfeatures into TDNN and Conformer ASR systems for dysarthric and elderly speech\nrecognition. These include: a) input feature fusion between standard acoustic\nfrontends and domain fine-tuned SSL speech representations; b) frame-level\njoint decoding between TDNN systems separately trained using standard acoustic\nfeatures alone and those with additional domain fine-tuned SSL features; and c)\nmulti-pass decoding involving the TDNN/Conformer system outputs to be rescored\nusing domain fine-tuned pre-trained ASR models. In addition, fine-tuned SSL\nspeech features are used in acoustic-to-articulatory (A2A) inversion to\nconstruct multi-modal ASR systems. Experiments are conducted on four tasks: the\nEnglish UASpeech and TORGO dysarthric speech corpora; and the English\nDementiaBank Pitt and Cantonese JCCOCC MoCA elderly speech datasets. The TDNN\nsystems constructed by integrating domain-adapted HuBERT, wav2vec2-conformer or\nmulti-lingual XLSR models and their features consistently outperform the\nstandalone fine-tuned SSL pre-trained models. These systems produced\nstatistically significant WER or CER reductions of 6.53%, 1.90%, 2.04% and\n7.97% absolute (24.10%, 23.84%, 10.14% and 31.39% relative) on the four tasks\nrespectively. Consistent improvements in Alzheimer's Disease detection accuracy\nare also obtained using the DementiaBank Pitt elderly speech recognition\noutputs.\n","subjects":["Electrical Engineering and Systems Science/Audio and Speech Processing","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Sound"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}