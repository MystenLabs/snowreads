{"id":"2407.06045","title":"OpenCIL: Benchmarking Out-of-Distribution Detection in Class-Incremental\n  Learning","authors":"Wenjun Miao, Guansong Pang, Trong-Tung Nguyen, Ruohang Fang, Jin\n  Zheng, Xiao Bai","authorsParsed":[["Miao","Wenjun",""],["Pang","Guansong",""],["Nguyen","Trong-Tung",""],["Fang","Ruohang",""],["Zheng","Jin",""],["Bai","Xiao",""]],"versions":[{"version":"v1","created":"Mon, 8 Jul 2024 15:42:02 GMT"},{"version":"v2","created":"Tue, 9 Jul 2024 12:14:47 GMT"}],"updateDate":"2024-07-10","timestamp":1720453322000,"abstract":"  Class incremental learning (CIL) aims to learn a model that can not only\nincrementally accommodate new classes, but also maintain the learned knowledge\nof old classes. Out-of-distribution (OOD) detection in CIL is to retain this\nincremental learning ability, while being able to reject unknown samples that\nare drawn from different distributions of the learned classes. This capability\nis crucial to the safety of deploying CIL models in open worlds. However,\ndespite remarkable advancements in the respective CIL and OOD detection, there\nlacks a systematic and large-scale benchmark to assess the capability of\nadvanced CIL models in detecting OOD samples. To fill this gap, in this study\nwe design a comprehensive empirical study to establish such a benchmark, named\n$\\textbf{OpenCIL}$. To this end, we propose two principled frameworks for\nenabling four representative CIL models with 15 diverse OOD detection methods,\nresulting in 60 baseline models for OOD detection in CIL. The empirical\nevaluation is performed on two popular CIL datasets with six commonly-used OOD\ndatasets. One key observation we find through our comprehensive evaluation is\nthat the CIL models can be severely biased towards the OOD samples and newly\nadded classes when they are exposed to open environments. Motivated by this, we\nfurther propose a new baseline for OOD detection in CIL, namely Bi-directional\nEnergy Regularization ($\\textbf{BER}$), which is specially designed to mitigate\nthese two biases in different CIL models by having energy regularization on\nboth old and new classes. Its superior performance is justified in our\nexperiments. All codes and datasets are open-source at\nhttps://github.com/mala-lab/OpenCIL.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}