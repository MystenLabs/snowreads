{"id":"2408.03144","title":"Active Learning for Level Set Estimation Using Randomized Straddle\n  Algorithms","authors":"Yu Inatsu, Shion Takeno, Kentaro Kutsukake, Ichiro Takeuchi","authorsParsed":[["Inatsu","Yu",""],["Takeno","Shion",""],["Kutsukake","Kentaro",""],["Takeuchi","Ichiro",""]],"versions":[{"version":"v1","created":"Tue, 6 Aug 2024 12:39:12 GMT"}],"updateDate":"2024-08-07","timestamp":1722947952000,"abstract":"  Level set estimation (LSE), the problem of identifying the set of input\npoints where a function takes value above (or below) a given threshold, is\nimportant in practical applications. When the function is expensive-to-evaluate\nand black-box, the \\textit{straddle} algorithm, which is a representative\nheuristic for LSE based on Gaussian process models, and its extensions having\ntheoretical guarantees have been developed. However, many of existing methods\ninclude a confidence parameter $\\beta^{1/2}_t$ that must be specified by the\nuser, and methods that choose $\\beta^{1/2}_t$ heuristically do not provide\ntheoretical guarantees. In contrast, theoretically guaranteed values of\n$\\beta^{1/2}_t$ need to be increased depending on the number of iterations and\ncandidate points, and are conservative and not good for practical performance.\nIn this study, we propose a novel method, the \\textit{randomized straddle}\nalgorithm, in which $\\beta_t$ in the straddle algorithm is replaced by a random\nsample from the chi-squared distribution with two degrees of freedom. The\nconfidence parameter in the proposed method has the advantages of not needing\nadjustment, not depending on the number of iterations and candidate points, and\nnot being conservative. Furthermore, we show that the proposed method has\ntheoretical guarantees that depend on the sample complexity and the number of\niterations. Finally, we confirm the usefulness of the proposed method through\nnumerical experiments using synthetic and real data.\n","subjects":["Statistics/Machine Learning","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}