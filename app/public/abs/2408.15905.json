{"id":"2408.15905","title":"MetaGFN: Exploring Distant Modes with Adapted Metadynamics for\n  Continuous GFlowNets","authors":"Dominic Phillips and Flaviu Cipcigan","authorsParsed":[["Phillips","Dominic",""],["Cipcigan","Flaviu",""]],"versions":[{"version":"v1","created":"Wed, 28 Aug 2024 16:19:35 GMT"}],"updateDate":"2024-08-29","timestamp":1724861975000,"abstract":"  Generative Flow Networks (GFlowNets) are a class of generative models that\nsample objects in proportion to a specified reward function through a learned\npolicy. They can be trained either on-policy or off-policy, needing a balance\nbetween exploration and exploitation for fast convergence to a target\ndistribution. While exploration strategies for discrete GFlowNets have been\nstudied, exploration in the continuous case remains to be investigated, despite\nthe potential for novel exploration algorithms due to the local connectedness\nof continuous domains. Here, we introduce Adapted Metadynamics, a variant of\nmetadynamics that can be applied to arbitrary black-box reward functions on\ncontinuous domains. We use Adapted Metadynamics as an exploration strategy for\ncontinuous GFlowNets. We show three continuous domains where the resulting\nalgorithm, MetaGFN, accelerates convergence to the target distribution and\ndiscovers more distant reward modes than previous off-policy exploration\nstrategies used for GFlowNets.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}