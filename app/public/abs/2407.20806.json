{"id":"2407.20806","title":"ARCLE: The Abstraction and Reasoning Corpus Learning Environment for\n  Reinforcement Learning","authors":"Hosung Lee, Sejin Kim, Seungpil Lee, Sanha Hwang, Jihwan Lee,\n  Byung-Jun Lee, Sundong Kim","authorsParsed":[["Lee","Hosung",""],["Kim","Sejin",""],["Lee","Seungpil",""],["Hwang","Sanha",""],["Lee","Jihwan",""],["Lee","Byung-Jun",""],["Kim","Sundong",""]],"versions":[{"version":"v1","created":"Tue, 30 Jul 2024 13:11:45 GMT"}],"updateDate":"2024-07-31","timestamp":1722345105000,"abstract":"  This paper introduces ARCLE, an environment designed to facilitate\nreinforcement learning research on the Abstraction and Reasoning Corpus (ARC).\nAddressing this inductive reasoning benchmark with reinforcement learning\npresents these challenges: a vast action space, a hard-to-reach goal, and a\nvariety of tasks. We demonstrate that an agent with proximal policy\noptimization can learn individual tasks through ARCLE. The adoption of\nnon-factorial policies and auxiliary losses led to performance enhancements,\neffectively mitigating issues associated with action spaces and goal\nattainment. Based on these insights, we propose several research directions and\nmotivations for using ARCLE, including MAML, GFlowNets, and World Models.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"B1x6eJGydygEamwITg2tSoC9GopEzqmO7DjKyOj0n-k","pdfSize":"1584239"}
