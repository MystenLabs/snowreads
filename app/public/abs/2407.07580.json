{"id":"2407.07580","title":"InstructLayout: Instruction-Driven 2D and 3D Layout Synthesis with\n  Semantic Graph Prior","authors":"Chenguo Lin, Yuchen Lin, Panwang Pan, Xuanyang Zhang and Yadong Mu","authorsParsed":[["Lin","Chenguo",""],["Lin","Yuchen",""],["Pan","Panwang",""],["Zhang","Xuanyang",""],["Mu","Yadong",""]],"versions":[{"version":"v1","created":"Wed, 10 Jul 2024 12:13:39 GMT"},{"version":"v2","created":"Thu, 11 Jul 2024 03:19:08 GMT"}],"updateDate":"2024-07-12","timestamp":1720613619000,"abstract":"  Comprehending natural language instructions is a charming property for both\n2D and 3D layout synthesis systems. Existing methods implicitly model object\njoint distributions and express object relations, hindering generation's\ncontrollability. We introduce InstructLayout, a novel generative framework that\nintegrates a semantic graph prior and a layout decoder to improve\ncontrollability and fidelity for 2D and 3D layout synthesis. The proposed\nsemantic graph prior learns layout appearances and object distributions\nsimultaneously, demonstrating versatility across various downstream tasks in a\nzero-shot manner. To facilitate the benchmarking for text-driven 2D and 3D\nscene synthesis, we respectively curate two high-quality datasets of\nlayout-instruction pairs from public Internet resources with large language and\nmultimodal models. Extensive experimental results reveal that the proposed\nmethod outperforms existing state-of-the-art approaches by a large margin in\nboth 2D and 3D layout synthesis tasks. Thorough ablation studies confirm the\nefficacy of crucial design components.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}