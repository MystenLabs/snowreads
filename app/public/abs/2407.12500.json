{"id":"2407.12500","title":"Automate or Assist? The Role of Computational Models in Identifying\n  Gendered Discourse in US Capital Trial Transcripts","authors":"Andrea W Wen-Yi, Kathryn Adamson, Nathalie Greenfield, Rachel\n  Goldberg, Sandra Babcock, David Mimno, Allison Koenecke","authorsParsed":[["Wen-Yi","Andrea W",""],["Adamson","Kathryn",""],["Greenfield","Nathalie",""],["Goldberg","Rachel",""],["Babcock","Sandra",""],["Mimno","David",""],["Koenecke","Allison",""]],"versions":[{"version":"v1","created":"Wed, 17 Jul 2024 11:30:04 GMT"},{"version":"v2","created":"Sat, 27 Jul 2024 00:52:44 GMT"}],"updateDate":"2024-07-30","timestamp":1721215804000,"abstract":"  The language used by US courtroom actors in criminal trials has long been\nstudied for biases. However, systematic studies for bias in high-stakes court\ntrials have been difficult, due to the nuanced nature of bias and the legal\nexpertise required. Large language models offer the possibility to automate\nannotation. But validating the computational approach requires both an\nunderstanding of how automated methods fit in existing annotation workflows and\nwhat they really offer. We present a case study of adding a computational model\nto a complex and high-stakes problem: identifying gender-biased language in US\ncapital trials for women defendants. Our team of experienced death-penalty\nlawyers and NLP technologists pursue a three-phase study: first annotating\nmanually, then training and evaluating computational models, and finally\ncomparing expert annotations to model predictions. Unlike many typical NLP\ntasks, annotating for gender bias in months-long capital trials is complicated,\nwith many individual judgment calls. Contrary to standard arguments for\nautomation that are based on efficiency and scalability, legal experts find the\ncomputational models most useful in providing opportunities to reflect on their\nown bias in annotation and to build consensus on annotation rules. This\nexperience suggests that seeking to replace experts with computational models\nfor complex annotation is both unrealistic and undesirable. Rather,\ncomputational models offer valuable opportunities to assist the legal experts\nin annotation-based studies.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}