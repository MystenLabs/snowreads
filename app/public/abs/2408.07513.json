{"id":"2408.07513","title":"Image Scaling Attack Simulation: A Measure of Stealth and Detectability","authors":"Devon A. Kelly, Sarah A. Flanery, Christiana Chamon","authorsParsed":[["Kelly","Devon A.",""],["Flanery","Sarah A.",""],["Chamon","Christiana",""]],"versions":[{"version":"v1","created":"Wed, 14 Aug 2024 12:48:00 GMT"}],"updateDate":"2024-08-15","timestamp":1723639680000,"abstract":"  Cybersecurity practices require effort to be maintained, and one weakness is\na lack of awareness regarding potential attacks not only in the usage of\nmachine learning models, but also in their development process. Previous\nstudies have determined that preprocessing attacks, such as image scaling\nattacks, have been difficult to detect by humans (through visual response) and\ncomputers (through entropic algorithms). However, these studies fail to address\nthe real-world performance and detectability of these attacks. The purpose of\nthis work is to analyze the relationship between awareness of image scaling\nattacks with respect to demographic background and experience. We conduct a\nsurvey where we gather the subjects' demographics, analyze the subjects'\nexperience in cybersecurity, record their responses to a poorly-performing\nconvolutional neural network model that has been unknowingly hindered by an\nimage scaling attack of a used dataset, and document their reactions after it\nis revealed that the images used within the broken models have been attacked.\nWe find in this study that the overall detection rate of the attack is low\nenough to be viable in a workplace or academic setting, and even after\ndiscovery, subjects cannot conclusively determine benign images from attacked\nimages.\n","subjects":["Computing Research Repository/Human-Computer Interaction"],"license":"http://creativecommons.org/publicdomain/zero/1.0/","blobId":"hchj8xMJZkw-JhvretnTkgpo8wNocjAMIawamnAddHE","pdfSize":"2805074"}
