{"id":"2407.10377","title":"Enhanced Self-supervised Learning for Multi-modality MRI Segmentation\n  and Classification: A Novel Approach Avoiding Model Collapse","authors":"Linxuan Han, Sa Xiao, Zimeng Li, Haidong Li, Xiuchao Zhao, Fumin Guo,\n  Yeqing Han, Xin Zhou","authorsParsed":[["Han","Linxuan",""],["Xiao","Sa",""],["Li","Zimeng",""],["Li","Haidong",""],["Zhao","Xiuchao",""],["Guo","Fumin",""],["Han","Yeqing",""],["Zhou","Xin",""]],"versions":[{"version":"v1","created":"Mon, 15 Jul 2024 01:11:30 GMT"},{"version":"v2","created":"Wed, 17 Jul 2024 07:05:57 GMT"}],"updateDate":"2024-07-18","timestamp":1721005890000,"abstract":"  Multi-modality magnetic resonance imaging (MRI) can provide complementary\ninformation for computer-aided diagnosis. Traditional deep learning algorithms\nare suitable for identifying specific anatomical structures segmenting lesions\nand classifying diseases with magnetic resonance images. However, manual labels\nare limited due to high expense, which hinders further improvement of model\naccuracy. Self-supervised learning (SSL) can effectively learn feature\nrepresentations from unlabeled data by pre-training and is demonstrated to be\neffective in natural image analysis. Most SSL methods ignore the similarity of\nmulti-modality MRI, leading to model collapse. This limits the efficiency of\npre-training, causing low accuracy in downstream segmentation and\nclassification tasks. To solve this challenge, we establish and validate a\nmulti-modality MRI masked autoencoder consisting of hybrid mask pattern (HMP)\nand pyramid barlow twin (PBT) module for SSL on multi-modality MRI analysis.\nThe HMP concatenates three masking steps forcing the SSL to learn the semantic\nconnections of multi-modality images by reconstructing the masking patches. We\nhave proved that the proposed HMP can avoid model collapse. The PBT module\nexploits the pyramidal hierarchy of the network to construct barlow twin loss\nbetween masked and original views, aligning the semantic representations of\nimage patches at different vision scales in latent space. Experiments on\nBraTS2023, PI-CAI, and lung gas MRI datasets further demonstrate the\nsuperiority of our framework over the state-of-the-art. The performance of the\nsegmentation and classification is substantially enhanced, supporting the\naccurate detection of small lesion areas. The code is available at\nhttps://github.com/LinxuanHan/M2-MAE.\n","subjects":["Electrical Engineering and Systems Science/Image and Video Processing","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}