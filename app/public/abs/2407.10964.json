{"id":"2407.10964","title":"No Train, all Gain: Self-Supervised Gradients Improve Deep Frozen\n  Representations","authors":"Walter Simoncini, Spyros Gidaris, Andrei Bursuc, Yuki M. Asano","authorsParsed":[["Simoncini","Walter",""],["Gidaris","Spyros",""],["Bursuc","Andrei",""],["Asano","Yuki M.",""]],"versions":[{"version":"v1","created":"Mon, 15 Jul 2024 17:58:42 GMT"}],"updateDate":"2024-07-16","timestamp":1721066322000,"abstract":"  This paper introduces FUNGI, Features from UNsupervised GradIents, a method\nto enhance the features of vision encoders by leveraging self-supervised\ngradients. Our method is simple: given any pretrained model, we first compute\ngradients from various self-supervised objectives for each input. These are\nprojected to a lower dimension and then concatenated with the model's\nembedding. The resulting features are evaluated on k-nearest neighbor\nclassification over 11 datasets from vision, 5 from natural language\nprocessing, and 2 from audio. Across backbones spanning various sizes and\npretraining strategies, FUNGI features provide consistent performance\nimprovements over the embeddings. We also show that using FUNGI features can\nbenefit linear classification and image retrieval, and that they significantly\nimprove the retrieval-based in-context scene understanding abilities of\npretrained models, for example improving upon DINO by +17% for semantic\nsegmentation - without any training.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}