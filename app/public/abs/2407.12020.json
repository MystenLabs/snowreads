{"id":"2407.12020","title":"SignSpeak: Open-Source Time Series Classification for ASL Translation","authors":"Aditya Makkar, Divya Makkar, Aarav Patel, Liam Hebert","authorsParsed":[["Makkar","Aditya",""],["Makkar","Divya",""],["Patel","Aarav",""],["Hebert","Liam",""]],"versions":[{"version":"v1","created":"Thu, 27 Jun 2024 17:58:54 GMT"},{"version":"v2","created":"Thu, 18 Jul 2024 20:36:03 GMT"}],"updateDate":"2024-07-22","timestamp":1719511134000,"abstract":"  The lack of fluency in sign language remains a barrier to seamless\ncommunication for hearing and speech-impaired communities. In this work, we\npropose a low-cost, real-time ASL-to-speech translation glove and an exhaustive\ntraining dataset of sign language patterns. We then benchmarked this dataset\nwith supervised learning models, such as LSTMs, GRUs and Transformers, where\nour best model achieved 92% accuracy. The SignSpeak dataset has 7200 samples\nencompassing 36 classes (A-Z, 1-10) and aims to capture realistic signing\npatterns by using five low-cost flex sensors to measure finger positions at\neach time step at 36 Hz. Our open-source dataset, models and glove designs,\nprovide an accurate and efficient ASL translator while maintaining\ncost-effectiveness, establishing a framework for future work to build on.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}