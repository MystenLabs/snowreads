{"id":"2408.13239","title":"CustomCrafter: Customized Video Generation with Preserving Motion and\n  Concept Composition Abilities","authors":"Tao Wu, Yong Zhang, Xintao Wang, Xianpan Zhou, Guangcong Zheng,\n  Zhongang Qi, Ying Shan, Xi Li","authorsParsed":[["Wu","Tao",""],["Zhang","Yong",""],["Wang","Xintao",""],["Zhou","Xianpan",""],["Zheng","Guangcong",""],["Qi","Zhongang",""],["Shan","Ying",""],["Li","Xi",""]],"versions":[{"version":"v1","created":"Fri, 23 Aug 2024 17:26:06 GMT"}],"updateDate":"2024-08-26","timestamp":1724433966000,"abstract":"  Customized video generation aims to generate high-quality videos guided by\ntext prompts and subject's reference images. However, since it is only trained\non static images, the fine-tuning process of subject learning disrupts\nabilities of video diffusion models (VDMs) to combine concepts and generate\nmotions. To restore these abilities, some methods use additional video similar\nto the prompt to fine-tune or guide the model. This requires frequent changes\nof guiding videos and even re-tuning of the model when generating different\nmotions, which is very inconvenient for users. In this paper, we propose\nCustomCrafter, a novel framework that preserves the model's motion generation\nand conceptual combination abilities without additional video and fine-tuning\nto recovery. For preserving conceptual combination ability, we design a\nplug-and-play module to update few parameters in VDMs, enhancing the model's\nability to capture the appearance details and the ability of concept\ncombinations for new subjects. For motion generation, we observed that VDMs\ntend to restore the motion of video in the early stage of denoising, while\nfocusing on the recovery of subject details in the later stage. Therefore, we\npropose Dynamic Weighted Video Sampling Strategy. Using the pluggability of our\nsubject learning modules, we reduce the impact of this module on motion\ngeneration in the early stage of denoising, preserving the ability to generate\nmotion of VDMs. In the later stage of denoising, we restore this module to\nrepair the appearance details of the specified subject, thereby ensuring the\nfidelity of the subject's appearance. Experimental results show that our method\nhas a significant improvement compared to previous methods.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}