{"id":"2407.00121","title":"Granite-Function Calling Model: Introducing Function Calling Abilities\n  via Multi-task Learning of Granular Tasks","authors":"Ibrahim Abdelaziz, Kinjal Basu, Mayank Agarwal, Sadhana Kumaravel,\n  Matthew Stallone, Rameswar Panda, Yara Rizk, GP Bhargav, Maxwell Crouse,\n  Chulaka Gunasekara, Shajith Ikbal, Sachin Joshi, Hima Karanam, Vineet Kumar,\n  Asim Munawar, Sumit Neelam, Dinesh Raghu, Udit Sharma, Adriana Meza Soria,\n  Dheeraj Sreedhar, Praveen Venkateswaran, Merve Unuvar, David Cox, Salim\n  Roukos, Luis Lastras, Pavan Kapanipathi","authorsParsed":[["Abdelaziz","Ibrahim",""],["Basu","Kinjal",""],["Agarwal","Mayank",""],["Kumaravel","Sadhana",""],["Stallone","Matthew",""],["Panda","Rameswar",""],["Rizk","Yara",""],["Bhargav","GP",""],["Crouse","Maxwell",""],["Gunasekara","Chulaka",""],["Ikbal","Shajith",""],["Joshi","Sachin",""],["Karanam","Hima",""],["Kumar","Vineet",""],["Munawar","Asim",""],["Neelam","Sumit",""],["Raghu","Dinesh",""],["Sharma","Udit",""],["Soria","Adriana Meza",""],["Sreedhar","Dheeraj",""],["Venkateswaran","Praveen",""],["Unuvar","Merve",""],["Cox","David",""],["Roukos","Salim",""],["Lastras","Luis",""],["Kapanipathi","Pavan",""]],"versions":[{"version":"v1","created":"Thu, 27 Jun 2024 17:47:26 GMT"}],"updateDate":"2024-07-02","timestamp":1719510446000,"abstract":"  Large language models (LLMs) have recently shown tremendous promise in\nserving as the backbone to agentic systems, as demonstrated by their\nperformance in multi-faceted, challenging benchmarks like SWE-Bench and\nAgent-Bench. However, to realize the true potential of LLMs as autonomous\nagents, they must learn to identify, call, and interact with external tools and\napplication program interfaces (APIs) to complete complex tasks. These tasks\ntogether are termed function calling. Endowing LLMs with function calling\nabilities leads to a myriad of advantages, such as access to current and\ndomain-specific information in databases and knowledge sources, and the ability\nto outsource tasks that can be reliably performed by tools, e.g., a Python\ninterpreter or calculator. While there has been significant progress in\nfunction calling with LLMs, there is still a dearth of open models that perform\non par with proprietary LLMs like GPT, Claude, and Gemini. Therefore, in this\nwork, we introduce the GRANITE-20B-FUNCTIONCALLING model under an Apache 2.0\nlicense. The model is trained using a multi-task training approach on seven\nfundamental tasks encompassed in function calling, those being Nested Function\nCalling, Function Chaining, Parallel Functions, Function Name Detection,\nParameter-Value Pair Detection, Next-Best Function, and Response Generation. We\npresent a comprehensive evaluation on multiple out-of-domain datasets comparing\nGRANITE-20B-FUNCTIONCALLING to more than 15 other best proprietary and open\nmodels. GRANITE-20B-FUNCTIONCALLING provides the best performance among all\nopen models on the Berkeley Function Calling Leaderboard and fourth overall. As\na result of the diverse tasks and datasets used for training our model, we show\nthat GRANITE-20B-FUNCTIONCALLING has better generalizability on multiple tasks\nin seven different evaluation datasets.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/"}
