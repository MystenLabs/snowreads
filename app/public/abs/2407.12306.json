{"id":"2407.12306","title":"Splatfacto-W: A Nerfstudio Implementation of Gaussian Splatting for\n  Unconstrained Photo Collections","authors":"Congrong Xu, Justin Kerr, Angjoo Kanazawa","authorsParsed":[["Xu","Congrong",""],["Kerr","Justin",""],["Kanazawa","Angjoo",""]],"versions":[{"version":"v1","created":"Wed, 17 Jul 2024 04:02:54 GMT"}],"updateDate":"2024-07-18","timestamp":1721188974000,"abstract":"  Novel view synthesis from unconstrained in-the-wild image collections remains\na significant yet challenging task due to photometric variations and transient\noccluders that complicate accurate scene reconstruction. Previous methods have\napproached these issues by integrating per-image appearance features embeddings\nin Neural Radiance Fields (NeRFs). Although 3D Gaussian Splatting (3DGS) offers\nfaster training and real-time rendering, adapting it for unconstrained image\ncollections is non-trivial due to the substantially different architecture. In\nthis paper, we introduce Splatfacto-W, an approach that integrates per-Gaussian\nneural color features and per-image appearance embeddings into the\nrasterization process, along with a spherical harmonics-based background model\nto represent varying photometric appearances and better depict backgrounds. Our\nkey contributions include latent appearance modeling, efficient transient\nobject handling, and precise background modeling. Splatfacto-W delivers\nhigh-quality, real-time novel view synthesis with improved scene consistency in\nin-the-wild scenarios. Our method improves the Peak Signal-to-Noise Ratio\n(PSNR) by an average of 5.3 dB compared to 3DGS, enhances training speed by 150\ntimes compared to NeRF-based methods, and achieves a similar rendering speed to\n3DGS. Additional video results and code integrated into Nerfstudio are\navailable at https://kevinxu02.github.io/splatfactow/.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}