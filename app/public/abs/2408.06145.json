{"id":"2408.06145","title":"Efficient and Scalable Point Cloud Generation with Sparse Point-Voxel\n  Diffusion Models","authors":"Ioannis Romanelis, Vlassios Fotis, Athanasios Kalogeras, Christos\n  Alexakos, Konstantinos Moustakas, Adrian Munteanu","authorsParsed":[["Romanelis","Ioannis",""],["Fotis","Vlassios",""],["Kalogeras","Athanasios",""],["Alexakos","Christos",""],["Moustakas","Konstantinos",""],["Munteanu","Adrian",""]],"versions":[{"version":"v1","created":"Mon, 12 Aug 2024 13:41:47 GMT"}],"updateDate":"2024-08-13","timestamp":1723470107000,"abstract":"  We propose a novel point cloud U-Net diffusion architecture for 3D generative\nmodeling capable of generating high-quality and diverse 3D shapes while\nmaintaining fast generation times. Our network employs a dual-branch\narchitecture, combining the high-resolution representations of points with the\ncomputational efficiency of sparse voxels. Our fastest variant outperforms all\nnon-diffusion generative approaches on unconditional shape generation, the most\npopular benchmark for evaluating point cloud generative models, while our\nlargest model achieves state-of-the-art results among diffusion methods, with a\nruntime approximately 70% of the previously state-of-the-art PVD. Beyond\nunconditional generation, we perform extensive evaluations, including\nconditional generation on all categories of ShapeNet, demonstrating the\nscalability of our model to larger datasets, and implicit generation which\nallows our network to produce high quality point clouds on fewer timesteps,\nfurther decreasing the generation time. Finally, we evaluate the architecture's\nperformance in point cloud completion and super-resolution. Our model excels in\nall tasks, establishing it as a state-of-the-art diffusion U-Net for point\ncloud generative modeling. The code is publicly available at\nhttps://github.com/JohnRomanelis/SPVD.git.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}