{"id":"2408.08184","title":"Not Every Image is Worth a Thousand Words: Quantifying Originality in\n  Stable Diffusion","authors":"Adi Haviv, Shahar Sarfaty, Uri Hacohen, Niva Elkin-Koren, Roi Livni,\n  Amit H Bermano","authorsParsed":[["Haviv","Adi",""],["Sarfaty","Shahar",""],["Hacohen","Uri",""],["Elkin-Koren","Niva",""],["Livni","Roi",""],["Bermano","Amit H",""]],"versions":[{"version":"v1","created":"Thu, 15 Aug 2024 14:42:02 GMT"}],"updateDate":"2024-08-16","timestamp":1723732922000,"abstract":"  This work addresses the challenge of quantifying originality in text-to-image\n(T2I) generative diffusion models, with a focus on copyright originality. We\nbegin by evaluating T2I models' ability to innovate and generalize through\ncontrolled experiments, revealing that stable diffusion models can effectively\nrecreate unseen elements with sufficiently diverse training data. Then, our key\ninsight is that concepts and combinations of image elements the model is\nfamiliar with, and saw more during training, are more concisly represented in\nthe model's latent space. We hence propose a method that leverages textual\ninversion to measure the originality of an image based on the number of tokens\nrequired for its reconstruction by the model. Our approach is inspired by legal\ndefinitions of originality and aims to assess whether a model can produce\noriginal content without relying on specific prompts or having the training\ndata of the model. We demonstrate our method using both a pre-trained stable\ndiffusion model and a synthetic dataset, showing a correlation between the\nnumber of tokens and image originality. This work contributes to the\nunderstanding of originality in generative models and has implications for\ncopyright infringement cases.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"38QzMFFUWAMfx7neK35aczIwY4WVCYcWGgedqdqjj1k","pdfSize":"27287944"}
