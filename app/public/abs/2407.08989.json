{"id":"2407.08989","title":"Robustness of LLMs to Perturbations in Text","authors":"Ayush Singh, Navpreet Singh, Shubham Vatsal","authorsParsed":[["Singh","Ayush",""],["Singh","Navpreet",""],["Vatsal","Shubham",""]],"versions":[{"version":"v1","created":"Fri, 12 Jul 2024 04:50:17 GMT"}],"updateDate":"2024-07-15","timestamp":1720759817000,"abstract":"  Having a clean dataset has been the foundational assumption of most natural\nlanguage processing (NLP) systems. However, properly written text is rarely\nfound in real-world scenarios and hence, oftentimes invalidates the\naforementioned foundational assumption. Recently, Large language models (LLMs)\nhave shown impressive performance, but can they handle the inevitable noise in\nreal-world data? This work tackles this critical question by investigating\nLLMs' resilience against morphological variations in text. To that end, we\nartificially introduce varying levels of noise into a diverse set of datasets\nand systematically evaluate LLMs' robustness against the corrupt variations of\nthe original text. Our findings show that contrary to popular beliefs,\ngenerative LLMs are quiet robust to noisy perturbations in text. This is a\ndeparture from pre-trained models like BERT or RoBERTa whose performance has\nbeen shown to be sensitive to deteriorating noisy text. Additionally, we test\nLLMs' resilience on multiple real-world benchmarks that closely mimic commonly\nfound errors in the wild. With minimal prompting, LLMs achieve a new\nstate-of-the-art on the benchmark tasks of Grammar Error Correction (GEC) and\nLexical Semantic Change (LSC). To empower future research, we also release a\ndataset annotated by humans stating their preference for LLM vs.\nhuman-corrected outputs along with the code to reproduce our results.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"HMbZmMviU_liiTx7PO7OQcQ4Odmoqb6MpVSbj7bVaso","pdfSize":"358522","objectId":"0x940dbd98c3c2400652d5916154114c5c55622cc44400b7e91bff7efecab57f62","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
