{"id":"2408.07020","title":"Source Separation of Multi-source Raw Music using a Residual Quantized\n  Variational Autoencoder","authors":"Leonardo Berti","authorsParsed":[["Berti","Leonardo",""]],"versions":[{"version":"v1","created":"Mon, 12 Aug 2024 17:30:17 GMT"}],"updateDate":"2024-08-14","timestamp":1723483817000,"abstract":"  I developed a neural audio codec model based on the residual quantized\nvariational autoencoder architecture. I train the model on the Slakh2100\ndataset, a standard dataset for musical source separation, composed of\nmulti-track audio. The model can separate audio sources, achieving almost SoTA\nresults with much less computing power. The code is publicly available at\ngithub.com/LeonardoBerti00/Source-Separation-of-Multi-source-Music-using-Residual-Quantizad-Variational-Autoencoder\n","subjects":["Computing Research Repository/Sound","Computing Research Repository/Machine Learning","Computing Research Repository/Multimedia","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"9ZXKq651Er-kljZF_oagpt0z1S3gId5FTci6wa3bf1E","pdfSize":"125055"}
