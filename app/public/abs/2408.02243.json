{"id":"2408.02243","title":"Self-Enhancing Video Data Management System for Compositional Events\n  with Large Language Models [Technical Report]","authors":"Enhao Zhang, Nicole Sullivan, Brandon Haynes, Ranjay Krishna,\n  Magdalena Balazinska","authorsParsed":[["Zhang","Enhao",""],["Sullivan","Nicole",""],["Haynes","Brandon",""],["Krishna","Ranjay",""],["Balazinska","Magdalena",""]],"versions":[{"version":"v1","created":"Mon, 5 Aug 2024 05:27:52 GMT"}],"updateDate":"2024-08-06","timestamp":1722835672000,"abstract":"  Complex video queries can be answered by decomposing them into modular\nsubtasks. However, existing video data management systems assume the existence\nof predefined modules for each subtask. We introduce VOCAL-UDF, a novel\nself-enhancing system that supports compositional queries over videos without\nthe need for predefined modules. VOCAL-UDF automatically identifies and\nconstructs missing modules and encapsulates them as user-defined functions\n(UDFs), thus expanding its querying capabilities. To achieve this, we formulate\na unified UDF model that leverages large language models (LLMs) to aid in new\nUDF generation. VOCAL-UDF handles a wide range of concepts by supporting both\nprogram-based UDFs (i.e., Python functions generated by LLMs) and\ndistilled-model UDFs (lightweight vision models distilled from strong\npretrained models). To resolve the inherent ambiguity in user intent, VOCAL-UDF\ngenerates multiple candidate UDFs and uses active learning to efficiently\nselect the best one. With the self-enhancing capability, VOCAL-UDF\nsignificantly improves query performance across three video datasets.\n","subjects":["Computing Research Repository/Databases"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}