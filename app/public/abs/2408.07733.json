{"id":"2408.07733","title":"Enhancing Adversarial Attacks via Parameter Adaptive Adversarial Attack","authors":"Zhibo Jin, Jiayu Zhang, Zhiyu Zhu, Chenyu Zhang, Jiahao Huang,\n  Jianlong Zhou, Fang Chen","authorsParsed":[["Jin","Zhibo",""],["Zhang","Jiayu",""],["Zhu","Zhiyu",""],["Zhang","Chenyu",""],["Huang","Jiahao",""],["Zhou","Jianlong",""],["Chen","Fang",""]],"versions":[{"version":"v1","created":"Wed, 14 Aug 2024 17:51:15 GMT"}],"updateDate":"2024-08-16","timestamp":1723657875000,"abstract":"  In recent times, the swift evolution of adversarial attacks has captured\nwidespread attention, particularly concerning their transferability and other\nperformance attributes. These techniques are primarily executed at the sample\nlevel, frequently overlooking the intrinsic parameters of models. Such neglect\nsuggests that the perturbations introduced in adversarial samples might have\nthe potential for further reduction. Given the essence of adversarial attacks\nis to impair model integrity with minimal noise on original samples, exploring\navenues to maximize the utility of such perturbations is imperative. Against\nthis backdrop, we have delved into the complexities of adversarial attack\nalgorithms, dissecting the adversarial process into two critical phases: the\nDirectional Supervision Process (DSP) and the Directional Optimization Process\n(DOP). While DSP determines the direction of updates based on the current\nsamples and model parameters, it has been observed that existing model\nparameters may not always be conducive to adversarial attacks. The impact of\nmodels on adversarial efficacy is often overlooked in current research, leading\nto the neglect of DSP. We propose that under certain conditions, fine-tuning\nmodel parameters can significantly enhance the quality of DSP. For the first\ntime, we propose that under certain conditions, fine-tuning model parameters\ncan significantly improve the quality of the DSP. We provide, for the first\ntime, rigorous mathematical definitions and proofs for these conditions, and\nintroduce multiple methods for fine-tuning model parameters within DSP. Our\nextensive experiments substantiate the effectiveness of the proposed P3A\nmethod. Our code is accessible at: https://anonymous.4open.science/r/P3A-A12C/\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Cryptography and Security"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}