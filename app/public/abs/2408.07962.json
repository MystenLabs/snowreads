{"id":"2408.07962","title":"Meta SAC-Lag: Towards Deployable Safe Reinforcement Learning via\n  MetaGradient-based Hyperparameter Tuning","authors":"Homayoun Honari, Amir Mehdi Soufi Enayati, Mehran Ghafarian Tamizi,\n  Homayoun Najjaran","authorsParsed":[["Honari","Homayoun",""],["Enayati","Amir Mehdi Soufi",""],["Tamizi","Mehran Ghafarian",""],["Najjaran","Homayoun",""]],"versions":[{"version":"v1","created":"Thu, 15 Aug 2024 06:18:50 GMT"}],"updateDate":"2024-08-16","timestamp":1723702730000,"abstract":"  Safe Reinforcement Learning (Safe RL) is one of the prevalently studied\nsubcategories of trial-and-error-based methods with the intention to be\ndeployed on real-world systems. In safe RL, the goal is to maximize reward\nperformance while minimizing constraints, often achieved by setting bounds on\nconstraint functions and utilizing the Lagrangian method. However, deploying\nLagrangian-based safe RL in real-world scenarios is challenging due to the\nnecessity of threshold fine-tuning, as imprecise adjustments may lead to\nsuboptimal policy convergence. To mitigate this challenge, we propose a unified\nLagrangian-based model-free architecture called Meta Soft Actor-Critic\nLagrangian (Meta SAC-Lag). Meta SAC-Lag uses meta-gradient optimization to\nautomatically update the safety-related hyperparameters. The proposed method is\ndesigned to address safe exploration and threshold adjustment with minimal\nhyperparameter tuning requirement. In our pipeline, the inner parameters are\nupdated through the conventional formulation and the hyperparameters are\nadjusted using the meta-objectives which are defined based on the updated\nparameters. Our results show that the agent can reliably adjust the safety\nperformance due to the relatively fast convergence rate of the safety\nthreshold. We evaluate the performance of Meta SAC-Lag in five simulated\nenvironments against Lagrangian baselines, and the results demonstrate its\ncapability to create synergy between parameters, yielding better or competitive\nresults. Furthermore, we conduct a real-world experiment involving a robotic\narm tasked with pouring coffee into a cup without spillage. Meta SAC-Lag is\nsuccessfully trained to execute the task, while minimizing effort constraints.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Robotics","Computing Research Repository/Systems and Control","Electrical Engineering and Systems Science/Systems and Control"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"v-P6FE0rc4uplHI44q83NiAlYMK-FN03w4qcNHhOV_E","pdfSize":"1555569"}
