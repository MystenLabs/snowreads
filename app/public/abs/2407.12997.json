{"id":"2407.12997","title":"Multi-Iteration Multi-Stage Fine-Tuning of Transformers for Sound Event\n  Detection with Heterogeneous Datasets","authors":"Florian Schmid, Paul Primus, Tobias Morocutti, Jonathan Greif, Gerhard\n  Widmer","authorsParsed":[["Schmid","Florian",""],["Primus","Paul",""],["Morocutti","Tobias",""],["Greif","Jonathan",""],["Widmer","Gerhard",""]],"versions":[{"version":"v1","created":"Wed, 17 Jul 2024 20:32:58 GMT"}],"updateDate":"2024-07-19","timestamp":1721248378000,"abstract":"  A central problem in building effective sound event detection systems is the\nlack of high-quality, strongly annotated sound event datasets. For this reason,\nTask 4 of the DCASE 2024 challenge proposes learning from two heterogeneous\ndatasets, including audio clips labeled with varying annotation granularity and\nwith different sets of possible events. We propose a multi-iteration,\nmulti-stage procedure for fine-tuning Audio Spectrogram Transformers on the\njoint DESED and MAESTRO Real datasets. The first stage closely matches the\nbaseline system setup and trains a CRNN model while keeping the pre-trained\ntransformer model frozen. In the second stage, both CRNN and transformer are\nfine-tuned using heavily weighted self-supervised losses. After the second\nstage, we compute strong pseudo-labels for all audio clips in the training set\nusing an ensemble of fine-tuned transformers. Then, in a second iteration, we\nrepeat the two-stage training process and include a distillation loss based on\nthe pseudo-labels, achieving a new single-model, state-of-the-art performance\non the public evaluation set of DESED with a PSDS1 of 0.692. A single model and\nan ensemble, both based on our proposed training procedure, ranked first in\nTask 4 of the DCASE Challenge 2024.\n","subjects":["Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}