{"id":"2407.02791","title":"Model-Enhanced LLM-Driven VUI Testing of VPA Apps","authors":"Suwan Li, Lei Bu, Guangdong Bai, Fuman Xie, Kai Chen and Chang Yue","authorsParsed":[["Li","Suwan",""],["Bu","Lei",""],["Bai","Guangdong",""],["Xie","Fuman",""],["Chen","Kai",""],["Yue","Chang",""]],"versions":[{"version":"v1","created":"Wed, 3 Jul 2024 03:36:05 GMT"}],"updateDate":"2024-07-04","timestamp":1719977765000,"abstract":"  The flourishing ecosystem centered around voice personal assistants (VPA),\nsuch as Amazon Alexa, has led to the booming of VPA apps. The largest app\nmarket Amazon skills store, for example, hosts over 200,000 apps. Despite their\npopularity, the open nature of app release and the easy accessibility of apps\nalso raise significant concerns regarding security, privacy and quality.\nConsequently, various testing approaches have been proposed to systematically\nexamine VPA app behaviors. To tackle the inherent lack of a visible user\ninterface in the VPA app, two strategies are employed during testing, i.e.,\nchatbot-style testing and model-based testing. The former often lacks effective\nguidance for expanding its search space, while the latter falls short in\ninterpreting the semantics of conversations to construct precise and\ncomprehensive behavior models for apps. In this work, we introduce Elevate, a\nmodel-enhanced large language model (LLM)-driven VUI testing framework. Elevate\nleverages LLMs' strong capability in natural language processing to compensate\nfor semantic information loss during model-based VUI testing. It operates by\nprompting LLMs to extract states from VPA apps' outputs and generate\ncontext-related inputs. During the automatic interactions with the app, it\nincrementally constructs the behavior model, which facilitates the LLM in\ngenerating inputs that are highly likely to discover new states. Elevate\nbridges the LLM and the behavior model with innovative techniques such as\nencoding behavior model into prompts and selecting LLM-generated inputs based\non the context relevance. Elevate is benchmarked on 4,000 real-world Alexa\nskills, against the state-of-the-art tester Vitas. It achieves 15% higher state\nspace coverage compared to Vitas on all types of apps, and exhibits significant\nadvancement in efficiency.\n","subjects":["Computing Research Repository/Software Engineering","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}