{"id":"2407.08991","title":"Optimization of DNN-based speaker verification model through efficient\n  quantization technique","authors":"Yeona Hong, Woo-Jin Chung, Hong-Goo Kang","authorsParsed":[["Hong","Yeona",""],["Chung","Woo-Jin",""],["Kang","Hong-Goo",""]],"versions":[{"version":"v1","created":"Fri, 12 Jul 2024 05:03:10 GMT"}],"updateDate":"2024-07-15","timestamp":1720760590000,"abstract":"  As Deep Neural Networks (DNNs) rapidly advance in various fields, including\nspeech verification, they typically involve high computational costs and\nsubstantial memory consumption, which can be challenging to manage on mobile\nsystems. Quantization of deep models offers a means to reduce both\ncomputational and memory expenses. Our research proposes an optimization\nframework for the quantization of the speaker verification model. By analyzing\nperformance changes and model size reductions in each layer of a pre-trained\nspeaker verification model, we have effectively minimized performance\ndegradation while significantly reducing the model size. Our quantization\nalgorithm is the first attempt to maintain the performance of the\nstate-of-the-art pre-trained speaker verification model, ECAPATDNN, while\nsignificantly compressing its model size. Overall, our quantization approach\nresulted in reducing the model size by half, with an increase in EER limited to\n0.07%.\n","subjects":["Electrical Engineering and Systems Science/Audio and Speech Processing","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computational Complexity"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}