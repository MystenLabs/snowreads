{"id":"2407.05428","title":"Diffusion as Sound Propagation: Physics-inspired Model for Ultrasound\n  Image Generation","authors":"Marina Dom\\'inguez, Yordanka Velikova, Nassir Navab, Mohammad Farid\n  Azampour","authorsParsed":[["Dom√≠nguez","Marina",""],["Velikova","Yordanka",""],["Navab","Nassir",""],["Azampour","Mohammad Farid",""]],"versions":[{"version":"v1","created":"Sun, 7 Jul 2024 16:09:20 GMT"}],"updateDate":"2024-07-09","timestamp":1720368560000,"abstract":"  Deep learning (DL) methods typically require large datasets to effectively\nlearn data distributions. However, in the medical field, data is often limited\nin quantity, and acquiring labeled data can be costly. To mitigate this data\nscarcity, data augmentation techniques are commonly employed. Among these\ntechniques, generative models play a pivotal role in expanding datasets.\nHowever, when it comes to ultrasound (US) imaging, the authenticity of\ngenerated data often diminishes due to the oversight of ultrasound physics.\n  We propose a novel approach to improve the quality of generated US images by\nintroducing a physics-based diffusion model that is specifically designed for\nthis image modality. The proposed model incorporates an US-specific scheduler\nscheme that mimics the natural behavior of sound wave propagation in ultrasound\nimaging. Our analysis demonstrates how the proposed method aids in modeling the\nattenuation dynamics in US imaging. We present both qualitative and\nquantitative results based on standard generative model metrics, showing that\nour proposed method results in overall more plausible images. Our code is\navailable at https://github.com/marinadominguez/diffusion-for-us-images\n","subjects":["Electrical Engineering and Systems Science/Image and Video Processing","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"W8y3pf16lCOjieRqJ4deYSIKfSGYXB_CtDXEy9VUaLY","pdfSize":"4902505"}
