{"id":"2408.05362","title":"MindSpeech: Continuous Imagined Speech Decoding using High-Density fNIRS\n  and Prompt Tuning for Advanced Human-AI Interaction","authors":"Suyi Zhang, Ekram Alam, Jack Baber, Francesca Bianco, Edward Turner,\n  Maysam Chamanzar, Hamid Dehghani","authorsParsed":[["Zhang","Suyi",""],["Alam","Ekram",""],["Baber","Jack",""],["Bianco","Francesca",""],["Turner","Edward",""],["Chamanzar","Maysam",""],["Dehghani","Hamid",""]],"versions":[{"version":"v1","created":"Thu, 25 Jul 2024 16:39:21 GMT"}],"updateDate":"2024-08-13","timestamp":1721925561000,"abstract":"  In the coming decade, artificial intelligence systems will continue to\nimprove and revolutionise every industry and facet of human life. Designing\neffective, seamless and symbiotic communication paradigms between humans and AI\nagents is increasingly important. This paper reports a novel method for\nhuman-AI interaction by developing a direct brain-AI interface. We discuss a\nnovel AI model, called MindSpeech, which enables open-vocabulary, continuous\ndecoding for imagined speech. This study focuses on enhancing human-AI\ncommunication by utilising high-density functional near-infrared spectroscopy\n(fNIRS) data to develop an AI model capable of decoding imagined speech\nnon-invasively. We discuss a new word cloud paradigm for data collection,\nimproving the quality and variety of imagined sentences generated by\nparticipants and covering a broad semantic space. Utilising a prompt\ntuning-based approach, we employed the Llama2 large language model (LLM) for\ntext generation guided by brain signals. Our results show significant\nimprovements in key metrics, such as BLEU-1 and BERT P scores, for three out of\nfour participants, demonstrating the method's effectiveness. Additionally, we\ndemonstrate that combining data from multiple participants enhances the decoder\nperformance, with statistically significant improvements in BERT scores for two\nparticipants. Furthermore, we demonstrated significantly above-chance decoding\naccuracy for imagined speech versus resting conditions and the identified\nactivated brain regions during imagined speech tasks in our study are\nconsistent with the previous studies on brain regions involved in speech\nencoding. This study underscores the feasibility of continuous imagined speech\ndecoding. By integrating high-density fNIRS with advanced AI techniques, we\nhighlight the potential for non-invasive, accurate communication systems with\nAI in the near future.\n","subjects":["Computing Research Repository/Human-Computer Interaction","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"CYg4Fq14F2XjsmRmmzSaG9_QFE1PIHRD_eZddc2_jXg","pdfSize":"42493467"}
