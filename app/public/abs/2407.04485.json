{"id":"2407.04485","title":"Leveraging Graph Structures to Detect Hallucinations in Large Language\n  Models","authors":"Noa Nonkes, Sergei Agaronian, Evangelos Kanoulas, Roxana Petcu","authorsParsed":[["Nonkes","Noa",""],["Agaronian","Sergei",""],["Kanoulas","Evangelos",""],["Petcu","Roxana",""]],"versions":[{"version":"v1","created":"Fri, 5 Jul 2024 13:08:58 GMT"}],"updateDate":"2024-07-08","timestamp":1720184938000,"abstract":"  Large language models are extensively applied across a wide range of tasks,\nsuch as customer support, content creation, educational tutoring, and providing\nfinancial guidance. However, a well-known drawback is their predisposition to\ngenerate hallucinations. This damages the trustworthiness of the information\nthese models provide, impacting decision-making and user confidence. We propose\na method to detect hallucinations by looking at the structure of the latent\nspace and finding associations within hallucinated and non-hallucinated\ngenerations. We create a graph structure that connects generations that lie\nclosely in the embedding space. Moreover, we employ a Graph Attention Network\nwhich utilizes message passing to aggregate information from neighboring nodes\nand assigns varying degrees of importance to each neighbor based on their\nrelevance. Our findings show that 1) there exists a structure in the latent\nspace that differentiates between hallucinated and non-hallucinated\ngenerations, 2) Graph Attention Networks can learn this structure and\ngeneralize it to unseen generations, and 3) the robustness of our method is\nenhanced when incorporating contrastive learning. When evaluated against\nevidence-based benchmarks, our model performs similarly without access to\nsearch-based methods.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}