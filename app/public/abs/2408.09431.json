{"id":"2408.09431","title":"Adversarial Attacked Teacher for Unsupervised Domain Adaptive Object\n  Detection","authors":"Kaiwen Wang, Yinzhe Shen and Martin Lauer","authorsParsed":[["Wang","Kaiwen",""],["Shen","Yinzhe",""],["Lauer","Martin",""]],"versions":[{"version":"v1","created":"Sun, 18 Aug 2024 10:22:23 GMT"}],"updateDate":"2024-08-20","timestamp":1723976543000,"abstract":"  Object detectors encounter challenges in handling domain shifts. Cutting-edge\ndomain adaptive object detection methods use the teacher-student framework and\ndomain adversarial learning to generate domain-invariant pseudo-labels for\nself-training. However, the pseudo-labels generated by the teacher model tend\nto be biased towards the majority class and often mistakenly include\noverconfident false positives and underconfident false negatives. We reveal\nthat pseudo-labels vulnerable to adversarial attacks are more likely to be\nlow-quality. To address this, we propose a simple yet effective framework named\nAdversarial Attacked Teacher (AAT) to improve the quality of pseudo-labels.\nSpecifically, we apply adversarial attacks to the teacher model, prompting it\nto generate adversarial pseudo-labels to correct bias, suppress overconfidence,\nand encourage underconfident proposals. An adaptive pseudo-label regularization\nis introduced to emphasize the influence of pseudo-labels with high certainty\nand reduce the negative impacts of uncertain predictions. Moreover, robust\nminority objects verified by pseudo-label regularization are oversampled to\nminimize dataset imbalance without introducing false positives. Extensive\nexperiments conducted on various datasets demonstrate that AAT achieves\nsuperior performance, reaching 52.6 mAP on Clipart1k, surpassing the previous\nstate-of-the-art by 6.7%.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}