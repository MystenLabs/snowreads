{"id":"2407.09886","title":"Speech-Copilot: Leveraging Large Language Models for Speech Processing\n  via Task Decomposition, Modularization, and Program Generation","authors":"Chun-Yi Kuan, Chih-Kai Yang, Wei-Ping Huang, Ke-Han Lu, Hung-yi Lee","authorsParsed":[["Kuan","Chun-Yi",""],["Yang","Chih-Kai",""],["Huang","Wei-Ping",""],["Lu","Ke-Han",""],["Lee","Hung-yi",""]],"versions":[{"version":"v1","created":"Sat, 13 Jul 2024 13:26:43 GMT"}],"updateDate":"2024-07-16","timestamp":1720877203000,"abstract":"  In this work, we introduce Speech-Copilot, a modular framework for\ninstruction-oriented speech-processing tasks that minimizes human effort in\ntoolset construction. Unlike end-to-end methods using large audio-language\nmodels, Speech-Copilot builds speech processing-specific toolsets by analyzing\npre-collected task instructions and breaking tasks into manageable sub-tasks.\nIt features a flexible agent based on large language models that performs tasks\nthrough program generation. Our approach achieves state-of-the-art performance\non the Dynamic-SUPERB benchmark, demonstrating its effectiveness across diverse\nspeech-processing tasks. Key contributions include: 1) developing an innovative\nframework for speech processing-specific toolset construction, 2) establishing\na high-performing agent based on large language models, and 3) offering a new\nperspective on addressing challenging instruction-oriented speech-processing\ntasks. Without additional training processes required by end-to-end approaches,\nour method provides a flexible and extendable solution for a wide range of\nspeech-processing applications.\n","subjects":["Electrical Engineering and Systems Science/Audio and Speech Processing","Computing Research Repository/Computation and Language","Computing Research Repository/Sound"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}