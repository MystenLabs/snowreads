{"id":"2408.01739","title":"LAM3D: Leveraging Attention for Monocular 3D Object Detection","authors":"Diana-Alexandra Sas, Leandro Di Bella, Yangxintong Lyu, Florin Oniga\n  and Adrian Munteanu","authorsParsed":[["Sas","Diana-Alexandra",""],["Di Bella","Leandro",""],["Lyu","Yangxintong",""],["Oniga","Florin",""],["Munteanu","Adrian",""]],"versions":[{"version":"v1","created":"Sat, 3 Aug 2024 10:50:07 GMT"}],"updateDate":"2024-08-06","timestamp":1722682207000,"abstract":"  Since the introduction of the self-attention mechanism and the adoption of\nthe Transformer architecture for Computer Vision tasks, the Vision\nTransformer-based architectures gained a lot of popularity in the field, being\nused for tasks such as image classification, object detection and image\nsegmentation. However, efficiently leveraging the attention mechanism in vision\ntransformers for the Monocular 3D Object Detection task remains an open\nquestion. In this paper, we present LAM3D, a framework that Leverages\nself-Attention mechanism for Monocular 3D object Detection. To do so, the\nproposed method is built upon a Pyramid Vision Transformer v2 (PVTv2) as\nfeature extraction backbone and 2D/3D detection machinery. We evaluate the\nproposed method on the KITTI 3D Object Detection Benchmark, proving the\napplicability of the proposed solution in the autonomous driving domain and\noutperforming reference methods. Moreover, due to the usage of self-attention,\nLAM3D is able to systematically outperform the equivalent architecture that\ndoes not employ self-attention.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"kpU-ibX4I2YW2SxpbKXB9q9BpFO5ei4Qv4S90NRl-yY","pdfSize":"8724486","txDigest":"DB6i3SD3pqRU9911gP5MeRS46wntn6N3oEpaxmMchCFS","endEpoch":"1","status":"CERTIFIED"}
