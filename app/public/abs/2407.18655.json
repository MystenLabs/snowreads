{"id":"2407.18655","title":"Aspects of importance sampling in parameter selection for neural\n  networks using ridgelet transform","authors":"Hikaru Homma and Jun Ohkubo","authorsParsed":[["Homma","Hikaru",""],["Ohkubo","Jun",""]],"versions":[{"version":"v1","created":"Fri, 26 Jul 2024 10:45:27 GMT"}],"updateDate":"2024-07-29","timestamp":1721990727000,"abstract":"  The choice of parameters in neural networks is crucial in the performance,\nand an oracle distribution derived from the ridgelet transform enables us to\nobtain suitable initial parameters. In other words, the distribution of\nparameters is connected to the integral representation of target functions. The\noracle distribution allows us to avoid the conventional backpropagation\nlearning process; only a linear regression is enough to construct the neural\nnetwork in simple cases. This study provides a new look at the oracle\ndistributions and ridgelet transforms, i.e., an aspect of importance sampling.\nIn addition, we propose extensions of the parameter sampling methods. We\ndemonstrate the aspect of importance sampling and the proposed sampling\nalgorithms via one-dimensional and high-dimensional examples; the results imply\nthat the magnitude of weight parameters could be more crucial than the\nintercept parameters.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}