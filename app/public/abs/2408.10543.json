{"id":"2408.10543","title":"Diff-PCC: Diffusion-based Neural Compression for 3D Point Clouds","authors":"Kai Liu and Kang You and Pan Gao","authorsParsed":[["Liu","Kai",""],["You","Kang",""],["Gao","Pan",""]],"versions":[{"version":"v1","created":"Tue, 20 Aug 2024 04:55:29 GMT"}],"updateDate":"2024-08-21","timestamp":1724129729000,"abstract":"  Stable diffusion networks have emerged as a groundbreaking development for\ntheir ability to produce realistic and detailed visual content. This\ncharacteristic renders them ideal decoders, capable of producing high-quality\nand aesthetically pleasing reconstructions. In this paper, we introduce the\nfirst diffusion-based point cloud compression method, dubbed Diff-PCC, to\nleverage the expressive power of the diffusion model for generative and\naesthetically superior decoding. Different from the conventional autoencoder\nfashion, a dual-space latent representation is devised in this paper, in which\na compressor composed of two independent encoding backbones is considered to\nextract expressive shape latents from distinct latent spaces. At the decoding\nside, a diffusion-based generator is devised to produce high-quality\nreconstructions by considering the shape latents as guidance to stochastically\ndenoise the noisy point clouds. Experiments demonstrate that the proposed\nDiff-PCC achieves state-of-the-art compression performance (e.g., 7.711 dB\nBD-PSNR gains against the latest G-PCC standard at ultra-low bitrate) while\nattaining superior subjective quality. Source code will be made publicly\navailable.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence","Electrical Engineering and Systems Science/Image and Video Processing"],"license":"http://creativecommons.org/licenses/by/4.0/"}