{"id":"2407.16503","title":"HDRSplat: Gaussian Splatting for High Dynamic Range 3D Scene\n  Reconstruction from Raw Images","authors":"Shreyas Singh, Aryan Garg, Kaushik Mitra","authorsParsed":[["Singh","Shreyas",""],["Garg","Aryan",""],["Mitra","Kaushik",""]],"versions":[{"version":"v1","created":"Tue, 23 Jul 2024 14:21:00 GMT"}],"updateDate":"2024-07-24","timestamp":1721744460000,"abstract":"  The recent advent of 3D Gaussian Splatting (3DGS) has revolutionized the 3D\nscene reconstruction space enabling high-fidelity novel view synthesis in\nreal-time. However, with the exception of RawNeRF, all prior 3DGS and\nNeRF-based methods rely on 8-bit tone-mapped Low Dynamic Range (LDR) images for\nscene reconstruction. Such methods struggle to achieve accurate reconstructions\nin scenes that require a higher dynamic range. Examples include scenes captured\nin nighttime or poorly lit indoor spaces having a low signal-to-noise ratio, as\nwell as daylight scenes with shadow regions exhibiting extreme contrast. Our\nproposed method HDRSplat tailors 3DGS to train directly on 14-bit linear raw\nimages in near darkness which preserves the scenes' full dynamic range and\ncontent. Our key contributions are two-fold: Firstly, we propose a linear HDR\nspace-suited loss that effectively extracts scene information from noisy dark\nregions and nearly saturated bright regions simultaneously, while also handling\nview-dependent colors without increasing the degree of spherical harmonics.\nSecondly, through careful rasterization tuning, we implicitly overcome the\nheavy reliance and sensitivity of 3DGS on point cloud initialization. This is\ncritical for accurate reconstruction in regions of low texture, high depth of\nfield, and low illumination. HDRSplat is the fastest method to date that does\n14-bit (HDR) 3D scene reconstruction in $\\le$15 minutes/scene ($\\sim$30x faster\nthan prior state-of-the-art RawNeRF). It also boasts the fastest inference\nspeed at $\\ge$120fps. We further demonstrate the applicability of our HDR scene\nreconstruction by showcasing various applications like synthetic defocus, dense\ndepth map extraction, and post-capture control of exposure, tone-mapping and\nview-point.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Electrical Engineering and Systems Science/Image and Video Processing"],"license":"http://creativecommons.org/licenses/by/4.0/"}