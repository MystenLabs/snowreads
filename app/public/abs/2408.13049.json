{"id":"2408.13049","title":"G3FA: Geometry-guided GAN for Face Animation","authors":"Alireza Javanmardi, Alain Pagani and Didier Stricker","authorsParsed":[["Javanmardi","Alireza",""],["Pagani","Alain",""],["Stricker","Didier",""]],"versions":[{"version":"v1","created":"Fri, 23 Aug 2024 13:13:24 GMT"}],"updateDate":"2024-08-26","timestamp":1724418804000,"abstract":"  Animating human face images aims to synthesize a desired source identity in a\nnatural-looking way mimicking a driving video's facial movements. In this\ncontext, Generative Adversarial Networks have demonstrated remarkable potential\nin real-time face reenactment using a single source image, yet are constrained\nby limited geometry consistency compared to graphic-based approaches. In this\npaper, we introduce Geometry-guided GAN for Face Animation (G3FA) to tackle\nthis limitation. Our novel approach empowers the face animation model to\nincorporate 3D information using only 2D images, improving the image generation\ncapabilities of the talking head synthesis model. We integrate inverse\nrendering techniques to extract 3D facial geometry properties, improving the\nfeedback loop to the generator through a weighted average ensemble of\ndiscriminators. In our face reenactment model, we leverage 2D motion warping to\ncapture motion dynamics along with orthogonal ray sampling and volume rendering\ntechniques to produce the ultimate visual output. To evaluate the performance\nof our G3FA, we conducted comprehensive experiments using various evaluation\nprotocols on VoxCeleb2 and TalkingHead benchmarks to demonstrate the\neffectiveness of our proposed framework compared to the state-of-the-art\nreal-time face animation methods.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"aVRXtsHRr-zXYcLzbSsvRXgWeR-CFq2iiUi05lJYg-4","pdfSize":"806661"}
