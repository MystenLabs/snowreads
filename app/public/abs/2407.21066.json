{"id":"2407.21066","title":"ELP-Adapters: Parameter Efficient Adapter Tuning for Various Speech\n  Processing Tasks","authors":"Nakamasa Inoue, Shinta Otake, Takumi Hirose, Masanari Ohi, Rei\n  Kawakami","authorsParsed":[["Inoue","Nakamasa",""],["Otake","Shinta",""],["Hirose","Takumi",""],["Ohi","Masanari",""],["Kawakami","Rei",""]],"versions":[{"version":"v1","created":"Sun, 28 Jul 2024 05:26:03 GMT"}],"updateDate":"2024-08-01","timestamp":1722144363000,"abstract":"  Self-supervised learning has emerged as a key approach for learning generic\nrepresentations from speech data. Despite promising results in downstream tasks\nsuch as speech recognition, speaker verification, and emotion recognition, a\nsignificant number of parameters is required, which makes fine-tuning for each\ntask memory-inefficient. To address this limitation, we introduce ELP-adapter\ntuning, a novel method for parameter-efficient fine-tuning using three types of\nadapter, namely encoder adapters (E-adapters), layer adapters (L-adapters), and\na prompt adapter (P-adapter). The E-adapters are integrated into\ntransformer-based encoder layers and help to learn fine-grained speech\nrepresentations that are effective for speech recognition. The L-adapters\ncreate paths from each encoder layer to the downstream head and help to extract\nnon-linguistic features from lower encoder layers that are effective for\nspeaker verification and emotion recognition. The P-adapter appends pseudo\nfeatures to CNN features to further improve effectiveness and efficiency. With\nthese adapters, models can be quickly adapted to various speech processing\ntasks. Our evaluation across four downstream tasks using five backbone models\ndemonstrated the effectiveness of the proposed method. With the WavLM backbone,\nits performance was comparable to or better than that of full fine-tuning on\nall tasks while requiring 90% fewer learnable parameters.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning","Computing Research Repository/Sound","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}