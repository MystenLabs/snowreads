{"id":"2407.00085","title":"Compressing Search with Language Models","authors":"Thomas Mulc and Jennifer L. Steele","authorsParsed":[["Mulc","Thomas",""],["Steele","Jennifer L.",""]],"versions":[{"version":"v1","created":"Mon, 24 Jun 2024 17:43:49 GMT"}],"updateDate":"2024-07-02","timestamp":1719251029000,"abstract":"  Millions of people turn to Google Search each day for information on things\nas diverse as new cars or flu symptoms. The terms that they enter contain\nvaluable information on their daily intent and activities, but the information\nin these search terms has been difficult to fully leverage. User-defined\ncategorical filters have been the most common way to shrink the dimensionality\nof search data to a tractable size for analysis and modeling. In this paper we\npresent a new approach to reducing the dimensionality of search data while\nretaining much of the information in the individual terms without user-defined\nrules. Our contributions are two-fold: 1) we introduce SLaM Compression, a way\nto quantify search terms using pre-trained language models and create a\nrepresentation of search data that has low dimensionality, is memory efficient,\nand effectively acts as a summary of search, and 2) we present CoSMo, a\nConstrained Search Model for estimating real world events using only search\ndata. We demonstrate the efficacy of our contributions by estimating with high\naccuracy U.S. automobile sales and U.S. flu rates using only Google Search\ndata.\n","subjects":["Computing Research Repository/Information Retrieval","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}