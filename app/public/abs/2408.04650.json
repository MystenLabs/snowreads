{"id":"2408.04650","title":"Building Trust in Mental Health Chatbots: Safety Metrics and LLM-Based\n  Evaluation Tools","authors":"Jung In Park, Mahyar Abbasian, Iman Azimi, Dawn Bounds, Angela Jun,\n  Jaesu Han, Robert McCarron, Jessica Borelli, Jia Li, Mona Mahmoudi, Carmen\n  Wiedenhoeft, Amir Rahmani","authorsParsed":[["Park","Jung In",""],["Abbasian","Mahyar",""],["Azimi","Iman",""],["Bounds","Dawn",""],["Jun","Angela",""],["Han","Jaesu",""],["McCarron","Robert",""],["Borelli","Jessica",""],["Li","Jia",""],["Mahmoudi","Mona",""],["Wiedenhoeft","Carmen",""],["Rahmani","Amir",""]],"versions":[{"version":"v1","created":"Sat, 3 Aug 2024 19:57:49 GMT"}],"updateDate":"2024-08-12","timestamp":1722715069000,"abstract":"  Objective: This study aims to develop and validate an evaluation framework to\nensure the safety and reliability of mental health chatbots, which are\nincreasingly popular due to their accessibility, human-like interactions, and\ncontext-aware support. Materials and Methods: We created an evaluation\nframework with 100 benchmark questions and ideal responses, and five guideline\nquestions for chatbot responses. This framework, validated by mental health\nexperts, was tested on a GPT-3.5-turbo-based chatbot. Automated evaluation\nmethods explored included large language model (LLM)-based scoring, an agentic\napproach using real-time data, and embedding models to compare chatbot\nresponses against ground truth standards. Results: The results highlight the\nimportance of guidelines and ground truth for improving LLM evaluation\naccuracy. The agentic method, dynamically accessing reliable information,\ndemonstrated the best alignment with human assessments. Adherence to a\nstandardized, expert-validated framework significantly enhanced chatbot\nresponse safety and reliability. Discussion: Our findings emphasize the need\nfor comprehensive, expert-tailored safety evaluation metrics for mental health\nchatbots. While LLMs have significant potential, careful implementation is\nnecessary to mitigate risks. The superior performance of the agentic approach\nunderscores the importance of real-time data access in enhancing chatbot\nreliability. Conclusion: The study validated an evaluation framework for mental\nhealth chatbots, proving its effectiveness in improving safety and reliability.\nFuture work should extend evaluations to accuracy, bias, empathy, and privacy\nto ensure holistic assessment and responsible integration into healthcare.\nStandardized evaluations will build trust among users and professionals,\nfacilitating broader adoption and improved mental health support through\ntechnology.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Human-Computer Interaction","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}