{"id":"2407.15087","title":"Navigation Instruction Generation with BEV Perception and Large Language\n  Models","authors":"Sheng Fan, Rui Liu, Wenguan Wang, Yi Yang","authorsParsed":[["Fan","Sheng",""],["Liu","Rui",""],["Wang","Wenguan",""],["Yang","Yi",""]],"versions":[{"version":"v1","created":"Sun, 21 Jul 2024 08:05:29 GMT"}],"updateDate":"2024-07-23","timestamp":1721549129000,"abstract":"  Navigation instruction generation, which requires embodied agents to describe\nthe navigation routes, has been of great interest in robotics and\nhuman-computer interaction. Existing studies directly map the sequence of 2D\nperspective observations to route descriptions. Though straightforward, they\noverlook the geometric information and object semantics of the 3D environment.\nTo address these challenges, we propose BEVInstructor, which incorporates\nBird's Eye View (BEV) features into Multi-Modal Large Language Models (MLLMs)\nfor instruction generation. Specifically, BEVInstructor constructs a\nPerspectiveBEVVisual Encoder for the comprehension of 3D environments through\nfusing BEV and perspective features. To leverage the powerful language\ncapabilities of MLLMs, the fused representations are used as visual prompts for\nMLLMs, and perspective-BEV prompt tuning is proposed for parameter-efficient\nupdating. Based on the perspective-BEV prompts, BEVInstructor further adopts an\ninstance-guided iterative refinement pipeline, which improves the instructions\nin a progressive manner. BEVInstructor achieves impressive performance across\ndiverse datasets (i.e., R2R, REVERIE, and UrbanWalk).\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}