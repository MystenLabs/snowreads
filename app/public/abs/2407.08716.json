{"id":"2407.08716","title":"A Taxonomy for Data Contamination in Large Language Models","authors":"Medha Palavalli and Amanda Bertsch and Matthew R. Gormley","authorsParsed":[["Palavalli","Medha",""],["Bertsch","Amanda",""],["Gormley","Matthew R.",""]],"versions":[{"version":"v1","created":"Thu, 11 Jul 2024 17:50:34 GMT"}],"updateDate":"2024-07-12","timestamp":1720720234000,"abstract":"  Large language models pretrained on extensive web corpora demonstrate\nremarkable performance across a wide range of downstream tasks. However, a\ngrowing concern is data contamination, where evaluation datasets may be\ncontained in the pretraining corpus, inflating model performance.\nDecontamination, the process of detecting and removing such data, is a\npotential solution; yet these contaminants may originate from altered versions\nof the test set, evading detection during decontamination. How different types\nof contamination impact the performance of language models on downstream tasks\nis not fully understood. We present a taxonomy that categorizes the various\ntypes of contamination encountered by LLMs during the pretraining phase and\nidentify which types pose the highest risk. We analyze the impact of\ncontamination on two key NLP tasks -- summarization and question answering --\nrevealing how different types of contamination influence task performance\nduring evaluation.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}