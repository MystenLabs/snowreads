{"id":"2408.11316","title":"Probabilistic Medical Predictions of Large Language Models","authors":"Bowen Gu, Rishi J. Desai, Kueiyu Joshua Lin, Jie Yang","authorsParsed":[["Gu","Bowen",""],["Desai","Rishi J.",""],["Lin","Kueiyu Joshua",""],["Yang","Jie",""]],"versions":[{"version":"v1","created":"Wed, 21 Aug 2024 03:47:17 GMT"}],"updateDate":"2024-08-22","timestamp":1724212037000,"abstract":"  Large Language Models (LLMs) have demonstrated significant potential in\nclinical applications through prompt engineering, which enables the generation\nof flexible and diverse clinical predictions. However, they pose challenges in\nproducing prediction probabilities, which are essential for transparency and\nallowing clinicians to apply flexible probability thresholds in\ndecision-making. While explicit prompt instructions can lead LLMs to provide\nprediction probability numbers through text generation, LLMs' limitations in\nnumerical reasoning raise concerns about the reliability of these\ntext-generated probabilities. To assess this reliability, we compared explicit\nprobabilities derived from text generation to implicit probabilities calculated\nbased on the likelihood of predicting the correct label token. Experimenting\nwith six advanced open-source LLMs across five medical datasets, we found that\nthe performance of explicit probabilities was consistently lower than implicit\nprobabilities with respect to discrimination, precision, and recall. Moreover,\nthese differences were enlarged on small LLMs and imbalanced datasets,\nemphasizing the need for cautious interpretation and applications, as well as\nfurther research into robust probability estimation methods for LLMs in\nclinical contexts.\n","subjects":["Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"nKS5dTUwWpLqVD7_z1awFUu1C_LeRmzdgxfKBxOra20","pdfSize":"4289747"}
