{"id":"2407.13761","title":"SegPoint: Segment Any Point Cloud via Large Language Model","authors":"Shuting He, Henghui Ding, Xudong Jiang, Bihan Wen","authorsParsed":[["He","Shuting",""],["Ding","Henghui",""],["Jiang","Xudong",""],["Wen","Bihan",""]],"versions":[{"version":"v1","created":"Thu, 18 Jul 2024 17:58:03 GMT"}],"updateDate":"2024-07-19","timestamp":1721325483000,"abstract":"  Despite significant progress in 3D point cloud segmentation, existing methods\nprimarily address specific tasks and depend on explicit instructions to\nidentify targets, lacking the capability to infer and understand implicit user\nintentions in a unified framework. In this work, we propose a model, called\nSegPoint, that leverages the reasoning capabilities of a multi-modal Large\nLanguage Model (LLM) to produce point-wise segmentation masks across a diverse\nrange of tasks: 1) 3D instruction segmentation, 2) 3D referring segmentation,\n3) 3D semantic segmentation, and 4) 3D open-vocabulary semantic segmentation.\nTo advance 3D instruction research, we introduce a new benchmark, Instruct3D,\ndesigned to evaluate segmentation performance from complex and implicit\ninstructional texts, featuring 2,565 point cloud-instruction pairs. Our\nexperimental results demonstrate that SegPoint achieves competitive performance\non established benchmarks such as ScanRefer for referring segmentation and\nScanNet for semantic segmentation, while delivering outstanding outcomes on the\nInstruct3D dataset. To our knowledge, SegPoint is the first model to address\nthese varied segmentation tasks within a single framework, achieving\nsatisfactory performance.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}