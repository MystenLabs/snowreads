{"id":"2408.04829","title":"Hyper Recurrent Neural Network: Condition Mechanisms for Black-box Audio\n  Effect Modeling","authors":"Yen-Tung Yeh, Wen-Yi Hsiao, Yi-Hsuan Yang","authorsParsed":[["Yeh","Yen-Tung",""],["Hsiao","Wen-Yi",""],["Yang","Yi-Hsuan",""]],"versions":[{"version":"v1","created":"Fri, 9 Aug 2024 03:00:25 GMT"}],"updateDate":"2024-08-12","timestamp":1723172425000,"abstract":"  Recurrent neural networks (RNNs) have demonstrated impressive results for\nvirtual analog modeling of audio effects. These networks process time-domain\naudio signals using a series of matrix multiplication and nonlinear activation\nfunctions to emulate the behavior of the target device accurately. To\nadditionally model the effect of the knobs for an RNN-based model, existing\napproaches integrate control parameters by concatenating them channel-wisely\nwith some intermediate representation of the input signal. While this method is\nparameter-efficient, there is room to further improve the quality of generated\naudio because the concatenation-based conditioning method has limited capacity\nin modulating signals. In this paper, we propose three novel conditioning\nmechanisms for RNNs, tailored for black-box virtual analog modeling. These\nadvanced conditioning mechanisms modulate the model based on control\nparameters, yielding superior results to existing RNN- and CNN-based\narchitectures across various evaluation metrics.\n","subjects":["Computing Research Repository/Sound","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by/4.0/"}