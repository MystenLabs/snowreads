{"id":"2407.00765","title":"Structured and Balanced Multi-component and Multi-layer Neural Networks","authors":"Shijun Zhang, Hongkai Zhao, Yimin Zhong, Haomin Zhou","authorsParsed":[["Zhang","Shijun",""],["Zhao","Hongkai",""],["Zhong","Yimin",""],["Zhou","Haomin",""]],"versions":[{"version":"v1","created":"Sun, 30 Jun 2024 17:00:42 GMT"}],"updateDate":"2024-07-02","timestamp":1719766842000,"abstract":"  In this work, we propose a balanced multi-component and multi-layer neural\nnetwork (MMNN) structure to approximate functions with complex features with\nboth accuracy and efficiency in terms of degrees of freedom and computation\ncost. The main idea is motivated by a multi-component, each of which can be\napproximated effectively by a single-layer network, and multi-layer\ndecomposition in a \"divide-and-conquer\" type of strategy to deal with a complex\nfunction. While an easy modification to fully connected neural networks (FCNNs)\nor multi-layer perceptrons (MLPs) through the introduction of balanced\nmulti-component structures in the network, MMNNs achieve a significant\nreduction of training parameters, a much more efficient training process, and a\nmuch improved accuracy compared to FCNNs or MLPs. Extensive numerical\nexperiments are presented to illustrate the effectiveness of MMNNs in\napproximating high oscillatory functions and its automatic adaptivity in\ncapturing localized features.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Numerical Analysis","Computing Research Repository/Neural and Evolutionary Computing","Mathematics/Numerical Analysis","Statistics/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}