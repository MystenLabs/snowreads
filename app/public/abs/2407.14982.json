{"id":"2407.14982","title":"GreenStableYolo: Optimizing Inference Time and Image Quality of\n  Text-to-Image Generation","authors":"Jingzhi Gong, Sisi Li, Giordano d'Aloisio, Zishuo Ding, Yulong Ye,\n  William B. Langdon, Federica Sarro","authorsParsed":[["Gong","Jingzhi",""],["Li","Sisi",""],["d'Aloisio","Giordano",""],["Ding","Zishuo",""],["Ye","Yulong",""],["Langdon","William B.",""],["Sarro","Federica",""]],"versions":[{"version":"v1","created":"Sat, 20 Jul 2024 21:14:24 GMT"}],"updateDate":"2024-07-23","timestamp":1721510064000,"abstract":"  Tuning the parameters and prompts for improving AI-based text-to-image\ngeneration has remained a substantial yet unaddressed challenge. Hence we\nintroduce GreenStableYolo, which improves the parameters and prompts for Stable\nDiffusion to both reduce GPU inference time and increase image generation\nquality using NSGA-II and Yolo.\n  Our experiments show that despite a relatively slight trade-off (18%) in\nimage quality compared to StableYolo (which only considers image quality),\nGreenStableYolo achieves a substantial reduction in inference time (266% less)\nand a 526% higher hypervolume, thereby advancing the state-of-the-art for\ntext-to-image generation.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/"}