{"id":"2407.09722","title":"Multi-Token Joint Speculative Decoding for Accelerating Large Language\n  Model Inference","authors":"Zongyue Qin, Ziniu Hu, Zifan He, Neha Prakriya, Jason Cong, Yizhou Sun","authorsParsed":[["Qin","Zongyue",""],["Hu","Ziniu",""],["He","Zifan",""],["Prakriya","Neha",""],["Cong","Jason",""],["Sun","Yizhou",""]],"versions":[{"version":"v1","created":"Fri, 12 Jul 2024 23:29:54 GMT"}],"updateDate":"2024-07-16","timestamp":1720826994000,"abstract":"  Transformer-based Large language models (LLMs) have demonstrated their power\nin various tasks, but their inference incurs significant time and energy costs.\nTo accelerate LLM inference, speculative decoding uses a smaller model to\npropose one sequence of tokens, which are subsequently validated in batch by\nthe target large model. Compared with autoregressive decoding, speculative\ndecoding generates the same number of tokens with fewer runs of the large\nmodel, hence accelerating the overall inference by $1$-$2\\times$. However,\ngreedy decoding is not the optimal decoding algorithm in terms of output\nperplexity, which is a direct measurement of the effectiveness of a decoding\nalgorithm. An algorithm that has better output perplexity and even better\nefficiency than speculative decoding can be more useful in practice. To achieve\nthis seemingly contradictory goal, we first introduce multi-token joint greedy\ndecoding (MJGD), which greedily generates multiple tokens at each step based on\ntheir joint perplexity. We show that it leads to better perplexity for the\nwhole output. But the computation cost of MJGD is infeasible in practice. So we\nfurther propose multi-token joint speculative decoding (MJSD), which\napproximates and accelerates the MJGD from two aspects: it approximates the\njoint distribution of the large model with that of a small model, and uses a\nverification step to guarantee the accuracy of approximation; then it uses beam\ndecoding to accelerate the sequence generation from the joint distribution.\nCompared with vanilla speculative decoding, MJSD has two advantages: (1) it is\nan approximation of MJGD, thus achieving better output perplexity; (2)\nverification with joint likelihood allows it to accept the longest prefix\nsub-sequence of the draft tokens with valid perplexity, leading to better\nefficiency...\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}