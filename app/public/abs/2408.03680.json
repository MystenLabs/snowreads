{"id":"2408.03680","title":"Iterative Knowledge Distillation through Feedback-Driven Learning Cycles","authors":"Yujia Chen, Yang Ye, Zhongqi Li, Yuchi Ma, Cuiyun Gao","authorsParsed":[["Chen","Yujia",""],["Ye","Yang",""],["Li","Zhongqi",""],["Ma","Yuchi",""],["Gao","Cuiyun",""]],"versions":[{"version":"v1","created":"Wed, 7 Aug 2024 10:43:59 GMT"}],"updateDate":"2024-08-08","timestamp":1723027439000,"abstract":"  Large code models (LCMs) have remarkably advanced the field of code\nintelligence. Despite their impressive capabilities, they still face practical\nemployment challenges, such as high costs, limited accessibility of proprietary\nLCMs, and adaptability issues of ultra-large LCMs. These challenges highlight\nthe critical need for more accessible, lightweight yet effective LCMs. In this\npaper, we propose IterKD, an Iter Knowledge Distillation framework, which aims\nat continually transferring the programming capabilities of larger, advanced\nLCMs (Teacher) to smaller, less powerful LCMs (Student). IterKD consists of\nthree stages in one cycle: (1) Correct-and-Fault Knowledge Delivery stage aims\nat improving the student models capability to recognize errors while ensuring\nits basic programming skill during the knowledge transferring, which involves\ncorrectness-aware supervised learning and fault-aware contrastive learning\nmethods. (2) Multi-view Feedback stage aims at measuring the quality of results\ngenerated by the student model from two views, including model-based and static\ntool-based measurement; (3) Feedback-based Knowledge Update stage aims at\nupdating the student model adaptively by generating new questions at different\ndifficulty levels, in which the difficulty levels are categorized based on the\nfeedback in the last stage. By performing the training cycle iteratively, the\nstudent model is continuously refined through learning more advanced\nprogramming skills from the teacher model. Finally, based on the proposed\nIterKD framework, we develop a lightweight yet effective LCM, named IterCoder,\nwhich is built upon CodeLlama-7B. Experimental results show that IterCoder\nachieves a Pass@1 score of 65.2 on the HumanEval benchmark, outperforming\nover-30B-sized LCMs by an average of 47.51% and surpassing comparable-sized\nLCMs by an average of 118.47%.\n","subjects":["Computing Research Repository/Software Engineering"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}