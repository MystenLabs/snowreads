{"id":"2408.02606","title":"Backward explanations via redefinition of predicates","authors":"L\\'eo Sauli\\`eres and Martin C. Cooper and Florence Dupin de Saint Cyr","authorsParsed":[["Saulières","Léo",""],["Cooper","Martin C.",""],["Cyr","Florence Dupin de Saint",""]],"versions":[{"version":"v1","created":"Mon, 5 Aug 2024 16:31:38 GMT"}],"updateDate":"2024-08-06","timestamp":1722875498000,"abstract":"  History eXplanation based on Predicates (HXP), studies the behavior of a\nReinforcement Learning (RL) agent in a sequence of agent's interactions with\nthe environment (a history), through the prism of an arbitrary predicate. To\nthis end, an action importance score is computed for each action in the\nhistory. The explanation consists in displaying the most important actions to\nthe user. As the calculation of an action's importance is #W[1]-hard, it is\nnecessary for long histories to approximate the scores, at the expense of their\nquality. We therefore propose a new HXP method, called Backward-HXP, to provide\nexplanations for these histories without having to approximate scores.\nExperiments show the ability of B-HXP to summarise long histories.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computational Complexity"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"EeDOddeHN2i_1YF4AMXCO5bS0lAwn4hw9IEGUCYahpI","pdfSize":"4174060","txDigest":"93AFzgPrUfLTcdzZizk3Y3sps95rDqvhiLQAN3Z589Pm","endEpoch":"1","status":"CERTIFIED"}
