{"id":"2407.10221","title":"Stability of Least Square Approximation under Random Sampling","authors":"Zhiqiang Xu, Xinyue Zhang","authorsParsed":[["Xu","Zhiqiang",""],["Zhang","Xinyue",""]],"versions":[{"version":"v1","created":"Sun, 14 Jul 2024 14:25:19 GMT"}],"updateDate":"2024-07-16","timestamp":1720967119000,"abstract":"  This paper investigates the stability of the least squares approximation\n$P_m^n$ within the univariate polynomial space of degree $m$, denoted by\n${\\mathbb P}_m$. The approximation $P_m^n$ entails identifying a polynomial in\n${\\mathbb P}_m$ that approximates a function $f$ over a domain $X$ based on\nsamples of $f$ taken at $n$ randomly selected points, according to a specified\nmeasure $\\rho_X$. The primary goal is to determine the sampling rate necessary\nto ensure the stability of $P_m^n$. Assuming the sampling points are i.i.d.\nwith respect to a Jacobi weight function, we present the sampling rates that\nguarantee the stability of $P_m^n$. Specifically, for uniform random sampling,\nwe demonstrate that a sampling rate of $n \\asymp m^2$ is required to maintain\nstability. By integrating these findings with those of\nCohen-Davenport-Leviatan, we conclude that, for uniform random sampling, the\noptimal sampling rate for guaranteeing the stability of $P_m^n$ is $n \\asymp\nm^2$, up to a $\\log n$ factor. Motivated by this result, we extend the\nimpossibility theorem, previously applicable to equally spaced samples, to the\ncase of random samples, illustrating the balance between accuracy and stability\nin recovering analytic functions.\n","subjects":["Mathematics/Numerical Analysis","Computing Research Repository/Numerical Analysis"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}