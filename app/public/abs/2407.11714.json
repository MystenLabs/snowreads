{"id":"2407.11714","title":"Improving Unsupervised Video Object Segmentation via Fake Flow\n  Generation","authors":"Suhwan Cho, Minhyeok Lee, Jungho Lee, Donghyeong Kim, Seunghoon Lee,\n  Sungmin Woo, Sangyoun Lee","authorsParsed":[["Cho","Suhwan",""],["Lee","Minhyeok",""],["Lee","Jungho",""],["Kim","Donghyeong",""],["Lee","Seunghoon",""],["Woo","Sungmin",""],["Lee","Sangyoun",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 13:32:50 GMT"}],"updateDate":"2024-07-17","timestamp":1721136770000,"abstract":"  Unsupervised video object segmentation (VOS), also known as video salient\nobject detection, aims to detect the most prominent object in a video at the\npixel level. Recently, two-stream approaches that leverage both RGB images and\noptical flow maps have gained significant attention. However, the limited\namount of training data remains a substantial challenge. In this study, we\npropose a novel data generation method that simulates fake optical flows from\nsingle images, thereby creating large-scale training data for stable network\nlearning. Inspired by the observation that optical flow maps are highly\ndependent on depth maps, we generate fake optical flows by refining and\naugmenting the estimated depth maps of each image. By incorporating our\nsimulated image-flow pairs, we achieve new state-of-the-art performance on all\npublic benchmark datasets without relying on complex modules. We believe that\nour data generation method represents a potential breakthrough for future VOS\nresearch.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}