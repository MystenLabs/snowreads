{"id":"2407.01371","title":"Binary Losses for Density Ratio Estimation","authors":"Werner Zellinger","authorsParsed":[["Zellinger","Werner",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 15:24:34 GMT"}],"updateDate":"2024-07-02","timestamp":1719847474000,"abstract":"  Estimating the ratio of two probability densities from finitely many\nobservations of the densities, is a central problem in machine learning and\nstatistics. A large class of methods constructs estimators from binary\nclassifiers which distinguish observations from the two densities. However, the\nerror of these constructions depends on the choice of the binary loss function,\nraising the question of which loss function to choose based on desired error\nproperties. In this work, we start from prescribed error measures in a class of\nBregman divergences and characterize all loss functions that lead to density\nratio estimators with a small error. Our characterization provides a simple\nrecipe for constructing loss functions with certain properties, such as loss\nfunctions that prioritize an accurate estimation of large values. This\ncontrasts with classical loss functions, such as the logistic loss or boosting\nloss, which prioritize accurate estimation of small values. We provide\nnumerical illustrations with kernel methods and test their performance in\napplications of parameter selection for deep domain adaptation.\n","subjects":["Computing Research Repository/Machine Learning","Statistics/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"LcjCf_Q_xI0L-Drr5xgs9trXftiEieBjuS941WKBTrY","pdfSize":"7835118"}
