{"id":"2407.04859","title":"Hybrid Primal Sketch: Combining Analogy, Qualitative Representations,\n  and Computer Vision for Scene Understanding","authors":"Kenneth D. Forbus, Kezhen Chen, Wangcheng Xu, Madeline Usher","authorsParsed":[["Forbus","Kenneth D.",""],["Chen","Kezhen",""],["Xu","Wangcheng",""],["Usher","Madeline",""]],"versions":[{"version":"v1","created":"Fri, 5 Jul 2024 20:44:35 GMT"}],"updateDate":"2024-07-09","timestamp":1720212275000,"abstract":"  One of the purposes of perception is to bridge between sensors and conceptual\nunderstanding. Marr's Primal Sketch combined initial edge-finding with multiple\ndownstream processes to capture aspects of visual perception such as grouping\nand stereopsis. Given the progress made in multiple areas of AI since then, we\nhave developed a new framework inspired by Marr's work, the Hybrid Primal\nSketch, which combines computer vision components into an ensemble to produce\nsketch-like entities which are then further processed by CogSketch, our model\nof high-level human vision, to produce both more detailed shape representations\nand scene representations which can be used for data-efficient learning via\nanalogical generalization. This paper describes our theoretical framework,\nsummarizes several previous experiments, and outlines a new experiment in\nprogress on diagram understanding.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"F1BiYkKUh9bNAtwboiac4FQVl6SlmLpPHP3iaICE09Y","pdfSize":"1205850"}
