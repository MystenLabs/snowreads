{"id":"2407.01291","title":"Lightweight Zero-shot Text-to-Speech with Mixture of Adapters","authors":"Kenichi Fujita, Takanori Ashihara, Marc Delcroix, and Yusuke Ijima","authorsParsed":[["Fujita","Kenichi",""],["Ashihara","Takanori",""],["Delcroix","Marc",""],["Ijima","Yusuke",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 13:45:31 GMT"}],"updateDate":"2024-07-02","timestamp":1719841531000,"abstract":"  The advancements in zero-shot text-to-speech (TTS) methods, based on\nlarge-scale models, have demonstrated high fidelity in reproducing speaker\ncharacteristics. However, these models are too large for practical daily use.\nWe propose a lightweight zero-shot TTS method using a mixture of adapters\n(MoA). Our proposed method incorporates MoA modules into the decoder and the\nvariance adapter of a non-autoregressive TTS model. These modules enhance the\nability to adapt a wide variety of speakers in a zero-shot manner by selecting\nappropriate adapters associated with speaker characteristics on the basis of\nspeaker embeddings. Our method achieves high-quality speech synthesis with\nminimal additional parameters. Through objective and subjective evaluations, we\nconfirmed that our method achieves better performance than the baseline with\nless than 40\\% of parameters at 1.9 times faster inference speed. Audio samples\nare available on our demo page\n(https://ntt-hilab-gensp.github.io/is2024lightweightTTS/).\n","subjects":["Computing Research Repository/Sound","Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by-sa/4.0/"}