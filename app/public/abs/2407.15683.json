{"id":"2407.15683","title":"Enhancing Transferability of Targeted Adversarial Examples: A\n  Self-Universal Perspective","authors":"Bowen Peng, Li Liu, Tianpeng Liu, Zhen Liu, Yongxiang Liu","authorsParsed":[["Peng","Bowen",""],["Liu","Li",""],["Liu","Tianpeng",""],["Liu","Zhen",""],["Liu","Yongxiang",""]],"versions":[{"version":"v1","created":"Mon, 22 Jul 2024 14:51:28 GMT"}],"updateDate":"2024-07-23","timestamp":1721659888000,"abstract":"  Transfer-based targeted adversarial attacks against black-box deep neural\nnetworks (DNNs) have been proven to be significantly more challenging than\nuntargeted ones. The impressive transferability of current SOTA, the generative\nmethods, comes at the cost of requiring massive amounts of additional data and\ntime-consuming training for each targeted label. This results in limited\nefficiency and flexibility, significantly hindering their deployment in\npractical applications. In this paper, we offer a self-universal perspective\nthat unveils the great yet underexplored potential of input transformations in\npursuing this goal. Specifically, transformations universalize gradient-based\nattacks with intrinsic but overlooked semantics inherent within individual\nimages, exhibiting similar scalability and comparable results to time-consuming\nlearning over massive additional data from diverse classes. We also contribute\na surprising empirical insight that one of the most fundamental\ntransformations, simple image scaling, is highly effective, scalable,\nsufficient, and necessary in enhancing targeted transferability. We further\naugment simple scaling with orthogonal transformations and block-wise\napplicability, resulting in the Simple, faSt, Self-universal yet Strong Scale\nTransformation (S$^4$ST) for self-universal TTA. On the ImageNet-Compatible\nbenchmark dataset, our method achieves a 19.8% improvement in the average\ntargeted transfer success rate against various challenging victim models over\nexisting SOTA transformation methods while only consuming 36% time for\nattacking. It also outperforms resource-intensive attacks by a large margin in\nvarious challenging settings.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}