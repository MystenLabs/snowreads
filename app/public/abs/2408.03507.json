{"id":"2408.03507","title":"GUI Element Detection Using SOTA YOLO Deep Learning Models","authors":"Seyed Shayan Daneshvar and Shaowei Wang","authorsParsed":[["Daneshvar","Seyed Shayan",""],["Wang","Shaowei",""]],"versions":[{"version":"v1","created":"Wed, 7 Aug 2024 02:18:39 GMT"}],"updateDate":"2024-08-08","timestamp":1722997119000,"abstract":"  Detection of Graphical User Interface (GUI) elements is a crucial task for\nautomatic code generation from images and sketches, GUI testing, and GUI\nsearch. Recent studies have leveraged both old-fashioned and modern computer\nvision (CV) techniques. Oldfashioned methods utilize classic image processing\nalgorithms (e.g. edge detection and contour detection) and modern methods use\nmature deep learning solutions for general object detection tasks. GUI element\ndetection, however, is a domain-specific case of object detection, in which\nobjects overlap more often, and are located very close to each other, plus the\nnumber of object classes is considerably lower, yet there are more objects in\nthe images compared to natural images. Hence, the studies that have been\ncarried out on comparing various object detection models, might not apply to\nGUI element detection. In this study, we evaluate the performance of the four\nmost recent successful YOLO models for general object detection tasks on GUI\nelement detection and investigate their accuracy performance in detecting\nvarious GUI elements.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Software Engineering"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}