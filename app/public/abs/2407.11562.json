{"id":"2407.11562","title":"RobotKeyframing: Learning Locomotion with High-Level Objectives via\n  Mixture of Dense and Sparse Rewards","authors":"Fatemeh Zargarbashi, Jin Cheng, Dongho Kang, Robert Sumner, Stelian\n  Coros","authorsParsed":[["Zargarbashi","Fatemeh",""],["Cheng","Jin",""],["Kang","Dongho",""],["Sumner","Robert",""],["Coros","Stelian",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 10:15:35 GMT"}],"updateDate":"2024-07-17","timestamp":1721124935000,"abstract":"  This paper presents a novel learning-based control framework that uses\nkeyframing to incorporate high-level objectives in natural locomotion for\nlegged robots. These high-level objectives are specified as a variable number\nof partial or complete pose targets that are spaced arbitrarily in time. Our\nproposed framework utilizes a multi-critic reinforcement learning algorithm to\neffectively handle the mixture of dense and sparse rewards. Additionally, it\nemploys a transformer-based encoder to accommodate a variable number of input\ntargets, each associated with specific time-to-arrivals. Throughout simulation\nand hardware experiments, we demonstrate that our framework can effectively\nsatisfy the target keyframe sequence at the required times. In the experiments,\nthe multi-critic method significantly reduces the effort of hyperparameter\ntuning compared to the standard single-critic alternative. Moreover, the\nproposed transformer-based architecture enables robots to anticipate future\ngoals, which results in quantitative improvements in their ability to reach\ntheir targets.\n","subjects":["Computing Research Repository/Robotics","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}