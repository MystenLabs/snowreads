{"id":"2408.10202","title":"SANER: Annotation-free Societal Attribute Neutralizer for Debiasing CLIP","authors":"Yusuke Hirota, Min-Hung Chen, Chien-Yi Wang, Yuta Nakashima, Yu-Chiang\n  Frank Wang, Ryo Hachiuma","authorsParsed":[["Hirota","Yusuke",""],["Chen","Min-Hung",""],["Wang","Chien-Yi",""],["Nakashima","Yuta",""],["Wang","Yu-Chiang Frank",""],["Hachiuma","Ryo",""]],"versions":[{"version":"v1","created":"Mon, 19 Aug 2024 17:57:28 GMT"}],"updateDate":"2024-08-20","timestamp":1724090248000,"abstract":"  Large-scale vision-language models, such as CLIP, are known to contain\nharmful societal bias regarding protected attributes (e.g., gender and age). In\nthis paper, we aim to address the problems of societal bias in CLIP. Although\nprevious studies have proposed to debias societal bias through adversarial\nlearning or test-time projecting, our comprehensive study of these works\nidentifies two critical limitations: 1) loss of attribute information when it\nis explicitly disclosed in the input and 2) use of the attribute annotations\nduring debiasing process. To mitigate societal bias in CLIP and overcome these\nlimitations simultaneously, we introduce a simple-yet-effective debiasing\nmethod called SANER (societal attribute neutralizer) that eliminates attribute\ninformation from CLIP text features only of attribute-neutral descriptions.\nExperimental results show that SANER, which does not require attribute\nannotations and preserves original information for attribute-specific\ndescriptions, demonstrates superior debiasing ability than the existing\nmethods.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"xi2K6NImsUO0GiQY3s0vN9OCX_4RpzeGYViK_hri3yM","pdfSize":"7472923"}
