{"id":"2408.03160","title":"User-in-the-loop Evaluation of Multimodal LLMs for Activity Assistance","authors":"Mrinal Verghese, Brian Chen, Hamid Eghbalzadeh, Tushar Nagarajan, Ruta\n  Desai","authorsParsed":[["Verghese","Mrinal",""],["Chen","Brian",""],["Eghbalzadeh","Hamid",""],["Nagarajan","Tushar",""],["Desai","Ruta",""]],"versions":[{"version":"v1","created":"Sun, 4 Aug 2024 06:12:42 GMT"},{"version":"v2","created":"Mon, 12 Aug 2024 01:59:00 GMT"}],"updateDate":"2024-08-14","timestamp":1722751962000,"abstract":"  Our research investigates the capability of modern multimodal reasoning\nmodels, powered by Large Language Models (LLMs), to facilitate vision-powered\nassistants for multi-step daily activities. Such assistants must be able to 1)\nencode relevant visual history from the assistant's sensors, e.g., camera, 2)\nforecast future actions for accomplishing the activity, and 3) replan based on\nthe user in the loop. To evaluate the first two capabilities, grounding visual\nhistory and forecasting in short and long horizons, we conduct benchmarking of\ntwo prominent classes of multimodal LLM approaches -- Socratic Models and\nVision Conditioned Language Models (VCLMs) on video-based action anticipation\ntasks using offline datasets. These offline benchmarks, however, do not allow\nus to close the loop with the user, which is essential to evaluate the\nreplanning capabilities and measure successful activity completion in assistive\nscenarios. To that end, we conduct a first-of-its-kind user study, with 18\nparticipants performing 3 different multi-step cooking activities while wearing\nan egocentric observation device called Aria and following assistance from\nmultimodal LLMs. We find that the Socratic approach outperforms VCLMs in both\noffline and online settings. We further highlight how grounding long visual\nhistory, common in activity assistance, remains challenging in current models,\nespecially for VCLMs, and demonstrate that offline metrics do not indicate\nonline performance.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/"}