{"id":"2407.01317","title":"Leveraging Speaker Embeddings in End-to-End Neural Diarization for\n  Two-Speaker Scenarios","authors":"Juan Ignacio Alvarez-Trejos, Beltr\\'an Labrador, Alicia Lozano-Diez","authorsParsed":[["Alvarez-Trejos","Juan Ignacio",""],["Labrador","Beltr√°n",""],["Lozano-Diez","Alicia",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 14:26:28 GMT"}],"updateDate":"2024-07-02","timestamp":1719843988000,"abstract":"  End-to-end neural speaker diarization systems are able to address the speaker\ndiarization task while effectively handling speech overlap. This work explores\nthe incorporation of speaker information embeddings into the end-to-end systems\nto enhance the speaker discriminative capabilities, while maintaining their\noverlap handling strengths. To achieve this, we propose several methods for\nincorporating these embeddings along the acoustic features. Furthermore, we\ndelve into an analysis of the correct handling of silence frames, the window\nlength for extracting speaker embeddings and the transformer encoder size. The\neffectiveness of our proposed approach is thoroughly evaluated on the CallHome\ndataset for the two-speaker diarization task, with results that demonstrate a\nsignificant reduction in diarization error rates achieving a relative\nimprovement of a 10.78% compared to the baseline end-to-end model.\n","subjects":["Computing Research Repository/Sound","Computing Research Repository/Artificial Intelligence","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by-sa/4.0/"}