{"id":"2407.01898","title":"Learning Granular Media Avalanche Behavior for Indirectly Manipulating\n  Obstacles on a Granular Slope","authors":"Haodi Hu, Feifei Qian, Daniel Seita","authorsParsed":[["Hu","Haodi",""],["Qian","Feifei",""],["Seita","Daniel",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 02:46:26 GMT"}],"updateDate":"2024-07-03","timestamp":1719888386000,"abstract":"  Legged robot locomotion on sand slopes is challenging due to the complex\ndynamics of granular media and how the lack of solid surfaces can hinder\nlocomotion. A promising strategy, inspired by ghost crabs and other organisms\nin nature, is to strategically interact with rocks, debris, and other obstacles\nto facilitate movement. To provide legged robots with this ability, we present\na novel approach that leverages avalanche dynamics to indirectly manipulate\nobjects on a granular slope. We use a Vision Transformer (ViT) to process image\nrepresentations of granular dynamics and robot excavation actions. The ViT\npredicts object movement, which we use to determine which leg excavation action\nto execute. We collect training data from 100 real physical trials and, at test\ntime, deploy our trained model in novel settings. Experimental results suggest\nthat our model can accurately predict object movements and achieve a success\nrate $\\geq 80\\%$ in a variety of manipulation tasks with up to four obstacles,\nand can also generalize to objects with different physics properties. To our\nknowledge, this is the first paper to leverage granular media avalanche\ndynamics to indirectly manipulate objects on granular slopes. Supplementary\nmaterial is available at https://sites.google.com/view/grain-corl2024/home.\n","subjects":["Computing Research Repository/Robotics"],"license":"http://creativecommons.org/licenses/by/4.0/"}