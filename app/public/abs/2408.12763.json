{"id":"2408.12763","title":"Assessing Modality Bias in Video Question Answering Benchmarks with\n  Multimodal Large Language Models","authors":"Jean Park, Kuk Jin Jang, Basam Alasaly, Sriharsha Mopidevi, Andrew\n  Zolensky, Eric Eaton, Insup Lee, Kevin Johnson","authorsParsed":[["Park","Jean",""],["Jang","Kuk Jin",""],["Alasaly","Basam",""],["Mopidevi","Sriharsha",""],["Zolensky","Andrew",""],["Eaton","Eric",""],["Lee","Insup",""],["Johnson","Kevin",""]],"versions":[{"version":"v1","created":"Thu, 22 Aug 2024 23:32:42 GMT"}],"updateDate":"2024-08-26","timestamp":1724369562000,"abstract":"  Multimodal large language models (MLLMs) can simultaneously process visual,\ntextual, and auditory data, capturing insights that complement human analysis.\nHowever, existing video question-answering (VidQA) benchmarks and datasets\noften exhibit a bias toward a single modality, despite the goal of requiring\nadvanced reasoning skills that integrate diverse modalities to answer the\nqueries. In this work, we introduce the modality importance score (MIS) to\nidentify such bias. It is designed to assess which modality embeds the\nnecessary information to answer the question. Additionally, we propose an\ninnovative method using state-of-the-art MLLMs to estimate the modality\nimportance, which can serve as a proxy for human judgments of modality\nperception. With this MIS, we demonstrate the presence of unimodal bias and the\nscarcity of genuinely multimodal questions in existing datasets. We further\nvalidate the modality importance score with multiple ablation studies to\nevaluate the performance of MLLMs on permuted feature sets. Our results\nindicate that current models do not effectively integrate information due to\nmodality imbalance in existing datasets. Our proposed MLLM-derived MIS can\nguide the curation of modality-balanced datasets that advance multimodal\nlearning and enhance MLLMs' capabilities to understand and utilize synergistic\nrelations across modalities.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}