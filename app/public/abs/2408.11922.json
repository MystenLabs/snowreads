{"id":"2408.11922","title":"Evaluating Four Methods for Detecting Differential Item Functioning in\n  Large-Scale Assessments with More Than Two Groups","authors":"Dandan Chen Kaptur, Jinming Zhang","authorsParsed":[["Kaptur","Dandan Chen",""],["Zhang","Jinming",""]],"versions":[{"version":"v1","created":"Wed, 21 Aug 2024 18:14:13 GMT"}],"updateDate":"2024-08-23","timestamp":1724264053000,"abstract":"  This study evaluated four multi-group differential item functioning (DIF)\nmethods (the root mean square deviation approach, Wald-1, generalized logistic\nregression procedure, and generalized Mantel-Haenszel method) via Monte Carlo\nsimulation of controlled testing conditions. These conditions varied in the\nnumber of groups, the ability and sample size of the DIF-contaminated group,\nthe parameter associated with DIF, and the proportion of DIF items. When\ncomparing Type-I error rates and powers of the methods, we showed that the RMSD\napproach yielded the best Type-I error rates when it was used with\nmodel-predicted cutoff values. Also, this approach was found to be overly\nconservative when used with the commonly used cutoff value of 0.1. Implications\nfor future research for educational researchers and practitioners were\ndiscussed.\n","subjects":["Statistics/Applications"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"yH2vxjtnDNebefhvYc2FR1xUzyHkrXuFKBw-IoJbCTQ","pdfSize":"3923544"}
