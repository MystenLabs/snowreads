{"id":"2408.03545","title":"CLIP-based Point Cloud Classification via Point Cloud to Image\n  Translation","authors":"Shuvozit Ghose, Manyi Li, Yiming Qian, Yang Wang","authorsParsed":[["Ghose","Shuvozit",""],["Li","Manyi",""],["Qian","Yiming",""],["Wang","Yang",""]],"versions":[{"version":"v1","created":"Wed, 7 Aug 2024 04:50:05 GMT"}],"updateDate":"2024-08-08","timestamp":1723006205000,"abstract":"  Point cloud understanding is an inherently challenging problem because of the\nsparse and unordered structure of the point cloud in the 3D space. Recently,\nContrastive Vision-Language Pre-training (CLIP) based point cloud\nclassification model i.e. PointCLIP has added a new direction in the point\ncloud classification research domain. In this method, at first multi-view depth\nmaps are extracted from the point cloud and passed through the CLIP visual\nencoder. To transfer the 3D knowledge to the network, a small network called an\nadapter is fine-tuned on top of the CLIP visual encoder. PointCLIP has two\nlimitations. Firstly, the point cloud depth maps lack image information which\nis essential for tasks like classification and recognition. Secondly, the\nadapter only relies on the global representation of the multi-view features.\nMotivated by this observation, we propose a Pretrained Point Cloud to Image\nTranslation Network (PPCITNet) that produces generalized colored images along\nwith additional salient visual cues to the point cloud depth maps so that it\ncan achieve promising performance on point cloud classification and\nunderstanding. In addition, we propose a novel viewpoint adapter that combines\nthe view feature processed by each viewpoint as well as the global intertwined\nknowledge that exists across the multi-view features. The experimental results\ndemonstrate the superior performance of the proposed model over existing\nstate-of-the-art CLIP-based models on ModelNet10, ModelNet40, and ScanobjectNN\ndatasets.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}