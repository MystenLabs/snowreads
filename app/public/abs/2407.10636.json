{"id":"2407.10636","title":"Temporal Residual Guided Diffusion Framework for Event-Driven Video\n  Reconstruction","authors":"Lin Zhu, Yunlong Zheng, Yijun Zhang, Xiao Wang, Lizhi Wang, Hua Huang","authorsParsed":[["Zhu","Lin",""],["Zheng","Yunlong",""],["Zhang","Yijun",""],["Wang","Xiao",""],["Wang","Lizhi",""],["Huang","Hua",""]],"versions":[{"version":"v1","created":"Mon, 15 Jul 2024 11:48:57 GMT"}],"updateDate":"2024-07-16","timestamp":1721044137000,"abstract":"  Event-based video reconstruction has garnered increasing attention due to its\nadvantages, such as high dynamic range and rapid motion capture capabilities.\nHowever, current methods often prioritize the extraction of temporal\ninformation from continuous event flow, leading to an overemphasis on\nlow-frequency texture features in the scene, resulting in over-smoothing and\nblurry artifacts. Addressing this challenge necessitates the integration of\nconditional information, encompassing temporal features, low-frequency texture,\nand high-frequency events, to guide the Denoising Diffusion Probabilistic Model\n(DDPM) in producing accurate and natural outputs. To tackle this issue, we\nintroduce a novel approach, the Temporal Residual Guided Diffusion Framework,\nwhich effectively leverages both temporal and frequency-based event priors. Our\nframework incorporates three key conditioning modules: a pre-trained\nlow-frequency intensity estimation module, a temporal recurrent encoder module,\nand an attention-based high-frequency prior enhancement module. In order to\ncapture temporal scene variations from the events at the current moment, we\nemploy a temporal-domain residual image as the target for the diffusion model.\nThrough the combination of these three conditioning paths and the temporal\nresidual framework, our framework excels in reconstructing high-quality videos\nfrom event flow, mitigating issues such as artifacts and over-smoothing\ncommonly observed in previous approaches. Extensive experiments conducted on\nmultiple benchmark datasets validate the superior performance of our framework\ncompared to prior event-based reconstruction methods.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}