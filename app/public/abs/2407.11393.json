{"id":"2407.11393","title":"CIC-BART-SSA: Controllable Image Captioning with Structured Semantic\n  Augmentation","authors":"Kalliopi Basioti, Mohamed A. Abdelsalam, Federico Fancellu, Vladimir\n  Pavlovic, Afsaneh Fazly","authorsParsed":[["Basioti","Kalliopi",""],["Abdelsalam","Mohamed A.",""],["Fancellu","Federico",""],["Pavlovic","Vladimir",""],["Fazly","Afsaneh",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 05:26:12 GMT"},{"version":"v2","created":"Wed, 17 Jul 2024 16:40:05 GMT"}],"updateDate":"2024-07-18","timestamp":1721107572000,"abstract":"  Controllable Image Captioning (CIC) aims at generating natural language\ndescriptions for an image, conditioned on information provided by end users,\ne.g., regions, entities or events of interest. However, available\nimage-language datasets mainly contain captions that describe the entirety of\nan image, making them ineffective for training CIC models that can potentially\nattend to any subset of regions or relationships. To tackle this challenge, we\npropose a novel, fully automatic method to sample additional focused and\nvisually grounded captions using a unified structured semantic representation\nbuilt on top of the existing set of captions associated with an image. We\nleverage Abstract Meaning Representation (AMR), a cross-lingual graph-based\nsemantic formalism, to encode all possible spatio-semantic relations between\nentities, beyond the typical spatial-relations-only focus of current methods.\nWe use this Structured Semantic Augmentation (SSA) framework to augment\nexisting image-caption datasets with the grounded controlled captions,\nincreasing their spatial and semantic diversity and focal coverage. We then\ndevelop a new model, CIC-BART-SSA, specifically tailored for the CIC task, that\nsources its control signals from SSA-diversified datasets. We empirically show\nthat, compared to SOTA CIC models, CIC-BART-SSA generates captions that are\nsuperior in diversity and text quality, are competitive in controllability,\nand, importantly, minimize the gap between broad and highly focused controlled\ncaptioning performance by efficiently generalizing to the challenging highly\nfocused scenarios. Code is available at\nhttps://github.com/SamsungLabs/CIC-BART-SSA.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}