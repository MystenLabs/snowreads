{"id":"2408.16504","title":"A Simple and Generalist Approach for Panoptic Segmentation","authors":"Nedyalko Prisadnikov, Wouter Van Gansbeke, Danda Pani Paudel, Luc Van\n  Gool","authorsParsed":[["Prisadnikov","Nedyalko",""],["Van Gansbeke","Wouter",""],["Paudel","Danda Pani",""],["Van Gool","Luc",""]],"versions":[{"version":"v1","created":"Thu, 29 Aug 2024 13:02:12 GMT"}],"updateDate":"2024-08-30","timestamp":1724936532000,"abstract":"  Generalist vision models aim for one and the same architecture for a variety\nof vision tasks. While such shared architecture may seem attractive, generalist\nmodels tend to be outperformed by their bespoken counterparts, especially in\nthe case of panoptic segmentation. We address this problem by introducing two\nkey contributions, without compromising the desirable properties of generalist\nmodels. These contributions are: (i) a positional-embedding (PE) based loss for\nimproved centroid regressions; (ii) Edge Distance Sampling (EDS) for the better\nseparation of instance boundaries. The PE-based loss facilitates a better\nper-pixel regression of the associated instance's centroid, whereas EDS\ncontributes by carefully handling the void regions (caused by missing labels)\nand smaller instances. These two simple yet effective modifications\nsignificantly improve established baselines, while achieving state-of-the-art\nresults among all generalist solutions. More specifically, our method achieves\na panoptic quality(PQ) of 52.5 on the COCO dataset, which is an improvement of\n10 points over the best model with similar approach (Painter), and is superior\nby 2 to the best performing diffusion-based method Pix2Seq-$\\mathcal{D}$.\nFurthermore, we provide insights into and an in-depth analysis of our\ncontributions through exhaustive experiments. Our source code and model weights\nwill be made publicly available.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}