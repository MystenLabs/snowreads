{"id":"2408.00298","title":"Tails Tell Tales: Chapter-Wide Manga Transcriptions with Character Names","authors":"Ragav Sachdeva, Gyungin Shin, Andrew Zisserman","authorsParsed":[["Sachdeva","Ragav",""],["Shin","Gyungin",""],["Zisserman","Andrew",""]],"versions":[{"version":"v1","created":"Thu, 1 Aug 2024 05:47:04 GMT"}],"updateDate":"2024-08-02","timestamp":1722491224000,"abstract":"  Enabling engagement of manga by visually impaired individuals presents a\nsignificant challenge due to its inherently visual nature. With the goal of\nfostering accessibility, this paper aims to generate a dialogue transcript of a\ncomplete manga chapter, entirely automatically, with a particular emphasis on\nensuring narrative consistency. This entails identifying (i) what is being\nsaid, i.e., detecting the texts on each page and classifying them into\nessential vs non-essential, and (ii) who is saying it, i.e., attributing each\ndialogue to its speaker, while ensuring the same characters are named\nconsistently throughout the chapter.\n  To this end, we introduce: (i) Magiv2, a model that is capable of generating\nhigh-quality chapter-wide manga transcripts with named characters and\nsignificantly higher precision in speaker diarisation over prior works; (ii) an\nextension of the PopManga evaluation dataset, which now includes annotations\nfor speech-bubble tail boxes, associations of text to corresponding tails,\nclassifications of text as essential or non-essential, and the identity for\neach character box; and (iii) a new character bank dataset, which comprises\nover 11K characters from 76 manga series, featuring 11.5K exemplar character\nimages in total, as well as a list of chapters in which they appear. The code,\ntrained model, and both datasets can be found at:\nhttps://github.com/ragavsachdeva/magi\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}