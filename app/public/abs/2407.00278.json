{"id":"2407.00278","title":"PerAct2: Benchmarking and Learning for Robotic Bimanual Manipulation\n  Tasks","authors":"Markus Grotz, Mohit Shridhar, Tamim Asfour, Dieter Fox","authorsParsed":[["Grotz","Markus",""],["Shridhar","Mohit",""],["Asfour","Tamim",""],["Fox","Dieter",""]],"versions":[{"version":"v1","created":"Sat, 29 Jun 2024 02:06:01 GMT"},{"version":"v2","created":"Wed, 31 Jul 2024 17:57:37 GMT"}],"updateDate":"2024-08-01","timestamp":1719626761000,"abstract":"  Bimanual manipulation is challenging due to precise spatial and temporal\ncoordination required between two arms. While there exist several real-world\nbimanual systems, there is a lack of simulated benchmarks with a large task\ndiversity for systematically studying bimanual capabilities across a wide range\nof tabletop tasks. This paper addresses the gap by extending RLBench to\nbimanual manipulation. We open-source our code and benchmark comprising 13 new\ntasks with 23 unique task variations, each requiring a high degree of\ncoordination and adaptability. To kickstart the benchmark, we extended several\nstate-of-the art methods to bimanual manipulation and also present a\nlanguage-conditioned behavioral cloning agent -- PerAct2, which enables the\nlearning and execution of bimanual 6-DoF manipulation tasks. Our novel network\narchitecture efficiently integrates language processing with action prediction,\nallowing robots to understand and perform complex bimanual tasks in response to\nuser-specified goals. Project website with code is available at:\nhttp://bimanual.github.io\n","subjects":["Computing Research Repository/Robotics","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}