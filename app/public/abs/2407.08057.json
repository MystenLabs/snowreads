{"id":"2407.08057","title":"Imitation Learning with Additional Constraints on Motion Style using\n  Parametric Bias","authors":"Kento Kawaharazuka and Yoichiro Kawamura and Kei Okada and Masayuki\n  Inaba","authorsParsed":[["Kawaharazuka","Kento",""],["Kawamura","Yoichiro",""],["Okada","Kei",""],["Inaba","Masayuki",""]],"versions":[{"version":"v1","created":"Wed, 10 Jul 2024 21:32:43 GMT"}],"updateDate":"2024-07-12","timestamp":1720647163000,"abstract":"  Imitation learning is one of the methods for reproducing human demonstration\nadaptively in robots. So far, it has been found that generalization ability of\nthe imitation learning enables the robots to perform tasks adaptably in\nuntrained environments. However, motion styles such as motion trajectory and\nthe amount of force applied depend largely on the dataset of human\ndemonstration, and settle down to an average motion style. In this study, we\npropose a method that adds parametric bias to the conventional imitation\nlearning network and can add constraints to the motion style. By experiments\nusing PR2 and the musculoskeletal humanoid MusashiLarm, we show that it is\npossible to perform tasks by changing its motion style as intended with\nconstraints on joint velocity, muscle length velocity, and muscle tension.\n","subjects":["Computing Research Repository/Robotics"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}