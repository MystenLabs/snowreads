{"id":"2407.05898","title":"Contrastive Learning of Preferences with a Contextual InfoNCE Loss","authors":"Timo Bertram, Johannes F\\\"urnkranz, Martin M\\\"uller","authorsParsed":[["Bertram","Timo",""],["Fürnkranz","Johannes",""],["Müller","Martin",""]],"versions":[{"version":"v1","created":"Mon, 8 Jul 2024 13:05:08 GMT"}],"updateDate":"2024-07-09","timestamp":1720443908000,"abstract":"  A common problem in contextual preference ranking is that a single preferred\naction is compared against several choices, thereby blowing up the complexity\nand skewing the preference distribution. In this work, we show how one can\nsolve this problem via a suitable adaptation of the CLIP framework.This\nadaptation is not entirely straight-forward, because although the InfoNCE loss\nused by CLIP has achieved great success in computer vision and multi-modal\ndomains, its batch-construction technique requires the ability to compare\narbitrary items, and is not well-defined if one item has multiple positive\nassociations in the same batch. We empirically demonstrate the utility of our\nadapted version of the InfoNCE loss in the domain of collectable card games,\nwhere we aim to learn an embedding space that captures the associations between\nsingle cards and whole card pools based on human selections. Such selection\ndata only exists for restricted choices, thus generating concrete preferences\nof one item over a set of other items rather than a perfect fit between the\ncard and the pool.\n  Our results show that vanilla CLIP does not perform well due to the\naforementioned intuitive issues. However, by adapting CLIP to the problem, we\nreceive a model outperforming previous work trained with the triplet loss,\nwhile also alleviating problems associated with mining triplets.\n","subjects":["Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/"}