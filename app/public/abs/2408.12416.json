{"id":"2408.12416","title":"Unlearning Trojans in Large Language Models: A Comparison Between\n  Natural Language and Source Code","authors":"Mahdi Kazemi, Aftab Hussain, Md Rafiqul Islam Rabin, Mohammad Amin\n  Alipour, Sen Lin","authorsParsed":[["Kazemi","Mahdi",""],["Hussain","Aftab",""],["Rabin","Md Rafiqul Islam",""],["Alipour","Mohammad Amin",""],["Lin","Sen",""]],"versions":[{"version":"v1","created":"Thu, 22 Aug 2024 14:12:06 GMT"}],"updateDate":"2024-08-23","timestamp":1724335926000,"abstract":"  This work investigates the application of Machine Unlearning (MU) for\nmitigating the impact of trojans embedded in conventional large language models\nof natural language (Text-LLMs) and large language models of code (Code-LLMs)\nWe propose a novel unlearning approach, LYA, that leverages both gradient\nascent and elastic weight consolidation, a Fisher Information Matrix (FIM)\nbased regularization technique, to unlearn trojans from poisoned models. We\ncompare the effectiveness of LYA against conventional techniques like\nfine-tuning, retraining, and vanilla gradient ascent. The subject models we\ninvestigate are BERT and CodeBERT, for sentiment analysis and code defect\ndetection tasks, respectively. Our findings demonstrate that the combination of\ngradient ascent and FIM-based regularization, as done in LYA, outperforms\nexisting methods in removing the trojan's influence from the poisoned model,\nwhile preserving its original functionality. To the best of our knowledge, this\nis the first work that compares and contrasts MU of trojans in LLMs, in the NL\nand Coding domain.\n","subjects":["Computing Research Repository/Software Engineering","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}