{"id":"2407.17361","title":"MuST: Multi-Scale Transformers for Surgical Phase Recognition","authors":"Alejandra P\\'erez and Santiago Rodr\\'iguez and Nicol\\'as Ayobi and\n  Nicol\\'as Aparicio and Eug\\'enie Dessevres and Pablo Arbel\\'aez","authorsParsed":[["Pérez","Alejandra",""],["Rodríguez","Santiago",""],["Ayobi","Nicolás",""],["Aparicio","Nicolás",""],["Dessevres","Eugénie",""],["Arbeláez","Pablo",""]],"versions":[{"version":"v1","created":"Wed, 24 Jul 2024 15:38:20 GMT"}],"updateDate":"2024-07-25","timestamp":1721835500000,"abstract":"  Phase recognition in surgical videos is crucial for enhancing computer-aided\nsurgical systems as it enables automated understanding of sequential procedural\nstages. Existing methods often rely on fixed temporal windows for video\nanalysis to identify dynamic surgical phases. Thus, they struggle to\nsimultaneously capture short-, mid-, and long-term information necessary to\nfully understand complex surgical procedures. To address these issues, we\npropose Multi-Scale Transformers for Surgical Phase Recognition (MuST), a novel\nTransformer-based approach that combines a Multi-Term Frame encoder with a\nTemporal Consistency Module to capture information across multiple temporal\nscales of a surgical video. Our Multi-Term Frame Encoder computes\ninterdependencies across a hierarchy of temporal scales by sampling sequences\nat increasing strides around the frame of interest. Furthermore, we employ a\nlong-term Transformer encoder over the frame embeddings to further enhance\nlong-term reasoning. MuST achieves higher performance than previous\nstate-of-the-art methods on three different public benchmarks.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}