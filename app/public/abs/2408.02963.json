{"id":"2408.02963","title":"Adversarial Robustness of Open-source Text Classification Models and\n  Fine-Tuning Chains","authors":"Hao Qin, Mingyang Li, Junjie Wang, Qing Wang","authorsParsed":[["Qin","Hao",""],["Li","Mingyang",""],["Wang","Junjie",""],["Wang","Qing",""]],"versions":[{"version":"v1","created":"Tue, 6 Aug 2024 05:17:17 GMT"}],"updateDate":"2024-08-07","timestamp":1722921437000,"abstract":"  Context:With the advancement of artificial intelligence (AI) technology and\napplications, numerous AI models have been developed, leading to the emergence\nof open-source model hosting platforms like Hugging Face (HF). Thanks to these\nplatforms, individuals can directly download and use models, as well as\nfine-tune them to construct more domain-specific models. However, just like\ntraditional software supply chains face security risks, AI models and\nfine-tuning chains also encounter new security risks, such as adversarial\nattacks. Therefore, the adversarial robustness of these models has garnered\nattention, potentially influencing people's choices regarding open-source\nmodels. Objective:This paper aims to explore the adversarial robustness of\nopen-source AI models and their chains formed by the upstream-downstream\nrelationships via fine-tuning to provide insights into the potential\nadversarial risks. Method:We collect text classification models on HF and\nconstruct the fine-tuning chains.Then, we conduct an empirical analysis of\nmodel reuse and associated robustness risks under existing adversarial attacks\nfrom two aspects, i.e., models and their fine-tuning chains. Results:Despite\nthe models' widespread downloading and reuse, they are generally susceptible to\nadversarial attack risks, with an average of 52.70% attack success rate.\nMoreover, fine-tuning typically exacerbates this risk, resulting in an average\n12.60% increase in attack success rates. We also delve into the influence of\nfactors such as attack techniques, datasets, and model architectures on the\nsuccess rate, as well as the transitivity along the model chains.\n","subjects":["Computing Research Repository/Software Engineering"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}