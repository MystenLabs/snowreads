{"id":"2408.00205","title":"Sentence-wise Speech Summarization: Task, Datasets, and End-to-End\n  Modeling with LM Knowledge Distillation","authors":"Kohei Matsuura, Takanori Ashihara, Takafumi Moriya, Masato Mimura,\n  Takatomo Kano, Atsunori Ogawa, Marc Delcroix","authorsParsed":[["Matsuura","Kohei",""],["Ashihara","Takanori",""],["Moriya","Takafumi",""],["Mimura","Masato",""],["Kano","Takatomo",""],["Ogawa","Atsunori",""],["Delcroix","Marc",""]],"versions":[{"version":"v1","created":"Thu, 1 Aug 2024 00:18:21 GMT"}],"updateDate":"2024-08-02","timestamp":1722471501000,"abstract":"  This paper introduces a novel approach called sentence-wise speech\nsummarization (Sen-SSum), which generates text summaries from a spoken document\nin a sentence-by-sentence manner. Sen-SSum combines the real-time processing of\nautomatic speech recognition (ASR) with the conciseness of speech\nsummarization. To explore this approach, we present two datasets for Sen-SSum:\nMega-SSum and CSJ-SSum. Using these datasets, our study evaluates two types of\nTransformer-based models: 1) cascade models that combine ASR and strong text\nsummarization models, and 2) end-to-end (E2E) models that directly convert\nspeech into a text summary. While E2E models are appealing to develop\ncompute-efficient models, they perform worse than cascade models. Therefore, we\npropose knowledge distillation for E2E models using pseudo-summaries generated\nby the cascade models. Our experiments show that this proposed knowledge\ndistillation effectively improves the performance of the E2E model on both\ndatasets.\n","subjects":["Computing Research Repository/Computation and Language","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"UfhePjKXCE-Fo2bqjwE0S7KLWdUy32UI_CDPX3uyP4A","pdfSize":"1009414"}
