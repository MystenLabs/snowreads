{"id":"2408.03325","title":"CoverBench: A Challenging Benchmark for Complex Claim Verification","authors":"Alon Jacovi, Moran Ambar, Eyal Ben-David, Uri Shaham, Amir Feder, Mor\n  Geva, Dror Marcus, Avi Caciularu","authorsParsed":[["Jacovi","Alon",""],["Ambar","Moran",""],["Ben-David","Eyal",""],["Shaham","Uri",""],["Feder","Amir",""],["Geva","Mor",""],["Marcus","Dror",""],["Caciularu","Avi",""]],"versions":[{"version":"v1","created":"Tue, 6 Aug 2024 17:58:53 GMT"}],"updateDate":"2024-08-07","timestamp":1722967133000,"abstract":"  There is a growing line of research on verifying the correctness of language\nmodels' outputs. At the same time, LMs are being used to tackle complex queries\nthat require reasoning. We introduce CoverBench, a challenging benchmark\nfocused on verifying LM outputs in complex reasoning settings. Datasets that\ncan be used for this purpose are often designed for other complex reasoning\ntasks (e.g., QA) targeting specific use-cases (e.g., financial tables),\nrequiring transformations, negative sampling and selection of hard examples to\ncollect such a benchmark. CoverBench provides a diversified evaluation for\ncomplex claim verification in a variety of domains, types of reasoning,\nrelatively long inputs, and a variety of standardizations, such as multiple\nrepresentations for tables where available, and a consistent schema. We\nmanually vet the data for quality to ensure low levels of label noise. Finally,\nwe report a variety of competitive baseline results to show CoverBench is\nchallenging and has very significant headroom. The data is available at\nhttps://huggingface.co/datasets/google/coverbench .\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}