{"id":"2408.03551","title":"VPOcc: Exploiting Vanishing Point for Monocular 3D Semantic Occupancy\n  Prediction","authors":"Junsu Kim, Junhee Lee, Ukcheol Shin, Jean Oh and Kyungdon Joo","authorsParsed":[["Kim","Junsu",""],["Lee","Junhee",""],["Shin","Ukcheol",""],["Oh","Jean",""],["Joo","Kyungdon",""]],"versions":[{"version":"v1","created":"Wed, 7 Aug 2024 05:23:52 GMT"}],"updateDate":"2024-08-08","timestamp":1723008232000,"abstract":"  Monocular 3D semantic occupancy prediction is becoming important in robot\nvision due to the compactness of using a single RGB camera. However, existing\nmethods often do not adequately account for camera perspective geometry,\nresulting in information imbalance along the depth range of the image. To\naddress this issue, we propose a vanishing point (VP) guided monocular 3D\nsemantic occupancy prediction framework named VPOcc. Our framework consists of\nthree novel modules utilizing VP. First, in the VPZoomer module, we initially\nutilize VP in feature extraction to achieve information balanced feature\nextraction across the scene by generating a zoom-in image based on VP. Second,\nwe perform perspective geometry-aware feature aggregation by sampling points\ntowards VP using a VP-guided cross-attention (VPCA) module. Finally, we create\nan information-balanced feature volume by effectively fusing original and\nzoom-in voxel feature volumes with a balanced feature volume fusion (BVFV)\nmodule. Experiments demonstrate that our method achieves state-of-the-art\nperformance for both IoU and mIoU on SemanticKITTI and SSCBench-KITTI360. These\nresults are obtained by effectively addressing the information imbalance in\nimages through the utilization of VP. Our code will be available at\nwww.github.com/anonymous.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Robotics"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}