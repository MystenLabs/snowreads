{"id":"2407.04575","title":"FA-GAN: Artifacts-free and Phase-aware High-fidelity GAN-based Vocoder","authors":"Rubing Shen, Yanzhen Ren, Zongkun Sun","authorsParsed":[["Shen","Rubing",""],["Ren","Yanzhen",""],["Sun","Zongkun",""]],"versions":[{"version":"v1","created":"Fri, 5 Jul 2024 15:10:11 GMT"}],"updateDate":"2024-07-08","timestamp":1720192211000,"abstract":"  Generative adversarial network (GAN) based vocoders have achieved significant\nattention in speech synthesis with high quality and fast inference speed.\nHowever, there still exist many noticeable spectral artifacts, resulting in the\nquality decline of synthesized speech. In this work, we adopt a novel GAN-based\nvocoder designed for few artifacts and high fidelity, called FA-GAN. To\nsuppress the aliasing artifacts caused by non-ideal upsampling layers in\nhigh-frequency components, we introduce the anti-aliased twin deconvolution\nmodule in the generator. To alleviate blurring artifacts and enrich the\nreconstruction of spectral details, we propose a novel fine-grained\nmulti-resolution real and imaginary loss to assist in the modeling of phase\ninformation. Experimental results reveal that FA-GAN outperforms the compared\napproaches in promoting audio quality and alleviating spectral artifacts, and\nexhibits superior performance when applied to unseen speaker scenarios.\n","subjects":["Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}