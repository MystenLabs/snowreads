{"id":"2408.05777","title":"Seg-CycleGAN : SAR-to-optical image translation guided by a downstream\n  task","authors":"Hannuo Zhang, Huihui Li, Jiarui Lin, Yujie Zhang, Jianghua Fan, Hang\n  Liu","authorsParsed":[["Zhang","Hannuo",""],["Li","Huihui",""],["Lin","Jiarui",""],["Zhang","Yujie",""],["Fan","Jianghua",""],["Liu","Hang",""]],"versions":[{"version":"v1","created":"Sun, 11 Aug 2024 14:01:21 GMT"}],"updateDate":"2024-08-13","timestamp":1723384881000,"abstract":"  Optical remote sensing and Synthetic Aperture Radar(SAR) remote sensing are\ncrucial for earth observation, offering complementary capabilities. While\noptical sensors provide high-quality images, they are limited by weather and\nlighting conditions. In contrast, SAR sensors can operate effectively under\nadverse conditions. This letter proposes a GAN-based SAR-to-optical image\ntranslation method named Seg-CycleGAN, designed to enhance the accuracy of ship\ntarget translation by leveraging semantic information from a pre-trained\nsemantic segmentation model. Our method utilizes the downstream task of ship\ntarget semantic segmentation to guide the training of image translation\nnetwork, improving the quality of output Optical-styled images. The potential\nof foundation-model-annotated datasets in SAR-to-optical translation tasks is\nrevealed. This work suggests broader research and applications for\ndownstream-task-guided frameworks. The code will be available at\nhttps://github.com/NPULHH/\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence","Electrical Engineering and Systems Science/Image and Video Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}