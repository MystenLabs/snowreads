{"id":"2407.19918","title":"FreeLong: Training-Free Long Video Generation with SpectralBlend\n  Temporal Attention","authors":"Yu Lu, Yuanzhi Liang, Linchao Zhu, Yi Yang","authorsParsed":[["Lu","Yu",""],["Liang","Yuanzhi",""],["Zhu","Linchao",""],["Yang","Yi",""]],"versions":[{"version":"v1","created":"Mon, 29 Jul 2024 11:52:07 GMT"}],"updateDate":"2024-07-30","timestamp":1722253927000,"abstract":"  Video diffusion models have made substantial progress in various video\ngeneration applications. However, training models for long video generation\ntasks require significant computational and data resources, posing a challenge\nto developing long video diffusion models. This paper investigates a\nstraightforward and training-free approach to extend an existing short video\ndiffusion model (e.g. pre-trained on 16-frame videos) for consistent long video\ngeneration (e.g. 128 frames). Our preliminary observation has found that\ndirectly applying the short video diffusion model to generate long videos can\nlead to severe video quality degradation. Further investigation reveals that\nthis degradation is primarily due to the distortion of high-frequency\ncomponents in long videos, characterized by a decrease in spatial\nhigh-frequency components and an increase in temporal high-frequency\ncomponents. Motivated by this, we propose a novel solution named FreeLong to\nbalance the frequency distribution of long video features during the denoising\nprocess. FreeLong blends the low-frequency components of global video features,\nwhich encapsulate the entire video sequence, with the high-frequency components\nof local video features that focus on shorter subsequences of frames. This\napproach maintains global consistency while incorporating diverse and\nhigh-quality spatiotemporal details from local videos, enhancing both the\nconsistency and fidelity of long video generation. We evaluated FreeLong on\nmultiple base video diffusion models and observed significant improvements.\nAdditionally, our method supports coherent multi-prompt generation, ensuring\nboth visual coherence and seamless transitions between scenes.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}