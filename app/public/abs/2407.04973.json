{"id":"2407.04973","title":"LogicVista: Multimodal LLM Logical Reasoning Benchmark in Visual\n  Contexts","authors":"Yijia Xiao, Edward Sun, Tianyu Liu, Wei Wang","authorsParsed":[["Xiao","Yijia",""],["Sun","Edward",""],["Liu","Tianyu",""],["Wang","Wei",""]],"versions":[{"version":"v1","created":"Sat, 6 Jul 2024 06:48:16 GMT"}],"updateDate":"2024-07-09","timestamp":1720248496000,"abstract":"  We propose LogicVista, an evaluation benchmark that assesses the integrated\nlogical reasoning capabilities of multimodal large language models (MLLMs) in\nVisual contexts. Recent advancements in MLLMs have demonstrated various\nfascinating abilities, from crafting poetry based on an image to performing\nmathematical reasoning. However, there is still a lack of systematic evaluation\nof MLLMs' proficiency in logical reasoning tasks, which are essential for\nactivities like navigation and puzzle-solving. Thus we evaluate general logical\ncognition abilities across 5 logical reasoning tasks encompassing 9 different\ncapabilities, using a sample of 448 multiple-choice questions. Each question is\nannotated with the correct answer and the human-written reasoning behind the\nselection, enabling both open-ended and multiple-choice evaluation. A total of\n8 MLLMs are comprehensively evaluated using LogicVista. Code and Data Available\nat https://github.com/Yijia-Xiao/LogicVista.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language","Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}