{"id":"2408.04803","title":"FewShotNeRF: Meta-Learning-based Novel View Synthesis for Rapid\n  Scene-Specific Adaptation","authors":"Piraveen Sivakumar, Paul Janson, Jathushan Rajasegaran, Thanuja\n  Ambegoda","authorsParsed":[["Sivakumar","Piraveen",""],["Janson","Paul",""],["Rajasegaran","Jathushan",""],["Ambegoda","Thanuja",""]],"versions":[{"version":"v1","created":"Fri, 9 Aug 2024 01:13:14 GMT"}],"updateDate":"2024-08-12","timestamp":1723165994000,"abstract":"  In this paper, we address the challenge of generating novel views of\nreal-world objects with limited multi-view images through our proposed\napproach, FewShotNeRF. Our method utilizes meta-learning to acquire optimal\ninitialization, facilitating rapid adaptation of a Neural Radiance Field (NeRF)\nto specific scenes. The focus of our meta-learning process is on capturing\nshared geometry and textures within a category, embedded in the weight\ninitialization. This approach expedites the learning process of NeRFs and\nleverages recent advancements in positional encodings to reduce the time\nrequired for fitting a NeRF to a scene, thereby accelerating the inner loop\noptimization of meta-learning. Notably, our method enables meta-learning on a\nlarge number of 3D scenes to establish a robust 3D prior for various\ncategories. Through extensive evaluations on the Common Objects in 3D open\nsource dataset, we empirically demonstrate the efficacy and potential of\nmeta-learning in generating high-quality novel views of objects.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}