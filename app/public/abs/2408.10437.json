{"id":"2408.10437","title":"Understanding Generative AI Content with Embedding Models","authors":"Max Vargas, Reilly Cannon, Andrew Engel, Anand D. Sarwate, Tony Chiang","authorsParsed":[["Vargas","Max",""],["Cannon","Reilly",""],["Engel","Andrew",""],["Sarwate","Anand D.",""],["Chiang","Tony",""]],"versions":[{"version":"v1","created":"Mon, 19 Aug 2024 22:07:05 GMT"},{"version":"v2","created":"Thu, 22 Aug 2024 21:50:46 GMT"}],"updateDate":"2024-08-26","timestamp":1724105225000,"abstract":"  The construction of high-quality numerical features is critical to any\nquantitative data analysis. Feature engineering has been historically addressed\nby carefully hand-crafting data representations based on domain expertise. This\nwork views the internal representations of modern deep neural networks (DNNs),\ncalled embeddings, as an automated form of traditional feature engineering. For\ntrained DNNs, we show that these embeddings can reveal interpretable,\nhigh-level concepts in unstructured sample data. We use these embeddings in\nnatural language and computer vision tasks to uncover both inherent\nheterogeneity in the underlying data and human-understandable explanations for\nit. In particular, we find empirical evidence that there is inherent\nseparability between real data and that generated from AI models.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}