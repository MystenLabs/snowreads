{"id":"2407.02104","title":"Joint-Dataset Learning and Cross-Consistent Regularization for\n  Text-to-Motion Retrieval","authors":"Nicola Messina, Jan Sedmidubsky, Fabrizio Falchi, Tom\\'a\\v{s} Rebok","authorsParsed":[["Messina","Nicola",""],["Sedmidubsky","Jan",""],["Falchi","Fabrizio",""],["Rebok","Tomáš",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 09:43:47 GMT"}],"updateDate":"2024-07-03","timestamp":1719913427000,"abstract":"  Pose-estimation methods enable extracting human motion from common videos in\nthe structured form of 3D skeleton sequences. Despite great application\nopportunities, effective content-based access to such spatio-temporal motion\ndata is a challenging problem. In this paper, we focus on the recently\nintroduced text-motion retrieval tasks, which aim to search for database\nmotions that are the most relevant to a specified natural-language textual\ndescription (text-to-motion) and vice-versa (motion-to-text). Despite recent\nefforts to explore these promising avenues, a primary challenge remains the\ninsufficient data available to train robust text-motion models effectively. To\naddress this issue, we propose to investigate joint-dataset learning - where we\ntrain on multiple text-motion datasets simultaneously - together with the\nintroduction of a Cross-Consistent Contrastive Loss function (CCCL), which\nregularizes the learned text-motion common space by imposing uni-modal\nconstraints that augment the representation ability of the trained network. To\nlearn a proper motion representation, we also introduce a transformer-based\nmotion encoder, called MoT++, which employs spatio-temporal attention to\nprocess sequences of skeleton data. We demonstrate the benefits of the proposed\napproaches on the widely-used KIT Motion-Language and HumanML3D datasets. We\nperform detailed experimentation on joint-dataset learning and cross-dataset\nscenarios, showing the effectiveness of each introduced module in a carefully\nconducted ablation study and, in turn, pointing out the limitations of\nstate-of-the-art methods.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Information Retrieval","Computing Research Repository/Multimedia"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}