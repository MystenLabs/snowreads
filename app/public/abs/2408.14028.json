{"id":"2408.14028","title":"SurGen: Text-Guided Diffusion Model for Surgical Video Generation","authors":"Joseph Cho, Samuel Schmidgall, Cyril Zakka, Mrudang Mathur, Rohan\n  Shad, William Hiesinger","authorsParsed":[["Cho","Joseph",""],["Schmidgall","Samuel",""],["Zakka","Cyril",""],["Mathur","Mrudang",""],["Shad","Rohan",""],["Hiesinger","William",""]],"versions":[{"version":"v1","created":"Mon, 26 Aug 2024 05:38:27 GMT"},{"version":"v2","created":"Wed, 28 Aug 2024 18:06:50 GMT"}],"updateDate":"2024-08-30","timestamp":1724650707000,"abstract":"  Diffusion-based video generation models have made significant strides,\nproducing outputs with improved visual fidelity, temporal coherence, and user\ncontrol. These advancements hold great promise for improving surgical education\nby enabling more realistic, diverse, and interactive simulation environments.\nIn this study, we introduce SurGen, a text-guided diffusion model tailored for\nsurgical video synthesis, producing the highest resolution and longest duration\nvideos among existing surgical video generation models. We validate the visual\nand temporal quality of the outputs using standard image and video generation\nmetrics. Additionally, we assess their alignment to the corresponding text\nprompts through a deep learning classifier trained on surgical data. Our\nresults demonstrate the potential of diffusion models to serve as valuable\neducational tools for surgical trainees.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/"}