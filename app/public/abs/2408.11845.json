{"id":"2408.11845","title":"LLaMA based Punctuation Restoration With Forward Pass Only Decoding","authors":"Yutong Pang, Debjyoti Paul, Kevin Jiang, Xuedong Zhang, Xin Lei","authorsParsed":[["Pang","Yutong",""],["Paul","Debjyoti",""],["Jiang","Kevin",""],["Zhang","Xuedong",""],["Lei","Xin",""]],"versions":[{"version":"v1","created":"Fri, 9 Aug 2024 22:20:56 GMT"}],"updateDate":"2024-08-23","timestamp":1723242056000,"abstract":"  This paper introduces two advancements in the field of Large Language Model\nAnnotation with a focus on punctuation restoration tasks. Our first\ncontribution is the application of LLaMA for punctuation restoration, which\ndemonstrates superior performance compared to the established benchmark.\n  Despite its impressive quality, LLaMA faces challenges regarding inference\nspeed and hallucinations. To address this, our second contribution presents\nForward Pass Only Decoding (FPOD), a novel decoding approach for annotation\ntasks. This innovative method results in a substantial 19.8x improvement in\ninference speed, effectively addressing a critical bottleneck and enhancing the\npractical utility of LLaMA for large-scale data annotation tasks without\nhallucinations.\n  The combination of these contributions not only solidifies LLaMA as a\npowerful tool for punctuation restoration but also highlights FPOD as a crucial\nstrategy for overcoming speed constraints.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}