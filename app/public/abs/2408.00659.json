{"id":"2408.00659","title":"Refinement of genetic variants needs attention","authors":"Omar Abdelwahab, Davoud Torkamaneh","authorsParsed":[["Abdelwahab","Omar",""],["Torkamaneh","Davoud",""]],"versions":[{"version":"v1","created":"Thu, 1 Aug 2024 15:48:56 GMT"}],"updateDate":"2024-08-02","timestamp":1722527336000,"abstract":"  Variant calling refinement is crucial for distinguishing true genetic\nvariants from technical artifacts in high-throughput sequencing data. Manual\nreview is time-consuming while heuristic filtering often lacks optimal\nsolutions. Traditional variant calling methods often struggle with accuracy,\nespecially in regions of low read coverage, leading to false-positive or\nfalse-negative calls. Here, we introduce VariantTransformer, a\nTransformer-based deep learning model, designed to automate variant calling\nrefinement directly from VCF files in low-coverage data (10-15X).\nVariantTransformer, trained on two million variants, including SNPs and short\nInDels, from low-coverage sequencing data, achieved an accuracy of 89.26% and a\nROC AUC of 0.88. When integrated into conventional variant calling pipelines,\nVariantTransformer outperformed traditional heuristic filters and approached\nthe performance of state-of-the-art AI-based variant callers like DeepVariant.\nComparative analysis demonstrated VariantTransformer's superiority in\nfunctionality, variant type coverage, training size, and input data type.\nVariantTransformer represents a significant advancement in variant calling\nrefinement for low-coverage genomic studies.\n","subjects":["Quantitative Biology/Genomics"],"license":"http://creativecommons.org/licenses/by/4.0/"}