{"id":"2407.16788","title":"Occlusion-Aware 3D Motion Interpretation for Abnormal Behavior Detection","authors":"Su Li, Wang Liang, Jianye Wang, Ziheng Zhang, Lei Zhang","authorsParsed":[["Li","Su",""],["Liang","Wang",""],["Wang","Jianye",""],["Zhang","Ziheng",""],["Zhang","Lei",""]],"versions":[{"version":"v1","created":"Tue, 23 Jul 2024 18:41:16 GMT"}],"updateDate":"2024-07-25","timestamp":1721760076000,"abstract":"  Estimating abnormal posture based on 3D pose is vital in human pose analysis,\nyet it presents challenges, especially when reconstructing 3D human poses from\nmonocular datasets with occlusions. Accurate reconstructions enable the\nrestoration of 3D movements, which assist in the extraction of semantic details\nnecessary for analyzing abnormal behaviors. However, most existing methods\ndepend on predefined key points as a basis for estimating the coordinates of\noccluded joints, where variations in data quality have adversely affected the\nperformance of these models. In this paper, we present OAD2D, which\ndiscriminates against motion abnormalities based on reconstructing 3D\ncoordinates of mesh vertices and human joints from monocular videos. The OAD2D\nemploys optical flow to capture motion prior information in video streams,\nenriching the information on occluded human movements and ensuring\ntemporal-spatial alignment of poses. Moreover, we reformulate the abnormal\nposture estimation by coupling it with Motion to Text (M2T) model in which, the\nVQVAE is employed to quantize motion features. This approach maps motion tokens\nto text tokens, allowing for a semantically interpretable analysis of motion,\nand enhancing the generalization of abnormal posture detection boosted by\nLanguage model. Our approach demonstrates the robustness of abnormal behavior\ndetection against severe and self-occlusions, as it reconstructs human motion\ntrajectories in global coordinates to effectively mitigate occlusion issues.\nOur method, validated using the Human3.6M, 3DPW, and NTU RGB+D datasets,\nachieves a high $F_1-$Score of 0.94 on the NTU RGB+D dataset for medical\ncondition detection. And we will release all of our code and data.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}