{"id":"2408.13102","title":"Dynamic Label Adversarial Training for Deep Learning Robustness Against\n  Adversarial Attacks","authors":"Zhenyu Liu, Haoran Duan, Huizhi Liang, Yang Long, Vaclav Snasel,\n  Guiseppe Nicosia, Rajiv Ranjan, Varun Ojha","authorsParsed":[["Liu","Zhenyu",""],["Duan","Haoran",""],["Liang","Huizhi",""],["Long","Yang",""],["Snasel","Vaclav",""],["Nicosia","Guiseppe",""],["Ranjan","Rajiv",""],["Ojha","Varun",""]],"versions":[{"version":"v1","created":"Fri, 23 Aug 2024 14:25:12 GMT"}],"updateDate":"2024-08-26","timestamp":1724423112000,"abstract":"  Adversarial training is one of the most effective methods for enhancing model\nrobustness. Recent approaches incorporate adversarial distillation in\nadversarial training architectures. However, we notice two scenarios of defense\nmethods that limit their performance: (1) Previous methods primarily use static\nground truth for adversarial training, but this often causes robust\noverfitting; (2) The loss functions are either Mean Squared Error or\nKL-divergence leading to a sub-optimal performance on clean accuracy. To solve\nthose problems, we propose a dynamic label adversarial training (DYNAT)\nalgorithm that enables the target model to gradually and dynamically gain\nrobustness from the guide model's decisions. Additionally, we found that a\nbudgeted dimension of inner optimization for the target model may contribute to\nthe trade-off between clean accuracy and robust accuracy. Therefore, we propose\na novel inner optimization method to be incorporated into the adversarial\ntraining. This will enable the target model to adaptively search for\nadversarial examples based on dynamic labels from the guiding model,\ncontributing to the robustness of the target model. Extensive experiments\nvalidate the superior performance of our approach.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}