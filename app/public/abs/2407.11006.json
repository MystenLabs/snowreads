{"id":"2407.11006","title":"Evaluating the Efficacy of Foundational Models: Advancing Benchmarking\n  Practices to Enhance Fine-Tuning Decision-Making","authors":"Oluyemi Enoch Amujo and Shanchieh Jay Yang","authorsParsed":[["Amujo","Oluyemi Enoch",""],["Yang","Shanchieh Jay",""]],"versions":[{"version":"v1","created":"Tue, 25 Jun 2024 20:52:31 GMT"},{"version":"v2","created":"Tue, 20 Aug 2024 19:17:58 GMT"}],"updateDate":"2024-08-22","timestamp":1719348751000,"abstract":"  Recently, large language models (LLMs) have expanded into various domains.\nHowever, there remains a need to evaluate how these models perform when\nprompted with commonplace queries compared to domain-specific queries, which\nmay be useful for benchmarking prior to fine-tuning for domain-specific\ndownstream tasks. This study evaluates LLMs, specifically Gemma-2B and\nGemma-7B, across diverse domains, including cybersecurity, medicine, and\nfinance, compared to common knowledge queries. This study utilizes a\ncomprehensive methodology to assess foundational models, which includes problem\nformulation, data analysis, and the development of ThroughCut, a novel outlier\ndetection technique that automatically identifies response throughput outliers\nbased on their conciseness. This methodological rigor enhances the credibility\nof the presented evaluation frameworks. This study focused on assessing\ninference time, response length, throughput, quality, and resource utilization\nand investigated the correlations between these factors. The results indicate\nthat model size and types of prompts used for inference significantly\ninfluenced response length and quality. In addition, common prompts, which\ninclude various types of queries, generate diverse and inconsistent responses\nat irregular intervals. In contrast, domain-specific prompts consistently\ngenerate concise responses within a reasonable time. Overall, this study\nunderscores the need for comprehensive evaluation frameworks to enhance the\nreliability of benchmarking procedures in multidomain AI research.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning","Computing Research Repository/Performance"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/"}