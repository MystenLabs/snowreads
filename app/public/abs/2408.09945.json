{"id":"2408.09945","title":"Benchmarking LLMs for Translating Classical Chinese Poetry:Evaluating\n  Adequacy, Fluency, and Elegance","authors":"Andong Chen, Lianzhang Lou, Kehai Chen, Xuefeng Bai, Yang Xiang, Muyun\n  Yang, Tiejun Zhao, Min Zhang","authorsParsed":[["Chen","Andong",""],["Lou","Lianzhang",""],["Chen","Kehai",""],["Bai","Xuefeng",""],["Xiang","Yang",""],["Yang","Muyun",""],["Zhao","Tiejun",""],["Zhang","Min",""]],"versions":[{"version":"v1","created":"Mon, 19 Aug 2024 12:34:31 GMT"}],"updateDate":"2024-08-20","timestamp":1724070871000,"abstract":"  Large language models (LLMs) have shown remarkable performance in general\ntranslation tasks. However, the increasing demand for high-quality translations\nthat are not only adequate but also fluent and elegant. To assess the extent to\nwhich current LLMs can meet these demands, we introduce a suitable benchmark\nfor translating classical Chinese poetry into English. This task requires not\nonly adequacy in translating culturally and historically significant content\nbut also a strict adherence to linguistic fluency and poetic elegance. Our\nstudy reveals that existing LLMs fall short of this task. To address these\nissues, we propose RAT, a \\textbf{R}etrieval-\\textbf{A}ugmented machine\n\\textbf{T}ranslation method that enhances the translation process by\nincorporating knowledge related to classical poetry. Additionally, we propose\nan automatic evaluation metric based on GPT-4, which better assesses\ntranslation quality in terms of adequacy, fluency, and elegance, overcoming the\nlimitations of traditional metrics. Our dataset and code will be made\navailable.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}