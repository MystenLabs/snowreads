{"id":"2407.01090","title":"Learning 3D Gaussians for Extremely Sparse-View Cone-Beam CT\n  Reconstruction","authors":"Yiqun Lin, Hualiang Wang, Jixiang Chen, Xiaomeng Li","authorsParsed":[["Lin","Yiqun",""],["Wang","Hualiang",""],["Chen","Jixiang",""],["Li","Xiaomeng",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 08:48:04 GMT"},{"version":"v2","created":"Sun, 7 Jul 2024 07:23:07 GMT"}],"updateDate":"2024-07-09","timestamp":1719823684000,"abstract":"  Cone-Beam Computed Tomography (CBCT) is an indispensable technique in medical\nimaging, yet the associated radiation exposure raises concerns in clinical\npractice. To mitigate these risks, sparse-view reconstruction has emerged as an\nessential research direction, aiming to reduce the radiation dose by utilizing\nfewer projections for CT reconstruction. Although implicit neural\nrepresentations have been introduced for sparse-view CBCT reconstruction,\nexisting methods primarily focus on local 2D features queried from sparse\nprojections, which is insufficient to process the more complicated anatomical\nstructures, such as the chest. To this end, we propose a novel reconstruction\nframework, namely DIF-Gaussian, which leverages 3D Gaussians to represent the\nfeature distribution in the 3D space, offering additional 3D spatial\ninformation to facilitate the estimation of attenuation coefficients.\nFurthermore, we incorporate test-time optimization during inference to further\nimprove the generalization capability of the model. We evaluate DIF-Gaussian on\ntwo public datasets, showing significantly superior reconstruction performance\nthan previous state-of-the-art methods.\n","subjects":["Electrical Engineering and Systems Science/Image and Video Processing","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/"}