{"id":"2408.13920","title":"Wav2Small: Distilling Wav2Vec2 to 72K parameters for Low-Resource Speech\n  emotion recognition","authors":"Dionyssos Kounadis-Bastian, Oliver Schr\\\"ufer, Anna Derington, Hagen\n  Wierstorf, Florian Eyben, Felix Burkhardt, Bj\\\"orn Schuller","authorsParsed":[["Kounadis-Bastian","Dionyssos",""],["Schrüfer","Oliver",""],["Derington","Anna",""],["Wierstorf","Hagen",""],["Eyben","Florian",""],["Burkhardt","Felix",""],["Schuller","Björn",""]],"versions":[{"version":"v1","created":"Sun, 25 Aug 2024 19:13:56 GMT"},{"version":"v2","created":"Fri, 30 Aug 2024 15:44:38 GMT"},{"version":"v3","created":"Thu, 5 Sep 2024 14:46:39 GMT"}],"updateDate":"2024-09-06","timestamp":1724613236000,"abstract":"  Speech Emotion Recognition (SER) needs high computational resources to\novercome the challenge of substantial annotator disagreement. Today SER is\nshifting towards dimensional annotations of arousal, dominance, and valence\n(A/D/V). Universal metrics as the L2 distance prove unsuitable for evaluating\nA/D/V accuracy due to non converging consensus of annotator opinions. However,\nConcordance Correlation Coefficient (CCC) arose as an alternative metric for\nA/D/V where a model's output is evaluated to match a whole dataset's CCC rather\nthan L2 distances of individual audios. Recent studies have shown that wav2vec2\n/ wavLM architectures outputing a float value for each A/D/V dimension achieve\ntoday's State-of-the-art (Sota) CCC on A/D/V. The Wav2Vec2.0 / WavLM family has\na high computational footprint, but training small models using human\nannotations has been unsuccessful. In this paper we use a large Transformer\nSota A/D/V model as Teacher/Annotator to train 5 student models: 4 MobileNets\nand our proposed Wav2Small, using only the Teacher's A/D/V outputs instead of\nhuman annotations. The Teacher model we propose also sets a new Sota on the MSP\nPodcast dataset of valence CCC=0.676. We choose MobileNetV4 / MobileNet-V3 as\nstudents, as MobileNet has been designed for fast execution times. We also\npropose Wav2Small - an architecture designed for minimal parameters and RAM\nconsumption. Wav2Small with an .onnx (quantised) of only 120KB is a potential\nsolution for A/D/V on hardware with low resources, having only 72K parameters\nvs 3.12M parameters for MobileNet-V4-Small.\n","subjects":["Computing Research Repository/Sound","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"_6RiCbz56gLf9xVlrC0GWYfT4s4hUv8xcEAsZKqAh1I","pdfSize":"882833"}
