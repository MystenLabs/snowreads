{"id":"2407.11343","title":"Ev-GS: Event-based Gaussian splatting for Efficient and Accurate\n  Radiance Field Rendering","authors":"Jingqian Wu, Shuo Zhu, Chutian Wang, Edmund Y. Lam","authorsParsed":[["Wu","Jingqian",""],["Zhu","Shuo",""],["Wang","Chutian",""],["Lam","Edmund Y.",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 03:15:13 GMT"}],"updateDate":"2024-07-17","timestamp":1721099713000,"abstract":"  Computational neuromorphic imaging (CNI) with event cameras offers advantages\nsuch as minimal motion blur and enhanced dynamic range, compared to\nconventional frame-based methods. Existing event-based radiance field rendering\nmethods are built on neural radiance field, which is computationally heavy and\nslow in reconstruction speed. Motivated by the two aspects, we introduce Ev-GS,\nthe first CNI-informed scheme to infer 3D Gaussian splatting from a monocular\nevent camera, enabling efficient novel view synthesis. Leveraging 3D Gaussians\nwith pure event-based supervision, Ev-GS overcomes challenges such as the\ndetection of fast-moving objects and insufficient lighting. Experimental\nresults show that Ev-GS outperforms the method that takes frame-based signals\nas input by rendering realistic views with reduced blurring and improved visual\nquality. Moreover, it demonstrates competitive reconstruction quality and\nreduced computing occupancy compared to existing methods, which paves the way\nto a highly efficient CNI approach for signal processing.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}