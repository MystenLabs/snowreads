{"id":"2407.00592","title":"Unveiling Glitches: A Deep Dive into Image Encoding Bugs within CLIP","authors":"Ayush Ranjan, Daniel Wen, Karthik Bhat","authorsParsed":[["Ranjan","Ayush",""],["Wen","Daniel",""],["Bhat","Karthik",""]],"versions":[{"version":"v1","created":"Sun, 30 Jun 2024 05:23:11 GMT"}],"updateDate":"2024-07-02","timestamp":1719724991000,"abstract":"  Understanding the limitations and weaknesses of state-of-the-art models in\nartificial intelligence is crucial for their improvement and responsible\napplication. In this research, we focus on CLIP, a model renowned for its\nintegration of vision and language processing. Our objective is to uncover\nrecurring problems and blind spots in CLIP's image comprehension. By delving\ninto both the commonalities and disparities between CLIP and human image\nunderstanding, we augment our comprehension of these models' capabilities.\nThrough our analysis, we reveal significant discrepancies in CLIP's\ninterpretation of images compared to human perception, shedding light on areas\nrequiring improvement. Our methodologies, the Discrepancy Analysis Framework\n(DAF) and the Transformative Caption Analysis for CLIP (TCAC), enable a\ncomprehensive evaluation of CLIP's performance. We identify 14 systemic faults,\nincluding Action vs. Stillness confusion, Failure to identify the direction of\nmovement or positioning of objects in the image, Hallucination of Water-like\nFeatures, Misattribution of Geographic Context, among others. By addressing\nthese limitations, we lay the groundwork for the development of more accurate\nand nuanced image embedding models, contributing to advancements in artificial\nintelligence.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}