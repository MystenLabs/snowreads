{"id":"2408.14765","title":"CrossViewDiff: A Cross-View Diffusion Model for Satellite-to-Street View\n  Synthesis","authors":"Weijia Li, Jun He, Junyan Ye, Huaping Zhong, Zhimeng Zheng, Zilong\n  Huang, Dahua Lin, Conghui He","authorsParsed":[["Li","Weijia",""],["He","Jun",""],["Ye","Junyan",""],["Zhong","Huaping",""],["Zheng","Zhimeng",""],["Huang","Zilong",""],["Lin","Dahua",""],["He","Conghui",""]],"versions":[{"version":"v1","created":"Tue, 27 Aug 2024 03:41:44 GMT"}],"updateDate":"2024-08-28","timestamp":1724730104000,"abstract":"  Satellite-to-street view synthesis aims at generating a realistic street-view\nimage from its corresponding satellite-view image. Although stable diffusion\nmodels have exhibit remarkable performance in a variety of image generation\napplications, their reliance on similar-view inputs to control the generated\nstructure or texture restricts their application to the challenging cross-view\nsynthesis task. In this work, we propose CrossViewDiff, a cross-view diffusion\nmodel for satellite-to-street view synthesis. To address the challenges posed\nby the large discrepancy across views, we design the satellite scene structure\nestimation and cross-view texture mapping modules to construct the structural\nand textural controls for street-view image synthesis. We further design a\ncross-view control guided denoising process that incorporates the above\ncontrols via an enhanced cross-view attention module. To achieve a more\ncomprehensive evaluation of the synthesis results, we additionally design a\nGPT-based scoring method as a supplement to standard evaluation metrics. We\nalso explore the effect of different data sources (e.g., text, maps, building\nheights, and multi-temporal satellite imagery) on this task. Results on three\npublic cross-view datasets show that CrossViewDiff outperforms current\nstate-of-the-art on both standard and GPT-based evaluation metrics, generating\nhigh-quality street-view panoramas with more realistic structures and textures\nacross rural, suburban, and urban scenes. The code and models of this work will\nbe released at https://opendatalab.github.io/CrossViewDiff/.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}