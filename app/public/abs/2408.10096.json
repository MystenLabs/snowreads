{"id":"2408.10096","title":"Convert and Speak: Zero-shot Accent Conversion with Minimum Supervision","authors":"Zhijun Jia, Huaying Xue, Xiulian Peng and Yan Lu","authorsParsed":[["Jia","Zhijun",""],["Xue","Huaying",""],["Peng","Xiulian",""],["Lu","Yan",""]],"versions":[{"version":"v1","created":"Mon, 19 Aug 2024 15:33:59 GMT"},{"version":"v2","created":"Thu, 22 Aug 2024 09:56:20 GMT"}],"updateDate":"2024-08-23","timestamp":1724081639000,"abstract":"  Low resource of parallel data is the key challenge of accent conversion(AC)\nproblem in which both the pronunciation units and prosody pattern need to be\nconverted. We propose a two-stage generative framework \"convert-and-speak\" in\nwhich the conversion is only operated on the semantic token level and the\nspeech is synthesized conditioned on the converted semantic token with a speech\ngenerative model in target accent domain. The decoupling design enables the\n\"speaking\" module to use massive amount of target accent speech and relieves\nthe parallel data required for the \"conversion\" module. Conversion with the\nbridge of semantic token also relieves the requirement for the data with text\ntranscriptions and unlocks the usage of language pre-training technology to\nfurther efficiently reduce the need of parallel accent speech data. To reduce\nthe complexity and latency of \"speaking\", a single-stage AR generative model is\ndesigned to achieve good quality as well as lower computation cost. Experiments\non Indian-English to general American-English conversion show that the proposed\nframework achieves state-of-the-art performance in accent similarity, speech\nquality, and speaker maintenance with only 15 minutes of weakly parallel data\nwhich is not constrained to the same speaker. Extensive experimentation with\ndiverse accent types suggests that this framework possesses a high degree of\nadaptability, making it readily scalable to accommodate other accents with\nlow-resource data. Audio samples are available at\nhttps://www.microsoft.com/en-us/research/project/convert-and-speak-zero-shot-accent-conversion-with-minimumsupervision/.\n","subjects":["Computing Research Repository/Sound","Computing Research Repository/Artificial Intelligence","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}