{"id":"2407.13126","title":"Improving GPU Multi-Tenancy Through Dynamic Multi-Instance GPU\n  Reconfiguration","authors":"Tianyu Wang, Sheng Li, Bingyao Li, Yue Dai, Ao Li, Geng Yuan, Yufei\n  Ding, Youtao Zhang and Xulong Tang","authorsParsed":[["Wang","Tianyu",""],["Li","Sheng",""],["Li","Bingyao",""],["Dai","Yue",""],["Li","Ao",""],["Yuan","Geng",""],["Ding","Yufei",""],["Zhang","Youtao",""],["Tang","Xulong",""]],"versions":[{"version":"v1","created":"Thu, 18 Jul 2024 03:32:53 GMT"}],"updateDate":"2024-07-19","timestamp":1721273573000,"abstract":"  Continuous learning (CL) has emerged as one of the most popular deep learning\nparadigms deployed in modern cloud GPUs. Specifically, CL has the capability to\ncontinuously update the model parameters (through model retraining) and use the\nupdated model (if available) to serve overtime arriving inference requests. It\nis generally beneficial to co-locate the retraining and inference together to\nenable timely model updates and avoid model transfer overheads. This brings the\nneed for GPU sharing among retraining and inferences. Meanwhile, multiple CL\nworkloads can share the modern GPUs in the cloud, leading to multi-tenancy\nexecution. In this paper, we observe that prior GPU-sharing techniques are not\noptimized for multi-tenancy CL workloads. Specifically, they do not coherently\nconsider the accuracy of the retraining model and the inference service level\nobjective (SLO) attainment. Moreover, they cannot accommodate the overtime\ndynamics (e.g., inference arrival intensity) in CL execution. In this paper, we\npropose MIGRator, a novel GPU reconfiguration runtime that dynamically performs\nGPU reconfiguration for multi-tenancy CL workloads. MIGRator is based on the\nrecent NVIDIA multi-instance GPU (MIG) to mitigate resource contention and\nformulates the reconfiguration optimization into Integer Linear Programming\n(ILP) to dynamically identify, reconfigure, and allocate the GPU instances.\nMIGRator leverages the \"Goodput\" metric in the ILP objective function to\nconsider both inference SLO attainment and model accuracy in the\nreconfiguration exploration. We evaluate MIGRator using representative\nmulti-tenancy CL workloads. The results show our approach outperforms the\nstate-of-the-art GPU sharing techniques (i.e., Ekya, Astraea, and PARIS) by\n17\\%, 21\\%, and 20\\%, respectively.\n","subjects":["Computing Research Repository/Distributed, Parallel, and Cluster Computing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}