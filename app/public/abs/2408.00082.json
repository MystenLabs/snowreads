{"id":"2408.00082","title":"TASI Lectures on Physics for Machine Learning","authors":"Jim Halverson","authorsParsed":[["Halverson","Jim",""]],"versions":[{"version":"v1","created":"Wed, 31 Jul 2024 18:00:22 GMT"}],"updateDate":"2024-08-02","timestamp":1722448822000,"abstract":"  These notes are based on lectures I gave at TASI 2024 on Physics for Machine\nLearning. The focus is on neural network theory, organized according to network\nexpressivity, statistics, and dynamics. I present classic results such as the\nuniversal approximation theorem and neural network / Gaussian process\ncorrespondence, and also more recent results such as the neural tangent kernel,\nfeature learning with the maximal update parameterization, and\nKolmogorov-Arnold networks. The exposition on neural network theory emphasizes\na field theoretic perspective familiar to theoretical physicists. I elaborate\non connections between the two, including a neural network approach to field\ntheory.\n","subjects":["Physics/High Energy Physics - Theory","Computing Research Repository/Machine Learning","Physics/High Energy Physics - Phenomenology"],"license":"http://creativecommons.org/licenses/by/4.0/"}