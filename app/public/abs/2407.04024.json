{"id":"2407.04024","title":"Adaptive Step-size Perception Unfolding Network with Non-local Hybrid\n  Attention for Hyperspectral Image Reconstruction","authors":"Yanan Yang, Like Xin","authorsParsed":[["Yang","Yanan",""],["Xin","Like",""]],"versions":[{"version":"v1","created":"Thu, 4 Jul 2024 16:09:52 GMT"}],"updateDate":"2024-07-08","timestamp":1720109392000,"abstract":"  Deep unfolding methods and transformer architecture have recently shown\npromising results in hyperspectral image (HSI) reconstruction. However, there\nstill exist two issues: (1) in the data subproblem, most methods represents the\nstepsize utilizing a learnable parameter. Nevertheless, for different spectral\nchannel, error between features and ground truth is unequal. (2) Transformer\nstruggles to balance receptive field size with pixel-wise detail information.\nTo overcome the aforementioned drawbacks, We proposed an adaptive step-size\nperception unfolding network (ASPUN), a deep unfolding network based on FISTA\nalgorithm, which uses an adaptive step-size perception module to estimate the\nupdate step-size of each spectral channel. In addition, we design a Non-local\nHybrid Attention Transformer(NHAT) module for fully leveraging the receptive\nfield advantage of transformer. By plugging the NLHA into the Non-local\nInformation Aggregation (NLIA) module, the unfolding network can achieve better\nreconstruction results. Experimental results show that our ASPUN is superior to\nthe existing SOTA algorithms and achieves the best performance.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}