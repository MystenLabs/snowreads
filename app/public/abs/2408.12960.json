{"id":"2408.12960","title":"Measuring Code Efficiency Optimization Capabilities with ACEOB","authors":"Yue Pan, Xiuting Shao, Chen Lyu","authorsParsed":[["Pan","Yue",""],["Shao","Xiuting",""],["Lyu","Chen",""]],"versions":[{"version":"v1","created":"Fri, 23 Aug 2024 10:10:37 GMT"}],"updateDate":"2024-08-26","timestamp":1724407837000,"abstract":"  As Moore's Law gains diminish, software performance and efficiency become\nincreasingly vital. Optimizing code efficiency is challenging, even for\nprofessional programmers. However, related research remains relatively scarce,\nand rigorously assessing models' abilities to optimize code efficiency is\nfraught with difficulties. In response to this challenge, we first conduct an\nin-depth analysis of \"code patterns\" in the model training dataset,\nmeticulously exploring human-written code. Secondly, we define a task for\noptimizing code efficiency and introduce the Automatic Code Efficiency\nOptimization Benchmark (ACEOB), which consists of 95,359 pairs of\nefficient-inefficient code aimed at assessing code efficiency optimization\ncapabilities. To our knowledge, ACEOB is the first dataset specifically\ntargeting Python code efficiency optimization. To evaluate models' ability in\noptimizing code efficiency, we propose two new metrics: the Isomorphic Optimal\nComparison CodeBLEU (IOCCB) metric and the Normalized Performance Index (NPI)\nmetric, to assess the efficiency of model-generated code. We also evaluate\nseveral advanced code models, such as PolyCoder and CodeT5, after fine-tuning\nthem on ACEOB and demonstrate that the efficiency of each model improves after\nintroducing the NPI filter. However, it was observed that even ChatGPT does not\nperform optimally in code efficiency optimization tasks.\n","subjects":["Computing Research Repository/Software Engineering"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}