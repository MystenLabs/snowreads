{"id":"2407.19014","title":"Sparse Refinement for Efficient High-Resolution Semantic Segmentation","authors":"Zhijian Liu, Zhuoyang Zhang, Samir Khaki, Shang Yang, Haotian Tang,\n  Chenfeng Xu, Kurt Keutzer, Song Han","authorsParsed":[["Liu","Zhijian",""],["Zhang","Zhuoyang",""],["Khaki","Samir",""],["Yang","Shang",""],["Tang","Haotian",""],["Xu","Chenfeng",""],["Keutzer","Kurt",""],["Han","Song",""]],"versions":[{"version":"v1","created":"Fri, 26 Jul 2024 18:00:09 GMT"}],"updateDate":"2024-07-30","timestamp":1722016809000,"abstract":"  Semantic segmentation empowers numerous real-world applications, such as\nautonomous driving and augmented/mixed reality. These applications often\noperate on high-resolution images (e.g., 8 megapixels) to capture the fine\ndetails. However, this comes at the cost of considerable computational\ncomplexity, hindering the deployment in latency-sensitive scenarios. In this\npaper, we introduce SparseRefine, a novel approach that enhances dense\nlow-resolution predictions with sparse high-resolution refinements. Based on\ncoarse low-resolution outputs, SparseRefine first uses an entropy selector to\nidentify a sparse set of pixels with high entropy. It then employs a sparse\nfeature extractor to efficiently generate the refinements for those pixels of\ninterest. Finally, it leverages a gated ensembler to apply these sparse\nrefinements to the initial coarse predictions. SparseRefine can be seamlessly\nintegrated into any existing semantic segmentation model, regardless of CNN- or\nViT-based. SparseRefine achieves significant speedup: 1.5 to 3.7 times when\napplied to HRNet-W48, SegFormer-B5, Mask2Former-T/L and SegNeXt-L on\nCityscapes, with negligible to no loss of accuracy. Our \"dense+sparse\" paradigm\npaves the way for efficient high-resolution visual computing.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}