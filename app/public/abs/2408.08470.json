{"id":"2408.08470","title":"Context-Aware Assistant Selection for Improved Inference Acceleration\n  with Large Language Models","authors":"Jerry Huang, Prasanna Parthasarathi, Mehdi Rezagholizadeh, Sarath\n  Chandar","authorsParsed":[["Huang","Jerry",""],["Parthasarathi","Prasanna",""],["Rezagholizadeh","Mehdi",""],["Chandar","Sarath",""]],"versions":[{"version":"v1","created":"Fri, 16 Aug 2024 01:12:21 GMT"}],"updateDate":"2024-08-19","timestamp":1723770741000,"abstract":"  Despite their widespread adoption, large language models (LLMs) remain\nprohibitive to use under resource constraints, with their ever growing sizes\nonly increasing the barrier for use. One noted issue is the high latency\nassociated with auto-regressive generation, rendering large LLMs use dependent\non advanced computing infrastructure. Assisted decoding, where a smaller draft\nmodel guides a larger target model's generation, has helped alleviate this, but\nremains dependent on alignment between the two models. Thus if the draft model\nis insufficiently capable on some domain relative to the target model,\nperformance can degrade. Alternatively, one can leverage multiple draft models\nto better cover the expertise of the target, but when multiple black-box draft\nmodels are available, selecting an assistant without details about its\nconstruction can be difficult. To better understand this decision making\nproblem, we observe it as a contextual bandit, where a policy must choose a\ndraft model based on a context. We show that even without prior knowledge of\nthe draft models, creating an offline dataset from only outputs of independent\ndraft/target models and training a policy over the alignment of these outputs\ncan accelerate performance on multiple domains provided the candidates are\neffective. Further results show this to hold on various settings with multiple\nassisted decoding candidates, highlighting its flexibility and the advantageous\nrole that such decision making can play.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"JLI7WejwcyxZNX7H6koCKV44vH_x_qjOSR0aZYVlSc8","pdfSize":"3761269"}
