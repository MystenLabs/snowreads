{"id":"2407.01009","title":"DynaThink: Fast or Slow? A Dynamic Decision-Making Framework for Large\n  Language Models","authors":"Jiabao Pan, Yan Zhang, Chen Zhang, Zuozhu Liu, Hongwei Wang, and\n  Haizhou Li","authorsParsed":[["Pan","Jiabao",""],["Zhang","Yan",""],["Zhang","Chen",""],["Liu","Zuozhu",""],["Wang","Hongwei",""],["Li","Haizhou",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 06:45:13 GMT"}],"updateDate":"2024-07-02","timestamp":1719816313000,"abstract":"  Large language models (LLMs) have demonstrated emergent capabilities across\ndiverse reasoning tasks via popular Chains-of-Thought (COT) prompting. However,\nsuch a simple and fast COT approach often encounters limitations in dealing\nwith complicated problems, while a thorough method, which considers multiple\nreasoning pathways and verifies each step carefully, results in slower\ninference. This paper addresses the challenge of enabling LLMs to autonomously\nselect between fast and slow inference methods, thereby optimizing both\nefficiency and effectiveness. We introduce a dynamic decision-making framework\nthat categorizes tasks into two distinct pathways: 'Fast', designated for tasks\nwhere the LLM quickly identifies a high-confidence solution, and 'Slow',\nallocated for tasks that the LLM perceives as complex and for which it has low\nconfidence in immediate solutions as well as requiring more reasoning paths to\nverify. Experiments on five popular reasoning benchmarks demonstrated the\nsuperiority of the DynaThink over baselines.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}