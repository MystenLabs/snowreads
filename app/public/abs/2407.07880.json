{"id":"2407.07880","title":"Towards Robust Alignment of Language Models: Distributionally\n  Robustifying Direct Preference Optimization","authors":"Junkang Wu, Yuexiang Xie, Zhengyi Yang, Jiancan Wu, Jiawei Chen,\n  Jinyang Gao, Bolin Ding, Xiang Wang, Xiangnan He","authorsParsed":[["Wu","Junkang",""],["Xie","Yuexiang",""],["Yang","Zhengyi",""],["Wu","Jiancan",""],["Chen","Jiawei",""],["Gao","Jinyang",""],["Ding","Bolin",""],["Wang","Xiang",""],["He","Xiangnan",""]],"versions":[{"version":"v1","created":"Wed, 10 Jul 2024 17:48:25 GMT"}],"updateDate":"2024-07-11","timestamp":1720633705000,"abstract":"  This study addresses the challenge of noise in training datasets for Direct\nPreference Optimization (DPO), a method for aligning Large Language Models\n(LLMs) with human preferences. We categorize noise into pointwise noise, which\nincludes low-quality data points, and pairwise noise, which encompasses\nerroneous data pair associations that affect preference rankings. Utilizing\nDistributionally Robust Optimization (DRO), we enhance DPO's resilience to\nthese types of noise. Our theoretical insights reveal that DPO inherently\nembeds DRO principles, conferring robustness to pointwise noise, with the\nregularization coefficient $\\beta$ playing a critical role in its noise\nresistance. Extending this framework, we introduce Distributionally\nRobustifying DPO (Dr. DPO), which integrates pairwise robustness by optimizing\nagainst worst-case pairwise scenarios. The novel hyperparameter $\\beta'$ in Dr.\nDPO allows for fine-tuned control over data pair reliability, providing a\nstrategic balance between exploration and exploitation in noisy training\nenvironments. Empirical evaluations demonstrate that Dr. DPO substantially\nimproves the quality of generated text and response accuracy in preference\ndatasets, showcasing enhanced performance in both noisy and noise-free\nsettings. The code is available at https://github.com/junkangwu/Dr_DPO.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}