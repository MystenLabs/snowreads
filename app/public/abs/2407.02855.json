{"id":"2407.02855","title":"Safe Unlearning: A Surprisingly Effective and Generalizable Solution to\n  Defend Against Jailbreak Attacks","authors":"Zhexin Zhang, Junxiao Yang, Pei Ke, Shiyao Cui, Chujie Zheng, Hongning\n  Wang, Minlie Huang","authorsParsed":[["Zhang","Zhexin",""],["Yang","Junxiao",""],["Ke","Pei",""],["Cui","Shiyao",""],["Zheng","Chujie",""],["Wang","Hongning",""],["Huang","Minlie",""]],"versions":[{"version":"v1","created":"Wed, 3 Jul 2024 07:14:05 GMT"}],"updateDate":"2024-07-04","timestamp":1719990845000,"abstract":"  LLMs are known to be vulnerable to jailbreak attacks, even after safety\nalignment. An important observation is that, while different types of jailbreak\nattacks can generate significantly different queries, they mostly result in\nsimilar responses that are rooted in the same harmful knowledge (e.g., detailed\nsteps to make a bomb). Therefore, we conjecture that directly unlearn the\nharmful knowledge in the LLM can be a more effective way to defend against\njailbreak attacks than the mainstream supervised fine-tuning (SFT) based\napproaches. Our extensive experiments confirmed our insight and suggested\nsurprising generalizability of our unlearning-based approach: using only 20 raw\nharmful questions \\emph{without} any jailbreak prompt during training, our\nsolution reduced the Attack Success Rate (ASR) in Vicuna-7B on\n\\emph{out-of-distribution} (OOD) harmful questions wrapped with various complex\njailbreak prompts from 82.6\\% to 7.7\\%. This significantly outperforms\nLlama2-7B-Chat, which is fine-tuned on about 0.1M safety alignment samples but\nstill has an ASR of 21.9\\% even under the help of an additional safety system\nprompt. Further analysis reveals that the generalization ability of our\nsolution stems from the intrinsic relatedness among harmful responses across\nharmful questions (e.g., response patterns, shared steps and actions, and\nsimilarity among their learned representations in the LLM). Our code is\navailable at \\url{https://github.com/thu-coai/SafeUnlearning}.\n","subjects":["Computing Research Repository/Cryptography and Security","Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}