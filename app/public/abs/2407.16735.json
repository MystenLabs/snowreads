{"id":"2407.16735","title":"Theoretical Analysis of Privacy Leakage in Trustworthy Federated\n  Learning: A Perspective from Linear Algebra and Optimization Theory","authors":"Xiaojin Zhang, Wei Chen","authorsParsed":[["Zhang","Xiaojin",""],["Chen","Wei",""]],"versions":[{"version":"v1","created":"Tue, 23 Jul 2024 16:23:38 GMT"}],"updateDate":"2024-07-25","timestamp":1721751818000,"abstract":"  Federated learning has emerged as a promising paradigm for collaborative\nmodel training while preserving data privacy. However, recent studies have\nshown that it is vulnerable to various privacy attacks, such as data\nreconstruction attacks. In this paper, we provide a theoretical analysis of\nprivacy leakage in federated learning from two perspectives: linear algebra and\noptimization theory. From the linear algebra perspective, we prove that when\nthe Jacobian matrix of the batch data is not full rank, there exist different\nbatches of data that produce the same model update, thereby ensuring a level of\nprivacy. We derive a sufficient condition on the batch size to prevent data\nreconstruction attacks. From the optimization theory perspective, we establish\nan upper bound on the privacy leakage in terms of the batch size, the\ndistortion extent, and several other factors. Our analysis provides insights\ninto the relationship between privacy leakage and various aspects of federated\nlearning, offering a theoretical foundation for designing privacy-preserving\nfederated learning algorithms.\n","subjects":["Computing Research Repository/Cryptography and Security","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning","Statistics/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}