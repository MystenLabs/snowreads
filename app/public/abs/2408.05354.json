{"id":"2408.05354","title":"Trusting Your AI Agent Emotionally and Cognitively: Development and\n  Validation of a Semantic Differential Scale for AI Trust","authors":"Ruoxi Shang, Gary Hsieh, Chirag Shah","authorsParsed":[["Shang","Ruoxi",""],["Hsieh","Gary",""],["Shah","Chirag",""]],"versions":[{"version":"v1","created":"Thu, 25 Jul 2024 18:55:33 GMT"}],"updateDate":"2024-08-13","timestamp":1721933733000,"abstract":"  Trust is not just a cognitive issue but also an emotional one, yet the\nresearch in human-AI interactions has primarily focused on the cognitive route\nof trust development. Recent work has highlighted the importance of studying\naffective trust towards AI, especially in the context of emerging human-like\nLLMs-powered conversational agents. However, there is a lack of validated and\ngeneralizable measures for the two-dimensional construct of trust in AI agents.\nTo address this gap, we developed and validated a set of 27-item semantic\ndifferential scales for affective and cognitive trust through a scenario-based\nsurvey study. We then further validated and applied the scale through an\nexperiment study. Our empirical findings showed how the emotional and cognitive\naspects of trust interact with each other and collectively shape a person's\noverall trust in AI agents. Our study methodology and findings also provide\ninsights into the capability of the state-of-art LLMs to foster trust through\ndifferent routes.\n","subjects":["Computing Research Repository/Human-Computer Interaction","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/"}