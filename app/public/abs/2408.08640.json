{"id":"2408.08640","title":"Math-PUMA: Progressive Upward Multimodal Alignment to Enhance\n  Mathematical Reasoning","authors":"Wenwen Zhuang, Xin Huang, Xiantao Zhang, Jin Zeng","authorsParsed":[["Zhuang","Wenwen",""],["Huang","Xin",""],["Zhang","Xiantao",""],["Zeng","Jin",""]],"versions":[{"version":"v1","created":"Fri, 16 Aug 2024 10:11:05 GMT"}],"updateDate":"2024-08-19","timestamp":1723803065000,"abstract":"  Multimodal Large Language Models (MLLMs) excel in solving text-based\nmathematical problems, but they struggle with mathematical diagrams since they\nare primarily trained on natural scene images. For humans, visual aids\ngenerally enhance problem-solving, but MLLMs perform worse as information\nshifts from textual to visual modality. This decline is mainly due to their\nshortcomings in aligning images and text. To tackle aforementioned challenges,\nwe propose Math-PUMA, a methodology focused on Progressive Upward Multimodal\nAlignment. This approach is designed to improve the mathematical reasoning\nskills of MLLMs through a three-stage training process, with the second stage\nbeing the critical alignment stage. We first enhance the language model's\nmathematical reasoning capabilities with extensive set of textual mathematical\nproblems. We then construct a multimodal dataset with varying degrees of\ntextual and visual information, creating data pairs by presenting each problem\nin at least two forms. By leveraging the Kullback-Leibler (KL) divergence of\nnext-token prediction distributions to align visual and textual modalities,\nconsistent problem-solving abilities are ensured. Finally, we utilize\nmultimodal instruction tuning for MLLMs with high-quality multimodal data.\nExperimental results on multiple mathematical reasoning benchmarks demonstrate\nthat the MLLMs trained with Math-PUMA surpass most open-source MLLMs. Our\napproach effectively narrows the performance gap for problems presented in\ndifferent modalities.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}