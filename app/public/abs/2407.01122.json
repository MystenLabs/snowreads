{"id":"2407.01122","title":"Calibrated Large Language Models for Binary Question Answering","authors":"Patrizio Giovannotti and Alexander Gammerman","authorsParsed":[["Giovannotti","Patrizio",""],["Gammerman","Alexander",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 09:31:03 GMT"}],"updateDate":"2024-07-02","timestamp":1719826263000,"abstract":"  Quantifying the uncertainty of predictions made by large language models\n(LLMs) in binary text classification tasks remains a challenge. Calibration, in\nthe context of LLMs, refers to the alignment between the model's predicted\nprobabilities and the actual correctness of its predictions. A well-calibrated\nmodel should produce probabilities that accurately reflect the likelihood of\nits predictions being correct. We propose a novel approach that utilizes the\ninductive Venn--Abers predictor (IVAP) to calibrate the probabilities\nassociated with the output tokens corresponding to the binary labels. Our\nexperiments on the BoolQ dataset using the Llama 2 model demonstrate that IVAP\nconsistently outperforms the commonly used temperature scaling method for\nvarious label token choices, achieving well-calibrated probabilities while\nmaintaining high predictive quality. Our findings contribute to the\nunderstanding of calibration techniques for LLMs and provide a practical\nsolution for obtaining reliable uncertainty estimates in binary question\nanswering tasks, enhancing the interpretability and trustworthiness of LLM\npredictions.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"JWw8PAIK25VNdKaW-33oIyidXmGwMEtKg53_kIovmKg","pdfSize":"1053604","objectId":"0xf541aa4448d8995cfe8ba10b7417180b476b662c0f363912297674507231a9c5","registeredEpoch":"3","certifiedEpoch":"3","startEpoch":"3","endEpoch":"203"}
