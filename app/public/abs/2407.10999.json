{"id":"2407.10999","title":"TALEC: Teach Your LLM to Evaluate in Specific Domain with In-house\n  Criteria by Criteria Division and Zero-shot Plus Few-shot","authors":"Kaiqi Zhang, Shuai Yuan, Honghan Zhao","authorsParsed":[["Zhang","Kaiqi",""],["Yuan","Shuai",""],["Zhao","Honghan",""]],"versions":[{"version":"v1","created":"Tue, 25 Jun 2024 10:02:42 GMT"}],"updateDate":"2024-07-17","timestamp":1719309762000,"abstract":"  With the rapid development of large language models (LLM), the evaluation of\nLLM becomes increasingly important. Measuring text generation tasks such as\nsummarization and article creation is very difficult. Especially in specific\napplication domains (e.g., to-business or to-customer service), in-house\nevaluation criteria have to meet not only general standards (correctness,\nhelpfulness and creativity, etc.) but also specific needs of customers and\nbusiness security requirements at the same time, making the evaluation more\ndifficult. So far, the evaluation of LLM in business scenarios has mainly\nrelied on manual, which is expensive and time-consuming. In this paper, we\npropose a model-based evaluation method: TALEC, which allows users to flexibly\nset their own evaluation criteria, and uses in-context learning (ICL) to teach\njudge model these in-house criteria. In addition, we try combining zero-shot\nand few-shot to make the judge model focus on more information. We also propose\na prompt paradigm and an engineering approach to adjust and iterate the shots\n,helping judge model to better understand the complex criteria. We then compare\nfine-tuning with ICL, finding that fine-tuning can be replaced by ICL. TALEC\ndemonstrates a strong capability to accurately reflect human preferences and\nachieves a correlation of over 80% with human judgments, outperforming even the\ninter-human correlation in some tasks. The code is released in\nhttps://github.com/zlkqz/auto_eval\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}