{"id":"2407.20570","title":"Fine-Tuned Large Language Model for Visualization System: A Study on\n  Self-Regulated Learning in Education","authors":"Lin Gao, Jing Lu, Zekai Shao, Ziyue Lin, Shengbin Yue, Chiokit Ieong,\n  Yi Sun, Rory James Zauner, Zhongyu Wei and Siming Chen","authorsParsed":[["Gao","Lin",""],["Lu","Jing",""],["Shao","Zekai",""],["Lin","Ziyue",""],["Yue","Shengbin",""],["Ieong","Chiokit",""],["Sun","Yi",""],["Zauner","Rory James",""],["Wei","Zhongyu",""],["Chen","Siming",""]],"versions":[{"version":"v1","created":"Tue, 30 Jul 2024 05:59:26 GMT"}],"updateDate":"2024-07-31","timestamp":1722319166000,"abstract":"  Large Language Models (LLMs) have shown great potential in intelligent\nvisualization systems, especially for domain-specific applications. Integrating\nLLMs into visualization systems presents challenges, and we categorize these\nchallenges into three alignments: domain problems with LLMs, visualization with\nLLMs, and interaction with LLMs. To achieve these alignments, we propose a\nframework and outline a workflow to guide the application of fine-tuned LLMs to\nenhance visual interactions for domain-specific tasks. These alignment\nchallenges are critical in education because of the need for an intelligent\nvisualization system to support beginners' self-regulated learning. Therefore,\nwe apply the framework to education and introduce Tailor-Mind, an interactive\nvisualization system designed to facilitate self-regulated learning for\nartificial intelligence beginners. Drawing on insights from a preliminary\nstudy, we identify self-regulated learning tasks and fine-tuning objectives to\nguide visualization design and tuning data construction. Our focus on aligning\nvisualization with fine-tuned LLM makes Tailor-Mind more like a personalized\ntutor. Tailor-Mind also supports interactive recommendations to help beginners\nbetter achieve their learning goals. Model performance evaluations and user\nstudies confirm that Tailor-Mind improves the self-regulated learning\nexperience, effectively validating the proposed framework.\n","subjects":["Computing Research Repository/Human-Computer Interaction"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}