{"id":"2408.03046","title":"Comb, Prune, Distill: Towards Unified Pruning for Vision Model\n  Compression","authors":"Jonas Schmitt, Ruiping Liu, Junwei Zheng, Jiaming Zhang and Rainer\n  Stiefelhagen","authorsParsed":[["Schmitt","Jonas",""],["Liu","Ruiping",""],["Zheng","Junwei",""],["Zhang","Jiaming",""],["Stiefelhagen","Rainer",""]],"versions":[{"version":"v1","created":"Tue, 6 Aug 2024 09:02:31 GMT"}],"updateDate":"2024-08-07","timestamp":1722934951000,"abstract":"  Lightweight and effective models are essential for devices with limited\nresources, such as intelligent vehicles. Structured pruning offers a promising\napproach to model compression and efficiency enhancement. However, existing\nmethods often tie pruning techniques to specific model architectures or vision\ntasks. To address this limitation, we propose a novel unified pruning framework\nComb, Prune, Distill (CPD), which addresses both model-agnostic and\ntask-agnostic concerns simultaneously. Our framework employs a combing step to\nresolve hierarchical layer-wise dependency issues, enabling architecture\nindependence. Additionally, the pruning pipeline adaptively remove parameters\nbased on the importance scoring metrics regardless of vision tasks. To support\nthe model in retaining its learned information, we introduce knowledge\ndistillation during the pruning step. Extensive experiments demonstrate the\ngeneralizability of our framework, encompassing both convolutional neural\nnetwork (CNN) and transformer models, as well as image classification and\nsegmentation tasks. In image classification we achieve a speedup of up to x4.3\nwith a accuracy loss of 1.8% and in semantic segmentation up to x1.89 with a\n5.1% loss in mIoU.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}