{"id":"2407.09121","title":"Refuse Whenever You Feel Unsafe: Improving Safety in LLMs via Decoupled\n  Refusal Training","authors":"Youliang Yuan, Wenxiang Jiao, Wenxuan Wang, Jen-tse Huang, Jiahao Xu,\n  Tian Liang, Pinjia He, Zhaopeng Tu","authorsParsed":[["Yuan","Youliang",""],["Jiao","Wenxiang",""],["Wang","Wenxuan",""],["Huang","Jen-tse",""],["Xu","Jiahao",""],["Liang","Tian",""],["He","Pinjia",""],["Tu","Zhaopeng",""]],"versions":[{"version":"v1","created":"Fri, 12 Jul 2024 09:36:33 GMT"}],"updateDate":"2024-07-15","timestamp":1720776993000,"abstract":"  This study addresses a critical gap in safety tuning practices for Large\nLanguage Models (LLMs) by identifying and tackling a refusal position bias\nwithin safety tuning data, which compromises the models' ability to\nappropriately refuse generating unsafe content. We introduce a novel approach,\nDecoupled Refusal Training (DeRTa), designed to empower LLMs to refuse\ncompliance to harmful prompts at any response position, significantly enhancing\ntheir safety capabilities. DeRTa incorporates two novel components: (1) Maximum\nLikelihood Estimation (MLE) with Harmful Response Prefix, which trains models\nto recognize and avoid unsafe content by appending a segment of harmful\nresponse to the beginning of a safe response, and (2) Reinforced Transition\nOptimization (RTO), which equips models with the ability to transition from\npotential harm to safety refusal consistently throughout the harmful response\nsequence. Our empirical evaluation, conducted using LLaMA3 and Mistral model\nfamilies across six attack scenarios, demonstrates that our method not only\nimproves model safety without compromising performance but also surpasses\nwell-known models such as GPT-4 in defending against attacks. Importantly, our\napproach successfully defends recent advanced attack methods (e.g., CodeAttack)\nthat have jailbroken GPT-4 and LLaMA3-70B-Instruct. Our code and data can be\nfound at https://github.com/RobustNLP/DeRTa.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}