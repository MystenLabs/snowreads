{"id":"2408.11327","title":"Plug, Play, and Fuse: Zero-Shot Joint Decoding via Word-Level Re-ranking\n  Across Diverse Vocabularies","authors":"Sai Koneru, Matthias Huck, Miriam Exel, Jan Niehues","authorsParsed":[["Koneru","Sai",""],["Huck","Matthias",""],["Exel","Miriam",""],["Niehues","Jan",""]],"versions":[{"version":"v1","created":"Wed, 21 Aug 2024 04:20:55 GMT"}],"updateDate":"2024-08-22","timestamp":1724214055000,"abstract":"  Recent advancements in NLP have resulted in models with specialized\nstrengths, such as processing multimodal inputs or excelling in specific\ndomains. However, real-world tasks, like multimodal translation, often require\na combination of these strengths, such as handling both translation and image\nprocessing. While individual translation and vision models are powerful, they\ntypically lack the ability to perform both tasks in a single system. Combining\nthese models poses challenges, particularly due to differences in their\nvocabularies, which limit the effectiveness of traditional ensemble methods to\npost-generation techniques like N-best list re-ranking. In this work, we\npropose a novel zero-shot ensembling strategy that allows for the integration\nof different models during the decoding phase without the need for additional\ntraining. Our approach re-ranks beams during decoding by combining scores at\nthe word level, using heuristics to predict when a word is completed. We\ndemonstrate the effectiveness of this method in machine translation scenarios,\nshowing that it enables the generation of translations that are both speech-\nand image-aware while also improving overall translation quality\\footnote{We\nwill release the code upon paper acceptance.}.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/"}