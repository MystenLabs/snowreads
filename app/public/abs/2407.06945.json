{"id":"2407.06945","title":"Adaptively Robust and Sparse K-means Clustering","authors":"Hao Li, Shonosuke Sugasawa, Shota Katayama","authorsParsed":[["Li","Hao",""],["Sugasawa","Shonosuke",""],["Katayama","Shota",""]],"versions":[{"version":"v1","created":"Tue, 9 Jul 2024 15:20:41 GMT"}],"updateDate":"2024-07-10","timestamp":1720538441000,"abstract":"  While K-means is known to be a standard clustering algorithm, it may be\ncompromised due to the presence of outliers and high-dimensional noisy\nvariables. This paper proposes adaptively robust and sparse K-means clustering\n(ARSK) to address these practical limitations of the standard K-means\nalgorithm. We introduce a redundant error component for each observation for\nrobustness, and this additional parameter is penalized using a group sparse\npenalty. To accommodate the impact of high-dimensional noisy variables, the\nobjective function is modified by incorporating weights and implementing a\npenalty to control the sparsity of the weight vector. The tuning parameters to\ncontrol the robustness and sparsity are selected by Gap statistics. Through\nsimulation experiments and real data analysis, we demonstrate the superiority\nof the proposed method to existing algorithms in identifying clusters without\noutliers and informative variables simultaneously.\n","subjects":["Statistics/Computation","Statistics/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}