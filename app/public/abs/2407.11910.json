{"id":"2407.11910","title":"Benchmarking the Attribution Quality of Vision Models","authors":"Robin Hesse, Simone Schaub-Meyer, Stefan Roth","authorsParsed":[["Hesse","Robin",""],["Schaub-Meyer","Simone",""],["Roth","Stefan",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 17:02:20 GMT"}],"updateDate":"2024-07-17","timestamp":1721149340000,"abstract":"  Attribution maps are one of the most established tools to explain the\nfunctioning of computer vision models. They assign importance scores to input\nfeatures, indicating how relevant each feature is for the prediction of a deep\nneural network. While much research has gone into proposing new attribution\nmethods, their proper evaluation remains a difficult challenge. In this work,\nwe propose a novel evaluation protocol that overcomes two fundamental\nlimitations of the widely used incremental-deletion protocol, i.e., the\nout-of-domain issue and lacking inter-model comparisons. This allows us to\nevaluate 23 attribution methods and how eight different design choices of\npopular vision models affect their attribution quality. We find that\nintrinsically explainable models outperform standard models and that raw\nattribution values exhibit a higher attribution quality than what is known from\nprevious work. Further, we show consistent changes in the attribution quality\nwhen varying the network design, indicating that some standard design choices\npromote attribution quality.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}