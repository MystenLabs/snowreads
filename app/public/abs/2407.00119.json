{"id":"2407.00119","title":"Efficient Long-distance Latent Relation-aware Graph Neural Network for\n  Multi-modal Emotion Recognition in Conversations","authors":"Yuntao Shou, Wei Ai, Jiayi Du, Tao Meng, Haiyan Liu, Nan Yin","authorsParsed":[["Shou","Yuntao",""],["Ai","Wei",""],["Du","Jiayi",""],["Meng","Tao",""],["Liu","Haiyan",""],["Yin","Nan",""]],"versions":[{"version":"v1","created":"Thu, 27 Jun 2024 15:54:12 GMT"},{"version":"v2","created":"Sat, 31 Aug 2024 12:44:38 GMT"}],"updateDate":"2024-09-04","timestamp":1719503652000,"abstract":"  The task of multi-modal emotion recognition in conversation (MERC) aims to\nanalyze the genuine emotional state of each utterance based on the multi-modal\ninformation in the conversation, which is crucial for conversation\nunderstanding. Existing methods focus on using graph neural networks (GNN) to\nmodel conversational relationships and capture contextual latent semantic\nrelationships. However, due to the complexity of GNN, existing methods cannot\nefficiently capture the potential dependencies between long-distance\nutterances, which limits the performance of MERC. In this paper, we propose an\nEfficient Long-distance Latent Relation-aware Graph Neural Network (ELR-GNN)\nfor multi-modal emotion recognition in conversations. Specifically, we first\nuse pre-extracted text, video and audio features as input to Bi-LSTM to capture\ncontextual semantic information and obtain low-level utterance features. Then,\nwe use low-level utterance features to construct a conversational emotion\ninteraction graph. To efficiently capture the potential dependencies between\nlong-distance utterances, we use the dilated generalized forward push algorithm\nto precompute the emotional propagation between global utterances and design an\nemotional relation-aware operator to capture the potential semantic\nassociations between different utterances. Furthermore, we combine early fusion\nand adaptive late fusion mechanisms to fuse latent dependency information\nbetween speaker relationship information and context. Finally, we obtain\nhigh-level discourse features and feed them into MLP for emotion prediction.\nExtensive experimental results show that ELR-GNN achieves state-of-the-art\nperformance on the benchmark datasets IEMOCAP and MELD, with running times\nreduced by 52\\% and 35\\%, respectively.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/"}