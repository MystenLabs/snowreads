{"id":"2407.12141","title":"Predicting Emotion Intensity in Polish Political Texts: Comparing\n  Supervised Models and Large Language Models in a Resource-Poor Language","authors":"Hubert Plisiecki, Piotr Koc, Maria Flakus, Artur Pokropek","authorsParsed":[["Plisiecki","Hubert",""],["Koc","Piotr",""],["Flakus","Maria",""],["Pokropek","Artur",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 19:53:14 GMT"}],"updateDate":"2024-07-18","timestamp":1721159594000,"abstract":"  This study explores the use of large language models (LLMs) to predict\nemotion intensity in Polish political texts, a resource-poor language context.\nThe research compares the performance of several LLMs against a supervised\nmodel trained on an annotated corpus of 10,000 social media texts, evaluated\nfor the intensity of emotions by expert judges. The findings indicate that\nwhile the supervised model generally outperforms LLMs, offering higher accuracy\nand lower variance, LLMs present a viable alternative, especially given the\nhigh costs associated with data annotation. The study highlights the potential\nof LLMs in low-resource language settings and underscores the need for further\nresearch on emotion intensity prediction and its application across different\nlanguages and continuous features. The implications suggest a nuanced\ndecision-making process to choose the right approach to emotion prediction for\nresearchers and practitioners based on resource availability and the specific\nrequirements of their tasks.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by-sa/4.0/","blobId":"p68r-V5dWn0gsBkrq4sADFjmIzAXjm5rBbglMZpLcyA","pdfSize":"816829"}
