{"id":"2407.16643","title":"Synthesizer Sound Matching Using Audio Spectrogram Transformers","authors":"Fred Bruford, Frederik Blang, and Shahan Nercessian","authorsParsed":[["Bruford","Fred",""],["Blang","Frederik",""],["Nercessian","Shahan",""]],"versions":[{"version":"v1","created":"Tue, 23 Jul 2024 16:58:14 GMT"}],"updateDate":"2024-07-24","timestamp":1721753894000,"abstract":"  Systems for synthesizer sound matching, which automatically set the\nparameters of a synthesizer to emulate an input sound, have the potential to\nmake the process of synthesizer programming faster and easier for novice and\nexperienced musicians alike, whilst also affording new means of interaction\nwith synthesizers. Considering the enormous variety of synthesizers in the\nmarketplace, and the complexity of many of them, general-purpose sound matching\nsystems that function with minimal knowledge or prior assumptions about the\nunderlying synthesis architecture are particularly desirable. With this in\nmind, we introduce a synthesizer sound matching model based on the Audio\nSpectrogram Transformer. We demonstrate the viability of this model by training\non a large synthetic dataset of randomly generated samples from the popular\nMassive synthesizer. We show that this model can reconstruct parameters of\nsamples generated from a set of 16 parameters, highlighting its improved\nfidelity relative to multi-layer perceptron and convolutional neural network\nbaselines. We also provide audio examples demonstrating the out-of-domain model\nperformance in emulating vocal imitations, and sounds from other synthesizers\nand musical instruments.\n","subjects":["Electrical Engineering and Systems Science/Audio and Speech Processing","Computing Research Repository/Machine Learning","Computing Research Repository/Sound"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"e-KkKB5iQiF_mwTazPb1x2xAbKDIlkbkSgGHM3BM_bE","pdfSize":"408713"}
