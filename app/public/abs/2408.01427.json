{"id":"2408.01427","title":"Siamese Transformer Networks for Few-shot Image Classification","authors":"Weihao Jiang, Shuoxi Zhang, Kun He","authorsParsed":[["Jiang","Weihao",""],["Zhang","Shuoxi",""],["He","Kun",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 14:27:23 GMT"}],"updateDate":"2024-08-06","timestamp":1721140043000,"abstract":"  Humans exhibit remarkable proficiency in visual classification tasks,\naccurately recognizing and classifying new images with minimal examples. This\nability is attributed to their capacity to focus on details and identify common\nfeatures between previously seen and new images. In contrast, existing few-shot\nimage classification methods often emphasize either global features or local\nfeatures, with few studies considering the integration of both. To address this\nlimitation, we propose a novel approach based on the Siamese Transformer\nNetwork (STN). Our method employs two parallel branch networks utilizing the\npre-trained Vision Transformer (ViT) architecture to extract global and local\nfeatures, respectively. Specifically, we implement the ViT-Small network\narchitecture and initialize the branch networks with pre-trained model\nparameters obtained through self-supervised learning. We apply the Euclidean\ndistance measure to the global features and the Kullback-Leibler (KL)\ndivergence measure to the local features. To integrate the two metrics, we\nfirst employ L2 normalization and then weight the normalized results to obtain\nthe final similarity score. This strategy leverages the advantages of both\nglobal and local features while ensuring their complementary benefits. During\nthe training phase, we adopt a meta-learning approach to fine-tune the entire\nnetwork. Our strategy effectively harnesses the potential of global and local\nfeatures in few-shot image classification, circumventing the need for complex\nfeature adaptation modules and enhancing the model's generalization ability.\nExtensive experiments demonstrate that our framework is simple yet effective,\nachieving superior performance compared to state-of-the-art baselines on four\npopular few-shot classification benchmarks in both 5-shot and 1-shot scenarios.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}