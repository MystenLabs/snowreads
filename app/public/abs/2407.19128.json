{"id":"2407.19128","title":"Relational Q-Functionals: Multi-Agent Learning to Recover from\n  Unforeseen Robot Malfunctions in Continuous Action Domains","authors":"Yasin Findik, Paul Robinette, Kshitij Jerath, Reza Azadeh","authorsParsed":[["Findik","Yasin",""],["Robinette","Paul",""],["Jerath","Kshitij",""],["Azadeh","Reza",""]],"versions":[{"version":"v1","created":"Sat, 27 Jul 2024 00:03:14 GMT"}],"updateDate":"2024-07-30","timestamp":1722038594000,"abstract":"  Cooperative multi-agent learning methods are essential in developing\neffective cooperation strategies in multi-agent domains. In robotics, these\nmethods extend beyond multi-robot scenarios to single-robot systems, where they\nenable coordination among different robot modules (e.g., robot legs or joints).\nHowever, current methods often struggle to quickly adapt to unforeseen\nfailures, such as a malfunctioning robot leg, especially after the algorithm\nhas converged to a strategy. To overcome this, we introduce the Relational\nQ-Functionals (RQF) framework. RQF leverages a relational network, representing\nagents' relationships, to enhance adaptability, providing resilience against\nmalfunction(s). Our algorithm also efficiently handles continuous state-action\ndomains, making it adept for robotic learning tasks. Our empirical results show\nthat RQF enables agents to use these relationships effectively to facilitate\ncooperation and recover from an unexpected malfunction in single-robot systems\nwith multiple interacting modules. Thus, our approach offers promising\napplications in multi-agent systems, particularly in scenarios with unforeseen\nmalfunctions.\n","subjects":["Computing Research Repository/Robotics","Computing Research Repository/Multiagent Systems"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"IWBJswaXkdwBjSVCCRVYEEArArImuz2nXhwaodd4T0g","pdfSize":"507666"}
