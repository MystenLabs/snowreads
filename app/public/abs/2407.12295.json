{"id":"2407.12295","title":"Exploiting Inter-Image Similarity Prior for Low-Bitrate Remote Sensing\n  Image Compression","authors":"Junhui Li and Xingsong Hou","authorsParsed":[["Li","Junhui",""],["Hou","Xingsong",""]],"versions":[{"version":"v1","created":"Wed, 17 Jul 2024 03:33:16 GMT"}],"updateDate":"2024-07-18","timestamp":1721187196000,"abstract":"  Deep learning-based methods have garnered significant attention in remote\nsensing (RS) image compression due to their superior performance. Most of these\nmethods focus on enhancing the coding capability of the compression network and\nimproving entropy model prediction accuracy. However, they typically compress\nand decompress each image independently, ignoring the significant inter-image\nsimilarity prior. In this paper, we propose a codebook-based RS image\ncompression (Code-RSIC) method with a generated discrete codebook, which is\ndeployed at the decoding end of a compression algorithm to provide inter-image\nsimilarity prior. Specifically, we first pretrain a high-quality discrete\ncodebook using the competitive generation model VQGAN. We then introduce a\nTransformer-based prediction model to align the latent features of the decoded\nimages from an existing compression algorithm with the frozen high-quality\ncodebook. Finally, we develop a hierarchical prior integration network (HPIN),\nwhich mainly consists of Transformer blocks and multi-head cross-attention\nmodules (MCMs) that can query hierarchical prior from the codebook, thus\nenhancing the ability of the proposed method to decode texture-rich RS images.\nExtensive experimental results demonstrate that the proposed Code-RSIC\nsignificantly outperforms state-of-the-art traditional and learning-based image\ncompression algorithms in terms of perception quality. The code will be\navailable at \\url{https://github.com/mlkk518/Code-RSIC/\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Electrical Engineering and Systems Science/Image and Video Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}