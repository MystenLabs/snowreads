{"id":"2408.15254","title":"vFusedSeg3D: 3rd Place Solution for 2024 Waymo Open Dataset Challenge in\n  Semantic Segmentation","authors":"Osama Amjad and Ammad Nadeem","authorsParsed":[["Amjad","Osama",""],["Nadeem","Ammad",""]],"versions":[{"version":"v1","created":"Fri, 9 Aug 2024 11:34:19 GMT"}],"updateDate":"2024-08-29","timestamp":1723203259000,"abstract":"  In this technical study, we introduce VFusedSeg3D, an innovative multi-modal\nfusion system created by the VisionRD team that combines camera and LiDAR data\nto significantly enhance the accuracy of 3D perception. VFusedSeg3D uses the\nrich semantic content of the camera pictures and the accurate depth sensing of\nLiDAR to generate a strong and comprehensive environmental understanding,\naddressing the constraints inherent in each modality. Through a carefully\nthought-out network architecture that aligns and merges these information at\ndifferent stages, our novel feature fusion technique combines geometric\nfeatures from LiDAR point clouds with semantic features from camera images.\nWith the use of multi-modality techniques, performance has significantly\nimproved, yielding a state-of-the-art mIoU of 72.46% on the validation set as\nopposed to the prior 70.51%.VFusedSeg3D sets a new benchmark in 3D segmentation\naccuracy. making it an ideal solution for applications requiring precise\nenvironmental perception.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"yWc5zn62dk02xBlVSPkwnQKvaPl5hTOxLxdyOZwKUe8","pdfSize":"355864"}
