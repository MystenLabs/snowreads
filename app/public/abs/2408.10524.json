{"id":"2408.10524","title":"XCB: an effective contextual biasing approach to bias cross-lingual\n  phrases in speech recognition","authors":"Xucheng Wan, Naijun Zheng, Kai Liu, Huan Zhou","authorsParsed":[["Wan","Xucheng",""],["Zheng","Naijun",""],["Liu","Kai",""],["Zhou","Huan",""]],"versions":[{"version":"v1","created":"Tue, 20 Aug 2024 04:00:19 GMT"}],"updateDate":"2024-08-21","timestamp":1724126419000,"abstract":"  Contextualized ASR models have been demonstrated to effectively improve the\nrecognition accuracy of uncommon phrases when a predefined phrase list is\navailable. However, these models often struggle with bilingual settings, which\nare prevalent in code-switching speech recognition. In this study, we make the\ninitial attempt to address this challenge by introducing a Cross-lingual\nContextual Biasing(XCB) module. Specifically, we augment a pre-trained ASR\nmodel for the dominant language by integrating an auxiliary language biasing\nmodule and a supplementary language-specific loss, aimed at enhancing the\nrecognition of phrases in the secondary language. Experimental results\nconducted on our in-house code-switching dataset have validated the efficacy of\nour approach, demonstrating significant improvements in the recognition of\nbiasing phrases in the secondary language, even without any additional\ninference overhead. Additionally, our proposed system exhibits both efficiency\nand generalization when is applied by the unseen ASRU-2019 test set.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Sound","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"6QUvQgQY2lZI9IqNxUoRgOsIDpCDS3l1Ruf4y0yXyMw","pdfSize":"387462"}
