{"id":"2407.16030","title":"Enhancing Temporal Understanding in LLMs for Semi-structured Tables","authors":"Irwin Deng, Kushagra Dixit, Vivek Gupta, Dan Roth","authorsParsed":[["Deng","Irwin",""],["Dixit","Kushagra",""],["Gupta","Vivek",""],["Roth","Dan",""]],"versions":[{"version":"v1","created":"Mon, 22 Jul 2024 20:13:10 GMT"}],"updateDate":"2024-07-24","timestamp":1721679190000,"abstract":"  Temporal reasoning over tabular data presents substantial challenges for\nlarge language models (LLMs), as evidenced by recent research. In this study,\nwe conduct a comprehensive analysis of temporal datasets to pinpoint the\nspecific limitations of LLMs. Our investigation leads to enhancements in\nTempTabQA, a dataset specifically designed for tabular temporal question\nanswering. We provide critical insights for improving LLM performance in\ntemporal reasoning tasks with tabular data. Furthermore, we introduce a novel\napproach, C.L.E.A.R to strengthen LLM capabilities in this domain. Our findings\ndemonstrate that our method significantly improves evidence-based reasoning\nacross various models. Additionally, our experimental results reveal that\nindirect supervision with auxiliary data substantially boosts model performance\nin these tasks. This work contributes to a deeper understanding of LLMs'\ntemporal reasoning abilities over tabular data and promotes advancements in\ntheir application across diverse fields.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Databases","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"dDSxzBWNaVpHnSavO-AxOYJB4ZnNcOMNVzlqFLl75NA","pdfSize":"670736"}
