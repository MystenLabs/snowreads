{"id":"2408.06997","title":"Faster Private Minimum Spanning Trees","authors":"Rasmus Pagh, Lukas Retschmeier","authorsParsed":[["Pagh","Rasmus",""],["Retschmeier","Lukas",""]],"versions":[{"version":"v1","created":"Tue, 13 Aug 2024 16:00:30 GMT"}],"updateDate":"2024-08-14","timestamp":1723564830000,"abstract":"  Motivated by applications in clustering and synthetic data generation, we\nconsider the problem of releasing a minimum spanning tree (MST) under\nedge-weight differential privacy constraints where a graph topology $G=(V,E)$\nwith $n$ vertices and $m$ edges is public, the weight matrix $\\vec{W}\\in\n\\mathbb{R}^{n \\times n}$ is private, and we wish to release an approximate MST\nunder $\\rho$-zero-concentrated differential privacy. Weight matrices are\nconsidered neighboring if they differ by at most $\\Delta_\\infty$ in each entry,\ni.e., we consider an $\\ell_\\infty$ neighboring relationship. Existing private\nMST algorithms either add noise to each entry in $\\vec{W}$ and estimate the MST\nby post-processing or add noise to weights in-place during the execution of a\nspecific MST algorithm. Using the post-processing approach with an efficient\nMST algorithm takes $O(n^2)$ time on dense graphs but results in an additive\nerror on the weight of the MST of magnitude $O(n^2\\log n)$. In-place algorithms\ngive asymptotically better utility, but the running time of existing in-place\nalgorithms is $O(n^3)$ for dense graphs. Our main result is a new\ndifferentially private MST algorithm that matches the utility of existing\nin-place methods while running in time $O(m + n^{3/2}\\log n)$ for fixed privacy\nparameter $\\rho$. The technical core of our algorithm is an efficient sublinear\ntime simulation of Report-Noisy-Max that works by discretizing all edge weights\nto a multiple of $\\Delta_\\infty$ and forming groups of edges with identical\nweights. Specifically, we present a data structure that allows us to sample a\nnoisy minimum weight edge among at most $O(n^2)$ cut edges in $O(\\sqrt{n} \\log\nn)$ time. Experimental evaluations support our claims that our algorithm\nsignificantly improves previous algorithms either in utility or running time.\n","subjects":["Computing Research Repository/Data Structures and Algorithms","Computing Research Repository/Cryptography and Security","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"k2vpIWBZFJFoBDUoAFeLis1t4rHU2Y9Taym4IX1v6HA","pdfSize":"2627059"}
