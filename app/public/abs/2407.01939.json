{"id":"2407.01939","title":"Unsupervised Face-Masked Speech Enhancement Using Generative Adversarial\n  Networks With Human-in-the-Loop Assessment Metrics","authors":"Syu-Siang Wang, Jia-Yang Chen, Bo-Ren Bai, Shih-Hau Fang and Yu Tsao","authorsParsed":[["Wang","Syu-Siang",""],["Chen","Jia-Yang",""],["Bai","Bo-Ren",""],["Fang","Shih-Hau",""],["Tsao","Yu",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 04:13:59 GMT"},{"version":"v2","created":"Sat, 20 Jul 2024 16:26:34 GMT"}],"updateDate":"2024-07-23","timestamp":1719893639000,"abstract":"  The utilization of face masks is an essential healthcare measure,\nparticularly during times of pandemics, yet it can present challenges in\ncommunication in our daily lives. To address this problem, we propose a novel\napproach known as the human-in-the-loop StarGAN (HL-StarGAN) face-masked speech\nenhancement method. HL-StarGAN comprises discriminator, classifier, metric\nassessment predictor, and generator that leverages an attention mechanism. The\nmetric assessment predictor, referred to as MaskQSS, incorporates human\nparticipants in its development and serves as a \"human-in-the-loop\" module\nduring the learning process of HL-StarGAN. The overall HL-StarGAN model was\ntrained using an unsupervised learning strategy that simultaneously focuses on\nthe reconstruction of the original clean speech and the optimization of human\nperception. To implement HL-StarGAN, we curated a face-masked speech database\nnamed \"FMVD,\" which comprises recordings from 34 speakers in three distinct\nface-masked scenarios and a clean condition. We conducted subjective and\nobjective tests on the proposed HL-StarGAN using this database. The outcomes of\nthe test results are as follows: (1) MaskQSS successfully predicted the quality\nscores of face mask voices, outperforming several existing speech assessment\nmethods. (2) The integration of the MaskQSS predictor enhanced the ability of\nHL-StarGAN to transform face mask voices into high-quality speech; this\nenhancement is evident in both objective and subjective tests, outperforming\nconventional StarGAN and CycleGAN-based systems.\n","subjects":["Electrical Engineering and Systems Science/Audio and Speech Processing","Electrical Engineering and Systems Science/Signal Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}