{"id":"2408.03178","title":"An Object is Worth 64x64 Pixels: Generating 3D Object via Image\n  Diffusion","authors":"Xingguang Yan, Han-Hung Lee, Ziyu Wan, Angel X. Chang","authorsParsed":[["Yan","Xingguang",""],["Lee","Han-Hung",""],["Wan","Ziyu",""],["Chang","Angel X.",""]],"versions":[{"version":"v1","created":"Tue, 6 Aug 2024 13:22:51 GMT"}],"updateDate":"2024-08-07","timestamp":1722950571000,"abstract":"  We introduce a new approach for generating realistic 3D models with UV maps\nthrough a representation termed \"Object Images.\" This approach encapsulates\nsurface geometry, appearance, and patch structures within a 64x64 pixel image,\neffectively converting complex 3D shapes into a more manageable 2D format. By\ndoing so, we address the challenges of both geometric and semantic irregularity\ninherent in polygonal meshes. This method allows us to use image generation\nmodels, such as Diffusion Transformers, directly for 3D shape generation.\nEvaluated on the ABO dataset, our generated shapes with patch structures\nachieve point cloud FID comparable to recent 3D generative models, while\nnaturally supporting PBR material generation.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Graphics","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}