{"id":"2408.17246","title":"Learning and Verifying Maximal Taylor-Neural Lyapunov functions","authors":"Matthieu Barreau, Nicola Bastianello","authorsParsed":[["Barreau","Matthieu",""],["Bastianello","Nicola",""]],"versions":[{"version":"v1","created":"Fri, 30 Aug 2024 12:40:12 GMT"}],"updateDate":"2024-09-02","timestamp":1725021612000,"abstract":"  We introduce a novel neural network architecture, termed Taylor-neural\nLyapunov functions, designed to approximate Lyapunov functions with formal\ncertification. This architecture innovatively encodes local approximations and\nextends them globally by leveraging neural networks to approximate the\nresiduals. Our method recasts the problem of estimating the largest region of\nattraction - specifically for maximal Lyapunov functions - into a learning\nproblem, ensuring convergence around the origin through robust control theory.\nPhysics-informed machine learning techniques further refine the estimation of\nthe largest region of attraction. Remarkably, this method is versatile,\noperating effectively even without simulated data points. We validate the\nefficacy of our approach by providing numerical certificates of convergence\nacross multiple examples. Our proposed methodology not only competes closely\nwith state-of-the-art approaches, such as sum-of-squares and LyZNet, but also\nachieves comparable results even in the absence of simulated data. This work\nrepresents a significant advancement in control theory, with broad potential\napplications in the design of stable control systems and beyond.\n","subjects":["Mathematics/Optimization and Control","Computing Research Repository/Machine Learning","Computing Research Repository/Systems and Control","Electrical Engineering and Systems Science/Systems and Control"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}