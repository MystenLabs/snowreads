{"id":"2408.04737","title":"Quantifying the Corpus Bias Problem in Automatic Music Transcription\n  Systems","authors":"Luk\\'a\\v{s} Samuel Mart\\'ak, Patricia Hu and Gerhard Widmer","authorsParsed":[["Marták","Lukáš Samuel",""],["Hu","Patricia",""],["Widmer","Gerhard",""]],"versions":[{"version":"v1","created":"Thu, 8 Aug 2024 19:40:28 GMT"}],"updateDate":"2024-08-12","timestamp":1723146028000,"abstract":"  Automatic Music Transcription (AMT) is the task of recognizing notes in audio\nrecordings of music. The State-of-the-Art (SotA) benchmarks have been dominated\nby deep learning systems. Due to the scarcity of high quality data, they are\nusually trained and evaluated exclusively or predominantly on classical piano\nmusic. Unfortunately, that hinders our ability to understand how they\ngeneralize to other music. Previous works have revealed several aspects of\nmemorization and overfitting in these systems. We identify two primary sources\nof distribution shift: the music, and the sound. Complementing recent results\non the sound axis (i.e. acoustics, timbre), we investigate the musical one\n(i.e. note combinations, dynamics, genre). We evaluate the performance of\nseveral SotA AMT systems on two new experimental test sets which we carefully\nconstruct to emulate different levels of musical distribution shift. Our\nresults reveal a stark performance gap, shedding further light on the Corpus\nBias problem, and the extent to which it continues to trouble these systems.\n","subjects":["Computing Research Repository/Sound","Computing Research Repository/Machine Learning","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}