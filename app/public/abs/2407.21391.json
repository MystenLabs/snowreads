{"id":"2407.21391","title":"Design and Development of Laughter Recognition System Based on\n  Multimodal Fusion and Deep Learning","authors":"Fuzheng Zhao and Yu Bai","authorsParsed":[["Zhao","Fuzheng",""],["Bai","Yu",""]],"versions":[{"version":"v1","created":"Wed, 31 Jul 2024 07:31:13 GMT"}],"updateDate":"2024-08-01","timestamp":1722411073000,"abstract":"  This study aims to design and implement a laughter recognition system based\non multimodal fusion and deep learning, leveraging image and audio processing\ntechnologies to achieve accurate laughter recognition and emotion analysis.\nFirst, the system loads video files and uses the OpenCV library to extract\nfacial information while employing the Librosa library to process audio\nfeatures such as MFCC. Then, multimodal fusion techniques are used to integrate\nimage and audio features, followed by training and prediction using deep\nlearning models. Evaluation results indicate that the model achieved 80%\naccuracy, precision, and recall on the test dataset, with an F1 score of 80%,\ndemonstrating robust performance and the ability to handle real-world data\nvariability. This study not only verifies the effectiveness of multimodal\nfusion methods in laughter recognition but also highlights their potential\napplications in affective computing and human-computer interaction. Future work\nwill focus on further optimizing feature extraction and model architecture to\nimprove recognition accuracy and expand application scenarios, promoting the\ndevelopment of laughter recognition technology in fields such as mental health\nmonitoring and educational activity evaluation\n","subjects":["Computing Research Repository/Sound","Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Multimedia","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by-sa/4.0/","blobId":"ib1YzQ5aZkgfNZwuXFkUyUfJWlHKXwMGcdZEUmr3bqI","pdfSize":"747829"}
