{"id":"2408.06259","title":"Context-aware Visual Storytelling with Visual Prefix Tuning and\n  Contrastive Learning","authors":"Yingjin Song, Denis Paperno, Albert Gatt","authorsParsed":[["Song","Yingjin",""],["Paperno","Denis",""],["Gatt","Albert",""]],"versions":[{"version":"v1","created":"Mon, 12 Aug 2024 16:15:32 GMT"}],"updateDate":"2024-08-13","timestamp":1723479332000,"abstract":"  Visual storytelling systems generate multi-sentence stories from image\nsequences. In this task, capturing contextual information and bridging visual\nvariation bring additional challenges. We propose a simple yet effective\nframework that leverages the generalization capabilities of pretrained\nfoundation models, only training a lightweight vision-language mapping network\nto connect modalities, while incorporating context to enhance coherence. We\nintroduce a multimodal contrastive objective that also improves visual\nrelevance and story informativeness. Extensive experimental results, across\nboth automatic metrics and human evaluations, demonstrate that the stories\ngenerated by our framework are diverse, coherent, informative, and interesting.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}