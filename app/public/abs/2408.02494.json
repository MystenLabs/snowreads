{"id":"2408.02494","title":"HyperSpaceX: Radial and Angular Exploration of HyperSpherical Dimensions","authors":"Chiranjeev Chiranjeev, Muskan Dosi, Kartik Thakral, Mayank Vatsa and\n  Richa Singh","authorsParsed":[["Chiranjeev","Chiranjeev",""],["Dosi","Muskan",""],["Thakral","Kartik",""],["Vatsa","Mayank",""],["Singh","Richa",""]],"versions":[{"version":"v1","created":"Mon, 5 Aug 2024 14:18:29 GMT"}],"updateDate":"2024-08-06","timestamp":1722867509000,"abstract":"  Traditional deep learning models rely on methods such as softmax\ncross-entropy and ArcFace loss for tasks like classification and face\nrecognition. These methods mainly explore angular features in a hyperspherical\nspace, often resulting in entangled inter-class features due to dense angular\ndata across many classes. In this paper, a new field of feature exploration is\nproposed known as HyperSpaceX which enhances class discrimination by exploring\nboth angular and radial dimensions in multi-hyperspherical spaces, facilitated\nby a novel DistArc loss. The proposed DistArc loss encompasses three feature\narrangement components: two angular and one radial, enforcing intra-class\nbinding and inter-class separation in multi-radial arrangement, improving\nfeature discriminability. Evaluation of HyperSpaceX framework for the novel\nrepresentation utilizes a proposed predictive measure that accounts for both\nangular and radial elements, providing a more comprehensive assessment of model\naccuracy beyond standard metrics. Experiments across seven object\nclassification and six face recognition datasets demonstrate state-of-the-art\n(SoTA) results obtained from HyperSpaceX, achieving up to a 20% performance\nimprovement on large-scale object datasets in lower dimensions and up to 6%\ngain in higher dimensions.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"VjMv6ceE_k__99H3kharPAEbHWCou23PlH9x6ghIeH4","pdfSize":"5664597"}
