{"id":"2408.12480","title":"Vintern-1B: An Efficient Multimodal Large Language Model for Vietnamese","authors":"Khang T. Doan, Bao G. Huynh, Dung T. Hoang, Thuc D. Pham, Nhat H.\n  Pham, Quan T.M. Nguyen, Bang Q. Vo and Suong N. Hoang","authorsParsed":[["Doan","Khang T.",""],["Huynh","Bao G.",""],["Hoang","Dung T.",""],["Pham","Thuc D.",""],["Pham","Nhat H.",""],["Nguyen","Quan T. M.",""],["Vo","Bang Q.",""],["Hoang","Suong N.",""]],"versions":[{"version":"v1","created":"Thu, 22 Aug 2024 15:15:51 GMT"},{"version":"v2","created":"Fri, 23 Aug 2024 09:52:52 GMT"}],"updateDate":"2024-08-26","timestamp":1724339751000,"abstract":"  In this report, we introduce Vintern-1B, a reliable 1-billion-parameters\nmultimodal large language model (MLLM) for Vietnamese language tasks. By\nintegrating the Qwen2-0.5B-Instruct language model with the\nInternViT-300M-448px visual model, Vintern-1B is optimized for a range of\napplications, including optical character recognition (OCR), document\nextraction, and general question-answering in Vietnamese context. The model is\nfine-tuned on an extensive dataset of over 3 million image-question-answer\npairs, achieving robust performance and reliable results across multiple\nVietnamese language benchmarks like OpenViVQA and ViTextVQA. Vintern-1B is\nsmall enough to fit into various on-device applications easily. Additionally,\nwe have open-sourced several Vietnamese vision question answering (VQA)\ndatasets for text and diagrams, created with Gemini 1.5 Flash. Our models are\navailable at: https://huggingface.co/5CD-AI/Vintern-1B-v2.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/publicdomain/zero/1.0/","blobId":"CMaMwLaw5WV2UPod-Ok9WjjvhaPcoYFlHCgFoRONB78","pdfSize":"4651762"}
