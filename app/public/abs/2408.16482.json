{"id":"2408.16482","title":"Self-Alignment: Improving Alignment of Cultural Values in LLMs via\n  In-Context Learning","authors":"Rochelle Choenni, Ekaterina Shutova","authorsParsed":[["Choenni","Rochelle",""],["Shutova","Ekaterina",""]],"versions":[{"version":"v1","created":"Thu, 29 Aug 2024 12:18:04 GMT"}],"updateDate":"2024-08-30","timestamp":1724933884000,"abstract":"  Improving the alignment of Large Language Models (LLMs) with respect to the\ncultural values that they encode has become an increasingly important topic. In\nthis work, we study whether we can exploit existing knowledge about cultural\nvalues at inference time to adjust model responses to cultural value probes. We\npresent a simple and inexpensive method that uses a combination of in-context\nlearning (ICL) and human survey data, and show that we can improve the\nalignment to cultural values across 5 models that include both English-centric\nand multilingual LLMs. Importantly, we show that our method could prove useful\nin test languages other than English and can improve alignment to the cultural\nvalues that correspond to a range of culturally diverse countries.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}