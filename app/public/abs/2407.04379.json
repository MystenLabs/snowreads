{"id":"2407.04379","title":"A Mapping Strategy for Interacting with Latent Audio Synthesis Using\n  Artistic Materials","authors":"Shuoyang Zheng, Anna Xamb\\'o Sed\\'o, and Nick Bryan-Kinns","authorsParsed":[["Zheng","Shuoyang",""],["Sedó","Anna Xambó",""],["Bryan-Kinns","Nick",""]],"versions":[{"version":"v1","created":"Fri, 5 Jul 2024 09:32:44 GMT"}],"updateDate":"2024-07-22","timestamp":1720171964000,"abstract":"  This paper presents a mapping strategy for interacting with the latent spaces\nof generative AI models. Our approach involves using unsupervised feature\nlearning to encode a human control space and mapping it to an audio synthesis\nmodel's latent space. To demonstrate how this mapping strategy can turn\nhigh-dimensional sensor data into control mechanisms of a deep generative\nmodel, we present a proof-of-concept system that uses visual sketches to\ncontrol an audio synthesis model. We draw on emerging discourses in XAIxArts to\ndiscuss how this approach can contribute to XAI in artistic and creative\ncontexts, we also discuss its current limitations and propose future research\ndirections.\n","subjects":["Computing Research Repository/Sound","Computing Research Repository/Human-Computer Interaction","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by/4.0/"}