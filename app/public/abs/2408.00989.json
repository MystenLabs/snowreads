{"id":"2408.00989","title":"On the Resilience of Multi-Agent Systems with Malicious Agents","authors":"Jen-tse Huang, Jiaxu Zhou, Tailin Jin, Xuhui Zhou, Zixi Chen, Wenxuan\n  Wang, Youliang Yuan, Maarten Sap, Michael R. Lyu","authorsParsed":[["Huang","Jen-tse",""],["Zhou","Jiaxu",""],["Jin","Tailin",""],["Zhou","Xuhui",""],["Chen","Zixi",""],["Wang","Wenxuan",""],["Yuan","Youliang",""],["Sap","Maarten",""],["Lyu","Michael R.",""]],"versions":[{"version":"v1","created":"Fri, 2 Aug 2024 03:25:20 GMT"}],"updateDate":"2024-08-05","timestamp":1722569120000,"abstract":"  Multi-agent systems, powered by large language models, have shown great\nabilities across various tasks due to the collaboration of expert agents, each\nfocusing on a specific domain. However, when agents are deployed separately,\nthere is a risk that malicious users may introduce malicious agents who\ngenerate incorrect or irrelevant results that are too stealthy to be identified\nby other non-specialized agents. Therefore, this paper investigates two\nessential questions: (1) What is the resilience of various multi-agent system\nstructures (e.g., A$\\rightarrow$B$\\rightarrow$C,\nA$\\leftrightarrow$B$\\leftrightarrow$C) under malicious agents, on different\ndownstream tasks? (2) How can we increase system resilience to defend against\nmalicious agents? To simulate malicious agents, we devise two methods,\nAutoTransform and AutoInject, to transform any agent into a malicious one while\npreserving its functional integrity. We run comprehensive experiments on four\ndownstream multi-agent systems tasks, namely code generation, math problems,\ntranslation, and text evaluation. Results suggest that the \"hierarchical\"\nmulti-agent structure, i.e., A$\\rightarrow$(B$\\leftrightarrow$C), exhibits\nsuperior resilience with the lowest performance drop of $23.6\\%$, compared to\n$46.4\\%$ and $49.8\\%$ of other two structures. Additionally, we show the\npromise of improving multi-agent system resilience by demonstrating that two\ndefense methods, introducing an additional agent to review and correct messages\nor mechanisms for each agent to challenge others' outputs, can enhance system\nresilience. Our code and data are available at\nhttps://github.com/CUHK-ARISE/MAS-Resilience.\n","subjects":["Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}