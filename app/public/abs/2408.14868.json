{"id":"2408.14868","title":"ZeroMamba: Exploring Visual State Space Model for Zero-Shot Learning","authors":"Wenjin Hou, Dingjie Fu, Kun Li, Shiming Chen, Hehe Fan, Yi Yang","authorsParsed":[["Hou","Wenjin",""],["Fu","Dingjie",""],["Li","Kun",""],["Chen","Shiming",""],["Fan","Hehe",""],["Yang","Yi",""]],"versions":[{"version":"v1","created":"Tue, 27 Aug 2024 08:39:47 GMT"}],"updateDate":"2024-08-28","timestamp":1724747987000,"abstract":"  Zero-shot learning (ZSL) aims to recognize unseen classes by transferring\nsemantic knowledge from seen classes to unseen ones, guided by semantic\ninformation. To this end, existing works have demonstrated remarkable\nperformance by utilizing global visual features from Convolutional Neural\nNetworks (CNNs) or Vision Transformers (ViTs) for visual-semantic interactions.\nDue to the limited receptive fields of CNNs and the quadratic complexity of\nViTs, however, these visual backbones achieve suboptimal visual-semantic\ninteractions. In this paper, motivated by the visual state space model (i.e.,\nVision Mamba), which is capable of capturing long-range dependencies and\nmodeling complex visual dynamics, we propose a parameter-efficient ZSL\nframework called ZeroMamba to advance ZSL. Our ZeroMamba comprises three key\ncomponents: Semantic-aware Local Projection (SLP), Global Representation\nLearning (GRL), and Semantic Fusion (SeF). Specifically, SLP integrates\nsemantic embeddings to map visual features to local semantic-related\nrepresentations, while GRL encourages the model to learn global semantic\nrepresentations. SeF combines these two semantic representations to enhance the\ndiscriminability of semantic features. We incorporate these designs into Vision\nMamba, forming an end-to-end ZSL framework. As a result, the learned semantic\nrepresentations are better suited for classification. Through extensive\nexperiments on four prominent ZSL benchmarks, ZeroMamba demonstrates superior\nperformance, significantly outperforming the state-of-the-art (i.e., CNN-based\nand ViT-based) methods under both conventional ZSL (CZSL) and generalized ZSL\n(GZSL) settings. Code is available at:\nhttps://anonymous.4open.science/r/ZeroMamba.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}