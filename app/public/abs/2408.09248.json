{"id":"2408.09248","title":"MagicID: Flexible ID Fidelity Generation System","authors":"Zhaoli Deng, Wen Liu, Fanyi Wang, Junkang Zhang, Fan Chen, Meng Zhang,\n  Wendong Zhang, Zhenpeng Mi","authorsParsed":[["Deng","Zhaoli",""],["Liu","Wen",""],["Wang","Fanyi",""],["Zhang","Junkang",""],["Chen","Fan",""],["Zhang","Meng",""],["Zhang","Wendong",""],["Mi","Zhenpeng",""]],"versions":[{"version":"v1","created":"Sat, 17 Aug 2024 16:34:03 GMT"},{"version":"v2","created":"Tue, 20 Aug 2024 14:39:46 GMT"}],"updateDate":"2024-08-21","timestamp":1723912443000,"abstract":"  Portrait Fidelity Generation is a prominent research area in generative\nmodels, with a primary focus on enhancing both controllability and fidelity.\nCurrent methods face challenges in generating high-fidelity portrait results\nwhen faces occupy a small portion of the image with a low resolution,\nespecially in multi-person group photo settings. To tackle these issues, we\npropose a systematic solution called MagicID, based on a self-constructed\nmillion-level multi-modal dataset named IDZoom. MagicID consists of Multi-Mode\nFusion training strategy (MMF) and DDIM Inversion based ID Restoration\ninference framework (DIIR). During training, MMF iteratively uses the skeleton\nand landmark modalities from IDZoom as conditional guidance. By introducing the\nClone Face Tuning in training stage and Mask Guided Multi-ID Cross Attention\n(MGMICA) in inference stage, explicit constraints on face positional features\nare achieved for multi-ID group photo generation. The DIIR aims to address the\nissue of artifacts. The DDIM Inversion is used in conjunction with face\nlandmarks, global and local face features to achieve face restoration while\nkeeping the background unchanged. Additionally, DIIR is plug-and-play and can\nbe applied to any diffusion-based portrait generation method. To validate the\neffectiveness of MagicID, we conducted extensive comparative and ablation\nexperiments. The experimental results demonstrate that MagicID has significant\nadvantages in both subjective and objective metrics, and achieves controllable\ngeneration in multi-person scenarios.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/"}