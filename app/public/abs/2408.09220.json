{"id":"2408.09220","title":"Flatten: Video Action Recognition is an Image Classification task","authors":"Junlin Chen, Chengcheng Xu, Yangfan Xu, Jian Yang, Jun Li, Zhiping Shi","authorsParsed":[["Chen","Junlin",""],["Xu","Chengcheng",""],["Xu","Yangfan",""],["Yang","Jian",""],["Li","Jun",""],["Shi","Zhiping",""]],"versions":[{"version":"v1","created":"Sat, 17 Aug 2024 14:59:58 GMT"}],"updateDate":"2024-08-20","timestamp":1723906798000,"abstract":"  In recent years, video action recognition, as a fundamental task in the field\nof video understanding, has been deeply explored by numerous researchers.Most\ntraditional video action recognition methods typically involve converting\nvideos into three-dimensional data that encapsulates both spatial and temporal\ninformation, subsequently leveraging prevalent image understanding models to\nmodel and analyze these data. However,these methods have significant drawbacks.\nFirstly, when delving into video action recognition tasks, image understanding\nmodels often need to be adapted accordingly in terms of model architecture and\npreprocessing for these spatiotemporal tasks; Secondly, dealing with\nhigh-dimensional data often poses greater challenges and incurs higher time\ncosts compared to its lower-dimensional counterparts.To bridge the gap between\nimage-understanding and video-understanding tasks while simplifying the\ncomplexity of video comprehension, we introduce a novel video representation\narchitecture, Flatten, which serves as a plug-and-play module that can be\nseamlessly integrated into any image-understanding network for efficient and\neffective 3D temporal data modeling.Specifically, by applying specific\nflattening operations (e.g., row-major transform), 3D spatiotemporal data is\ntransformed into 2D spatial information, and then ordinary image understanding\nmodels are used to capture temporal dynamic and spatial semantic information,\nwhich in turn accomplishes effective and efficient video action recognition.\nExtensive experiments on commonly used datasets (Kinetics-400,\nSomething-Something v2, and HMDB-51) and three classical image classification\nmodels (Uniformer, SwinV2, and ResNet), have demonstrated that embedding\nFlatten provides a significant performance improvements over original model.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/"}