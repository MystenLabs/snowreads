{"id":"2407.18902","title":"Lessons from Learning to Spin \"Pens\"","authors":"Jun Wang, Ying Yuan, Haichuan Che, Haozhi Qi, Yi Ma, Jitendra Malik,\n  Xiaolong Wang","authorsParsed":[["Wang","Jun",""],["Yuan","Ying",""],["Che","Haichuan",""],["Qi","Haozhi",""],["Ma","Yi",""],["Malik","Jitendra",""],["Wang","Xiaolong",""]],"versions":[{"version":"v1","created":"Fri, 26 Jul 2024 17:56:01 GMT"}],"updateDate":"2024-07-29","timestamp":1722016561000,"abstract":"  In-hand manipulation of pen-like objects is an important skill in our daily\nlives, as many tools such as hammers and screwdrivers are similarly shaped.\nHowever, current learning-based methods struggle with this task due to a lack\nof high-quality demonstrations and the significant gap between simulation and\nthe real world. In this work, we push the boundaries of learning-based in-hand\nmanipulation systems by demonstrating the capability to spin pen-like objects.\nWe first use reinforcement learning to train an oracle policy with privileged\ninformation and generate a high-fidelity trajectory dataset in simulation. This\nserves two purposes: 1) pre-training a sensorimotor policy in simulation; 2)\nconducting open-loop trajectory replay in the real world. We then fine-tune the\nsensorimotor policy using these real-world trajectories to adapt it to the real\nworld dynamics. With less than 50 trajectories, our policy learns to rotate\nmore than ten pen-like objects with different physical properties for multiple\nrevolutions. We present a comprehensive analysis of our design choices and\nshare the lessons learned during development.\n","subjects":["Computing Research Repository/Robotics","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}