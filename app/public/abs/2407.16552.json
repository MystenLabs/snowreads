{"id":"2407.16552","title":"MicroEmo: Time-Sensitive Multimodal Emotion Recognition with\n  Micro-Expression Dynamics in Video Dialogues","authors":"Liyun Zhang","authorsParsed":[["Zhang","Liyun",""]],"versions":[{"version":"v1","created":"Tue, 23 Jul 2024 15:05:55 GMT"},{"version":"v2","created":"Wed, 24 Jul 2024 01:09:36 GMT"}],"updateDate":"2024-07-25","timestamp":1721747155000,"abstract":"  Multimodal Large Language Models (MLLMs) have demonstrated remarkable\nmultimodal emotion recognition capabilities, integrating multimodal cues from\nvisual, acoustic, and linguistic contexts in the video to recognize human\nemotional states. However, existing methods ignore capturing local facial\nfeatures of temporal dynamics of micro-expressions and do not leverage the\ncontextual dependencies of the utterance-aware temporal segments in the video,\nthereby limiting their expected effectiveness to a certain extent. In this\nwork, we propose MicroEmo, a time-sensitive MLLM aimed at directing attention\nto the local facial micro-expression dynamics and the contextual dependencies\nof utterance-aware video clips. Our model incorporates two key architectural\ncontributions: (1) a global-local attention visual encoder that integrates\nglobal frame-level timestamp-bound image features with local facial features of\ntemporal dynamics of micro-expressions; (2) an utterance-aware video Q-Former\nthat captures multi-scale and contextual dependencies by generating visual\ntoken sequences for each utterance segment and for the entire video then\ncombining them. Preliminary qualitative experiments demonstrate that in a new\nExplainable Multimodal Emotion Recognition (EMER) task that exploits\nmulti-modal and multi-faceted clues to predict emotions in an open-vocabulary\n(OV) manner, MicroEmo demonstrates its effectiveness compared with the latest\nmethods.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Multimedia"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}