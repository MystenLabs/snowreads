{"id":"2408.11455","title":"Using Part-based Representations for Explainable Deep Reinforcement\n  Learning","authors":"Manos Kirtas, Konstantinos Tsampazis, Loukia Avramelou, Nikolaos\n  Passalis, Anastasios Tefas","authorsParsed":[["Kirtas","Manos",""],["Tsampazis","Konstantinos",""],["Avramelou","Loukia",""],["Passalis","Nikolaos",""],["Tefas","Anastasios",""]],"versions":[{"version":"v1","created":"Wed, 21 Aug 2024 09:21:59 GMT"},{"version":"v2","created":"Thu, 22 Aug 2024 05:46:23 GMT"}],"updateDate":"2024-08-23","timestamp":1724232119000,"abstract":"  Utilizing deep learning models to learn part-based representations holds\nsignificant potential for interpretable-by-design approaches, as these models\nincorporate latent causes obtained from feature representations through simple\naddition. However, training a part-based learning model presents challenges,\nparticularly in enforcing non-negative constraints on the model's parameters,\nwhich can result in training difficulties such as instability and convergence\nissues. Moreover, applying such approaches in Deep Reinforcement Learning (RL)\nis even more demanding due to the inherent instabilities that impact many\noptimization methods. In this paper, we propose a non-negative training\napproach for actor models in RL, enabling the extraction of part-based\nrepresentations that enhance interpretability while adhering to non-negative\nconstraints. To this end, we employ a non-negative initialization technique, as\nwell as a modified sign-preserving training method, which can ensure better\ngradient flow compared to existing approaches. We demonstrate the effectiveness\nof the proposed approach using the well-known Cartpole benchmark.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}