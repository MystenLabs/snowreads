{"id":"2408.12109","title":"RoVRM: A Robust Visual Reward Model Optimized via Auxiliary Textual\n  Preference Data","authors":"Chenglong Wang, Yang Gan, Yifu Huo, Yongyu Mu, Murun Yang, Qiaozhi He,\n  Tong Xiao, Chunliang Zhang, Tongran Liu, Quan Du, Di Yang and Jingbo Zhu","authorsParsed":[["Wang","Chenglong",""],["Gan","Yang",""],["Huo","Yifu",""],["Mu","Yongyu",""],["Yang","Murun",""],["He","Qiaozhi",""],["Xiao","Tong",""],["Zhang","Chunliang",""],["Liu","Tongran",""],["Du","Quan",""],["Yang","Di",""],["Zhu","Jingbo",""]],"versions":[{"version":"v1","created":"Thu, 22 Aug 2024 03:49:18 GMT"}],"updateDate":"2024-08-23","timestamp":1724298558000,"abstract":"  Large vision-language models (LVLMs) often fail to align with human\npreferences, leading to issues like generating misleading content without\nproper visual context (also known as hallucination). A promising solution to\nthis problem is using human-preference alignment techniques, such as best-of-n\nsampling and reinforcement learning. However, these techniques face the\ndifficulty arising from the scarcity of visual preference data, which is\nrequired to train a visual reward model (VRM). In this work, we continue the\nline of research. We present a Robust Visual Reward Model (RoVRM) which\nimproves human-preference alignment for LVLMs. RoVRM leverages auxiliary\ntextual preference data through a three-phase progressive training and optimal\ntransport-based preference data selection to effectively mitigate the scarcity\nof visual preference data. We experiment with RoVRM on the commonly used\nvision-language tasks based on the LLaVA-1.5-7B and -13B models. Experimental\nresults demonstrate that RoVRM consistently outperforms traditional VRMs.\nFurthermore, our three-phase progressive training and preference data selection\napproaches can yield consistent performance gains over ranking-based alignment\ntechniques, such as direct preference optimization.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}