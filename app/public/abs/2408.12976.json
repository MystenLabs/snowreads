{"id":"2408.12976","title":"Optimal OnTheFly Feedback Control of Event Sensors","authors":"Valery Vishnevskiy, Greg Burman, Sebastian Kozerke, Diederik Paul\n  Moeys","authorsParsed":[["Vishnevskiy","Valery",""],["Burman","Greg",""],["Kozerke","Sebastian",""],["Moeys","Diederik Paul",""]],"versions":[{"version":"v1","created":"Fri, 23 Aug 2024 10:49:16 GMT"}],"updateDate":"2024-08-26","timestamp":1724410156000,"abstract":"  Event-based vision sensors produce an asynchronous stream of events which are\ntriggered when the pixel intensity variation exceeds a predefined threshold.\nSuch sensors offer significant advantages, including reduced data redundancy,\nmicro-second temporal resolution, and low power consumption, making them\nvaluable for applications in robotics and computer vision. In this work, we\nconsider the problem of video reconstruction from events, and propose an\napproach for dynamic feedback control of activation thresholds, in which a\ncontroller network analyzes the past emitted events and predicts the optimal\ndistribution of activation thresholds for the following time segment.\nAdditionally, we allow a user-defined target peak-event-rate for which the\ncontrol network is conditioned and optimized to predict per-column activation\nthresholds that would eventually produce the best possible video\nreconstruction. The proposed OnTheFly control scheme is data-driven and trained\nin an end-to-end fashion using probabilistic relaxation of the discrete event\nrepresentation. We demonstrate that our approach outperforms both fixed and\nrandomly-varying threshold schemes by 6-12% in terms of LPIPS perceptual image\ndissimilarity metric, and by 49% in terms of event rate, achieving superior\nreconstruction quality while enabling a fine-tuned balance between performance\naccuracy and the event rate. Additionally, we show that sampling strategies\nprovided by our OnTheFly control are interpretable and reflect the\ncharacteristics of the scene. Our results, derived from a physically-accurate\nsimulator, underline the promise of the proposed methodology in enhancing the\nutility of event cameras for image reconstruction and other downstream tasks,\npaving the way for hardware implementation of dynamic feedback EVS control in\nsilicon.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}