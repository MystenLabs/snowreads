{"id":"2408.14805","title":"Platypus: A Generalized Specialist Model for Reading Text in Various\n  Forms","authors":"Peng Wang, Zhaohai Li, Jun Tang, Humen Zhong, Fei Huang, Zhibo Yang,\n  Cong Yao","authorsParsed":[["Wang","Peng",""],["Li","Zhaohai",""],["Tang","Jun",""],["Zhong","Humen",""],["Huang","Fei",""],["Yang","Zhibo",""],["Yao","Cong",""]],"versions":[{"version":"v1","created":"Tue, 27 Aug 2024 06:24:51 GMT"}],"updateDate":"2024-08-28","timestamp":1724739891000,"abstract":"  Reading text from images (either natural scenes or documents) has been a\nlong-standing research topic for decades, due to the high technical challenge\nand wide application range. Previously, individual specialist models are\ndeveloped to tackle the sub-tasks of text reading (e.g., scene text\nrecognition, handwritten text recognition and mathematical expression\nrecognition). However, such specialist models usually cannot effectively\ngeneralize across different sub-tasks. Recently, generalist models (such as\nGPT-4V), trained on tremendous data in a unified way, have shown enormous\npotential in reading text in various scenarios, but with the drawbacks of\nlimited accuracy and low efficiency. In this work, we propose Platypus, a\ngeneralized specialist model for text reading. Specifically, Platypus combines\nthe best of both worlds: being able to recognize text of various forms with a\nsingle unified architecture, while achieving excellent accuracy and high\nefficiency. To better exploit the advantage of Platypus, we also construct a\ntext reading dataset (called Worms), the images of which are curated from\nprevious datasets and partially re-labeled. Experiments on standard benchmarks\ndemonstrate the effectiveness and superiority of the proposed Platypus model.\nModel and data will be made publicly available at\nhttps://github.com/AlibabaResearch/AdvancedLiterateMachinery/tree/main/OCR/Platypus.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/"}