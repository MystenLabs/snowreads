{"id":"2407.01942","title":"Certainly Uncertain: A Benchmark and Metric for Multimodal Epistemic and\n  Aleatoric Awareness","authors":"Khyathi Raghavi Chandu, Linjie Li, Anas Awadalla, Ximing Lu, Jae Sung\n  Park, Jack Hessel, Lijuan Wang, Yejin Choi","authorsParsed":[["Chandu","Khyathi Raghavi",""],["Li","Linjie",""],["Awadalla","Anas",""],["Lu","Ximing",""],["Park","Jae Sung",""],["Hessel","Jack",""],["Wang","Lijuan",""],["Choi","Yejin",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 04:23:54 GMT"}],"updateDate":"2024-07-03","timestamp":1719894234000,"abstract":"  The ability to acknowledge the inevitable uncertainty in their knowledge and\nreasoning is a prerequisite for AI systems to be truly truthful and reliable.\nIn this paper, we present a taxonomy of uncertainty specific to vision-language\nAI systems, distinguishing between epistemic uncertainty (arising from a lack\nof information) and aleatoric uncertainty (due to inherent unpredictability),\nand further explore finer categories within. Based on this taxonomy, we\nsynthesize a benchmark dataset, CertainlyUncertain, featuring 178K visual\nquestion answering (VQA) samples as contrastive pairs. This is achieved by 1)\ninpainting images to make previously answerable questions into unanswerable\nones; and 2) using image captions to prompt large language models for both\nanswerable and unanswerable questions. Additionally, we introduce a new metric\nconfidence-weighted accuracy, that is well correlated with both accuracy and\ncalibration error, to address the shortcomings of existing metrics.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}