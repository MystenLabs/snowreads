{"id":"2407.12425","title":"Navigating the Noisy Crowd: Finding Key Information for Claim\n  Verification","authors":"Haisong Gong, Huanhuan Ma, Qiang Liu, Shu Wu, Liang Wang","authorsParsed":[["Gong","Haisong",""],["Ma","Huanhuan",""],["Liu","Qiang",""],["Wu","Shu",""],["Wang","Liang",""]],"versions":[{"version":"v1","created":"Wed, 17 Jul 2024 09:24:10 GMT"}],"updateDate":"2024-07-18","timestamp":1721208250000,"abstract":"  Claim verification is a task that involves assessing the truthfulness of a\ngiven claim based on multiple evidence pieces. Using large language models\n(LLMs) for claim verification is a promising way. However, simply feeding all\nthe evidence pieces to an LLM and asking if the claim is factual does not yield\ngood results. The challenge lies in the noisy nature of both the evidence and\nthe claim: evidence passages typically contain irrelevant information, with the\nkey facts hidden within the context, while claims often convey multiple aspects\nsimultaneously. To navigate this \"noisy crowd\" of information, we propose EACon\n(Evidence Abstraction and Claim Deconstruction), a framework designed to find\nkey information within evidence and verify each aspect of a claim separately.\nEACon first finds keywords from the claim and employs fuzzy matching to select\nrelevant keywords for each raw evidence piece. These keywords serve as a guide\nto extract and summarize critical information into abstracted evidence.\nSubsequently, EACon deconstructs the original claim into subclaims, which are\nthen verified against both abstracted and raw evidence individually. We\nevaluate EACon using two open-source LLMs on two challenging datasets. Results\ndemonstrate that EACon consistently and substantially improve LLMs' performance\nin claim verification.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}