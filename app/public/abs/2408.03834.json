{"id":"2408.03834","title":"Target Prompting for Information Extraction with Vision Language Model","authors":"Dipankar Medhi","authorsParsed":[["Medhi","Dipankar",""]],"versions":[{"version":"v1","created":"Wed, 7 Aug 2024 15:17:51 GMT"}],"updateDate":"2024-08-08","timestamp":1723043871000,"abstract":"  The recent trend in the Large Vision and Language model has brought a new\nchange in how information extraction systems are built. VLMs have set a new\nbenchmark with their State-of-the-art techniques in understanding documents and\nbuilding question-answering systems across various industries. They are\nsignificantly better at generating text from document images and providing\naccurate answers to questions. However, there are still some challenges in\neffectively utilizing these models to build a precise conversational system.\nGeneral prompting techniques used with large language models are often not\nsuitable for these specially designed vision language models. The output\ngenerated by such generic input prompts is ordinary and may contain information\ngaps when compared with the actual content of the document. To obtain more\naccurate and specific answers, a well-targeted prompt is required by the vision\nlanguage model, along with the document image. In this paper, a technique is\ndiscussed called Target prompting, which focuses on explicitly targeting parts\nof document images and generating related answers from those specific regions\nonly. The paper also covers the evaluation of response for each prompting\ntechnique using different user queries and input prompts.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/"}