{"id":"2407.01784","title":"Analyzing Persuasive Strategies in Meme Texts: A Fusion of Language\n  Models with Paraphrase Enrichment","authors":"Kota Shamanth Ramanath Nayak and Leila Kosseim","authorsParsed":[["Nayak","Kota Shamanth Ramanath",""],["Kosseim","Leila",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 20:25:20 GMT"}],"updateDate":"2024-07-04","timestamp":1719865520000,"abstract":"  This paper describes our approach to hierarchical multi-label detection of\npersuasion techniques in meme texts. Our model, developed as a part of the\nrecent SemEval task, is based on fine-tuning individual language models (BERT,\nXLM-RoBERTa, and mBERT) and leveraging a mean-based ensemble model in addition\nto dataset augmentation through paraphrase generation from ChatGPT. The scope\nof the study encompasses enhancing model performance through innovative\ntraining techniques and data augmentation strategies. The problem addressed is\nthe effective identification and classification of multiple persuasive\ntechniques in meme texts, a task complicated by the diversity and complexity of\nsuch content. The objective of the paper is to improve detection accuracy by\nrefining model training methods and examining the impact of balanced versus\nunbalanced training datasets. Novelty in the results and discussion lies in the\nfinding that training with paraphrases enhances model performance, yet a\nbalanced training set proves more advantageous than a larger unbalanced one.\nAdditionally, the analysis reveals the potential pitfalls of indiscriminate\nincorporation of paraphrases from diverse distributions, which can introduce\nsubstantial noise. Results with the SemEval 2024 data confirm these insights,\ndemonstrating improved model efficacy with the proposed methods.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"p5CDy30TfjbqYlBM1qSBwmkLiugapEJY0PUZro0pgVs","pdfSize":"908814"}
