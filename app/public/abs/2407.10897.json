{"id":"2407.10897","title":"Optical Diffusion Models for Image Generation","authors":"Ilker Oguz, Niyazi Ulas Dinc, Mustafa Yildirim, Junjie Ke, Innfarn\n  Yoo, Qifei Wang, Feng Yang, Christophe Moser, Demetri Psaltis","authorsParsed":[["Oguz","Ilker",""],["Dinc","Niyazi Ulas",""],["Yildirim","Mustafa",""],["Ke","Junjie",""],["Yoo","Innfarn",""],["Wang","Qifei",""],["Yang","Feng",""],["Moser","Christophe",""],["Psaltis","Demetri",""]],"versions":[{"version":"v1","created":"Mon, 15 Jul 2024 16:46:14 GMT"}],"updateDate":"2024-07-16","timestamp":1721061974000,"abstract":"  Diffusion models generate new samples by progressively decreasing the noise\nfrom the initially provided random distribution. This inference procedure\ngenerally utilizes a trained neural network numerous times to obtain the final\noutput, creating significant latency and energy consumption on digital\nelectronic hardware such as GPUs. In this study, we demonstrate that the\npropagation of a light beam through a semi-transparent medium can be programmed\nto implement a denoising diffusion model on image samples. This framework\nprojects noisy image patterns through passive diffractive optical layers, which\ncollectively only transmit the predicted noise term in the image. The optical\ntransparent layers, which are trained with an online training approach,\nbackpropagating the error to the analytical model of the system, are passive\nand kept the same across different steps of denoising. Hence this method\nenables high-speed image generation with minimal power consumption, benefiting\nfrom the bandwidth and energy efficiency of optical information processing.\n","subjects":["Physics/Optics","Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}