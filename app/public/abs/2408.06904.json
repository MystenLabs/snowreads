{"id":"2408.06904","title":"Re-TASK: Revisiting LLM Tasks from Capability, Skill, and Knowledge\n  Perspectives","authors":"Zhihu Wang, Shiwan Zhao, Yu Wang, Heyuan Huang, Jiaxin Shi, Sitao Xie,\n  Zhixing Wang, Yubo Zhang, Hongyan Li, Junchi Yan","authorsParsed":[["Wang","Zhihu",""],["Zhao","Shiwan",""],["Wang","Yu",""],["Huang","Heyuan",""],["Shi","Jiaxin",""],["Xie","Sitao",""],["Wang","Zhixing",""],["Zhang","Yubo",""],["Li","Hongyan",""],["Yan","Junchi",""]],"versions":[{"version":"v1","created":"Tue, 13 Aug 2024 13:58:23 GMT"}],"updateDate":"2024-08-14","timestamp":1723557503000,"abstract":"  As large language models (LLMs) continue to scale, their enhanced performance\noften proves insufficient for solving domain-specific tasks. Systematically\nanalyzing their failures and effectively enhancing their performance remain\nsignificant challenges. This paper introduces the Re-TASK framework, a novel\ntheoretical model that Revisits LLM Tasks from cApability, Skill, Knowledge\nperspectives, guided by the principles of Bloom's Taxonomy and Knowledge Space\nTheory. The Re-TASK framework provides a systematic methodology to deepen our\nunderstanding, evaluation, and enhancement of LLMs for domain-specific tasks.\nIt explores the interplay among an LLM's capabilities, the knowledge it\nprocesses, and the skills it applies, elucidating how these elements are\ninterconnected and impact task performance. Our application of the Re-TASK\nframework reveals that many failures in domain-specific tasks can be attributed\nto insufficient knowledge or inadequate skill adaptation. With this insight, we\npropose structured strategies for enhancing LLMs through targeted knowledge\ninjection and skill adaptation. Specifically, we identify key capability items\nassociated with tasks and employ a deliberately designed prompting strategy to\nenhance task performance, thereby reducing the need for extensive fine-tuning.\nAlternatively, we fine-tune the LLM using capability-specific instructions,\nfurther validating the efficacy of our framework. Experimental results confirm\nthe framework's effectiveness, demonstrating substantial improvements in both\nthe performance and applicability of LLMs.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}