{"id":"2408.15480","title":"Feelit: Combining Compliant Shape Displays with Vision-Based Tactile\n  Sensors for Real-Time Teletaction","authors":"Oscar Yu, Yu She","authorsParsed":[["Yu","Oscar",""],["She","Yu",""]],"versions":[{"version":"v1","created":"Wed, 28 Aug 2024 02:00:40 GMT"}],"updateDate":"2024-08-29","timestamp":1724810440000,"abstract":"  Teletaction, the transmission of tactile feedback or touch, is a crucial\naspect in the field of teleoperation. High-quality teletaction feedback allows\nusers to remotely manipulate objects and increase the quality of the\nhuman-machine interface between the operator and the robot, making complex\nmanipulation tasks possible. Advances in the field of teletaction for\nteleoperation however, have yet to make full use of the high-resolution 3D data\nprovided by modern vision-based tactile sensors. Existing solutions for\nteletaction lack in one or more areas of form or function, such as fidelity or\nhardware footprint. In this paper, we showcase our design for a low-cost\nteletaction device that can utilize real-time high-resolution tactile\ninformation from vision-based tactile sensors, through both physical 3D surface\nreconstruction and shear displacement. We present our device, the Feelit, which\nuses a combination of a pin-based shape display and compliant mechanisms to\naccomplish this task. The pin-based shape display utilizes an array of 24\nservomotors with miniature Bowden cables, giving the device a resolution of 6x4\npins in a 15x10 mm display footprint. Each pin can actuate up to 3 mm in 200\nms, while providing 80 N of force and 1.5 um of depth resolution. Shear\ndisplacement and rotation is achieved using a compliant mechanism design,\nallowing a minimum of 1 mm displacement laterally and 10 degrees of rotation.\nThis real-time 3D tactile reconstruction is achieved with the use of a\nvision-based tactile sensor, the GelSight [1], along with an algorithm that\nsamples the depth data and marker tracking to generate actuator commands.\nThrough a series of experiments including shape recognition and relative weight\nidentification, we show that our device has the potential to expand teletaction\ncapabilities in the teleoperation space.\n","subjects":["Computing Research Repository/Robotics"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}