{"id":"2407.12492","title":"Test-Time Adaptation with State-Space Models","authors":"Mona Schirmer, Dan Zhang, Eric Nalisnick","authorsParsed":[["Schirmer","Mona",""],["Zhang","Dan",""],["Nalisnick","Eric",""]],"versions":[{"version":"v1","created":"Wed, 17 Jul 2024 11:18:49 GMT"}],"updateDate":"2024-07-18","timestamp":1721215129000,"abstract":"  Distribution shifts between training and test data are all but inevitable\nover the lifecycle of a deployed model and lead to performance decay. Adapting\nthe model can hopefully mitigate this drop in performance. Yet, adaptation is\nchallenging since it must be unsupervised: we usually do not have access to any\nlabeled data at test time. In this paper, we propose a probabilistic\nstate-space model that can adapt a deployed model subjected to distribution\ndrift. Our model learns the dynamics induced by distribution shifts on the last\nset of hidden features. Without requiring labels, we infer time-evolving class\nprototypes that serve as a dynamic classification head. Moreover, our approach\nis lightweight, modifying only the model's last linear layer. In experiments on\nreal-world distribution shifts and synthetic corruptions, we demonstrate that\nour approach performs competitively with methods that require back-propagation\nand access to the model backbone. Our model especially excels in the case of\nsmall test batches - the most difficult setting.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computer Vision and Pattern Recognition","Statistics/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}