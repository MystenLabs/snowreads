{"id":"2408.09530","title":"PA-LLaVA: A Large Language-Vision Assistant for Human Pathology Image\n  Understanding","authors":"Dawei Dai, Yuanhui Zhang, Long Xu, Qianlan Yang, Xiaojing Shen, Shuyin\n  Xia, and Guoyin Wang","authorsParsed":[["Dai","Dawei",""],["Zhang","Yuanhui",""],["Xu","Long",""],["Yang","Qianlan",""],["Shen","Xiaojing",""],["Xia","Shuyin",""],["Wang","Guoyin",""]],"versions":[{"version":"v1","created":"Sun, 18 Aug 2024 16:30:32 GMT"}],"updateDate":"2024-08-20","timestamp":1723998632000,"abstract":"  The previous advancements in pathology image understanding primarily involved\ndeveloping models tailored to specific tasks. Recent studies has demonstrated\nthat the large vision-language model can enhance the performance of various\ndownstream tasks in medical image understanding. In this study, we developed a\ndomain-specific large language-vision assistant (PA-LLaVA) for pathology image\nunderstanding. Specifically, (1) we first construct a human pathology\nimage-text dataset by cleaning the public medical image-text data for\ndomain-specific alignment; (2) Using the proposed image-text data, we first\ntrain a pathology language-image pretraining (PLIP) model as the specialized\nvisual encoder for pathology image, and then we developed scale-invariant\nconnector to avoid the information loss caused by image scaling; (3) We adopt\ntwo-stage learning to train PA-LLaVA, first stage for domain alignment, and\nsecond stage for end to end visual question \\& answering (VQA) task. In\nexperiments, we evaluate our PA-LLaVA on both supervised and zero-shot VQA\ndatasets, our model achieved the best overall performance among multimodal\nmodels of similar scale. The ablation experiments also confirmed the\neffectiveness of our design. We posit that our PA-LLaVA model and the datasets\npresented in this work can promote research in field of computational\npathology. All codes are available at:\nhttps://github.com/ddw2AIGROUP2CQUPT/PA-LLaVA}{https://github.com/ddw2AIGROUP2CQUPT/PA-LLaVA\n","subjects":["Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}