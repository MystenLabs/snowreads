{"id":"2407.02762","title":"SF-GNN: Self Filter for Message Lossless Propagation in Deep Graph\n  Neural Network","authors":"Yushan Zhu, Wen Zhang, Yajing Xu, Zhen Yao, Mingyang Chen, Huajun Chen","authorsParsed":[["Zhu","Yushan",""],["Zhang","Wen",""],["Xu","Yajing",""],["Yao","Zhen",""],["Chen","Mingyang",""],["Chen","Huajun",""]],"versions":[{"version":"v1","created":"Wed, 3 Jul 2024 02:40:39 GMT"}],"updateDate":"2024-07-04","timestamp":1719974439000,"abstract":"  Graph Neural Network (GNN), with the main idea of encoding graph structure\ninformation of graphs by propagation and aggregation, has developed rapidly. It\nachieved excellent performance in representation learning of multiple types of\ngraphs such as homogeneous graphs, heterogeneous graphs, and more complex\ngraphs like knowledge graphs. However, merely stacking GNN layers may not\nimprove the model's performance and can even be detrimental. For the phenomenon\nof performance degradation in deep GNNs, we propose a new perspective. Unlike\nthe popular explanations of over-smoothing or over-squashing, we think the\nissue arises from the interference of low-quality node representations during\nmessage propagation. We introduce a simple and general method, SF-GNN, to\naddress this problem. In SF-GNN, we define two representations for each node,\none is the node representation that represents the feature of the node itself,\nand the other is the message representation specifically for propagating\nmessages to neighbor nodes. A self-filter module evaluates the quality of the\nnode representation and decides whether to integrate it into the message\npropagation based on this quality assessment. Experiments on node\nclassification tasks for both homogeneous and heterogeneous graphs, as well as\nlink prediction tasks on knowledge graphs, demonstrate that our method can be\napplied to various GNN models and outperforms state-of-the-art baseline methods\nin addressing deep GNN degradation.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}