{"id":"2408.11054","title":"NeCo: Improving DINOv2's spatial representations in 19 GPU hours with\n  Patch Neighbor Consistency","authors":"Valentinos Pariza, Mohammadreza Salehi, Gertjan Burghouts, Francesco\n  Locatello, Yuki M. Asano","authorsParsed":[["Pariza","Valentinos",""],["Salehi","Mohammadreza",""],["Burghouts","Gertjan",""],["Locatello","Francesco",""],["Asano","Yuki M.",""]],"versions":[{"version":"v1","created":"Tue, 20 Aug 2024 17:58:59 GMT"}],"updateDate":"2024-08-21","timestamp":1724176739000,"abstract":"  We propose sorting patch representations across views as a novel\nself-supervised learning signal to improve pretrained representations. To this\nend, we introduce NeCo: Patch Neighbor Consistency, a novel training loss that\nenforces patch-level nearest neighbor consistency across a student and teacher\nmodel, relative to reference batches. Our method leverages a differentiable\nsorting method applied on top of pretrained representations, such as\nDINOv2-registers to bootstrap the learning signal and further improve upon\nthem. This dense post-pretraining leads to superior performance across various\nmodels and datasets, despite requiring only 19 hours on a single GPU. We\ndemonstrate that this method generates high-quality dense feature encoders and\nestablish several new state-of-the-art results: +5.5% and + 6% for\nnon-parametric in-context semantic segmentation on ADE20k and Pascal VOC, and\n+7.2% and +5.7% for linear segmentation evaluations on COCO-Things and -Stuff.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}