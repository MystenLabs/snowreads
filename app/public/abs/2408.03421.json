{"id":"2408.03421","title":"Probabilistic Scores of Classifiers, Calibration is not Enough","authors":"Agathe Fernandes Machado, Arthur Charpentier, Emmanuel Flachaire, Ewen\n  Gallic, Fran\\c{c}ois Hu","authorsParsed":[["Machado","Agathe Fernandes",""],["Charpentier","Arthur",""],["Flachaire","Emmanuel",""],["Gallic","Ewen",""],["Hu","Fran√ßois",""]],"versions":[{"version":"v1","created":"Tue, 6 Aug 2024 19:53:00 GMT"}],"updateDate":"2024-08-08","timestamp":1722973980000,"abstract":"  In binary classification tasks, accurate representation of probabilistic\npredictions is essential for various real-world applications such as predicting\npayment defaults or assessing medical risks. The model must then be\nwell-calibrated to ensure alignment between predicted probabilities and actual\noutcomes. However, when score heterogeneity deviates from the underlying data\nprobability distribution, traditional calibration metrics lose reliability,\nfailing to align score distribution with actual probabilities. In this study,\nwe highlight approaches that prioritize optimizing the alignment between\npredicted scores and true probability distributions over minimizing traditional\nperformance or calibration metrics. When employing tree-based models such as\nRandom Forest and XGBoost, our analysis emphasizes the flexibility these models\noffer in tuning hyperparameters to minimize the Kullback-Leibler (KL)\ndivergence between predicted and true distributions. Through extensive\nempirical analysis across 10 UCI datasets and simulations, we demonstrate that\noptimizing tree-based models based on KL divergence yields superior alignment\nbetween predicted scores and actual probabilities without significant\nperformance loss. In real-world scenarios, the reference probability is\ndetermined a priori as a Beta distribution estimated through maximum\nlikelihood. Conversely, minimizing traditional calibration metrics may lead to\nsuboptimal results, characterized by notable performance declines and inferior\nKL values. Our findings reveal limitations in traditional calibration metrics,\nwhich could undermine the reliability of predictive models for critical\ndecision-making.\n","subjects":["Computing Research Repository/Machine Learning","Statistics/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}