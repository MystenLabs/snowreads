{"id":"2407.10550","title":"Learning Natural Consistency Representation for Face Forgery Video\n  Detection","authors":"Daichi Zhang, Zihao Xiao, Shikun Li, Fanzhao Lin, Jianmin Li, and\n  Shiming Ge","authorsParsed":[["Zhang","Daichi",""],["Xiao","Zihao",""],["Li","Shikun",""],["Lin","Fanzhao",""],["Li","Jianmin",""],["Ge","Shiming",""]],"versions":[{"version":"v1","created":"Mon, 15 Jul 2024 09:00:02 GMT"}],"updateDate":"2024-07-16","timestamp":1721034002000,"abstract":"  Face Forgery videos have elicited critical social public concerns and various\ndetectors have been proposed. However, fully-supervised detectors may lead to\neasily overfitting to specific forgery methods or videos, and existing\nself-supervised detectors are strict on auxiliary tasks, such as requiring\naudio or multi-modalities, leading to limited generalization and robustness. In\nthis paper, we examine whether we can address this issue by leveraging\nvisual-only real face videos. To this end, we propose to learn the Natural\nConsistency representation (NACO) of real face videos in a self-supervised\nmanner, which is inspired by the observation that fake videos struggle to\nmaintain the natural spatiotemporal consistency even under unknown forgery\nmethods and different perturbations. Our NACO first extracts spatial features\nof each frame by CNNs then integrates them into Transformer to learn the\nlong-range spatiotemporal representation, leveraging the advantages of CNNs and\nTransformer on local spatial receptive field and long-term memory respectively.\nFurthermore, a Spatial Predictive Module~(SPM) and a Temporal Contrastive\nModule~(TCM) are introduced to enhance the natural consistency representation\nlearning. The SPM aims to predict random masked spatial features from\nspatiotemporal representation, and the TCM regularizes the latent distance of\nspatiotemporal representation by shuffling the natural order to disturb the\nconsistency, which could both force our NACO more sensitive to the natural\nspatiotemporal consistency. After the representation learning stage, a MLP head\nis fine-tuned to perform the usual forgery video classification task. Extensive\nexperiments show that our method outperforms other state-of-the-art competitors\nwith impressive generalization and robustness.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}