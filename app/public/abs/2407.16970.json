{"id":"2407.16970","title":"Towards Aligning Language Models with Textual Feedback","authors":"Sa\\\"uc Abadal Lloret, Shehzaad Dhuliawala, Keerthiram Murugesan,\n  Mrinmaya Sachan","authorsParsed":[["Lloret","Sa√ºc Abadal",""],["Dhuliawala","Shehzaad",""],["Murugesan","Keerthiram",""],["Sachan","Mrinmaya",""]],"versions":[{"version":"v1","created":"Wed, 24 Jul 2024 03:32:05 GMT"}],"updateDate":"2024-07-25","timestamp":1721791925000,"abstract":"  We present ALT (ALignment with Textual feedback), an approach that aligns\nlanguage models with user preferences expressed in text. We argue that text\noffers greater expressiveness, enabling users to provide richer feedback than\nsimple comparative preferences and this richer feedback can lead to more\nefficient and effective alignment. ALT aligns the model by conditioning its\ngeneration on the textual feedback. Our method relies solely on language\nmodeling techniques and requires minimal hyper-parameter tuning, though it\nstill presents the main benefits of RL-based alignment algorithms and can\neffectively learn from textual feedback. We explore the efficacy and efficiency\nof textual feedback across different tasks such as toxicity reduction,\nsummarization, and dialog response generation. We find that ALT outperforms PPO\nfor the task of toxicity reduction while being able to match its performance on\nsummarization with only 20% of the samples. We also explore how ALT can be used\nwith feedback provided by an existing LLM where we explore an LLM providing\nconstrained and unconstrained textual feedback. We also outline future\ndirections to align models with natural language feedback.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"nmbL2UY59uVh07oUWGJ8hq6RSLGZ7eOEAue-npWgfxk","pdfSize":"1370669","objectId":"0xf139ce5edeca7a7214649b39ca4a60f21cb1d059f1428908e516fe3ee0936ced","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
