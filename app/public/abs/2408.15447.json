{"id":"2408.15447","title":"Fine-grained length controllable video captioning with ordinal\n  embeddings","authors":"Tomoya Nitta, Takumi Fukuzawa, Toru Tamaki","authorsParsed":[["Nitta","Tomoya",""],["Fukuzawa","Takumi",""],["Tamaki","Toru",""]],"versions":[{"version":"v1","created":"Tue, 27 Aug 2024 23:53:52 GMT"}],"updateDate":"2024-08-29","timestamp":1724802832000,"abstract":"  This paper proposes a method for video captioning that controls the length of\ngenerated captions. Previous work on length control often had few levels for\nexpressing length. In this study, we propose two methods of length embedding\nfor fine-grained length control. A traditional embedding method is linear,\nusing a one-hot vector and an embedding matrix. In this study, we propose\nmethods that represent length in multi-hot vectors. One is bit embedding that\nexpresses length in bit representation, and the other is ordinal embedding that\nuses the binary representation often used in ordinal regression. These length\nrepresentations of multi-hot vectors are converted into length embedding by a\nnonlinear MLP. This method allows for not only the length control of caption\nsentences but also the control of the time when reading the caption.\nExperiments using ActivityNet Captions and Spoken Moments in Time show that the\nproposed method effectively controls the length of the generated captions.\nAnalysis of the embedding vectors with ICA shows that length and semantics were\nlearned separately, demonstrating the effectiveness of the proposed embedding\nmethods.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}