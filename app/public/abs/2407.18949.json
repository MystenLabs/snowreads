{"id":"2407.18949","title":"Predicting Winning Captions for Weekly New Yorker Comics","authors":"Stanley Cao, Sonny Young","authorsParsed":[["Cao","Stanley",""],["Young","Sonny",""]],"versions":[{"version":"v1","created":"Fri, 12 Jul 2024 00:45:00 GMT"}],"updateDate":"2024-07-30","timestamp":1720745100000,"abstract":"  Image captioning using Vision Transformers (ViTs) represents a pivotal\nconvergence of computer vision and natural language processing, offering the\npotential to enhance user experiences, improve accessibility, and provide\ntextual representations of visual data. This paper explores the application of\nimage captioning techniques to New Yorker cartoons, aiming to generate captions\nthat emulate the wit and humor of winning entries in the New Yorker Cartoon\nCaption Contest. This task necessitates sophisticated visual and linguistic\nprocessing, along with an understanding of cultural nuances and humor. We\npropose several new baselines for using vision transformer encoder-decoder\nmodels to generate captions for the New Yorker cartoon caption contest.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/"}