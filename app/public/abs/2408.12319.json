{"id":"2408.12319","title":"Neural-ANOVA: Model Decomposition for Interpretable Machine Learning","authors":"Steffen Limmer, Steffen Udluft, Clemens Otte","authorsParsed":[["Limmer","Steffen",""],["Udluft","Steffen",""],["Otte","Clemens",""]],"versions":[{"version":"v1","created":"Thu, 22 Aug 2024 11:55:43 GMT"}],"updateDate":"2024-08-23","timestamp":1724327743000,"abstract":"  The analysis of variance (ANOVA) decomposition offers a systematic method to\nunderstand the interaction effects that contribute to a specific decision\noutput. In this paper we introduce Neural-ANOVA, an approach to decompose\nneural networks into glassbox models using the ANOVA decomposition. Our\napproach formulates a learning problem, which enables rapid and closed-form\nevaluation of integrals over subspaces that appear in the calculation of the\nANOVA decomposition. Finally, we conduct numerical experiments to illustrate\nthe advantages of enhanced interpretability and model validation by a\ndecomposition of the learned interaction effects.\n","subjects":["Statistics/Machine Learning","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}