{"id":"2407.06653","title":"Toward Motion Robustness: A masked attention regularization framework in\n  remote photoplethysmography","authors":"Pengfei Zhao, Qigong Sun, Xiaolin Tian, Yige Yang, Shuo Tao, Jie\n  Cheng, Jiantong Chen","authorsParsed":[["Zhao","Pengfei",""],["Sun","Qigong",""],["Tian","Xiaolin",""],["Yang","Yige",""],["Tao","Shuo",""],["Cheng","Jie",""],["Chen","Jiantong",""]],"versions":[{"version":"v1","created":"Tue, 9 Jul 2024 08:25:30 GMT"}],"updateDate":"2024-07-10","timestamp":1720513530000,"abstract":"  There has been growing interest in facial video-based remote\nphotoplethysmography (rPPG) measurement recently, with a focus on assessing\nvarious vital signs such as heart rate and heart rate variability. Despite\nprevious efforts on static datasets, their approaches have been hindered by\ninaccurate region of interest (ROI) localization and motion issues, and have\nshown limited generalization in real-world scenarios. To address these\nchallenges, we propose a novel masked attention regularization (MAR-rPPG)\nframework that mitigates the impact of ROI localization and complex motion\nartifacts. Specifically, our approach first integrates a masked attention\nregularization mechanism into the rPPG field to capture the visual semantic\nconsistency of facial clips, while it also employs a masking technique to\nprevent the model from overfitting on inaccurate ROIs and subsequently\ndegrading its performance. Furthermore, we propose an enhanced rPPG expert\naggregation (EREA) network as the backbone to obtain rPPG signals and attention\nmaps simultaneously. Our EREA network is capable of discriminating divergent\nattentions from different facial areas and retaining the consistency of\nspatiotemporal attention maps. For motion robustness, a simple open source\ndetector MediaPipe for data preprocessing is sufficient for our framework due\nto its superior capability of rPPG signal extraction and attention\nregularization. Exhaustive experiments on three benchmark datasets (UBFC-rPPG,\nPURE, and MMPD) substantiate the superiority of our proposed method,\noutperforming recent state-of-the-art works by a considerable margin.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}