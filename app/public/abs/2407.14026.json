{"id":"2407.14026","title":"Semi-supervised reference-based sketch extraction using a contrastive\n  learning framework","authors":"Chang Wook Seo, Amirsaman Ashtari, Junyong Noh","authorsParsed":[["Seo","Chang Wook",""],["Ashtari","Amirsaman",""],["Noh","Junyong",""]],"versions":[{"version":"v1","created":"Fri, 19 Jul 2024 04:51:34 GMT"}],"updateDate":"2024-07-22","timestamp":1721364694000,"abstract":"  Sketches reflect the drawing style of individual artists; therefore, it is\nimportant to consider their unique styles when extracting sketches from color\nimages for various applications. Unfortunately, most existing sketch extraction\nmethods are designed to extract sketches of a single style. Although there have\nbeen some attempts to generate various style sketches, the methods generally\nsuffer from two limitations: low quality results and difficulty in training the\nmodel due to the requirement of a paired dataset. In this paper, we propose a\nnovel multi-modal sketch extraction method that can imitate the style of a\ngiven reference sketch with unpaired data training in a semi-supervised manner.\nOur method outperforms state-of-the-art sketch extraction methods and unpaired\nimage translation methods in both quantitative and qualitative evaluations.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}