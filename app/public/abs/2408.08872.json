{"id":"2408.08872","title":"xGen-MM (BLIP-3): A Family of Open Large Multimodal Models","authors":"Le Xue, Manli Shu, Anas Awadalla, Jun Wang, An Yan, Senthil\n  Purushwalkam, Honglu Zhou, Viraj Prabhu, Yutong Dai, Michael S Ryoo, Shrikant\n  Kendre, Jieyu Zhang, Can Qin, Shu Zhang, Chia-Chih Chen, Ning Yu, Juntao Tan,\n  Tulika Manoj Awalgaonkar, Shelby Heinecke, Huan Wang, Yejin Choi, Ludwig\n  Schmidt, Zeyuan Chen, Silvio Savarese, Juan Carlos Niebles, Caiming Xiong,\n  Ran Xu","authorsParsed":[["Xue","Le",""],["Shu","Manli",""],["Awadalla","Anas",""],["Wang","Jun",""],["Yan","An",""],["Purushwalkam","Senthil",""],["Zhou","Honglu",""],["Prabhu","Viraj",""],["Dai","Yutong",""],["Ryoo","Michael S",""],["Kendre","Shrikant",""],["Zhang","Jieyu",""],["Qin","Can",""],["Zhang","Shu",""],["Chen","Chia-Chih",""],["Yu","Ning",""],["Tan","Juntao",""],["Awalgaonkar","Tulika Manoj",""],["Heinecke","Shelby",""],["Wang","Huan",""],["Choi","Yejin",""],["Schmidt","Ludwig",""],["Chen","Zeyuan",""],["Savarese","Silvio",""],["Niebles","Juan Carlos",""],["Xiong","Caiming",""],["Xu","Ran",""]],"versions":[{"version":"v1","created":"Fri, 16 Aug 2024 17:57:01 GMT"},{"version":"v2","created":"Wed, 28 Aug 2024 05:03:34 GMT"}],"updateDate":"2024-08-29","timestamp":1723831021000,"abstract":"  This report introduces xGen-MM (also known as BLIP-3), a framework for\ndeveloping Large Multimodal Models (LMMs). The framework comprises meticulously\ncurated datasets, a training recipe, model architectures, and a resulting suite\nof LMMs. xGen-MM, short for xGen-MultiModal, expands the Salesforce xGen\ninitiative on foundation AI models. Our models undergo rigorous evaluation\nacross a range of tasks, including both single and multi-image benchmarks. Our\npre-trained base model exhibits strong in-context learning capabilities and the\ninstruction-tuned model demonstrates competitive performance among open-source\nLMMs with similar model sizes. In addition, we introduce a safety-tuned model\nwith DPO, aiming to mitigate harmful behaviors such as hallucinations and\nimprove safety. We open-source our models, curated large-scale datasets, and\nour fine-tuning codebase to facilitate further advancements in LMM research.\nAssociated resources will be available on our project page above.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by-sa/4.0/","blobId":"YYxFzyPjUElrv9KNywHuV_s4_BZC5kgoVVrRiH0WZ7c","pdfSize":"10750185"}
