{"id":"2407.11381","title":"Leveraging Segment Anything Model in Identifying Buildings within\n  Refugee Camps (SAM4Refugee) from Satellite Imagery for Humanitarian\n  Operations","authors":"Yunya Gao","authorsParsed":[["Gao","Yunya",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 04:52:58 GMT"}],"updateDate":"2024-07-17","timestamp":1721105578000,"abstract":"  Updated building footprints with refugee camps from high-resolution satellite\nimagery can support related humanitarian operations. This study explores the\nutilization of the \"Segment Anything Model\" (SAM) and one of its branches,\nSAM-Adapter, for semantic segmentation tasks in the building extraction from\nsatellite imagery. SAM-Adapter is a lightweight adaptation of the SAM and\nemerges as a powerful tool for this extraction task across diverse refugee\ncamps. Our research proves that SAM-Adapter excels in scenarios where data\navailability is limited compared to other classic (e.g., U-Net) or advanced\nsemantic segmentation models (e.g., Transformer). Furthermore, the impact of\nupscaling techniques on model performance is highlighted, with methods like\nsuper-resolution (SR) models proving invaluable for improving model\nperformance. Additionally, the study unveils intriguing phenomena, including\nthe model's rapid convergence in the first training epoch when using upscaled\nimage data for training, suggesting opportunities for future research. The\ncodes covering each step from data preparation, model training, model\ninferencing, and the generation of Shapefiles for predicted masks are available\non a GitHub repository to benefit the extended scientific community and\nhumanitarian operations.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}