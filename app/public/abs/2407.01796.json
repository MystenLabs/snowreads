{"id":"2407.01796","title":"Ground Every Sentence: Improving Retrieval-Augmented LLMs with\n  Interleaved Reference-Claim Generation","authors":"Sirui Xia, Xintao Wang, Jiaqing Liang, Yifei Zhang, Weikang Zhou,\n  Jiaji Deng, Fei Yu, Yanghua Xiao","authorsParsed":[["Xia","Sirui",""],["Wang","Xintao",""],["Liang","Jiaqing",""],["Zhang","Yifei",""],["Zhou","Weikang",""],["Deng","Jiaji",""],["Yu","Fei",""],["Xiao","Yanghua",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 20:47:47 GMT"}],"updateDate":"2024-07-03","timestamp":1719866867000,"abstract":"  Retrieval-Augmented Generation (RAG) has been widely adopted to enhance Large\nLanguage Models (LLMs) in knowledge-intensive tasks. Recently, Attributed Text\nGeneration (ATG) has attracted growing attention, which provides citations to\nsupport the model's responses in RAG, so as to enhance the credibility of\nLLM-generated content and facilitate verification. Prior methods mainly adopt\ncoarse-grained attributions, linking to passage-level references or providing\nparagraph-level citations. However, these methods still fall short in\nverifiability and require certain time costs for fact checking. This paper\nproposes a fine-grained ATG method called ReClaim(Refer & Claim), which\nalternates the generation of references and answers step by step. Unlike\ntraditional coarse-grained attribution, ReClaim allows the model to add\nsentence-level fine-grained citations to each answer sentence in long-form\nquestion-answering tasks. Our experiments encompass various training and\ninference methods and multiple LLMs, verifying the effectiveness of our\napproach.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"PRZAKZ43VXsMAojtoH9WXAaxwVhCqSWEzYGWByeaSjc","pdfSize":"654838"}
