{"id":"2408.09777","title":"Summarizing long regulatory documents with a multi-step pipeline","authors":"Mika Sie and Ruby Beek and Michiel Bots and Sjaak Brinkkemper and\n  Albert Gatt","authorsParsed":[["Sie","Mika",""],["Beek","Ruby",""],["Bots","Michiel",""],["Brinkkemper","Sjaak",""],["Gatt","Albert",""]],"versions":[{"version":"v1","created":"Mon, 19 Aug 2024 08:07:25 GMT"}],"updateDate":"2024-08-20","timestamp":1724054845000,"abstract":"  Due to their length and complexity, long regulatory texts are challenging to\nsummarize. To address this, a multi-step extractive-abstractive architecture is\nproposed to handle lengthy regulatory documents more effectively. In this\npaper, we show that the effectiveness of a two-step architecture for\nsummarizing long regulatory texts varies significantly depending on the model\nused. Specifically, the two-step architecture improves the performance of\ndecoder-only models. For abstractive encoder-decoder models with short context\nlengths, the effectiveness of an extractive step varies, whereas for\nlong-context encoder-decoder models, the extractive step worsens their\nperformance. This research also highlights the challenges of evaluating\ngenerated texts, as evidenced by the differing results from human and automated\nevaluations. Most notably, human evaluations favoured language models\npretrained on legal text, while automated metrics rank general-purpose language\nmodels higher. The results underscore the importance of selecting the\nappropriate summarization strategy based on model architecture and context\nlength.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"InK76ib7L_gcmFwBecoB0u99gLDIGHFQT3nvXAbL82E","pdfSize":"377102"}
