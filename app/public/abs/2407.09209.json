{"id":"2407.09209","title":"Pronunciation Assessment with Multi-modal Large Language Models","authors":"Kaiqi Fu, Linkai Peng, Nan Yang, Shuran Zhou","authorsParsed":[["Fu","Kaiqi",""],["Peng","Linkai",""],["Yang","Nan",""],["Zhou","Shuran",""]],"versions":[{"version":"v1","created":"Fri, 12 Jul 2024 12:16:14 GMT"},{"version":"v2","created":"Thu, 18 Jul 2024 13:09:20 GMT"}],"updateDate":"2024-07-19","timestamp":1720786574000,"abstract":"  Large language models (LLMs), renowned for their powerful conversational\nabilities, are widely recognized as exceptional tools in the field of\neducation, particularly in the context of automated intelligent instruction\nsystems for language learning. In this paper, we propose a scoring system based\non LLMs, motivated by their positive impact on text-related scoring tasks.\nSpecifically, the speech encoder first maps the learner's speech into\ncontextual features. The adapter layer then transforms these features to align\nwith the text embedding in latent space. The assessment task-specific prefix\nand prompt text are embedded and concatenated with the features generated by\nthe modality adapter layer, enabling the LLMs to predict accuracy and fluency\nscores. Our experiments demonstrate that the proposed scoring systems achieve\ncompetitive results compared to the baselines on the Speechocean762 datasets.\nMoreover, we also conducted an ablation study to better understand the\ncontributions of the prompt text and training strategy in the proposed scoring\nsystem.\n","subjects":["Computing Research Repository/Computation and Language","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}