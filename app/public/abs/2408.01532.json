{"id":"2408.01532","title":"Contextual Cross-Modal Attention for Audio-Visual Deepfake Detection and\n  Localization","authors":"Vinaya Sree Katamneni and Ajita Rattani","authorsParsed":[["Katamneni","Vinaya Sree",""],["Rattani","Ajita",""]],"versions":[{"version":"v1","created":"Fri, 2 Aug 2024 18:45:01 GMT"},{"version":"v2","created":"Tue, 6 Aug 2024 21:19:20 GMT"}],"updateDate":"2024-08-08","timestamp":1722624301000,"abstract":"  In the digital age, the emergence of deepfakes and synthetic media presents a\nsignificant threat to societal and political integrity. Deepfakes based on\nmulti-modal manipulation, such as audio-visual, are more realistic and pose a\ngreater threat. Current multi-modal deepfake detectors are often based on the\nattention-based fusion of heterogeneous data streams from multiple modalities.\nHowever, the heterogeneous nature of the data (such as audio and visual\nsignals) creates a distributional modality gap and poses a significant\nchallenge in effective fusion and hence multi-modal deepfake detection. In this\npaper, we propose a novel multi-modal attention framework based on recurrent\nneural networks (RNNs) that leverages contextual information for audio-visual\ndeepfake detection. The proposed approach applies attention to multi-modal\nmulti-sequence representations and learns the contributing features among them\nfor deepfake detection and localization. Thorough experimental validations on\naudio-visual deepfake datasets, namely FakeAVCeleb, AV-Deepfake1M, TVIL, and\nLAV-DF datasets, demonstrate the efficacy of our approach. Cross-comparison\nwith the published studies demonstrates superior performance of our approach\nwith an improved accuracy and precision by 3.47% and 2.05% in deepfake\ndetection and localization, respectively. Thus, obtaining state-of-the-art\nperformance. To facilitate reproducibility, the code and the datasets\ninformation is available at https://github.com/vcbsl/audiovisual-deepfake/.\n","subjects":["Computing Research Repository/Sound","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Multimedia","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by-sa/4.0/","blobId":"_bPUW6d8Dj9nVtQ4GeIlJPtwoaaCu8wE9CVv-t8bmqY","pdfSize":"971512","txDigest":"CEWh5D3UcVe4xN3sZxtt7XT1in9y3LWrLH8QmBtM3dzE","endEpoch":"1","status":"CERTIFIED"}
