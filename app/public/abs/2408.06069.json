{"id":"2408.06069","title":"Fully Bayesian Differential Gaussian Processes through Stochastic\n  Differential Equations","authors":"Jian Xu, Zhiqi Lin, Min Chen, Junmei Yang, Delu Zeng, John Paisley","authorsParsed":[["Xu","Jian",""],["Lin","Zhiqi",""],["Chen","Min",""],["Yang","Junmei",""],["Zeng","Delu",""],["Paisley","John",""]],"versions":[{"version":"v1","created":"Mon, 12 Aug 2024 11:41:07 GMT"}],"updateDate":"2024-08-13","timestamp":1723462867000,"abstract":"  Traditional deep Gaussian processes model the data evolution using a discrete\nhierarchy, whereas differential Gaussian processes (DIFFGPs) represent the\nevolution as an infinitely deep Gaussian process. However, prior DIFFGP methods\noften overlook the uncertainty of kernel hyperparameters and assume them to be\nfixed and time-invariant, failing to leverage the unique synergy between\ncontinuous-time models and approximate inference. In this work, we propose a\nfully Bayesian approach that treats the kernel hyperparameters as random\nvariables and constructs coupled stochastic differential equations (SDEs) to\nlearn their posterior distribution and that of inducing points. By\nincorporating estimation uncertainty on hyperparameters, our method enhances\nthe model's flexibility and adaptability to complex dynamics. Additionally, our\napproach provides a time-varying, comprehensive, and realistic posterior\napproximation through coupling variables using SDE methods. Experimental\nresults demonstrate the advantages of our method over traditional approaches,\nshowcasing its superior performance in terms of flexibility, accuracy, and\nother metrics. Our work opens up exciting research avenues for advancing\nBayesian inference and offers a powerful modeling tool for continuous-time\nGaussian processes.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/"}