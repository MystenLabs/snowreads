{"id":"2408.02205","title":"Towards AI-Safety-by-Design: A Taxonomy of Runtime Guardrails in\n  Foundation Model based Systems","authors":"Md Shamsujjoha, Qinghua Lu, Dehai Zhao, Liming Zhu","authorsParsed":[["Shamsujjoha","Md",""],["Lu","Qinghua",""],["Zhao","Dehai",""],["Zhu","Liming",""]],"versions":[{"version":"v1","created":"Mon, 5 Aug 2024 03:08:51 GMT"}],"updateDate":"2024-08-06","timestamp":1722827331000,"abstract":"  The rapid advancement and widespread deployment of foundation model (FM)\nbased systems have revolutionized numerous applications across various domains.\nHowever, the fast-growing capabilities and autonomy have also raised\nsignificant concerns about responsible AI and AI safety. Recently, there have\nbeen increasing attention toward implementing guardrails to ensure the runtime\nbehavior of FM-based systems is safe and responsible. Given the early stage of\nFMs and their applications (such as agents), the design of guardrails have not\nyet been systematically studied. It remains underexplored which software\nqualities should be considered when designing guardrails and how these\nqualities can be ensured from a software architecture perspective. Therefore,\nin this paper, we present a taxonomy for guardrails to classify and compare the\ncharacteristics and design options of guardrails. Our taxonomy is organized\ninto three main categories: the motivation behind adopting runtime guardrails,\nthe quality attributes to consider, and the design options available. This\ntaxonomy provides structured and concrete guidance for making architectural\ndesign decisions when designing guardrails and highlights trade-offs arising\nfrom the design decisions.\n","subjects":["Computing Research Repository/Software Engineering","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"-AdhODqLkut0zZEfVUr4FyK-KgXp-Ag7eZULXafX8js","pdfSize":"906578","txDigest":"AMbNwFK4U9YMELzim38U8xVYyejbKfxDVabte5YGj4uN","endEpoch":"1","status":"CERTIFIED"}
