{"id":"2408.01682","title":"Multi-Frame Vision-Language Model for Long-form Reasoning in Driver\n  Behavior Analysis","authors":"Hiroshi Takato, Hiroshi Tsutsui, Komei Soda, Hidetaka Kamigaito","authorsParsed":[["Takato","Hiroshi",""],["Tsutsui","Hiroshi",""],["Soda","Komei",""],["Kamigaito","Hidetaka",""]],"versions":[{"version":"v1","created":"Sat, 3 Aug 2024 06:40:00 GMT"}],"updateDate":"2024-08-06","timestamp":1722667200000,"abstract":"  Identifying risky driving behavior in real-world situations is essential for\nthe safety of both drivers and pedestrians. However, integrating natural\nlanguage models in this field remains relatively untapped. To address this, we\ncreated a novel multi-modal instruction tuning dataset and driver coaching\ninference system. Our primary use case is dashcam-based coaching for commercial\ndrivers. The North American Dashcam Market is expected to register a CAGR of\n15.4 percent from 2022 to 2027. Our dataset enables language models to learn\nvisual instructions across various risky driving scenarios, emphasizing\ndetailed reasoning crucial for effective driver coaching and managerial\ncomprehension. Our model is trained on road-facing and driver-facing RGB camera\nfootage, capturing the comprehensive scope of driving behavior in vehicles\nequipped with dashcams.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}