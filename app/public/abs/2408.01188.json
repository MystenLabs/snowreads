{"id":"2408.01188","title":"Multi-Objective Deep Reinforcement Learning for Optimisation in\n  Autonomous Systems","authors":"Juan C. Rosero, Ivana Dusparic, Nicol\\'as Cardozo","authorsParsed":[["Rosero","Juan C.",""],["Dusparic","Ivana",""],["Cardozo","Nicol√°s",""]],"versions":[{"version":"v1","created":"Fri, 2 Aug 2024 11:16:09 GMT"}],"updateDate":"2024-08-05","timestamp":1722597369000,"abstract":"  Reinforcement Learning (RL) is used extensively in Autonomous Systems (AS) as\nit enables learning at runtime without the need for a model of the environment\nor predefined actions. However, most applications of RL in AS, such as those\nbased on Q-learning, can only optimize one objective, making it necessary in\nmulti-objective systems to combine multiple objectives in a single objective\nfunction with predefined weights. A number of Multi-Objective Reinforcement\nLearning (MORL) techniques exist but they have mostly been applied in RL\nbenchmarks rather than real-world AS systems. In this work, we use a MORL\ntechnique called Deep W-Learning (DWN) and apply it to the Emergent Web Servers\nexemplar, a self-adaptive server, to find the optimal configuration for runtime\nperformance optimization. We compare DWN to two single-objective optimization\nimplementations: {\\epsilon}-greedy algorithm and Deep Q-Networks. Our initial\nevaluation shows that DWN optimizes multiple objectives simultaneously with\nsimilar results than DQN and {\\epsilon}-greedy approaches, having a better\nperformance for some metrics, and avoids issues associated with combining\nmultiple objectives into a single utility function.\n","subjects":["Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/"}