{"id":"2407.08331","title":"Towards Explainable Evolution Strategies with Large Language Models","authors":"Jill Baumann and Oliver Kramer","authorsParsed":[["Baumann","Jill",""],["Kramer","Oliver",""]],"versions":[{"version":"v1","created":"Thu, 11 Jul 2024 09:28:27 GMT"},{"version":"v2","created":"Mon, 5 Aug 2024 08:13:37 GMT"}],"updateDate":"2024-08-06","timestamp":1720690107000,"abstract":"  This paper introduces an approach that integrates self-adaptive Evolution\nStrategies (ES) with Large Language Models (LLMs) to enhance the explainability\nof complex optimization processes. By employing a self-adaptive ES equipped\nwith a restart mechanism, we effectively navigate the challenging landscapes of\nbenchmark functions, capturing detailed logs of the optimization journey. The\nlogs include fitness evolution, step-size adjustments and restart events due to\nstagnation. An LLM is then utilized to process these logs, generating concise,\nuser-friendly summaries that highlight key aspects such as convergence\nbehavior, optimal fitness achievements, and encounters with local optima. Our\ncase study on the Rastrigin function demonstrates how our approach makes the\ncomplexities of ES optimization transparent. Our findings highlight the\npotential of using LLMs to bridge the gap between advanced optimization\nalgorithms and their interpretability.\n","subjects":["Computing Research Repository/Neural and Evolutionary Computing","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}