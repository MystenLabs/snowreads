{"id":"2408.00178","title":"Adapting Skills to Novel Grasps: A Self-Supervised Approach","authors":"Georgios Papagiannis, Kamil Dreczkowski, Vitalis Vosylius, Edward\n  Johns","authorsParsed":[["Papagiannis","Georgios",""],["Dreczkowski","Kamil",""],["Vosylius","Vitalis",""],["Johns","Edward",""]],"versions":[{"version":"v1","created":"Wed, 31 Jul 2024 22:18:09 GMT"}],"updateDate":"2024-08-02","timestamp":1722464289000,"abstract":"  In this paper, we study the problem of adapting manipulation trajectories\ninvolving grasped objects (e.g. tools) defined for a single grasp pose to novel\ngrasp poses. A common approach to address this is to define a new trajectory\nfor each possible grasp explicitly, but this is highly inefficient. Instead, we\npropose a method to adapt such trajectories directly while only requiring a\nperiod of self-supervised data collection, during which a camera observes the\nrobot's end-effector moving with the object rigidly grasped. Importantly, our\nmethod requires no prior knowledge of the grasped object (such as a 3D CAD\nmodel), it can work with RGB images, depth images, or both, and it requires no\ncamera calibration. Through a series of real-world experiments involving 1360\nevaluations, we find that self-supervised RGB data consistently outperforms\nalternatives that rely on depth images including several state-of-the-art pose\nestimation methods. Compared to the best-performing baseline, our method\nresults in an average of 28.5% higher success rate when adapting manipulation\ntrajectories to novel grasps on several everyday tasks. Videos of the\nexperiments are available on our webpage at\nhttps://www.robot-learning.uk/adapting-skills\n","subjects":["Computing Research Repository/Robotics","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"Pq7LeZcO8sVsiq6QmCoQqKIEeuCO3h7ZAKsQSS7_JhA","pdfSize":"15714855","txDigest":"FpUSpxK44tc2bXCoS87A9XVQEgGKouzZGWGdpoZ6NYvW","endEpoch":"1","status":"CERTIFIED"}
