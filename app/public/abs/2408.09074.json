{"id":"2408.09074","title":"Gradient-Variation Online Learning under Generalized Smoothness","authors":"Yan-Feng Xie, Peng Zhao, Zhi-Hua Zhou","authorsParsed":[["Xie","Yan-Feng",""],["Zhao","Peng",""],["Zhou","Zhi-Hua",""]],"versions":[{"version":"v1","created":"Sat, 17 Aug 2024 02:22:08 GMT"}],"updateDate":"2024-08-20","timestamp":1723861328000,"abstract":"  Gradient-variation online learning aims to achieve regret guarantees that\nscale with the variations in the gradients of online functions, which has been\nshown to be crucial for attaining fast convergence in games and robustness in\nstochastic optimization, hence receiving increased attention. Existing results\noften require the smoothness condition by imposing a fixed bound on the\ngradient Lipschitzness, but this may not hold in practice. Recent efforts in\nneural network optimization suggest a generalized smoothness condition,\nallowing smoothness to correlate with gradient norms. In this paper, we\nsystematically study gradient-variation online learning under generalized\nsmoothness. To this end, we extend the classic optimistic mirror descent\nalgorithm to derive gradient-variation bounds by conducting stability analysis\nover the optimization trajectory and exploiting smoothness locally.\nFurthermore, we explore universal online learning, designing a single algorithm\nenjoying optimal gradient-variation regrets for convex and strongly convex\nfunctions simultaneously without knowing curvature information. The algorithm\nadopts a two-layer structure with a meta-algorithm running over a group of\nbase-learners. To ensure favorable guarantees, we have designed a new\nmeta-algorithm that is Lipschitz-adaptive to handle potentially unbounded\ngradients and meanwhile ensures second-order regret to cooperate with\nbase-learners. Finally, we provide implications of our findings and obtain new\nresults in fast-rate games and stochastic extended adversarial optimization.\n","subjects":["Computing Research Repository/Machine Learning","Mathematics/Optimization and Control"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}