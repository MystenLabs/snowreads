{"id":"2407.02549","title":"Diffusion Models for Tabular Data Imputation and Synthetic Data\n  Generation","authors":"Mario Villaiz\\'an-Vallelado and Matteo Salvatori and Carlos Segura and\n  Ioannis Arapakis","authorsParsed":[["Villaiz√°n-Vallelado","Mario",""],["Salvatori","Matteo",""],["Segura","Carlos",""],["Arapakis","Ioannis",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 15:27:06 GMT"}],"updateDate":"2024-07-04","timestamp":1719934026000,"abstract":"  Data imputation and data generation have important applications for many\ndomains, like healthcare and finance, where incomplete or missing data can\nhinder accurate analysis and decision-making. Diffusion models have emerged as\npowerful generative models capable of capturing complex data distributions\nacross various data modalities such as image, audio, and time series data.\nRecently, they have been also adapted to generate tabular data. In this paper,\nwe propose a diffusion model for tabular data that introduces three key\nenhancements: (1) a conditioning attention mechanism, (2) an encoder-decoder\ntransformer as the denoising network, and (3) dynamic masking. The conditioning\nattention mechanism is designed to improve the model's ability to capture the\nrelationship between the condition and synthetic data. The transformer layers\nhelp model interactions within the condition (encoder) or synthetic data\n(decoder), while dynamic masking enables our model to efficiently handle both\nmissing data imputation and synthetic data generation tasks within a unified\nframework. We conduct a comprehensive evaluation by comparing the performance\nof diffusion models with transformer conditioning against state-of-the-art\ntechniques, such as Variational Autoencoders, Generative Adversarial Networks\nand Diffusion Models, on benchmark datasets. Our evaluation focuses on the\nassessment of the generated samples with respect to three important criteria,\nnamely: (1) Machine Learning efficiency, (2) statistical similarity, and (3)\nprivacy risk mitigation. For the task of data imputation, we consider the\nefficiency of the generated samples across different levels of missing\nfeatures.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"-ih7T2GsKRtl74OhfXQCVFQ1DiqD-bochJbGjvEwoH0","pdfSize":"4277103","objectId":"0x896834422ee7f96d4d3e8aa0e93a430bac53e472b8201840766973b94c742fe9","registeredEpoch":"3","certifiedEpoch":"3","startEpoch":"3","endEpoch":"203"}
