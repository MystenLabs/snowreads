{"id":"2407.18556","title":"Look Globally and Reason: Two-stage Path Reasoning over Sparse Knowledge\n  Graphs","authors":"Saiping Guan, Jiyao Wei, Xiaolong Jin, Jiafeng Guo, Xueqi Cheng","authorsParsed":[["Guan","Saiping",""],["Wei","Jiyao",""],["Jin","Xiaolong",""],["Guo","Jiafeng",""],["Cheng","Xueqi",""]],"versions":[{"version":"v1","created":"Fri, 26 Jul 2024 07:10:27 GMT"}],"updateDate":"2024-07-29","timestamp":1721977827000,"abstract":"  Sparse Knowledge Graphs (KGs), frequently encountered in real-world\napplications, contain fewer facts in the form of (head entity, relation, tail\nentity) compared to more populated KGs. The sparse KG completion task, which\nreasons answers for given queries in the form of (head entity, relation, ?) for\nsparse KGs, is particularly challenging due to the necessity of reasoning\nmissing facts based on limited facts. Path-based models, known for excellent\nexplainability, are often employed for this task. However, existing path-based\nmodels typically rely on external models to fill in missing facts and\nsubsequently perform path reasoning. This approach introduces unexplainable\nfactors or necessitates meticulous rule design. In light of this, this paper\nproposes an alternative approach by looking inward instead of seeking external\nassistance. We introduce a two-stage path reasoning model called LoGRe (Look\nGlobally and Reason) over sparse KGs. LoGRe constructs a relation-path\nreasoning schema by globally analyzing the training data to alleviate the\nsparseness problem. Based on this schema, LoGRe then aggregates paths to reason\nout answers. Experimental results on five benchmark sparse KG datasets\ndemonstrate the effectiveness of the proposed LoGRe model.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}