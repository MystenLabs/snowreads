{"id":"2407.08954","title":"PriRoAgg: Achieving Robust Model Aggregation with Minimum Privacy\n  Leakage for Federated Learning","authors":"Sizai Hou, Songze Li, Tayyebeh Jahani-Nezhad, Giuseppe Caire","authorsParsed":[["Hou","Sizai",""],["Li","Songze",""],["Jahani-Nezhad","Tayyebeh",""],["Caire","Giuseppe",""]],"versions":[{"version":"v1","created":"Fri, 12 Jul 2024 03:18:08 GMT"}],"updateDate":"2024-07-15","timestamp":1720754288000,"abstract":"  Federated learning (FL) has recently gained significant momentum due to its\npotential to leverage large-scale distributed user data while preserving user\nprivacy. However, the typical paradigm of FL faces challenges of both privacy\nand robustness: the transmitted model updates can potentially leak sensitive\nuser information, and the lack of central control of the local training process\nleaves the global model susceptible to malicious manipulations on model\nupdates. Current solutions attempting to address both problems under the\none-server FL setting fall short in the following aspects: 1) designed for\nsimple validity checks that are insufficient against advanced attacks (e.g.,\nchecking norm of individual update); and 2) partial privacy leakage for more\ncomplicated robust aggregation algorithms (e.g., distances between model\nupdates are leaked for multi-Krum). In this work, we formalize a novel security\nnotion of aggregated privacy that characterizes the minimum amount of user\ninformation, in the form of some aggregated statistics of users' updates, that\nis necessary to be revealed to accomplish more advanced robust aggregation. We\ndevelop a general framework PriRoAgg, utilizing Lagrange coded computing and\ndistributed zero-knowledge proof, to execute a wide range of robust aggregation\nalgorithms while satisfying aggregated privacy. As concrete instantiations of\nPriRoAgg, we construct two secure and robust protocols based on\nstate-of-the-art robust algorithms, for which we provide full theoretical\nanalyses on security and complexity. Extensive experiments are conducted for\nthese protocols, demonstrating their robustness against various model integrity\nattacks, and their efficiency advantages over baselines.\n","subjects":["Computing Research Repository/Cryptography and Security"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"_M-TPI8LtXJLrduyAaKEIXoHAOW_r_7s1bK4PiJh3ag","pdfSize":"2570077"}
