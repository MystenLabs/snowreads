{"id":"2407.19094","title":"Solving Robotics Problems in Zero-Shot with Vision-Language Models","authors":"Zidan Wang, Rui Shen, Bradly Stadie","authorsParsed":[["Wang","Zidan",""],["Shen","Rui",""],["Stadie","Bradly",""]],"versions":[{"version":"v1","created":"Fri, 26 Jul 2024 21:18:57 GMT"},{"version":"v2","created":"Fri, 23 Aug 2024 16:06:27 GMT"}],"updateDate":"2024-08-26","timestamp":1722028737000,"abstract":"  We introduce Wonderful Team, a multi-agent visual LLM (VLLM) framework for\nsolving robotics problems in the zero-shot regime. By zero-shot we mean that,\nfor a novel environment, we feed a VLLM an image of the robot's environment and\na description of the task, and have the VLLM output the sequence of actions\nnecessary for the robot to complete the task. Prior work on VLLMs in robotics\nhas largely focused on settings where some part of the pipeline is fine-tuned,\nsuch as tuning an LLM on robot data or training a separate vision encoder for\nperception and action generation. Surprisingly, due to recent advances in the\ncapabilities of VLLMs, this type of fine-tuning may no longer be necessary for\nmany tasks. In this work, we show that with careful engineering, we can prompt\na single off-the-shelf VLLM to handle all aspects of a robotics task, from\nhigh-level planning to low-level location-extraction and action-execution.\nWonderful Team builds on recent advances in multi-agent LLMs to partition tasks\nacross an agent hierarchy, making it self-corrective and able to effectively\npartition and solve even long-horizon tasks. Extensive experiments on VIMABench\nand real-world robotic environments demonstrate the system's capability to\nhandle a variety of robotic tasks, including manipulation, visual\ngoal-reaching, and visual reasoning, all in a zero-shot manner. These results\nunderscore a key point: vision-language models have progressed rapidly in the\npast year, and should strongly be considered as a backbone for robotics\nproblems going forward.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Robotics"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}