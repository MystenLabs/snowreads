{"id":"2407.10112","title":"Warming Up Cold-Start CTR Prediction by Learning Item-Specific Feature\n  Interactions","authors":"Yaqing Wang and Hongming Piao and Daxiang Dong and Quanming Yao and\n  Jingbo Zhou","authorsParsed":[["Wang","Yaqing",""],["Piao","Hongming",""],["Dong","Daxiang",""],["Yao","Quanming",""],["Zhou","Jingbo",""]],"versions":[{"version":"v1","created":"Sun, 14 Jul 2024 07:58:13 GMT"}],"updateDate":"2024-07-16","timestamp":1720943893000,"abstract":"  In recommendation systems, new items are continuously introduced, initially\nlacking interaction records but gradually accumulating them over time.\nAccurately predicting the click-through rate (CTR) for these items is crucial\nfor enhancing both revenue and user experience. While existing methods focus on\nenhancing item ID embeddings for new items within general CTR models, they tend\nto adopt a global feature interaction approach, often overshadowing new items\nwith sparse data by those with abundant interactions. Addressing this, our work\nintroduces EmerG, a novel approach that warms up cold-start CTR prediction by\nlearning item-specific feature interaction patterns. EmerG utilizes\nhypernetworks to generate an item-specific feature graph based on item\ncharacteristics, which is then processed by a Graph Neural Network (GNN). This\nGNN is specially tailored to provably capture feature interactions at any order\nthrough a customized message passing mechanism. We further design a meta\nlearning strategy that optimizes parameters of hypernetworks and GNN across\nvarious item CTR prediction tasks, while only adjusting a minimal set of\nitem-specific parameters within each task. This strategy effectively reduces\nthe risk of overfitting when dealing with limited data. Extensive experiments\non benchmark datasets validate that EmerG consistently performs the best given\nno, a few and sufficient instances of new items.\n","subjects":["Computing Research Repository/Information Retrieval"],"license":"http://creativecommons.org/licenses/by/4.0/"}