{"id":"2407.04363","title":"AriGraph: Learning Knowledge Graph World Models with Episodic Memory for\n  LLM Agents","authors":"Petr Anokhin, Nikita Semenov, Artyom Sorokin, Dmitry Evseev, Mikhail\n  Burtsev, Evgeny Burnaev","authorsParsed":[["Anokhin","Petr",""],["Semenov","Nikita",""],["Sorokin","Artyom",""],["Evseev","Dmitry",""],["Burtsev","Mikhail",""],["Burnaev","Evgeny",""]],"versions":[{"version":"v1","created":"Fri, 5 Jul 2024 09:06:47 GMT"},{"version":"v2","created":"Mon, 9 Sep 2024 07:01:56 GMT"}],"updateDate":"2024-09-10","timestamp":1720170407000,"abstract":"  Advancements in the capabilities of Large Language Models (LLMs) have created\na promising foundation for developing autonomous agents. With the right tools,\nthese agents could learn to solve tasks in new environments by accumulating and\nupdating their knowledge. Current LLM-based agents process past experiences\nusing a full history of observations, summarization, retrieval augmentation.\nHowever, these unstructured memory representations do not facilitate the\nreasoning and planning essential for complex decision-making. In our study, we\nintroduce AriGraph, a novel method wherein the agent constructs and updates a\nmemory graph that integrates semantic and episodic memories while exploring the\nenvironment. We demonstrate that our Ariadne LLM agent, consisting of the\nproposed memory architecture augmented with planning and decision-making,\neffectively handles complex tasks within interactive text game environments\ndifficult even for human players. Results show that our approach markedly\noutperforms other established memory methods and strong RL baselines in a range\nof problems of varying complexity. Additionally, AriGraph demonstrates\ncompetitive performance compared to dedicated knowledge graph-based methods in\nstatic multi-hop question-answering.\n","subjects":["Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}