{"id":"2408.07680","title":"A Spitting Image: Modular Superpixel Tokenization in Vision Transformers","authors":"Marius Aasan, Odd Kolbj{\\o}rnsen, Anne Schistad Solberg, Ad\\'in\n  Ramirez Rivera","authorsParsed":[["Aasan","Marius",""],["Kolbjørnsen","Odd",""],["Solberg","Anne Schistad",""],["Rivera","Adín Ramirez",""]],"versions":[{"version":"v1","created":"Wed, 14 Aug 2024 17:28:58 GMT"},{"version":"v2","created":"Thu, 15 Aug 2024 12:07:00 GMT"}],"updateDate":"2024-08-16","timestamp":1723656538000,"abstract":"  Vision Transformer (ViT) architectures traditionally employ a grid-based\napproach to tokenization independent of the semantic content of an image. We\npropose a modular superpixel tokenization strategy which decouples tokenization\nand feature extraction; a shift from contemporary approaches where these are\ntreated as an undifferentiated whole. Using on-line content-aware tokenization\nand scale- and shape-invariant positional embeddings, we perform experiments\nand ablations that contrast our approach with patch-based tokenization and\nrandomized partitions as baselines. We show that our method significantly\nimproves the faithfulness of attributions, gives pixel-level granularity on\nzero-shot unsupervised dense prediction tasks, while maintaining predictive\nperformance in classification tasks. Our approach provides a modular\ntokenization framework commensurable with standard architectures, extending the\nspace of ViTs to a larger class of semantically-rich models.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"Q5Ixo0YbzJmOyIeWPANgYdvAp7x2EV7tIKdJukFSSJQ","pdfSize":"10802449"}
