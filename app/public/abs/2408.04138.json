{"id":"2408.04138","title":"Enhancing Healthcare through Large Language Models: A Study on Medical\n  Question Answering","authors":"Haoran Yu, Chang Yu, Zihan Wang, Dongxian Zou, Hao Qin","authorsParsed":[["Yu","Haoran",""],["Yu","Chang",""],["Wang","Zihan",""],["Zou","Dongxian",""],["Qin","Hao",""]],"versions":[{"version":"v1","created":"Thu, 8 Aug 2024 00:35:39 GMT"}],"updateDate":"2024-08-09","timestamp":1723077339000,"abstract":"  In recent years, the application of Large Language Models (LLMs) in\nhealthcare has shown significant promise in improving the accessibility and\ndissemination of medical knowledge. This paper presents a detailed study of\nvarious LLMs trained on the MedQuAD medical question-answering dataset, with a\nfocus on identifying the most effective model for providing accurate medical\ninformation. Among the models tested, the Sentence-t5 combined with Mistral 7B\ndemonstrated superior performance, achieving a precision score of 0.762. This\nmodel's enhanced capabilities are attributed to its advanced pretraining\ntechniques, robust architecture, and effective prompt construction\nmethodologies. By leveraging these strengths, the Sentence-t5 + Mistral 7B\nmodel excels in understanding and generating precise medical answers. Our\nfindings highlight the potential of integrating sophisticated LLMs in medical\ncontexts to facilitate efficient and accurate medical knowledge retrieval, thus\nsignificantly enhancing patient education and support.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}