{"id":"2408.02035","title":"Robustness of Watermarking on Text-to-Image Diffusion Models","authors":"Xiaodong Wu, Xiangman Li, Jianbing Ni","authorsParsed":[["Wu","Xiaodong",""],["Li","Xiangman",""],["Ni","Jianbing",""]],"versions":[{"version":"v1","created":"Sun, 4 Aug 2024 13:59:09 GMT"}],"updateDate":"2024-08-06","timestamp":1722779949000,"abstract":"  Watermarking has become one of promising techniques to not only aid in\nidentifying AI-generated images but also serve as a deterrent against the\nunethical use of these models. However, the robustness of watermarking\ntechniques has not been extensively studied recently. In this paper, we\ninvestigate the robustness of generative watermarking, which is created from\nthe integration of watermarking embedding and text-to-image generation\nprocessing in generative models, e.g., latent diffusion models. Specifically,\nwe propose three attacking methods, i.e., discriminator-based attacks, edge\nprediction-based attacks, and fine-tune-based attacks, under the scenario where\nthe watermark decoder is not accessible. The model is allowed to be fine-tuned\nto created AI agents with specific generative tasks for personalizing or\nspecializing. We found that generative watermarking methods are robust to\ndirect evasion attacks, like discriminator-based attacks, or manipulation based\non the edge information in edge prediction-based attacks but vulnerable to\nmalicious fine-tuning. Experimental results show that our fine-tune-based\nattacks can decrease the accuracy of the watermark detection to nearly\n$67.92\\%$. In addition, We conduct an ablation study on the length of\nfine-tuned messages, encoder/decoder's depth and structure to identify key\nfactors that impact the performance of fine-tune-based attacks.\n","subjects":["Computing Research Repository/Cryptography and Security"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}