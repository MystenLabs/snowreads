{"id":"2407.02604","title":"D-Rax: Domain-specific Radiologic assistant leveraging multi-modal data\n  and eXpert model predictions","authors":"Hareem Nisar, Syed Muhammad Anwar, Zhifan Jiang, Abhijeet Parida,\n  Ramon Sanchez-Jacob, Vishwesh Nath, Holger R. Roth, Marius George Linguraru","authorsParsed":[["Nisar","Hareem",""],["Anwar","Syed Muhammad",""],["Jiang","Zhifan",""],["Parida","Abhijeet",""],["Sanchez-Jacob","Ramon",""],["Nath","Vishwesh",""],["Roth","Holger R.",""],["Linguraru","Marius George",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 18:43:10 GMT"},{"version":"v2","created":"Fri, 2 Aug 2024 13:45:53 GMT"}],"updateDate":"2024-08-05","timestamp":1719945790000,"abstract":"  Large vision language models (VLMs) have progressed incredibly from research\nto applicability for general-purpose use cases. LLaVA-Med, a pioneering large\nlanguage and vision assistant for biomedicine, can perform multi-modal\nbiomedical image and data analysis to provide a natural language interface for\nradiologists. While it is highly generalizable and works with multi-modal data,\nit is currently limited by well-known challenges that exist in the large\nlanguage model space. Hallucinations and imprecision in responses can lead to\nmisdiagnosis which currently hinder the clinical adaptability of VLMs. To\ncreate precise, user-friendly models in healthcare, we propose D-Rax -- a\ndomain-specific, conversational, radiologic assistance tool that can be used to\ngain insights about a particular radiologic image. In this study, we enhance\nthe conversational analysis of chest X-ray (CXR) images to support radiological\nreporting, offering comprehensive insights from medical imaging and aiding in\nthe formulation of accurate diagnosis. D-Rax is achieved by fine-tuning the\nLLaVA-Med architecture on our curated enhanced instruction-following data,\ncomprising of images, instructions, as well as disease diagnosis and\ndemographic predictions derived from MIMIC-CXR imaging data, CXR-related visual\nquestion answer (VQA) pairs, and predictive outcomes from multiple expert AI\nmodels. We observe statistically significant improvement in responses when\nevaluated for both open and close-ended conversations. Leveraging the power of\nstate-of-the-art diagnostic models combined with VLMs, D-Rax empowers\nclinicians to interact with medical images using natural language, which could\npotentially streamline their decision-making process, enhance diagnostic\naccuracy, and conserve their time.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning","Electrical Engineering and Systems Science/Image and Video Processing"],"license":"http://creativecommons.org/licenses/by/4.0/"}