{"id":"2407.10886","title":"SLIP: Securing LLMs IP Using Weights Decomposition","authors":"Yehonathan Refael, Adam Hakim, Lev Greenberg, Tal Aviv, Satya Lokam,\n  Ben Fishman, Shachar Seidman","authorsParsed":[["Refael","Yehonathan",""],["Hakim","Adam",""],["Greenberg","Lev",""],["Aviv","Tal",""],["Lokam","Satya",""],["Fishman","Ben",""],["Seidman","Shachar",""]],"versions":[{"version":"v1","created":"Mon, 15 Jul 2024 16:37:55 GMT"},{"version":"v2","created":"Thu, 1 Aug 2024 20:34:18 GMT"}],"updateDate":"2024-08-05","timestamp":1721061475000,"abstract":"  Large language models (LLMs) have recently seen widespread adoption, in both\nacademia and industry. As these models grow, they become valuable intellectual\nproperty (IP), reflecting enormous investments by their owners. Moreover, the\nhigh cost of cloud-based deployment has driven interest towards deployment to\nedge devices, yet this risks exposing valuable parameters to theft and\nunauthorized use. Current methods to protect models' IP on the edge have\nlimitations in terms of practicality, loss in accuracy, or suitability to\nrequirements. In this paper, we introduce a novel hybrid inference algorithm,\nnamed SLIP, designed to protect edge-deployed models from theft. SLIP is the\nfirst hybrid protocol that is both practical for real-world applications and\nprovably secure, while having zero accuracy degradation and minimal impact on\nlatency. It involves partitioning the model between two computing resources,\none secure but expensive, and another cost-effective but vulnerable. This is\nachieved through matrix decomposition, ensuring that the secure resource\nretains a maximally sensitive portion of the model's IP while performing a\nminimal amount of computations, and vice versa for the vulnerable resource.\nImportantly, the protocol includes security guarantees that prevent attackers\nfrom exploiting the partition to infer the secured information. Finally, we\npresent experimental results that show the robustness and effectiveness of our\nmethod, positioning it as a compelling solution for protecting LLMs.\n","subjects":["Computing Research Repository/Cryptography and Security","Computing Research Repository/Machine Learning","Statistics/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}