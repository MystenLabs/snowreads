{"id":"2407.06305","title":"SweepNet: Unsupervised Learning Shape Abstraction via Neural Sweepers","authors":"Mingrui Zhao, Yizhi Wang, Fenggen Yu, Changqing Zou, Ali Mahdavi-Amiri","authorsParsed":[["Zhao","Mingrui",""],["Wang","Yizhi",""],["Yu","Fenggen",""],["Zou","Changqing",""],["Mahdavi-Amiri","Ali",""]],"versions":[{"version":"v1","created":"Mon, 8 Jul 2024 18:18:17 GMT"}],"updateDate":"2024-07-10","timestamp":1720462697000,"abstract":"  Shape abstraction is an important task for simplifying complex geometric\nstructures while retaining essential features. Sweep surfaces, commonly found\nin human-made objects, aid in this process by effectively capturing and\nrepresenting object geometry, thereby facilitating abstraction. In this paper,\nwe introduce \\papername, a novel approach to shape abstraction through sweep\nsurfaces. We propose an effective parameterization for sweep surfaces,\nutilizing superellipses for profile representation and B-spline curves for the\naxis. This compact representation, requiring as few as 14 float numbers,\nfacilitates intuitive and interactive editing while preserving shape details\neffectively. Additionally, by introducing a differentiable neural sweeper and\nan encoder-decoder architecture, we demonstrate the ability to predict sweep\nsurface representations without supervision. We show the superiority of our\nmodel through several quantitative and qualitative experiments throughout the\npaper. Our code is available at https://mingrui-zhao.github.io/SweepNet/\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Graphics"],"license":"http://creativecommons.org/licenses/by/4.0/"}