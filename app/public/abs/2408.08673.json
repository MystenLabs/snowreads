{"id":"2408.08673","title":"MAT-SED: A Masked Audio Transformer with Masked-Reconstruction Based\n  Pre-training for Sound Event Detection","authors":"Pengfei Cai, Yan Song, Kang Li, Haoyu Song, Ian McLoughlin","authorsParsed":[["Cai","Pengfei",""],["Song","Yan",""],["Li","Kang",""],["Song","Haoyu",""],["McLoughlin","Ian",""]],"versions":[{"version":"v1","created":"Fri, 16 Aug 2024 11:33:16 GMT"},{"version":"v2","created":"Mon, 19 Aug 2024 07:11:39 GMT"}],"updateDate":"2024-08-20","timestamp":1723807996000,"abstract":"  Sound event detection (SED) methods that leverage a large pre-trained\nTransformer encoder network have shown promising performance in recent DCASE\nchallenges. However, they still rely on an RNN-based context network to model\ntemporal dependencies, largely due to the scarcity of labeled data. In this\nwork, we propose a pure Transformer-based SED model with masked-reconstruction\nbased pre-training, termed MAT-SED. Specifically, a Transformer with relative\npositional encoding is first designed as the context network, pre-trained by\nthe masked-reconstruction task on all available target data in a\nself-supervised way. Both the encoder and the context network are jointly\nfine-tuned in a semi-supervised manner. Furthermore, a global-local feature\nfusion strategy is proposed to enhance the localization capability. Evaluation\nof MAT-SED on DCASE2023 task4 surpasses state-of-the-art performance, achieving\n0.587/0.896 PSDS1/PSDS2 respectively.\n","subjects":["Computing Research Repository/Sound","Computing Research Repository/Artificial Intelligence","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"zkDkSbkdypp7LnXQyZ6ntLVEn-LBNwFgnQij-PfrKR0","pdfSize":"1417268"}
