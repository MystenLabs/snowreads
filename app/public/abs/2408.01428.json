{"id":"2408.01428","title":"Transferable Adversarial Facial Images for Privacy Protection","authors":"Minghui Li, Jiangxiong Wang, Hao Zhang, Ziqi Zhou, Shengshan Hu,\n  Xiaobing Pei","authorsParsed":[["Li","Minghui",""],["Wang","Jiangxiong",""],["Zhang","Hao",""],["Zhou","Ziqi",""],["Hu","Shengshan",""],["Pei","Xiaobing",""]],"versions":[{"version":"v1","created":"Thu, 18 Jul 2024 02:16:11 GMT"}],"updateDate":"2024-08-06","timestamp":1721268971000,"abstract":"  The success of deep face recognition (FR) systems has raised serious privacy\nconcerns due to their ability to enable unauthorized tracking of users in the\ndigital world. Previous studies proposed introducing imperceptible adversarial\nnoises into face images to deceive those face recognition models, thus\nachieving the goal of enhancing facial privacy protection. Nevertheless, they\nheavily rely on user-chosen references to guide the generation of adversarial\nnoises, and cannot simultaneously construct natural and highly transferable\nadversarial face images in black-box scenarios. In light of this, we present a\nnovel face privacy protection scheme with improved transferability while\nmaintain high visual quality. We propose shaping the entire face space directly\ninstead of exploiting one kind of facial characteristic like makeup information\nto integrate adversarial noises. To achieve this goal, we first exploit global\nadversarial latent search to traverse the latent space of the generative model,\nthereby creating natural adversarial face images with high transferability. We\nthen introduce a key landmark regularization module to preserve the visual\nidentity information. Finally, we investigate the impacts of various kinds of\nlatent spaces and find that $\\mathcal{F}$ latent space benefits the trade-off\nbetween visual naturalness and adversarial transferability. Extensive\nexperiments over two datasets demonstrate that our approach significantly\nenhances attack transferability while maintaining high visual quality,\noutperforming state-of-the-art methods by an average 25% improvement in deep FR\nmodels and 10% improvement on commercial FR APIs, including Face++, Aliyun, and\nTencent.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}