{"id":"2407.09697","title":"Uplifting Range-View-based 3D Semantic Segmentation in Real-Time with\n  Multi-Sensor Fusion","authors":"Shiqi Tan, Hamidreza Fazlali, Yixuan Xu, Yuan Ren, Bingbing Liu","authorsParsed":[["Tan","Shiqi",""],["Fazlali","Hamidreza",""],["Xu","Yixuan",""],["Ren","Yuan",""],["Liu","Bingbing",""]],"versions":[{"version":"v1","created":"Fri, 12 Jul 2024 21:41:57 GMT"}],"updateDate":"2024-07-16","timestamp":1720820517000,"abstract":"  Range-View(RV)-based 3D point cloud segmentation is widely adopted due to its\ncompact data form. However, RV-based methods fall short in providing robust\nsegmentation for the occluded points and suffer from distortion of projected\nRGB images due to the sparse nature of 3D point clouds. To alleviate these\nproblems, we propose a new LiDAR and Camera Range-view-based 3D point cloud\nsemantic segmentation method (LaCRange). Specifically, a\ndistortion-compensating knowledge distillation (DCKD) strategy is designed to\nremedy the adverse effect of RV projection of RGB images. Moreover, a\ncontext-based feature fusion module is introduced for robust and preservative\nsensor fusion. Finally, in order to address the limited resolution of RV and\nits insufficiency of 3D topology, a new point refinement scheme is devised for\nproper aggregation of features in 2D and augmentation of point features in 3D.\nWe evaluated the proposed method on large-scale autonomous driving datasets \\ie\nSemanticKITTI and nuScenes. In addition to being real-time, the proposed method\nachieves state-of-the-art results on nuScenes benchmark\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}