{"id":"2408.00420","title":"MPT-PAR:Mix-Parameters Transformer for Panoramic Activity Recognition","authors":"Wenqing Gan, Yan Sun, Feiran Liu, Xiangfeng Luo","authorsParsed":[["Gan","Wenqing",""],["Sun","Yan",""],["Liu","Feiran",""],["Luo","Xiangfeng",""]],"versions":[{"version":"v1","created":"Thu, 1 Aug 2024 09:42:44 GMT"}],"updateDate":"2024-08-02","timestamp":1722505364000,"abstract":"  The objective of the panoramic activity recognition task is to identify\nbehaviors at various granularities within crowded and complex environments,\nencompassing individual actions, social group activities, and global\nactivities. Existing methods generally use either parameter-independent modules\nto capture task-specific features or parameter-sharing modules to obtain common\nfeatures across all tasks. However, there is often a strong interrelatedness\nand complementary effect between tasks of different granularities that previous\nmethods have yet to notice. In this paper, we propose a model called MPT-PAR\nthat considers both the unique characteristics of each task and the synergies\nbetween different tasks simultaneously, thereby maximizing the utilization of\nfeatures across multi-granularity activity recognition. Furthermore, we\nemphasize the significance of temporal and spatial information by introducing a\nspatio-temporal relation-enhanced module and a scene representation learning\nmodule, which integrate the the spatio-temporal context of action and global\nscene into the feature map of each granularity. Our method achieved an overall\nF1 score of 47.5\\% on the JRDB-PAR dataset, significantly outperforming all the\nstate-of-the-art methods.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}