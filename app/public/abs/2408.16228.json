{"id":"2408.16228","title":"Policy Adaptation via Language Optimization: Decomposing Tasks for\n  Few-Shot Imitation","authors":"Vivek Myers, Bill Chunyuan Zheng, Oier Mees, Sergey Levine, Kuan Fang","authorsParsed":[["Myers","Vivek",""],["Zheng","Bill Chunyuan",""],["Mees","Oier",""],["Levine","Sergey",""],["Fang","Kuan",""]],"versions":[{"version":"v1","created":"Thu, 29 Aug 2024 03:03:35 GMT"}],"updateDate":"2024-08-30","timestamp":1724900615000,"abstract":"  Learned language-conditioned robot policies often struggle to effectively\nadapt to new real-world tasks even when pre-trained across a diverse set of\ninstructions. We propose a novel approach for few-shot adaptation to unseen\ntasks that exploits the semantic understanding of task decomposition provided\nby vision-language models (VLMs). Our method, Policy Adaptation via Language\nOptimization (PALO), combines a handful of demonstrations of a task with\nproposed language decompositions sampled from a VLM to quickly enable rapid\nnonparametric adaptation, avoiding the need for a larger fine-tuning dataset.\nWe evaluate PALO on extensive real-world experiments consisting of challenging\nunseen, long-horizon robot manipulation tasks. We find that PALO is able of\nconsistently complete long-horizon, multi-tier tasks in the real world,\noutperforming state of the art pre-trained generalist policies, and methods\nthat have access to the same demonstrations.\n","subjects":["Computing Research Repository/Robotics","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"6YMZVT8XN6M6wDfl36iJ2iwPANIQTlMZUdLkrH66J18","pdfSize":"29162481"}
