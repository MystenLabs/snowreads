{"id":"2407.18667","title":"A Labeled Ophthalmic Ultrasound Dataset with Medical Report Generation\n  Based on Cross-modal Deep Learning","authors":"Jing Wang, Junyan Fan, Meng Zhou, Yanzhu Zhang, Mingyu Shi","authorsParsed":[["Wang","Jing",""],["Fan","Junyan",""],["Zhou","Meng",""],["Zhang","Yanzhu",""],["Shi","Mingyu",""]],"versions":[{"version":"v1","created":"Fri, 26 Jul 2024 11:03:18 GMT"}],"updateDate":"2024-07-29","timestamp":1721991798000,"abstract":"  Ultrasound imaging reveals eye morphology and aids in diagnosing and treating\neye diseases. However, interpreting diagnostic reports requires specialized\nphysicians. We present a labeled ophthalmic dataset for the precise analysis\nand the automated exploration of medical images along with their associated\nreports. It collects three modal data, including the ultrasound images, blood\nflow information and examination reports from 2,417 patients at an\nophthalmology hospital in Shenyang, China, during the year 2018, in which the\npatient information is de-identified for privacy protection. To the best of our\nknowledge, it is the only ophthalmic dataset that contains the three modal\ninformation simultaneously. It incrementally consists of 4,858 images with the\ncorresponding free-text reports, which describe 15 typical imaging findings of\nintraocular diseases and the corresponding anatomical locations. Each image\nshows three kinds of blood flow indices at three specific arteries, i.e., nine\nparameter values to describe the spectral characteristics of blood flow\ndistribution. The reports were written by ophthalmologists during the clinical\ncare. The proposed dataset is applied to generate medical report based on the\ncross-modal deep learning model. The experimental results demonstrate that our\ndataset is suitable for training supervised models concerning cross-modal\nmedical data.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}