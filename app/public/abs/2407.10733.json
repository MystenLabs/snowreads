{"id":"2407.10733","title":"Joint-Embedding Predictive Architecture for Self-Supervised Learning of\n  Mask Classification Architecture","authors":"Dong-Hee Kim, Sungduk Cho, Hyeonwoo Cho, Chanmin Park, Jinyoung Kim,\n  Won Hwa Kim","authorsParsed":[["Kim","Dong-Hee",""],["Cho","Sungduk",""],["Cho","Hyeonwoo",""],["Park","Chanmin",""],["Kim","Jinyoung",""],["Kim","Won Hwa",""]],"versions":[{"version":"v1","created":"Mon, 15 Jul 2024 14:01:03 GMT"}],"updateDate":"2024-07-16","timestamp":1721052063000,"abstract":"  In this work, we introduce Mask-JEPA, a self-supervised learning framework\ntailored for mask classification architectures (MCA), to overcome the\ntraditional constraints associated with training segmentation models. Mask-JEPA\ncombines a Joint Embedding Predictive Architecture with MCA to adeptly capture\nintricate semantics and precise object boundaries. Our approach addresses two\ncritical challenges in self-supervised learning: 1) extracting comprehensive\nrepresentations for universal image segmentation from a pixel decoder, and 2)\neffectively training the transformer decoder. The use of the transformer\ndecoder as a predictor within the JEPA framework allows proficient training in\nuniversal image segmentation tasks. Through rigorous evaluations on datasets\nsuch as ADE20K, Cityscapes and COCO, Mask-JEPA demonstrates not only\ncompetitive results but also exceptional adaptability and robustness across\nvarious training scenarios. The architecture-agnostic nature of Mask-JEPA\nfurther underscores its versatility, allowing seamless adaptation to various\nmask classification family.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"raU1Uc_0inWZVy9soIlFe_ZlVEowHJ7VtiA8KucMjoc","pdfSize":"9001389"}
