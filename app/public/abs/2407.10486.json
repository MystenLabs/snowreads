{"id":"2407.10486","title":"IDEAL: Leveraging Infinite and Dynamic Characterizations of Large\n  Language Models for Query-focused Summarization","authors":"Jie Cao, Dian Jiao, Qiang Yan, Wenqiao Zhang, Siliang Tang, Yueting\n  Zhuang","authorsParsed":[["Cao","Jie",""],["Jiao","Dian",""],["Yan","Qiang",""],["Zhang","Wenqiao",""],["Tang","Siliang",""],["Zhuang","Yueting",""]],"versions":[{"version":"v1","created":"Mon, 15 Jul 2024 07:14:56 GMT"}],"updateDate":"2024-07-16","timestamp":1721027696000,"abstract":"  Query-focused summarization (QFS) aims to produce summaries that answer\nparticular questions of interest, enabling greater user control and\npersonalization. With the advent of large language models (LLMs), shows their\nimpressive capability of textual understanding through large-scale pretraining,\nwhich implies the great potential of extractive snippet generation. In this\npaper, we systematically investigated two indispensable characteristics that\nthe LLMs-based QFS models should be harnessed, Lengthy Document Summarization\nand Efficiently Fine-grained Query-LLM Alignment, respectively.\nCorrespondingly, we propose two modules called Query-aware HyperExpert and\nQuery-focused Infini-attention to access the aforementioned characteristics.\nThese innovations pave the way for broader application and accessibility in the\nfield of QFS technology. Extensive experiments conducted on existing QFS\nbenchmarks indicate the effectiveness and generalizability of the proposed\napproach. Our code is publicly available at\nhttps://github.com/DCDmllm/IDEAL_Summary.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}