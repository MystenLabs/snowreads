{"id":"2408.17384","title":"LASSO-MOGAT: A Multi-Omics Graph Attention Framework for Cancer\n  Classification","authors":"Fadi Alharbi, Aleksandar Vakanski, Murtada K. Elbashir, Mohanad\n  Mohammed","authorsParsed":[["Alharbi","Fadi",""],["Vakanski","Aleksandar",""],["Elbashir","Murtada K.",""],["Mohammed","Mohanad",""]],"versions":[{"version":"v1","created":"Fri, 30 Aug 2024 16:26:04 GMT"}],"updateDate":"2024-09-02","timestamp":1725035164000,"abstract":"  The application of machine learning methods to analyze changes in gene\nexpression patterns has recently emerged as a powerful approach in cancer\nresearch, enhancing our understanding of the molecular mechanisms underpinning\ncancer development and progression. Combining gene expression data with other\ntypes of omics data has been reported by numerous works to improve cancer\nclassification outcomes. Despite these advances, effectively integrating\nhigh-dimensional multi-omics data and capturing the complex relationships\nacross different biological layers remains challenging. This paper introduces\nLASSO-MOGAT (LASSO-Multi-Omics Gated ATtention), a novel graph-based deep\nlearning framework that integrates messenger RNA, microRNA, and DNA methylation\ndata to classify 31 cancer types. Utilizing differential expression analysis\nwith LIMMA and LASSO regression for feature selection, and leveraging Graph\nAttention Networks (GATs) to incorporate protein-protein interaction (PPI)\nnetworks, LASSO-MOGAT effectively captures intricate relationships within\nmulti-omics data. Experimental validation using five-fold cross-validation\ndemonstrates the method's precision, reliability, and capacity for providing\ncomprehensive insights into cancer molecular mechanisms. The computation of\nattention coefficients for the edges in the graph by the proposed\ngraph-attention architecture based on protein-protein interactions proved\nbeneficial for identifying synergies in multi-omics data for cancer\nclassification.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}