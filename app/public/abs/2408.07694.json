{"id":"2408.07694","title":"End-to-end Semantic-centric Video-based Multimodal Affective Computing","authors":"Ronghao Lin, Ying Zeng, Sijie Mai and Haifeng Hu","authorsParsed":[["Lin","Ronghao",""],["Zeng","Ying",""],["Mai","Sijie",""],["Hu","Haifeng",""]],"versions":[{"version":"v1","created":"Wed, 14 Aug 2024 17:50:27 GMT"}],"updateDate":"2024-08-15","timestamp":1723657827000,"abstract":"  In the pathway toward Artificial General Intelligence (AGI), understanding\nhuman's affection is essential to enhance machine's cognition abilities. For\nachieving more sensual human-AI interaction, Multimodal Affective Computing\n(MAC) in human-spoken videos has attracted increasing attention. However,\nprevious methods are mainly devoted to designing multimodal fusion algorithms,\nsuffering from two issues: semantic imbalance caused by diverse pre-processing\noperations and semantic mismatch raised by inconsistent affection content\ncontained in different modalities comparing with the multimodal ground truth.\nBesides, the usage of manual features extractors make they fail in building\nend-to-end pipeline for multiple MAC downstream tasks. To address above\nchallenges, we propose a novel end-to-end framework named SemanticMAC to\ncompute multimodal semantic-centric affection for human-spoken videos. We\nfirstly employ pre-trained Transformer model in multimodal data pre-processing\nand design Affective Perceiver module to capture unimodal affective\ninformation. Moreover, we present a semantic-centric approach to unify\nmultimodal representation learning in three ways, including gated feature\ninteraction, multi-task pseudo label generation, and intra-/inter-sample\ncontrastive learning. Finally, SemanticMAC effectively learn specific- and\nshared-semantic representations in the guidance of semantic-centric labels.\nExtensive experimental results demonstrate that our approach surpass the\nstate-of-the-art methods on 7 public datasets in four MAC downstream tasks.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning","Computing Research Repository/Multimedia"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}