{"id":"2408.02192","title":"Unsupervised Domain Adaption Harnessing Vision-Language Pre-training","authors":"Wenlve Zhou and Zhiheng Zhou","authorsParsed":[["Zhou","Wenlve",""],["Zhou","Zhiheng",""]],"versions":[{"version":"v1","created":"Mon, 5 Aug 2024 02:37:59 GMT"}],"updateDate":"2024-08-06","timestamp":1722825479000,"abstract":"  This paper addresses two vital challenges in Unsupervised Domain Adaptation\n(UDA) with a focus on harnessing the power of Vision-Language Pre-training\n(VLP) models. Firstly, UDA has primarily relied on ImageNet pre-trained models.\nHowever, the potential of VLP models in UDA remains largely unexplored. The\nrich representation of VLP models holds significant promise for enhancing UDA\ntasks. To address this, we propose a novel method called Cross-Modal Knowledge\nDistillation (CMKD), leveraging VLP models as teacher models to guide the\nlearning process in the target domain, resulting in state-of-the-art\nperformance. Secondly, current UDA paradigms involve training separate models\nfor each task, leading to significant storage overhead and impractical model\ndeployment as the number of transfer tasks grows. To overcome this challenge,\nwe introduce Residual Sparse Training (RST) exploiting the benefits conferred\nby VLP's extensive pre-training, a technique that requires minimal adjustment\n(approximately 0.1\\%$\\sim$0.5\\%) of VLP model parameters to achieve performance\ncomparable to fine-tuning. Combining CMKD and RST, we present a comprehensive\nsolution that effectively leverages VLP models for UDA tasks while reducing\nstorage overhead for model deployment. Furthermore, CMKD can serve as a\nbaseline in conjunction with other methods like FixMatch, enhancing the\nperformance of UDA. Our proposed method outperforms existing techniques on\nstandard benchmarks. Our code will be available at:\nhttps://github.com/Wenlve-Zhou/VLP-UDA.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}