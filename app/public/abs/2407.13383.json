{"id":"2407.13383","title":"NeuroPlug: Plugging Side-Channel Leaks in NPUs using Space Filling\n  Curves","authors":"Nivedita Shrivastava and Smruti R. Sarangi","authorsParsed":[["Shrivastava","Nivedita",""],["Sarangi","Smruti R.",""]],"versions":[{"version":"v1","created":"Thu, 18 Jul 2024 10:40:41 GMT"}],"updateDate":"2024-07-19","timestamp":1721299241000,"abstract":"  Securing deep neural networks (DNNs) from side-channel attacks is an\nimportant problem as of today, given the substantial investment of time and\nresources in acquiring the raw data and training complex models. All published\ncountermeasures (CMs) add noise N to a signal X (parameter of interest such as\nthe net memory traffic that is leaked). The adversary observes X+N ; we shall\nshow that it is easy to filter this noise out using targeted measurements,\nstatistical analyses and different kinds of reasonably-assumed side\ninformation. We present a novel CM NeuroPlug that is immune to these attack\nmethodologies mainly because we use a different formulation CX + N . We\nintroduce a multiplicative variable C that naturally arises from feature map\ncompression; it plays a key role in obfuscating the parameters of interest. Our\napproach is based on mapping all the computations to a 1-D space filling curve\nand then performing a sequence of tiling, compression and binning-based\nobfuscation operations. We follow up with proposing a theoretical framework\nbased on Mellin transforms that allows us to accurately quantify the size of\nthe search space as a function of the noise we add and the side information\nthat an adversary possesses. The security guarantees provided by NeuroPlug are\nvalidated using a battery of statistical and information theory-based tests. We\nalso demonstrate a substantial performance enhancement of 15% compared to the\nclosest competing work.\n","subjects":["Computing Research Repository/Cryptography and Security"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}