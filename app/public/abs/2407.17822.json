{"id":"2407.17822","title":"Advanced deep-reinforcement-learning methods for flow control:\n  group-invariant and positional-encoding networks improve learning speed and\n  quality","authors":"Joogoo Jeon, Jean Rabault, Joel Vasanth, Francisco\n  Alc\\'antara-\\'Avila, Shilaj Baral, Ricardo Vinuesa","authorsParsed":[["Jeon","Joogoo",""],["Rabault","Jean",""],["Vasanth","Joel",""],["Alcántara-Ávila","Francisco",""],["Baral","Shilaj",""],["Vinuesa","Ricardo",""]],"versions":[{"version":"v1","created":"Thu, 25 Jul 2024 07:24:41 GMT"}],"updateDate":"2024-07-26","timestamp":1721892281000,"abstract":"  Flow control is key to maximize energy efficiency in a wide range of\napplications. However, traditional flow-control methods face significant\nchallenges in addressing non-linear systems and high-dimensional data, limiting\ntheir application in realistic energy systems. This study advances\ndeep-reinforcement-learning (DRL) methods for flow control, particularly\nfocusing on integrating group-invariant networks and positional encoding into\nDRL architectures. Our methods leverage multi-agent reinforcement learning\n(MARL) to exploit policy invariance in space, in combination with\ngroup-invariant networks to ensure local symmetry invariance. Additionally, a\npositional encoding inspired by the transformer architecture is incorporated to\nprovide location information to the agents, mitigating action constraints from\nstrict invariance. The proposed methods are verified using a case study of\nRayleigh-B\\'enard convection, where the goal is to minimize the Nusselt number\nNu. The group-invariant neural networks (GI-NNs) show faster convergence\ncompared to the base MARL, achieving better average policy performance. The\nGI-NNs not only cut DRL training time in half but also notably enhance learning\nreproducibility. Positional encoding further enhances these results,\neffectively reducing the minimum Nu and stabilizing convergence. Interestingly,\ngroup invariant networks specialize in improving learning speed and positional\nencoding specializes in improving learning quality. These results demonstrate\nthat choosing a suitable feature-representation method according to the purpose\nas well as the characteristics of each control problem is essential. We believe\nthat the results of this study will not only inspire novel DRL methods with\ninvariant and unique representations, but also provide useful insights for\nindustrial applications.\n","subjects":["Computing Research Repository/Machine Learning","Physics/Fluid Dynamics"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}