{"id":"2407.08652","title":"DART: A Solution for Decentralized Federated Learning Model Robustness\n  Analysis","authors":"Chao Feng, Alberto Huertas Celdr\\'an, Jan von der Assen, Enrique\n  Tom\\'as Mart\\'inez Beltr\\'an, G\\'er\\^ome Bovet, Burkhard Stiller","authorsParsed":[["Feng","Chao",""],["Celdrán","Alberto Huertas",""],["von der Assen","Jan",""],["Beltrán","Enrique Tomás Martínez",""],["Bovet","Gérôme",""],["Stiller","Burkhard",""]],"versions":[{"version":"v1","created":"Thu, 11 Jul 2024 16:32:06 GMT"}],"updateDate":"2024-07-12","timestamp":1720715526000,"abstract":"  Federated Learning (FL) has emerged as a promising approach to address\nprivacy concerns inherent in Machine Learning (ML) practices. However,\nconventional FL methods, particularly those following the Centralized FL (CFL)\nparadigm, utilize a central server for global aggregation, which exhibits\nlimitations such as bottleneck and single point of failure. To address these\nissues, the Decentralized FL (DFL) paradigm has been proposed, which removes\nthe client-server boundary and enables all participants to engage in model\ntraining and aggregation tasks. Nevertheless, as CFL, DFL remains vulnerable to\nadversarial attacks, notably poisoning attacks that undermine model\nperformance. While existing research on model robustness has predominantly\nfocused on CFL, there is a noteworthy gap in understanding the model robustness\nof the DFL paradigm. In this paper, a thorough review of poisoning attacks\ntargeting the model robustness in DFL systems, as well as their corresponding\ncountermeasures, are presented. Additionally, a solution called DART is\nproposed to evaluate the robustness of DFL models, which is implemented and\nintegrated into a DFL platform. Through extensive experiments, this paper\ncompares the behavior of CFL and DFL under diverse poisoning attacks,\npinpointing key factors affecting attack spread and effectiveness within the\nDFL. It also evaluates the performance of different defense mechanisms and\ninvestigates whether defense mechanisms designed for CFL are compatible with\nDFL. The empirical results provide insights into research challenges and\nsuggest ways to improve the robustness of DFL models for future research.\n","subjects":["Computing Research Repository/Distributed, Parallel, and Cluster Computing"],"license":"http://creativecommons.org/licenses/by/4.0/"}