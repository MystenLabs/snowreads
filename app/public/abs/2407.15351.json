{"id":"2407.15351","title":"LLMExplainer: Large Language Model based Bayesian Inference for Graph\n  Explanation Generation","authors":"Jiaxing Zhang, Jiayi Liu, Dongsheng Luo, Jennifer Neville, Hua Wei","authorsParsed":[["Zhang","Jiaxing",""],["Liu","Jiayi",""],["Luo","Dongsheng",""],["Neville","Jennifer",""],["Wei","Hua",""]],"versions":[{"version":"v1","created":"Mon, 22 Jul 2024 03:36:38 GMT"},{"version":"v2","created":"Tue, 23 Jul 2024 04:01:19 GMT"}],"updateDate":"2024-07-24","timestamp":1721619398000,"abstract":"  Recent studies seek to provide Graph Neural Network (GNN) interpretability\nvia multiple unsupervised learning models. Due to the scarcity of datasets,\ncurrent methods easily suffer from learning bias. To solve this problem, we\nembed a Large Language Model (LLM) as knowledge into the GNN explanation\nnetwork to avoid the learning bias problem. We inject LLM as a Bayesian\nInference (BI) module to mitigate learning bias. The efficacy of the BI module\nhas been proven both theoretically and experimentally. We conduct experiments\non both synthetic and real-world datasets. The innovation of our work lies in\ntwo parts: 1. We provide a novel view of the possibility of an LLM functioning\nas a Bayesian inference to improve the performance of existing algorithms; 2.\nWe are the first to discuss the learning bias issues in the GNN explanation\nproblem.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}