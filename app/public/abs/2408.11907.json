{"id":"2408.11907","title":"Higher-order Interpretations of Deepcode, a Learned Feedback Code","authors":"Yingyao Zhou, Natasha Devroye, Gyorgy Turan, Milos Zefran","authorsParsed":[["Zhou","Yingyao",""],["Devroye","Natasha",""],["Turan","Gyorgy",""],["Zefran","Milos",""]],"versions":[{"version":"v1","created":"Wed, 21 Aug 2024 18:00:56 GMT"}],"updateDate":"2024-08-23","timestamp":1724263256000,"abstract":"  We present an interpretation of Deepcode, a learned feedback code that\nshowcases higher-order error correction relative to an earlier interpretable\nmodel. By interpretation, we mean succinct analytical encoder and decoder\nexpressions (albeit with learned parameters) in which the role of feedback in\nachieving error correction is easy to understand. By higher-order, we mean that\nlonger sequences of large noise values are acted upon by the encoder (which has\naccess to these through the feedback) and used in error correction at the\ndecoder in a two-stage decoding process.\n","subjects":["Computing Research Repository/Information Theory","Mathematics/Information Theory"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}