{"id":"2407.07342","title":"Multilingual Blending: LLM Safety Alignment Evaluation with Language\n  Mixture","authors":"Jiayang Song, Yuheng Huang, Zhehua Zhou, Lei Ma","authorsParsed":[["Song","Jiayang",""],["Huang","Yuheng",""],["Zhou","Zhehua",""],["Ma","Lei",""]],"versions":[{"version":"v1","created":"Wed, 10 Jul 2024 03:26:15 GMT"}],"updateDate":"2024-07-11","timestamp":1720581975000,"abstract":"  As safety remains a crucial concern throughout the development lifecycle of\nLarge Language Models (LLMs), researchers and industrial practitioners have\nincreasingly focused on safeguarding and aligning LLM behaviors with human\npreferences and ethical standards. LLMs, trained on extensive multilingual\ncorpora, exhibit powerful generalization abilities across diverse languages and\ndomains. However, current safety alignment practices predominantly focus on\nsingle-language scenarios, which leaves their effectiveness in complex\nmultilingual contexts, especially for those complex mixed-language formats,\nlargely unexplored. In this study, we introduce Multilingual Blending, a\nmixed-language query-response scheme designed to evaluate the safety alignment\nof various state-of-the-art LLMs (e.g., GPT-4o, GPT-3.5, Llama3) under\nsophisticated, multilingual conditions. We further investigate language\npatterns such as language availability, morphology, and language family that\ncould impact the effectiveness of Multilingual Blending in compromising the\nsafeguards of LLMs. Our experimental results show that, without meticulously\ncrafted prompt templates, Multilingual Blending significantly amplifies the\ndetriment of malicious queries, leading to dramatically increased bypass rates\nin LLM safety alignment (67.23% on GPT-3.5 and 40.34% on GPT-4o), far exceeding\nthose of single-language baselines. Moreover, the performance of Multilingual\nBlending varies notably based on intrinsic linguistic properties, with\nlanguages of different morphology and from diverse families being more prone to\nevading safety alignments. These findings underscore the necessity of\nevaluating LLMs and developing corresponding safety alignment strategies in a\ncomplex, multilingual context to align with their superior cross-language\ngeneralization capabilities.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}