{"id":"2408.11748","title":"GeoMeter: Probing Depth and Height Perception of Large Visual-Language\n  Models","authors":"Shehreen Azad, Yash Jain, Rishit Garg, Yogesh S Rawat, Vibhav Vineet","authorsParsed":[["Azad","Shehreen",""],["Jain","Yash",""],["Garg","Rishit",""],["Rawat","Yogesh S",""],["Vineet","Vibhav",""]],"versions":[{"version":"v1","created":"Wed, 21 Aug 2024 16:16:18 GMT"},{"version":"v2","created":"Thu, 22 Aug 2024 18:49:48 GMT"},{"version":"v3","created":"Fri, 30 Aug 2024 13:52:12 GMT"}],"updateDate":"2024-09-02","timestamp":1724256978000,"abstract":"  Geometric understanding is crucial for navigating and interacting with our\nenvironment. While large Vision Language Models (VLMs) demonstrate impressive\ncapabilities, deploying them in real-world scenarios necessitates a comparable\ngeometric understanding in visual perception. In this work, we focus on the\ngeometric comprehension of these models; specifically targeting the depths and\nheights of objects within a scene. Our observations reveal that, although VLMs\nexcel in basic geometric properties perception such as shape and size, they\nencounter significant challenges in reasoning about the depth and height of\nobjects. To address this, we introduce GeoMeter, a suite of benchmark datasets\nencompassing Synthetic 2D, Synthetic 3D, and Real-World scenarios to rigorously\nevaluate these aspects. We benchmark 17 state-of-the-art VLMs using these\ndatasets and find that they consistently struggle with both depth and height\nperception. Our key insights include detailed analyses of the shortcomings in\ndepth and height reasoning capabilities of VLMs and the inherent bias present\nin these models. This study aims to pave the way for the development of VLMs\nwith enhanced geometric understanding, crucial for real-world applications.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"maSoovISE3VKfezlH7G3OL0ajdvLqqoYoxbkAu3Oo6U","pdfSize":"21478168"}
