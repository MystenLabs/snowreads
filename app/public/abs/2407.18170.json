{"id":"2407.18170","title":"RIDA: A Robust Attack Framework on Incomplete Graphs","authors":"Jianke Yu, Hanchen Wang, Chen Chen, Xiaoyang Wang, Wenjie Zhang, Ying\n  Zhang","authorsParsed":[["Yu","Jianke",""],["Wang","Hanchen",""],["Chen","Chen",""],["Wang","Xiaoyang",""],["Zhang","Wenjie",""],["Zhang","Ying",""]],"versions":[{"version":"v1","created":"Thu, 25 Jul 2024 16:33:35 GMT"}],"updateDate":"2024-07-26","timestamp":1721925215000,"abstract":"  Graph Neural Networks (GNNs) are vital in data science but are increasingly\nsusceptible to adversarial attacks. To help researchers develop more robust GNN\nmodels, it's essential to focus on designing strong attack models as\nfoundational benchmarks and guiding references. Among adversarial attacks,\ngray-box poisoning attacks are noteworthy due to their effectiveness and fewer\nconstraints. These attacks exploit GNNs' need for retraining on updated data,\nthereby impacting their performance by perturbing these datasets. However,\ncurrent research overlooks the real-world scenario of incomplete graphs.To\naddress this gap, we introduce the Robust Incomplete Deep Attack Framework\n(RIDA). It is the first algorithm for robust gray-box poisoning attacks on\nincomplete graphs. The approach innovatively aggregates distant vertex\ninformation and ensures powerful data utilization.Extensive tests against 9\nSOTA baselines on 3 real-world datasets demonstrate RIDA's superiority in\nhandling incompleteness and high attack performance on the incomplete graph.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}