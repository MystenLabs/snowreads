{"id":"2407.20657","title":"Prompt-Driven Contrastive Learning for Transferable Adversarial Attacks","authors":"Hunmin Yang, Jongoh Jeong, Kuk-Jin Yoon","authorsParsed":[["Yang","Hunmin",""],["Jeong","Jongoh",""],["Yoon","Kuk-Jin",""]],"versions":[{"version":"v1","created":"Tue, 30 Jul 2024 08:52:16 GMT"}],"updateDate":"2024-07-31","timestamp":1722329536000,"abstract":"  Recent vision-language foundation models, such as CLIP, have demonstrated\nsuperior capabilities in learning representations that can be transferable\nacross diverse range of downstream tasks and domains. With the emergence of\nsuch powerful models, it has become crucial to effectively leverage their\ncapabilities in tackling challenging vision tasks. On the other hand, only a\nfew works have focused on devising adversarial examples that transfer well to\nboth unknown domains and model architectures. In this paper, we propose a novel\ntransfer attack method called PDCL-Attack, which leverages the CLIP model to\nenhance the transferability of adversarial perturbations generated by a\ngenerative model-based attack framework. Specifically, we formulate an\neffective prompt-driven feature guidance by harnessing the semantic\nrepresentation power of text, particularly from the ground-truth class labels\nof input images. To the best of our knowledge, we are the first to introduce\nprompt learning to enhance the transferable generative attacks. Extensive\nexperiments conducted across various cross-domain and cross-model settings\nempirically validate our approach, demonstrating its superiority over\nstate-of-the-art methods.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}