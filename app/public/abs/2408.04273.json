{"id":"2408.04273","title":"SG-JND: Semantic-Guided Just Noticeable Distortion Predictor For Image\n  Compression","authors":"Linhan Cao, Wei Sun, Xiongkuo Min, Jun Jia, Zicheng Zhang, Zijian\n  Chen, Yucheng Zhu, Lizhou Liu, Qiubo Chen, Jing Chen, Guangtao Zhai","authorsParsed":[["Cao","Linhan",""],["Sun","Wei",""],["Min","Xiongkuo",""],["Jia","Jun",""],["Zhang","Zicheng",""],["Chen","Zijian",""],["Zhu","Yucheng",""],["Liu","Lizhou",""],["Chen","Qiubo",""],["Chen","Jing",""],["Zhai","Guangtao",""]],"versions":[{"version":"v1","created":"Thu, 8 Aug 2024 07:14:57 GMT"}],"updateDate":"2024-08-09","timestamp":1723101297000,"abstract":"  Just noticeable distortion (JND), representing the threshold of distortion in\nan image that is minimally perceptible to the human visual system (HVS), is\ncrucial for image compression algorithms to achieve a trade-off between\ntransmission bit rate and image quality. However, traditional JND prediction\nmethods only rely on pixel-level or sub-band level features, lacking the\nability to capture the impact of image content on JND. To bridge this gap, we\npropose a Semantic-Guided JND (SG-JND) network to leverage semantic information\nfor JND prediction. In particular, SG-JND consists of three essential modules:\nthe image preprocessing module extracts semantic-level patches from images, the\nfeature extraction module extracts multi-layer features by utilizing the\ncross-scale attention layers, and the JND prediction module regresses the\nextracted features into the final JND value. Experimental results show that\nSG-JND achieves the state-of-the-art performance on two publicly available JND\ndatasets, which demonstrates the effectiveness of SG-JND and highlight the\nsignificance of incorporating semantic information in JND assessment.\n","subjects":["Electrical Engineering and Systems Science/Image and Video Processing","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}