{"id":"2407.10108","title":"Advancing Continual Learning for Robust Deepfake Audio Classification","authors":"Feiyi Dong and Qingchen Tang and Yichen Bai and Zihan Wang","authorsParsed":[["Dong","Feiyi",""],["Tang","Qingchen",""],["Bai","Yichen",""],["Wang","Zihan",""]],"versions":[{"version":"v1","created":"Sun, 14 Jul 2024 07:32:24 GMT"}],"updateDate":"2024-07-16","timestamp":1720942344000,"abstract":"  The emergence of new spoofing attacks poses an increasing challenge to audio\nsecurity. Current detection methods often falter when faced with unseen\nspoofing attacks. Traditional strategies, such as retraining with new data, are\nnot always feasible due to extensive storage. This paper introduces a novel\ncontinual learning method Continual Audio Defense Enhancer (CADE). First, by\nutilizing a fixed memory size to store randomly selected samples from previous\ndatasets, our approach conserves resources and adheres to privacy constraints.\nAdditionally, we also apply two distillation losses in CADE. By distillation in\nclassifiers, CADE ensures that the student model closely resembles that of the\nteacher model. This resemblance helps the model retain old information while\nfacing unseen data. We further refine our model's performance with a novel\nembedding similarity loss that extends across multiple depth layers,\nfacilitating superior positive sample alignment. Experiments conducted on the\nASVspoof2019 dataset show that our proposed method outperforms the baseline\nmethods.\n","subjects":["Electrical Engineering and Systems Science/Audio and Speech Processing","Computing Research Repository/Sound"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"7eDzZzd4OFlCwCxH-6oQuTsO_0bmquoXzUtpnMpYzbE","pdfSize":"420945"}
