{"id":"2408.07467","title":"Domain-invariant Representation Learning via Segment Anything Model for\n  Blood Cell Classification","authors":"Yongcheng Li, Lingcong Cai, Ying Lu, Cheng Lin, Yupeng Zhang, Jingyan\n  Jiang, Genan Dai, Bowen Zhang, Jingzhou Cao, Xiangzhong Zhang, and Xiaomao\n  Fan","authorsParsed":[["Li","Yongcheng",""],["Cai","Lingcong",""],["Lu","Ying",""],["Lin","Cheng",""],["Zhang","Yupeng",""],["Jiang","Jingyan",""],["Dai","Genan",""],["Zhang","Bowen",""],["Cao","Jingzhou",""],["Zhang","Xiangzhong",""],["Fan","Xiaomao",""]],"versions":[{"version":"v1","created":"Wed, 14 Aug 2024 11:24:13 GMT"}],"updateDate":"2024-08-15","timestamp":1723634653000,"abstract":"  Accurate classification of blood cells is of vital significance in the\ndiagnosis of hematological disorders. However, in real-world scenarios, domain\nshifts caused by the variability in laboratory procedures and settings, result\nin a rapid deterioration of the model's generalization performance. To address\nthis issue, we propose a novel framework of domain-invariant representation\nlearning (DoRL) via segment anything model (SAM) for blood cell classification.\nThe DoRL comprises two main components: a LoRA-based SAM (LoRA-SAM) and a\ncross-domain autoencoder (CAE). The advantage of DoRL is that it can extract\ndomain-invariant representations from various blood cell datasets in an\nunsupervised manner. Specifically, we first leverage the large-scale foundation\nmodel of SAM, fine-tuned with LoRA, to learn general image embeddings and\nsegment blood cells. Additionally, we introduce CAE to learn domain-invariant\nrepresentations across different-domain datasets while mitigating images'\nartifacts. To validate the effectiveness of domain-invariant representations,\nwe employ five widely used machine learning classifiers to construct blood cell\nclassification models. Experimental results on two public blood cell datasets\nand a private real dataset demonstrate that our proposed DoRL achieves a new\nstate-of-the-art cross-domain performance, surpassing existing methods by a\nsignificant margin. The source code can be available at the URL\n(https://github.com/AnoK3111/DoRL).\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}