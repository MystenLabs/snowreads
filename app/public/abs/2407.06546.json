{"id":"2407.06546","title":"Exploring the Causality of End-to-End Autonomous Driving","authors":"Jiankun Li, Hao Li, Jiangjiang Liu, Zhikang Zou, Xiaoqing Ye, Fan\n  Wang, Jizhou Huang, Hua Wu, Haifeng Wang","authorsParsed":[["Li","Jiankun",""],["Li","Hao",""],["Liu","Jiangjiang",""],["Zou","Zhikang",""],["Ye","Xiaoqing",""],["Wang","Fan",""],["Huang","Jizhou",""],["Wu","Hua",""],["Wang","Haifeng",""]],"versions":[{"version":"v1","created":"Tue, 9 Jul 2024 04:56:11 GMT"},{"version":"v2","created":"Fri, 19 Jul 2024 11:52:15 GMT"}],"updateDate":"2024-07-22","timestamp":1720500971000,"abstract":"  Deep learning-based models are widely deployed in autonomous driving areas,\nespecially the increasingly noticed end-to-end solutions. However, the\nblack-box property of these models raises concerns about their trustworthiness\nand safety for autonomous driving, and how to debug the causality has become a\npressing concern. Despite some existing research on the explainability of\nautonomous driving, there is currently no systematic solution to help\nresearchers debug and identify the key factors that lead to the final predicted\naction of end-to-end autonomous driving. In this work, we propose a\ncomprehensive approach to explore and analyze the causality of end-to-end\nautonomous driving. First, we validate the essential information that the final\nplanning depends on by using controlled variables and counterfactual\ninterventions for qualitative analysis. Then, we quantitatively assess the\nfactors influencing model decisions by visualizing and statistically analyzing\nthe response of key model inputs. Finally, based on the comprehensive study of\nthe multi-factorial end-to-end autonomous driving system, we have developed a\nstrong baseline and a tool for exploring causality in the close-loop simulator\nCARLA. It leverages the essential input sources to obtain a well-designed\nmodel, resulting in highly competitive capabilities. As far as we know, our\nwork is the first to unveil the mystery of end-to-end autonomous driving and\nturn the black box into a white one. Thorough close-loop experiments\ndemonstrate that our method can be applied to end-to-end autonomous driving\nsolutions for causality debugging. Code will be available at\nhttps://github.com/bdvisl/DriveInsight.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Robotics"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}