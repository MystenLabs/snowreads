{"id":"2408.12578","title":"A Percolation Model of Emergence: Analyzing Transformers Trained on a\n  Formal Language","authors":"Ekdeep Singh Lubana, Kyogo Kawaguchi, Robert P. Dick, Hidenori Tanaka","authorsParsed":[["Lubana","Ekdeep Singh",""],["Kawaguchi","Kyogo",""],["Dick","Robert P.",""],["Tanaka","Hidenori",""]],"versions":[{"version":"v1","created":"Thu, 22 Aug 2024 17:44:22 GMT"},{"version":"v2","created":"Sat, 7 Sep 2024 20:10:28 GMT"}],"updateDate":"2024-09-10","timestamp":1724348662000,"abstract":"  Increase in data, size, or compute can lead to sudden learning of specific\ncapabilities by a neural network -- a phenomenon often called \"emergence''.\nBeyond scientific understanding, establishing the causal factors underlying\nsuch emergent capabilities is crucial to enable risk regulation frameworks for\nAI. In this work, we seek inspiration from study of emergent properties in\nother fields and propose a phenomenological definition for the concept in the\ncontext of neural networks. Our definition implicates the acquisition of\ngeneral structures underlying the data-generating process as a cause of sudden\nperformance growth for specific, narrower tasks. We empirically investigate\nthis definition by proposing an experimental system grounded in a\ncontext-sensitive formal language and find that Transformers trained to perform\ntasks on top of strings from this language indeed exhibit emergent\ncapabilities. Specifically, we show that once the language's underlying grammar\nand context-sensitivity inducing structures are learned by the model,\nperformance on narrower tasks suddenly begins to improve. We then analogize our\nnetwork's learning dynamics with the process of percolation on a bipartite\ngraph, establishing a formal phase transition model that predicts the shift in\nthe point of emergence observed in our experiments when changing the data\nstructure. Overall, our experimental and theoretical frameworks yield a step\ntowards better defining, characterizing, and predicting emergence in neural\nnetworks.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}