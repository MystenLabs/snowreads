{"id":"2408.01945","title":"Generalized Maximum Likelihood Estimation for Perspective-n-Point\n  Problem","authors":"Tian Zhan, Chunfeng Xu, Cheng Zhang and Ke Zhu","authorsParsed":[["Zhan","Tian",""],["Xu","Chunfeng",""],["Zhang","Cheng",""],["Zhu","Ke",""]],"versions":[{"version":"v1","created":"Sun, 4 Aug 2024 07:06:04 GMT"}],"updateDate":"2024-08-06","timestamp":1722755164000,"abstract":"  The Perspective-n-Point (PnP) problem has been widely studied in the\nliterature and applied in various vision-based pose estimation scenarios.\nHowever, existing methods ignore the anisotropy uncertainty of observations, as\ndemonstrated in several real-world datasets in this paper. This oversight may\nlead to suboptimal and inaccurate estimation, particularly in the presence of\nnoisy observations. To this end, we propose a generalized maximum likelihood\nPnP solver, named GMLPnP, that minimizes the determinant criterion by iterating\nthe GLS procedure to estimate the pose and uncertainty simultaneously. Further,\nthe proposed method is decoupled from the camera model. Results of synthetic\nand real experiments show that our method achieves better accuracy in common\npose estimation scenarios, GMLPnP improves rotation/translation accuracy by\n4.7%/2.0% on TUM-RGBD and 18.6%/18.4% on KITTI-360 dataset compared to the best\nbaseline. It is more accurate under very noisy observations in a vision-based\nUAV localization task, outperforming the best baseline by 34.4% in translation\nestimation accuracy.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Robotics"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}