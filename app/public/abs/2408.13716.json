{"id":"2408.13716","title":"FreqINR: Frequency Consistency for Implicit Neural Representation with\n  Adaptive DCT Frequency Loss","authors":"Meiyi Wei, Liu Xie, Ying Sun, Gang Chen","authorsParsed":[["Wei","Meiyi",""],["Xie","Liu",""],["Sun","Ying",""],["Chen","Gang",""]],"versions":[{"version":"v1","created":"Sun, 25 Aug 2024 03:53:17 GMT"}],"updateDate":"2024-08-27","timestamp":1724557997000,"abstract":"  Recent advancements in local Implicit Neural Representation (INR) demonstrate\nits exceptional capability in handling images at various resolutions. However,\nfrequency discrepancies between high-resolution (HR) and ground-truth images,\nespecially at larger scales, result in significant artifacts and blurring in HR\nimages. This paper introduces Frequency Consistency for Implicit Neural\nRepresentation (FreqINR), an innovative Arbitrary-scale Super-resolution method\naimed at enhancing detailed textures by ensuring spectral consistency\nthroughout both training and inference. During training, we employ Adaptive\nDiscrete Cosine Transform Frequency Loss (ADFL) to minimize the frequency gap\nbetween HR and ground-truth images, utilizing 2-Dimensional DCT bases and\nfocusing dynamically on challenging frequencies. During inference, we extend\nthe receptive field to preserve spectral coherence between low-resolution (LR)\nand ground-truth images, which is crucial for the model to generate\nhigh-frequency details from LR counterparts. Experimental results show that\nFreqINR, as a lightweight approach, achieves state-of-the-art performance\ncompared to existing Arbitrary-scale Super-resolution methods and offers\nnotable improvements in computational efficiency. The code for our method will\nbe made publicly available.\n","subjects":["Electrical Engineering and Systems Science/Image and Video Processing","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}