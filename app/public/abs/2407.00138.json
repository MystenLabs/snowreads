{"id":"2407.00138","title":"Analyzing Quality, Bias, and Performance in Text-to-Image Generative\n  Models","authors":"Nila Masrourisaadat, Nazanin Sedaghatkish, Fatemeh Sarshartehrani and\n  Edward A. Fox","authorsParsed":[["Masrourisaadat","Nila",""],["Sedaghatkish","Nazanin",""],["Sarshartehrani","Fatemeh",""],["Fox","Edward A.",""]],"versions":[{"version":"v1","created":"Fri, 28 Jun 2024 14:10:42 GMT"}],"updateDate":"2024-07-02","timestamp":1719583842000,"abstract":"  Advances in generative models have led to significant interest in image\nsynthesis, demonstrating the ability to generate high-quality images for a\ndiverse range of text prompts. Despite this progress, most studies ignore the\npresence of bias. In this paper, we examine several text-to-image models not\nonly by qualitatively assessing their performance in generating accurate images\nof human faces, groups, and specified numbers of objects but also by presenting\na social bias analysis. As expected, models with larger capacity generate\nhigher-quality images. However, we also document the inherent gender or social\nbiases these models possess, offering a more complete understanding of their\nimpact and limitations.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"KoqJOoUOpjOJZJ2dqDrLACKvtCLz9MitSPUYvQj6H8w","pdfSize":"3564385"}
