{"id":"2408.13426","title":"Optimal Layer Selection for Latent Data Augmentation","authors":"Tomoumi Takase, Ryo Karakida","authorsParsed":[["Takase","Tomoumi",""],["Karakida","Ryo",""]],"versions":[{"version":"v1","created":"Sat, 24 Aug 2024 01:38:38 GMT"}],"updateDate":"2024-08-27","timestamp":1724463518000,"abstract":"  While data augmentation (DA) is generally applied to input data, several\nstudies have reported that applying DA to hidden layers in neural networks,\ni.e., feature augmentation, can improve performance. However, in previous\nstudies, the layers to which DA is applied have not been carefully considered,\noften being applied randomly and uniformly or only to a specific layer, leaving\nroom for arbitrariness. Thus, in this study, we investigated the trends of\nsuitable layers for applying DA in various experimental configurations, e.g.,\ntraining from scratch, transfer learning, various dataset settings, and\ndifferent models. In addition, to adjust the suitable layers for DA\nautomatically, we propose the adaptive layer selection (AdaLASE) method, which\nupdates the ratio to perform DA for each layer based on the gradient descent\nmethod during training. The experimental results obtained on several image\nclassification datasets indicate that the proposed AdaLASE method altered the\nratio as expected and achieved high overall test accuracy.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}