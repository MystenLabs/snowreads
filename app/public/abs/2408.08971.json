{"id":"2408.08971","title":"A Multi-Task and Multi-Label Classification Model for Implicit Discourse\n  Relation Recognition","authors":"Nelson Filipe Costa, Leila Kosseim","authorsParsed":[["Costa","Nelson Filipe",""],["Kosseim","Leila",""]],"versions":[{"version":"v1","created":"Fri, 16 Aug 2024 18:47:08 GMT"}],"updateDate":"2024-08-20","timestamp":1723834028000,"abstract":"  In this work, we address the inherent ambiguity in Implicit Discourse\nRelation Recognition (IDRR) by introducing a novel multi-task classification\nmodel capable of learning both multi-label and single-label representations of\ndiscourse relations. Leveraging the DiscoGeM corpus, we train and evaluate our\nmodel on both multi-label and traditional single-label classification tasks. To\nthe best of our knowledge, our work presents the first truly multi-label\nclassifier in IDRR, establishing a benchmark for multi-label classification and\nachieving SOTA results in single-label classification on DiscoGeM.\nAdditionally, we evaluate our model on the PDTB 3.0 corpus for single-label\nclassification without any prior exposure to its data. While the performance is\nbelow the current SOTA, our model demonstrates promising results indicating\npotential for effective transfer learning across both corpora.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/"}