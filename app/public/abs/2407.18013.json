{"id":"2407.18013","title":"Self-Supervision Improves Diffusion Models for Tabular Data Imputation","authors":"Yixin Liu, Thalaiyasingam Ajanthan, Hisham Husain, Vu Nguyen","authorsParsed":[["Liu","Yixin",""],["Ajanthan","Thalaiyasingam",""],["Husain","Hisham",""],["Nguyen","Vu",""]],"versions":[{"version":"v1","created":"Thu, 25 Jul 2024 13:06:30 GMT"}],"updateDate":"2024-07-26","timestamp":1721912790000,"abstract":"  The ubiquity of missing data has sparked considerable attention and focus on\ntabular data imputation methods. Diffusion models, recognized as the\ncutting-edge technique for data generation, demonstrate significant potential\nin tabular data imputation tasks. However, in pursuit of diversity, vanilla\ndiffusion models often exhibit sensitivity to initialized noises, which hinders\nthe models from generating stable and accurate imputation results.\nAdditionally, the sparsity inherent in tabular data poses challenges for\ndiffusion models in accurately modeling the data manifold, impacting the\nrobustness of these models for data imputation. To tackle these challenges,\nthis paper introduces an advanced diffusion model named Self-supervised\nimputation Diffusion Model (SimpDM for brevity), specifically tailored for\ntabular data imputation tasks. To mitigate sensitivity to noise, we introduce a\nself-supervised alignment mechanism that aims to regularize the model, ensuring\nconsistent and stable imputation predictions. Furthermore, we introduce a\ncarefully devised state-dependent data augmentation strategy within SimpDM,\nenhancing the robustness of the diffusion model when dealing with limited data.\nExtensive experiments demonstrate that SimpDM matches or outperforms\nstate-of-the-art imputation methods across various scenarios.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}