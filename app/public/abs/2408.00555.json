{"id":"2408.00555","title":"Alleviating Hallucination in Large Vision-Language Models with Active\n  Retrieval Augmentation","authors":"Xiaoye Qu, Qiyuan Chen, Wei Wei, Jishuo Sun, Jianfeng Dong","authorsParsed":[["Qu","Xiaoye",""],["Chen","Qiyuan",""],["Wei","Wei",""],["Sun","Jishuo",""],["Dong","Jianfeng",""]],"versions":[{"version":"v1","created":"Thu, 1 Aug 2024 13:38:58 GMT"}],"updateDate":"2024-08-02","timestamp":1722519538000,"abstract":"  Despite the remarkable ability of large vision-language models (LVLMs) in\nimage comprehension, these models frequently generate plausible yet factually\nincorrect responses, a phenomenon known as hallucination.Recently, in large\nlanguage models (LLMs), augmenting LLMs by retrieving information from external\nknowledge resources has been proven as a promising solution to mitigate\nhallucinations.However, the retrieval augmentation in LVLM significantly lags\nbehind the widespread applications of LVLM. Moreover, when transferred to\naugmenting LVLMs, sometimes the hallucination degree of the model is even\nexacerbated.Motivated by the research gap and counter-intuitive phenomenon, we\nintroduce a novel framework, the Active Retrieval-Augmented large\nvision-language model (ARA), specifically designed to address hallucinations by\nincorporating three critical dimensions: (i) dissecting the retrieval targets\nbased on the inherent hierarchical structures of images. (ii) pinpointing the\nmost effective retrieval methods and filtering out the reliable retrieval\nresults. (iii) timing the retrieval process to coincide with episodes of low\ncertainty, while circumventing unnecessary retrieval during periods of high\ncertainty. To assess the capability of our proposed ARA model in reducing\nhallucination, we employ three widely used LVLM models (LLaVA-1.5, Qwen-VL, and\nmPLUG-Owl2) across four benchmarks. Our empirical observations suggest that by\nutilizing fitting retrieval mechanisms and timing the retrieval judiciously, we\ncan effectively mitigate the hallucination problem. We hope that this study can\nprovide deeper insights into how to adapt the retrieval augmentation to LVLMs\nfor reducing hallucinations with more effective retrieval and minimal retrieval\noccurrences.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/"}