{"id":"2407.00390","title":"Advancing Process Verification for Large Language Models via Tree-Based\n  Preference Learning","authors":"Mingqian He, Yongliang Shen, Wenqi Zhang, Zeqi Tan, Weiming Lu","authorsParsed":[["He","Mingqian",""],["Shen","Yongliang",""],["Zhang","Wenqi",""],["Tan","Zeqi",""],["Lu","Weiming",""]],"versions":[{"version":"v1","created":"Sat, 29 Jun 2024 10:09:49 GMT"}],"updateDate":"2024-07-02","timestamp":1719655789000,"abstract":"  Large Language Models (LLMs) have demonstrated remarkable potential in\nhandling complex reasoning tasks by generating step-by-step rationales.Some\nmethods have proven effective in boosting accuracy by introducing extra\nverifiers to assess these paths. However, existing verifiers, typically trained\non binary-labeled reasoning paths, fail to fully utilize the relative merits of\nintermediate steps, thereby limiting the effectiveness of the feedback\nprovided. To overcome this limitation, we propose Tree-based Preference\nLearning Verifier (Tree-PLV), a novel approach that constructs reasoning trees\nvia a best-first search algorithm and collects step-level paired data for\npreference training. Compared to traditional binary classification, step-level\npreferences more finely capture the nuances between reasoning steps, allowing\nfor a more precise evaluation of the complete reasoning path. We empirically\nevaluate Tree-PLV across a range of arithmetic and commonsense reasoning tasks,\nwhere it significantly outperforms existing benchmarks. For instance, Tree-PLV\nachieved substantial performance gains over the Mistral-7B self-consistency\nbaseline on GSM8K (67.55% to 82.79%), MATH (17.00% to 26.80%), CSQA (68.14% to\n72.97%), and StrategyQA (82.86% to 83.25%).Additionally, our study explores the\nappropriate granularity for applying preference learning, revealing that\nstep-level guidance provides feedback that better aligns with the evaluation of\nthe reasoning process.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}