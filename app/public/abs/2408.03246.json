{"id":"2408.03246","title":"Making Long-Context Language Models Better Multi-Hop Reasoners","authors":"Yanyang Li, Shuo Liang, Michael R. Lyu, Liwei Wang","authorsParsed":[["Li","Yanyang",""],["Liang","Shuo",""],["Lyu","Michael R.",""],["Wang","Liwei",""]],"versions":[{"version":"v1","created":"Tue, 6 Aug 2024 15:06:40 GMT"}],"updateDate":"2024-08-07","timestamp":1722956800000,"abstract":"  Recent advancements in long-context modeling have enhanced language models\n(LMs) for complex tasks across multiple NLP applications. Despite this\nprogress, we find that these models struggle with multi-hop reasoning and\nexhibit decreased performance in the presence of noisy contexts. In this paper,\nwe introduce Reasoning with Attributions, a novel approach that prompts LMs to\nsupply attributions for each assertion during their reasoning. We validate our\napproach through experiments on three multi-hop datasets, employing both\nproprietary and open-source models, and demonstrate its efficacy and\nresilience. Furthermore, we explore methods to augment reasoning capabilities\nvia fine-tuning and offer an attribution-annotated dataset and a specialized\ntraining strategy. Our fine-tuned model achieves competitive performance on\nmulti-hop reasoning benchmarks, closely paralleling proprietary LMs such as\nChatGPT and Claude-instant.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}