{"id":"2408.04367","title":"MultiViPerFrOG: A Globally Optimized Multi-Viewpoint Perception\n  Framework for Camera Motion and Tissue Deformation","authors":"Guido Caccianiga, Julian Nubert, Cesar Cadena, Marco Hutter, and\n  Katherine J. Kuchenbecker","authorsParsed":[["Caccianiga","Guido",""],["Nubert","Julian",""],["Cadena","Cesar",""],["Hutter","Marco",""],["Kuchenbecker","Katherine J.",""]],"versions":[{"version":"v1","created":"Thu, 8 Aug 2024 10:55:55 GMT"}],"updateDate":"2024-08-09","timestamp":1723114555000,"abstract":"  Reconstructing the 3D shape of a deformable environment from the information\ncaptured by a moving depth camera is highly relevant to surgery. The underlying\nchallenge is the fact that simultaneously estimating camera motion and tissue\ndeformation in a fully deformable scene is an ill-posed problem, especially\nfrom a single arbitrarily moving viewpoint. Current solutions are often\norgan-specific and lack the robustness required to handle large deformations.\nHere we propose a multi-viewpoint global optimization framework that can\nflexibly integrate the output of low-level perception modules (data\nassociation, depth, and relative scene flow) with kinematic and scene-modeling\npriors to jointly estimate multiple camera motions and absolute scene flow. We\nuse simulated noisy data to show three practical examples that successfully\nconstrain the convergence to a unique solution. Overall, our method shows\nrobustness to combined noisy input measures and can process hundreds of points\nin a few milliseconds. MultiViPerFrOG builds a generalized learning-free\nscaffolding for spatio-temporal encoding that can unlock advanced surgical\nscene representations and will facilitate the development of the\ncomputer-assisted-surgery technologies of the future.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}