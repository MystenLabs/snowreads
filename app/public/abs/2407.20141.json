{"id":"2407.20141","title":"DDAP: Dual-Domain Anti-Personalization against Text-to-Image Diffusion\n  Models","authors":"Jing Yang, Runping Xi, Yingxin Lai, Xun Lin, Zitong Yu","authorsParsed":[["Yang","Jing",""],["Xi","Runping",""],["Lai","Yingxin",""],["Lin","Xun",""],["Yu","Zitong",""]],"versions":[{"version":"v1","created":"Mon, 29 Jul 2024 16:11:21 GMT"}],"updateDate":"2024-07-30","timestamp":1722269481000,"abstract":"  Diffusion-based personalized visual content generation technologies have\nachieved significant breakthroughs, allowing for the creation of specific\nobjects by just learning from a few reference photos. However, when misused to\nfabricate fake news or unsettling content targeting individuals, these\ntechnologies could cause considerable societal harm. To address this problem,\ncurrent methods generate adversarial samples by adversarially maximizing the\ntraining loss, thereby disrupting the output of any personalized generation\nmodel trained with these samples. However, the existing methods fail to achieve\neffective defense and maintain stealthiness, as they overlook the intrinsic\nproperties of diffusion models. In this paper, we introduce a novel Dual-Domain\nAnti-Personalization framework (DDAP). Specifically, we have developed Spatial\nPerturbation Learning (SPL) by exploiting the fixed and perturbation-sensitive\nnature of the image encoder in personalized generation. Subsequently, we have\ndesigned a Frequency Perturbation Learning (FPL) method that utilizes the\ncharacteristics of diffusion models in the frequency domain. The SPL disrupts\nthe overall texture of the generated images, while the FPL focuses on image\ndetails. By alternating between these two methods, we construct the DDAP\nframework, effectively harnessing the strengths of both domains. To further\nenhance the visual quality of the adversarial samples, we design a localization\nmodule to accurately capture attentive areas while ensuring the effectiveness\nof the attack and avoiding unnecessary disturbances in the background.\nExtensive experiments on facial benchmarks have shown that the proposed DDAP\nenhances the disruption of personalized generation models while also\nmaintaining high quality in adversarial samples, making it more effective in\nprotecting privacy in practical applications.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}