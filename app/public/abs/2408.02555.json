{"id":"2408.02555","title":"MeshAnything V2: Artist-Created Mesh Generation With Adjacent Mesh\n  Tokenization","authors":"Yiwen Chen, Yikai Wang, Yihao Luo, Zhengyi Wang, Zilong Chen, Jun Zhu,\n  Chi Zhang, Guosheng Lin","authorsParsed":[["Chen","Yiwen",""],["Wang","Yikai",""],["Luo","Yihao",""],["Wang","Zhengyi",""],["Chen","Zilong",""],["Zhu","Jun",""],["Zhang","Chi",""],["Lin","Guosheng",""]],"versions":[{"version":"v1","created":"Mon, 5 Aug 2024 15:33:45 GMT"}],"updateDate":"2024-08-06","timestamp":1722872025000,"abstract":"  We introduce MeshAnything V2, an autoregressive transformer that generates\nArtist-Created Meshes (AM) aligned to given shapes. It can be integrated with\nvarious 3D asset production pipelines to achieve high-quality, highly\ncontrollable AM generation. MeshAnything V2 surpasses previous methods in both\nefficiency and performance using models of the same size. These improvements\nare due to our newly proposed mesh tokenization method: Adjacent Mesh\nTokenization (AMT). Different from previous methods that represent each face\nwith three vertices, AMT uses a single vertex whenever possible. Compared to\nprevious methods, AMT requires about half the token sequence length to\nrepresent the same mesh in average. Furthermore, the token sequences from AMT\nare more compact and well-structured, fundamentally benefiting AM generation.\nOur extensive experiments show that AMT significantly improves the efficiency\nand performance of AM generation. Project Page:\nhttps://buaacyw.github.io/meshanything-v2/\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Graphics"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}