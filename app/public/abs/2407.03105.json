{"id":"2407.03105","title":"On Generalization for Generative Flow Networks","authors":"Anas Krichel, Nikolay Malkin, Salem Lahlou, Yoshua Bengio","authorsParsed":[["Krichel","Anas",""],["Malkin","Nikolay",""],["Lahlou","Salem",""],["Bengio","Yoshua",""]],"versions":[{"version":"v1","created":"Wed, 3 Jul 2024 13:42:21 GMT"}],"updateDate":"2024-07-04","timestamp":1720014141000,"abstract":"  Generative Flow Networks (GFlowNets) have emerged as an innovative learning\nparadigm designed to address the challenge of sampling from an unnormalized\nprobability distribution, called the reward function. This framework learns a\npolicy on a constructed graph, which enables sampling from an approximation of\nthe target probability distribution through successive steps of sampling from\nthe learned policy. To achieve this, GFlowNets can be trained with various\nobjectives, each of which can lead to the model s ultimate goal. The\naspirational strength of GFlowNets lies in their potential to discern intricate\npatterns within the reward function and their capacity to generalize\neffectively to novel, unseen parts of the reward function. This paper attempts\nto formalize generalization in the context of GFlowNets, to link generalization\nwith stability, and also to design experiments that assess the capacity of\nthese models to uncover unseen parts of the reward function. The experiments\nwill focus on length generalization meaning generalization to states that can\nbe constructed only by longer trajectories than those seen in training.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}