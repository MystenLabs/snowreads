{"id":"2408.06263","title":"Optimal Integrative Estimation for Distributed Precision Matrices with\n  Heterogeneity Adjustment","authors":"Yinrui Sun and Yin Xia","authorsParsed":[["Sun","Yinrui",""],["Xia","Yin",""]],"versions":[{"version":"v1","created":"Mon, 12 Aug 2024 16:23:33 GMT"}],"updateDate":"2024-08-13","timestamp":1723479813000,"abstract":"  Distributed learning offers a practical solution for the integrative analysis\nof multi-source datasets, especially under privacy or communication\nconstraints. However, addressing prospective distributional heterogeneity and\nensuring communication efficiency pose significant challenges on distributed\nstatistical analysis. In this article, we focus on integrative estimation of\ndistributed heterogeneous precision matrices, a crucial task related to joint\nprecision matrix estimation where computation-efficient algorithms and\nstatistical optimality theories are still underdeveloped. To tackle these\nchallenges, we introduce a novel HEterogeneity-adjusted Aggregating and\nThresholding (HEAT) approach for distributed integrative estimation. HEAT is\ndesigned to be both communication- and computation-efficient, and we\ndemonstrate its statistical optimality by establishing the convergence rates\nand the corresponding minimax lower bounds under various integrative losses. To\nenhance the optimality of HEAT, we further propose an iterative HEAT (IteHEAT)\napproach. By iteratively refining the higher-order errors of HEAT estimators\nthrough multi-round communications, IteHEAT achieves geometric contraction\nrates of convergence. Extensive simulations and real data applications validate\nthe numerical performance of HEAT and IteHEAT methods.\n","subjects":["Statistics/Methodology"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}