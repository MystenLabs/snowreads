{"id":"2408.06265","title":"EyeSight Hand: Design of a Fully-Actuated Dexterous Robot Hand with\n  Integrated Vision-Based Tactile Sensors and Compliant Actuation","authors":"Branden Romero, Hao-Shu Fang, Pulkit Agrawal, Edward Adelson","authorsParsed":[["Romero","Branden",""],["Fang","Hao-Shu",""],["Agrawal","Pulkit",""],["Adelson","Edward",""]],"versions":[{"version":"v1","created":"Mon, 12 Aug 2024 16:24:21 GMT"}],"updateDate":"2024-08-13","timestamp":1723479861000,"abstract":"  In this work, we introduce the EyeSight Hand, a novel 7 degrees of freedom\n(DoF) humanoid hand featuring integrated vision-based tactile sensors tailored\nfor enhanced whole-hand manipulation. Additionally, we introduce an actuation\nscheme centered around quasi-direct drive actuation to achieve human-like\nstrength and speed while ensuring robustness for large-scale data collection.\nWe evaluate the EyeSight Hand on three challenging tasks: bottle opening,\nplasticine cutting, and plate pick and place, which require a blend of complex\nmanipulation, tool use, and precise force application. Imitation learning\nmodels trained on these tasks, with a novel vision dropout strategy, showcase\nthe benefits of tactile feedback in enhancing task success rates. Our results\nreveal that the integration of tactile sensing dramatically improves task\nperformance, underscoring the critical role of tactile information in dexterous\nmanipulation.\n","subjects":["Computing Research Repository/Robotics"],"license":"http://creativecommons.org/licenses/by/4.0/"}