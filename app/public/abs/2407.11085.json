{"id":"2407.11085","title":"SpreadFGL: Edge-Client Collaborative Federated Graph Learning with\n  Adaptive Neighbor Generation","authors":"Luying Zhong, Yueyang Pi, Zheyi Chen, Zhengxin Yu, Wang Miao, Xing\n  Chen, and Geyong Min","authorsParsed":[["Zhong","Luying",""],["Pi","Yueyang",""],["Chen","Zheyi",""],["Yu","Zhengxin",""],["Miao","Wang",""],["Chen","Xing",""],["Min","Geyong",""]],"versions":[{"version":"v1","created":"Sun, 14 Jul 2024 09:34:19 GMT"}],"updateDate":"2024-07-17","timestamp":1720949659000,"abstract":"  Federated Graph Learning (FGL) has garnered widespread attention by enabling\ncollaborative training on multiple clients for semi-supervised classification\ntasks. However, most existing FGL studies do not well consider the missing\ninter-client topology information in real-world scenarios, causing insufficient\nfeature aggregation of multi-hop neighbor clients during model training.\nMoreover, the classic FGL commonly adopts the FedAvg but neglects the high\ntraining costs when the number of clients expands, resulting in the overload of\na single edge server. To address these important challenges, we propose a novel\nFGL framework, named SpreadFGL, to promote the information flow in edge-client\ncollaboration and extract more generalized potential relationships between\nclients. In SpreadFGL, an adaptive graph imputation generator incorporated with\na versatile assessor is first designed to exploit the potential links between\nsubgraphs, without sharing raw data. Next, a new negative sampling mechanism is\ndeveloped to make SpreadFGL concentrate on more refined information in\ndownstream tasks. To facilitate load balancing at the edge layer, SpreadFGL\nfollows a distributed training manner that enables fast model convergence.\nUsing real-world testbed and benchmark graph datasets, extensive experiments\ndemonstrate the effectiveness of the proposed SpreadFGL. The results show that\nSpreadFGL achieves higher accuracy and faster convergence against\nstate-of-the-art algorithms.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}