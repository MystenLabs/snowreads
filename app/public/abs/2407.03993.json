{"id":"2407.03993","title":"A Survey on Natural Language Counterfactual Generation","authors":"Yongjie Wang, Xiaoqi Qiu, Yu Yue, Xu Guo, Zhiwei Zeng, Yuhong Feng,\n  Zhiqi Shen","authorsParsed":[["Wang","Yongjie",""],["Qiu","Xiaoqi",""],["Yue","Yu",""],["Guo","Xu",""],["Zeng","Zhiwei",""],["Feng","Yuhong",""],["Shen","Zhiqi",""]],"versions":[{"version":"v1","created":"Thu, 4 Jul 2024 15:13:59 GMT"}],"updateDate":"2024-07-08","timestamp":1720106039000,"abstract":"  Natural Language Counterfactual generation aims to minimally modify a given\ntext such that the modified text will be classified into a different class. The\ngenerated counterfactuals provide insight into the reasoning behind a model's\npredictions by highlighting which words significantly influence the outcomes.\nAdditionally, they can be used to detect model fairness issues or augment the\ntraining data to enhance the model's robustness. A substantial amount of\nresearch has been conducted to generate counterfactuals for various NLP tasks,\nemploying different models and methodologies. With the rapid growth of studies\nin this field, a systematic review is crucial to guide future researchers and\ndevelopers. To bridge this gap, this survey comprehensively overview textual\ncounterfactual generation methods, particularly including those based on Large\nLanguage Models. We propose a new taxonomy that categorizes the generation\nmethods into four groups and systematically summarize the metrics for\nevaluating the generation quality. Finally, we discuss ongoing research\nchallenges and outline promising directions for future work.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/"}