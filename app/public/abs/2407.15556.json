{"id":"2407.15556","title":"SETTP: Style Extraction and Tunable Inference via Dual-level\n  Transferable Prompt Learning","authors":"Chunzhen Jin, Yongfeng Huang, Yaqi Wang, Peng Cao, and Osmar Zaiane","authorsParsed":[["Jin","Chunzhen",""],["Huang","Yongfeng",""],["Wang","Yaqi",""],["Cao","Peng",""],["Zaiane","Osmar",""]],"versions":[{"version":"v1","created":"Mon, 22 Jul 2024 11:34:48 GMT"}],"updateDate":"2024-07-23","timestamp":1721648088000,"abstract":"  Text style transfer, an important research direction in natural language\nprocessing, aims to adapt the text to various preferences but often faces\nchallenges with limited resources. In this work, we introduce a novel method\ntermed Style Extraction and Tunable Inference via Dual-level Transferable\nPrompt Learning (SETTP) for effective style transfer in low-resource scenarios.\nFirst, SETTP learns source style-level prompts containing fundamental style\ncharacteristics from high-resource style transfer. During training, the source\nstyle-level prompts are transferred through an attention module to derive a\ntarget style-level prompt for beneficial knowledge provision in low-resource\nstyle transfer. Additionally, we propose instance-level prompts obtained by\nclustering the target resources based on the semantic content to reduce\nsemantic bias. We also propose an automated evaluation approach of style\nsimilarity based on alignment with human evaluations using ChatGPT-4. Our\nexperiments across three resourceful styles show that SETTP requires only\n1/20th of the data volume to achieve performance comparable to state-of-the-art\nmethods. In tasks involving scarce data like writing style and role style,\nSETTP outperforms previous methods by 16.24\\%.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}