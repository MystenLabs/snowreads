{"id":"2408.01044","title":"Boosting Gaze Object Prediction via Pixel-level Supervision from Vision\n  Foundation Model","authors":"Yang Jin, Lei Zhang, Shi Yan, Bin Fan, and Binglu Wang","authorsParsed":[["Jin","Yang",""],["Zhang","Lei",""],["Yan","Shi",""],["Fan","Bin",""],["Wang","Binglu",""]],"versions":[{"version":"v1","created":"Fri, 2 Aug 2024 06:32:45 GMT"}],"updateDate":"2024-08-05","timestamp":1722580365000,"abstract":"  Gaze object prediction (GOP) aims to predict the category and location of the\nobject that a human is looking at. Previous methods utilized box-level\nsupervision to identify the object that a person is looking at, but struggled\nwith semantic ambiguity, ie, a single box may contain several items since\nobjects are close together. The Vision foundation model (VFM) has improved in\nobject segmentation using box prompts, which can reduce confusion by more\nprecisely locating objects, offering advantages for fine-grained prediction of\ngaze objects. This paper presents a more challenging gaze object segmentation\n(GOS) task, which involves inferring the pixel-level mask corresponding to the\nobject captured by human gaze behavior. In particular, we propose that the\npixel-level supervision provided by VFM can be integrated into gaze object\nprediction to mitigate semantic ambiguity. This leads to our gaze object\ndetection and segmentation framework that enables accurate pixel-level\npredictions. Different from previous methods that require additional head input\nor ignore head features, we propose to automatically obtain head features from\nscene features to ensure the model's inference efficiency and flexibility in\nthe real world. Moreover, rather than directly fuse features to predict gaze\nheatmap as in existing methods, which may overlook spatial location and subtle\ndetails of the object, we develop a space-to-object gaze regression method to\nfacilitate human-object gaze interaction. Specifically, it first constructs an\ninitial human-object spatial connection, then refines this connection by\ninteracting with semantically clear features in the segmentation branch,\nultimately predicting a gaze heatmap for precise localization. Extensive\nexperiments on GOO-Synth and GOO-Real datasets demonstrate the effectiveness of\nour method.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}