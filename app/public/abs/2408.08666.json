{"id":"2408.08666","title":"A Multivocal Literature Review on Privacy and Fairness in Federated\n  Learning","authors":"Beatrice Balbierer, Lukas Heinlein, Domenique Zipperling, Niklas\n  K\\\"uhl","authorsParsed":[["Balbierer","Beatrice",""],["Heinlein","Lukas",""],["Zipperling","Domenique",""],["KÃ¼hl","Niklas",""]],"versions":[{"version":"v1","created":"Fri, 16 Aug 2024 11:15:52 GMT"}],"updateDate":"2024-08-19","timestamp":1723806952000,"abstract":"  Federated Learning presents a way to revolutionize AI applications by\neliminating the necessity for data sharing. Yet, research has shown that\ninformation can still be extracted during training, making additional\nprivacy-preserving measures such as differential privacy imperative. To\nimplement real-world federated learning applications, fairness, ranging from a\nfair distribution of performance to non-discriminative behaviour, must be\nconsidered. Particularly in high-risk applications (e.g. healthcare), avoiding\nthe repetition of past discriminatory errors is paramount. As recent research\nhas demonstrated an inherent tension between privacy and fairness, we conduct a\nmultivocal literature review to examine the current methods to integrate\nprivacy and fairness in federated learning. Our analyses illustrate that the\nrelationship between privacy and fairness has been neglected, posing a critical\nrisk for real-world applications. We highlight the need to explore the\nrelationship between privacy, fairness, and performance, advocating for the\ncreation of integrated federated learning frameworks.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/"}