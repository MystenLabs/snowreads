{"id":"2407.10207","title":"Learning to Steer Markovian Agents under Model Uncertainty","authors":"Jiawei Huang, Vinzenz Thoma, Zebang Shen, Heinrich H. Nax, Niao He","authorsParsed":[["Huang","Jiawei",""],["Thoma","Vinzenz",""],["Shen","Zebang",""],["Nax","Heinrich H.",""],["He","Niao",""]],"versions":[{"version":"v1","created":"Sun, 14 Jul 2024 14:01:38 GMT"}],"updateDate":"2024-07-16","timestamp":1720965698000,"abstract":"  Designing incentives for an adapting population is a ubiquitous problem in a\nwide array of economic applications and beyond. In this work, we study how to\ndesign additional rewards to steer multi-agent systems towards desired policies\n\\emph{without} prior knowledge of the agents' underlying learning dynamics. We\nintroduce a model-based non-episodic Reinforcement Learning (RL) formulation\nfor our steering problem. Importantly, we focus on learning a\n\\emph{history-dependent} steering strategy to handle the inherent model\nuncertainty about the agents' learning dynamics. We introduce a novel objective\nfunction to encode the desiderata of achieving a good steering outcome with\nreasonable cost. Theoretically, we identify conditions for the existence of\nsteering strategies to guide agents to the desired policies. Complementing our\ntheoretical contributions, we provide empirical algorithms to approximately\nsolve our objective, which effectively tackles the challenge in learning\nhistory-dependent strategies. We demonstrate the efficacy of our algorithms\nthrough empirical evaluations.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Multiagent Systems","Statistics/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}