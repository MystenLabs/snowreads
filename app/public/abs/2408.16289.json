{"id":"2408.16289","title":"Convolutional Neural Network Compression Based on Low-Rank Decomposition","authors":"Yaping He, Linhao Jiang, Di Wu","authorsParsed":[["He","Yaping",""],["Jiang","Linhao",""],["Wu","Di",""]],"versions":[{"version":"v1","created":"Thu, 29 Aug 2024 06:40:34 GMT"}],"updateDate":"2024-08-30","timestamp":1724913634000,"abstract":"  Deep neural networks typically impose significant computational loads and\nmemory consumption. Moreover, the large parameters pose constraints on\ndeploying the model on edge devices such as embedded systems. Tensor\ndecomposition offers a clear advantage in compressing large-scale weight\ntensors. Nevertheless, direct utilization of low-rank decomposition typically\nleads to significant accuracy loss. This paper proposes a model compression\nmethod that integrates Variational Bayesian Matrix Factorization (VBMF) with\northogonal regularization. Initially, the model undergoes over-parameterization\nand training, with orthogonal regularization applied to enhance its likelihood\nof achieving the accuracy of the original model. Secondly, VBMF is employed to\nestimate the rank of the weight tensor at each layer. Our framework is\nsufficiently general to apply to other convolutional neural networks and easily\nadaptable to incorporate other tensor decomposition methods. Experimental\nresults show that for both high and low compression ratios, our compression\nmodel exhibits advanced performance.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}