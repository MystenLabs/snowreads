{"id":"2407.05795","title":"HyCIR: Boosting Zero-Shot Composed Image Retrieval with Synthetic Labels","authors":"Yingying Jiang, Hanchao Jia, Xiaobing Wang, Peng Hao","authorsParsed":[["Jiang","Yingying",""],["Jia","Hanchao",""],["Wang","Xiaobing",""],["Hao","Peng",""]],"versions":[{"version":"v1","created":"Mon, 8 Jul 2024 09:55:36 GMT"},{"version":"v2","created":"Tue, 9 Jul 2024 03:44:55 GMT"}],"updateDate":"2024-07-10","timestamp":1720432536000,"abstract":"  Composed Image Retrieval (CIR) aims to retrieve images based on a query image\nwith text. Current Zero-Shot CIR (ZS-CIR) methods try to solve CIR tasks\nwithout using expensive triplet-labeled training datasets. However, the gap\nbetween ZS-CIR and triplet-supervised CIR is still large. In this work, we\npropose Hybrid CIR (HyCIR), which uses synthetic labels to boost the\nperformance of ZS-CIR. A new label Synthesis pipeline for CIR (SynCir) is\nproposed, in which only unlabeled images are required. First, image pairs are\nextracted based on visual similarity. Second, query text is generated for each\nimage pair based on vision-language model and LLM. Third, the data is further\nfiltered in language space based on semantic similarity. To improve ZS-CIR\nperformance, we propose a hybrid training strategy to work with both ZS-CIR\nsupervision and synthetic CIR triplets. Two kinds of contrastive learning are\nadopted. One is to use large-scale unlabeled image dataset to learn an\nimage-to-text mapping with good generalization. The other is to use synthetic\nCIR triplets to learn a better mapping for CIR tasks. Our approach achieves\nSOTA zero-shot performance on the common CIR benchmarks: CIRR and CIRCO.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/"}