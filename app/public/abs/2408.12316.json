{"id":"2408.12316","title":"Unrolled Decomposed Unpaired Learning for Controllable Low-Light Video\n  Enhancement","authors":"Lingyu Zhu, Wenhan Yang, Baoliang Chen, Hanwei Zhu, Zhangkai Ni, Qi\n  Mao, Shiqi Wang","authorsParsed":[["Zhu","Lingyu",""],["Yang","Wenhan",""],["Chen","Baoliang",""],["Zhu","Hanwei",""],["Ni","Zhangkai",""],["Mao","Qi",""],["Wang","Shiqi",""]],"versions":[{"version":"v1","created":"Thu, 22 Aug 2024 11:45:11 GMT"}],"updateDate":"2024-08-23","timestamp":1724327111000,"abstract":"  Obtaining pairs of low/normal-light videos, with motions, is more challenging\nthan still images, which raises technical issues and poses the technical route\nof unpaired learning as a critical role. This paper makes endeavors in the\ndirection of learning for low-light video enhancement without using paired\nground truth. Compared to low-light image enhancement, enhancing low-light\nvideos is more difficult due to the intertwined effects of noise, exposure, and\ncontrast in the spatial domain, jointly with the need for temporal coherence.\nTo address the above challenge, we propose the Unrolled Decomposed Unpaired\nNetwork (UDU-Net) for enhancing low-light videos by unrolling the optimization\nfunctions into a deep network to decompose the signal into spatial and\ntemporal-related factors, which are updated iteratively. Firstly, we formulate\nlow-light video enhancement as a Maximum A Posteriori estimation (MAP) problem\nwith carefully designed spatial and temporal visual regularization. Then, via\nunrolling the problem, the optimization of the spatial and temporal constraints\ncan be decomposed into different steps and updated in a stage-wise manner. From\nthe spatial perspective, the designed Intra subnet leverages unpair prior\ninformation from expert photography retouched skills to adjust the statistical\ndistribution. Additionally, we introduce a novel mechanism that integrates\nhuman perception feedback to guide network optimization, suppressing\nover/under-exposure conditions. Meanwhile, to address the issue from the\ntemporal perspective, the designed Inter subnet fully exploits temporal cues in\nprogressive optimization, which helps achieve improved temporal consistency in\nenhancement results. Consequently, the proposed method achieves superior\nperformance to state-of-the-art methods in video illumination, noise\nsuppression, and temporal consistency across outdoor and indoor scenes.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}