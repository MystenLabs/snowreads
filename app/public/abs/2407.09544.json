{"id":"2407.09544","title":"A Transformer-Based Multi-Stream Approach for Isolated Iranian Sign\n  Language Recognition","authors":"Ali Ghadami, Alireza Taheri, Ali Meghdari","authorsParsed":[["Ghadami","Ali",""],["Taheri","Alireza",""],["Meghdari","Ali",""]],"versions":[{"version":"v1","created":"Thu, 27 Jun 2024 06:54:25 GMT"}],"updateDate":"2024-07-16","timestamp":1719471265000,"abstract":"  Sign language is an essential means of communication for millions of people\naround the world and serves as their primary language. However, most\ncommunication tools are developed for spoken and written languages which can\ncause problems and difficulties for the deaf and hard of hearing community. By\ndeveloping a sign language recognition system, we can bridge this communication\ngap and enable people who use sign language as their main form of expression to\nbetter communicate with people and their surroundings. This recognition system\nincreases the quality of health services, improves public services, and creates\nequal opportunities for the deaf community. This research aims to recognize\nIranian Sign Language words with the help of the latest deep learning tools\nsuch as transformers. The dataset used includes 101 Iranian Sign Language words\nfrequently used in academic environments such as universities. The network used\nis a combination of early fusion and late fusion transformer encoder-based\nnetworks optimized with the help of genetic algorithm. The selected features to\ntrain this network include hands and lips key points, and the distance and\nangle between hands extracted from the sign videos. Also, in addition to the\ntraining model for the classes, the embedding vectors of words are used as\nmulti-task learning to have smoother and more efficient training. This model\nwas also tested on sentences generated from our word dataset using a windowing\ntechnique for sentence translation. Finally, the sign language training\nsoftware that provides real-time feedback to users with the help of the\ndeveloped model, which has 90.2% accuracy on test data, was introduced, and in\na survey, the effectiveness and efficiency of this type of sign language\nlearning software and the impact of feedback were investigated.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computer Vision and Pattern Recognition","Electrical Engineering and Systems Science/Image and Video Processing"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"8g3_ljOO7VFIY0v3fefTyspPQ6B9nuD_5TnpBiDeqR8","pdfSize":"13962925"}
