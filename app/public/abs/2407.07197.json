{"id":"2407.07197","title":"ColorPeel: Color Prompt Learning with Diffusion Models via Color and\n  Shape Disentanglement","authors":"Muhammad Atif Butt, Kai Wang, Javier Vazquez-Corral, Joost van de\n  Weijer","authorsParsed":[["Butt","Muhammad Atif",""],["Wang","Kai",""],["Vazquez-Corral","Javier",""],["van de Weijer","Joost",""]],"versions":[{"version":"v1","created":"Tue, 9 Jul 2024 19:26:34 GMT"}],"updateDate":"2024-07-11","timestamp":1720553194000,"abstract":"  Text-to-Image (T2I) generation has made significant advancements with the\nadvent of diffusion models. These models exhibit remarkable abilities to\nproduce images based on textual prompts. Current T2I models allow users to\nspecify object colors using linguistic color names. However, these labels\nencompass broad color ranges, making it difficult to achieve precise color\nmatching. To tackle this challenging task, named color prompt learning, we\npropose to learn specific color prompts tailored to user-selected colors.\nExisting T2I personalization methods tend to result in color-shape\nentanglement. To overcome this, we generate several basic geometric objects in\nthe target color, allowing for color and shape disentanglement during the color\nprompt learning. Our method, denoted as ColorPeel, successfully assists the T2I\nmodels to peel off the novel color prompts from these colored shapes. In the\nexperiments, we demonstrate the efficacy of ColorPeel in achieving precise\ncolor generation with T2I models. Furthermore, we generalize ColorPeel to\neffectively learn abstract attribute concepts, including textures, materials,\netc. Our findings represent a significant step towards improving precision and\nversatility of T2I models, offering new opportunities for creative applications\nand design tasks. Our project is available at\nhttps://moatifbutt.github.io/colorpeel/.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}