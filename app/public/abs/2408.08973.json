{"id":"2408.08973","title":"Image Class Translation Distance: A Novel Interpretable Feature for\n  Image Classification","authors":"Mikyla K. Bowen and Jesse W. Wilson","authorsParsed":[["Bowen","Mikyla K.",""],["Wilson","Jesse W.",""]],"versions":[{"version":"v1","created":"Fri, 16 Aug 2024 18:48:28 GMT"}],"updateDate":"2024-08-20","timestamp":1723834108000,"abstract":"  We propose a novel application of image translation networks for image\nclassification and demonstrate its potential as a more interpretable\nalternative to conventional black box classification networks. We train a\nnetwork to translate images between possible classes, and then quantify\ntranslation distance, i.e. the degree of alteration needed to conform an image\nto one class or another. These translation distances can then be examined for\nclusters and trends, and can be fed directly to a simple classifier (e.g. a\nsupport vector machine, SVM), providing comparable accuracy compared to a\nconventional end-to-end convolutional neural network classifier. In addition,\nvisual inspection of translated images can reveal class-specific\ncharacteristics and biases in the training sets, such as visual artifacts that\nare more frequently observed in one class or another. We demonstrate the\napproach on a toy 2-class scenario, apples versus oranges, and then apply it to\ntwo medical imaging tasks: detecting melanoma from photographs of pigmented\nlesions and classifying 6 cell types in a bone marrow biopsy smear. This novel\napplication of image-to-image networks shows the potential of the technology to\ngo beyond imagining different stylistic changes and to provide greater insight\ninto image classification and medical imaging datasets.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/"}