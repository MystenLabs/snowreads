{"id":"2408.17006","title":"Retrieval-Augmented Natural Language Reasoning for Explainable Visual\n  Question Answering","authors":"Su Hyeon Lim, Minkuk Kim, Hyeon Bae Kim, Seong Tae Kim","authorsParsed":[["Lim","Su Hyeon",""],["Kim","Minkuk",""],["Kim","Hyeon Bae",""],["Kim","Seong Tae",""]],"versions":[{"version":"v1","created":"Fri, 30 Aug 2024 04:39:43 GMT"}],"updateDate":"2024-09-02","timestamp":1724992783000,"abstract":"  Visual Question Answering with Natural Language Explanation (VQA-NLE) task is\nchallenging due to its high demand for reasoning-based inference. Recent\nVQA-NLE studies focus on enhancing model networks to amplify the model's\nreasoning capability but this approach is resource-consuming and unstable. In\nthis work, we introduce a new VQA-NLE model, ReRe (Retrieval-augmented natural\nlanguage Reasoning), using leverage retrieval information from the memory to\naid in generating accurate answers and persuasive explanations without relying\non complex networks and extra datasets. ReRe is an encoder-decoder architecture\nmodel using a pre-trained clip vision encoder and a pre-trained GPT-2 language\nmodel as a decoder. Cross-attention layers are added in the GPT-2 for\nprocessing retrieval features. ReRe outperforms previous methods in VQA\naccuracy and explanation score and shows improvement in NLE with more\npersuasive, reliability.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/"}