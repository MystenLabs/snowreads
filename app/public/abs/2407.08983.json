{"id":"2407.08983","title":"Towards More Trustworthy and Interpretable LLMs for Code through\n  Syntax-Grounded Explanations","authors":"David N. Palacio and Daniel Rodriguez-Cardenas and Alejandro Velasco\n  and Dipin Khati and Kevin Moran and Denys Poshyvanyk","authorsParsed":[["Palacio","David N.",""],["Rodriguez-Cardenas","Daniel",""],["Velasco","Alejandro",""],["Khati","Dipin",""],["Moran","Kevin",""],["Poshyvanyk","Denys",""]],"versions":[{"version":"v1","created":"Fri, 12 Jul 2024 04:38:28 GMT"}],"updateDate":"2024-07-15","timestamp":1720759108000,"abstract":"  Trustworthiness and interpretability are inextricably linked concepts for\nLLMs. The more interpretable an LLM is, the more trustworthy it becomes.\nHowever, current techniques for interpreting LLMs when applied to code-related\ntasks largely focus on accuracy measurements, measures of how models react to\nchange, or individual task performance instead of the fine-grained explanations\nneeded at prediction time for greater interpretability, and hence trust. To\nimprove upon this status quo, this paper introduces ASTrust, an\ninterpretability method for LLMs of code that generates explanations grounded\nin the relationship between model confidence and syntactic structures of\nprogramming languages. ASTrust explains generated code in the context of syntax\ncategories based on Abstract Syntax Trees and aids practitioners in\nunderstanding model predictions at both local (individual code snippets) and\nglobal (larger datasets of code) levels. By distributing and assigning model\nconfidence scores to well-known syntactic structures that exist within ASTs,\nour approach moves beyond prior techniques that perform token-level confidence\nmapping by offering a view of model confidence that directly aligns with\nprogramming language concepts with which developers are familiar. To put\nASTrust into practice, we developed an automated visualization that illustrates\nthe aggregated model confidence scores superimposed on sequence, heat-map, and\ngraph-based visuals of syntactic structures from ASTs. We examine both the\npractical benefit that ASTrust can provide through a data science study on 12\npopular LLMs on a curated set of GitHub repos and the usefulness of ASTrust\nthrough a human study.\n","subjects":["Computing Research Repository/Software Engineering","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"Bbp2_gaXAMGdHT_s370XyMPeJtm_DBwlKV_InS8VIMI","pdfSize":"3120384"}
