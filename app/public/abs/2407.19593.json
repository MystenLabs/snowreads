{"id":"2407.19593","title":"Bridging the Gap: Studio-like Avatar Creation from a Monocular Phone\n  Capture","authors":"ShahRukh Athar, Shunsuke Saito, Zhengyu Yang, Stanislav Pidhorsky,\n  Chen Cao","authorsParsed":[["Athar","ShahRukh",""],["Saito","Shunsuke",""],["Yang","Zhengyu",""],["Pidhorsky","Stanislav",""],["Cao","Chen",""]],"versions":[{"version":"v1","created":"Sun, 28 Jul 2024 21:26:33 GMT"},{"version":"v2","created":"Tue, 30 Jul 2024 02:20:28 GMT"}],"updateDate":"2024-07-31","timestamp":1722201993000,"abstract":"  Creating photorealistic avatars for individuals traditionally involves\nextensive capture sessions with complex and expensive studio devices like the\nLightStage system. While recent strides in neural representations have enabled\nthe generation of photorealistic and animatable 3D avatars from quick phone\nscans, they have the capture-time lighting baked-in, lack facial details and\nhave missing regions in areas such as the back of the ears. Thus, they lag in\nquality compared to studio-captured avatars. In this paper, we propose a method\nthat bridges this gap by generating studio-like illuminated texture maps from\nshort, monocular phone captures. We do this by parameterizing the phone texture\nmaps using the $W^+$ space of a StyleGAN2, enabling near-perfect\nreconstruction. Then, we finetune a StyleGAN2 by sampling in the $W^+$\nparameterized space using a very small set of studio-captured textures as an\nadversarial training signal. To further enhance the realism and accuracy of\nfacial details, we super-resolve the output of the StyleGAN2 using carefully\ndesigned diffusion model that is guided by image gradients of the\nphone-captured texture map. Once trained, our method excels at producing\nstudio-like facial texture maps from casual monocular smartphone videos.\nDemonstrating its capabilities, we showcase the generation of photorealistic,\nuniformly lit, complete avatars from monocular phone captures. The project page\ncan be found at http://shahrukhathar.github.io/2024/07/22/Bridging.html\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}