{"id":"2408.06257","title":"Reciprocal Learning","authors":"Julian Rodemann, Christoph Jansen, Georg Schollmeyer","authorsParsed":[["Rodemann","Julian",""],["Jansen","Christoph",""],["Schollmeyer","Georg",""]],"versions":[{"version":"v1","created":"Mon, 12 Aug 2024 16:14:52 GMT"}],"updateDate":"2024-08-13","timestamp":1723479292000,"abstract":"  We demonstrate that a wide array of machine learning algorithms are specific\ninstances of one single paradigm: reciprocal learning. These instances range\nfrom active learning over multi-armed bandits to self-training. We show that\nall these algorithms do not only learn parameters from data but also vice\nversa: They iteratively alter training data in a way that depends on the\ncurrent model fit. We introduce reciprocal learning as a generalization of\nthese algorithms using the language of decision theory. This allows us to study\nunder what conditions they converge. The key is to guarantee that reciprocal\nlearning contracts such that the Banach fixed-point theorem applies. In this\nway, we find that reciprocal learning algorithms converge at linear rates to an\napproximately optimal model under relatively mild assumptions on the loss\nfunction, if their predictions are probabilistic and the sample adaption is\nboth non-greedy and either randomized or regularized. We interpret these\nfindings and provide corollaries that relate them to specific active learning,\nself-training, and bandit algorithms.\n","subjects":["Statistics/Machine Learning","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"CPvuXWO9H47Ov9HgCm787LgPMvGZFLG6wG9lGHpShfM","pdfSize":"1097409"}
