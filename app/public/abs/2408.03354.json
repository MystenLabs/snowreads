{"id":"2408.03354","title":"The Use of Large Language Models (LLM) for Cyber Threat Intelligence\n  (CTI) in Cybercrime Forums","authors":"Vanessa Clairoux-Trepanier, Isa-May Beauchamp, Estelle Ruellan,\n  Masarah Paquet-Clouston, Serge-Olivier Paquette, Eric Clay","authorsParsed":[["Clairoux-Trepanier","Vanessa",""],["Beauchamp","Isa-May",""],["Ruellan","Estelle",""],["Paquet-Clouston","Masarah",""],["Paquette","Serge-Olivier",""],["Clay","Eric",""]],"versions":[{"version":"v1","created":"Tue, 6 Aug 2024 09:15:25 GMT"},{"version":"v2","created":"Thu, 8 Aug 2024 12:31:12 GMT"}],"updateDate":"2024-08-09","timestamp":1722935725000,"abstract":"  Large language models (LLMs) can be used to analyze cyber threat intelligence\n(CTI) data from cybercrime forums, which contain extensive information and key\ndiscussions about emerging cyber threats. However, to date, the level of\naccuracy and efficiency of LLMs for such critical tasks has yet to be\nthoroughly evaluated. Hence, this study assesses the accuracy of an LLM system\nbuilt on the OpenAI GPT-3.5-turbo model [7] to extract CTI information. To do\nso, a random sample of 500 daily conversations from three cybercrime forums,\nXSS, Exploit_in, and RAMP, was extracted, and the LLM system was instructed to\nsummarize the conversations and code 10 key CTI variables, such as whether a\nlarge organization and/or a critical infrastructure is being targeted. Then,\ntwo coders reviewed each conversation and evaluated whether the information\nextracted by the LLM was accurate. The LLM system performed strikingly well,\nwith an average accuracy score of 98%. Various ways to enhance the model were\nuncovered, such as the need to help the LLM distinguish between stories and\npast events, as well as being careful with verb tenses in prompts.\nNevertheless, the results of this study highlight the efficiency and relevance\nof using LLMs for cyber threat intelligence.\n","subjects":["Computing Research Repository/Cryptography and Security","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}