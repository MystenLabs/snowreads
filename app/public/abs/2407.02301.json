{"id":"2407.02301","title":"CFinBench: A Comprehensive Chinese Financial Benchmark for Large\n  Language Models","authors":"Ying Nie, Binwei Yan, Tianyu Guo, Hao Liu, Haoyu Wang, Wei He, Binfan\n  Zheng, Weihao Wang, Qiang Li, Weijian Sun, Yunhe Wang, Dacheng Tao","authorsParsed":[["Nie","Ying",""],["Yan","Binwei",""],["Guo","Tianyu",""],["Liu","Hao",""],["Wang","Haoyu",""],["He","Wei",""],["Zheng","Binfan",""],["Wang","Weihao",""],["Li","Qiang",""],["Sun","Weijian",""],["Wang","Yunhe",""],["Tao","Dacheng",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 14:34:36 GMT"}],"updateDate":"2024-07-03","timestamp":1719930876000,"abstract":"  Large language models (LLMs) have achieved remarkable performance on various\nNLP tasks, yet their potential in more challenging and domain-specific task,\nsuch as finance, has not been fully explored. In this paper, we present\nCFinBench: a meticulously crafted, the most comprehensive evaluation benchmark\nto date, for assessing the financial knowledge of LLMs under Chinese context.\nIn practice, to better align with the career trajectory of Chinese financial\npractitioners, we build a systematic evaluation from 4 first-level categories:\n(1) Financial Subject: whether LLMs can memorize the necessary basic knowledge\nof financial subjects, such as economics, statistics and auditing. (2)\nFinancial Qualification: whether LLMs can obtain the needed financial qualified\ncertifications, such as certified public accountant, securities qualification\nand banking qualification. (3) Financial Practice: whether LLMs can fulfill the\npractical financial jobs, such as tax consultant, junior accountant and\nsecurities analyst. (4) Financial Law: whether LLMs can meet the requirement of\nfinancial laws and regulations, such as tax law, insurance law and economic\nlaw. CFinBench comprises 99,100 questions spanning 43 second-level categories\nwith 3 question types: single-choice, multiple-choice and judgment. We conduct\nextensive experiments of 50 representative LLMs with various model size on\nCFinBench. The results show that GPT4 and some Chinese-oriented models lead the\nbenchmark, with the highest average accuracy being 60.16%, highlighting the\nchallenge presented by CFinBench. The dataset and evaluation code are available\nat https://cfinbench.github.io/.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}