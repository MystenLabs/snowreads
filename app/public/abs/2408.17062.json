{"id":"2408.17062","title":"Vote&Mix: Plug-and-Play Token Reduction for Efficient Vision Transformer","authors":"Shuai Peng, Di Fu, Baole Wei, Yong Cao, Liangcai Gao, Zhi Tang","authorsParsed":[["Peng","Shuai",""],["Fu","Di",""],["Wei","Baole",""],["Cao","Yong",""],["Gao","Liangcai",""],["Tang","Zhi",""]],"versions":[{"version":"v1","created":"Fri, 30 Aug 2024 07:48:05 GMT"}],"updateDate":"2024-09-02","timestamp":1725004085000,"abstract":"  Despite the remarkable success of Vision Transformers (ViTs) in various\nvisual tasks, they are often hindered by substantial computational cost. In\nthis work, we introduce Vote\\&Mix (\\textbf{VoMix}), a plug-and-play and\nparameter-free token reduction method, which can be readily applied to\noff-the-shelf ViT models \\textit{without any training}. VoMix tackles the\ncomputational redundancy of ViTs by identifying tokens with high homogeneity\nthrough a layer-wise token similarity voting mechanism. Subsequently, the\nselected tokens are mixed into the retained set, thereby preserving visual\ninformation. Experiments demonstrate VoMix significantly improves the\nspeed-accuracy tradeoff of ViTs on both images and videos. Without any\ntraining, VoMix achieves a 2$\\times$ increase in throughput of existing ViT-H\non ImageNet-1K and a 2.4$\\times$ increase in throughput of existing ViT-L on\nKinetics-400 video dataset, with a mere 0.3\\% drop in top-1 accuracy.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}