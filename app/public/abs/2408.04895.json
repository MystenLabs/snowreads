{"id":"2408.04895","title":"Better Not to Propagate: Understanding Edge Uncertainty and\n  Over-smoothing in Signed Graph Neural Networks","authors":"Yoonhyuk Choi, Jiho Choi, Taewook Ko, Chong-Kwon Kim","authorsParsed":[["Choi","Yoonhyuk",""],["Choi","Jiho",""],["Ko","Taewook",""],["Kim","Chong-Kwon",""]],"versions":[{"version":"v1","created":"Fri, 9 Aug 2024 06:46:06 GMT"},{"version":"v2","created":"Sun, 25 Aug 2024 22:30:42 GMT"}],"updateDate":"2024-08-27","timestamp":1723185966000,"abstract":"  Traditional Graph Neural Networks (GNNs) rely on network homophily, which can\nlead to performance degradation due to over-smoothing in many real-world\nheterophily scenarios. Recent studies analyze the smoothing effect\n(separability) after message-passing (MP), depending on the expectation of node\nfeatures. Regarding separability gain, they provided theoretical backgrounds on\nover-smoothing caused by various propagation schemes, including positive,\nsigned, and blocked MPs. More recently, by extending these theorems, some works\nhave suggested improvements in signed propagation under multiple classes.\nHowever, prior works assume that the error ratio of all propagation schemes is\nfixed, failing to investigate this phenomenon correctly. To solve this problem,\nwe propose a novel method for estimating homophily and edge error ratio,\nintegrated with dynamic selection between blocked and signed propagation during\ntraining. Our theoretical analysis, supported by extensive experiments,\ndemonstrates that blocking MP can be more effective than signed propagation\nunder high edge error ratios, improving the performance in both homophilic and\nheterophilic graphs.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}