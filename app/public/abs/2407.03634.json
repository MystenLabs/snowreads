{"id":"2407.03634","title":"SOWA: Adapting Hierarchical Frozen Window Self-Attention to\n  Visual-Language Models for Better Anomaly Detection","authors":"Zongxiang Hu, Zhaosheng Zhang","authorsParsed":[["Hu","Zongxiang",""],["Zhang","Zhaosheng",""]],"versions":[{"version":"v1","created":"Thu, 4 Jul 2024 04:54:03 GMT"},{"version":"v2","created":"Tue, 30 Jul 2024 11:02:50 GMT"}],"updateDate":"2024-07-31","timestamp":1720068843000,"abstract":"  Visual anomaly detection is critical in industrial manufacturing, but\ntraditional methods often rely on extensive normal datasets and custom models,\nlimiting scalability. Recent advancements in large-scale visual-language models\nhave significantly improved zero/few-shot anomaly detection. However, these\napproaches may not fully utilize hierarchical features, potentially missing\nnuanced details. We introduce a window self-attention mechanism based on the\nCLIP model, combined with learnable prompts to process multi-level features\nwithin a Soldier-Offier Window self-Attention (SOWA) framework. Our method has\nbeen tested on five benchmark datasets, demonstrating superior performance by\nleading in 18 out of 20 metrics compared to existing state-of-the-art\ntechniques.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}