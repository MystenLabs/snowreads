{"id":"2408.05437","title":"Predicting Long-Term Allograft Survival in Liver Transplant Recipients","authors":"Xiang Gao, Michael Cooper, Maryam Naghibzadeh, Amirhossein Azhie,\n  Mamatha Bhat, Rahul G. Krishnan","authorsParsed":[["Gao","Xiang",""],["Cooper","Michael",""],["Naghibzadeh","Maryam",""],["Azhie","Amirhossein",""],["Bhat","Mamatha",""],["Krishnan","Rahul G.",""]],"versions":[{"version":"v1","created":"Sat, 10 Aug 2024 04:44:36 GMT"}],"updateDate":"2024-08-13","timestamp":1723265076000,"abstract":"  Liver allograft failure occurs in approximately 20% of liver transplant\nrecipients within five years post-transplant, leading to mortality or the need\nfor retransplantation. Providing an accurate and interpretable model for\nindividualized risk estimation of graft failure is essential for improving\npost-transplant care. To this end, we introduce the Model for Allograft\nSurvival (MAS), a simple linear risk score that outperforms other advanced\nsurvival models. Using longitudinal patient follow-up data from the United\nStates (U.S.), we develop our models on 82,959 liver transplant recipients and\nconduct multi-site evaluations on 11 regions. Additionally, by testing on a\nseparate non-U.S. cohort, we explore the out-of-distribution generalization\nperformance of various models without additional fine-tuning, a crucial\nproperty for clinical deployment. We find that the most complex models are also\nthe ones most vulnerable to distribution shifts despite achieving the best\nin-distribution performance. Our findings not only provide a strong risk score\nfor predicting long-term graft failure but also suggest that the routine\nmachine learning pipeline with only in-distribution held-out validation could\ncreate harmful consequences for patients at deployment.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}