{"id":"2408.00254","title":"LoopSparseGS: Loop Based Sparse-View Friendly Gaussian Splatting","authors":"Zhenyu Bao, Guibiao Liao, Kaichen Zhou, Kanglin Liu, Qing Li, Guoping\n  Qiu","authorsParsed":[["Bao","Zhenyu",""],["Liao","Guibiao",""],["Zhou","Kaichen",""],["Liu","Kanglin",""],["Li","Qing",""],["Qiu","Guoping",""]],"versions":[{"version":"v1","created":"Thu, 1 Aug 2024 03:26:50 GMT"}],"updateDate":"2024-08-02","timestamp":1722482810000,"abstract":"  Despite the photorealistic novel view synthesis (NVS) performance achieved by\nthe original 3D Gaussian splatting (3DGS), its rendering quality significantly\ndegrades with sparse input views. This performance drop is mainly caused by the\nlimited number of initial points generated from the sparse input, insufficient\nsupervision during the training process, and inadequate regularization of the\noversized Gaussian ellipsoids. To handle these issues, we propose the\nLoopSparseGS, a loop-based 3DGS framework for the sparse novel view synthesis\ntask. In specific, we propose a loop-based Progressive Gaussian Initialization\n(PGI) strategy that could iteratively densify the initialized point cloud using\nthe rendered pseudo images during the training process. Then, the sparse and\nreliable depth from the Structure from Motion, and the window-based dense\nmonocular depth are leveraged to provide precise geometric supervision via the\nproposed Depth-alignment Regularization (DAR). Additionally, we introduce a\nnovel Sparse-friendly Sampling (SFS) strategy to handle oversized Gaussian\nellipsoids leading to large pixel errors. Comprehensive experiments on four\ndatasets demonstrate that LoopSparseGS outperforms existing state-of-the-art\nmethods for sparse-input novel view synthesis, across indoor, outdoor, and\nobject-level scenes with various image resolutions.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}