{"id":"2407.18018","title":"Continuous time Stochastic optimal control under discrete time partial\n  observations","authors":"Christian Bayer, Boualem Djehiche, Eliza Rezvanova, Raul Fidel Tempone","authorsParsed":[["Bayer","Christian",""],["Djehiche","Boualem",""],["Rezvanova","Eliza",""],["Tempone","Raul Fidel",""]],"versions":[{"version":"v1","created":"Thu, 25 Jul 2024 13:11:10 GMT"}],"updateDate":"2024-07-26","timestamp":1721913070000,"abstract":"  This work addresses stochastic optimal control problems where the unknown\nstate evolves in continuous time while partial, noisy, and possibly\ncontrollable measurements are only available in discrete time. We develop a\nframework for controlling such systems, focusing on the measure-valued process\nof the system's state and the control actions that depend on noisy and\nincomplete data. Our approach uses a stochastic optimal control framework with\na probability measure-valued state, which accommodates noisy measurements and\nintegrates them into control decisions through a Bayesian update mechanism. We\ncharacterize the control optimality in terms of a sequence of interlaced\nHamilton Jacobi Bellman (HJB) equations coupled with controlled impulse steps\nat the measurement times. For the case of Gaussian-controlled processes, we\nderive an equivalent HJB equation whose state variable is finite-dimensional,\nnamely the state's mean and covariance. We demonstrate the effectiveness of our\nmethods through numerical examples. These include control under perfect\nobservations, control under no observations, and control under noisy\nobservations. Our numerical results highlight significant differences in the\ncontrol strategies and their performance, emphasizing the challenges and\ncomputational demands of dealing with uncertainty in state observation.\n","subjects":["Mathematics/Optimization and Control"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}