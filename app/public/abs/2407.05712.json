{"id":"2407.05712","title":"MobilePortrait: Real-Time One-Shot Neural Head Avatars on Mobile Devices","authors":"Jianwen Jiang, Gaojie Lin, Zhengkun Rong, Chao Liang, Yongming Zhu,\n  Jiaqi Yang, Tianyun Zhong","authorsParsed":[["Jiang","Jianwen",""],["Lin","Gaojie",""],["Rong","Zhengkun",""],["Liang","Chao",""],["Zhu","Yongming",""],["Yang","Jiaqi",""],["Zhong","Tianyun",""]],"versions":[{"version":"v1","created":"Mon, 8 Jul 2024 08:12:57 GMT"}],"updateDate":"2024-07-09","timestamp":1720426377000,"abstract":"  Existing neural head avatars methods have achieved significant progress in\nthe image quality and motion range of portrait animation. However, these\nmethods neglect the computational overhead, and to the best of our knowledge,\nnone is designed to run on mobile devices. This paper presents MobilePortrait,\na lightweight one-shot neural head avatars method that reduces learning\ncomplexity by integrating external knowledge into both the motion modeling and\nimage synthesis, enabling real-time inference on mobile devices. Specifically,\nwe introduce a mixed representation of explicit and implicit keypoints for\nprecise motion modeling and precomputed visual features for enhanced foreground\nand background synthesis. With these two key designs and using simple U-Nets as\nbackbones, our method achieves state-of-the-art performance with less than\none-tenth the computational demand. It has been validated to reach speeds of\nover 100 FPS on mobile devices and support both video and audio-driven inputs.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}