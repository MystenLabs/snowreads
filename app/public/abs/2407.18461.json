{"id":"2407.18461","title":"Enhancing Dysarthric Speech Recognition for Unseen Speakers via\n  Prototype-Based Adaptation","authors":"Shiyao Wang, Shiwan Zhao, Jiaming Zhou, Aobo Kong, Yong Qin","authorsParsed":[["Wang","Shiyao",""],["Zhao","Shiwan",""],["Zhou","Jiaming",""],["Kong","Aobo",""],["Qin","Yong",""]],"versions":[{"version":"v1","created":"Fri, 26 Jul 2024 02:03:23 GMT"}],"updateDate":"2024-07-29","timestamp":1721959403000,"abstract":"  Dysarthric speech recognition (DSR) presents a formidable challenge due to\ninherent inter-speaker variability, leading to severe performance degradation\nwhen applying DSR models to new dysarthric speakers. Traditional speaker\nadaptation methodologies typically involve fine-tuning models for each speaker,\nbut this strategy is cost-prohibitive and inconvenient for disabled users,\nrequiring substantial data collection. To address this issue, we introduce a\nprototype-based approach that markedly improves DSR performance for unseen\ndysarthric speakers without additional fine-tuning. Our method employs a\nfeature extractor trained with HuBERT to produce per-word prototypes that\nencapsulate the characteristics of previously unseen speakers. These prototypes\nserve as the basis for classification. Additionally, we incorporate supervised\ncontrastive learning to refine feature extraction. By enhancing representation\nquality, we further improve DSR performance, enabling effective personalized\nDSR. We release our code at https://github.com/NKU-HLT/PB-DSR.\n","subjects":["Computing Research Repository/Sound","Computing Research Repository/Computation and Language","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}