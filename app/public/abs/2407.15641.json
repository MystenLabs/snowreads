{"id":"2407.15641","title":"Generating Sample-Based Musical Instruments Using Neural Audio Codec\n  Language Models","authors":"Shahan Nercessian, Johannes Imort, Ninon Devis, and Frederik Blang","authorsParsed":[["Nercessian","Shahan",""],["Imort","Johannes",""],["Devis","Ninon",""],["Blang","Frederik",""]],"versions":[{"version":"v1","created":"Mon, 22 Jul 2024 13:59:58 GMT"}],"updateDate":"2024-07-23","timestamp":1721656798000,"abstract":"  In this paper, we propose and investigate the use of neural audio codec\nlanguage models for the automatic generation of sample-based musical\ninstruments based on text or reference audio prompts. Our approach extends a\ngenerative audio framework to condition on pitch across an 88-key spectrum,\nvelocity, and a combined text/audio embedding. We identify maintaining timbral\nconsistency within the generated instruments as a major challenge. To tackle\nthis issue, we introduce three distinct conditioning schemes. We analyze our\nmethods through objective metrics and human listening tests, demonstrating that\nour approach can produce compelling musical instruments. Specifically, we\nintroduce a new objective metric to evaluate the timbral consistency of the\ngenerated instruments and adapt the average Contrastive Language-Audio\nPretraining (CLAP) score for the text-to-instrument case, noting that its naive\napplication is unsuitable for assessing this task. Our findings reveal a\ncomplex interplay between timbral consistency, the quality of generated\nsamples, and their correspondence to the input prompt.\n","subjects":["Electrical Engineering and Systems Science/Audio and Speech Processing","Computing Research Repository/Machine Learning","Computing Research Repository/Sound"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"R-AOWGFVz2IE-2X_5xsLgffAo6AbZFCz8TEJjYRwOYw","pdfSize":"580784"}
