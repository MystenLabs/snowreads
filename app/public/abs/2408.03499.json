{"id":"2408.03499","title":"FacialPulse: An Efficient RNN-based Depression Detection via Temporal\n  Facial Landmarks","authors":"Ruiqi Wang, Jinyang Huang, Jie Zhang, Xin Liu, Xiang Zhang, Zhi Liu,\n  Peng Zhao, Sigui Chen and Xiao Sun","authorsParsed":[["Wang","Ruiqi",""],["Huang","Jinyang",""],["Zhang","Jie",""],["Liu","Xin",""],["Zhang","Xiang",""],["Liu","Zhi",""],["Zhao","Peng",""],["Chen","Sigui",""],["Sun","Xiao",""]],"versions":[{"version":"v1","created":"Wed, 7 Aug 2024 01:50:34 GMT"}],"updateDate":"2024-08-08","timestamp":1722995434000,"abstract":"  Depression is a prevalent mental health disorder that significantly impacts\nindividuals' lives and well-being. Early detection and intervention are crucial\nfor effective treatment and management of depression. Recently, there are many\nend-to-end deep learning methods leveraging the facial expression features for\nautomatic depression detection. However, most current methods overlook the\ntemporal dynamics of facial expressions. Although very recent 3DCNN methods\nremedy this gap, they introduce more computational cost due to the selection of\nCNN-based backbones and redundant facial features.\n  To address the above limitations, by considering the timing correlation of\nfacial expressions, we propose a novel framework called FacialPulse, which\nrecognizes depression with high accuracy and speed. By harnessing the\nbidirectional nature and proficiently addressing long-term dependencies, the\nFacial Motion Modeling Module (FMMM) is designed in FacialPulse to fully\ncapture temporal features. Since the proposed FMMM has parallel processing\ncapabilities and has the gate mechanism to mitigate gradient vanishing, this\nmodule can also significantly boost the training speed.\n  Besides, to effectively use facial landmarks to replace original images to\ndecrease information redundancy, a Facial Landmark Calibration Module (FLCM) is\ndesigned to eliminate facial landmark errors to further improve recognition\naccuracy. Extensive experiments on the AVEC2014 dataset and MMDA dataset (a\ndepression dataset) demonstrate the superiority of FacialPulse on recognition\naccuracy and speed, with the average MAE (Mean Absolute Error) decreased by 21%\ncompared to baselines, and the recognition speed increased by 100% compared to\nstate-of-the-art methods. Codes are released at\nhttps://github.com/volatileee/FacialPulse.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}