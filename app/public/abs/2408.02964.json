{"id":"2408.02964","title":"Accuracy and Consistency of LLMs in the Registered Dietitian Exam: The\n  Impact of Prompt Engineering and Knowledge Retrieval","authors":"Iman Azimi, Mohan Qi, Li Wang, Amir M. Rahmani, Youlin Li","authorsParsed":[["Azimi","Iman",""],["Qi","Mohan",""],["Wang","Li",""],["Rahmani","Amir M.",""],["Li","Youlin",""]],"versions":[{"version":"v1","created":"Tue, 6 Aug 2024 05:21:13 GMT"},{"version":"v2","created":"Wed, 7 Aug 2024 18:50:48 GMT"}],"updateDate":"2024-08-09","timestamp":1722921673000,"abstract":"  Large language models (LLMs) are fundamentally transforming human-facing\napplications in the health and well-being domains: boosting patient engagement,\naccelerating clinical decision-making, and facilitating medical education.\nAlthough state-of-the-art LLMs have shown superior performance in several\nconversational applications, evaluations within nutrition and diet applications\nare still insufficient. In this paper, we propose to employ the Registered\nDietitian (RD) exam to conduct a standard and comprehensive evaluation of\nstate-of-the-art LLMs, GPT-4o, Claude 3.5 Sonnet, and Gemini 1.5 Pro, assessing\nboth accuracy and consistency in nutrition queries. Our evaluation includes\n1050 RD exam questions encompassing several nutrition topics and proficiency\nlevels. In addition, for the first time, we examine the impact of Zero-Shot\n(ZS), Chain of Thought (CoT), Chain of Thought with Self Consistency (CoT-SC),\nand Retrieval Augmented Prompting (RAP) on both accuracy and consistency of the\nresponses. Our findings revealed that while these LLMs obtained acceptable\noverall performance, their results varied considerably with different prompts\nand question domains. GPT-4o with CoT-SC prompting outperformed the other\napproaches, whereas Gemini 1.5 Pro with ZS recorded the highest consistency.\nFor GPT-4o and Claude 3.5, CoT improved the accuracy, and CoT-SC improved both\naccuracy and consistency. RAP was particularly effective for GPT-4o to answer\nExpert level questions. Consequently, choosing the appropriate LLM and\nprompting technique, tailored to the proficiency level and specific domain, can\nmitigate errors and potential risks in diet and nutrition chatbots.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/"}