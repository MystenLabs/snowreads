{"id":"2407.15216","title":"Explainability Paths for Sustained Artistic Practice with AI","authors":"Austin Tecks, Thomas Peschlow and Gabriel Vigliensoni","authorsParsed":[["Tecks","Austin",""],["Peschlow","Thomas",""],["Vigliensoni","Gabriel",""]],"versions":[{"version":"v1","created":"Sun, 21 Jul 2024 16:48:14 GMT"}],"updateDate":"2024-07-23","timestamp":1721580494000,"abstract":"  The development of AI-driven generative audio mirrors broader AI trends,\noften prioritizing immediate accessibility at the expense of explainability.\nConsequently, integrating such tools into sustained artistic practice remains a\nsignificant challenge. In this paper, we explore several paths to improve\nexplainability, drawing primarily from our research-creation practice in\ntraining and implementing generative audio models. As practical provisions for\nimproved explainability, we highlight human agency over training materials, the\nviability of small-scale datasets, the facilitation of the iterative creative\nprocess, and the integration of interactive machine learning as a mapping tool.\nImportantly, these steps aim to enhance human agency over generative AI systems\nnot only during model inference, but also when curating and preprocessing\ntraining data as well as during the training phase of models.\n","subjects":["Computing Research Repository/Sound","Computing Research Repository/Artificial Intelligence","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"BCWlUy0NTa34HAUgOyaPx_Wu0f1dzD1-2r3giQF3Ozo","pdfSize":"107095"}
