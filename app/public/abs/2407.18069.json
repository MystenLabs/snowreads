{"id":"2407.18069","title":"C2P: Featuring Large Language Models with Causal Reasoning","authors":"Abdolmahdi Bagheri, Matin Alinejad, Kevin Bello, Alireza Akhondi-Asl","authorsParsed":[["Bagheri","Abdolmahdi",""],["Alinejad","Matin",""],["Bello","Kevin",""],["Akhondi-Asl","Alireza",""]],"versions":[{"version":"v1","created":"Thu, 25 Jul 2024 14:24:57 GMT"},{"version":"v2","created":"Sun, 11 Aug 2024 15:45:07 GMT"}],"updateDate":"2024-08-13","timestamp":1721917497000,"abstract":"  Causal reasoning is the primary bottleneck that Large Language Models (LLMs)\nmust overcome to attain human-level intelligence. To address this, we introduce\nthe Causal Chain of Prompting (C2P) as the first reasoning framework that\nequips current LLMs with causal reasoning capabilities. C2P operates\nautonomously, avoiding reliance on external tools or modules during both the\ncausal learning and reasoning phases, and can be seamlessly implemented during\nthe training or fine-tuning of LLMs. Experimental results across various\nbenchmark datasets demonstrate a significant improvement in causal learning and\nsubsequent reasoning accuracy of LLMs. We illustrate how C2P enhances LLMs'\nability to causally reason in real-world scenarios, addressing complex problems\nin fields such as healthcare, medicine, economics, education, social sciences,\nenvironmental science, and marketing. With few-shot learning, GPT-4 Turbo using\nC2P with as few as six examples achieves significant performance improvements,\nboasting over a 33% increase in reasoning accuracy over the most\nstate-of-the-art LLMs, which perform nearly randomly in similar circumstances.\nThis demonstrates the transformative potential of integrating C2P into LLM\ntraining or fine-tuning processes, thereby empowering these models with\nadvanced causal reasoning capabilities.\n","subjects":["Computing Research Repository/Logic in Computer Science"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}