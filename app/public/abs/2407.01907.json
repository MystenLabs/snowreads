{"id":"2407.01907","title":"The Solution for the ICCV 2023 Perception Test Challenge 2023 -- Task 6\n  -- Grounded videoQA","authors":"Hailiang Zhang, Dian Chao, Zhihao Guan, Yang Yang","authorsParsed":[["Zhang","Hailiang",""],["Chao","Dian",""],["Guan","Zhihao",""],["Yang","Yang",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 03:13:27 GMT"}],"updateDate":"2024-07-03","timestamp":1719890007000,"abstract":"  In this paper, we introduce a grounded video question-answering solution. Our\nresearch reveals that the fixed official baseline method for video question\nanswering involves two main steps: visual grounding and object tracking.\nHowever, a significant challenge emerges during the initial step, where\nselected frames may lack clearly identifiable target objects. Furthermore,\nsingle images cannot address questions like \"Track the container from which the\nperson pours the first time.\" To tackle this issue, we propose an alternative\ntwo-stage approach:(1) First, we leverage the VALOR model to answer questions\nbased on video information.(2) concatenate the answered questions with their\nrespective answers. Finally, we employ TubeDETR to generate bounding boxes for\nthe targets.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}