{"id":"2408.10416","title":"Issues of parameterization and computation for posterior inference in\n  partially identified models","authors":"Seren Lee, Paul Gustafson","authorsParsed":[["Lee","Seren",""],["Gustafson","Paul",""]],"versions":[{"version":"v1","created":"Mon, 19 Aug 2024 21:04:13 GMT"}],"updateDate":"2024-08-21","timestamp":1724101453000,"abstract":"  A partially identified model, where the parameters can not be uniquely\nidentified, often arises during statistical analysis. While researchers\nfrequently use Bayesian inference to analyze the models, when Bayesian\ninference with an off-the-shelf MCMC sampling algorithm is applied to a\npartially identified model, the computational performance can be poor. It is\nfound that using importance sampling with transparent reparameterization (TP)\nis one remedy. This method is preferable since the model is known to be\nrendered as identified with respect to the new parameterization, and at the\nsame time, it may allow faster, i.i.d. Monte Carlo sampling by using conjugate\nconvenience priors. In this paper, we explain the importance sampling method\nwith the TP and a pseudo-TP. We introduce the pseudo-TP, an alternative to TP,\nsince finding a TP is sometimes difficult. Then, we test the methods'\nperformance in some scenarios and compare it to the performance of the\noff-the-shelf MCMC method - Gibbs sampling - applied in the original\nparameterization. While the importance sampling with TP (ISTP) shows generally\nbetter results than off-the-shelf MCMC methods, as seen in the compute time and\ntrace plots, it is also seen that finding a TP which is necessary for the\nmethod may not be easy. On the other hand, the pseudo-TP method shows a mixed\nresult and room for improvement since it relies on an approximation, which may\nnot be adequate for a given model and dataset.\n","subjects":["Statistics/Computation"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}