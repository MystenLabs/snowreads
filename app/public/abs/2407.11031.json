{"id":"2407.11031","title":"Purification Of Contaminated Convolutional Neural Networks Via Robust\n  Recovery: An Approach with Theoretical Guarantee in One-Hidden-Layer Case","authors":"Hanxiao Lu, Zeyu Huang, Ren Wang","authorsParsed":[["Lu","Hanxiao",""],["Huang","Zeyu",""],["Wang","Ren",""]],"versions":[{"version":"v1","created":"Thu, 4 Jul 2024 02:43:23 GMT"}],"updateDate":"2024-07-17","timestamp":1720061003000,"abstract":"  Convolutional neural networks (CNNs), one of the key architectures of deep\nlearning models, have achieved superior performance on many machine learning\ntasks such as image classification, video recognition, and power systems.\nDespite their success, CNNs can be easily contaminated by natural noises and\nartificially injected noises such as backdoor attacks. In this paper, we\npropose a robust recovery method to remove the noise from the potentially\ncontaminated CNNs and provide an exact recovery guarantee on one-hidden-layer\nnon-overlapping CNNs with the rectified linear unit (ReLU) activation function.\nOur theoretical results show that both CNNs' weights and biases can be exactly\nrecovered under the overparameterization setting with some mild assumptions.\nThe experimental results demonstrate the correctness of the proofs and the\neffectiveness of the method in both the synthetic environment and the practical\nneural network setting. Our results also indicate that the proposed method can\nbe extended to multiple-layer CNNs and potentially serve as a defense strategy\nagainst backdoor attacks.\n","subjects":["Computing Research Repository/Machine Learning","Electrical Engineering and Systems Science/Signal Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}