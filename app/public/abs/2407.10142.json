{"id":"2407.10142","title":"PARE-Net: Position-Aware Rotation-Equivariant Networks for Robust Point\n  Cloud Registration","authors":"Runzhao Yao, Shaoyi Du, Wenting Cui, Canhui Tang, Chengwu Yang","authorsParsed":[["Yao","Runzhao",""],["Du","Shaoyi",""],["Cui","Wenting",""],["Tang","Canhui",""],["Yang","Chengwu",""]],"versions":[{"version":"v1","created":"Sun, 14 Jul 2024 10:26:38 GMT"}],"updateDate":"2024-07-16","timestamp":1720952798000,"abstract":"  Learning rotation-invariant distinctive features is a fundamental requirement\nfor point cloud registration. Existing methods often use rotation-sensitive\nnetworks to extract features, while employing rotation augmentation to learn an\napproximate invariant mapping rudely. This makes networks fragile to rotations,\noverweight, and hinders the distinctiveness of features. To tackle these\nproblems, we propose a novel position-aware rotation-equivariant network, for\nefficient, light-weighted, and robust registration. The network can provide a\nstrong model inductive bias to learn rotation-equivariant/invariant features,\nthus addressing the aforementioned limitations. To further improve the\ndistinctiveness of descriptors, we propose a position-aware convolution, which\ncan better learn spatial information of local structures. Moreover, we also\npropose a feature-based hypothesis proposer. It leverages rotation-equivariant\nfeatures that encode fine-grained structure orientations to generate reliable\nmodel hypotheses. Each correspondence can generate a hypothesis, thus it is\nmore efficient than classic estimators that require multiple reliable\ncorrespondences. Accordingly, a contrastive rotation loss is presented to\nenhance the robustness of rotation-equivariant features against data\ndegradation. Extensive experiments on indoor and outdoor datasets demonstrate\nthat our method significantly outperforms the SOTA methods in terms of\nregistration recall while being lightweight and keeping a fast speed. Moreover,\nexperiments on rotated datasets demonstrate its robustness against rotation\nvariations. Code is available at https://github.com/yaorz97/PARENet.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}