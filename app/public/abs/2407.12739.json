{"id":"2407.12739","title":"GroundUp: Rapid Sketch-Based 3D City Massing","authors":"Gizem Esra Unlu, Mohamed Sayed, Yulia Gryaditskaya, Gabriel Brostow","authorsParsed":[["Unlu","Gizem Esra",""],["Sayed","Mohamed",""],["Gryaditskaya","Yulia",""],["Brostow","Gabriel",""]],"versions":[{"version":"v1","created":"Wed, 17 Jul 2024 16:59:29 GMT"}],"updateDate":"2024-07-18","timestamp":1721235569000,"abstract":"  We propose GroundUp, the first sketch-based ideation tool for 3D city massing\nof urban areas. We focus on early-stage urban design, where sketching is a\ncommon tool and the design starts from balancing building volumes (masses) and\nopen spaces. With Human-Centered AI in mind, we aim to help architects quickly\nrevise their ideas by easily switching between 2D sketches and 3D models,\nallowing for smoother iteration and sharing of ideas. Inspired by feedback from\narchitects and existing workflows, our system takes as a first input a user\nsketch of multiple buildings in a top-down view. The user then draws a\nperspective sketch of the envisioned site. Our method is designed to exploit\nthe complementarity of information in the two sketches and allows users to\nquickly preview and adjust the inferred 3D shapes. Our model has two main\ncomponents. First, we propose a novel sketch-to-depth prediction network for\nperspective sketches that exploits top-down sketch shapes. Second, we use depth\ncues derived from the perspective sketch as a condition to our diffusion model,\nwhich ultimately completes the geometry in a top-down view. Thus, our final 3D\ngeometry is represented as a heightfield, allowing users to construct the city\n`from the ground up'.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Human-Computer Interaction"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"f2IUAINjpHYw8r4v2kwzJ5gN013FSXPOYw1E4MN30u0","pdfSize":"17976754"}
