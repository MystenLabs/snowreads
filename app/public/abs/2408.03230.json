{"id":"2408.03230","title":"Contrastive Learning for Image Complexity Representation","authors":"Shipeng Liu, Liang Zhao, Dengfeng Chen, Zhanping Song","authorsParsed":[["Liu","Shipeng",""],["Zhao","Liang",""],["Chen","Dengfeng",""],["Song","Zhanping",""]],"versions":[{"version":"v1","created":"Tue, 6 Aug 2024 14:44:55 GMT"}],"updateDate":"2024-08-07","timestamp":1722955495000,"abstract":"  Quantifying and evaluating image complexity can be instrumental in enhancing\nthe performance of various computer vision tasks. Supervised learning can\neffectively learn image complexity features from well-annotated datasets.\nHowever, creating such datasets requires expensive manual annotation costs. The\nmodels may learn human subjective biases from it. In this work, we introduce\nthe MoCo v2 framework. We utilize contrastive learning to represent image\ncomplexity, named CLIC (Contrastive Learning for Image Complexity). We find\nthat there are complexity differences between different local regions of an\nimage, and propose Random Crop and Mix (RCM), which can produce positive\nsamples consisting of multi-scale local crops. RCM can also expand the train\nset and increase data diversity without introducing additional data. We conduct\nextensive experiments with CLIC, comparing it with both unsupervised and\nsupervised methods. The results demonstrate that the performance of CLIC is\ncomparable to that of state-of-the-art supervised methods. In addition, we\nestablish the pipelines that can apply CLIC to computer vision tasks to\neffectively improve their performance.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}