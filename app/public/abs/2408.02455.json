{"id":"2408.02455","title":"A Surprisingly Efficient Representation for Multi-Finger Grasping","authors":"Hengxu Yan, Hao-Shu Fang, Cewu Lu","authorsParsed":[["Yan","Hengxu",""],["Fang","Hao-Shu",""],["Lu","Cewu",""]],"versions":[{"version":"v1","created":"Mon, 5 Aug 2024 13:25:29 GMT"}],"updateDate":"2024-08-06","timestamp":1722864329000,"abstract":"  The problem of grasping objects using a multi-finger hand has received\nsignificant attention in recent years. However, it remains challenging to\nhandle a large number of unfamiliar objects in real and cluttered environments.\nIn this work, we propose a representation that can be effectively mapped to the\nmulti-finger grasp space. Based on this representation, we develop a simple\ndecision model that generates accurate grasp quality scores for different\nmulti-finger grasp poses using only hundreds to thousands of training samples.\nWe demonstrate that our representation performs well on a real robot and\nachieves a success rate of 78.64% after training with only 500 real-world grasp\nattempts and 87% with 4500 grasp attempts. Additionally, we achieve a success\nrate of 84.51% in a dynamic human-robot handover scenario using a multi-finger\nhand.\n","subjects":["Computing Research Repository/Robotics"],"license":"http://creativecommons.org/licenses/by/4.0/"}