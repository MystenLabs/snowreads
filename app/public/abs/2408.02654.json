{"id":"2408.02654","title":"On Using Quasirandom Sequences in Machine Learning for Model Weight\n  Initialization","authors":"Andriy Miranskyy and Adam Sorrenti and Viral Thakar","authorsParsed":[["Miranskyy","Andriy",""],["Sorrenti","Adam",""],["Thakar","Viral",""]],"versions":[{"version":"v1","created":"Mon, 5 Aug 2024 17:33:09 GMT"}],"updateDate":"2024-08-06","timestamp":1722879189000,"abstract":"  The effectiveness of training neural networks directly impacts computational\ncosts, resource allocation, and model development timelines in machine learning\napplications. An optimizer's ability to train the model adequately (in terms of\ntrained model performance) depends on the model's initial weights. Model weight\ninitialization schemes use pseudorandom number generators (PRNGs) as a source\nof randomness.\n  We investigate whether substituting PRNGs for low-discrepancy quasirandom\nnumber generators (QRNGs) -- namely Sobol' sequences -- as a source of\nrandomness for initializers can improve model performance. We examine\nMulti-Layer Perceptrons (MLP), Convolutional Neural Networks (CNN), Long\nShort-Term Memory (LSTM), and Transformer architectures trained on MNIST,\nCIFAR-10, and IMDB datasets using SGD and Adam optimizers. Our analysis uses\nten initialization schemes: Glorot, He, Lecun (both Uniform and Normal);\nOrthogonal, Random Normal, Truncated Normal, and Random Uniform. Models with\nweights set using PRNG- and QRNG-based initializers are compared pairwise for\neach combination of dataset, architecture, optimizer, and initialization\nscheme.\n  Our findings indicate that QRNG-based neural network initializers either\nreach a higher accuracy or achieve the same accuracy more quickly than\nPRNG-based initializers in 60% of the 120 experiments conducted. Thus, using\nQRNG-based initializers instead of PRNG-based initializers can speed up and\nimprove model training.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}