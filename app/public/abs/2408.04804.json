{"id":"2408.04804","title":"Hyper-YOLO: When Visual Object Detection Meets Hypergraph Computation","authors":"Yifan Feng, Jiangang Huang, Shaoyi Du, Shihui Ying, Jun-Hai Yong,\n  Yipeng Li, Guiguang Ding, Rongrong Ji, Yue Gao","authorsParsed":[["Feng","Yifan",""],["Huang","Jiangang",""],["Du","Shaoyi",""],["Ying","Shihui",""],["Yong","Jun-Hai",""],["Li","Yipeng",""],["Ding","Guiguang",""],["Ji","Rongrong",""],["Gao","Yue",""]],"versions":[{"version":"v1","created":"Fri, 9 Aug 2024 01:21:15 GMT"}],"updateDate":"2024-08-12","timestamp":1723166475000,"abstract":"  We introduce Hyper-YOLO, a new object detection method that integrates\nhypergraph computations to capture the complex high-order correlations among\nvisual features. Traditional YOLO models, while powerful, have limitations in\ntheir neck designs that restrict the integration of cross-level features and\nthe exploitation of high-order feature interrelationships. To address these\nchallenges, we propose the Hypergraph Computation Empowered Semantic Collecting\nand Scattering (HGC-SCS) framework, which transposes visual feature maps into a\nsemantic space and constructs a hypergraph for high-order message propagation.\nThis enables the model to acquire both semantic and structural information,\nadvancing beyond conventional feature-focused learning. Hyper-YOLO incorporates\nthe proposed Mixed Aggregation Network (MANet) in its backbone for enhanced\nfeature extraction and introduces the Hypergraph-Based Cross-Level and\nCross-Position Representation Network (HyperC2Net) in its neck. HyperC2Net\noperates across five scales and breaks free from traditional grid structures,\nallowing for sophisticated high-order interactions across levels and positions.\nThis synergy of components positions Hyper-YOLO as a state-of-the-art\narchitecture in various scale models, as evidenced by its superior performance\non the COCO dataset. Specifically, Hyper-YOLO-N significantly outperforms the\nadvanced YOLOv8-N and YOLOv9-T with 12\\% $\\text{AP}^{val}$ and 9\\%\n$\\text{AP}^{val}$ improvements. The source codes are at\nttps://github.com/iMoonLab/Hyper-YOLO.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}