{"id":"2407.03507","title":"Improved Iteration Complexity in Black-Box Optimization Problems under\n  Higher Order Smoothness Function Condition","authors":"Aleksandr Lobanov","authorsParsed":[["Lobanov","Aleksandr",""]],"versions":[{"version":"v1","created":"Wed, 3 Jul 2024 21:11:08 GMT"}],"updateDate":"2024-07-08","timestamp":1720041068000,"abstract":"  This paper is devoted to the study (common in many applications) of the\nblack-box optimization problem, where the black-box represents a gradient-free\noracle $\\tilde{f} = f(x) + \\xi$ providing the objective function value with\nsome stochastic noise. Assuming that the objective function is $\\mu$-strongly\nconvex, and also not just $L$-smooth, but has a higher order of smoothness\n($\\beta \\geq 2$) we provide a novel optimization method: Zero-Order Accelerated\nBatched Stochastic Gradient Descent, whose theoretical analysis closes the\nquestion regarding the iteration complexity, achieving optimal estimates.\nMoreover, we provide a thorough analysis of the maximum noise level, and show\nunder which condition the maximum noise level will take into account\ninformation about batch size $B$ as well as information about the smoothness\norder of the function $\\beta$.\n","subjects":["Mathematics/Optimization and Control"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}