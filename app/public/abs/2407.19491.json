{"id":"2407.19491","title":"Multi-modal Crowd Counting via Modal Emulation","authors":"Chenhao Wang, Xiaopeng Hong, Zhiheng Ma, Yupeng Wei, Yabin Wang,\n  Xiaopeng Fan","authorsParsed":[["Wang","Chenhao",""],["Hong","Xiaopeng",""],["Ma","Zhiheng",""],["Wei","Yupeng",""],["Wang","Yabin",""],["Fan","Xiaopeng",""]],"versions":[{"version":"v1","created":"Sun, 28 Jul 2024 13:14:57 GMT"}],"updateDate":"2024-07-30","timestamp":1722172497000,"abstract":"  Multi-modal crowd counting is a crucial task that uses multi-modal cues to\nestimate the number of people in crowded scenes. To overcome the gap between\ndifferent modalities, we propose a modal emulation-based two-pass multi-modal\ncrowd-counting framework that enables efficient modal emulation, alignment, and\nfusion. The framework consists of two key components: a \\emph{multi-modal\ninference} pass and a \\emph{cross-modal emulation} pass. The former utilizes a\nhybrid cross-modal attention module to extract global and local information and\nachieve efficient multi-modal fusion. The latter uses attention prompting to\ncoordinate different modalities and enhance multi-modal alignment. We also\nintroduce a modality alignment module that uses an efficient modal consistency\nloss to align the outputs of the two passes and bridge the semantic gap between\nmodalities. Extensive experiments on both RGB-Thermal and RGB-Depth counting\ndatasets demonstrate its superior performance compared to previous methods.\nCode available at\nhttps://github.com/Mr-Monday/Multi-modal-Crowd-Counting-via-Modal-Emulation.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}