{"id":"2408.12116","title":"Geolocation Representation from Large Language Models are Generic\n  Enhancers for Spatio-Temporal Learning","authors":"Junlin He, Tong Nie, Wei Ma","authorsParsed":[["He","Junlin",""],["Nie","Tong",""],["Ma","Wei",""]],"versions":[{"version":"v1","created":"Thu, 22 Aug 2024 04:05:02 GMT"}],"updateDate":"2024-08-23","timestamp":1724299502000,"abstract":"  In the geospatial domain, universal representation models are significantly\nless prevalent than their extensive use in natural language processing and\ncomputer vision. This discrepancy arises primarily from the high costs\nassociated with the input of existing representation models, which often\nrequire street views and mobility data. To address this, we develop a novel,\ntraining-free method that leverages large language models (LLMs) and auxiliary\nmap data from OpenStreetMap to derive geolocation representations (LLMGeovec).\nLLMGeovec can represent the geographic semantics of city, country, and global\nscales, which acts as a generic enhancer for spatio-temporal learning.\nSpecifically, by direct feature concatenation, we introduce a simple yet\neffective paradigm for enhancing multiple spatio-temporal tasks including\ngeographic prediction (GP), long-term time series forecasting (LTSF), and\ngraph-based spatio-temporal forecasting (GSTF). LLMGeovec can seamlessly\nintegrate into a wide spectrum of spatio-temporal learning models, providing\nimmediate enhancements. Experimental results demonstrate that LLMGeovec\nachieves global coverage and significantly boosts the performance of leading\nGP, LTSF, and GSTF models.\n","subjects":["Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}