{"id":"2407.11536","title":"Fine-Tuning Medical Language Models for Enhanced Long-Contextual\n  Understanding and Domain Expertise","authors":"Qimin Yang, Rongsheng Wang, Jiexin Chen, Runqi Su, Tao Tan","authorsParsed":[["Yang","Qimin",""],["Wang","Rongsheng",""],["Chen","Jiexin",""],["Su","Runqi",""],["Tan","Tao",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 09:37:20 GMT"}],"updateDate":"2024-07-17","timestamp":1721122640000,"abstract":"  Large Language Models (LLMs) have been widely applied in various professional\nfields. By fine-tuning the models using domain specific question and answer\ndatasets, the professional domain knowledge and Q\\&A abilities of these models\nhave significantly improved, for example, medical professional LLMs that use\nfine-tuning of doctor-patient Q\\&A data exhibit extraordinary disease\ndiagnostic abilities. However, we observed that despite improvements in\nspecific domain knowledge, the performance of medical LLM in long-context\nunderstanding has significantly declined, especially compared to general\nlanguage models with similar parameters. The purpose of this study is to\ninvestigate the phenomenon of reduced performance in understanding long-context\nin medical LLM. We designed a series of experiments to conduct open-book\nprofessional knowledge exams on all models to evaluate their ability to read\nlong-context. By adjusting the proportion and quantity of general data and\nmedical data in the process of fine-tuning, we can determine the best data\ncomposition to optimize the professional model and achieve a balance between\nlong-context performance and specific domain knowledge.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}