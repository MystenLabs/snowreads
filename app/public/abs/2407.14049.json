{"id":"2407.14049","title":"Prompted Aspect Key Point Analysis for Quantitative Review Summarization","authors":"An Quang Tang, Xiuzhen Zhang, Minh Ngoc Dinh, Erik Cambria","authorsParsed":[["Tang","An Quang",""],["Zhang","Xiuzhen",""],["Dinh","Minh Ngoc",""],["Cambria","Erik",""]],"versions":[{"version":"v1","created":"Fri, 19 Jul 2024 06:07:32 GMT"}],"updateDate":"2024-07-22","timestamp":1721369252000,"abstract":"  Key Point Analysis (KPA) aims for quantitative summarization that provides\nkey points (KPs) as succinct textual summaries and quantities measuring their\nprevalence. KPA studies for arguments and reviews have been reported in the\nliterature. A majority of KPA studies for reviews adopt supervised learning to\nextract short sentences as KPs before matching KPs to review comments for\nquantification of KP prevalence. Recent abstractive approaches still generate\nKPs based on sentences, often leading to KPs with overlapping and hallucinated\nopinions, and inaccurate quantification. In this paper, we propose Prompted\nAspect Key Point Analysis (PAKPA) for quantitative review summarization. PAKPA\nemploys aspect sentiment analysis and prompted in-context learning with Large\nLanguage Models (LLMs) to generate and quantify KPs grounded in aspects for\nbusiness entities, which achieves faithful KPs with accurate quantification,\nand removes the need for large amounts of annotated data for supervised\ntraining. Experiments on the popular review dataset Yelp and the\naspect-oriented review summarization dataset SPACE show that our framework\nachieves state-of-the-art performance. Source code and data are available at:\nhttps://github.com/antangrocket1312/PAKPA\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/"}