{"id":"2408.08984","title":"Fire Dynamic Vision: Image Segmentation and Tracking for Multi-Scale\n  Fire and Plume Behavior","authors":"Daryn Sagel and Bryan Quaife","authorsParsed":[["Sagel","Daryn",""],["Quaife","Bryan",""]],"versions":[{"version":"v1","created":"Fri, 16 Aug 2024 19:25:19 GMT"}],"updateDate":"2024-08-20","timestamp":1723836319000,"abstract":"  The increasing frequency and severity of wildfires highlight the need for\naccurate fire and plume spread models. We introduce an approach that\neffectively isolates and tracks fire and plume behavior across various spatial\nand temporal scales and image types, identifying physical phenomena in the\nsystem and providing insights useful for developing and validating models. Our\nmethod combines image segmentation and graph theory to delineate fire fronts\nand plume boundaries. We demonstrate that the method effectively distinguishes\nfires and plumes from visually similar objects. Results demonstrate the\nsuccessful isolation and tracking of fire and plume dynamics across various\nimage sources, ranging from synoptic-scale ($10^4$-$10^5$ m) satellite images\nto sub-microscale ($10^0$-$10^1$ m) images captured close to the fire\nenvironment. Furthermore, the methodology leverages image inpainting and\nspatio-temporal dataset generation for use in statistical and machine learning\nmodels.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}