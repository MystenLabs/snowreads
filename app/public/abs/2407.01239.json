{"id":"2407.01239","title":"SGCCNet: Single-Stage 3D Object Detector With Saliency-Guided Data\n  Augmentation and Confidence Correction Mechanism","authors":"Ao Liang, Wenyu Chen, Jian Fang and Huaici Zhao","authorsParsed":[["Liang","Ao",""],["Chen","Wenyu",""],["Fang","Jian",""],["Zhao","Huaici",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 12:36:01 GMT"}],"updateDate":"2024-07-02","timestamp":1719837361000,"abstract":"  The single-stage point-based 3D object detectors have attracted widespread\nresearch interest due to their advantages of lightweight and fast inference\nspeed. However, they still face challenges such as inadequate learning of\nlow-quality objects (ILQ) and misalignment between localization accuracy and\nclassification confidence (MLC). In this paper, we propose SGCCNet to alleviate\nthese two issues. For ILQ, SGCCNet adopts a Saliency-Guided Data Augmentation\n(SGDA) strategy to enhance the robustness of the model on low-quality objects\nby reducing its reliance on salient features. Specifically, We construct a\nclassification task and then approximate the saliency scores of points by\nmoving points towards the point cloud centroid in a differentiable process.\nDuring the training process, SGCCNet will be forced to learn from low saliency\nfeatures through dropping points. Meanwhile, to avoid internal covariate shift\nand contextual features forgetting caused by dropping points, we add a\ngeometric normalization module and skip connection block in each stage. For\nMLC, we design a Confidence Correction Mechanism (CCM) specifically for\npoint-based multi-class detectors. This mechanism corrects the confidence of\nthe current proposal by utilizing the predictions of other key points within\nthe local region in the post-processing stage. Extensive experiments on the\nKITTI dataset demonstrate the generality and effectiveness of our SGCCNet. On\nthe KITTI \\textit{test} set, SGCCNet achieves $80.82\\%$ for the metric of\n$AP_{3D}$ on the \\textit{Moderate} level, outperforming all other point-based\ndetectors, surpassing IA-SSD and Fast Point R-CNN by $2.35\\%$ and $3.42\\%$,\nrespectively. Additionally, SGCCNet demonstrates excellent portability for\nother point-based detectors\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}