{"id":"2408.11860","title":"Risks and NLP Design: A Case Study on Procedural Document QA","authors":"Nikita Haduong (1), Alice Gao (1), Noah A. Smith (1 and 2) ((1) Paul\n  G. Allen School of Computer Science & Engineering, University of Washington,\n  (2) Allen Institute for Artificial Intelligence)","authorsParsed":[["Haduong","Nikita","","1 and 2"],["Gao","Alice","","1 and 2"],["Smith","Noah A.","","1 and 2"]],"versions":[{"version":"v1","created":"Fri, 16 Aug 2024 17:23:43 GMT"}],"updateDate":"2024-08-23","timestamp":1723829023000,"abstract":"  As NLP systems are increasingly deployed at scale, concerns about their\npotential negative impacts have attracted the attention of the research\ncommunity, yet discussions of risk have mostly been at an abstract level and\nfocused on generic AI or NLP applications. We argue that clearer assessments of\nrisks and harms to users--and concrete strategies to mitigate them--will be\npossible when we specialize the analysis to more concrete applications and\ntheir plausible users. As an illustration, this paper is grounded in cooking\nrecipe procedural document question answering (ProcDocQA), where there are\nwell-defined risks to users such as injuries or allergic reactions. Our case\nstudy shows that an existing language model, applied in \"zero-shot\" mode,\nquantitatively answers real-world questions about recipes as well or better\nthan the humans who have answered the questions on the web. Using a novel\nquestionnaire informed by theoretical work on AI risk, we conduct a\nrisk-oriented error analysis that could then inform the design of a future\nsystem to be deployed with lower risk of harm and better performance.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Human-Computer Interaction"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}