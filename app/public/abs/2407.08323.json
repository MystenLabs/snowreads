{"id":"2407.08323","title":"Leveraging GPT for the Generation of Multi-Platform Social Media\n  Datasets for Research","authors":"Henry Tari, Danial Khan, Justus Rutten, Darian Othman, Rishabh\n  Kaushal, Thales Bertaglia, and Adriana Iamnitchi","authorsParsed":[["Tari","Henry",""],["Khan","Danial",""],["Rutten","Justus",""],["Othman","Darian",""],["Kaushal","Rishabh",""],["Bertaglia","Thales",""],["Iamnitchi","Adriana",""]],"versions":[{"version":"v1","created":"Thu, 11 Jul 2024 09:12:39 GMT"}],"updateDate":"2024-07-12","timestamp":1720689159000,"abstract":"  Social media datasets are essential for research on disinformation, influence\noperations, social sensing, hate speech detection, cyberbullying, and other\nsignificant topics. However, access to these datasets is often restricted due\nto costs and platform regulations. As such, acquiring datasets that span\nmultiple platforms which are crucial for a comprehensive understanding of the\ndigital ecosystem is particularly challenging. This paper explores the\npotential of large language models to create lexically and semantically\nrelevant social media datasets across multiple platforms, aiming to match the\nquality of real datasets. We employ ChatGPT to generate synthetic data from two\nreal datasets, each consisting of posts from three different social media\nplatforms. We assess the lexical and semantic properties of the synthetic data\nand compare them with those of the real data. Our empirical findings suggest\nthat using large language models to generate synthetic multi-platform social\nmedia data is promising. However, further enhancements are necessary to improve\nthe fidelity of the outputs.\n","subjects":["Computing Research Repository/Computers and Society"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}