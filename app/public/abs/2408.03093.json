{"id":"2408.03093","title":"Learning Provably Robust Policies in Uncertain Parametric Environments","authors":"Yannik Schnitzer, Alessandro Abate, David Parker","authorsParsed":[["Schnitzer","Yannik",""],["Abate","Alessandro",""],["Parker","David",""]],"versions":[{"version":"v1","created":"Tue, 6 Aug 2024 10:48:15 GMT"}],"updateDate":"2024-08-07","timestamp":1722941295000,"abstract":"  We present a data-driven approach for learning MDP policies that are robust\nacross stochastic environments whose transition probabilities are defined by\nparameters with an unknown distribution. We produce probably approximately\ncorrect (PAC) guarantees for the performance of these learned policies in a\nnew, unseen environment over the unknown distribution. Our approach is based on\nfinite samples of the MDP environments, for each of which we build an\napproximation of the model as an interval MDP, by exploring a set of generated\ntrajectories. We use the built approximations to synthesise a single policy\nthat performs well (meets given requirements) across the sampled environments,\nand furthermore bound its risk (of not meeting the given requirements) when\ndeployed in an unseen environment. Our procedure offers a trade-off between the\nguaranteed performance of the learned policy and the risk of not meeting the\nguarantee in an unseen environment. Our approach exploits knowledge of the\nenvironment's state space and graph structure, and we show how additional\nknowledge of its parametric structure can be leveraged to optimize learning and\nto obtain tighter guarantees from less samples. We evaluate our approach on a\ndiverse range of established benchmarks, demonstrating that we can generate\nhighly performing and robust policies, along with guarantees that tightly\nquantify their performance and the associated risk.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Systems and Control","Electrical Engineering and Systems Science/Systems and Control"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"RDlc5Wb9SfWR9sP1-GthNfl4Td9y2Y4hcSyxtllDppQ","pdfSize":"1282047"}
