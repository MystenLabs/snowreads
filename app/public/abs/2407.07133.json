{"id":"2407.07133","title":"Neuromimetic metaplasticity for adaptive continual learning","authors":"Suhee Cho, Hyeonsu Lee, Seungdae Baek and Se-Bum Paik","authorsParsed":[["Cho","Suhee",""],["Lee","Hyeonsu",""],["Baek","Seungdae",""],["Paik","Se-Bum",""]],"versions":[{"version":"v1","created":"Tue, 9 Jul 2024 12:21:35 GMT"}],"updateDate":"2024-07-11","timestamp":1720527695000,"abstract":"  Conventional intelligent systems based on deep neural network (DNN) models\nencounter challenges in achieving human-like continual learning due to\ncatastrophic forgetting. Here, we propose a metaplasticity model inspired by\nhuman working memory, enabling DNNs to perform catastrophic forgetting-free\ncontinual learning without any pre- or post-processing. A key aspect of our\napproach involves implementing distinct types of synapses from stable to\nflexible, and randomly intermixing them to train synaptic connections with\ndifferent degrees of flexibility. This strategy allowed the network to\nsuccessfully learn a continuous stream of information, even under unexpected\nchanges in input length. The model achieved a balanced tradeoff between memory\ncapacity and performance without requiring additional training or structural\nmodifications, dynamically allocating memory resources to retain both old and\nnew information. Furthermore, the model demonstrated robustness against data\npoisoning attacks by selectively filtering out erroneous memories, leveraging\nthe Hebb repetition effect to reinforce the retention of significant data.\n","subjects":["Computing Research Repository/Neural and Evolutionary Computing","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"9R_40U7vCpqGboXO9gHdzh7r3JZjZsYipuRZanm67Fs","pdfSize":"2614103"}
