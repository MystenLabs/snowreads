{"id":"2408.16233","title":"PSE-Net: Channel Pruning for Convolutional Neural Networks with\n  Parallel-subnets Estimator","authors":"Shiguang Wang, Tao Xie, Haijun Liu, Xingcheng Zhang, Jian Cheng","authorsParsed":[["Wang","Shiguang",""],["Xie","Tao",""],["Liu","Haijun",""],["Zhang","Xingcheng",""],["Cheng","Jian",""]],"versions":[{"version":"v1","created":"Thu, 29 Aug 2024 03:20:43 GMT"}],"updateDate":"2024-08-30","timestamp":1724901643000,"abstract":"  Channel Pruning is one of the most widespread techniques used to compress\ndeep neural networks while maintaining their performances. Currently, a typical\npruning algorithm leverages neural architecture search to directly find\nnetworks with a configurable width, the key step of which is to identify\nrepresentative subnet for various pruning ratios by training a supernet.\nHowever, current methods mainly follow a serial training strategy to optimize\nsupernet, which is very time-consuming. In this work, we introduce PSE-Net, a\nnovel parallel-subnets estimator for efficient channel pruning. Specifically,\nwe propose a parallel-subnets training algorithm that simulate the\nforward-backward pass of multiple subnets by droping extraneous features on\nbatch dimension, thus various subnets could be trained in one round. Our\nproposed algorithm facilitates the efficiency of supernet training and equips\nthe network with the ability to interpolate the accuracy of unsampled subnets,\nenabling PSE-Net to effectively evaluate and rank the subnets. Over the trained\nsupernet, we develop a prior-distributed-based sampling algorithm to boost the\nperformance of classical evolutionary search. Such algorithm utilizes the prior\ninformation of supernet training phase to assist in the search of optimal\nsubnets while tackling the challenge of discovering samples that satisfy\nresource constraints due to the long-tail distribution of network\nconfiguration. Extensive experiments demonstrate PSE-Net outperforms previous\nstate-of-the-art channel pruning methods on the ImageNet dataset while\nretaining superior supernet training efficiency. For example, under 300M FLOPs\nconstraint, our pruned MobileNetV2 achieves 75.2% Top-1 accuracy on ImageNet\ndataset, exceeding the original MobileNetV2 by 2.6 units while only cost\n30%/16% times than BCNet/AutoAlim.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}