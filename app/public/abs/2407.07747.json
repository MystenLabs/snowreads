{"id":"2407.07747","title":"HGFF: A Deep Reinforcement Learning Framework for Lifetime Maximization\n  in Wireless Sensor Networks","authors":"Xiaoxu Han, Xin Mu, Jinghui Zhong","authorsParsed":[["Han","Xiaoxu",""],["Mu","Xin",""],["Zhong","Jinghui",""]],"versions":[{"version":"v1","created":"Thu, 11 Apr 2024 13:09:11 GMT"}],"updateDate":"2024-07-11","timestamp":1712840951000,"abstract":"  Planning the movement of the sink to maximize the lifetime in wireless sensor\nnetworks is an essential problem of great research challenge and practical\nvalue. Many existing mobile sink techniques based on mathematical programming\nor heuristics have demonstrated the feasibility of the task. Nevertheless, the\nhuge computation consumption or the over-reliance on human knowledge can result\nin relatively low performance. In order to balance the need for high-quality\nsolutions with the goal of minimizing inference time, we propose a new\nframework combining heterogeneous graph neural network with deep reinforcement\nlearning to automatically construct the movement path of the sink. Modeling the\nwireless sensor networks as heterogeneous graphs, we utilize the graph neural\nnetwork to learn representations of sites and sensors by aggregating features\nof neighbor nodes and extracting hierarchical graph features. Meanwhile, the\nmulti-head attention mechanism is leveraged to allow the sites to attend to\ninformation from sensor nodes, which highly improves the expressive capacity of\nthe learning model. Based on the node representations, a greedy policy is\nlearned to append the next best site in the solution incrementally. We design\nten types of static and dynamic maps to simulate different wireless sensor\nnetworks in the real world, and extensive experiments are conducted to evaluate\nand analyze our approach. The empirical results show that our approach\nconsistently outperforms the existing methods on all types of maps.\n","subjects":["Computing Research Repository/Networking and Internet Architecture","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}