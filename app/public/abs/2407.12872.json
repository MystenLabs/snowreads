{"id":"2407.12872","title":"Evaluating Large Language Models with fmeval","authors":"Pola Schw\\\"obel, Luca Franceschi, Muhammad Bilal Zafar, Keerthan\n  Vasist, Aman Malhotra, Tomer Shenhar, Pinal Tailor, Pinar Yilmaz, Michael\n  Diamond, Michele Donini","authorsParsed":[["Schw√∂bel","Pola",""],["Franceschi","Luca",""],["Zafar","Muhammad Bilal",""],["Vasist","Keerthan",""],["Malhotra","Aman",""],["Shenhar","Tomer",""],["Tailor","Pinal",""],["Yilmaz","Pinar",""],["Diamond","Michael",""],["Donini","Michele",""]],"versions":[{"version":"v1","created":"Mon, 15 Jul 2024 12:15:08 GMT"}],"updateDate":"2024-07-19","timestamp":1721045708000,"abstract":"  fmeval is an open source library to evaluate large language models (LLMs) in\na range of tasks. It helps practitioners evaluate their model for task\nperformance and along multiple responsible AI dimensions. This paper presents\nthe library and exposes its underlying design principles: simplicity, coverage,\nextensibility and performance. We then present how these were implemented in\nthe scientific and engineering choices taken when developing fmeval. A case\nstudy demonstrates a typical use case for the library: picking a suitable model\nfor a question answering task. We close by discussing limitations and further\nwork in the development of the library. fmeval can be found at\nhttps://github.com/aws/fmeval.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}