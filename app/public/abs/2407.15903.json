{"id":"2407.15903","title":"Semantics Guided Disentangled GAN for Chest X-ray Image Rib Segmentation","authors":"Lili Huang, Dexin Ma, Xiaowei Zhao, Chenglong Li, Haifeng Zhao, Jin\n  Tang and Chuanfu Li","authorsParsed":[["Huang","Lili",""],["Ma","Dexin",""],["Zhao","Xiaowei",""],["Li","Chenglong",""],["Zhao","Haifeng",""],["Tang","Jin",""],["Li","Chuanfu",""]],"versions":[{"version":"v1","created":"Mon, 22 Jul 2024 12:13:02 GMT"}],"updateDate":"2024-07-24","timestamp":1721650382000,"abstract":"  The label annotations for chest X-ray image rib segmentation are time\nconsuming and laborious, and the labeling quality heavily relies on medical\nknowledge of annotators. To reduce the dependency on annotated data, existing\nworks often utilize generative adversarial network (GAN) to generate training\ndata. However, GAN-based methods overlook the nuanced information specific to\nindividual organs, which degrades the generation quality of chest X-ray image.\nHence, we propose a novel Semantics guided Disentangled GAN (SD-GAN), which can\ngenerate the high-quality training data by fully utilizing the semantic\ninformation of different organs, for chest X-ray image rib segmentation. In\nparticular, we use three ResNet50 branches to disentangle features of different\norgans, then use a decoder to combine features and generate corresponding\nimages. To ensure that the generated images correspond to the input organ\nlabels in semantics tags, we employ a semantics guidance module to perform\nsemantic guidance on the generated images. To evaluate the efficacy of SD-GAN\nin generating high-quality samples, we introduce modified TransUNet(MTUNet), a\nspecialized segmentation network designed for multi-scale contextual\ninformation extracting and multi-branch decoding, effectively tackling the\nchallenge of organ overlap. We also propose a new chest X-ray image dataset\n(CXRS). It includes 1250 samples from various medical institutions. Lungs,\nclavicles, and 24 ribs are simultaneously annotated on each chest X-ray image.\nThe visualization and quantitative results demonstrate the efficacy of SD-GAN\nin generating high-quality chest X-ray image-mask pairs. Using generated data,\nour trained MTUNet overcomes the limitations of the data scale and outperforms\nother segmentation networks.\n","subjects":["Electrical Engineering and Systems Science/Image and Video Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}