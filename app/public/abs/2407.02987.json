{"id":"2407.02987","title":"LoRA-Guard: Parameter-Efficient Guardrail Adaptation for Content\n  Moderation of Large Language Models","authors":"Hayder Elesedy, Pedro M. Esperan\\c{c}a, Silviu Vlad Oprea, Mete Ozay","authorsParsed":[["Elesedy","Hayder",""],["Esperan√ßa","Pedro M.",""],["Oprea","Silviu Vlad",""],["Ozay","Mete",""]],"versions":[{"version":"v1","created":"Wed, 3 Jul 2024 10:38:40 GMT"}],"updateDate":"2024-07-04","timestamp":1720003120000,"abstract":"  Guardrails have emerged as an alternative to safety alignment for content\nmoderation of large language models (LLMs). Existing model-based guardrails\nhave not been designed for resource-constrained computational portable devices,\nsuch as mobile phones, more and more of which are running LLM-based\napplications locally. We introduce LoRA-Guard, a parameter-efficient guardrail\nadaptation method that relies on knowledge sharing between LLMs and guardrail\nmodels. LoRA-Guard extracts language features from the LLMs and adapts them for\nthe content moderation task using low-rank adapters, while a dual-path design\nprevents any performance degradation on the generative task. We show that\nLoRA-Guard outperforms existing approaches with 100-1000x lower parameter\noverhead while maintaining accuracy, enabling on-device content moderation.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"tYArv4RiSL2o-QmKi-vnwQ9Z7Y0rCwATYh6dG5zLF08","pdfSize":"552378","objectId":"0x109e665630c0cfcd4077614f1c8dae8e5d4c72d5c0fc7d74f1e1d6319fbd8f8c","registeredEpoch":"3","certifiedEpoch":"3","startEpoch":"3","endEpoch":"203"}
