{"id":"2408.05606","title":"Exploring Applications of State Space Models and Advanced Training\n  Techniques in Sequential Recommendations: A Comparative Study on Efficiency\n  and Performance","authors":"Mark Obozov, Makar Baderko, Stepan Kulibaba, Nikolay Kutuzov,\n  Alexander Gasnikov","authorsParsed":[["Obozov","Mark",""],["Baderko","Makar",""],["Kulibaba","Stepan",""],["Kutuzov","Nikolay",""],["Gasnikov","Alexander",""]],"versions":[{"version":"v1","created":"Sat, 10 Aug 2024 18:09:10 GMT"}],"updateDate":"2024-08-13","timestamp":1723313350000,"abstract":"  Recommender systems aim to estimate the dynamically changing user preferences\nand sequential dependencies between historical user behaviour and metadata.\nAlthough transformer-based models have proven to be effective in sequential\nrecommendations, their state growth is proportional to the length of the\nsequence that is being processed, which makes them expensive in terms of memory\nand inference costs. Our research focused on three promising directions in\nsequential recommendations: enhancing speed through the use of State Space\nModels (SSM), as they can achieve SOTA results in the sequential\nrecommendations domain with lower latency, memory, and inference costs, as\nproposed by arXiv:2403.03900 improving the quality of recommendations with\nLarge Language Models (LLMs) via Monolithic Preference Optimization without\nReference Model (ORPO); and implementing adaptive batch- and step-size\nalgorithms to reduce costs and accelerate training processes.\n","subjects":["Computing Research Repository/Information Retrieval","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning","Mathematics/Optimization and Control"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}