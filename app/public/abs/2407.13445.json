{"id":"2407.13445","title":"Constrained Approximate Optimal Transport Maps","authors":"Eloi Tanguy, Agn\\`es Desolneux and Julie Delon","authorsParsed":[["Tanguy","Eloi",""],["Desolneux","Agn√®s",""],["Delon","Julie",""]],"versions":[{"version":"v1","created":"Thu, 18 Jul 2024 12:14:18 GMT"}],"updateDate":"2024-07-19","timestamp":1721304858000,"abstract":"  We investigate finding a map $g$ within a function class $G$ that minimises\nan Optimal Transport (OT) cost between a target measure $\\nu$ and the image by\n$g$ of a source measure $\\mu$. This is relevant when an OT map from $\\mu$ to\n$\\nu$ does not exist or does not satisfy the desired constraints of $G$. We\naddress existence and uniqueness for generic subclasses of $L$-Lipschitz\nfunctions, including gradients of (strongly) convex functions and typical\nNeural Networks. We explore a variant that approaches a transport plan, showing\nequivalence to a map problem in some cases. For the squared Euclidean cost, we\npropose alternating minimisation over a transport plan $\\pi$ and map $g$, with\nthe optimisation over $g$ being the $L^2$ projection on $G$ of the barycentric\nmapping $\\overline{\\pi}$. In dimension one, this global problem equates the\n$L^2$ projection of $\\overline{\\pi^*}$ onto $G$ for an OT plan $\\pi^*$ between\n$\\mu$ and $\\nu$, but this does not extend to higher dimensions. We introduce a\nsimple kernel method to find $g$ within a Reproducing Kernel Hilbert Space in\nthe discrete case. Finally, we present numerical methods for $L$-Lipschitz\ngradients of $\\ell$-strongly convex potentials.\n","subjects":["Mathematics/Optimization and Control"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}