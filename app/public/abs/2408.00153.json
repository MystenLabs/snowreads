{"id":"2408.00153","title":"Understanding Feedback Mechanisms in Machine Learning Jupyter Notebooks","authors":"Arumoy Shome, Luis Cruz, Diomidis Spinellis, Arie van Deursen","authorsParsed":[["Shome","Arumoy",""],["Cruz","Luis",""],["Spinellis","Diomidis",""],["van Deursen","Arie",""]],"versions":[{"version":"v1","created":"Wed, 31 Jul 2024 20:31:13 GMT"}],"updateDate":"2024-08-02","timestamp":1722457873000,"abstract":"  The machine learning development lifecycle is characterized by iterative and\nexploratory processes that rely on feedback mechanisms to ensure data and model\nintegrity. Despite the critical role of feedback in machine learning\nengineering, no prior research has been conducted to identify and understand\nthese mechanisms. To address this knowledge gap, we mine 297.8 thousand Jupyter\nnotebooks and analyse 2.3 million code cells. We identify three key feedback\nmechanisms -- assertions, print statements and last cell statements -- and\nfurther categorize them into implicit and explicit forms of feedback. Our\nfindings reveal extensive use of implicit feedback for critical design\ndecisions and the relatively limited adoption of explicit feedback mechanisms.\nBy conducting detailed case studies with selected feedback instances, we\nuncover the potential for automated validation of critical assumptions in ML\nworkflows using assertions. Finally, this study underscores the need for\nimproved documentation, and provides practical recommendations on how existing\nfeedback mechanisms in the ML development workflow can be effectively used to\nmitigate technical debt and enhance reproducibility.\n","subjects":["Computing Research Repository/Software Engineering"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"YPB2o-1F-TQ7RBY9-r-Z5KyL36D_xXMPYylAMjITX0c","pdfSize":"834924","txDigest":"GpwqUEDbSQB2x7WiVto2v5uao4qpULkurZ1r5jgeY81H","endEpoch":"1","status":"CERTIFIED"}
