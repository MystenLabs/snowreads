{"id":"2408.13852","title":"LaneTCA: Enhancing Video Lane Detection with Temporal Context\n  Aggregation","authors":"Keyi Zhou, Li Li, Wengang Zhou, Yonghui Wang, Hao Feng, Houqiang Li","authorsParsed":[["Zhou","Keyi",""],["Li","Li",""],["Zhou","Wengang",""],["Wang","Yonghui",""],["Feng","Hao",""],["Li","Houqiang",""]],"versions":[{"version":"v1","created":"Sun, 25 Aug 2024 14:46:29 GMT"}],"updateDate":"2024-08-27","timestamp":1724597189000,"abstract":"  In video lane detection, there are rich temporal contexts among successive\nframes, which is under-explored in existing lane detectors. In this work, we\npropose LaneTCA to bridge the individual video frames and explore how to\neffectively aggregate the temporal context. Technically, we develop an\naccumulative attention module and an adjacent attention module to abstract the\nlong-term and short-term temporal context, respectively. The accumulative\nattention module continuously accumulates visual information during the journey\nof a vehicle, while the adjacent attention module propagates this lane\ninformation from the previous frame to the current frame. The two modules are\nmeticulously designed based on the transformer architecture. Finally, these\nlong-short context features are fused with the current frame features to\npredict the lane lines in the current frame. Extensive quantitative and\nqualitative experiments are conducted on two prevalent benchmark datasets. The\nresults demonstrate the effectiveness of our method, achieving several new\nstate-of-the-art records. The codes and models are available at\nhttps://github.com/Alex-1337/LaneTCA\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}