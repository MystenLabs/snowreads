{"id":"2407.18129","title":"Dallah: A Dialect-Aware Multimodal Large Language Model for Arabic","authors":"Fakhraddin Alwajih, Gagan Bhatia, Muhammad Abdul-Mageed","authorsParsed":[["Alwajih","Fakhraddin",""],["Bhatia","Gagan",""],["Abdul-Mageed","Muhammad",""]],"versions":[{"version":"v1","created":"Thu, 25 Jul 2024 15:36:48 GMT"},{"version":"v2","created":"Fri, 26 Jul 2024 15:34:12 GMT"}],"updateDate":"2024-07-29","timestamp":1721921808000,"abstract":"  Recent advancements have significantly enhanced the capabilities of\nMultimodal Large Language Models (MLLMs) in generating and understanding\nimage-to-text content. Despite these successes, progress is predominantly\nlimited to English due to the scarcity of high quality multimodal resources in\nother languages. This limitation impedes the development of competitive models\nin languages such as Arabic. To alleviate this situation, we introduce an\nefficient Arabic multimodal assistant, dubbed Dallah, that utilizes an advanced\nlanguage model based on LLaMA-2 to facilitate multimodal interactions. Dallah\ndemonstrates state-of-the-art performance in Arabic MLLMs. Through fine-tuning\nsix Arabic dialects, Dallah showcases its capability to handle complex\ndialectal interactions incorporating both textual and visual elements. The\nmodel excels in two benchmark tests: one evaluating its performance on Modern\nStandard Arabic (MSA) and another specifically designed to assess dialectal\nresponses. Beyond its robust performance in multimodal interaction tasks,\nDallah has the potential to pave the way for further development of\ndialect-aware Arabic MLLMs.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by-sa/4.0/"}