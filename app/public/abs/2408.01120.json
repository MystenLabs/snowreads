{"id":"2408.01120","title":"An Efficient and Effective Transformer Decoder-Based Framework for\n  Multi-Task Visual Grounding","authors":"Wei Chen, Long Chen, Yu Wu","authorsParsed":[["Chen","Wei",""],["Chen","Long",""],["Wu","Yu",""]],"versions":[{"version":"v1","created":"Fri, 2 Aug 2024 09:01:05 GMT"}],"updateDate":"2024-08-05","timestamp":1722589265000,"abstract":"  Most advanced visual grounding methods rely on Transformers for\nvisual-linguistic feature fusion. However, these Transformer-based approaches\nencounter a significant drawback: the computational costs escalate\nquadratically due to the self-attention mechanism in the Transformer Encoder,\nparticularly when dealing with high-resolution images or long context\nsentences. This quadratic increase in computational burden restricts the\napplicability of visual grounding to more intricate scenes, such as\nconversation-based reasoning segmentation, which involves lengthy language\nexpressions. In this paper, we propose an efficient and effective multi-task\nvisual grounding (EEVG) framework based on Transformer Decoder to address this\nissue, which reduces the cost in both language and visual aspects. In the\nlanguage aspect, we employ the Transformer Decoder to fuse visual and\nlinguistic features, where linguistic features are input as memory and visual\nfeatures as queries. This allows fusion to scale linearly with language\nexpression length. In the visual aspect, we introduce a parameter-free approach\nto reduce computation by eliminating background visual tokens based on\nattention scores. We then design a light mask head to directly predict\nsegmentation masks from the remaining sparse feature maps. Extensive results\nand ablation studies on benchmarks demonstrate the efficiency and effectiveness\nof our approach. Code is available in https://github.com/chenwei746/EEVG.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"V-1OzGKJIJ6sVtfzsP-FWC2yZY6AGLLDkgyqVlCknlE","pdfSize":"10677063","txDigest":"FkwEBpAiLy1u9LhHMof5KfkeH8HF4nkKaPUQVwXtLRGJ","endEpoch":"1","status":"CERTIFIED"}
