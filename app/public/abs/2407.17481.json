{"id":"2407.17481","title":"Human Oversight of Artificial Intelligence and Technical Standardisation","authors":"Marion Ho-Dac (UA, CDEP), Baptiste Martinez (UA, CDEP)","authorsParsed":[["Ho-Dac","Marion","","UA, CDEP"],["Martinez","Baptiste","","UA, CDEP"]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 07:43:46 GMT"}],"updateDate":"2024-07-26","timestamp":1719906226000,"abstract":"  The adoption of human oversight measures makes it possible to regulate, to\nvarying degrees and in different ways, the decision-making process of\nArtificial Intelligence (AI) systems, for example by placing a human being in\ncharge of supervising the system and, upstream, by developing the AI system to\nenable such supervision. Within the global governance of AI, the requirement\nfor human oversight is embodied in several regulatory formats, within a\ndiversity of normative sources. On the one hand, it reinforces the\naccountability of AI systems' users (for example, by requiring them to carry\nout certain checks) and, on the other hand, it better protects the individuals\naffected by the AI-based decision (for example, by allowing them to request a\nreview of the decision). In the European context, the AI Act imposes\nobligations on providers of high-risk AI systems (and to some extent also on\nprofessional users of these systems, known as deployers), including the\nintroduction of human oversight tools throughout the life cycle of AI systems,\nincluding by design (and their implementation by deployers). The EU legislator\nis therefore going much further than in the past in \"spelling out\" the legal\nrequirement for human oversight. But it does not intend to provide for all\nimplementation details; it calls on standardisation to technically flesh out\nthis requirement (and more broadly all the requirements of section 2 of chapter\nIII) on the basis of article 40 of the AI Act. In this multi-level regulatory\ncontext, the question of the place of humans in the AI decision-making process\nshould be given particular attention. Indeed, depending on whether it is the\nlaw or the technical standard that sets the contours of human oversight, the\n\"regulatory governance\" of AI is not the same: its nature, content and scope\nare different. This analysis is at the heart of the contribution made (or to be\nmade) by legal experts to the central reflection on the most appropriate\nregulatory governance -- in terms of both its institutional format and its\nsubstance -- to ensure the effectiveness of human oversight and AI\ntrustworthiness.\n","subjects":["Computing Research Repository/Computers and Society"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}