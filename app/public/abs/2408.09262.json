{"id":"2408.09262","title":"PREMAP: A Unifying PREiMage APproximation Framework for Neural Networks","authors":"Xiyue Zhang, Benjie Wang, Marta Kwiatkowska, Huan Zhang","authorsParsed":[["Zhang","Xiyue",""],["Wang","Benjie",""],["Kwiatkowska","Marta",""],["Zhang","Huan",""]],"versions":[{"version":"v1","created":"Sat, 17 Aug 2024 17:24:47 GMT"}],"updateDate":"2024-08-20","timestamp":1723915487000,"abstract":"  Most methods for neural network verification focus on bounding the image,\ni.e., set of outputs for a given input set. This can be used to, for example,\ncheck the robustness of neural network predictions to bounded perturbations of\nan input. However, verifying properties concerning the preimage, i.e., the set\nof inputs satisfying an output property, requires abstractions in the input\nspace. We present a general framework for preimage abstraction that produces\nunder- and over-approximations of any polyhedral output set. Our framework\nemploys cheap parameterised linear relaxations of the neural network, together\nwith an anytime refinement procedure that iteratively partitions the input\nregion by splitting on input features and neurons. The effectiveness of our\napproach relies on carefully designed heuristics and optimization objectives to\nachieve rapid improvements in the approximation volume. We evaluate our method\non a range of tasks, demonstrating significant improvement in efficiency and\nscalability to high-input-dimensional image classification tasks compared to\nstate-of-the-art techniques. Further, we showcase the application to\nquantitative verification and robustness analysis, presenting a sound and\ncomplete algorithm for the former and providing sound quantitative results for\nthe latter.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Logic in Computer Science"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"Frwj0T5zG-CxKINcRAJZx22cx0Cy-FVhCQDBnctRnU4","pdfSize":"1606146"}
