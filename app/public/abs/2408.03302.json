{"id":"2408.03302","title":"TextIM: Part-aware Interactive Motion Synthesis from Text","authors":"Siyuan Fan, Bo Du, Xiantao Cai, Bo Peng, Longling Sun","authorsParsed":[["Fan","Siyuan",""],["Du","Bo",""],["Cai","Xiantao",""],["Peng","Bo",""],["Sun","Longling",""]],"versions":[{"version":"v1","created":"Tue, 6 Aug 2024 17:08:05 GMT"}],"updateDate":"2024-08-07","timestamp":1722964085000,"abstract":"  In this work, we propose TextIM, a novel framework for synthesizing\nTEXT-driven human Interactive Motions, with a focus on the precise alignment of\npart-level semantics. Existing methods often overlook the critical roles of\ninteractive body parts and fail to adequately capture and align part-level\nsemantics, resulting in inaccuracies and even erroneous movement outcomes. To\naddress these issues, TextIM utilizes a decoupled conditional diffusion\nframework to enhance the detailed alignment between interactive movements and\ncorresponding semantic intents from textual descriptions. Our approach\nleverages large language models, functioning as a human brain, to identify\ninteracting human body parts and to comprehend interaction semantics to\ngenerate complicated and subtle interactive motion. Guided by the refined\nmovements of the interacting parts, TextIM further extends these movements into\na coherent whole-body motion. We design a spatial coherence module to\ncomplement the entire body movements while maintaining consistency and harmony\nacross body parts using a part graph convolutional network. For training and\nevaluation, we carefully selected and re-labeled interactive motions from\nHUMANML3D to develop a specialized dataset. Experimental results demonstrate\nthat TextIM produces semantically accurate human interactive motions,\nsignificantly enhancing the realism and applicability of synthesized\ninteractive motions in diverse scenarios, even including interactions with\ndeformable and dynamically changing objects.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}