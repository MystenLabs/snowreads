{"id":"2407.00170","title":"Dataset Representativeness and Downstream Task Fairness","authors":"Victor Borza, Andrew Estornell, Chien-Ju Ho, Bradley Malin, Yevgeniy\n  Vorobeychik","authorsParsed":[["Borza","Victor",""],["Estornell","Andrew",""],["Ho","Chien-Ju",""],["Malin","Bradley",""],["Vorobeychik","Yevgeniy",""]],"versions":[{"version":"v1","created":"Fri, 28 Jun 2024 18:11:16 GMT"}],"updateDate":"2024-07-02","timestamp":1719598276000,"abstract":"  Our society collects data on people for a wide range of applications, from\nbuilding a census for policy evaluation to running meaningful clinical trials.\nTo collect data, we typically sample individuals with the goal of accurately\nrepresenting a population of interest. However, current sampling processes\noften collect data opportunistically from data sources, which can lead to\ndatasets that are biased and not representative, i.e., the collected dataset\ndoes not accurately reflect the distribution of demographics of the true\npopulation. This is a concern because subgroups within the population can be\nunder- or over-represented in a dataset, which may harm generalizability and\nlead to an unequal distribution of benefits and harms from downstream tasks\nthat use such datasets (e.g., algorithmic bias in medical decision-making\nalgorithms). In this paper, we assess the relationship between dataset\nrepresentativeness and group-fairness of classifiers trained on that dataset.\nWe demonstrate that there is a natural tension between dataset\nrepresentativeness and classifier fairness; empirically we observe that\ntraining datasets with better representativeness can frequently result in\nclassifiers with higher rates of unfairness. We provide some intuition as to\nwhy this occurs via a set of theoretical results in the case of univariate\nclassifiers. We also find that over-sampling underrepresented groups can result\nin classifiers which exhibit greater bias to those groups. Lastly, we observe\nthat fairness-aware sampling strategies (i.e., those which are specifically\ndesigned to select data with high downstream fairness) will often over-sample\nmembers of majority groups. These results demonstrate that the relationship\nbetween dataset representativeness and downstream classifier fairness is\ncomplex; balancing these two quantities requires special care from both model-\nand dataset-designers.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Computers and Society"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}