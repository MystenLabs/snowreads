{"id":"2408.13285","title":"SIn-NeRF2NeRF: Editing 3D Scenes with Instructions through Segmentation\n  and Inpainting","authors":"Jiseung Hong, Changmin Lee, Gyusang Yu","authorsParsed":[["Hong","Jiseung",""],["Lee","Changmin",""],["Yu","Gyusang",""]],"versions":[{"version":"v1","created":"Fri, 23 Aug 2024 02:20:42 GMT"}],"updateDate":"2024-08-27","timestamp":1724379642000,"abstract":"  TL;DR Perform 3D object editing selectively by disentangling it from the\nbackground scene. Instruct-NeRF2NeRF (in2n) is a promising method that enables\nediting of 3D scenes composed of Neural Radiance Field (NeRF) using text\nprompts. However, it is challenging to perform geometrical modifications such\nas shrinking, scaling, or moving on both the background and object\nsimultaneously. In this project, we enable geometrical changes of objects\nwithin the 3D scene by selectively editing the object after separating it from\nthe scene. We perform object segmentation and background inpainting\nrespectively, and demonstrate various examples of freely resizing or moving\ndisentangled objects within the three-dimensional space.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}