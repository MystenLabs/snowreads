{"id":"2408.10286","title":"GPT-Augmented Reinforcement Learning with Intelligent Control for\n  Vehicle Dispatching","authors":"Xiao Han, Zijian Zhang, Xiangyu Zhao, Guojiang Shen, Xiangjie Kong,\n  Xuetao Wei, Liqiang Nie, Jieping Ye","authorsParsed":[["Han","Xiao",""],["Zhang","Zijian",""],["Zhao","Xiangyu",""],["Shen","Guojiang",""],["Kong","Xiangjie",""],["Wei","Xuetao",""],["Nie","Liqiang",""],["Ye","Jieping",""]],"versions":[{"version":"v1","created":"Mon, 19 Aug 2024 08:23:38 GMT"}],"updateDate":"2024-08-21","timestamp":1724055818000,"abstract":"  As urban residents demand higher travel quality, vehicle dispatch has become\na critical component of online ride-hailing services. However, current vehicle\ndispatch systems struggle to navigate the complexities of urban traffic\ndynamics, including unpredictable traffic conditions, diverse driver behaviors,\nand fluctuating supply and demand patterns. These challenges have resulted in\ntravel difficulties for passengers in certain areas, while many drivers in\nother areas are unable to secure orders, leading to a decline in the overall\nquality of urban transportation services. To address these issues, this paper\nintroduces GARLIC: a framework of GPT-Augmented Reinforcement Learning with\nIntelligent Control for vehicle dispatching. GARLIC utilizes multiview graphs\nto capture hierarchical traffic states, and learns a dynamic reward function\nthat accounts for individual driving behaviors. The framework further\nintegrates a GPT model trained with a custom loss function to enable\nhigh-precision predictions and optimize dispatching policies in real-world\nscenarios. Experiments conducted on two real-world datasets demonstrate that\nGARLIC effectively aligns with driver behaviors while reducing the empty load\nrate of vehicles.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/publicdomain/zero/1.0/"}