{"id":"2408.07854","title":"CON-FOLD -- Explainable Machine Learning with Confidence","authors":"Lachlan McGinness and Peter Baumgartner","authorsParsed":[["McGinness","Lachlan",""],["Baumgartner","Peter",""]],"versions":[{"version":"v1","created":"Wed, 14 Aug 2024 23:45:21 GMT"}],"updateDate":"2024-08-16","timestamp":1723679121000,"abstract":"  FOLD-RM is an explainable machine learning classification algorithm that uses\ntraining data to create a set of classification rules. In this paper we\nintroduce CON-FOLD which extends FOLD-RM in several ways. CON-FOLD assigns\nprobability-based confidence scores to rules learned for a classification task.\nThis allows users to know how confident they should be in a prediction made by\nthe model. We present a confidence-based pruning algorithm that uses the unique\nstructure of FOLD-RM rules to efficiently prune rules and prevent overfitting.\nFurthermore, CON-FOLD enables the user to provide pre-existing knowledge in the\nform of logic program rules that are either (fixed) background knowledge or\n(modifiable) initial rule candidates. The paper describes our method in detail\nand reports on practical experiments. We demonstrate the performance of the\nalgorithm on benchmark datasets from the UCI Machine Learning Repository. For\nthat, we introduce a new metric, Inverse Brier Score, to evaluate the accuracy\nof the produced confidence scores. Finally we apply this extension to a real\nworld example that requires explainability: marking of student responses to a\nshort answer question from the Australian Physics Olympiad.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/"}