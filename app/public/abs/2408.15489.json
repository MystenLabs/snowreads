{"id":"2408.15489","title":"Shared-PIM: Enabling Concurrent Computation and Data Flow for Faster\n  Processing-in-DRAM","authors":"Ahmed Mamdouh, Haoran Geng, Michael Niemier, Xiaobo Sharon Hu, and\n  Dayane Reis","authorsParsed":[["Mamdouh","Ahmed",""],["Geng","Haoran",""],["Niemier","Michael",""],["Hu","Xiaobo Sharon",""],["Reis","Dayane",""]],"versions":[{"version":"v1","created":"Wed, 28 Aug 2024 02:27:50 GMT"}],"updateDate":"2024-08-29","timestamp":1724812070000,"abstract":"  Processing-in-Memory (PIM) enhances memory with computational capabilities,\npotentially solving energy and latency issues associated with data transfer\nbetween memory and processors. However, managing concurrent computation and\ndata flow within the PIM architecture incurs significant latency and energy\npenalty for applications. This paper introduces Shared-PIM, an architecture for\nin-DRAM PIM that strategically allocates rows in memory banks, bolstered by\nmemory peripherals, for concurrent processing and data movement. Shared-PIM\nenables simultaneous computation and data transfer within a memory bank. When\ncompared to LISA, a state-of-the-art architecture that facilitates data\ntransfers for in-DRAM PIM, Shared-PIM reduces data movement latency and energy\nby 5x and 1.2x respectively. Furthermore, when integrated to a state-of-the-art\n(SOTA) in-DRAM PIM architecture (pLUTo), Shared-PIM achieves 1.4x faster\naddition and multiplication, and thereby improves the performance of matrix\nmultiplication (MM) tasks by 40%, polynomial multiplication (PMM) by 44%, and\nnumeric number transfer (NTT) tasks by 31%. Moreover, for graph processing\ntasks like Breadth-First Search (BFS) and Depth-First Search (DFS), Shared-PIM\nachieves a 29% improvement in speed, all with an area overhead of just 7.16%\ncompared to the baseline pLUTo.\n","subjects":["Computing Research Repository/Hardware Architecture"],"license":"http://creativecommons.org/publicdomain/zero/1.0/","blobId":"x8UIyPyvT3gD0ZPMz1RbU8cCfk6ok8OLWZ3Mq-6BRCs","pdfSize":"1144145"}
