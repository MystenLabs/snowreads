{"id":"2408.08338","title":"Activation Space Selectable Kolmogorov-Arnold Networks","authors":"Zhuoqin Yang, Jiansong Zhang, Xiaoling Luo, Zheng Lu, Linlin Shen","authorsParsed":[["Yang","Zhuoqin",""],["Zhang","Jiansong",""],["Luo","Xiaoling",""],["Lu","Zheng",""],["Shen","Linlin",""]],"versions":[{"version":"v1","created":"Thu, 15 Aug 2024 11:34:05 GMT"}],"updateDate":"2024-08-19","timestamp":1723721645000,"abstract":"  The multilayer perceptron (MLP), a fundamental paradigm in current artificial\nintelligence, is widely applied in fields such as computer vision and natural\nlanguage processing. However, the recently proposed Kolmogorov-Arnold Network\n(KAN), based on nonlinear additive connections, has been proven to achieve\nperformance comparable to MLPs with significantly fewer parameters. Despite\nthis potential, the use of a single activation function space results in\nreduced performance of KAN and related works across different tasks. To address\nthis issue, we propose an activation space Selectable KAN (S-KAN). S-KAN\nemploys an adaptive strategy to choose the possible activation mode for data at\neach feedforward KAN node. Our approach outperforms baseline methods in seven\nrepresentative function fitting tasks and significantly surpasses MLP methods\nwith the same level of parameters. Furthermore, we extend the structure of\nS-KAN and propose an activation space selectable Convolutional KAN (S-ConvKAN),\nwhich achieves leading results on four general image classification datasets.\nOur method mitigates the performance variability of the original KAN across\ndifferent tasks and demonstrates through extensive experiments that feedforward\nKANs with selectable activations can achieve or even exceed the performance of\nMLP-based methods. This work contributes to the understanding of the\ndata-centric design of new AI paradigms and provides a foundational reference\nfor innovations in KAN-based network architectures.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}