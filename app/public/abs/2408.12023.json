{"id":"2408.12023","title":"Limitations in Employing Natural Language Supervision for Sensor-Based\n  Human Activity Recognition -- And Ways to Overcome Them","authors":"Harish Haresamudram, Apoorva Beedu, Mashfiqui Rabbi, Sankalita Saha,\n  Irfan Essa, Thomas Ploetz","authorsParsed":[["Haresamudram","Harish",""],["Beedu","Apoorva",""],["Rabbi","Mashfiqui",""],["Saha","Sankalita",""],["Essa","Irfan",""],["Ploetz","Thomas",""]],"versions":[{"version":"v1","created":"Wed, 21 Aug 2024 22:30:36 GMT"}],"updateDate":"2024-08-23","timestamp":1724279436000,"abstract":"  Cross-modal contrastive pre-training between natural language and other\nmodalities, e.g., vision and audio, has demonstrated astonishing performance\nand effectiveness across a diverse variety of tasks and domains. In this paper,\nwe investigate whether such natural language supervision can be used for\nwearable sensor based Human Activity Recognition (HAR), and discover\nthat-surprisingly-it performs substantially worse than standard end-to-end\ntraining and self-supervision. We identify the primary causes for this as:\nsensor heterogeneity and the lack of rich, diverse text descriptions of\nactivities. To mitigate their impact, we also develop strategies and assess\ntheir effectiveness through an extensive experimental evaluation. These\nstrategies lead to significant increases in activity recognition, bringing\nperformance closer to supervised and self-supervised training, while also\nenabling the recognition of unseen activities and cross modal retrieval of\nvideos. Overall, our work paves the way for better sensor-language learning,\nultimately leading to the development of foundational models for HAR using\nwearables.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Computation and Language","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}