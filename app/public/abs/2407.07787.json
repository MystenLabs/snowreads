{"id":"2407.07787","title":"Continuous Control with Coarse-to-fine Reinforcement Learning","authors":"Younggyo Seo, Jafar Uru\\c{c}, Stephen James","authorsParsed":[["Seo","Younggyo",""],["Uru√ß","Jafar",""],["James","Stephen",""]],"versions":[{"version":"v1","created":"Wed, 10 Jul 2024 16:04:08 GMT"}],"updateDate":"2024-07-11","timestamp":1720627448000,"abstract":"  Despite recent advances in improving the sample-efficiency of reinforcement\nlearning (RL) algorithms, designing an RL algorithm that can be practically\ndeployed in real-world environments remains a challenge. In this paper, we\npresent Coarse-to-fine Reinforcement Learning (CRL), a framework that trains RL\nagents to zoom-into a continuous action space in a coarse-to-fine manner,\nenabling the use of stable, sample-efficient value-based RL algorithms for\nfine-grained continuous control tasks. Our key idea is to train agents that\noutput actions by iterating the procedure of (i) discretizing the continuous\naction space into multiple intervals and (ii) selecting the interval with the\nhighest Q-value to further discretize at the next level. We then introduce a\nconcrete, value-based algorithm within the CRL framework called Coarse-to-fine\nQ-Network (CQN). Our experiments demonstrate that CQN significantly outperforms\nRL and behavior cloning baselines on 20 sparsely-rewarded RLBench manipulation\ntasks with a modest number of environment interactions and expert\ndemonstrations. We also show that CQN robustly learns to solve real-world\nmanipulation tasks within a few minutes of online training.\n","subjects":["Computing Research Repository/Robotics","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Machine Learning","Computing Research Repository/Systems and Control","Electrical Engineering and Systems Science/Systems and Control"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}