{"id":"2407.02924","title":"Federated Fine-Tuning for Pre-Trained Foundation Models Over Wireless\n  Networks","authors":"Zixin Wang, Yong Zhou, Yuanming Shi, and Khaled. B. Letaief","authorsParsed":[["Wang","Zixin",""],["Zhou","Yong",""],["Shi","Yuanming",""],["Letaief","Khaled. B.",""]],"versions":[{"version":"v1","created":"Wed, 3 Jul 2024 08:56:24 GMT"}],"updateDate":"2024-07-04","timestamp":1719996984000,"abstract":"  Pre-trained foundation models (FMs), with extensive number of neurons, are\nkey to advancing next-generation intelligence services, where personalizing\nthese models requires massive amount of task-specific data and computational\nresources. The prevalent solution involves centralized processing at the edge\nserver, which, however, raises privacy concerns due to the transmission of raw\ndata. Instead, federated fine-tuning (FedFT) is an emerging privacy-preserving\nfine-tuning (FT) paradigm for personalized pre-trained foundation models. In\nparticular, by integrating low-rank adaptation (LoRA) with federated learning\n(FL), federated LoRA enables the collaborative FT of a global model with edge\ndevices, achieving comparable learning performance to full FT while training\nfewer parameters over distributed data and preserving raw data privacy.\nHowever, the limited radio resources and computation capabilities of edge\ndevices pose significant challenges for deploying federated LoRA over wireless\nnetworks. To this paper, we propose a split federated LoRA framework, which\ndeploys the computationally-intensive encoder of a pre-trained model at the\nedge server, while keeping the embedding and task modules at the edge devices.\nBuilding on this split framework, the paper provides a rigorous analysis of the\nupper bound of the convergence gap for the wireless federated LoRA system. This\nanalysis motivates the formulation of a long-term upper bound minimization\nproblem, where we decompose the formulated long-term mixed-integer programming\n(MIP) problem into sequential sub-problems using the Lyapunov technique. We\nthen develop an online algorithm for effective device scheduling and bandwidth\nallocation. Simulation results demonstrate the effectiveness of the proposed\nonline algorithm in enhancing learning performance.\n","subjects":["Electrical Engineering and Systems Science/Systems and Control","Computing Research Repository/Systems and Control"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}