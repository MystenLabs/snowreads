{"id":"2408.11135","title":"MS$^3$D: A RG Flow-Based Regularization for GAN Training with Limited\n  Data","authors":"Jian Wang, Xin Lan, Yuxin Tian and Jiancheng Lv","authorsParsed":[["Wang","Jian",""],["Lan","Xin",""],["Tian","Yuxin",""],["Lv","Jiancheng",""]],"versions":[{"version":"v1","created":"Tue, 20 Aug 2024 18:37:37 GMT"}],"updateDate":"2024-08-22","timestamp":1724179057000,"abstract":"  Generative adversarial networks (GANs) have made impressive advances in image\ngeneration, but they often require large-scale training data to avoid\ndegradation caused by discriminator overfitting. To tackle this issue, we\ninvestigate the challenge of training GANs with limited data, and propose a\nnovel regularization method based on the idea of renormalization group (RG) in\nphysics.We observe that in the limited data setting, the gradient pattern that\nthe generator obtains from the discriminator becomes more aggregated over time.\nIn RG context, this aggregated pattern exhibits a high discrepancy from its\ncoarse-grained versions, which implies a high-capacity and sensitive system,\nprone to overfitting and collapse. To address this problem, we introduce a\n\\textbf{m}ulti-\\textbf{s}cale \\textbf{s}tructural\n\\textbf{s}elf-\\textbf{d}issimilarity (MS$^3$D) regularization, which constrains\nthe gradient field to have a consistent pattern across different scales,\nthereby fostering a more redundant and robust system. We show that our method\ncan effectively enhance the performance and stability of GANs under limited\ndata scenarios, and even allow them to generate high-quality images with very\nfew data.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/"}