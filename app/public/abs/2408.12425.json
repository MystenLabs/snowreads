{"id":"2408.12425","title":"Dynamic Gated Recurrent Neural Network for Compute-efficient Speech\n  Enhancement","authors":"Longbiao Cheng, Ashutosh Pandey, Buye Xu, Tobi Delbruck, Shih-Chii Liu","authorsParsed":[["Cheng","Longbiao",""],["Pandey","Ashutosh",""],["Xu","Buye",""],["Delbruck","Tobi",""],["Liu","Shih-Chii",""]],"versions":[{"version":"v1","created":"Thu, 22 Aug 2024 14:20:11 GMT"}],"updateDate":"2024-08-23","timestamp":1724336411000,"abstract":"  This paper introduces a new Dynamic Gated Recurrent Neural Network (DG-RNN)\nfor compute-efficient speech enhancement models running on resource-constrained\nhardware platforms. It leverages the slow evolution characteristic of RNN\nhidden states over steps, and updates only a selected set of neurons at each\nstep by adding a newly proposed select gate to the RNN model. This select gate\nallows the computation cost of the conventional RNN to be reduced during\nnetwork inference. As a realization of the DG-RNN, we further propose the\nDynamic Gated Recurrent Unit (D-GRU) which does not require additional\nparameters. Test results obtained from several state-of-the-art\ncompute-efficient RNN-based speech enhancement architectures using the DNS\nchallenge dataset, show that the D-GRU based model variants maintain similar\nspeech intelligibility and quality metrics comparable to the baseline GRU based\nmodels even with an average 50% reduction in GRU computes.\n","subjects":["Electrical Engineering and Systems Science/Audio and Speech Processing","Computing Research Repository/Machine Learning","Computing Research Repository/Sound"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}