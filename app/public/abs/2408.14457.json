{"id":"2408.14457","title":"Dense Center-Direction Regression for Object Counting and Localization\n  with Point Supervision","authors":"Domen Tabernik, Jon Muhovi\\v{c} and Danijel Sko\\v{c}aj","authorsParsed":[["Tabernik","Domen",""],["Muhovič","Jon",""],["Skočaj","Danijel",""]],"versions":[{"version":"v1","created":"Mon, 26 Aug 2024 17:49:27 GMT"}],"updateDate":"2024-09-13","timestamp":1724694567000,"abstract":"  Object counting and localization problems are commonly addressed with point\nsupervised learning, which allows the use of less labor-intensive point\nannotations. However, learning based on point annotations poses challenges due\nto the high imbalance between the sets of annotated and unannotated pixels,\nwhich is often treated with Gaussian smoothing of point annotations and focal\nloss. However, these approaches still focus on the pixels in the immediate\nvicinity of the point annotations and exploit the rest of the data only\nindirectly. In this work, we propose a novel approach termed CeDiRNet for\npoint-supervised learning that uses a dense regression of directions pointing\ntowards the nearest object centers, i.e. center-directions. This provides\ngreater support for each center point arising from many surrounding pixels\npointing towards the object center. We propose a formulation of\ncenter-directions that allows the problem to be split into the domain-specific\ndense regression of center-directions and the final localization task based on\na small, lightweight, and domain-agnostic localization network that can be\ntrained with synthetic data completely independent of the target domain. We\ndemonstrate the performance of the proposed method on six different datasets\nfor object counting and localization, and show that it outperforms the existing\nstate-of-the-art methods. The code is accessible on GitHub at\nhttps://github.com/vicoslab/CeDiRNet.git.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}