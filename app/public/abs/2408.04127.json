{"id":"2408.04127","title":"Incorporating Spatial Awareness in Data-Driven Gesture Generation for\n  Virtual Agents","authors":"Anna Deichler, Simon Alexanderson, Jonas Beskow","authorsParsed":[["Deichler","Anna",""],["Alexanderson","Simon",""],["Beskow","Jonas",""]],"versions":[{"version":"v1","created":"Wed, 7 Aug 2024 23:23:50 GMT"}],"updateDate":"2024-08-09","timestamp":1723073030000,"abstract":"  This paper focuses on enhancing human-agent communication by integrating\nspatial context into virtual agents' non-verbal behaviors, specifically\ngestures. Recent advances in co-speech gesture generation have primarily\nutilized data-driven methods, which create natural motion but limit the scope\nof gestures to those performed in a void. Our work aims to extend these methods\nby enabling generative models to incorporate scene information into\nspeech-driven gesture synthesis. We introduce a novel synthetic gesture dataset\ntailored for this purpose. This development represents a critical step toward\ncreating embodied conversational agents that interact more naturally with their\nenvironment and users.\n","subjects":["Computing Research Repository/Human-Computer Interaction","Computing Research Repository/Computation and Language","Computing Research Repository/Graphics"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"S20Nh4rAo72Nc_RjppmFuvAzq21Z8apKNF_dk7bH1TU","pdfSize":"1267438"}
