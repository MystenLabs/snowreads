{"id":"2407.20407","title":"Deep Learning for Super-resolution Ultrasound Imaging with\n  Spatiotemporal Data","authors":"Arthur David Redfern, Katherine G. Brown","authorsParsed":[["Redfern","Arthur David",""],["Brown","Katherine G.",""]],"versions":[{"version":"v1","created":"Mon, 29 Jul 2024 20:29:22 GMT"},{"version":"v2","created":"Fri, 2 Aug 2024 17:48:11 GMT"}],"updateDate":"2024-08-05","timestamp":1722284962000,"abstract":"  Super-resolution ultrasound imaging (SRUS) is an active area of research as\nit brings up to a ten-fold improvement in the resolution of microvascular\nstructures. The limitations to the clinical adoption of SRUS include long\nacquisition times and long image processing times. Both these limitations can\nbe alleviated with deep learning approaches to the processing of SRUS images.\nIn this study we propose an optimized architecture based on modern improvements\nto convolutional neural networks from the ConvNeXt architecture and further\ncustomize the choice of features to improve performance on the specific tasks\nof both MB detection and localization within a single network. We employ a\nspatiotemporal input of up to five successive image frames to increase the\nnumber of MBs detected. The output structure produces three classifications: a\nMB detection Boolean for each pixel in the central image frame, as well as x\nand z offsets at 4-fold subpixel resolution for each MB detected. Ultrasound\nsimulations generated images based on the L22-14v transducer (Verasonics) for\ntraining and testing of the proposed SRUS-ConvNeXt network. In vivo image data\nof a mouse brain was used as further validation of the architecture. The\nproposed network had the highest performance as measured by F1 score when\nconfigured for a 3-frame spatiotemporal input. The smallest localization error\nof {\\lambda}/22 was achieved when the network was configured for a single input\nframe. The flexibility of the proposed architecture allows extension to 10-fold\nupscaling for SRUS images with a much lower impact to number of parameters and\nsubsequent increase in inference time than typical U-Net style approaches. This\nnetwork is promising in the quest to develop a SRUS deep network architecture\nfor real time image formation.\n","subjects":["Electrical Engineering and Systems Science/Image and Video Processing"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/"}