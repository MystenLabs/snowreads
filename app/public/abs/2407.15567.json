{"id":"2407.15567","title":"A New Theoretical Perspective on Data Heterogeneity in Federated\n  Optimization","authors":"Jiayi Wang, Shiqiang Wang, Rong-Rong Chen, Mingyue Ji","authorsParsed":[["Wang","Jiayi",""],["Wang","Shiqiang",""],["Chen","Rong-Rong",""],["Ji","Mingyue",""]],"versions":[{"version":"v1","created":"Mon, 22 Jul 2024 11:52:58 GMT"}],"updateDate":"2024-07-23","timestamp":1721649178000,"abstract":"  In federated learning (FL), data heterogeneity is the main reason that\nexisting theoretical analyses are pessimistic about the convergence rate. In\nparticular, for many FL algorithms, the convergence rate grows dramatically\nwhen the number of local updates becomes large, especially when the product of\nthe gradient divergence and local Lipschitz constant is large. However,\nempirical studies can show that more local updates can improve the convergence\nrate even when these two parameters are large, which is inconsistent with the\ntheoretical findings. This paper aims to bridge this gap between theoretical\nunderstanding and practical performance by providing a theoretical analysis\nfrom a new perspective on data heterogeneity. In particular, we propose a new\nand weaker assumption compared to the local Lipschitz gradient assumption,\nnamed the heterogeneity-driven pseudo-Lipschitz assumption. We show that this\nand the gradient divergence assumptions can jointly characterize the effect of\ndata heterogeneity. By deriving a convergence upper bound for FedAvg and its\nextensions, we show that, compared to the existing works, local Lipschitz\nconstant is replaced by the much smaller heterogeneity-driven pseudo-Lipschitz\nconstant and the corresponding convergence upper bound can be significantly\nreduced for the same number of local updates, although its order stays the\nsame. In addition, when the local objective function is quadratic, more\ninsights on the impact of data heterogeneity can be obtained using the\nheterogeneity-driven pseudo-Lipschitz constant. For example, we can identify a\nregion where FedAvg can outperform mini-batch SGD even when the gradient\ndivergence can be arbitrarily large. Our findings are validated using\nexperiments.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Distributed, Parallel, and Cluster Computing","Computing Research Repository/Information Theory","Mathematics/Information Theory","Mathematics/Optimization and Control"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}