{"id":"2407.13744","title":"LLMs as Function Approximators: Terminology, Taxonomy, and Questions for\n  Evaluation","authors":"David Schlangen","authorsParsed":[["Schlangen","David",""]],"versions":[{"version":"v1","created":"Thu, 18 Jul 2024 17:49:56 GMT"}],"updateDate":"2024-07-19","timestamp":1721324996000,"abstract":"  Natural Language Processing has moved rather quickly from modelling specific\ntasks to taking more general pre-trained models and fine-tuning them for\nspecific tasks, to a point where we now have what appear to be inherently\ngeneralist models. This paper argues that the resultant loss of clarity on what\nthese models model leads to metaphors like \"artificial general intelligences\"\nthat are not helpful for evaluating their strengths and weaknesses. The\nproposal is to see their generality, and their potential value, in their\nability to approximate specialist function, based on a natural language\nspecification. This framing brings to the fore questions of the quality of the\napproximation, but beyond that, also questions of discoverability, stability,\nand protectability of these functions. As the paper will show, this framing\nhence brings together in one conceptual framework various aspects of\nevaluation, both from a practical and a theoretical perspective, as well as\nquestions often relegated to a secondary status (such as \"prompt injection\" and\n\"jailbreaking\").\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}