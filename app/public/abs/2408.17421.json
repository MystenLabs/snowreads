{"id":"2408.17421","title":"Generative AI Enables Medical Image Segmentation in Ultra Low-Data\n  Regimes","authors":"Li Zhang, Basu Jindal, Ahmed Alaa, Robert Weinreb, David Wilson, Eran\n  Segal, James Zou, Pengtao Xie","authorsParsed":[["Zhang","Li",""],["Jindal","Basu",""],["Alaa","Ahmed",""],["Weinreb","Robert",""],["Wilson","David",""],["Segal","Eran",""],["Zou","James",""],["Xie","Pengtao",""]],"versions":[{"version":"v1","created":"Fri, 30 Aug 2024 17:11:36 GMT"}],"updateDate":"2024-09-02","timestamp":1725037896000,"abstract":"  Semantic segmentation of medical images is pivotal in applications like\ndisease diagnosis and treatment planning. While deep learning has excelled in\nautomating this task, a major hurdle is the need for numerous annotated\nsegmentation masks, which are resource-intensive to produce due to the required\nexpertise and time. This scenario often leads to ultra low-data regimes, where\nannotated images are extremely limited, posing significant challenges for the\ngeneralization of conventional deep learning methods on test images. To address\nthis, we introduce a generative deep learning framework, which uniquely\ngenerates high-quality paired segmentation masks and medical images, serving as\nauxiliary data for training robust models in data-scarce environments. Unlike\ntraditional generative models that treat data generation and segmentation model\ntraining as separate processes, our method employs multi-level optimization for\nend-to-end data generation. This approach allows segmentation performance to\ndirectly influence the data generation process, ensuring that the generated\ndata is specifically tailored to enhance the performance of the segmentation\nmodel. Our method demonstrated strong generalization performance across 9\ndiverse medical image segmentation tasks and on 16 datasets, in ultra-low data\nregimes, spanning various diseases, organs, and imaging modalities. When\napplied to various segmentation models, it achieved performance improvements of\n10-20\\% (absolute), in both same-domain and out-of-domain scenarios. Notably,\nit requires 8 to 20 times less training data than existing methods to achieve\ncomparable results. This advancement significantly improves the feasibility and\ncost-effectiveness of applying deep learning in medical imaging, particularly\nin scenarios with limited data availability.\n","subjects":["Electrical Engineering and Systems Science/Image and Video Processing","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}