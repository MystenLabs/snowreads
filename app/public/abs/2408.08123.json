{"id":"2408.08123","title":"General single-loop methods for bilevel parameter learning","authors":"Ensio Suonper\\\"a and Tuomo Valkonen","authorsParsed":[["Suonper√§","Ensio",""],["Valkonen","Tuomo",""]],"versions":[{"version":"v1","created":"Thu, 15 Aug 2024 12:50:07 GMT"}],"updateDate":"2024-08-16","timestamp":1723726207000,"abstract":"  Bilevel optimisation is used in inverse problems for hyperparameter learning\nand experimental design. For instance, it can be used to find optimal\nregularisation parameters and forward operators, based on a set of training\npairs. However, computationally, the process is costly. To reduce this cost,\nrecently in bilevel optimisation research, especially as applied to machine\nlearning, so-called single-loop approaches have been introduced. On each step\nof an outer optimisation method, such methods only take a single gradient\ndescent step towards the solution of the inner problem. In this paper, we\nflexibilise the inner algorithm, to allow for methods more applicable to\ndifficult inverse problems with nonsmooth regularisation, including primal-dual\nproximal splitting (PDPS). Moreover, as we have recently shown, significant\nperformance improvements can be obtained in PDE-constrained optimisation by\ninterweaving the steps of conventional iterative solvers (Jacobi, Gauss-Seidel,\nconjugate gradients) for both the PDE and its adjoint, with the steps of the\noptimisation method. In this paper we demonstrate how the adjoint equation in\nbilevel problems can also benefit from such interweaving with conventional\nlinear system solvers. We demonstrate the performance of our proposed methods\non learning the deconvolution kernel for image deblurring, and the subsampling\noperator for magnetic resonance imaging (MRI).\n","subjects":["Mathematics/Optimization and Control"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}