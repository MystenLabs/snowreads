{"id":"2407.02862","title":"HybEA: Hybrid Attention Models for Entity Alignment","authors":"Nikolaos Fanourakis and Fatia Lekbour and Vasilis Efthymiou and\n  Guillaume Renton and Vassilis Christophides","authorsParsed":[["Fanourakis","Nikolaos",""],["Lekbour","Fatia",""],["Efthymiou","Vasilis",""],["Renton","Guillaume",""],["Christophides","Vassilis",""]],"versions":[{"version":"v1","created":"Wed, 3 Jul 2024 07:22:20 GMT"}],"updateDate":"2024-07-04","timestamp":1719991340000,"abstract":"  The proliferation of Knowledge Graphs (KGs) that support a wide variety of\napplications, like entity search, question answering and recommender systems,\nhas led to the need for identifying overlapping information among different\nKGs. Entity Alignment (EA) is the problem of detecting such overlapping\ninformation among KGs that refer to the same real-world entities. Recent works\nhave shown a great potential in exploiting KG embeddings for the task of EA,\nwith most works focusing on the structural representation of entities (i.e.,\nentity neighborhoods) in a KG and some works also exploiting the available\nfactual information of entities (e.g., their names and associated literal\nvalues). However, real-word KGs exhibit high levels of structural and semantic\nheterogeneity, making EA a challenging task in which most existing methods\nstruggle to achieve good results. In this work, we propose HybEA, an\nopen-source EA method that focuses on both structure and facts, using two\nseparate attention-based models. Our experimental results show that HybEA\noutperforms state-of-the-art methods by at least 5% and as much as 20+% (with\nan average difference of 11+%) Hits@1, in 5 widely used benchmark datasets.\n","subjects":["Computing Research Repository/Databases"],"license":"http://creativecommons.org/licenses/by/4.0/"}