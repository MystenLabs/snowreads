{"id":"2408.08217","title":"RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train\n  and Deploy Edge Classifiers for Computational Social Science","authors":"David Farr, Nico Manzonelli, Iain Cruickshank, and Jevin West","authorsParsed":[["Farr","David",""],["Manzonelli","Nico",""],["Cruickshank","Iain",""],["West","Jevin",""]],"versions":[{"version":"v1","created":"Thu, 15 Aug 2024 15:28:37 GMT"}],"updateDate":"2024-08-16","timestamp":1723735717000,"abstract":"  Large language models (LLMs) have enhanced our ability to rapidly analyze and\nclassify unstructured natural language data. However, concerns regarding cost,\nnetwork limitations, and security constraints have posed challenges for their\nintegration into work processes. In this study, we adopt a systems design\napproach to employing LLMs as imperfect data annotators for downstream\nsupervised learning tasks, introducing novel system intervention measures aimed\nat improving classification performance. Our methodology outperforms\nLLM-generated labels in seven of eight tests, demonstrating an effective\nstrategy for incorporating LLMs into the design and deployment of specialized,\nsupervised learning models present in many industry use cases.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Social and Information Networks"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"kYHXct2qruDIQgqg5copo_PFgKbCg6qHFT5ImpTQ4tA","pdfSize":"577347"}
