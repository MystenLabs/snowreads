{"id":"2408.16589","title":"CrisperWhisper: Accurate Timestamps on Verbatim Speech Transcriptions","authors":"Laurin Wagner, Bernhard Thallinger, Mario Zusag","authorsParsed":[["Wagner","Laurin",""],["Thallinger","Bernhard",""],["Zusag","Mario",""]],"versions":[{"version":"v1","created":"Thu, 29 Aug 2024 14:52:42 GMT"}],"updateDate":"2024-08-30","timestamp":1724943162000,"abstract":"  We demonstrate that carefully adjusting the tokenizer of the Whisper speech\nrecognition model significantly improves the precision of word-level timestamps\nwhen applying dynamic time warping to the decoder's cross-attention scores. We\nfine-tune the model to produce more verbatim speech transcriptions and employ\nseveral techniques to increase robustness against multiple speakers and\nbackground noise. These adjustments achieve state-of-the-art performance on\nbenchmarks for verbatim speech transcription, word segmentation, and the timed\ndetection of filler events, and can further mitigate transcription\nhallucinations. The code is available open\nhttps://github.com/nyrahealth/CrisperWhisper.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"uNKpwr0KlXmfgUGv-iYbmvmbFEmN0qTHEMGBQW72FyI","pdfSize":"2387507"}
