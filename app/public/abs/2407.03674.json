{"id":"2407.03674","title":"Short-Long Policy Evaluation with Novel Actions","authors":"Hyunji Alex Nam, Yash Chandak and Emma Brunskill","authorsParsed":[["Nam","Hyunji Alex",""],["Chandak","Yash",""],["Brunskill","Emma",""]],"versions":[{"version":"v1","created":"Thu, 4 Jul 2024 06:42:21 GMT"},{"version":"v2","created":"Tue, 9 Jul 2024 18:05:10 GMT"}],"updateDate":"2024-07-11","timestamp":1720075341000,"abstract":"  From incorporating LLMs in education, to identifying new drugs and improving\nways to charge batteries, innovators constantly try new strategies in search of\nbetter long-term outcomes for students, patients and consumers. One major\nbottleneck in this innovation cycle is the amount of time it takes to observe\nthe downstream effects of a decision policy that incorporates new\ninterventions. The key question is whether we can quickly evaluate long-term\noutcomes of a new decision policy without making long-term observations.\nOrganizations often have access to prior data about past decision policies and\ntheir outcomes, evaluated over the full horizon of interest. Motivated by this,\nwe introduce a new setting for short-long policy evaluation for sequential\ndecision making tasks. Our proposed methods significantly outperform prior\nresults on simulators of HIV treatment, kidney dialysis and battery charging.\nWe also demonstrate that our methods can be useful for applications in AI\nsafety by quickly identifying when a new decision policy is likely to have\nsubstantially lower performance than past policies.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}