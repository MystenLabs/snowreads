{"id":"2408.12974","title":"Accuracy Improvement of Cell Image Segmentation Using Feedback Former","authors":"Hinako Mitsuoka, Kazuhiro Hotta","authorsParsed":[["Mitsuoka","Hinako",""],["Hotta","Kazuhiro",""]],"versions":[{"version":"v1","created":"Fri, 23 Aug 2024 10:48:03 GMT"}],"updateDate":"2024-08-26","timestamp":1724410083000,"abstract":"  Semantic segmentation of microscopy cell images by deep learning is a\nsignificant technique. We considered that the Transformers, which have recently\noutperformed CNNs in image recognition, could also be improved and developed\nfor cell image segmentation. Transformers tend to focus more on contextual\ninformation than on detailed information. This tendency leads to a lack of\ndetailed information for segmentation. Therefore, to supplement or reinforce\nthe missing detailed information, we hypothesized that feedback processing in\nthe human visual cortex should be effective. Our proposed Feedback Former is a\nnovel architecture for semantic segmentation, in which Transformers is used as\nan encoder and has a feedback processing mechanism. Feature maps with detailed\ninformation are fed back to the lower layers from near the output of the model\nto compensate for the lack of detailed information which is the weakness of\nTransformers and improve the segmentation accuracy. By experiments on three\ncell image datasets, we confirmed that our method surpasses methods without\nfeedback, demonstrating its superior accuracy in cell image segmentation. Our\nmethod achieved higher segmentation accuracy while consuming less computational\ncost than conventional feedback approaches. Moreover, our method offered\nsuperior precision without simply increasing the model size of Transformer\nencoder, demonstrating higher accuracy with lower computational cost.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}