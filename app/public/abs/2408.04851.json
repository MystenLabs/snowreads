{"id":"2408.04851","title":"Your Classifier Can Be Secretly a Likelihood-Based OOD Detector","authors":"Jirayu Burapacheep, Yixuan Li","authorsParsed":[["Burapacheep","Jirayu",""],["Li","Yixuan",""]],"versions":[{"version":"v1","created":"Fri, 9 Aug 2024 04:00:53 GMT"}],"updateDate":"2024-08-12","timestamp":1723176053000,"abstract":"  The ability to detect out-of-distribution (OOD) inputs is critical to\nguarantee the reliability of classification models deployed in an open\nenvironment. A fundamental challenge in OOD detection is that a discriminative\nclassifier is typically trained to estimate the posterior probability p(y|z)\nfor class y given an input z, but lacks the explicit likelihood estimation of\np(z) ideally needed for OOD detection. While numerous OOD scoring functions\nhave been proposed for classification models, these estimate scores are often\nheuristic-driven and cannot be rigorously interpreted as likelihood. To bridge\nthe gap, we propose Intrinsic Likelihood (INK), which offers rigorous\nlikelihood interpretation to modern discriminative-based classifiers.\nSpecifically, our proposed INK score operates on the constrained latent\nembeddings of a discriminative classifier, which are modeled as a mixture of\nhyperspherical embeddings with constant norm. We draw a novel connection\nbetween the hyperspherical distribution and the intrinsic likelihood, which can\nbe effectively optimized in modern neural networks. Extensive experiments on\nthe OpenOOD benchmark empirically demonstrate that INK establishes a new\nstate-of-the-art in a variety of OOD detection setups, including both far-OOD\nand near-OOD. Code is available at https://github.com/deeplearning-wisc/ink.\n","subjects":["Computing Research Repository/Machine Learning","Statistics/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}