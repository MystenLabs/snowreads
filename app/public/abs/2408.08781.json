{"id":"2408.08781","title":"Evaluating the Evaluator: Measuring LLMs' Adherence to Task Evaluation\n  Instructions","authors":"Bhuvanashree Murugadoss, Christian Poelitz, Ian Drosos, Vu Le, Nick\n  McKenna, Carina Suzana Negreanu, Chris Parnin, Advait Sarkar","authorsParsed":[["Murugadoss","Bhuvanashree",""],["Poelitz","Christian",""],["Drosos","Ian",""],["Le","Vu",""],["McKenna","Nick",""],["Negreanu","Carina Suzana",""],["Parnin","Chris",""],["Sarkar","Advait",""]],"versions":[{"version":"v1","created":"Fri, 16 Aug 2024 14:49:35 GMT"}],"updateDate":"2024-08-19","timestamp":1723819775000,"abstract":"  LLMs-as-a-judge is a recently popularized method which replaces human\njudgements in task evaluation (Zheng et al. 2024) with automatic evaluation\nusing LLMs. Due to widespread use of RLHF (Reinforcement Learning from Human\nFeedback), state-of-the-art LLMs like GPT4 and Llama3 are expected to have\nstrong alignment with human preferences when prompted for a quality judgement,\nsuch as the coherence of a text. While this seems beneficial, it is not clear\nwhether the assessments by an LLM-as-a-judge constitute only an evaluation\nbased on the instructions in the prompts, or reflect its preference for\nhigh-quality data similar to its fine-tune data. To investigate how much\ninfluence prompting the LLMs-as-a-judge has on the alignment of AI judgements\nto human judgements, we analyze prompts with increasing levels of instructions\nabout the target quality of an evaluation, for several LLMs-as-a-judge.\nFurther, we compare to a prompt-free method using model perplexity as a quality\nmeasure instead. We aggregate a taxonomy of quality criteria commonly used\nacross state-of-the-art evaluations with LLMs and provide this as a rigorous\nbenchmark of models as judges. Overall, we show that the LLMs-as-a-judge\nbenefit only little from highly detailed instructions in prompts and that\nperplexity can sometimes align better with human judgements than prompting,\nespecially on textual quality.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/"}