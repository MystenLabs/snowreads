{"id":"2407.14006","title":"MSceneSpeech: A Multi-Scene Speech Dataset For Expressive Speech\n  Synthesis","authors":"Qian Yang, Jialong Zuo, Zhe Su, Ziyue Jiang, Mingze Li, Zhou Zhao,\n  Feiyang Chen, Zhefeng Wang, Baoxing Huai","authorsParsed":[["Yang","Qian",""],["Zuo","Jialong",""],["Su","Zhe",""],["Jiang","Ziyue",""],["Li","Mingze",""],["Zhao","Zhou",""],["Chen","Feiyang",""],["Wang","Zhefeng",""],["Huai","Baoxing",""]],"versions":[{"version":"v1","created":"Fri, 19 Jul 2024 03:36:48 GMT"}],"updateDate":"2024-07-22","timestamp":1721360208000,"abstract":"  We introduce an open source high-quality Mandarin TTS dataset MSceneSpeech\n(Multiple Scene Speech Dataset), which is intended to provide resources for\nexpressive speech synthesis. MSceneSpeech comprises numerous audio recordings\nand texts performed and recorded according to daily life scenarios. Each\nscenario includes multiple speakers and a diverse range of prosodic styles,\nmaking it suitable for speech synthesis that entails multi-speaker style and\nprosody modeling. We have established a robust baseline, through the prompting\nmechanism, that can effectively synthesize speech characterized by both\nuser-specific timbre and scene-specific prosody with arbitrary text input. The\nopen source MSceneSpeech Dataset and audio samples of our baseline are\navailable at https://speechai-demo.github.io/MSceneSpeech/.\n","subjects":["Electrical Engineering and Systems Science/Audio and Speech Processing","Computing Research Repository/Sound"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"7hMFDS3b9O5t_zKm7NbzuAjHoPZ6_T3ZNbM796JyhEw","pdfSize":"352737"}
