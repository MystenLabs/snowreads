{"id":"2408.04817","title":"Performance Metric for Multiple Anomaly Score Distributions with\n  Discrete Severity Levels","authors":"Wonjun Yi, Yong-Hwa Park, and Wonho Jung","authorsParsed":[["Yi","Wonjun",""],["Park","Yong-Hwa",""],["Jung","Wonho",""]],"versions":[{"version":"v1","created":"Fri, 9 Aug 2024 02:17:49 GMT"}],"updateDate":"2024-08-12","timestamp":1723169869000,"abstract":"  The rise of smart factories has heightened the demand for automated\nmaintenance, and normal-data-based anomaly detection has proved particularly\neffective in environments where anomaly data are scarce. This method, which\ndoes not require anomaly data during training, has prompted researchers to\nfocus not only on detecting anomalies but also on classifying severity levels\nby using anomaly scores. However, the existing performance metrics, such as the\narea under the receiver operating characteristic curve (AUROC), do not\neffectively reflect the performance of models in classifying severity levels\nbased on anomaly scores. To address this limitation, we propose the weighted\nsum of the area under the receiver operating characteristic curve (WS-AUROC),\nwhich combines AUROC with a penalty for severity level differences. We\nconducted various experiments using different penalty assignment methods:\nuniform penalty regardless of severity level differences, penalty based on\nseverity level index differences, and penalty based on actual physical\nquantities that cause anomalies. The latter method was the most sensitive.\nAdditionally, we propose an anomaly detector that achieves clear separation of\ndistributions and outperforms the ablation models on the WS-AUROC and AUROC\nmetrics.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/"}