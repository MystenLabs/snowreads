{"id":"2408.14293","title":"Investigating the Effectiveness of Bayesian Spam Filters in Detecting\n  LLM-modified Spam Mails","authors":"Malte Josten and Torben Weis","authorsParsed":[["Josten","Malte",""],["Weis","Torben",""]],"versions":[{"version":"v1","created":"Mon, 26 Aug 2024 14:25:30 GMT"}],"updateDate":"2024-08-27","timestamp":1724682330000,"abstract":"  Spam and phishing remain critical threats in cybersecurity, responsible for\nnearly 90% of security incidents. As these attacks grow in sophistication, the\nneed for robust defensive mechanisms intensifies. Bayesian spam filters, like\nthe widely adopted open-source SpamAssassin, are essential tools in this fight.\nHowever, the emergence of large language models (LLMs) such as ChatGPT presents\nnew challenges. These models are not only powerful and accessible, but also\ninexpensive to use, raising concerns about their misuse in crafting\nsophisticated spam emails that evade traditional spam filters. This work aims\nto evaluate the robustness and effectiveness of SpamAssassin against\nLLM-modified email content. We developed a pipeline to test this vulnerability.\nOur pipeline modifies spam emails using GPT-3.5 Turbo and assesses\nSpamAssassin's ability to classify these modified emails correctly. The results\nshow that SpamAssassin misclassified up to 73.7% of LLM-modified spam emails as\nlegitimate. In contrast, a simpler dictionary-replacement attack showed a\nmaximum success rate of only 0.4%. These findings highlight the significant\nthreat posed by LLM-modified spam, especially given the cost-efficiency of such\nattacks (0.17 cents per email). This paper provides crucial insights into the\nvulnerabilities of current spam filters and the need for continuous improvement\nin cybersecurity measures.\n","subjects":["Computing Research Repository/Cryptography and Security"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/"}