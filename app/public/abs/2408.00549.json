{"id":"2408.00549","title":"Learning to Embed Distributions via Maximum Kernel Entropy","authors":"Oleksii Kachaiev, Stefano Recanatesi","authorsParsed":[["Kachaiev","Oleksii",""],["Recanatesi","Stefano",""]],"versions":[{"version":"v1","created":"Thu, 1 Aug 2024 13:34:19 GMT"}],"updateDate":"2024-08-02","timestamp":1722519259000,"abstract":"  Empirical data can often be considered as samples from a set of probability\ndistributions. Kernel methods have emerged as a natural approach for learning\nto classify these distributions. Although numerous kernels between\ndistributions have been proposed, applying kernel methods to distribution\nregression tasks remains challenging, primarily because selecting a suitable\nkernel is not straightforward. Surprisingly, the question of learning a\ndata-dependent distribution kernel has received little attention. In this\npaper, we propose a novel objective for the unsupervised learning of\ndata-dependent distribution kernel, based on the principle of entropy\nmaximization in the space of probability measure embeddings. We examine the\ntheoretical properties of the latent embedding space induced by our objective,\ndemonstrating that its geometric structure is well-suited for solving\ndownstream discriminative tasks. Finally, we demonstrate the performance of the\nlearned kernel across different modalities.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence","Electrical Engineering and Systems Science/Signal Processing","Statistics/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}