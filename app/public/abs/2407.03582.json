{"id":"2407.03582","title":"Integrating Randomness in Large Language Models: A Linear Congruential\n  Generator Approach for Generating Clinically Relevant Content","authors":"Andrew Bouras","authorsParsed":[["Bouras","Andrew",""]],"versions":[{"version":"v1","created":"Thu, 4 Jul 2024 02:21:47 GMT"}],"updateDate":"2024-07-08","timestamp":1720059707000,"abstract":"  Generating diverse, high-quality outputs from language models is crucial for\napplications in education and content creation. Achieving true randomness and\navoiding repetition remains a significant challenge. This study uses the Linear\nCongruential Generator method for systematic fact selection, combined with\nAI-powered content generation. We ensured unique combinations of\ngastrointestinal physiology and pathology facts across multiple rounds,\nintegrating these facts into prompts for GPT-4o to create clinically relevant,\nvignette-style outputs. Over 14 rounds, 98 unique outputs were generated,\ndemonstrating LCG's effectiveness in producing diverse and high-quality\ncontent. This method addresses key issues of randomness and repetition,\nenhancing the quality and efficiency of language model-generated content for\nvarious applications.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/"}