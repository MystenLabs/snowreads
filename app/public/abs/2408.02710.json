{"id":"2408.02710","title":"RCDM: Enabling Robustness for Conditional Diffusion Model","authors":"Weifeng Xu, Xiang Zhu, Xiaoyong Li","authorsParsed":[["Xu","Weifeng",""],["Zhu","Xiang",""],["Li","Xiaoyong",""]],"versions":[{"version":"v1","created":"Mon, 5 Aug 2024 13:12:57 GMT"}],"updateDate":"2024-08-07","timestamp":1722863577000,"abstract":"  The conditional diffusion model (CDM) enhances the standard diffusion model\nby providing more control, improving the quality and relevance of the outputs,\nand making the model adaptable to a wider range of complex tasks. However,\ninaccurate conditional inputs in the inverse process of CDM can easily lead to\ngenerating fixed errors in the neural network, which diminishes the\nadaptability of a well-trained model. The existing methods like data\naugmentation, adversarial training, robust optimization can improve the\nrobustness, while they often face challenges such as high computational\ncomplexity, limited applicability to unknown perturbations, and increased\ntraining difficulty. In this paper, we propose a lightweight solution, the\nRobust Conditional Diffusion Model (RCDM), based on control theory to\ndynamically reduce the impact of noise and significantly enhance the model's\nrobustness. RCDM leverages the collaborative interaction between two neural\nnetworks, along with optimal control strategies derived from control theory, to\noptimize the weights of two networks during the sampling process. Unlike\nconventional techniques, RCDM establishes a mathematical relationship between\nfixed errors and the weights of the two neural networks without incurring\nadditional computational overhead. Extensive experiments were conducted on\nMNIST and CIFAR-10 datasets, and the results demonstrate the effectiveness and\nadaptability of our proposed model.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}