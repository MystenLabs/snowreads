{"id":"2407.14008","title":"Investigating the Indirect Object Identification circuit in Mamba","authors":"Danielle Ensign, Adri\\`a Garriga-Alonso","authorsParsed":[["Ensign","Danielle",""],["Garriga-Alonso","Adri√†",""]],"versions":[{"version":"v1","created":"Fri, 19 Jul 2024 03:45:27 GMT"},{"version":"v2","created":"Mon, 22 Jul 2024 02:13:58 GMT"}],"updateDate":"2024-07-23","timestamp":1721360727000,"abstract":"  How well will current interpretability techniques generalize to future\nmodels? A relevant case study is Mamba, a recent recurrent architecture with\nscaling comparable to Transformers. We adapt pre-Mamba techniques to Mamba and\npartially reverse-engineer the circuit responsible for the Indirect Object\nIdentification (IOI) task. Our techniques provide evidence that 1) Layer 39 is\na key bottleneck, 2) Convolutions in layer 39 shift names one position forward,\nand 3) The name entities are stored linearly in Layer 39's SSM. Finally, we\nadapt an automatic circuit discovery tool, positional Edge Attribution\nPatching, to identify a Mamba IOI circuit. Our contributions provide initial\nevidence that circuit-based mechanistic interpretability tools work well for\nthe Mamba architecture.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}