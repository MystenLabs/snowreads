{"id":"2408.00284","title":"Bailing-TTS: Chinese Dialectal Speech Synthesis Towards Human-like\n  Spontaneous Representation","authors":"Xinhan Di, Zihao Chen, Yunming Liang, Junjie Zheng, Yihua Wang,\n  Chaofan Ding","authorsParsed":[["Di","Xinhan",""],["Chen","Zihao",""],["Liang","Yunming",""],["Zheng","Junjie",""],["Wang","Yihua",""],["Ding","Chaofan",""]],"versions":[{"version":"v1","created":"Thu, 1 Aug 2024 04:57:31 GMT"}],"updateDate":"2024-08-02","timestamp":1722488251000,"abstract":"  Large-scale text-to-speech (TTS) models have made significant progress\nrecently.However, they still fall short in the generation of Chinese dialectal\nspeech. Toaddress this, we propose Bailing-TTS, a family of large-scale TTS\nmodels capable of generating high-quality Chinese dialectal speech. Bailing-TTS\nserves as a foundation model for Chinese dialectal speech generation. First,\ncontinual semi-supervised learning is proposed to facilitate the alignment of\ntext tokens and speech tokens. Second, the Chinese dialectal representation\nlearning is developed using a specific transformer architecture and multi-stage\ntraining processes. With the proposed design of novel network architecture and\ncorresponding strategy, Bailing-TTS is able to generate Chinese dialectal\nspeech from text effectively and efficiently. Experiments demonstrate that\nBailing-TTS generates Chinese dialectal speech towards human-like spontaneous\nrepresentation. Readers are encouraged to listen to demos at\n\\url{https://c9412600.github.io/bltts_tech_report/index.html}.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Sound","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"_hFT1Dn7mtGWkCDICXQZxsLdMR2riYlpBJxkJj5qzMo","pdfSize":"2461709","txDigest":"F2ich8d2mpdxjXp7JcaaTApWvhU1gJvokK5QJEZNcBmh","endEpoch":"1","status":"CERTIFIED"}
