{"id":"2408.08560","title":"A training regime to learn unified representations from complementary\n  breast imaging modalities","authors":"Umang Sharma, Jungkyu Park, Laura Heacock, Sumit Chopra and Krzysztof\n  Geras","authorsParsed":[["Sharma","Umang",""],["Park","Jungkyu",""],["Heacock","Laura",""],["Chopra","Sumit",""],["Geras","Krzysztof",""]],"versions":[{"version":"v1","created":"Fri, 16 Aug 2024 06:52:06 GMT"}],"updateDate":"2024-08-19","timestamp":1723791126000,"abstract":"  Full Field Digital Mammograms (FFDMs) and Digital Breast Tomosynthesis (DBT)\nare the two most widely used imaging modalities for breast cancer screening.\nAlthough DBT has increased cancer detection compared to FFDM, its widespread\nadoption in clinical practice has been slowed by increased interpretation times\nand a perceived decrease in the conspicuity of specific lesion types.\nSpecifically, the non-inferiority of DBT for microcalcifications remains under\ndebate. Due to concerns about the decrease in visual acuity, combined DBT-FFDM\nacquisitions remain popular, leading to overall increased exam times and\nradiation dosage. Enabling DBT to provide diagnostic information present in\nboth FFDM and DBT would reduce reliance on FFDM, resulting in a reduction in\nboth quantities. We propose a machine learning methodology that learns\nhigh-level representations leveraging the complementary diagnostic signal from\nboth DBT and FFDM. Experiments on a large-scale data set validate our claims\nand show that our representations enable more accurate breast lesion detection\nthan any DBT- or FFDM-based model.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}