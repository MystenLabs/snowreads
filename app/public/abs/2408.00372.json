{"id":"2408.00372","title":"Few-shot Defect Image Generation based on Consistency Modeling","authors":"Qingfeng Shi, Jing Wei, Fei Shen, Zhengtao Zhang","authorsParsed":[["Shi","Qingfeng",""],["Wei","Jing",""],["Shen","Fei",""],["Zhang","Zhengtao",""]],"versions":[{"version":"v1","created":"Thu, 1 Aug 2024 08:29:42 GMT"}],"updateDate":"2024-08-02","timestamp":1722500982000,"abstract":"  Image generation can solve insufficient labeled data issues in defect\ndetection. Most defect generation methods are only trained on a single product\nwithout considering the consistencies among multiple products, leading to poor\nquality and diversity of generated results. To address these issues, we propose\nDefectDiffu, a novel text-guided diffusion method to model both intra-product\nbackground consistency and inter-product defect consistency across multiple\nproducts and modulate the consistency perturbation directions to control\nproduct type and defect strength, achieving diversified defect image\ngeneration. Firstly, we leverage a text encoder to separately provide\nconsistency prompts for background, defect, and fusion parts of the\ndisentangled integrated architecture, thereby disentangling defects and normal\nbackgrounds. Secondly, we propose the double-free strategy to generate defect\nimages through two-stage perturbation of consistency direction, thereby\ncontrolling product type and defect strength by adjusting the perturbation\nscale. Besides, DefectDiffu can generate defect mask annotations utilizing\ncross-attention maps from the defect part. Finally, to improve the generation\nquality of small defects and masks, we propose the adaptive attention-enhance\nloss to increase the attention to defects. Experimental results demonstrate\nthat DefectDiffu surpasses state-of-the-art methods in terms of generation\nquality and diversity, thus effectively improving downstream defection\nperformance. Moreover, defect perturbation directions can be transferred among\nvarious products to achieve zero-shot defect generation, which is highly\nbeneficial for addressing insufficient data issues. The code are available at\nhttps://github.com/FFDD-diffusion/DefectDiffu.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}