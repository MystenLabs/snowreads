{"id":"2407.16447","title":"The CHiME-8 DASR Challenge for Generalizable and Array Agnostic Distant\n  Automatic Speech Recognition and Diarization","authors":"Samuele Cornell and Taejin Park and Steve Huang and Christoph\n  Boeddeker and Xuankai Chang and Matthew Maciejewski and Matthew Wiesner and\n  Paola Garcia and Shinji Watanabe","authorsParsed":[["Cornell","Samuele",""],["Park","Taejin",""],["Huang","Steve",""],["Boeddeker","Christoph",""],["Chang","Xuankai",""],["Maciejewski","Matthew",""],["Wiesner","Matthew",""],["Garcia","Paola",""],["Watanabe","Shinji",""]],"versions":[{"version":"v1","created":"Tue, 23 Jul 2024 12:54:32 GMT"}],"updateDate":"2024-07-24","timestamp":1721739272000,"abstract":"  This paper presents the CHiME-8 DASR challenge which carries on from the\nprevious edition CHiME-7 DASR (C7DASR) and the past CHiME-6 challenge. It\nfocuses on joint multi-channel distant speech recognition (DASR) and\ndiarization with one or more, possibly heterogeneous, devices. The main goal is\nto spur research towards meeting transcription approaches that can generalize\nacross arbitrary number of speakers, diverse settings (formal vs. informal\nconversations), meeting duration, wide-variety of acoustic scenarios and\ndifferent recording configurations. Novelties with respect to C7DASR include:\ni) the addition of NOTSOFAR-1, an additional office/corporate meeting scenario,\nii) a manually corrected Mixer 6 development set, iii) a new track in which we\nallow the use of large-language models (LLM) iv) a jury award mechanism to\nencourage participants to explore also more practical and innovative solutions.\nTo lower the entry barrier for participants, we provide a standalone toolkit\nfor downloading and preparing such datasets as well as performing text\nnormalization and scoring their submissions. Furthermore, this year we also\nprovide two baseline systems, one directly inherited from C7DASR and based on\nESPnet and another one developed on NeMo and based on NeMo team submission in\nlast year C7DASR. Baseline system results suggest that the addition of the\nNOTSOFAR-1 scenario significantly increases the task's difficulty due to its\nhigh number of speakers and very short duration.\n","subjects":["Electrical Engineering and Systems Science/Audio and Speech Processing","Computing Research Repository/Sound"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}