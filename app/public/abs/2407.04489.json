{"id":"2407.04489","title":"Dude: Dual Distribution-Aware Context Prompt Learning For Large\n  Vision-Language Model","authors":"Duy M. H. Nguyen, An T. Le, Trung Q. Nguyen, Nghiem T. Diep, Tai\n  Nguyen, Duy Duong-Tran, Jan Peters, Li Shen, Mathias Niepert, Daniel Sonntag","authorsParsed":[["Nguyen","Duy M. H.",""],["Le","An T.",""],["Nguyen","Trung Q.",""],["Diep","Nghiem T.",""],["Nguyen","Tai",""],["Duong-Tran","Duy",""],["Peters","Jan",""],["Shen","Li",""],["Niepert","Mathias",""],["Sonntag","Daniel",""]],"versions":[{"version":"v1","created":"Fri, 5 Jul 2024 13:15:29 GMT"}],"updateDate":"2024-07-08","timestamp":1720185329000,"abstract":"  Prompt learning methods are gaining increasing attention due to their ability\nto customize large vision-language models to new domains using pre-trained\ncontextual knowledge and minimal training data. However, existing works\ntypically rely on optimizing unified prompt inputs, often struggling with\nfine-grained classification tasks due to insufficient discriminative\nattributes. To tackle this, we consider a new framework based on a dual context\nof both domain-shared and class-specific contexts, where the latter is\ngenerated by Large Language Models (LLMs) such as GPTs. Such dual prompt\nmethods enhance the model's feature representation by joining implicit and\nexplicit factors encoded in LLM knowledge. Moreover, we formulate the\nUnbalanced Optimal Transport (UOT) theory to quantify the relationships between\nconstructed prompts and visual tokens. Through partial matching, UOT can\nproperly align discrete sets of visual tokens and prompt embeddings under\ndifferent mass distributions, which is particularly valuable for handling\nirrelevant or noisy elements, ensuring that the preservation of mass does not\nrestrict transport solutions. Furthermore, UOT's characteristics integrate\nseamlessly with image augmentation, expanding the training sample pool while\nmaintaining a reasonable distance between perturbed images and prompt inputs.\nExtensive experiments across few-shot classification and adapter settings\nsubstantiate the superiority of our model over current state-of-the-art\nbaselines.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"P8upTiZuJKGs8OjyIsV0gEExAVHc_DC8HKkXichr8s8","pdfSize":"25484631"}
