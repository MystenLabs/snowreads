{"id":"2407.15672","title":"Computer Audition: From Task-Specific Machine Learning to Foundation\n  Models","authors":"Andreas Triantafyllopoulos, Iosif Tsangko, Alexander Gebhard,\n  Annamaria Mesaros, Tuomas Virtanen, Bj\\\"orn Schuller","authorsParsed":[["Triantafyllopoulos","Andreas",""],["Tsangko","Iosif",""],["Gebhard","Alexander",""],["Mesaros","Annamaria",""],["Virtanen","Tuomas",""],["Schuller","Bj√∂rn",""]],"versions":[{"version":"v1","created":"Mon, 22 Jul 2024 14:41:29 GMT"}],"updateDate":"2024-07-23","timestamp":1721659289000,"abstract":"  Foundation models (FMs) are increasingly spearheading recent advances on a\nvariety of tasks that fall under the purview of computer audition -- the use of\nmachines to understand sounds. They feature several advantages over traditional\npipelines: among others, the ability to consolidate multiple tasks in a single\nmodel, the option to leverage knowledge from other modalities, and the\nreadily-available interaction with human users. Naturally, these promises have\ncreated substantial excitement in the audio community, and have led to a wave\nof early attempts to build new, general-purpose foundation models for audio. In\nthe present contribution, we give an overview of computational audio analysis\nas it transitions from traditional pipelines towards auditory foundation\nmodels. Our work highlights the key operating principles that underpin those\nmodels, and showcases how they can accommodate multiple tasks that the audio\ncommunity previously tackled separately.\n","subjects":["Computing Research Repository/Sound","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}