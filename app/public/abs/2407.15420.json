{"id":"2407.15420","title":"Local All-Pair Correspondence for Point Tracking","authors":"Seokju Cho, Jiahui Huang, Jisu Nam, Honggyu An, Seungryong Kim,\n  Joon-Young Lee","authorsParsed":[["Cho","Seokju",""],["Huang","Jiahui",""],["Nam","Jisu",""],["An","Honggyu",""],["Kim","Seungryong",""],["Lee","Joon-Young",""]],"versions":[{"version":"v1","created":"Mon, 22 Jul 2024 06:49:56 GMT"}],"updateDate":"2024-07-23","timestamp":1721630996000,"abstract":"  We introduce LocoTrack, a highly accurate and efficient model designed for\nthe task of tracking any point (TAP) across video sequences. Previous\napproaches in this task often rely on local 2D correlation maps to establish\ncorrespondences from a point in the query image to a local region in the target\nimage, which often struggle with homogeneous regions or repetitive features,\nleading to matching ambiguities. LocoTrack overcomes this challenge with a\nnovel approach that utilizes all-pair correspondences across regions, i.e.,\nlocal 4D correlation, to establish precise correspondences, with bidirectional\ncorrespondence and matching smoothness significantly enhancing robustness\nagainst ambiguities. We also incorporate a lightweight correlation encoder to\nenhance computational efficiency, and a compact Transformer architecture to\nintegrate long-term temporal information. LocoTrack achieves unmatched accuracy\non all TAP-Vid benchmarks and operates at a speed almost 6 times faster than\nthe current state-of-the-art.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"BViIHTQr1ujYcvXkC_d7e8toc-tgXTySP9JrPrjQSTA","pdfSize":"7185428"}
