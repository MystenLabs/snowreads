{"id":"2408.09976","title":"Preference-Optimized Pareto Set Learning for Blackbox Optimization","authors":"Zhang Haishan, Diptesh Das, Koji Tsuda","authorsParsed":[["Haishan","Zhang",""],["Das","Diptesh",""],["Tsuda","Koji",""]],"versions":[{"version":"v1","created":"Mon, 19 Aug 2024 13:23:07 GMT"}],"updateDate":"2024-09-17","timestamp":1724073787000,"abstract":"  Multi-Objective Optimization (MOO) is an important problem in real-world\napplications. However, for a non-trivial problem, no single solution exists\nthat can optimize all the objectives simultaneously. In a typical MOO problem,\nthe goal is to find a set of optimum solutions (Pareto set) that trades off the\npreferences among objectives. Scalarization in MOO is a well-established method\nfor finding a finite set approximation of the whole Pareto set (PS). However,\nin real-world experimental design scenarios, it's beneficial to obtain the\nwhole PS for flexible exploration of the design space. Recently Pareto set\nlearning (PSL) has been introduced to approximate the whole PS. PSL involves\ncreating a manifold representing the Pareto front of a multi-objective\noptimization problem. A naive approach includes finding discrete points on the\nPareto front through randomly generated preference vectors and connecting them\nby regression. However, this approach is computationally expensive and leads to\na poor PS approximation. We propose to optimize the preference points to be\ndistributed evenly on the Pareto front. Our formulation leads to a bilevel\noptimization problem that can be solved by e.g. differentiable cross-entropy\nmethods. We demonstrated the efficacy of our method for complex and difficult\nblack-box MOO problems using both synthetic and real-world benchmark data.\n","subjects":["Computing Research Repository/Machine Learning","Mathematics/Optimization and Control"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}