{"id":"2408.10575","title":"MUSE: Mamba is Efficient Multi-scale Learner for Text-video Retrieval","authors":"Haoran Tang, Meng Cao, Jinfa Huang, Ruyang Liu, Peng Jin, Ge Li,\n  Xiaodan Liang","authorsParsed":[["Tang","Haoran",""],["Cao","Meng",""],["Huang","Jinfa",""],["Liu","Ruyang",""],["Jin","Peng",""],["Li","Ge",""],["Liang","Xiaodan",""]],"versions":[{"version":"v1","created":"Tue, 20 Aug 2024 06:30:37 GMT"}],"updateDate":"2024-08-21","timestamp":1724135437000,"abstract":"  Text-Video Retrieval (TVR) aims to align and associate relevant video content\nwith corresponding natural language queries. Most existing TVR methods are\nbased on large-scale pre-trained vision-language models (e.g., CLIP). However,\ndue to the inherent plain structure of CLIP, few TVR methods explore the\nmulti-scale representations which offer richer contextual information for a\nmore thorough understanding. To this end, we propose MUSE, a multi-scale mamba\nwith linear computational complexity for efficient cross-resolution modeling.\nSpecifically, the multi-scale representations are generated by applying a\nfeature pyramid on the last single-scale feature map. Then, we employ the Mamba\nstructure as an efficient multi-scale learner to jointly learn scale-wise\nrepresentations. Furthermore, we conduct comprehensive studies to investigate\ndifferent model structures and designs. Extensive results on three popular\nbenchmarks have validated the superiority of MUSE.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}