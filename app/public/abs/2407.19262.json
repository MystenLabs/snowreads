{"id":"2407.19262","title":"Understanding Memorisation in LLMs: Dynamics, Influencing Factors, and\n  Implications","authors":"Till Speicher, Mohammad Aflah Khan, Qinyuan Wu, Vedant Nanda, Soumi\n  Das, Bishwamittra Ghosh, Krishna P. Gummadi, Evimaria Terzi","authorsParsed":[["Speicher","Till",""],["Khan","Mohammad Aflah",""],["Wu","Qinyuan",""],["Nanda","Vedant",""],["Das","Soumi",""],["Ghosh","Bishwamittra",""],["Gummadi","Krishna P.",""],["Terzi","Evimaria",""]],"versions":[{"version":"v1","created":"Sat, 27 Jul 2024 14:00:21 GMT"}],"updateDate":"2024-07-30","timestamp":1722088821000,"abstract":"  Understanding whether and to what extent large language models (LLMs) have\nmemorised training data has important implications for the reliability of their\noutput and the privacy of their training data. In order to cleanly measure and\ndisentangle memorisation from other phenomena (e.g. in-context learning), we\ncreate an experimental framework that is based on repeatedly exposing LLMs to\nrandom strings. Our framework allows us to better understand the dynamics,\ni.e., the behaviour of the model, when repeatedly exposing it to random\nstrings. Using our framework, we make several striking observations: (a) we\nfind consistent phases of the dynamics across families of models (Pythia, Phi\nand Llama2), (b) we identify factors that make some strings easier to memorise\nthan others, and (c) we identify the role of local prefixes and global context\nin memorisation. We also show that sequential exposition to different random\nstrings has a significant effect on memorisation. Our results, often\nsurprising, have significant downstream implications in the study and usage of\nLLMs.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}