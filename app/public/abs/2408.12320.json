{"id":"2408.12320","title":"PolyRouter: A Multi-LLM Querying System","authors":"Dimitris Stripelis, Zijian Hu, Jipeng Zhang, Zhaozhuo Xu, Alay\n  Dilipbhai Shah, Han Jin, Yuhang Yao, Salman Avestimehr, and Chaoyang He","authorsParsed":[["Stripelis","Dimitris",""],["Hu","Zijian",""],["Zhang","Jipeng",""],["Xu","Zhaozhuo",""],["Shah","Alay Dilipbhai",""],["Jin","Han",""],["Yao","Yuhang",""],["Avestimehr","Salman",""],["He","Chaoyang",""]],"versions":[{"version":"v1","created":"Thu, 22 Aug 2024 11:57:07 GMT"},{"version":"v2","created":"Mon, 26 Aug 2024 23:05:51 GMT"}],"updateDate":"2024-08-28","timestamp":1724327827000,"abstract":"  With the rapid growth of Large Language Models (LLMs) across various domains,\nnumerous new LLMs have emerged, each possessing domain-specific expertise. This\nproliferation has highlighted the need for quick, high-quality, and\ncost-effective LLM query response methods. Yet, no single LLM exists to\nefficiently balance this trilemma. Some models are powerful but extremely\ncostly, while others are fast and inexpensive but qualitatively inferior. To\naddress this challenge, we present PolyRouter, a non-monolithic LLM querying\nsystem that seamlessly integrates various LLM experts into a single query\ninterface and dynamically routes incoming queries to the most high-performant\nexpert based on query's requirements. Through extensive experiments, we\ndemonstrate that when compared to standalone expert models, PolyRouter improves\nquery efficiency by up to 40%, and leads to significant cost reductions of up\nto 30%, while maintaining or enhancing model performance by up to 10%.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}