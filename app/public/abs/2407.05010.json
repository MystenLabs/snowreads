{"id":"2407.05010","title":"PRANCE: Joint Token-Optimization and Structural Channel-Pruning for\n  Adaptive ViT Inference","authors":"Ye Li, Chen Tang, Yuan Meng, Jiajun Fan, Zenghao Chai, Xinzhu Ma, Zhi\n  Wang, Wenwu Zhu","authorsParsed":[["Li","Ye",""],["Tang","Chen",""],["Meng","Yuan",""],["Fan","Jiajun",""],["Chai","Zenghao",""],["Ma","Xinzhu",""],["Wang","Zhi",""],["Zhu","Wenwu",""]],"versions":[{"version":"v1","created":"Sat, 6 Jul 2024 09:04:27 GMT"}],"updateDate":"2024-07-09","timestamp":1720256667000,"abstract":"  We introduce PRANCE, a Vision Transformer compression framework that jointly\noptimizes the activated channels and reduces tokens, based on the\ncharacteristics of inputs. Specifically, PRANCE~ leverages adaptive token\noptimization strategies for a certain computational budget, aiming to\naccelerate ViTs' inference from a unified data and architectural perspective.\nHowever, the joint framework poses challenges to both architectural and\ndecision-making aspects. Firstly, while ViTs inherently support variable-token\ninference, they do not facilitate dynamic computations for variable channels.\nTo overcome this limitation, we propose a meta-network using weight-sharing\ntechniques to support arbitrary channels of the Multi-head Self-Attention and\nMulti-layer Perceptron layers, serving as a foundational model for\narchitectural decision-making. Second, simultaneously optimizing the structure\nof the meta-network and input data constitutes a combinatorial optimization\nproblem with an extremely large decision space, reaching up to around\n$10^{14}$, making supervised learning infeasible. To this end, we design a\nlightweight selector employing Proximal Policy Optimization for efficient\ndecision-making. Furthermore, we introduce a novel \"Result-to-Go\" training\nmechanism that models ViTs' inference process as a Markov decision process,\nsignificantly reducing action space and mitigating delayed-reward issues during\ntraining. Extensive experiments demonstrate the effectiveness of PRANCE~ in\nreducing FLOPs by approximately 50\\%, retaining only about 10\\% of tokens while\nachieving lossless Top-1 accuracy. Additionally, our framework is shown to be\ncompatible with various token optimization techniques such as pruning, merging,\nand sequential pruning-merging strategies. The code is available at\n\\href{https://github.com/ChildTang/PRANCE}{https://github.com/ChildTang/PRANCE}.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}