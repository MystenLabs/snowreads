{"id":"2407.00596","title":"HATs: Hierarchical Adaptive Taxonomy Segmentation for Panoramic\n  Pathology Image Analysis","authors":"Ruining Deng, Quan Liu, Can Cui, Tianyuan Yao, Juming Xiong, Shunxing\n  Bao, Hao Li, Mengmeng Yin, Yu Wang, Shilin Zhao, Yucheng Tang, Haichun Yang,\n  Yuankai Huo","authorsParsed":[["Deng","Ruining",""],["Liu","Quan",""],["Cui","Can",""],["Yao","Tianyuan",""],["Xiong","Juming",""],["Bao","Shunxing",""],["Li","Hao",""],["Yin","Mengmeng",""],["Wang","Yu",""],["Zhao","Shilin",""],["Tang","Yucheng",""],["Yang","Haichun",""],["Huo","Yuankai",""]],"versions":[{"version":"v1","created":"Sun, 30 Jun 2024 05:35:26 GMT"}],"updateDate":"2024-07-02","timestamp":1719725726000,"abstract":"  Panoramic image segmentation in computational pathology presents a remarkable\nchallenge due to the morphologically complex and variably scaled anatomy. For\ninstance, the intricate organization in kidney pathology spans multiple layers,\nfrom regions like the cortex and medulla to functional units such as glomeruli,\ntubules, and vessels, down to various cell types. In this paper, we propose a\nnovel Hierarchical Adaptive Taxonomy Segmentation (HATs) method, which is\ndesigned to thoroughly segment panoramic views of kidney structures by\nleveraging detailed anatomical insights. Our approach entails (1) the\ninnovative HATs technique which translates spatial relationships among 15\ndistinct object classes into a versatile \"plug-and-play\" loss function that\nspans across regions, functional units, and cells, (2) the incorporation of\nanatomical hierarchies and scale considerations into a unified simple matrix\nrepresentation for all panoramic entities, (3) the adoption of the latest AI\nfoundation model (EfficientSAM) as a feature extraction tool to boost the\nmodel's adaptability, yet eliminating the need for manual prompt generation in\nconventional segment anything model (SAM). Experimental findings demonstrate\nthat the HATs method offers an efficient and effective strategy for integrating\nclinical insights and imaging precedents into a unified segmentation model\nacross more than 15 categories. The official implementation is publicly\navailable at https://github.com/hrlblab/HATs.\n","subjects":["Electrical Engineering and Systems Science/Image and Video Processing","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}