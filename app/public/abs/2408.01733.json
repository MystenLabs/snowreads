{"id":"2408.01733","title":"CoEdPilot: Recommending Code Edits with Learned Prior Edit Relevance,\n  Project-wise Awareness, and Interactive Nature","authors":"Chenyan Liu, Yufan Cai, Yun Lin, Yuhuan Huang, Yunrui Pei, Bo Jiang,\n  Ping Yang, Jin Song Dong, Hong Mei","authorsParsed":[["Liu","Chenyan",""],["Cai","Yufan",""],["Lin","Yun",""],["Huang","Yuhuan",""],["Pei","Yunrui",""],["Jiang","Bo",""],["Yang","Ping",""],["Dong","Jin Song",""],["Mei","Hong",""]],"versions":[{"version":"v1","created":"Sat, 3 Aug 2024 10:23:05 GMT"}],"updateDate":"2024-08-06","timestamp":1722680585000,"abstract":"  Recent years have seen the development of LLM-based code generation. Compared\nto generating code in a software project, incremental code edits are\nempirically observed to be more frequent. The emerging code editing approaches\nusually formulate the problem as generating an edit based on known relevant\nprior edits and context. However, practical code edits can be more complicated.\nFirst, an editing session can include multiple (ir)relevant edits to the code\nunder edit. Second, the inference of the subsequent edits is non-trivial as the\nscope of its ripple effect can be the whole project. In this work, we propose\nCoEdPilot, an LLM-driven solution to recommend code edits by discriminating the\nrelevant edits, exploring their interactive natures, and estimating its ripple\neffect in the project. Specifically, CoEdPilot orchestrates multiple neural\ntransformers to identify what and how to edit in the project regarding both\nedit location and edit content. When a user accomplishes an edit with an\noptional editing description, a Subsequent Edit Analysis first reports the most\nrelevant files in the project with what types of edits (e.g., keep, insert, and\nreplace) can happen for each line of their code. Next, an Edit-content\nGenerator generates concrete edit options for the lines of code, regarding its\nrelevant prior changes reported by an Edit-dependency Analyzer. Lastly, both\nthe Subsequent Edit Analysis and the Edit-content Generator capture relevant\nprior edits as feedback to readjust their recommendations. We train our models\nby collecting over 180K commits from 471 open-source projects in 5 programming\nlanguages. Our extensive experiments show that CoEdPilot can well predict the\nedits (i.e., predicting edit location with an accuracy of 70.8%-85.3%, and the\nedit content with an exact match rate of 41.8% and BLEU4 score of 60.7)...\n","subjects":["Computing Research Repository/Software Engineering"],"license":"http://creativecommons.org/publicdomain/zero/1.0/","blobId":"Mfy2HRwVeN3BTMsqAnqNyNgqbiz4mpKCv6NIUbevj2w","pdfSize":"1366628"}
