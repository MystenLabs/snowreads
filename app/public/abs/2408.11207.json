{"id":"2408.11207","title":"Quantum Inverse Contextual Vision Transformers (Q-ICVT): A New Frontier\n  in 3D Object Detection for AVs","authors":"Sanjay Bhargav Dharavath, Tanmoy Dam, Supriyo Chakraborty, Prithwiraj\n  Roy, and Aniruddha Maiti","authorsParsed":[["Dharavath","Sanjay Bhargav",""],["Dam","Tanmoy",""],["Chakraborty","Supriyo",""],["Roy","Prithwiraj",""],["Maiti","Aniruddha",""]],"versions":[{"version":"v1","created":"Tue, 20 Aug 2024 21:36:57 GMT"}],"updateDate":"2024-08-22","timestamp":1724189817000,"abstract":"  The field of autonomous vehicles (AVs) predominantly leverages multi-modal\nintegration of LiDAR and camera data to achieve better performance compared to\nusing a single modality. However, the fusion process encounters challenges in\ndetecting distant objects due to the disparity between the high resolution of\ncameras and the sparse data from LiDAR. Insufficient integration of global\nperspectives with local-level details results in sub-optimal fusion\nperformance.To address this issue, we have developed an innovative two-stage\nfusion process called Quantum Inverse Contextual Vision Transformers (Q-ICVT).\nThis approach leverages adiabatic computing in quantum concepts to create a\nnovel reversible vision transformer known as the Global Adiabatic Transformer\n(GAT). GAT aggregates sparse LiDAR features with semantic features in dense\nimages for cross-modal integration in a global form. Additionally, the Sparse\nExpert of Local Fusion (SELF) module maps the sparse LiDAR 3D proposals and\nencodes position information of the raw point cloud onto the dense camera\nfeature space using a gating point fusion approach. Our experiments show that\nQ-ICVT achieves an mAPH of 82.54 for L2 difficulties on the Waymo dataset,\nimproving by 1.88% over current state-of-the-art fusion methods. We also\nanalyze GAT and SELF in ablation studies to highlight the impact of Q-ICVT. Our\ncode is available at https://github.com/sanjay-810/Qicvt Q-ICVT\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"FD3UsUFPfTNvJLB8DZ-H9nCvK7msrNFsg6hq2nZBiaE","pdfSize":"1994903"}
