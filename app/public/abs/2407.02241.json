{"id":"2407.02241","title":"Sign Language Recognition Based On Facial Expression and Hand Skeleton","authors":"Zhiyu Long, Xingyou Liu, Jiaqi Qiao, Zhi Li","authorsParsed":[["Long","Zhiyu",""],["Liu","Xingyou",""],["Qiao","Jiaqi",""],["Li","Zhi",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 13:02:51 GMT"}],"updateDate":"2024-07-03","timestamp":1719925371000,"abstract":"  Sign language is a visual language used by the deaf and dumb community to\ncommunicate. However, for most recognition methods based on monocular cameras,\nthe recognition accuracy is low and the robustness is poor. Even if the effect\nis good on some data, it may perform poorly in other data with different\ninterference due to the inability to extract effective features. To solve these\nproblems, we propose a sign language recognition network that integrates\nskeleton features of hands and facial expression. Among this, we propose a hand\nskeleton feature extraction based on coordinate transformation to describe the\nshape of the hand more accurately. Moreover, by incorporating facial expression\ninformation, the accuracy and robustness of sign language recognition are\nfinally improved, which was verified on A Dataset for Argentinian Sign Language\nand SEU's Chinese Sign Language Recognition Database (SEUCSLRD).\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}