{"id":"2407.10483","title":"G-PCGRL: Procedural Graph Data Generation via Reinforcement Learning","authors":"Florian Rupp, Kai Eckert","authorsParsed":[["Rupp","Florian",""],["Eckert","Kai",""]],"versions":[{"version":"v1","created":"Mon, 15 Jul 2024 07:11:00 GMT"}],"updateDate":"2024-09-10","timestamp":1721027460000,"abstract":"  Graph data structures offer a versatile and powerful means to model\nrelationships and interconnections in various domains, promising substantial\nadvantages in data representation, analysis, and visualization. In games,\ngraph-based data structures are omnipresent and represent, for example, game\neconomies, skill trees or complex, branching quest lines. With this paper, we\npropose G-PCGRL, a novel and controllable method for the procedural generation\nof graph data using reinforcement learning. Therefore, we frame this problem as\nmanipulating a graph's adjacency matrix to fulfill a given set of constraints.\nOur method adapts and extends the Procedural Content Generation via\nReinforcement Learning (PCGRL) framework and introduces new representations to\nframe the problem of graph data generation as a Markov decision process. We\ncompare the performance of our method with the original PCGRL, the run time\nwith a random search and evolutionary algorithm, and evaluate G-PCGRL on two\ngraph data domains in games: game economies and skill trees. The results show\nthat our method is capable of generating graph-based content quickly and\nreliably to support and inspire designers in the game creation process. In\naddition, trained models are controllable in terms of the type and number of\nnodes to be generated.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}