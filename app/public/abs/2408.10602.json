{"id":"2408.10602","title":"MV-MOS: Multi-View Feature Fusion for 3D Moving Object Segmentation","authors":"Jintao Cheng, Xingming Chen, Jinxin Liang, Xiaoyu Tang, Xieyuanli\n  Chen, Dachuan Li","authorsParsed":[["Cheng","Jintao",""],["Chen","Xingming",""],["Liang","Jinxin",""],["Tang","Xiaoyu",""],["Chen","Xieyuanli",""],["Li","Dachuan",""]],"versions":[{"version":"v1","created":"Tue, 20 Aug 2024 07:30:00 GMT"}],"updateDate":"2024-08-21","timestamp":1724139000000,"abstract":"  Effectively summarizing dense 3D point cloud data and extracting motion\ninformation of moving objects (moving object segmentation, MOS) is crucial to\nautonomous driving and robotics applications. How to effectively utilize motion\nand semantic features and avoid information loss during 3D-to-2D projection is\nstill a key challenge. In this paper, we propose a novel multi-view MOS model\n(MV-MOS) by fusing motion-semantic features from different 2D representations\nof point clouds. To effectively exploit complementary information, the motion\nbranches of the proposed model combines motion features from both bird's eye\nview (BEV) and range view (RV) representations. In addition, a semantic branch\nis introduced to provide supplementary semantic features of moving objects.\nFinally, a Mamba module is utilized to fuse the semantic features with motion\nfeatures and provide effective guidance for the motion branches. We validated\nthe effectiveness of the proposed multi-branch fusion MOS framework via\ncomprehensive experiments, and our proposed model outperforms existing\nstate-of-the-art models on the SemanticKITTI benchmark.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}