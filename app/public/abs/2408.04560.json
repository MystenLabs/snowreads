{"id":"2408.04560","title":"Conversational Prompt Engineering","authors":"Liat Ein-Dor, Orith Toledo-Ronen, Artem Spector, Shai Gretz, Lena\n  Dankin, Alon Halfon, Yoav Katz, Noam Slonim","authorsParsed":[["Ein-Dor","Liat",""],["Toledo-Ronen","Orith",""],["Spector","Artem",""],["Gretz","Shai",""],["Dankin","Lena",""],["Halfon","Alon",""],["Katz","Yoav",""],["Slonim","Noam",""]],"versions":[{"version":"v1","created":"Thu, 8 Aug 2024 16:18:39 GMT"}],"updateDate":"2024-08-09","timestamp":1723133919000,"abstract":"  Prompts are how humans communicate with LLMs. Informative prompts are\nessential for guiding LLMs to produce the desired output. However, prompt\nengineering is often tedious and time-consuming, requiring significant\nexpertise, limiting its widespread use. We propose Conversational Prompt\nEngineering (CPE), a user-friendly tool that helps users create personalized\nprompts for their specific tasks. CPE uses a chat model to briefly interact\nwith users, helping them articulate their output preferences and integrating\nthese into the prompt. The process includes two main stages: first, the model\nuses user-provided unlabeled data to generate data-driven questions and utilize\nuser responses to shape the initial instruction. Then, the model shares the\noutputs generated by the instruction and uses user feedback to further refine\nthe instruction and the outputs. The final result is a few-shot prompt, where\nthe outputs approved by the user serve as few-shot examples. A user study on\nsummarization tasks demonstrates the value of CPE in creating personalized,\nhigh-performing prompts. The results suggest that the zero-shot prompt obtained\nis comparable to its - much longer - few-shot counterpart, indicating\nsignificant savings in scenarios involving repetitive tasks with large text\nvolumes.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/"}