{"id":"2408.09810","title":"Efficient Area-based and Speaker-Agnostic Source Separation","authors":"Martin Strauss and Okan K\\\"op\\\"ukl\\\"u","authorsParsed":[["Strauss","Martin",""],["Köpüklü","Okan",""]],"versions":[{"version":"v1","created":"Mon, 19 Aug 2024 09:02:41 GMT"}],"updateDate":"2024-08-20","timestamp":1724058161000,"abstract":"  This paper introduces an area-based source separation method designed for\nvirtual meeting scenarios. The aim is to preserve speech signals from an\nunspecified number of sources within a defined spatial area in front of a\nlinear microphone array, while suppressing all other sounds. Therefore, we\nemploy an efficient neural network architecture adapted for multi-channel input\nto encompass the predefined target area. To evaluate the approach, training\ndata and specific test scenarios including multiple target and interfering\nspeakers, as well as background noise are simulated. All models are rated\naccording to DNSMOS and scale-invariant signal-to-distortion ratio. Our\nexperiments show that the proposed method separates speech from multiple\nspeakers within the target area well, besides being of very low complexity,\nintended for real-time processing. In addition, a power reduction heatmap is\nused to demonstrate the networks' ability to identify sources located within\nthe target area. We put our approach in context with a well-established\nbaseline for speaker-speaker separation and discuss its strengths and\nchallenges.\n","subjects":["Electrical Engineering and Systems Science/Audio and Speech Processing","Computing Research Repository/Sound"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}