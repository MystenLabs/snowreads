{"id":"2408.01585","title":"OpenLogParser: Unsupervised Parsing with Open-Source Large Language\n  Models","authors":"Zeyang Ma, Dong Jae Kim, Tse-Hsun Chen","authorsParsed":[["Ma","Zeyang",""],["Kim","Dong Jae",""],["Chen","Tse-Hsun",""]],"versions":[{"version":"v1","created":"Fri, 2 Aug 2024 21:54:13 GMT"}],"updateDate":"2024-08-06","timestamp":1722635653000,"abstract":"  Log parsing is a critical step that transforms unstructured log data into\nstructured formats, facilitating subsequent log-based analysis. Traditional\nsyntax-based log parsers are efficient and effective, but they often experience\ndecreased accuracy when processing logs that deviate from the predefined rules.\nRecently, large language models (LLM) based log parsers have shown superior\nparsing accuracy. However, existing LLM-based parsers face three main\nchallenges: 1)time-consuming and labor-intensive manual labeling for\nfine-tuning or in-context learning, 2)increased parsing costs due to the vast\nvolume of log data and limited context size of LLMs, and 3)privacy risks from\nusing commercial models like ChatGPT with sensitive log information. To\novercome these limitations, this paper introduces OpenLogParser, an\nunsupervised log parsing approach that leverages open-source LLMs (i.e.,\nLlama3-8B) to enhance privacy and reduce operational costs while achieving\nstate-of-the-art parsing accuracy. OpenLogParser first groups logs with similar\nstatic text but varying dynamic variables using a fixed-depth grouping tree. It\nthen parses logs within these groups using three components: i)similarity\nscoring-based retrieval augmented generation: selects diverse logs within each\ngroup based on Jaccard similarity, helping the LLM distinguish between static\ntext and dynamic variables; ii)self-reflection: iteratively query LLMs to\nrefine log templates to improve parsing accuracy; and iii) log template memory:\nstores parsed templates to reduce LLM queries for improved parsing efficiency.\nOur evaluation on LogHub-2.0 shows that OpenLogParser achieves 25% higher\nparsing accuracy and processes logs 2.7 times faster compared to\nstate-of-the-art LLM-based parsers. In short, OpenLogParser addresses privacy\nand cost concerns of using commercial LLMs while achieving state-of-the-arts\nparsing efficiency and accuracy.\n","subjects":["Computing Research Repository/Software Engineering","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}