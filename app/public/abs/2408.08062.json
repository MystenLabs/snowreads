{"id":"2408.08062","title":"BINDy -- Bayesian identification of nonlinear dynamics with\n  reversible-jump Markov-chain Monte-Carlo","authors":"Max D. Champneys, Timothy J. Rogers","authorsParsed":[["Champneys","Max D.",""],["Rogers","Timothy J.",""]],"versions":[{"version":"v1","created":"Thu, 15 Aug 2024 10:03:30 GMT"}],"updateDate":"2024-08-16","timestamp":1723716210000,"abstract":"  Model parsimony is an important \\emph{cognitive bias} in data-driven\nmodelling that aids interpretability and helps to prevent over-fitting. Sparse\nidentification of nonlinear dynamics (SINDy) methods are able to learn sparse\nrepresentations of complex dynamics directly from data, given a basis of\nlibrary functions. In this work, a novel Bayesian treatment of dictionary\nlearning system identification, as an alternative to SINDy, is envisaged. The\nproposed method -- Bayesian identification of nonlinear dynamics (BINDy) -- is\ndistinct from previous approaches in that it targets the full joint posterior\ndistribution over both the terms in the library and their parameterisation in\nthe model. This formulation confers the advantage that an arbitrary prior may\nbe placed over the model structure to produce models that are sparse in the\nmodel space rather than in parameter space. Because this posterior is defined\nover parameter vectors that can change in dimension, the inference cannot be\nperformed by standard techniques. Instead, a Gibbs sampler based on\nreversible-jump Markov-chain Monte-Carlo is proposed. BINDy is shown to compare\nfavourably to ensemble SINDy in three benchmark case-studies. In particular, it\nis seen that the proposed method is better able to assign high probability to\ncorrect model terms.\n","subjects":["Statistics/Machine Learning","Computing Research Repository/Machine Learning","Mathematics/Dynamical Systems"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"skGFrXONRU0YOPB69hWckgPhNRUq1vEY2sBSo6Y_1wU","pdfSize":"8219719"}
