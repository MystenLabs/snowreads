{"id":"2407.12504","title":"Case2Code: Learning Inductive Reasoning with Synthetic Data","authors":"Yunfan Shao, Linyang Li, Yichuan Ma, Peiji Li, Demin Song, Qinyuan\n  Cheng, Shimin Li, Xiaonan Li, Pengyu Wang, Qipeng Guo, Hang Yan, Xipeng Qiu,\n  Xuanjing Huang, Dahua Lin","authorsParsed":[["Shao","Yunfan",""],["Li","Linyang",""],["Ma","Yichuan",""],["Li","Peiji",""],["Song","Demin",""],["Cheng","Qinyuan",""],["Li","Shimin",""],["Li","Xiaonan",""],["Wang","Pengyu",""],["Guo","Qipeng",""],["Yan","Hang",""],["Qiu","Xipeng",""],["Huang","Xuanjing",""],["Lin","Dahua",""]],"versions":[{"version":"v1","created":"Wed, 17 Jul 2024 11:35:00 GMT"}],"updateDate":"2024-07-18","timestamp":1721216100000,"abstract":"  Complex reasoning is an impressive ability shown by large language models\n(LLMs). Most LLMs are skilled in deductive reasoning, such as chain-of-thought\nprompting or iterative tool-using to solve challenging tasks step-by-step. In\nthis paper, we hope to focus on evaluating and teaching LLMs to conduct\ninductive reasoning, that is, LLMs are supposed to infer underlying rules by\nobserving examples or sequential transformations. However, collecting\nlarge-scale and diverse human-generated inductive data is challenging. We focus\non data synthesis in the code domain and propose a \\textbf{Case2Code} task by\nexploiting the expressiveness and correctness of programs. Specifically, we\ncollect a diverse set of executable programs, synthesize input-output\ntransformations for each program, and force LLMs to infer the underlying code\nimplementations based on the synthetic I/O cases. We first evaluate\nrepresentative LLMs on the synthesized Case2Code task and demonstrate that the\nCase-to-code induction is challenging for LLMs. Then, we synthesize large-scale\nCase2Code training samples to train LLMs to perform inductive reasoning.\nExperimental results show that such induction training benefits not only in\ndistribution Case2Code performance but also enhances various coding abilities\nof trained LLMs, demonstrating the great potential of learning inductive\nreasoning via synthetic data.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}