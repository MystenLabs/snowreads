{"id":"2408.15915","title":"Leveraging Open Knowledge for Advancing Task Expertise in Large Language\n  Models","authors":"Yuncheng Yang, Yulei Qin, Tong Wu, Zihan Xu, Gang Li, Pengcheng Guo,\n  Hang Shao, Yuchen Shi, Ke Li, Xing Sun, Jie Yang, Yun Gu","authorsParsed":[["Yang","Yuncheng",""],["Qin","Yulei",""],["Wu","Tong",""],["Xu","Zihan",""],["Li","Gang",""],["Guo","Pengcheng",""],["Shao","Hang",""],["Shi","Yuchen",""],["Li","Ke",""],["Sun","Xing",""],["Yang","Jie",""],["Gu","Yun",""]],"versions":[{"version":"v1","created":"Wed, 28 Aug 2024 16:28:07 GMT"},{"version":"v2","created":"Sat, 7 Sep 2024 15:12:51 GMT"}],"updateDate":"2024-09-10","timestamp":1724862487000,"abstract":"  The cultivation of expertise for large language models (LLMs) to solve tasks\nof specific areas often requires special-purpose tuning with calibrated\nbehaviors on the expected stable outputs. To avoid huge cost brought by manual\npreparation of instruction datasets and training resources up to hundreds of\nhours, the exploitation of open knowledge including a wealth of low rank\nadaptation (LoRA) models and instruction datasets serves as a good starting\npoint. However, existing methods on model and data selection focus on the\nperformance of general-purpose capabilities while neglecting the knowledge gap\nexposed in domain-specific deployment. In the present study, we propose to\nbridge such gap by introducing few human-annotated samples (i.e., K-shot) for\nadvancing task expertise of LLMs with open knowledge. Specifically, we develop\nan efficient and scalable pipeline to cost-efficiently produce task experts\nwhere K-shot data intervene in selecting the most promising expert candidates\nand the task-relevant instructions. A mixture-of-expert (MoE) system is built\nto make the best use of individual-yet-complementary knowledge between multiple\nexperts. We unveil the two keys to the success of a MoE system, 1) the abidance\nby K-shot, and 2) the insistence on diversity. For the former, we ensure that\nmodels that truly possess problem-solving abilities on K-shot are selected\nrather than those blind guessers. Besides, during data selection, instructions\nthat share task-relevant contexts with K-shot are prioritized. For the latter,\nwe highlight the diversity of constituting experts and that of the fine-tuning\ninstructions throughout the model and data selection process. Extensive\nexperimental results confirm the superiority of our approach over existing\nmethods on utilization of open knowledge across various tasks. Our codes will\nbe available at https://github.com/Yaphabates/Rocket.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"OWMiO5JY_o365Oye1ekE8rkUTAlfFXjDCmr_FfIAZ1A","pdfSize":"3999854"}
