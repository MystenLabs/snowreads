{"id":"2407.00301","title":"Benchmark Evaluation of Image Fusion algorithms for Smartphone Camera\n  Capture","authors":"Lucas N. Kirsten","authorsParsed":[["Kirsten","Lucas N.",""]],"versions":[{"version":"v1","created":"Sat, 29 Jun 2024 03:47:54 GMT"}],"updateDate":"2024-07-02","timestamp":1719632874000,"abstract":"  This paper investigates the trade-off between computational resource\nutilization and image quality in the context of image fusion techniques for\nsmartphone camera capture. The study explores various combinations of fusion\nmethods, fusion weights, number of frames, and stacking (a.k.a. merging)\ntechniques using a proprietary dataset of images captured with Motorola\nsmartphones. The objective was to identify optimal configurations that balance\ncomputational efficiency with image quality. Our results indicate that\nmulti-scale methods and their single-scale fusion counterparts return similar\nimage quality measures and runtime, but single-scale ones have lower memory\nusage. Furthermore, we identified that fusion methods operating in the YUV\ncolor space yield better performance in terms of image quality, resource\nutilization, and runtime. The study also shows that fusion weights have an\noverall small impact on image quality, runtime, and memory. Moreover, our\nresults reveal that increasing the number of highly exposed input frames does\nnot necessarily improve image quality and comes with a corresponding increase\nin computational resources usage and runtime; and that stacking methods,\nalthough reducing memory usage, may compromise image quality. Finally, our work\nunderscores the importance of thoughtful configuration selection for image\nfusion techniques in constrained environments and offers insights for future\nimage fusion method development, particularly in the realm of smartphone\napplications.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/"}