{"id":"2407.19746","title":"Octave-YOLO: Cross frequency detection network with octave convolution","authors":"Sangjune Shin, Dongkun Shin","authorsParsed":[["Shin","Sangjune",""],["Shin","Dongkun",""]],"versions":[{"version":"v1","created":"Mon, 29 Jul 2024 07:18:11 GMT"}],"updateDate":"2024-07-30","timestamp":1722237491000,"abstract":"  Despite the rapid advancement of object detection algorithms, processing\nhigh-resolution images on embedded devices remains a significant challenge.\nTheoretically, the fully convolutional network architecture used in current\nreal-time object detectors can handle all input resolutions. However, the\nsubstantial computational demands required to process high-resolution images\nrender them impractical for real-time applications. To address this issue,\nreal-time object detection models typically downsample the input image for\ninference, leading to a loss of detail and decreased accuracy. In response, we\ndeveloped Octave-YOLO, designed to process high-resolution images in real-time\nwithin the constraints of embedded systems. We achieved this through the\nintroduction of the cross frequency partial network (CFPNet), which divides the\ninput feature map into low-resolution, low-frequency, and high-resolution,\nhigh-frequency sections. This configuration enables complex operations such as\nconvolution bottlenecks and self-attention to be conducted exclusively on\nlow-resolution feature maps while simultaneously preserving the details in\nhigh-resolution maps. Notably, this approach not only dramatically reduces the\ncomputational demands of convolution tasks but also allows for the integration\nof attention modules, which are typically challenging to implement in real-time\napplications, with minimal additional cost. Additionally, we have incorporated\ndepthwise separable convolution into the core building blocks and downsampling\nlayers to further decrease latency. Experimental results have shown that\nOctave-YOLO matches the performance of YOLOv8 while significantly reducing\ncomputational demands. For example, in 1080x1080 resolution, Octave-YOLO-N is\n1.56 times faster than YOLOv8, achieving nearly the same accuracy on the COCO\ndataset with approximately 40 percent fewer parameters and FLOPs.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"dopVyogYOpmQ3FjcC2I56uOuL2i3z3Kj8lYwp60L6qo","pdfSize":"1778517"}
