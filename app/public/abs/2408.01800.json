{"id":"2408.01800","title":"MiniCPM-V: A GPT-4V Level MLLM on Your Phone","authors":"Yuan Yao, Tianyu Yu, Ao Zhang, Chongyi Wang, Junbo Cui, Hongji Zhu,\n  Tianchi Cai, Haoyu Li, Weilin Zhao, Zhihui He, Qianyu Chen, Huarong Zhou,\n  Zhensheng Zou, Haoye Zhang, Shengding Hu, Zhi Zheng, Jie Zhou, Jie Cai, Xu\n  Han, Guoyang Zeng, Dahai Li, Zhiyuan Liu, Maosong Sun","authorsParsed":[["Yao","Yuan",""],["Yu","Tianyu",""],["Zhang","Ao",""],["Wang","Chongyi",""],["Cui","Junbo",""],["Zhu","Hongji",""],["Cai","Tianchi",""],["Li","Haoyu",""],["Zhao","Weilin",""],["He","Zhihui",""],["Chen","Qianyu",""],["Zhou","Huarong",""],["Zou","Zhensheng",""],["Zhang","Haoye",""],["Hu","Shengding",""],["Zheng","Zhi",""],["Zhou","Jie",""],["Cai","Jie",""],["Han","Xu",""],["Zeng","Guoyang",""],["Li","Dahai",""],["Liu","Zhiyuan",""],["Sun","Maosong",""]],"versions":[{"version":"v1","created":"Sat, 3 Aug 2024 15:02:21 GMT"}],"updateDate":"2024-08-06","timestamp":1722697341000,"abstract":"  The recent surge of Multimodal Large Language Models (MLLMs) has\nfundamentally reshaped the landscape of AI research and industry, shedding\nlight on a promising path toward the next AI milestone. However, significant\nchallenges remain preventing MLLMs from being practical in real-world\napplications. The most notable challenge comes from the huge cost of running an\nMLLM with a massive number of parameters and extensive computation. As a\nresult, most MLLMs need to be deployed on high-performing cloud servers, which\ngreatly limits their application scopes such as mobile, offline,\nenergy-sensitive, and privacy-protective scenarios. In this work, we present\nMiniCPM-V, a series of efficient MLLMs deployable on end-side devices. By\nintegrating the latest MLLM techniques in architecture, pretraining and\nalignment, the latest MiniCPM-Llama3-V 2.5 has several notable features: (1)\nStrong performance, outperforming GPT-4V-1106, Gemini Pro and Claude 3 on\nOpenCompass, a comprehensive evaluation over 11 popular benchmarks, (2) strong\nOCR capability and 1.8M pixel high-resolution image perception at any aspect\nratio, (3) trustworthy behavior with low hallucination rates, (4) multilingual\nsupport for 30+ languages, and (5) efficient deployment on mobile phones. More\nimportantly, MiniCPM-V can be viewed as a representative example of a promising\ntrend: The model sizes for achieving usable (e.g., GPT-4V) level performance\nare rapidly decreasing, along with the fast growth of end-side computation\ncapacity. This jointly shows that GPT-4V level MLLMs deployed on end devices\nare becoming increasingly possible, unlocking a wider spectrum of real-world AI\napplications in the near future.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"gOZJdXnu5ifmZZUN6y8w-zPJ6QO6us5rC4MMxHrJqO0","pdfSize":"11258737"}
