{"id":"2408.14319","title":"Rethinking Knowledge Transfer in Learning Using Privileged Information","authors":"Danil Provodin, Bram van den Akker, Christina Katsimerou, Maurits\n  Kaptein, Mykola Pechenizkiy","authorsParsed":[["Provodin","Danil",""],["Akker","Bram van den",""],["Katsimerou","Christina",""],["Kaptein","Maurits",""],["Pechenizkiy","Mykola",""]],"versions":[{"version":"v1","created":"Mon, 26 Aug 2024 14:51:26 GMT"}],"updateDate":"2024-08-28","timestamp":1724683886000,"abstract":"  In supervised machine learning, privileged information (PI) is information\nthat is unavailable at inference, but is accessible during training time.\nResearch on learning using privileged information (LUPI) aims to transfer the\nknowledge captured in PI onto a model that can perform inference without PI. It\nseems that this extra bit of information ought to make the resulting model\nbetter. However, finding conclusive theoretical or empirical evidence that\nsupports the ability to transfer knowledge using PI has been challenging. In\nthis paper, we critically examine the assumptions underlying existing\ntheoretical analyses and argue that there is little theoretical justification\nfor when LUPI should work. We analyze LUPI methods and reveal that apparent\nimprovements in empirical risk of existing research may not directly result\nfrom PI. Instead, these improvements often stem from dataset anomalies or\nmodifications in model design misguidedly attributed to PI. Our experiments for\na wide variety of application domains further demonstrate that state-of-the-art\nLUPI approaches fail to effectively transfer knowledge from PI. Thus, we\nadvocate for practitioners to exercise caution when working with PI to avoid\nunintended inductive biases.\n","subjects":["Computing Research Repository/Machine Learning","Statistics/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}