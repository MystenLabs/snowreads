{"id":"2408.00376","title":"On the Limitations and Prospects of Machine Unlearning for Generative AI","authors":"Shiji Zhou, Lianzhe Wang, Jiangnan Ye, Yongliang Wu, Heng Chang","authorsParsed":[["Zhou","Shiji",""],["Wang","Lianzhe",""],["Ye","Jiangnan",""],["Wu","Yongliang",""],["Chang","Heng",""]],"versions":[{"version":"v1","created":"Thu, 1 Aug 2024 08:35:40 GMT"}],"updateDate":"2024-08-02","timestamp":1722501340000,"abstract":"  Generative AI (GenAI), which aims to synthesize realistic and diverse data\nsamples from latent variables or other data modalities, has achieved remarkable\nresults in various domains, such as natural language, images, audio, and\ngraphs. However, they also pose challenges and risks to data privacy, security,\nand ethics. Machine unlearning is the process of removing or weakening the\ninfluence of specific data samples or features from a trained model, without\naffecting its performance on other data or tasks. While machine unlearning has\nshown significant efficacy in traditional machine learning tasks, it is still\nunclear if it could help GenAI become safer and aligned with human desire. To\nthis end, this position paper provides an in-depth discussion of the machine\nunlearning approaches for GenAI. Firstly, we formulate the problem of machine\nunlearning tasks on GenAI and introduce the background. Subsequently, we\nsystematically examine the limitations of machine unlearning on GenAI models by\nfocusing on the two representative branches: LLMs and image generative\n(diffusion) models. Finally, we provide our prospects mainly from three\naspects: benchmark, evaluation metrics, and utility-unlearning trade-off, and\nconscientiously advocate for the future development of this field.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}