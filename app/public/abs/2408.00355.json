{"id":"2408.00355","title":"DNTextSpotter: Arbitrary-Shaped Scene Text Spotting via Improved\n  Denoising Training","authors":"Yu Xie, Qian Qiao, Jun Gao, Tianxiang Wu, Shaoyao Huang, Jiaqing Fan,\n  Ziqiang Cao, Zili Wang, Yue Zhang, Jielei Zhang, Huyang Sun","authorsParsed":[["Xie","Yu",""],["Qiao","Qian",""],["Gao","Jun",""],["Wu","Tianxiang",""],["Huang","Shaoyao",""],["Fan","Jiaqing",""],["Cao","Ziqiang",""],["Wang","Zili",""],["Zhang","Yue",""],["Zhang","Jielei",""],["Sun","Huyang",""]],"versions":[{"version":"v1","created":"Thu, 1 Aug 2024 07:52:07 GMT"}],"updateDate":"2024-08-02","timestamp":1722498727000,"abstract":"  More and more end-to-end text spotting methods based on Transformer\narchitecture have demonstrated superior performance. These methods utilize a\nbipartite graph matching algorithm to perform one-to-one optimal matching\nbetween predicted objects and actual objects. However, the instability of\nbipartite graph matching can lead to inconsistent optimization targets, thereby\naffecting the training performance of the model. Existing literature applies\ndenoising training to solve the problem of bipartite graph matching instability\nin object detection tasks. Unfortunately, this denoising training method cannot\nbe directly applied to text spotting tasks, as these tasks need to perform\nirregular shape detection tasks and more complex text recognition tasks than\nclassification. To address this issue, we propose a novel denoising training\nmethod (DNTextSpotter) for arbitrary-shaped text spotting. Specifically, we\ndecompose the queries of the denoising part into noised positional queries and\nnoised content queries. We use the four Bezier control points of the Bezier\ncenter curve to generate the noised positional queries. For the noised content\nqueries, considering that the output of the text in a fixed positional order is\nnot conducive to aligning position with content, we employ a masked character\nsliding method to initialize noised content queries, thereby assisting in the\nalignment of text content and position. To improve the model's perception of\nthe background, we further utilize an additional loss function for background\ncharacters classification in the denoising training part.Although DNTextSpotter\nis conceptually simple, it outperforms the state-of-the-art methods on four\nbenchmarks (Total-Text, SCUT-CTW1500, ICDAR15, and Inverse-Text), especially\nyielding an improvement of 11.3% against the best approach in Inverse-Text\ndataset.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"kxrmmykV3YpbVwEDAVqy9dkitFD6LJF23jRJRRDpUbo","pdfSize":"10767152"}
