{"id":"2407.07532","title":"Neural Localizer Fields for Continuous 3D Human Pose and Shape\n  Estimation","authors":"Istv\\'an S\\'ar\\'andi, Gerard Pons-Moll","authorsParsed":[["Sárándi","István",""],["Pons-Moll","Gerard",""]],"versions":[{"version":"v1","created":"Wed, 10 Jul 2024 10:44:18 GMT"}],"updateDate":"2024-07-11","timestamp":1720608258000,"abstract":"  With the explosive growth of available training data, single-image 3D human\nmodeling is ahead of a transition to a data-centric paradigm. A key to\nsuccessfully exploiting data scale is to design flexible models that can be\nsupervised from various heterogeneous data sources produced by different\nresearchers or vendors. To this end, we propose a simple yet powerful paradigm\nfor seamlessly unifying different human pose and shape-related tasks and\ndatasets. Our formulation is centered on the ability - both at training and\ntest time - to query any arbitrary point of the human volume, and obtain its\nestimated location in 3D. We achieve this by learning a continuous neural field\nof body point localizer functions, each of which is a differently parameterized\n3D heatmap-based convolutional point localizer (detector). For generating\nparametric output, we propose an efficient post-processing step for fitting\nSMPL-family body models to nonparametric joint and vertex predictions. With\nthis approach, we can naturally exploit differently annotated data sources\nincluding mesh, 2D/3D skeleton and dense pose, without having to convert\nbetween them, and thereby train large-scale 3D human mesh and skeleton\nestimation models that outperform the state-of-the-art on several public\nbenchmarks including 3DPW, EMDB and SSP-3D by a considerable margin.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}