{"id":"2407.18062","title":"Audio Entailment: Assessing Deductive Reasoning for Audio Understanding","authors":"Soham Deshmukh, Shuo Han, Hazim Bukhari, Benjamin Elizalde, Hannes\n  Gamper, Rita Singh, Bhiksha Raj","authorsParsed":[["Deshmukh","Soham",""],["Han","Shuo",""],["Bukhari","Hazim",""],["Elizalde","Benjamin",""],["Gamper","Hannes",""],["Singh","Rita",""],["Raj","Bhiksha",""]],"versions":[{"version":"v1","created":"Thu, 25 Jul 2024 14:17:56 GMT"}],"updateDate":"2024-07-26","timestamp":1721917076000,"abstract":"  Recent literature uses language to build foundation models for audio. These\nAudio-Language Models (ALMs) are trained on a vast number of audio-text pairs\nand show remarkable performance in tasks including Text-to-Audio Retrieval,\nCaptioning, and Question Answering. However, their ability to engage in more\ncomplex open-ended tasks, like Interactive Question-Answering, requires\nproficiency in logical reasoning -- a skill not yet benchmarked. We introduce\nthe novel task of Audio Entailment to evaluate an ALM's deductive reasoning\nability. This task assesses whether a text description (hypothesis) of audio\ncontent can be deduced from an audio recording (premise), with potential\nconclusions being entailment, neutral, or contradiction, depending on the\nsufficiency of the evidence. We create two datasets for this task with audio\nrecordings sourced from two audio captioning datasets -- AudioCaps and Clotho\n-- and hypotheses generated using Large Language Models (LLMs). We benchmark\nstate-of-the-art ALMs and find deficiencies in logical reasoning with both\nzero-shot and linear probe evaluations. Finally, we propose\n\"caption-before-reason\", an intermediate step of captioning that improves the\nzero-shot and linear-probe performance of ALMs by an absolute 6% and 3%,\nrespectively.\n","subjects":["Computing Research Repository/Sound","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by/4.0/"}