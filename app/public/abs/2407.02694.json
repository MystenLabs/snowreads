{"id":"2407.02694","title":"LLM-Select: Feature Selection with Large Language Models","authors":"Daniel P. Jeong, Zachary C. Lipton, Pradeep Ravikumar","authorsParsed":[["Jeong","Daniel P.",""],["Lipton","Zachary C.",""],["Ravikumar","Pradeep",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 22:23:40 GMT"}],"updateDate":"2024-07-04","timestamp":1719959020000,"abstract":"  In this paper, we demonstrate a surprising capability of large language\nmodels (LLMs): given only input feature names and a description of a prediction\ntask, they are capable of selecting the most predictive features, with\nperformance rivaling the standard tools of data science. Remarkably, these\nmodels exhibit this capacity across various query mechanisms. For example, we\nzero-shot prompt an LLM to output a numerical importance score for a feature\n(e.g., \"blood pressure\") in predicting an outcome of interest (e.g., \"heart\nfailure\"), with no additional context. In particular, we find that the latest\nmodels, such as GPT-4, can consistently identify the most predictive features\nregardless of the query mechanism and across various prompting strategies. We\nillustrate these findings through extensive experiments on real-world data,\nwhere we show that LLM-based feature selection consistently achieves strong\nperformance competitive with data-driven methods such as the LASSO, despite\nnever having looked at the downstream training data. Our findings suggest that\nLLMs may be useful not only for selecting the best features for training but\nalso for deciding which features to collect in the first place. This could\npotentially benefit practitioners in domains like healthcare, where collecting\nhigh-quality data comes at a high cost.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language","Statistics/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}