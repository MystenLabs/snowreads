{"id":"2408.09064","title":"MoRA: LoRA Guided Multi-Modal Disease Diagnosis with Missing Modality","authors":"Zhiyi Shi, Junsik Kim, Wanhua Li, Yicong Li, Hanspeter Pfister","authorsParsed":[["Shi","Zhiyi",""],["Kim","Junsik",""],["Li","Wanhua",""],["Li","Yicong",""],["Pfister","Hanspeter",""]],"versions":[{"version":"v1","created":"Sat, 17 Aug 2024 01:40:00 GMT"}],"updateDate":"2024-08-20","timestamp":1723858800000,"abstract":"  Multi-modal pre-trained models efficiently extract and fuse features from\ndifferent modalities with low memory requirements for fine-tuning. Despite this\nefficiency, their application in disease diagnosis is under-explored. A\nsignificant challenge is the frequent occurrence of missing modalities, which\nimpairs performance. Additionally, fine-tuning the entire pre-trained model\ndemands substantial computational resources. To address these issues, we\nintroduce Modality-aware Low-Rank Adaptation (MoRA), a computationally\nefficient method. MoRA projects each input to a low intrinsic dimension but\nuses different modality-aware up-projections for modality-specific adaptation\nin cases of missing modalities. Practically, MoRA integrates into the first\nblock of the model, significantly improving performance when a modality is\nmissing. It requires minimal computational resources, with less than 1.6% of\nthe trainable parameters needed compared to training the entire model.\nExperimental results show that MoRA outperforms existing techniques in disease\ndiagnosis, demonstrating superior performance, robustness, and training\nefficiency.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}