{"id":"2407.09887","title":"Benchmarking LLMs for Optimization Modeling and Enhancing Reasoning via\n  Reverse Socratic Synthesis","authors":"Zhicheng Yang, Yinya Huang, Wei Shi, Liang Feng, Linqi Song, Yiwei\n  Wang, Xiaodan Liang, Jing Tang","authorsParsed":[["Yang","Zhicheng",""],["Huang","Yinya",""],["Shi","Wei",""],["Feng","Liang",""],["Song","Linqi",""],["Wang","Yiwei",""],["Liang","Xiaodan",""],["Tang","Jing",""]],"versions":[{"version":"v1","created":"Sat, 13 Jul 2024 13:27:57 GMT"}],"updateDate":"2024-07-16","timestamp":1720877277000,"abstract":"  Large language models (LLMs) have exhibited their problem-solving ability in\nmathematical reasoning. Solving realistic optimization (OPT) problems in\nindustrial application scenarios requires advanced and applied math ability.\nHowever, current OPT benchmarks that merely solve linear programming are far\nfrom complex realistic situations. In this work, we propose E-OPT, a benchmark\nfor end-to-end optimization problem-solving with human-readable inputs and\noutputs. E-OPT contains rich optimization problems, including linear/nonlinear\nprogramming with/without table data, which can comprehensively evaluate LLMs'\nsolving ability. In our benchmark, LLMs are required to correctly understand\nthe problem in E-OPT and call code solver to get precise numerical answers.\nFurthermore, to alleviate the data scarcity for optimization problems, and to\nbridge the gap between open-source LLMs on a small scale (e.g., Llama-2-7b and\nLlama-3-8b) and closed-source LLMs (e.g., GPT-4), we further propose a novel\ndata synthesis method namely ReSocratic. Unlike general data synthesis methods\nthat proceed from questions to answers, ReSocratic first incrementally\nsynthesizes optimization scenarios with mathematical formulations step by step\nand then back-translates the generated scenarios into questions. In such a way,\nwe construct the ReSocratic-29k dataset from a small seed sample pool with the\npowerful open-source large model DeepSeek-V2. To demonstrate the effectiveness\nof ReSocratic, we conduct supervised fine-tuning with ReSocratic-29k on\nmultiple open-source models. The results show that Llama3-8b is significantly\nimproved from 13.6% to 51.7% on E-OPT, while DeepSeek-V2 reaches 61.0%,\napproaching 65.5% of GPT-4.\n","subjects":["Computing Research Repository/Machine Learning","Mathematics/Optimization and Control"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/"}