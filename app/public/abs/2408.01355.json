{"id":"2408.01355","title":"Hallu-PI: Evaluating Hallucination in Multi-modal Large Language Models\n  within Perturbed Inputs","authors":"Peng Ding, Jingyu Wu, Jun Kuang, Dan Ma, Xuezhi Cao, Xunliang Cai, Shi\n  Chen, Jiajun Chen, Shujian Huang","authorsParsed":[["Ding","Peng",""],["Wu","Jingyu",""],["Kuang","Jun",""],["Ma","Dan",""],["Cao","Xuezhi",""],["Cai","Xunliang",""],["Chen","Shi",""],["Chen","Jiajun",""],["Huang","Shujian",""]],"versions":[{"version":"v1","created":"Fri, 2 Aug 2024 16:07:15 GMT"},{"version":"v2","created":"Mon, 5 Aug 2024 02:14:54 GMT"}],"updateDate":"2024-08-06","timestamp":1722614835000,"abstract":"  Multi-modal Large Language Models (MLLMs) have demonstrated remarkable\nperformance on various visual-language understanding and generation tasks.\nHowever, MLLMs occasionally generate content inconsistent with the given\nimages, which is known as \"hallucination\". Prior works primarily center on\nevaluating hallucination using standard, unperturbed benchmarks, which overlook\nthe prevalent occurrence of perturbed inputs in real-world scenarios-such as\nimage cropping or blurring-that are critical for a comprehensive assessment of\nMLLMs' hallucination. In this paper, to bridge this gap, we propose Hallu-PI,\nthe first benchmark designed to evaluate Hallucination in MLLMs within\nPerturbed Inputs. Specifically, Hallu-PI consists of seven perturbed scenarios,\ncontaining 1,260 perturbed images from 11 object types. Each image is\naccompanied by detailed annotations, which include fine-grained hallucination\ntypes, such as existence, attribute, and relation. We equip these annotations\nwith a rich set of questions, making Hallu-PI suitable for both discriminative\nand generative tasks. Extensive experiments on 12 mainstream MLLMs, such as\nGPT-4V and Gemini-Pro Vision, demonstrate that these models exhibit significant\nhallucinations on Hallu-PI, which is not observed in unperturbed scenarios.\nFurthermore, our research reveals a severe bias in MLLMs' ability to handle\ndifferent types of hallucinations. We also design two baselines specifically\nfor perturbed scenarios, namely Perturbed-Reminder and Perturbed-ICL. We hope\nthat our study will bring researchers' attention to the limitations of MLLMs\nwhen dealing with perturbed inputs, and spur further investigations to address\nthis issue. Our code and datasets are publicly available at\nhttps://github.com/NJUNLP/Hallu-PI.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Multimedia"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"xHGBv6-9cOqa4JmhL-smELk_wkLjeDJkrJw51bI6V1g","pdfSize":"5557623","txDigest":"3DerGKPNqjoZDa6DyyyL9QpXK3QEs4HSBepmWgU6iqxP","endEpoch":"1","status":"CERTIFIED"}
