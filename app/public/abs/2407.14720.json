{"id":"2407.14720","title":"Downstream-Pretext Domain Knowledge Traceback for Active Learning","authors":"Beichen Zhang, Liang Li, Zheng-Jun Zha, Jiebo Luo, Qingming Huang","authorsParsed":[["Zhang","Beichen",""],["Li","Liang",""],["Zha","Zheng-Jun",""],["Luo","Jiebo",""],["Huang","Qingming",""]],"versions":[{"version":"v1","created":"Sat, 20 Jul 2024 01:34:13 GMT"}],"updateDate":"2024-07-23","timestamp":1721439253000,"abstract":"  Active learning (AL) is designed to construct a high-quality labeled dataset\nby iteratively selecting the most informative samples. Such sampling heavily\nrelies on data representation, while recently pre-training is popular for\nrobust feature learning. However, as pre-training utilizes low-level pretext\ntasks that lack annotation, directly using pre-trained representation in AL is\ninadequate for determining the sampling score. To address this problem, we\npropose a downstream-pretext domain knowledge traceback (DOKT) method that\ntraces the data interactions of downstream knowledge and pre-training guidance\nfor selecting diverse and instructive samples near the decision boundary. DOKT\nconsists of a traceback diversity indicator and a domain-based uncertainty\nestimator. The diversity indicator constructs two feature spaces based on the\npre-training pretext model and the downstream knowledge from annotation, by\nwhich it locates the neighbors of unlabeled data from the downstream space in\nthe pretext space to explore the interaction of samples. With this mechanism,\nDOKT unifies the data relations of low-level and high-level representations to\nestimate traceback diversity. Next, in the uncertainty estimator, domain mixing\nis designed to enforce perceptual perturbing to unlabeled samples with similar\nvisual patches in the pretext space. Then the divergence of perturbed samples\nis measured to estimate the domain uncertainty. As a result, DOKT selects the\nmost diverse and important samples based on these two modules. The experiments\nconducted on ten datasets show that our model outperforms other\nstate-of-the-art methods and generalizes well to various application scenarios\nsuch as semantic segmentation and image captioning.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}