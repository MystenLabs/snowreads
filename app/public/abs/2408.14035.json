{"id":"2408.14035","title":"FAST-LIVO2: Fast, Direct LiDAR-Inertial-Visual Odometry","authors":"Chunran Zheng, Wei Xu, Zuhao Zou, Tong Hua, Chongjian Yuan, Dongjiao\n  He, Bingyang Zhou, Zheng Liu, Jiarong Lin, Fangcheng Zhu, Yunfan Ren, Rong\n  Wang, Fanle Meng, Fu Zhang","authorsParsed":[["Zheng","Chunran",""],["Xu","Wei",""],["Zou","Zuhao",""],["Hua","Tong",""],["Yuan","Chongjian",""],["He","Dongjiao",""],["Zhou","Bingyang",""],["Liu","Zheng",""],["Lin","Jiarong",""],["Zhu","Fangcheng",""],["Ren","Yunfan",""],["Wang","Rong",""],["Meng","Fanle",""],["Zhang","Fu",""]],"versions":[{"version":"v1","created":"Mon, 26 Aug 2024 06:01:54 GMT"},{"version":"v2","created":"Wed, 28 Aug 2024 12:03:50 GMT"}],"updateDate":"2024-08-29","timestamp":1724652114000,"abstract":"  This paper proposes FAST-LIVO2: a fast, direct LiDAR-inertial-visual odometry\nframework to achieve accurate and robust state estimation in SLAM tasks and\nprovide great potential in real-time, onboard robotic applications. FAST-LIVO2\nfuses the IMU, LiDAR and image measurements efficiently through an ESIKF. To\naddress the dimension mismatch between the heterogeneous LiDAR and image\nmeasurements, we use a sequential update strategy in the Kalman filter. To\nenhance the efficiency, we use direct methods for both the visual and LiDAR\nfusion, where the LiDAR module registers raw points without extracting edge or\nplane features and the visual module minimizes direct photometric errors\nwithout extracting ORB or FAST corner features. The fusion of both visual and\nLiDAR measurements is based on a single unified voxel map where the LiDAR\nmodule constructs the geometric structure for registering new LiDAR scans and\nthe visual module attaches image patches to the LiDAR points. To enhance the\naccuracy of image alignment, we use plane priors from the LiDAR points in the\nvoxel map (and even refine the plane prior) and update the reference patch\ndynamically after new images are aligned. Furthermore, to enhance the\nrobustness of image alignment, FAST-LIVO2 employs an on-demanding raycast\noperation and estimates the image exposure time in real time. Lastly, we detail\nthree applications of FAST-LIVO2: UAV onboard navigation demonstrating the\nsystem's computation efficiency for real-time onboard navigation, airborne\nmapping showcasing the system's mapping accuracy, and 3D model rendering\n(mesh-based and NeRF-based) underscoring the suitability of our reconstructed\ndense map for subsequent rendering tasks. We open source our code, dataset and\napplication on GitHub to benefit the robotics community.\n","subjects":["Computing Research Repository/Robotics","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}