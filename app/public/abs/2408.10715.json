{"id":"2408.10715","title":"Fine-Tuning a Local LLaMA-3 Large Language Model for Automated\n  Privacy-Preserving Physician Letter Generation in Radiation Oncology","authors":"Yihao Hou, Christoph Bert, Ahmed Gomaa, Godehard Lahmer, Daniel\n  Hoefler, Thomas Weissmann, Raphaela Voigt, Philipp Schubert, Charlotte\n  Schmitter, Alina Depardon, Sabine Semrau, Andreas Maier, Rainer Fietkau,\n  Yixing Huang, Florian Putz","authorsParsed":[["Hou","Yihao",""],["Bert","Christoph",""],["Gomaa","Ahmed",""],["Lahmer","Godehard",""],["Hoefler","Daniel",""],["Weissmann","Thomas",""],["Voigt","Raphaela",""],["Schubert","Philipp",""],["Schmitter","Charlotte",""],["Depardon","Alina",""],["Semrau","Sabine",""],["Maier","Andreas",""],["Fietkau","Rainer",""],["Huang","Yixing",""],["Putz","Florian",""]],"versions":[{"version":"v1","created":"Tue, 20 Aug 2024 10:31:36 GMT"}],"updateDate":"2024-08-21","timestamp":1724149896000,"abstract":"  Generating physician letters is a time-consuming task in daily clinical\npractice. This study investigates local fine-tuning of large language models\n(LLMs), specifically LLaMA models, for physician letter generation in a\nprivacy-preserving manner within the field of radiation oncology. Our findings\ndemonstrate that base LLaMA models, without fine-tuning, are inadequate for\neffectively generating physician letters. The QLoRA algorithm provides an\nefficient method for local intra-institutional fine-tuning of LLMs with limited\ncomputational resources (i.e., a single 48 GB GPU workstation within the\nhospital). The fine-tuned LLM successfully learns radiation oncology-specific\ninformation and generates physician letters in an institution-specific style.\nROUGE scores of the generated summary reports highlight the superiority of the\n8B LLaMA-3 model over the 13B LLaMA-2 model. Further multidimensional physician\nevaluations of 10 cases reveal that, although the fine-tuned LLaMA-3 model has\nlimited capacity to generate content beyond the provided input data, it\nsuccessfully generates salutations, diagnoses and treatment histories,\nrecommendations for further treatment, and planned schedules. Overall, clinical\nbenefit was rated highly by the clinical experts (average score of 3.44 on a\n4-point scale). With careful physician review and correction, automated\nLLM-based physician letter generation has significant practical value.\n","subjects":["Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}