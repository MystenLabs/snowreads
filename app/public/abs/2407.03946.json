{"id":"2407.03946","title":"TrackPGD: A White-box Attack using Binary Masks against Robust\n  Transformer Trackers","authors":"Fatemeh Nourilenjan Nokabadi, Yann Batiste Pequignot, Jean-Francois\n  Lalonde, Christian Gagn\\'e","authorsParsed":[["Nokabadi","Fatemeh Nourilenjan",""],["Pequignot","Yann Batiste",""],["Lalonde","Jean-Francois",""],["Gagn√©","Christian",""]],"versions":[{"version":"v1","created":"Thu, 4 Jul 2024 14:02:12 GMT"}],"updateDate":"2024-07-08","timestamp":1720101732000,"abstract":"  Object trackers with transformer backbones have achieved robust performance\non visual object tracking datasets. However, the adversarial robustness of\nthese trackers has not been well studied in the literature. Due to the backbone\ndifferences, the adversarial white-box attacks proposed for object tracking are\nnot transferable to all types of trackers. For instance, transformer trackers\nsuch as MixFormerM still function well after black-box attacks, especially in\npredicting the object binary masks. We are proposing a novel white-box attack\nnamed TrackPGD, which relies on the predicted object binary mask to attack the\nrobust transformer trackers. That new attack focuses on annotation masks by\nadapting the well-known SegPGD segmentation attack, allowing to successfully\nconduct the white-box attack on trackers relying on transformer backbones. The\nexperimental results indicate that the TrackPGD is able to effectively attack\ntransformer-based trackers such as MixFormerM, OSTrackSTS, and TransT-SEG on\nseveral tracking datasets.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-sa/4.0/"}