{"id":"2408.05599","title":"Sequential Representation Learning via Static-Dynamic Conditional\n  Disentanglement","authors":"Mathieu Cyrille Simon, Pascal Frossard and Christophe De Vleeschouwer","authorsParsed":[["Simon","Mathieu Cyrille",""],["Frossard","Pascal",""],["De Vleeschouwer","Christophe",""]],"versions":[{"version":"v1","created":"Sat, 10 Aug 2024 17:04:39 GMT"}],"updateDate":"2024-08-13","timestamp":1723309479000,"abstract":"  This paper explores self-supervised disentangled representation learning\nwithin sequential data, focusing on separating time-independent and\ntime-varying factors in videos. We propose a new model that breaks the usual\nindependence assumption between those factors by explicitly accounting for the\ncausal relationship between the static/dynamic variables and that improves the\nmodel expressivity through additional Normalizing Flows. A formal definition of\nthe factors is proposed. This formalism leads to the derivation of sufficient\nconditions for the ground truth factors to be identifiable, and to the\nintroduction of a novel theoretically grounded disentanglement constraint that\ncan be directly and efficiently incorporated into our new framework. The\nexperiments show that the proposed approach outperforms previous complex\nstate-of-the-art techniques in scenarios where the dynamics of a scene are\ninfluenced by its content.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}