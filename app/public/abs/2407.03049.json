{"id":"2407.03049","title":"Enhancements for Real-Time Monte-Carlo Tree Search in General Video Game\n  Playing","authors":"Dennis J.N.J. Soemers and Chiara F. Sironi and Torsten Schuster and\n  Mark H.M. Winands","authorsParsed":[["Soemers","Dennis J. N. J.",""],["Sironi","Chiara F.",""],["Schuster","Torsten",""],["Winands","Mark H. M.",""]],"versions":[{"version":"v1","created":"Wed, 3 Jul 2024 12:18:28 GMT"}],"updateDate":"2024-07-04","timestamp":1720009108000,"abstract":"  General Video Game Playing (GVGP) is a field of Artificial Intelligence where\nagents play a variety of real-time video games that are unknown in advance.\nThis limits the use of domain-specific heuristics. Monte-Carlo Tree Search\n(MCTS) is a search technique for game playing that does not rely on\ndomain-specific knowledge. This paper discusses eight enhancements for MCTS in\nGVGP; Progressive History, N-Gram Selection Technique, Tree Reuse,\nBreadth-First Tree Initialization, Loss Avoidance, Novelty-Based Pruning,\nKnowledge-Based Evaluations, and Deterministic Game Detection. Some of these\nare known from existing literature, and are either extended or introduced in\nthe context of GVGP, and some are novel enhancements for MCTS. Most\nenhancements are shown to provide statistically significant increases in win\npercentages when applied individually. When combined, they increase the average\nwin percentage over sixty different games from 31.0% to 48.4% in comparison to\na vanilla MCTS implementation, approaching a level that is competitive with the\nbest agents of the GVG-AI competition in 2015.\n","subjects":["Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}