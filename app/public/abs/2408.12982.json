{"id":"2408.12982","title":"Inference-Adaptive Neural Steering for Real-Time Area-Based Sound Source\n  Separation","authors":"Martin Strauss, Wolfgang Mack, Mar\\'ia Luis Valero and Okan\n  K\\\"op\\\"ukl\\\"u","authorsParsed":[["Strauss","Martin",""],["Mack","Wolfgang",""],["Valero","María Luis",""],["Köpüklü","Okan",""]],"versions":[{"version":"v1","created":"Fri, 23 Aug 2024 10:59:14 GMT"}],"updateDate":"2024-08-26","timestamp":1724410754000,"abstract":"  We propose a novel Neural Steering technique that adapts the target area of a\nspatial-aware multi-microphone sound source separation algorithm during\ninference without the necessity of retraining the deep neural network (DNN). To\nachieve this, we first train a DNN aiming to retain speech within a target\nregion, defined by an angular span, while suppressing sound sources stemming\nfrom other directions. Afterward, a phase shift is applied to the microphone\nsignals, allowing us to shift the center of the target area during inference at\nnegligible additional cost in computational complexity. Further, we show that\nthe proposed approach performs well in a wide variety of acoustic scenarios,\nincluding several speakers inside and outside the target area and additional\nnoise. More precisely, the proposed approach performs on par with DNNs trained\nexplicitly for the steered target area in terms of DNSMOS and SI-SDR.\n","subjects":["Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}