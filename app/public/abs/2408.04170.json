{"id":"2408.04170","title":"M2EF-NNs: Multimodal Multi-instance Evidence Fusion Neural Networks for\n  Cancer Survival Prediction","authors":"Hui Luo, Jiashuang Huang, Hengrong Ju, Tianyi Zhou, Weiping Ding","authorsParsed":[["Luo","Hui",""],["Huang","Jiashuang",""],["Ju","Hengrong",""],["Zhou","Tianyi",""],["Ding","Weiping",""]],"versions":[{"version":"v1","created":"Thu, 8 Aug 2024 02:31:04 GMT"}],"updateDate":"2024-08-09","timestamp":1723084264000,"abstract":"  Accurate cancer survival prediction is crucial for assisting clinical doctors\nin formulating treatment plans. Multimodal data, including histopathological\nimages and genomic data, offer complementary and comprehensive information that\ncan greatly enhance the accuracy of this task. However, the current methods,\ndespite yielding promising results, suffer from two notable limitations: they\ndo not effectively utilize global context and disregard modal uncertainty. In\nthis study, we put forward a neural network model called M2EF-NNs, which\nleverages multimodal and multi-instance evidence fusion techniques for accurate\ncancer survival prediction. Specifically, to capture global information in the\nimages, we use a pre-trained Vision Transformer (ViT) model to obtain patch\nfeature embeddings of histopathological images. Then, we introduce a multimodal\nattention module that uses genomic embeddings as queries and learns the\nco-attention mapping between genomic and histopathological images to achieve an\nearly interaction fusion of multimodal information and better capture their\ncorrelations. Subsequently, we are the first to apply the Dempster-Shafer\nevidence theory (DST) to cancer survival prediction. We parameterize the\ndistribution of class probabilities using the processed multimodal features and\nintroduce subjective logic to estimate the uncertainty associated with\ndifferent modalities. By combining with the Dempster-Shafer theory, we can\ndynamically adjust the weights of class probabilities after multimodal fusion\nto achieve trusted survival prediction. Finally, Experimental validation on the\nTCGA datasets confirms the significant improvements achieved by our proposed\nmethod in cancer survival prediction and enhances the reliability of the model.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}