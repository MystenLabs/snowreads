{"id":"2407.21738","title":"Leveraging Self-Supervised Learning for Fetal Cardiac Planes\n  Classification using Ultrasound Scan Videos","authors":"Joseph Geo Benjamin, Mothilal Asokan, Amna Alhosani, Hussain Alasmawi,\n  Werner Gerhard Diehl, Leanne Bricker, Karthik Nandakumar, Mohammad Yaqub","authorsParsed":[["Benjamin","Joseph Geo",""],["Asokan","Mothilal",""],["Alhosani","Amna",""],["Alasmawi","Hussain",""],["Diehl","Werner Gerhard",""],["Bricker","Leanne",""],["Nandakumar","Karthik",""],["Yaqub","Mohammad",""]],"versions":[{"version":"v1","created":"Wed, 31 Jul 2024 16:47:21 GMT"}],"updateDate":"2024-08-01","timestamp":1722444441000,"abstract":"  Self-supervised learning (SSL) methods are popular since they can address\nsituations with limited annotated data by directly utilising the underlying\ndata distribution. However, the adoption of such methods is not explored enough\nin ultrasound (US) imaging, especially for fetal assessment. We investigate the\npotential of dual-encoder SSL in utilizing unlabelled US video data to improve\nthe performance of challenging downstream Standard Fetal Cardiac Planes (SFCP)\nclassification using limited labelled 2D US images. We study 7 SSL approaches\nbased on reconstruction, contrastive loss, distillation, and information theory\nand evaluate them extensively on a large private US dataset. Our observations\nand findings are consolidated from more than 500 downstream training\nexperiments under different settings. Our primary observation shows that for\nSSL training, the variance of the dataset is more crucial than its size because\nit allows the model to learn generalisable representations, which improve the\nperformance of downstream tasks. Overall, the BarlowTwins method shows robust\nperformance, irrespective of the training settings and data variations, when\nused as an initialisation for downstream tasks. Notably, full fine-tuning with\n1% of labelled data outperforms ImageNet initialisation by 12% in F1-score and\noutperforms other SSL initialisations by at least 4% in F1-score, thus making\nit a promising candidate for transfer learning from US video to image data.\n","subjects":["Electrical Engineering and Systems Science/Image and Video Processing","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}