{"id":"2408.08422","title":"Assessing and Enhancing Large Language Models in Rare Disease\n  Question-answering","authors":"Guanchu Wang and Junhao Ran and Ruixiang Tang and Chia-Yuan Chang and\n  Chia-Yuan Chang and Yu-Neng Chuang and Zirui Liu and Vladimir Braverman and\n  Zhandong Liu and Xia Hu","authorsParsed":[["Wang","Guanchu",""],["Ran","Junhao",""],["Tang","Ruixiang",""],["Chang","Chia-Yuan",""],["Chang","Chia-Yuan",""],["Chuang","Yu-Neng",""],["Liu","Zirui",""],["Braverman","Vladimir",""],["Liu","Zhandong",""],["Hu","Xia",""]],"versions":[{"version":"v1","created":"Thu, 15 Aug 2024 21:09:09 GMT"}],"updateDate":"2024-08-19","timestamp":1723756149000,"abstract":"  Despite the impressive capabilities of Large Language Models (LLMs) in\ngeneral medical domains, questions remain about their performance in diagnosing\nrare diseases. To answer this question, we aim to assess the diagnostic\nperformance of LLMs in rare diseases, and explore methods to enhance their\neffectiveness in this area. In this work, we introduce a rare disease\nquestion-answering (ReDis-QA) dataset to evaluate the performance of LLMs in\ndiagnosing rare diseases. Specifically, we collected 1360 high-quality\nquestion-answer pairs within the ReDis-QA dataset, covering 205 rare diseases.\nAdditionally, we annotated meta-data for each question, facilitating the\nextraction of subsets specific to any given disease and its property. Based on\nthe ReDis-QA dataset, we benchmarked several open-source LLMs, revealing that\ndiagnosing rare diseases remains a significant challenge for these models.\n  To facilitate retrieval augmentation generation for rare disease diagnosis,\nwe collect the first rare diseases corpus (ReCOP), sourced from the National\nOrganization for Rare Disorders (NORD) database. Specifically, we split the\nreport of each rare disease into multiple chunks, each representing a different\nproperty of the disease, including their overview, symptoms, causes, effects,\nrelated disorders, diagnosis, and standard therapies. This structure ensures\nthat the information within each chunk aligns consistently with a question.\nExperiment results demonstrate that ReCOP can effectively improve the accuracy\nof LLMs on the ReDis-QA dataset by an average of 8%. Moreover, it significantly\nguides LLMs to generate trustworthy answers and explanations that can be traced\nback to existing literature.\n","subjects":["Computing Research Repository/Computational Engineering, Finance, and Science","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}