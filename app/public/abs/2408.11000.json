{"id":"2408.11000","title":"SenPa-MAE: Sensor Parameter Aware Masked Autoencoder for Multi-Satellite\n  Self-Supervised Pretraining","authors":"Jonathan Prexl and Michael Schmitt","authorsParsed":[["Prexl","Jonathan",""],["Schmitt","Michael",""]],"versions":[{"version":"v1","created":"Tue, 20 Aug 2024 16:53:30 GMT"}],"updateDate":"2024-08-21","timestamp":1724172810000,"abstract":"  This paper introduces SenPa-MAE, a transformer architecture that encodes the\nsensor parameters of an observed multispectral signal into the image\nembeddings. SenPa-MAE can be pre-trained on imagery of different satellites\nwith non-matching spectral or geometrical sensor characteristics. To\nincorporate sensor parameters, we propose a versatile sensor parameter encoding\nmodule as well as a data augmentation strategy for the diversification of the\npre-training dataset. This enables the model to effectively differentiate\nbetween various sensors and gain an understanding of sensor parameters and the\ncorrelation to the observed signal. Given the rising number of Earth\nobservation satellite missions and the diversity in their sensor\nspecifications, our approach paves the way towards a sensor-independent Earth\nobservation foundation model. This opens up possibilities such as cross-sensor\ntraining and sensor-independent inference.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}