{"id":"2408.10942","title":"Robust Regression with Ensembles Communicating over Noisy Channels","authors":"Yuval Ben-Hur and Yuval Cassuto","authorsParsed":[["Ben-Hur","Yuval",""],["Cassuto","Yuval",""]],"versions":[{"version":"v1","created":"Tue, 20 Aug 2024 15:32:47 GMT"}],"updateDate":"2024-08-21","timestamp":1724167967000,"abstract":"  As machine-learning models grow in size, their implementation requirements\ncannot be met by a single computer system. This observation motivates\ndistributed settings, in which intermediate computations are performed across a\nnetwork of processing units, while the central node only aggregates their\noutputs. However, distributing inference tasks across low-precision or faulty\nedge devices, operating over a network of noisy communication channels, gives\nrise to serious reliability challenges. We study the problem of an ensemble of\ndevices, implementing regression algorithms, that communicate through additive\nnoisy channels in order to collaboratively perform a joint regression task. We\ndefine the problem formally, and develop methods for optimizing the aggregation\ncoefficients for the parameters of the noise in the channels, which can\npotentially be correlated. Our results apply to the leading state-of-the-art\nensemble regression methods: bagging and gradient boosting. We demonstrate the\neffectiveness of our algorithms on both synthetic and real-world datasets.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Distributed, Parallel, and Cluster Computing","Computing Research Repository/Information Theory","Mathematics/Information Theory"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}