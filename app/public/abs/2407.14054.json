{"id":"2407.14054","title":"PointRegGPT: Boosting 3D Point Cloud Registration using Generative\n  Point-Cloud Pairs for Training","authors":"Suyi Chen, Hao Xu, Haipeng Li, Kunming Luo, Guanghui Liu, Chi-Wing Fu,\n  Ping Tan, Shuaicheng Liu","authorsParsed":[["Chen","Suyi",""],["Xu","Hao",""],["Li","Haipeng",""],["Luo","Kunming",""],["Liu","Guanghui",""],["Fu","Chi-Wing",""],["Tan","Ping",""],["Liu","Shuaicheng",""]],"versions":[{"version":"v1","created":"Fri, 19 Jul 2024 06:29:57 GMT"}],"updateDate":"2024-07-22","timestamp":1721370597000,"abstract":"  Data plays a crucial role in training learning-based methods for 3D point\ncloud registration. However, the real-world dataset is expensive to build,\nwhile rendering-based synthetic data suffers from domain gaps. In this work, we\npresent PointRegGPT, boosting 3D point cloud registration using generative\npoint-cloud pairs for training. Given a single depth map, we first apply a\nrandom camera motion to re-project it into a target depth map. Converting them\nto point clouds gives a training pair. To enhance the data realism, we\nformulate a generative model as a depth inpainting diffusion to process the\ntarget depth map with the re-projected source depth map as the condition. Also,\nwe design a depth correction module to alleviate artifacts caused by point\npenetration during the re-projection. To our knowledge, this is the first\ngenerative approach that explores realistic data generation for indoor point\ncloud registration. When equipped with our approach, several recent algorithms\ncan improve their performance significantly and achieve SOTA consistently on\ntwo common benchmarks. The code and dataset will be released on\nhttps://github.com/Chen-Suyi/PointRegGPT.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}