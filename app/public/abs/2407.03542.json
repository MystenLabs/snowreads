{"id":"2407.03542","title":"Probing Perfection: The Relentless Art of Meddling for Pulmonary Airway\n  Segmentation from HRCT via a Human-AI Collaboration Based Active Learning\n  Method","authors":"Shiyi Wang, Yang Nan, Sheng Zhang, Federico Felder, Xiaodan Xing,\n  Yingying Fang, Javier Del Ser, Simon L F Walsh, Guang Yang","authorsParsed":[["Wang","Shiyi",""],["Nan","Yang",""],["Zhang","Sheng",""],["Felder","Federico",""],["Xing","Xiaodan",""],["Fang","Yingying",""],["Del Ser","Javier",""],["Walsh","Simon L F",""],["Yang","Guang",""]],"versions":[{"version":"v1","created":"Wed, 3 Jul 2024 23:27:53 GMT"},{"version":"v2","created":"Tue, 23 Jul 2024 11:16:22 GMT"}],"updateDate":"2024-07-24","timestamp":1720049273000,"abstract":"  In pulmonary tracheal segmentation, the scarcity of annotated data is a\nprevalent issue in medical segmentation. Additionally, Deep Learning (DL)\nmethods face challenges: the opacity of 'black box' models and the need for\nperformance enhancement. Our Human-Computer Interaction (HCI) based models\n(RS_UNet, LC_UNet, UUNet, and WD_UNet) address these challenges by combining\ndiverse query strategies with various DL models. We train four HCI models and\nrepeat these steps: (1) Query Strategy: The HCI models select samples that\nprovide the most additional representative information when labeled in each\niteration and identify unlabeled samples with the greatest predictive disparity\nusing Wasserstein Distance, Least Confidence, Entropy Sampling, and Random\nSampling. (2) Central line correction: Selected samples are used for expert\ncorrection of system-generated tracheal central lines in each training round.\n(3) Update training dataset: Experts update the training dataset after each DL\nmodel's training epoch, enhancing the trustworthiness and performance of the\nmodels. (4) Model training: The HCI model is trained using the updated dataset\nand an enhanced UNet version. Experimental results confirm the effectiveness of\nthese HCI-based approaches, showing that WD-UNet, LC-UNet, UUNet, and RS-UNet\nachieve comparable or superior performance to state-of-the-art DL models.\nNotably, WD-UNet achieves this with only 15%-35% of the training data, reducing\nphysician annotation time by 65%-85%.\n","subjects":["Electrical Engineering and Systems Science/Image and Video Processing","Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}