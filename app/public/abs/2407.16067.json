{"id":"2407.16067","title":"LCA-on-the-Line: Benchmarking Out-of-Distribution Generalization with\n  Class Taxonomies","authors":"Jia Shi, Gautam Gare, Jinjin Tian, Siqi Chai, Zhiqiu Lin, Arun\n  Vasudevan, Di Feng, Francesco Ferroni, Shu Kong","authorsParsed":[["Shi","Jia",""],["Gare","Gautam",""],["Tian","Jinjin",""],["Chai","Siqi",""],["Lin","Zhiqiu",""],["Vasudevan","Arun",""],["Feng","Di",""],["Ferroni","Francesco",""],["Kong","Shu",""]],"versions":[{"version":"v1","created":"Mon, 22 Jul 2024 21:54:19 GMT"}],"updateDate":"2024-07-24","timestamp":1721685259000,"abstract":"  We tackle the challenge of predicting models' Out-of-Distribution (OOD)\nperformance using in-distribution (ID) measurements without requiring OOD data.\nExisting evaluations with \"Effective Robustness\", which use ID accuracy as an\nindicator of OOD accuracy, encounter limitations when models are trained with\ndiverse supervision and distributions, such as class labels (Vision Models,\nVMs, on ImageNet) and textual descriptions (Visual-Language Models, VLMs, on\nLAION). VLMs often generalize better to OOD data than VMs despite having\nsimilar or lower ID performance. To improve the prediction of models' OOD\nperformance from ID measurements, we introduce the Lowest Common Ancestor\n(LCA)-on-the-Line framework. This approach revisits the established concept of\nLCA distance, which measures the hierarchical distance between labels and\npredictions within a predefined class hierarchy, such as WordNet. We assess 75\nmodels using ImageNet as the ID dataset and five significantly shifted OOD\nvariants, uncovering a strong linear correlation between ID LCA distance and\nOOD top-1 accuracy. Our method provides a compelling alternative for\nunderstanding why VLMs tend to generalize better. Additionally, we propose a\ntechnique to construct a taxonomic hierarchy on any dataset using K-means\nclustering, demonstrating that LCA distance is robust to the constructed\ntaxonomic hierarchy. Moreover, we demonstrate that aligning model predictions\nwith class taxonomies, through soft labels or prompt engineering, can enhance\nmodel generalization. Open source code in our Project Page:\nhttps://elvishelvis.github.io/papers/lca/.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}