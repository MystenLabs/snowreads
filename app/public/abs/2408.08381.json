{"id":"2408.08381","title":"Pre-processing and Compression: Understanding Hidden Representation\n  Refinement Across Imaging Domains via Intrinsic Dimension","authors":"Nicholas Konz, Maciej A. Mazurowski","authorsParsed":[["Konz","Nicholas",""],["Mazurowski","Maciej A.",""]],"versions":[{"version":"v1","created":"Thu, 15 Aug 2024 18:54:31 GMT"},{"version":"v2","created":"Wed, 4 Sep 2024 14:52:59 GMT"},{"version":"v3","created":"Mon, 9 Sep 2024 17:58:42 GMT"}],"updateDate":"2024-09-10","timestamp":1723748071000,"abstract":"  In recent years, there has been interest in how geometric properties such as\nintrinsic dimension (ID) of a neural network's hidden representations change\nthrough its layers, and how such properties are predictive of important model\nbehavior such as generalization ability. However, evidence has begun to emerge\nthat such behavior can change significantly depending on the domain of the\nnetwork's training data, such as natural versus medical images. Here, we\nfurther this inquiry by exploring how the ID of a network's learned\nrepresentations changes through its layers, in essence, characterizing how the\nnetwork successively refines the information content of input data to be used\nfor predictions. Analyzing eleven natural and medical image datasets across six\nnetwork architectures, we find that how ID changes through the network differs\nnoticeably between natural and medical image models. Specifically, medical\nimage models peak in representation ID earlier in the network, implying a\ndifference in the image features and their abstractness that are typically used\nfor downstream tasks in these domains. Additionally, we discover a strong\ncorrelation of this peak representation ID with the ID of the data in its input\nspace, implying that the intrinsic information content of a model's learned\nrepresentations is guided by that of the data it was trained on. Overall, our\nfindings emphasize notable discrepancies in network behavior between natural\nand non-natural imaging domains regarding hidden representation information\ncontent, and provide further insights into how a network's learned features are\nshaped by its training data.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Machine Learning","Electrical Engineering and Systems Science/Image and Video Processing","Statistics/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}