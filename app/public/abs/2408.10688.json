{"id":"2408.10688","title":"TDS-CLIP: Temporal Difference Side Network for Image-to-Video Transfer\n  Learning","authors":"Bin Wang and Wenqian Wang","authorsParsed":[["Wang","Bin",""],["Wang","Wenqian",""]],"versions":[{"version":"v1","created":"Tue, 20 Aug 2024 09:40:08 GMT"}],"updateDate":"2024-08-21","timestamp":1724146808000,"abstract":"  Recently, large-scale pre-trained vision-language models (e.g., CLIP), have\ngarnered significant attention thanks to their powerful representative\ncapabilities. This inspires researchers in transferring the knowledge from\nthese large pre-trained models to other task-specific models, e.g., Video\nAction Recognition (VAR) models, via particularly leveraging side networks to\nenhance the efficiency of parameter-efficient fine-tuning (PEFT). However,\ncurrent transferring approaches in VAR tend to directly transfer the frozen\nknowledge from large pre-trained models to action recognition networks with\nminimal cost, instead of exploiting the temporal modeling capabilities of the\naction recognition models themselves. Therefore, in this paper, we propose a\nmemory-efficient Temporal Difference Side Network (TDS-CLIP) to balance\nknowledge transferring and temporal modeling, avoiding backpropagation in\nfrozen parameter models. Specifically, we introduce a Temporal Difference\nAdapter (TD-Adapter), which can effectively capture local temporal differences\nin motion features to strengthen the model's global temporal modeling\ncapabilities. Furthermore, we designed a Side Motion Enhancement Adapter\n(SME-Adapter) to guide the proposed side network in efficiently learning the\nrich motion information in videos, thereby improving the side network's ability\nto capture and learn motion information. Extensive experiments are conducted on\nthree benchmark datasets, including Something-Something V1\\&V2, and\nKinetics-400. Experimental results demonstrate that our approach achieves\ncompetitive performance.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}