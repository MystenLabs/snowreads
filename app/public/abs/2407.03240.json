{"id":"2407.03240","title":"Cyclic Refiner: Object-Aware Temporal Representation Learning for\n  Multi-View 3D Detection and Tracking","authors":"Mingzhe Guo, Zhipeng Zhang, Liping Jing, Yuan He, Ke Wang, Heng Fan","authorsParsed":[["Guo","Mingzhe",""],["Zhang","Zhipeng",""],["Jing","Liping",""],["He","Yuan",""],["Wang","Ke",""],["Fan","Heng",""]],"versions":[{"version":"v1","created":"Wed, 3 Jul 2024 16:10:19 GMT"}],"updateDate":"2024-07-04","timestamp":1720023019000,"abstract":"  We propose a unified object-aware temporal learning framework for multi-view\n3D detection and tracking tasks. Having observed that the efficacy of the\ntemporal fusion strategy in recent multi-view perception methods may be\nweakened by distractors and background clutters in historical frames, we\npropose a cyclic learning mechanism to improve the robustness of multi-view\nrepresentation learning. The essence is constructing a backward bridge to\npropagate information from model predictions (e.g., object locations and sizes)\nto image and BEV features, which forms a circle with regular inference. After\nbackward refinement, the responses of target-irrelevant regions in historical\nframes would be suppressed, decreasing the risk of polluting future frames and\nimproving the object awareness ability of temporal fusion. We further tailor an\nobject-aware association strategy for tracking based on the cyclic learning\nmodel. The cyclic learning model not only provides refined features, but also\ndelivers finer clues (e.g., scale level) for tracklet association. The proposed\ncycle learning method and association module together contribute a novel and\nunified multi-task framework. Experiments on nuScenes show that the proposed\nmodel achieves consistent performance gains over baselines of different designs\n(i.e., dense query-based BEVFormer, sparse query-based SparseBEV and LSS-based\nBEVDet4D) on both detection and tracking evaluation.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}