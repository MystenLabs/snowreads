{"id":"2408.14998","title":"FastTextSpotter: A High-Efficiency Transformer for Multilingual Scene\n  Text Spotting","authors":"Alloy Das, Sanket Biswas, Umapada Pal, Josep Llad\\'os, Saumik\n  Bhattacharya","authorsParsed":[["Das","Alloy",""],["Biswas","Sanket",""],["Pal","Umapada",""],["Llad√≥s","Josep",""],["Bhattacharya","Saumik",""]],"versions":[{"version":"v1","created":"Tue, 27 Aug 2024 12:28:41 GMT"}],"updateDate":"2024-08-28","timestamp":1724761721000,"abstract":"  The proliferation of scene text in both structured and unstructured\nenvironments presents significant challenges in optical character recognition\n(OCR), necessitating more efficient and robust text spotting solutions. This\npaper presents FastTextSpotter, a framework that integrates a Swin Transformer\nvisual backbone with a Transformer Encoder-Decoder architecture, enhanced by a\nnovel, faster self-attention unit, SAC2, to improve processing speeds while\nmaintaining accuracy. FastTextSpotter has been validated across multiple\ndatasets, including ICDAR2015 for regular texts and CTW1500 and TotalText for\narbitrary-shaped texts, benchmarking against current state-of-the-art models.\nOur results indicate that FastTextSpotter not only achieves superior accuracy\nin detecting and recognizing multilingual scene text (English and Vietnamese)\nbut also improves model efficiency, thereby setting new benchmarks in the\nfield. This study underscores the potential of advanced transformer\narchitectures in improving the adaptability and speed of text spotting\napplications in diverse real-world settings. The dataset, code, and pre-trained\nmodels have been released in our Github.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"_pABdk3i8cr6AZ_JpTmMl-F8xvH_4bP-c946iy172tk","pdfSize":"5641547"}
