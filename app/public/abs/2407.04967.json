{"id":"2407.04967","title":"posteriordb: Testing, Benchmarking and Developing Bayesian Inference\n  Algorithms","authors":"M{\\aa}ns Magnusson, Jakob Torgander, Paul-Christian B\\\"urkner, Lu\n  Zhang, Bob Carpenter, Aki Vehtari","authorsParsed":[["Magnusson","Måns",""],["Torgander","Jakob",""],["Bürkner","Paul-Christian",""],["Zhang","Lu",""],["Carpenter","Bob",""],["Vehtari","Aki",""]],"versions":[{"version":"v1","created":"Sat, 6 Jul 2024 06:01:02 GMT"}],"updateDate":"2024-07-09","timestamp":1720245662000,"abstract":"  The generality and robustness of inference algorithms is critical to the\nsuccess of widely used probabilistic programming languages such as Stan, PyMC,\nPyro, and Turing.jl. When designing a new general-purpose inference algorithm,\nwhether it involves Monte Carlo sampling or variational approximation, the\nfundamental problem arises in evaluating its accuracy and efficiency across a\nrange of representative target models. To solve this problem, we propose\nposteriordb, a database of models and data sets defining target densities along\nwith reference Monte Carlo draws. We further provide a guide to the best\npractices in using posteriordb for model evaluation and comparison. To provide\na wide range of realistic target densities, posteriordb currently comprises 120\nrepresentative models and has been instrumental in developing several general\ninference algorithms.\n","subjects":["Statistics/Computation"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}