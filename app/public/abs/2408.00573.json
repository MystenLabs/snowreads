{"id":"2408.00573","title":"Convergence Analysis of Natural Gradient Descent for Over-parameterized\n  Physics-Informed Neural Networks","authors":"Xianliang Xu, Ting Du, Wang Kong, Ye Li, Zhongyi Huang","authorsParsed":[["Xu","Xianliang",""],["Du","Ting",""],["Kong","Wang",""],["Li","Ye",""],["Huang","Zhongyi",""]],"versions":[{"version":"v1","created":"Thu, 1 Aug 2024 14:06:34 GMT"},{"version":"v2","created":"Tue, 6 Aug 2024 12:36:57 GMT"}],"updateDate":"2024-08-07","timestamp":1722521194000,"abstract":"  First-order methods, such as gradient descent (GD) and stochastic gradient\ndescent (SGD), have been proven effective in training neural networks. In the\ncontext of over-parameterization, there is a line of work demonstrating that\nrandomly initialized (stochastic) gradient descent converges to a globally\noptimal solution at a linear convergence rate for the quadratic loss function.\nHowever, the learning rate of GD for training two-layer neural networks\nexhibits poor dependence on the sample size and the Gram matrix, leading to a\nslow training process. In this paper, we show that for the $L^2$ regression\nproblems, the learning rate can be improved from $\\mathcal{O}(\\lambda_0/n^2)$\nto $\\mathcal{O}(1/\\|\\bm{H}^{\\infty}\\|_2)$, which implies that GD actually\nenjoys a faster convergence rate. Furthermore, we generalize the method to GD\nin training two-layer Physics-Informed Neural Networks (PINNs), showing a\nsimilar improvement for the learning rate. Although the improved learning rate\nhas a mild dependence on the Gram matrix, we still need to set it small enough\nin practice due to the unknown eigenvalues of the Gram matrix. More\nimportantly, the convergence rate is tied to the least eigenvalue of the Gram\nmatrix, which can lead to slow convergence. In this work, we provide the\nconvergence analysis of natural gradient descent (NGD) in training two-layer\nPINNs, demonstrating that the learning rate can be $\\mathcal{O}(1)$, and at\nthis rate, the convergence rate is independent of the Gram matrix.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"dI9sNC7I3pm7i3R7kG7mC2NQInrfE3uzfx1pkm2KuyM","pdfSize":"383203"}
