{"id":"2407.18105","title":"Multi-Resolution Histopathology Patch Graphs for Ovarian Cancer\n  Subtyping","authors":"Jack Breen, Katie Allen, Kieran Zucker, Nicolas M. Orsi, Nishant\n  Ravikumar","authorsParsed":[["Breen","Jack",""],["Allen","Katie",""],["Zucker","Kieran",""],["Orsi","Nicolas M.",""],["Ravikumar","Nishant",""]],"versions":[{"version":"v1","created":"Thu, 25 Jul 2024 15:08:54 GMT"}],"updateDate":"2024-07-26","timestamp":1721920134000,"abstract":"  Computer vision models are increasingly capable of classifying ovarian\nepithelial cancer subtypes, but they differ from pathologists by processing\nsmall tissue patches at a single resolution. Multi-resolution graph models\nleverage the spatial relationships of patches at multiple magnifications,\nlearning the context for each patch. In this study, we conduct the most\nthorough validation of a graph model for ovarian cancer subtyping to date.\nSeven models were tuned and trained using five-fold cross-validation on a set\nof 1864 whole slide images (WSIs) from 434 patients treated at Leeds Teaching\nHospitals NHS Trust. The cross-validation models were ensembled and evaluated\nusing a balanced hold-out test set of 100 WSIs from 30 patients, and an\nexternal validation set of 80 WSIs from 80 patients in the Transcanadian Study.\nThe best-performing model, a graph model using 10x+20x magnification data, gave\nbalanced accuracies of 73%, 88%, and 99% in cross-validation, hold-out testing,\nand external validation, respectively. However, this only exceeded the\nperformance of attention-based multiple instance learning in external\nvalidation, with a 93% balanced accuracy. Graph models benefitted greatly from\nusing the UNI foundation model rather than an ImageNet-pretrained ResNet50 for\nfeature extraction, with this having a much greater effect on performance than\nchanging the subsequent classification approach. The accuracy of the combined\nfoundation model and multi-resolution graph network offers a step towards the\nclinical applicability of these models, with a new highest-reported performance\nfor this task, though further validations are still required to ensure the\nrobustness and usability of the models.\n","subjects":["Electrical Engineering and Systems Science/Image and Video Processing","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}