{"id":"2408.12099","title":"Query-Efficient Video Adversarial Attack with Stylized Logo","authors":"Duoxun Tang, Yuxin Cao, Xi Xiao, Derui Wang, Sheng Wen and Tianqing\n  Zhu","authorsParsed":[["Tang","Duoxun",""],["Cao","Yuxin",""],["Xiao","Xi",""],["Wang","Derui",""],["Wen","Sheng",""],["Zhu","Tianqing",""]],"versions":[{"version":"v1","created":"Thu, 22 Aug 2024 03:19:09 GMT"}],"updateDate":"2024-08-23","timestamp":1724296749000,"abstract":"  Video classification systems based on Deep Neural Networks (DNNs) have\ndemonstrated excellent performance in accurately verifying video content.\nHowever, recent studies have shown that DNNs are highly vulnerable to\nadversarial examples. Therefore, a deep understanding of adversarial attacks\ncan better respond to emergency situations. In order to improve attack\nperformance, many style-transfer-based attacks and patch-based attacks have\nbeen proposed. However, the global perturbation of the former will bring\nunnatural global color, while the latter is difficult to achieve success in\ntargeted attacks due to the limited perturbation space. Moreover, compared to a\nplethora of methods targeting image classifiers, video adversarial attacks are\nstill not that popular. Therefore, to generate adversarial examples with a low\nbudget and to provide them with a higher verisimilitude, we propose a novel\nblack-box video attack framework, called Stylized Logo Attack (SLA). SLA is\nconducted through three steps. The first step involves building a style\nreferences set for logos, which can not only make the generated examples more\nnatural, but also carry more target class features in the targeted attacks.\nThen, reinforcement learning (RL) is employed to determine the style reference\nand position parameters of the logo within the video, which ensures that the\nstylized logo is placed in the video with optimal attributes. Finally,\nperturbation optimization is designed to optimize perturbations to improve the\nfooling rate in a step-by-step manner. Sufficient experimental results indicate\nthat, SLA can achieve better performance than state-of-the-art methods and\nstill maintain good deception effects when facing various defense methods.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Cryptography and Security"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}