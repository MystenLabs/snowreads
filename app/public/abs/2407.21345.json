{"id":"2407.21345","title":"Towards EMG-to-Speech with a Necklace Form Factor","authors":"Peter Wu, Ryan Kaveh, Raghav Nautiyal, Christine Zhang, Albert Guo,\n  Anvitha Kachinthaya, Tavish Mishra, Bohan Yu, Alan W Black, Rikky Muller,\n  Gopala Krishna Anumanchipalli","authorsParsed":[["Wu","Peter",""],["Kaveh","Ryan",""],["Nautiyal","Raghav",""],["Zhang","Christine",""],["Guo","Albert",""],["Kachinthaya","Anvitha",""],["Mishra","Tavish",""],["Yu","Bohan",""],["Black","Alan W",""],["Muller","Rikky",""],["Anumanchipalli","Gopala Krishna",""]],"versions":[{"version":"v1","created":"Wed, 31 Jul 2024 05:28:50 GMT"}],"updateDate":"2024-08-01","timestamp":1722403730000,"abstract":"  Electrodes for decoding speech from electromyography (EMG) are typically\nplaced on the face, requiring adhesives that are inconvenient and\nskin-irritating if used regularly. We explore a different device form factor,\nwhere dry electrodes are placed around the neck instead. 11-word, multi-speaker\nvoiced EMG classifiers trained on data recorded with this device achieve 92.7%\naccuracy. Ablation studies reveal the importance of having more than two\nelectrodes on the neck, and phonological analyses reveal similar classification\nconfusions between neck-only and neck-and-face form factors. Finally,\nspeech-EMG correlation experiments demonstrate a linear relationship between\nmany EMG spectrogram frequency bins and self-supervised speech representation\ndimensions.\n","subjects":["Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}