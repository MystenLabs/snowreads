{"id":"2407.08969","title":"Detect Llama -- Finding Vulnerabilities in Smart Contracts using Large\n  Language Models","authors":"Peter Ince, Xiapu Luo, Jiangshan Yu, Joseph K. Liu, Xiaoning Du","authorsParsed":[["Ince","Peter",""],["Luo","Xiapu",""],["Yu","Jiangshan",""],["Liu","Joseph K.",""],["Du","Xiaoning",""]],"versions":[{"version":"v1","created":"Fri, 12 Jul 2024 03:33:13 GMT"}],"updateDate":"2024-07-17","timestamp":1720755193000,"abstract":"  In this paper, we test the hypothesis that although OpenAI's GPT-4 performs\nwell generally, we can fine-tune open-source models to outperform GPT-4 in\nsmart contract vulnerability detection. We fine-tune two models from Meta's\nCode Llama and a dataset of 17k prompts, Detect Llama - Foundation and Detect\nLlama - Instruct, and we also fine-tune OpenAI's GPT-3.5 Turbo model\n(GPT-3.5FT). We then evaluate these models, plus a random baseline, on a\ntestset we develop against GPT-4, and GPT-4 Turbo's, detection of eight\nvulnerabilities from the dataset and the two top identified vulnerabilities -\nand their weighted F1 scores.\n  We find that for binary classification (i.e., is this smart contract\nvulnerable?), our two best-performing models, GPT-3.5FT and Detect Llama -\nFoundation, achieve F1 scores of $0.776$ and $0.68$, outperforming both GPT-4\nand GPT-4 Turbo, $0.66$ and $0.675$. For the evaluation against individual\nvulnerability identification, our top two models, GPT-3.5FT and Detect Llama -\nFoundation, both significantly outperformed GPT-4 and GPT-4 Turbo in both\nweighted F1 for all vulnerabilities ($0.61$ and $0.56$ respectively against\nGPT-4's $0.218$ and GPT-4 Turbo's $0.243$) and weighted F1 for the top two\nidentified vulnerabilities ($0.719$ for GPT-3.5FT, $0.674$ for Detect Llama -\nFoundation against GPT-4's $0.363$ and GPT-4 Turbo's $0.429$).\n","subjects":["Computing Research Repository/Cryptography and Security"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}