{"id":"2408.12334","title":"Enhanced Expressivity in Graph Neural Networks with Lanczos-Based Linear\n  Constraints","authors":"Niloofar Azizi, Nils Kriege, Horst Bischof","authorsParsed":[["Azizi","Niloofar",""],["Kriege","Nils",""],["Bischof","Horst",""]],"versions":[{"version":"v1","created":"Thu, 22 Aug 2024 12:22:00 GMT"}],"updateDate":"2024-08-23","timestamp":1724329320000,"abstract":"  Graph Neural Networks (GNNs) excel in handling graph-structured data but\noften underperform in link prediction tasks compared to classical methods,\nmainly due to the limitations of the commonly used Message Passing GNNs\n(MPNNs). Notably, their ability to distinguish non-isomorphic graphs is limited\nby the 1-dimensional Weisfeiler-Lehman test. Our study presents a novel method\nto enhance the expressivity of GNNs by embedding induced subgraphs into the\ngraph Laplacian matrix's eigenbasis. We introduce a Learnable Lanczos algorithm\nwith Linear Constraints (LLwLC), proposing two novel subgraph extraction\nstrategies: encoding vertex-deleted subgraphs and applying Neumann eigenvalue\nconstraints. For the former, we conjecture that LLwLC establishes a universal\napproximator, offering efficient time complexity. The latter focuses on link\nrepresentations enabling differentiation between $k$-regular graphs and node\nautomorphism, a vital aspect for link prediction tasks. Our approach results in\nan extremely lightweight architecture, reducing the need for extensive training\ndatasets. Empirically, our method improves performance in challenging link\nprediction tasks across benchmark datasets, establishing its practical utility\nand supporting our theoretical findings. Notably, LLwLC achieves 20x and 10x\nspeedup by only requiring 5% and 10% data from the PubMed and OGBL-Vessel\ndatasets while comparing to the state-of-the-art.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by-sa/4.0/"}