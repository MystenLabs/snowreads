{"id":"2407.14812","title":"GaitMA: Pose-guided Multi-modal Feature Fusion for Gait Recognition","authors":"Fanxu Min, Shaoxiang Guo, Fan Hao, Junyu Dong","authorsParsed":[["Min","Fanxu",""],["Guo","Shaoxiang",""],["Hao","Fan",""],["Dong","Junyu",""]],"versions":[{"version":"v1","created":"Sat, 20 Jul 2024 09:05:17 GMT"}],"updateDate":"2024-07-23","timestamp":1721466317000,"abstract":"  Gait recognition is a biometric technology that recognizes the identity of\nhumans through their walking patterns. Existing appearance-based methods\nutilize CNN or Transformer to extract spatial and temporal features from\nsilhouettes, while model-based methods employ GCN to focus on the special\ntopological structure of skeleton points. However, the quality of silhouettes\nis limited by complex occlusions, and skeletons lack dense semantic features of\nthe human body. To tackle these problems, we propose a novel gait recognition\nframework, dubbed Gait Multi-model Aggregation Network (GaitMA), which\neffectively combines two modalities to obtain a more robust and comprehensive\ngait representation for recognition. First, skeletons are represented by\njoint/limb-based heatmaps, and features from silhouettes and skeletons are\nrespectively extracted using two CNN-based feature extractors. Second, a\nco-attention alignment module is proposed to align the features by element-wise\nattention. Finally, we propose a mutual learning module, which achieves feature\nfusion through cross-attention, Wasserstein loss is further introduced to\nensure the effective fusion of two modalities. Extensive experimental results\ndemonstrate the superiority of our model on Gait3D, OU-MVLP, and CASIA-B.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}