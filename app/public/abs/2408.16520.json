{"id":"2408.16520","title":"Towards Modality-agnostic Label-efficient Segmentation with\n  Entropy-Regularized Distribution Alignment","authors":"Liyao Tang, Zhe Chen, Shanshan Zhao, Chaoyue Wang, Dacheng Tao","authorsParsed":[["Tang","Liyao",""],["Chen","Zhe",""],["Zhao","Shanshan",""],["Wang","Chaoyue",""],["Tao","Dacheng",""]],"versions":[{"version":"v1","created":"Thu, 29 Aug 2024 13:31:15 GMT"}],"updateDate":"2024-08-30","timestamp":1724938275000,"abstract":"  Label-efficient segmentation aims to perform effective segmentation on input\ndata using only sparse and limited ground-truth labels for training. This topic\nis widely studied in 3D point cloud segmentation due to the difficulty of\nannotating point clouds densely, while it is also essential for cost-effective\nsegmentation on 2D images. Until recently, pseudo-labels have been widely\nemployed to facilitate training with limited ground-truth labels, and promising\nprogress has been witnessed in both the 2D and 3D segmentation. However,\nexisting pseudo-labeling approaches could suffer heavily from the noises and\nvariations in unlabelled data, which would result in significant discrepancies\nbetween generated pseudo-labels and current model predictions during training.\nWe analyze that this can further confuse and affect the model learning process,\nwhich shows to be a shared problem in label-efficient learning across both 2D\nand 3D modalities. To address this issue, we propose a novel learning strategy\nto regularize the pseudo-labels generated for training, thus effectively\nnarrowing the gaps between pseudo-labels and model predictions. More\nspecifically, our method introduces an Entropy Regularization loss and a\nDistribution Alignment loss for label-efficient learning, resulting in an ERDA\nlearning strategy. Interestingly, by using KL distance to formulate the\ndistribution alignment loss, ERDA reduces to a deceptively simple\ncross-entropy-based loss which optimizes both the pseudo-label generation\nmodule and the segmentation model simultaneously. In addition, we innovate in\nthe pseudo-label generation to make our ERDA consistently effective across both\n2D and 3D data modalities for segmentation. Enjoying simplicity and more\nmodality-agnostic pseudo-label generation, our method has shown outstanding\nperformance in fully utilizing all unlabeled data points for training across\n...\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}