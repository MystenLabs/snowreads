{"id":"2408.16544","title":"Spurfies: Sparse Surface Reconstruction using Local Geometry Priors","authors":"Kevin Raj, Christopher Wewer, Raza Yunus, Eddy Ilg, Jan Eric Lenssen","authorsParsed":[["Raj","Kevin",""],["Wewer","Christopher",""],["Yunus","Raza",""],["Ilg","Eddy",""],["Lenssen","Jan Eric",""]],"versions":[{"version":"v1","created":"Thu, 29 Aug 2024 14:02:47 GMT"}],"updateDate":"2024-08-30","timestamp":1724940167000,"abstract":"  We introduce Spurfies, a novel method for sparse-view surface reconstruction\nthat disentangles appearance and geometry information to utilize local geometry\npriors trained on synthetic data. Recent research heavily focuses on 3D\nreconstruction using dense multi-view setups, typically requiring hundreds of\nimages. However, these methods often struggle with few-view scenarios. Existing\nsparse-view reconstruction techniques often rely on multi-view stereo networks\nthat need to learn joint priors for geometry and appearance from a large amount\nof data. In contrast, we introduce a neural point representation that\ndisentangles geometry and appearance to train a local geometry prior using a\nsubset of the synthetic ShapeNet dataset only. During inference, we utilize\nthis surface prior as additional constraint for surface and appearance\nreconstruction from sparse input views via differentiable volume rendering,\nrestricting the space of possible solutions. We validate the effectiveness of\nour method on the DTU dataset and demonstrate that it outperforms previous\nstate of the art by 35% in surface quality while achieving competitive novel\nview synthesis quality. Moreover, in contrast to previous works, our method can\nbe applied to larger, unbounded scenes, such as Mip-NeRF 360.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"D8RTbrudqha9zih7DgFdX7i1iG-XTnHQJqQDdY-hzwI","pdfSize":"41935564"}
