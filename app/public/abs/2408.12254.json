{"id":"2408.12254","title":"A Language-agnostic Model of Child Language Acquisition","authors":"Louis Mahon and Omri Abend and Uri Berger and Katherine Demuth and\n  Mark Johnson and Mark Steedman","authorsParsed":[["Mahon","Louis",""],["Abend","Omri",""],["Berger","Uri",""],["Demuth","Katherine",""],["Johnson","Mark",""],["Steedman","Mark",""]],"versions":[{"version":"v1","created":"Thu, 22 Aug 2024 09:48:06 GMT"}],"updateDate":"2024-08-23","timestamp":1724320086000,"abstract":"  This work reimplements a recent semantic bootstrapping child-language\nacquisition model, which was originally designed for English, and trains it to\nlearn a new language: Hebrew. The model learns from pairs of utterances and\nlogical forms as meaning representations, and acquires both syntax and word\nmeanings simultaneously. The results show that the model mostly transfers to\nHebrew, but that a number of factors, including the richer morphology in\nHebrew, makes the learning slower and less robust. This suggests that a clear\ndirection for future work is to enable the model to leverage the similarities\nbetween different word forms.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"UEJzhGqt_E92sNLEkPuwJEtbMpNX6Xo4UzVvVjNR2xA","pdfSize":"899609"}
