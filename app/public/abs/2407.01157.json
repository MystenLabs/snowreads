{"id":"2407.01157","title":"Unaligning Everything: Or Aligning Any Text to Any Image in Multimodal\n  Models","authors":"Shaeke Salman, Md Montasir Bin Shams, Xiuwen Liu","authorsParsed":[["Salman","Shaeke",""],["Shams","Md Montasir Bin",""],["Liu","Xiuwen",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 10:25:47 GMT"}],"updateDate":"2024-07-02","timestamp":1719829547000,"abstract":"  Utilizing a shared embedding space, emerging multimodal models exhibit\nunprecedented zero-shot capabilities. However, the shared embedding space could\nlead to new vulnerabilities if different modalities can be misaligned. In this\npaper, we extend and utilize a recently developed effective gradient-based\nprocedure that allows us to match the embedding of a given text by minimally\nmodifying an image. Using the procedure, we show that we can align the\nembeddings of distinguishable texts to any image through unnoticeable\nadversarial attacks in joint image-text models, revealing that semantically\nunrelated images can have embeddings of identical texts and at the same time\nvisually indistinguishable images can be matched to the embeddings of very\ndifferent texts. Our technique achieves 100\\% success rate when it is applied\nto text datasets and images from multiple sources. Without overcoming the\nvulnerability, multimodal models cannot robustly align inputs from different\nmodalities in a semantically meaningful way. \\textbf{Warning: the text data\nused in this paper are toxic in nature and may be offensive to some readers.}\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}