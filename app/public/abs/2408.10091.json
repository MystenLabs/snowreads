{"id":"2408.10091","title":"Non-Plug-In Estimators Could Outperform Plug-In Estimators: a Cautionary\n  Note and a Diagnosis","authors":"Hongxiang Qiu","authorsParsed":[["Qiu","Hongxiang",""]],"versions":[{"version":"v1","created":"Mon, 19 Aug 2024 15:31:54 GMT"}],"updateDate":"2024-08-20","timestamp":1724081514000,"abstract":"  Objectives: Highly flexible nonparametric estimators have gained popularity\nin causal inference and epidemiology. Popular examples of such estimators\ninclude targeted maximum likelihood estimators (TMLE) and double machine\nlearning (DML). TMLE is often argued or suggested to be better than DML\nestimators and several other estimators in small to moderate samples -- even if\nthey share the same large-sample properties -- because TMLE is a plug-in\nestimator and respects the known bounds on the parameter, while other\nestimators might fall outside the known bounds and yield absurd estimates.\nHowever, this argument is not a rigorously proven result and may fail in\ncertain cases. Methods: In a carefully chosen simulation setting, I compare the\nperformance of several versions of TMLE and DML estimators of the average\ntreatment effect among treated in small to moderate samples. Results: In this\nsimulation setting, DML estimators outperforms some versions of TMLE in small\nsamples. TMLE fluctuations are unstable, and hence empirically checking the\nmagnitude of the TMLE fluctuation might alert cases where TMLE might perform\npoorly. Conclusions: As a plug-in estimator, TMLE is not guaranteed to\noutperform non-plug-in counterparts such as DML estimators in small samples.\nChecking the fluctuation magnitude might be a useful diagnosis for TMLE. More\nrigorous theoretical justification is needed to understand and compare the\nfinite-sample performance of these highly flexible estimators in general.\n","subjects":["Statistics/Methodology"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}