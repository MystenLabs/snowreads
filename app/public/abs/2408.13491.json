{"id":"2408.13491","title":"ESA: Annotation-Efficient Active Learning for Semantic Segmentation","authors":"Jinchao Ge, Zeyu Zhang, Minh Hieu Phan, Bowen Zhang, Akide Liu, Yang\n  Zhao","authorsParsed":[["Ge","Jinchao",""],["Zhang","Zeyu",""],["Phan","Minh Hieu",""],["Zhang","Bowen",""],["Liu","Akide",""],["Zhao","Yang",""]],"versions":[{"version":"v1","created":"Sat, 24 Aug 2024 06:30:03 GMT"}],"updateDate":"2024-08-27","timestamp":1724481003000,"abstract":"  Active learning enhances annotation efficiency by selecting the most\nrevealing samples for labeling, thereby reducing reliance on extensive human\ninput. Previous methods in semantic segmentation have centered on individual\npixels or small areas, neglecting the rich patterns in natural images and the\npower of advanced pre-trained models. To address these challenges, we propose\nthree key contributions: Firstly, we introduce Entity-Superpixel Annotation\n(ESA), an innovative and efficient active learning strategy which utilizes a\nclass-agnostic mask proposal network coupled with super-pixel grouping to\ncapture local structural cues. Additionally, our method selects a subset of\nentities within each image of the target domain, prioritizing superpixels with\nhigh entropy to ensure comprehensive representation. Simultaneously, it focuses\non a limited number of key entities, thereby optimizing for efficiency. By\nutilizing an annotator-friendly design that capitalizes on the inherent\nstructure of images, our approach significantly outperforms existing\npixel-based methods, achieving superior results with minimal queries,\nspecifically reducing click cost by 98% and enhancing performance by 1.71%. For\ninstance, our technique requires a mere 40 clicks for annotation, a stark\ncontrast to the 5000 clicks demanded by conventional methods.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"J1ryAQAQsLN44KGXPl_UuwpcsYebbJKDiUZjkwR1qkc","pdfSize":"6690704"}
