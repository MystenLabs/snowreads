{"id":"2407.08130","title":"Spiking Tucker Fusion Transformer for Audio-Visual Zero-Shot Learning","authors":"Wenrui Li, Penghong Wang, Ruiqin Xiong, Xiaopeng Fan","authorsParsed":[["Li","Wenrui",""],["Wang","Penghong",""],["Xiong","Ruiqin",""],["Fan","Xiaopeng",""]],"versions":[{"version":"v1","created":"Thu, 11 Jul 2024 02:01:26 GMT"}],"updateDate":"2024-07-12","timestamp":1720663286000,"abstract":"  The spiking neural networks (SNNs) that efficiently encode temporal sequences\nhave shown great potential in extracting audio-visual joint feature\nrepresentations. However, coupling SNNs (binary spike sequences) with\ntransformers (float-point sequences) to jointly explore the temporal-semantic\ninformation still facing challenges. In this paper, we introduce a novel\nSpiking Tucker Fusion Transformer (STFT) for audio-visual zero-shot learning\n(ZSL). The STFT leverage the temporal and semantic information from different\ntime steps to generate robust representations. The time-step factor (TSF) is\nintroduced to dynamically synthesis the subsequent inference information. To\nguide the formation of input membrane potentials and reduce the spike noise, we\npropose a global-local pooling (GLP) which combines the max and average pooling\noperations. Furthermore, the thresholds of the spiking neurons are dynamically\nadjusted based on semantic and temporal cues. Integrating the temporal and\nsemantic information extracted by SNNs and Transformers are difficult due to\nthe increased number of parameters in a straightforward bilinear model. To\naddress this, we introduce a temporal-semantic Tucker fusion module, which\nachieves multi-scale fusion of SNN and Transformer outputs while maintaining\nfull second-order interactions. Our experimental results demonstrate the\neffectiveness of the proposed approach in achieving state-of-the-art\nperformance in three benchmark datasets. The harmonic mean (HM) improvement of\nVGGSound, UCF101 and ActivityNet are around 15.4\\%, 3.9\\%, and 14.9\\%,\nrespectively.\n","subjects":["Computing Research Repository/Multimedia","Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Sound","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"G75k7h72JegwosGoA9BXao0E4QpIxDVTtknxgxteqfA","pdfSize":"1228240"}
