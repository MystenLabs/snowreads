{"id":"2408.14547","title":"Revisiting Image Captioning Training Paradigm via Direct CLIP-based\n  Optimization","authors":"Nicholas Moratelli, Davide Caffagni, Marcella Cornia, Lorenzo Baraldi,\n  Rita Cucchiara","authorsParsed":[["Moratelli","Nicholas",""],["Caffagni","Davide",""],["Cornia","Marcella",""],["Baraldi","Lorenzo",""],["Cucchiara","Rita",""]],"versions":[{"version":"v1","created":"Mon, 26 Aug 2024 18:00:33 GMT"}],"updateDate":"2024-08-28","timestamp":1724695233000,"abstract":"  The conventional training approach for image captioning involves pre-training\na network using teacher forcing and subsequent fine-tuning with Self-Critical\nSequence Training to maximize hand-crafted captioning metrics. However, when\nattempting to optimize modern and higher-quality metrics like CLIP-Score and\nPAC-Score, this training method often encounters instability and fails to\nacquire the genuine descriptive capabilities needed to produce fluent and\ninformative captions. In this paper, we propose a new training paradigm termed\nDirect CLIP-Based Optimization (DiCO). Our approach jointly learns and\noptimizes a reward model that is distilled from a learnable captioning\nevaluator with high human correlation. This is done by solving a weighted\nclassification problem directly inside the captioner. At the same time, DiCO\nprevents divergence from the original model, ensuring that fluency is\nmaintained. DiCO not only exhibits improved stability and enhanced quality in\nthe generated captions but also aligns more closely with human preferences\ncompared to existing methods, especially in modern metrics. Additionally, it\nmaintains competitive performance in traditional metrics. Our source code and\ntrained models are publicly available at https://github.com/aimagelab/DiCO.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language","Computing Research Repository/Multimedia"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}