{"id":"2408.08729","title":"ConcateNet: Dialogue Separation Using Local And Global Feature\n  Concatenation","authors":"Mhd Modar Halimeh, Matteo Torcoli, Emanu\\\"el Habets","authorsParsed":[["Halimeh","Mhd Modar",""],["Torcoli","Matteo",""],["Habets","EmanuÃ«l",""]],"versions":[{"version":"v1","created":"Fri, 16 Aug 2024 13:22:55 GMT"}],"updateDate":"2024-08-19","timestamp":1723814575000,"abstract":"  Dialogue separation involves isolating a dialogue signal from a mixture, such\nas a movie or a TV program. This can be a necessary step to enable dialogue\nenhancement for broadcast-related applications. In this paper, ConcateNet for\ndialogue separation is proposed, which is based on a novel approach for\nprocessing local and global features aimed at better generalization for\nout-of-domain signals. ConcateNet is trained using a noise reduction-focused,\npublicly available dataset and evaluated using three datasets: two noise\nreduction-focused datasets (in-domain), which show competitive performance for\nConcateNet, and a broadcast-focused dataset (out-of-domain), which verifies the\nbetter generalization performance for the proposed architecture compared to\nconsidered state-of-the-art noise-reduction methods.\n","subjects":["Electrical Engineering and Systems Science/Audio and Speech Processing","Computing Research Repository/Computation and Language","Computing Research Repository/Sound"],"license":"http://creativecommons.org/licenses/by/4.0/"}