{"id":"2408.01003","title":"Piculet: Specialized Models-Guided Hallucination Decrease for MultiModal\n  Large Language Models","authors":"Kohou Wang, Xiang Liu, Zhaoxiang Liu, Kai Wang, Shiguo Lian","authorsParsed":[["Wang","Kohou",""],["Liu","Xiang",""],["Liu","Zhaoxiang",""],["Wang","Kai",""],["Lian","Shiguo",""]],"versions":[{"version":"v1","created":"Fri, 2 Aug 2024 04:34:37 GMT"}],"updateDate":"2024-08-05","timestamp":1722573277000,"abstract":"  Multimodal Large Language Models (MLLMs) have made significant progress in\nbridging the gap between visual and language modalities. However,\nhallucinations in MLLMs, where the generated text does not align with image\ncontent, continue to be a major challenge. Existing methods for addressing\nhallucinations often rely on instruction-tuning, which requires retraining the\nmodel with specific data, which increases the cost of utilizing MLLMs further.\nIn this paper, we introduce a novel training-free method, named Piculet, for\nenhancing the input representation of MLLMs. Piculet leverages multiple\nspecialized models to extract descriptions of visual information from the input\nimage and combine these descriptions with the original image and query as input\nto the MLLM. We evaluate our method both quantitively and qualitatively, and\nthe results demonstrate that Piculet greatly decreases hallucinations of MLLMs.\nOur method can be easily extended to different MLLMs while being universal.\n","subjects":["Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"mT03SyE1fJOVunF0kC0LywaQLrrDFQkUI8FBV_KsLyA","pdfSize":"6438234","txDigest":"Hrv7Jc61uw2HC9ntufipcQoA79YVms8T4dz8hftyMGpo","endEpoch":"1","status":"CERTIFIED"}
