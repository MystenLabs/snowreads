{"id":"2407.17710","title":"Revisiting Machine Unlearning with Dimensional Alignment","authors":"Seonguk Seo, Dongwan Kim, Bohyung Han","authorsParsed":[["Seo","Seonguk",""],["Kim","Dongwan",""],["Han","Bohyung",""]],"versions":[{"version":"v1","created":"Thu, 25 Jul 2024 02:05:15 GMT"}],"updateDate":"2024-07-26","timestamp":1721873115000,"abstract":"  Machine unlearning, an emerging research topic focusing on compliance with\ndata privacy regulations, enables trained models to remove the information\nlearned from specific data. While many existing methods indirectly address this\nissue by intentionally injecting incorrect supervisions, they can drastically\nand unpredictably alter the decision boundaries and feature spaces, leading to\ntraining instability and undesired side effects. To fundamentally approach this\ntask, we first analyze the changes in latent feature spaces between original\nand retrained models, and observe that the feature representations of samples\nnot involved in training are closely aligned with the feature manifolds of\npreviously seen samples in training. Based on these findings, we introduce a\nnovel evaluation metric for machine unlearning, coined dimensional alignment,\nwhich measures the alignment between the eigenspaces of the forget and retain\nset samples. We employ this metric as a regularizer loss to build a robust and\nstable unlearning framework, which is further enhanced by integrating a\nself-distillation loss and an alternating training scheme. Our framework\neffectively eliminates information from the forget set and preserves knowledge\nfrom the retain set. Lastly, we identify critical flaws in established\nevaluation metrics for machine unlearning, and introduce new evaluation tools\nthat more accurately reflect the fundamental goals of machine unlearning.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"FMOxygiqxMZRWB-xV9iS_EMoZ4pA5oiJABhQbIGl_aM","pdfSize":"912211"}
