{"id":"2408.03150","title":"Conditioning LLMs with Emotion in Neural Machine Translation","authors":"Charles Brazier, Jean-Luc Rouas","authorsParsed":[["Brazier","Charles",""],["Rouas","Jean-Luc",""]],"versions":[{"version":"v1","created":"Tue, 6 Aug 2024 12:49:33 GMT"}],"updateDate":"2024-08-07","timestamp":1722948573000,"abstract":"  Large Language Models (LLMs) have shown remarkable performance in Natural\nLanguage Processing tasks, including Machine Translation (MT). In this work, we\npropose a novel MT pipeline that integrates emotion information extracted from\na Speech Emotion Recognition (SER) model into LLMs to enhance translation\nquality. We first fine-tune five existing LLMs on the Libri-trans dataset and\nselect the most performant model. Subsequently, we augment LLM prompts with\ndifferent dimensional emotions and train the selected LLM under these different\nconfigurations. Our experiments reveal that integrating emotion information,\nespecially arousal, into LLM prompts leads to notable improvements in\ntranslation quality.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}