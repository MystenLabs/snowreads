{"id":"2408.04633","title":"LiDAR-Event Stereo Fusion with Hallucinations","authors":"Luca Bartolomei, Matteo Poggi, Andrea Conti, Stefano Mattoccia","authorsParsed":[["Bartolomei","Luca",""],["Poggi","Matteo",""],["Conti","Andrea",""],["Mattoccia","Stefano",""]],"versions":[{"version":"v1","created":"Thu, 8 Aug 2024 17:59:58 GMT"}],"updateDate":"2024-08-09","timestamp":1723139998000,"abstract":"  Event stereo matching is an emerging technique to estimate depth from\nneuromorphic cameras; however, events are unlikely to trigger in the absence of\nmotion or the presence of large, untextured regions, making the correspondence\nproblem extremely challenging. Purposely, we propose integrating a stereo event\ncamera with a fixed-frequency active sensor -- e.g., a LiDAR -- collecting\nsparse depth measurements, overcoming the aforementioned limitations. Such\ndepth hints are used by hallucinating -- i.e., inserting fictitious events --\nthe stacks or raw input streams, compensating for the lack of information in\nthe absence of brightness changes. Our techniques are general, can be adapted\nto any structured representation to stack events and outperform\nstate-of-the-art fusion methods applied to event-based stereo.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}