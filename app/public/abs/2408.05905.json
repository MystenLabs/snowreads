{"id":"2408.05905","title":"Weakly Supervised Video Anomaly Detection and Localization with\n  Spatio-Temporal Prompts","authors":"Peng Wu, Xuerong Zhou, Guansong Pang, Zhiwei Yang, Qingsen Yan, Peng\n  Wang, Yanning Zhang","authorsParsed":[["Wu","Peng",""],["Zhou","Xuerong",""],["Pang","Guansong",""],["Yang","Zhiwei",""],["Yan","Qingsen",""],["Wang","Peng",""],["Zhang","Yanning",""]],"versions":[{"version":"v1","created":"Mon, 12 Aug 2024 03:31:29 GMT"},{"version":"v2","created":"Tue, 13 Aug 2024 13:55:03 GMT"}],"updateDate":"2024-08-14","timestamp":1723433489000,"abstract":"  Current weakly supervised video anomaly detection (WSVAD) task aims to\nachieve frame-level anomalous event detection with only coarse video-level\nannotations available. Existing works typically involve extracting global\nfeatures from full-resolution video frames and training frame-level classifiers\nto detect anomalies in the temporal dimension. However, most anomalous events\ntend to occur in localized spatial regions rather than the entire video frames,\nwhich implies existing frame-level feature based works may be misled by the\ndominant background information and lack the interpretation of the detected\nanomalies. To address this dilemma, this paper introduces a novel method called\nSTPrompt that learns spatio-temporal prompt embeddings for weakly supervised\nvideo anomaly detection and localization (WSVADL) based on pre-trained\nvision-language models (VLMs). Our proposed method employs a two-stream network\nstructure, with one stream focusing on the temporal dimension and the other\nprimarily on the spatial dimension. By leveraging the learned knowledge from\npre-trained VLMs and incorporating natural motion priors from raw videos, our\nmodel learns prompt embeddings that are aligned with spatio-temporal regions of\nvideos (e.g., patches of individual frames) for identify specific local regions\nof anomalies, enabling accurate video anomaly detection while mitigating the\ninfluence of background information. Without relying on detailed\nspatio-temporal annotations or auxiliary object detection/tracking, our method\nachieves state-of-the-art performance on three public benchmarks for the WSVADL\ntask.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}