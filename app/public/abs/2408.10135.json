{"id":"2408.10135","title":"$R^2$-Mesh: Reinforcement Learning Powered Mesh Reconstruction via\n  Geometry and Appearance Refinement","authors":"Haoyang Wang, Liming Liu, Quanlu Jia, Jiangkai Wu, Haodan Zhang,\n  Peiheng Wang, Xinggong Zhang","authorsParsed":[["Wang","Haoyang",""],["Liu","Liming",""],["Jia","Quanlu",""],["Wu","Jiangkai",""],["Zhang","Haodan",""],["Wang","Peiheng",""],["Zhang","Xinggong",""]],"versions":[{"version":"v1","created":"Mon, 19 Aug 2024 16:33:17 GMT"}],"updateDate":"2024-08-20","timestamp":1724085197000,"abstract":"  Mesh reconstruction based on Neural Radiance Fields (NeRF) is popular in a\nvariety of applications such as computer graphics, virtual reality, and medical\nimaging due to its efficiency in handling complex geometric structures and\nfacilitating real-time rendering. However, existing works often fail to capture\nfine geometric details accurately and struggle with optimizing rendering\nquality. To address these challenges, we propose a novel algorithm that\nprogressively generates and optimizes meshes from multi-view images. Our\napproach initiates with the training of a NeRF model to establish an initial\nSigned Distance Field (SDF) and a view-dependent appearance field.\nSubsequently, we iteratively refine the SDF through a differentiable mesh\nextraction method, continuously updating both the vertex positions and their\nconnectivity based on the loss from mesh differentiable rasterization, while\nalso optimizing the appearance representation. To further leverage\nhigh-fidelity and detail-rich representations from NeRF, we propose an\nonline-learning strategy based on Upper Confidence Bound (UCB) to enhance\nviewpoints by adaptively incorporating images rendered by the initial NeRF\nmodel into the training dataset. Through extensive experiments, we demonstrate\nthat our method delivers highly competitive and robust performance in both mesh\nrendering quality and geometric quality.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}