{"id":"2408.06475","title":"Quasi-Monte Carlo Beyond Hardy-Krause","authors":"Nikhil Bansal, Haotian Jiang","authorsParsed":[["Bansal","Nikhil",""],["Jiang","Haotian",""]],"versions":[{"version":"v1","created":"Mon, 12 Aug 2024 20:21:03 GMT"}],"updateDate":"2024-08-14","timestamp":1723494063000,"abstract":"  The classical approaches to numerically integrating a function $f$ are Monte\nCarlo (MC) and quasi-Monte Carlo (QMC) methods. MC methods use random samples\nto evaluate $f$ and have error $O(\\sigma(f)/\\sqrt{n})$, where $\\sigma(f)$ is\nthe standard deviation of $f$. QMC methods are based on evaluating $f$ at\nexplicit point sets with low discrepancy, and as given by the classical\nKoksma-Hlawka inequality, they have error\n$\\widetilde{O}(\\sigma_{\\mathsf{HK}}(f)/n)$, where $\\sigma_{\\mathsf{HK}}(f)$ is\nthe variation of $f$ in the sense of Hardy and Krause. These two methods have\ndistinctive advantages and shortcomings, and a fundamental question is to find\na method that combines the advantages of both.\n  In this work, we give a simple randomized algorithm that produces QMC point\nsets with the following desirable features: (1) It achieves substantially\nbetter error than given by the classical Koksma-Hlawka inequality. In\nparticular, it has error $\\widetilde{O}(\\sigma_{\\mathsf{SO}}(f)/n)$, where\n$\\sigma_{\\mathsf{SO}}(f)$ is a new measure of variation that we introduce,\nwhich is substantially smaller than the Hardy-Krause variation. (2) The\nalgorithm only requires random samples from the underlying distribution, which\nmakes it as flexible as MC. (3) It automatically achieves the best of both MC\nand QMC (and the above improvement over Hardy-Krause variation) in an optimal\nway. (4) The algorithm is extremely efficient, with an amortized\n$\\widetilde{O}(1)$ runtime per sample.\n  Our method is based on the classical transference principle in geometric\ndiscrepancy, combined with recent algorithmic innovations in combinatorial\ndiscrepancy that besides producing low-discrepancy colorings, also guarantee\ncertain subgaussian properties. This allows us to bypass several limitations of\nprevious works in bridging the gap between MC and QMC methods and go beyond the\nHardy-Krause variation.\n","subjects":["Computing Research Repository/Data Structures and Algorithms","Computing Research Repository/Computational Geometry","Computing Research Repository/Discrete Mathematics","Computing Research Repository/Numerical Analysis","Mathematics/Numerical Analysis"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}