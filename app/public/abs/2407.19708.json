{"id":"2407.19708","title":"ALEN: A Dual-Approach for Uniform and Non-Uniform Low-Light Image\n  Enhancement","authors":"Ezequiel Perez-Zarate and Oscar Ramos-Soto and Diego Oliva and Marco\n  Perez-Cisneros","authorsParsed":[["Perez-Zarate","Ezequiel",""],["Ramos-Soto","Oscar",""],["Oliva","Diego",""],["Perez-Cisneros","Marco",""]],"versions":[{"version":"v1","created":"Mon, 29 Jul 2024 05:19:23 GMT"}],"updateDate":"2024-07-30","timestamp":1722230363000,"abstract":"  Low-light image enhancement is an important task in computer vision,\nessential for improving the visibility and quality of images captured in\nnon-optimal lighting conditions. Inadequate illumination can lead to\nsignificant information loss and poor image quality, impacting various\napplications such as surveillance. photography, or even autonomous driving. In\nthis regard, automated methods have been developed to automatically adjust\nillumination in the image for a better visual perception. Current enhancement\ntechniques often use specific datasets to enhance low-light images, but still\npresent challenges when adapting to diverse real-world conditions, where\nillumination degradation may be localized to specific regions. To address this\nchallenge, the Adaptive Light Enhancement Network (ALEN) is introduced, whose\nmain approach is the use of a classification mechanism to determine whether\nlocal or global illumination enhancement is required. Subsequently, estimator\nnetworks adjust illumination based on this classification and simultaneously\nenhance color fidelity. ALEN integrates the Light Classification Network\n(LCNet) for illuminance categorization, complemented by the Single-Channel\nNetwork (SCNet), and Multi-Channel Network (MCNet) for precise estimation of\nillumination and color, respectively. Extensive experiments on publicly\navailable datasets for low-light conditions were carried out to underscore\nALEN's robust generalization capabilities, demonstrating superior performance\nin both quantitative metrics and qualitative assessments when compared to\nrecent state-of-the-art methods. The ALEN not only enhances image quality in\nterms of visual perception but also represents an advancement in high-level\nvision tasks, such as semantic segmentation, as presented in this work. The\ncode of this method is available at https://github.com/xingyumex/ALEN.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"8kmlibRc2PfqbVvenys0nWZQbYLg1DTB811cmRQIoQY","pdfSize":"20703608","objectId":"0x1abef34cd685cae96797d100c20fb8261d87f5a402944cbcea97c8cfa5f6a324","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
