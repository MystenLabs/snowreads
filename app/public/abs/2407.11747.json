{"id":"2407.11747","title":"PandORA: Automated Design and Comprehensive Evaluation of Deep\n  Reinforcement Learning Agents for Open RAN","authors":"Maria Tsampazi, Salvatore D'Oro, Michele Polese, Leonardo Bonati,\n  Gwenael Poitau, Michael Healy, Mohammad Alavirad, Tommaso Melodia","authorsParsed":[["Tsampazi","Maria",""],["D'Oro","Salvatore",""],["Polese","Michele",""],["Bonati","Leonardo",""],["Poitau","Gwenael",""],["Healy","Michael",""],["Alavirad","Mohammad",""],["Melodia","Tommaso",""]],"versions":[{"version":"v1","created":"Thu, 23 May 2024 18:45:09 GMT"}],"updateDate":"2024-07-17","timestamp":1716489909000,"abstract":"  The highly heterogeneous ecosystem of NextG wireless communication systems\ncalls for novel networking paradigms where functionalities and operations can\nbe dynamically and optimally reconfigured in real time to adapt to changing\ntraffic conditions and satisfy stringent and diverse QoS demands. Open RAN\ntechnologies, and specifically those being standardized by the O-RAN Alliance,\nmake it possible to integrate network intelligence into the once monolithic RAN\nvia intelligent applications, namely, xApps and rApps. These applications\nenable flexible control of the network resources and functionalities, network\nmanagement, and orchestration through data-driven intelligent control loops.\nRecent work has showed how DRL is effective in dynamically controlling O-RAN\nsystems. However, how to design these solutions in a way that manages\nheterogeneous optimization goals and prevents unfair resource allocation is\nstill an open challenge, with the logic within DRL agents often considered as a\nblack box. In this paper, we introduce PandORA, a framework to automatically\ndesign and train DRL agents for Open RAN applications, package them as xApps\nand evaluate them in the Colosseum wireless network emulator. We benchmark $23$\nxApps that embed DRL agents trained using different architectures, reward\ndesign, action spaces, and decision-making timescales, and with the ability to\nhierarchically control different network parameters. We test these agents on\nthe Colosseum testbed under diverse traffic and channel conditions, in static\nand mobile setups. Our experimental results indicate how suitable fine-tuning\nof the RAN control timers, as well as proper selection of reward designs and\nDRL architectures can boost network performance according to the network\nconditions and demand. Notably, finer decision-making granularities can improve\nmMTC's performance by ~56% and even increase eMBB Throughput by ~99%.\n","subjects":["Computing Research Repository/Networking and Internet Architecture"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}