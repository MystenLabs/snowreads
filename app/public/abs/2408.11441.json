{"id":"2408.11441","title":"Epistemic Injustice in Generative AI","authors":"Jackie Kay, Atoosa Kasirzadeh, Shakir Mohamed","authorsParsed":[["Kay","Jackie",""],["Kasirzadeh","Atoosa",""],["Mohamed","Shakir",""]],"versions":[{"version":"v1","created":"Wed, 21 Aug 2024 08:51:05 GMT"}],"updateDate":"2024-08-22","timestamp":1724230265000,"abstract":"  This paper investigates how generative AI can potentially undermine the\nintegrity of collective knowledge and the processes we rely on to acquire,\nassess, and trust information, posing a significant threat to our knowledge\necosystem and democratic discourse. Grounded in social and political\nphilosophy, we introduce the concept of \\emph{generative algorithmic epistemic\ninjustice}. We identify four key dimensions of this phenomenon: amplified and\nmanipulative testimonial injustice, along with hermeneutical ignorance and\naccess injustice. We illustrate each dimension with real-world examples that\nreveal how generative AI can produce or amplify misinformation, perpetuate\nrepresentational harm, and create epistemic inequities, particularly in\nmultilingual contexts. By highlighting these injustices, we aim to inform the\ndevelopment of epistemically just generative AI systems, proposing strategies\nfor resistance, system design principles, and two approaches that leverage\ngenerative AI to foster a more equitable information ecosystem, thereby\nsafeguarding democratic values and the integrity of knowledge production.\n","subjects":["Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"9iUxLlQvlA05g3PPwUsNxA3ZZRl3O7rvAsGG_xhh9u0","pdfSize":"181140"}
