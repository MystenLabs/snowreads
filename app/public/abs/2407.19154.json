{"id":"2407.19154","title":"RePLAy: Remove Projective LiDAR Depthmap Artifacts via Exploiting\n  Epipolar Geometry","authors":"Shengjie Zhu, Girish Chandar Ganesan, Abhinav Kumar, and Xiaoming Liu","authorsParsed":[["Zhu","Shengjie",""],["Ganesan","Girish Chandar",""],["Kumar","Abhinav",""],["Liu","Xiaoming",""]],"versions":[{"version":"v1","created":"Sat, 27 Jul 2024 03:13:16 GMT"}],"updateDate":"2024-07-30","timestamp":1722049996000,"abstract":"  3D sensing is a fundamental task for Autonomous Vehicles. Its deployment\noften relies on aligned RGB cameras and LiDAR. Despite meticulous\nsynchronization and calibration, systematic misalignment persists in LiDAR\nprojected depthmap. This is due to the physical baseline distance between the\ntwo sensors. The artifact is often reflected as background LiDAR incorrectly\nprojected onto the foreground, such as cars and pedestrians. The KITTI dataset\nuses stereo cameras as a heuristic solution to remove artifacts. However most\nAV datasets, including nuScenes, Waymo, and DDAD, lack stereo images, making\nthe KITTI solution inapplicable. We propose RePLAy, a parameter-free analytical\nsolution to remove the projective artifacts. We construct a binocular vision\nsystem between a hypothesized virtual LiDAR camera and the RGB camera. We then\nremove the projective artifacts by determining the epipolar occlusion with the\nproposed analytical solution. We show unanimous improvement in the\nState-of-The-Art (SoTA) monocular depth estimators and 3D object detectors with\nthe artifacts-free depthmaps.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}