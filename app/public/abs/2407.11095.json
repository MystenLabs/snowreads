{"id":"2407.11095","title":"DeepGate3: Towards Scalable Circuit Representation Learning","authors":"Zhengyuan Shi, Ziyang Zheng, Sadaf Khan, Jianyuan Zhong, Min Li and\n  Qiang Xu","authorsParsed":[["Shi","Zhengyuan",""],["Zheng","Ziyang",""],["Khan","Sadaf",""],["Zhong","Jianyuan",""],["Li","Min",""],["Xu","Qiang",""]],"versions":[{"version":"v1","created":"Mon, 15 Jul 2024 02:44:21 GMT"}],"updateDate":"2024-07-17","timestamp":1721011461000,"abstract":"  Circuit representation learning has shown promising results in advancing the\nfield of Electronic Design Automation (EDA). Existing models, such as DeepGate\nFamily, primarily utilize Graph Neural Networks (GNNs) to encode circuit\nnetlists into gate-level embeddings. However, the scalability of GNN-based\nmodels is fundamentally constrained by architectural limitations, impacting\ntheir ability to generalize across diverse and complex circuit designs. To\naddress these challenges, we introduce DeepGate3, an enhanced architecture that\nintegrates Transformer modules following the initial GNN processing. This novel\narchitecture not only retains the robust gate-level representation capabilities\nof its predecessor, DeepGate2, but also enhances them with the ability to model\nsubcircuits through a novel pooling transformer mechanism. DeepGate3 is further\nrefined with multiple innovative supervision tasks, significantly enhancing its\nlearning process and enabling superior representation of both gate-level and\nsubcircuit structures. Our experiments demonstrate marked improvements in\nscalability and generalizability over traditional GNN-based approaches,\nestablishing a significant step forward in circuit representation learning\ntechnology.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/"}