{"id":"2408.12013","title":"Detection of Under-represented Samples Using Dynamic Batch Training for\n  Brain Tumor Segmentation from MR Images","authors":"Subin Sahayam and John Michael Sujay Zakkam and Yoga Sri Varshan V and\n  Umarani Jayaraman","authorsParsed":[["Sahayam","Subin",""],["Zakkam","John Michael Sujay",""],["Varshan","Yoga Sri","V"],["Jayaraman","Umarani",""]],"versions":[{"version":"v1","created":"Wed, 21 Aug 2024 21:51:47 GMT"}],"updateDate":"2024-08-23","timestamp":1724277107000,"abstract":"  Brain tumors in magnetic resonance imaging (MR) are difficult,\ntime-consuming, and prone to human error. These challenges can be resolved by\ndeveloping automatic brain tumor segmentation methods from MR images. Various\ndeep-learning models based on the U-Net have been proposed for the task. These\ndeep-learning models are trained on a dataset of tumor images and then used for\nsegmenting the masks. Mini-batch training is a widely used method in deep\nlearning for training. However, one of the significant challenges associated\nwith this approach is that if the training dataset has under-represented\nsamples or samples with complex latent representations, the model may not\ngeneralize well to these samples. The issue leads to skewed learning of the\ndata, where the model learns to fit towards the majority representations while\nunderestimating the under-represented samples. The proposed dynamic batch\ntraining method addresses the challenges posed by under-represented data\npoints, data points with complex latent representation, and imbalances within\nthe class, where some samples may be harder to learn than others. Poor\nperformance of such samples can be identified only after the completion of the\ntraining, leading to the wastage of computational resources. Also, training\neasy samples after each epoch is an inefficient utilization of computation\nresources. To overcome these challenges, the proposed method identifies hard\nsamples and trains such samples for more iterations compared to easier samples\non the BraTS2020 dataset. Additionally, the samples trained multiple times are\nidentified and it provides a way to identify hard samples in the BraTS2020\ndataset. The comparison of the proposed training approach with U-Net and other\nmodels in the literature highlights the capabilities of the proposed training\napproach.\n","subjects":["Electrical Engineering and Systems Science/Image and Video Processing","Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}