{"id":"2408.04679","title":"Towards Linguistic Neural Representation Learning and Sentence Retrieval\n  from Electroencephalogram Recordings","authors":"Jinzhao Zhou, Yiqun Duan, Ziyi Zhao, Yu-Cheng Chang, Yu-Kai Wang,\n  Thomas Do, Chin-Teng Lin","authorsParsed":[["Zhou","Jinzhao",""],["Duan","Yiqun",""],["Zhao","Ziyi",""],["Chang","Yu-Cheng",""],["Wang","Yu-Kai",""],["Do","Thomas",""],["Lin","Chin-Teng",""]],"versions":[{"version":"v1","created":"Thu, 8 Aug 2024 03:40:25 GMT"}],"updateDate":"2024-08-12","timestamp":1723088425000,"abstract":"  Decoding linguistic information from non-invasive brain signals using EEG has\ngained increasing research attention due to its vast applicational potential.\nRecently, a number of works have adopted a generative-based framework to decode\nelectroencephalogram (EEG) signals into sentences by utilizing the power\ngenerative capacity of pretrained large language models (LLMs). However, this\napproach has several drawbacks that hinder the further development of\nlinguistic applications for brain-computer interfaces (BCIs). Specifically, the\nability of the EEG encoder to learn semantic information from EEG data remains\nquestionable, and the LLM decoder's tendency to generate sentences based on its\ntraining memory can be hard to avoid. These issues necessitate a novel approach\nfor converting EEG signals into sentences. In this paper, we propose a novel\ntwo-step pipeline that addresses these limitations and enhances the validity of\nlinguistic EEG decoding research. We first confirm that word-level semantic\ninformation can be learned from EEG data recorded during natural reading by\ntraining a Conformer encoder via a masked contrastive objective for word-level\nclassification. To achieve sentence decoding results, we employ a training-free\nretrieval method to retrieve sentences based on the predictions from the EEG\nencoder. Extensive experiments and ablation studies were conducted in this\npaper for a comprehensive evaluation of the proposed approach. Visualization of\nthe top prediction candidates reveals that our model effectively groups EEG\nsegments into semantic categories with similar meanings, thereby validating its\nability to learn patterns from unspoken EEG recordings. Despite the exploratory\nnature of this work, these results suggest that our method holds promise for\nproviding more reliable solutions for converting EEG signals into text.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"cwqNg9RowL8QMbfYCX5LcyAivXnMk8eLcZB69T4t4lA","pdfSize":"8763653"}
