{"id":"2407.20899","title":"Faithful and Plausible Natural Language Explanations for Image\n  Classification: A Pipeline Approach","authors":"Adam Wojciechowski, Mateusz Lango, Ondrej Dusek","authorsParsed":[["Wojciechowski","Adam",""],["Lango","Mateusz",""],["Dusek","Ondrej",""]],"versions":[{"version":"v1","created":"Tue, 30 Jul 2024 15:17:15 GMT"}],"updateDate":"2024-07-31","timestamp":1722352635000,"abstract":"  Existing explanation methods for image classification struggle to provide\nfaithful and plausible explanations. This paper addresses this issue by\nproposing a post-hoc natural language explanation method that can be applied to\nany CNN-based classifier without altering its training process or affecting\npredictive performance. By analysing influential neurons and the corresponding\nactivation maps, the method generates a faithful description of the\nclassifier's decision process in the form of a structured meaning\nrepresentation, which is then converted into text by a language model. Through\nthis pipeline approach, the generated explanations are grounded in the neural\nnetwork architecture, providing accurate insight into the classification\nprocess while remaining accessible to non-experts. Experimental results show\nthat the NLEs constructed by our method are significantly more plausible and\nfaithful. In particular, user interventions in the neural network structure\n(masking of neurons) are three times more effective than the baselines.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"uCmdyPiIekO2GtZauEAzGM2bw9TPABQ1MKNFvcjWQ_0","pdfSize":"1973983","objectId":"0xb69b0473f6fd904a6f4ae585a0e919c94f92228d38c60ae1fd59dcca751122f7","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
