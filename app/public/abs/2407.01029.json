{"id":"2407.01029","title":"EndoSparse: Real-Time Sparse View Synthesis of Endoscopic Scenes using\n  Gaussian Splatting","authors":"Chenxin Li, Brandon Y. Feng, Yifan Liu, Hengyu Liu, Cheng Wang, Weihao\n  Yu, Yixuan Yuan","authorsParsed":[["Li","Chenxin",""],["Feng","Brandon Y.",""],["Liu","Yifan",""],["Liu","Hengyu",""],["Wang","Cheng",""],["Yu","Weihao",""],["Yuan","Yixuan",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 07:24:09 GMT"}],"updateDate":"2024-07-02","timestamp":1719818649000,"abstract":"  3D reconstruction of biological tissues from a collection of endoscopic\nimages is a key to unlock various important downstream surgical applications\nwith 3D capabilities. Existing methods employ various advanced neural rendering\ntechniques for photorealistic view synthesis, but they often struggle to\nrecover accurate 3D representations when only sparse observations are\navailable, which is usually the case in real-world clinical scenarios. To\ntackle this {sparsity} challenge, we propose a framework leveraging the prior\nknowledge from multiple foundation models during the reconstruction process,\ndubbed as \\textit{EndoSparse}. Experimental results indicate that our proposed\nstrategy significantly improves the geometric and appearance quality under\nchallenging sparse-view conditions, including using only three views. In\nrigorous benchmarking experiments against state-of-the-art methods,\n\\textit{EndoSparse} achieves superior results in terms of accurate geometry,\nrealistic appearance, and rendering efficiency, confirming the robustness to\nsparse-view limitations in endoscopic reconstruction. \\textit{EndoSparse}\nsignifies a steady step towards the practical deployment of neural 3D\nreconstruction in real-world clinical scenarios. Project page:\nhttps://endo-sparse.github.io/.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}