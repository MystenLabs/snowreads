{"id":"2407.08861","title":"A Hybrid Spiking-Convolutional Neural Network Approach for Advancing\n  Machine Learning Models","authors":"Sanaullah, Kaushik Roy, Ulrich R\\\"uckert, and Thorsten Jungeblut","authorsParsed":[["Sanaullah","",""],["Roy","Kaushik",""],["RÃ¼ckert","Ulrich",""],["Jungeblut","Thorsten",""]],"versions":[{"version":"v1","created":"Thu, 11 Jul 2024 20:50:33 GMT"}],"updateDate":"2024-07-15","timestamp":1720731033000,"abstract":"  In this article, we propose a novel standalone hybrid Spiking-Convolutional\nNeural Network (SC-NN) model and test on using image inpainting tasks. Our\napproach uses the unique capabilities of SNNs, such as event-based computation\nand temporal processing, along with the strong representation learning\nabilities of CNNs, to generate high-quality inpainted images. The model is\ntrained on a custom dataset specifically designed for image inpainting, where\nmissing regions are created using masks. The hybrid model consists of SNNConv2d\nlayers and traditional CNN layers. The SNNConv2d layers implement the leaky\nintegrate-and-fire (LIF) neuron model, capturing spiking behavior, while the\nCNN layers capture spatial features. In this study, a mean squared error (MSE)\nloss function demonstrates the training process, where a training loss value of\n0.015, indicates accurate performance on the training set and the model\nachieved a validation loss value as low as 0.0017 on the testing set.\nFurthermore, extensive experimental results demonstrate state-of-the-art\nperformance, showcasing the potential of integrating temporal dynamics and\nfeature extraction in a single network for image inpainting.\n","subjects":["Computing Research Repository/Neural and Evolutionary Computing","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/"}