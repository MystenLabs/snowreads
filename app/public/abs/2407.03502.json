{"id":"2407.03502","title":"AgentInstruct: Toward Generative Teaching with Agentic Flows","authors":"Arindam Mitra, Luciano Del Corro, Guoqing Zheng, Shweti Mahajan, Dany\n  Rouhana, Andres Codas, Yadong Lu, Wei-ge Chen, Olga Vrousgos, Corby Rosset,\n  Fillipe Silva, Hamed Khanpour, Yash Lara, Ahmed Awadallah","authorsParsed":[["Mitra","Arindam",""],["Del Corro","Luciano",""],["Zheng","Guoqing",""],["Mahajan","Shweti",""],["Rouhana","Dany",""],["Codas","Andres",""],["Lu","Yadong",""],["Chen","Wei-ge",""],["Vrousgos","Olga",""],["Rosset","Corby",""],["Silva","Fillipe",""],["Khanpour","Hamed",""],["Lara","Yash",""],["Awadallah","Ahmed",""]],"versions":[{"version":"v1","created":"Wed, 3 Jul 2024 21:01:12 GMT"}],"updateDate":"2024-07-08","timestamp":1720040472000,"abstract":"  Synthetic data is becoming increasingly important for accelerating the\ndevelopment of language models, both large and small. Despite several\nsuccessful use cases, researchers also raised concerns around model collapse\nand drawbacks of imitating other models. This discrepancy can be attributed to\nthe fact that synthetic data varies in quality and diversity. Effective use of\nsynthetic data usually requires significant human effort in curating the data.\nWe focus on using synthetic data for post-training, specifically creating data\nby powerful models to teach a new skill or behavior to another model, we refer\nto this setting as Generative Teaching. We introduce AgentInstruct, an\nextensible agentic framework for automatically creating large amounts of\ndiverse and high-quality synthetic data. AgentInstruct can create both the\nprompts and responses, using only raw data sources like text documents and code\nfiles as seeds. We demonstrate the utility of AgentInstruct by creating a post\ntraining dataset of 25M pairs to teach language models different skills, such\nas text editing, creative writing, tool usage, coding, reading comprehension,\netc. The dataset can be used for instruction tuning of any base model. We\npost-train Mistral-7b with the data. When comparing the resulting model Orca-3\nto Mistral-7b-Instruct (which uses the same base model), we observe significant\nimprovements across many benchmarks. For example, 40% improvement on AGIEval,\n19% improvement on MMLU, 54% improvement on GSM8K, 38% improvement on BBH and\n45% improvement on AlpacaEval. Additionally, it consistently outperforms other\nmodels such as LLAMA-8B-instruct and GPT-3.5-turbo.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}