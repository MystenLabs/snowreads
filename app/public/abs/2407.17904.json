{"id":"2407.17904","title":"Exploring the Effect of Dataset Diversity in Self-Supervised Learning\n  for Surgical Computer Vision","authors":"Tim J.M. Jaspers, Ronald L.P.D. de Jong, Yasmina Al Khalil, Tijn\n  Zeelenberg, Carolus H.J. Kusters, Yiping Li, Romy C. van Jaarsveld,\n  Franciscus H.A. Bakker, Jelle P. Ruurda, Willem M. Brinkman, Peter H.N. De\n  With, Fons van der Sommen","authorsParsed":[["Jaspers","Tim J. M.",""],["de Jong","Ronald L. P. D.",""],["Khalil","Yasmina Al",""],["Zeelenberg","Tijn",""],["Kusters","Carolus H. J.",""],["Li","Yiping",""],["van Jaarsveld","Romy C.",""],["Bakker","Franciscus H. A.",""],["Ruurda","Jelle P.",""],["Brinkman","Willem M.",""],["De With","Peter H. N.",""],["van der Sommen","Fons",""]],"versions":[{"version":"v1","created":"Thu, 25 Jul 2024 09:49:04 GMT"},{"version":"v2","created":"Fri, 26 Jul 2024 08:33:23 GMT"}],"updateDate":"2024-07-29","timestamp":1721900944000,"abstract":"  Over the past decade, computer vision applications in minimally invasive\nsurgery have rapidly increased. Despite this growth, the impact of surgical\ncomputer vision remains limited compared to other medical fields like pathology\nand radiology, primarily due to the scarcity of representative annotated data.\nWhereas transfer learning from large annotated datasets such as ImageNet has\nbeen conventionally the norm to achieve high-performing models, recent\nadvancements in self-supervised learning (SSL) have demonstrated superior\nperformance. In medical image analysis, in-domain SSL pretraining has already\nbeen shown to outperform ImageNet-based initialization. Although unlabeled data\nin the field of surgical computer vision is abundant, the diversity within this\ndata is limited. This study investigates the role of dataset diversity in SSL\nfor surgical computer vision, comparing procedure-specific datasets against a\nmore heterogeneous general surgical dataset across three different downstream\nsurgical applications. The obtained results show that using solely\nprocedure-specific data can lead to substantial improvements of 13.8%, 9.5%,\nand 36.8% compared to ImageNet pretraining. However, extending this data with\nmore heterogeneous surgical data further increases performance by an additional\n5.0%, 5.2%, and 2.5%, suggesting that increasing diversity within SSL data is\nbeneficial for model performance. The code and pretrained model weights are\nmade publicly available at https://github.com/TimJaspers0801/SurgeNet.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"jfq-dcugh93uLXjlS9Mbinhr4bniBIQT4IHvojkhEIY","pdfSize":"4232859"}
