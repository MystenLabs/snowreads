{"id":"2408.07576","title":"MetaSeg: MetaFormer-based Global Contexts-aware Network for Efficient\n  Semantic Segmentation","authors":"Beoungwoo Kang, Seunghun Moon, Yubin Cho, Hyunwoo Yu, Suk-Ju Kang","authorsParsed":[["Kang","Beoungwoo",""],["Moon","Seunghun",""],["Cho","Yubin",""],["Yu","Hyunwoo",""],["Kang","Suk-Ju",""]],"versions":[{"version":"v1","created":"Wed, 14 Aug 2024 14:16:52 GMT"},{"version":"v2","created":"Thu, 15 Aug 2024 03:55:11 GMT"}],"updateDate":"2024-08-16","timestamp":1723645012000,"abstract":"  Beyond the Transformer, it is important to explore how to exploit the\ncapacity of the MetaFormer, an architecture that is fundamental to the\nperformance improvements of the Transformer. Previous studies have exploited it\nonly for the backbone network. Unlike previous studies, we explore the capacity\nof the Metaformer architecture more extensively in the semantic segmentation\ntask. We propose a powerful semantic segmentation network, MetaSeg, which\nleverages the Metaformer architecture from the backbone to the decoder. Our\nMetaSeg shows that the MetaFormer architecture plays a significant role in\ncapturing the useful contexts for the decoder as well as for the backbone. In\naddition, recent segmentation methods have shown that using a CNN-based\nbackbone for extracting the spatial information and a decoder for extracting\nthe global information is more effective than using a transformer-based\nbackbone with a CNN-based decoder. This motivates us to adopt the CNN-based\nbackbone using the MetaFormer block and design our MetaFormer-based decoder,\nwhich consists of a novel self-attention module to capture the global contexts.\nTo consider both the global contexts extraction and the computational\nefficiency of the self-attention for semantic segmentation, we propose a\nChannel Reduction Attention (CRA) module that reduces the channel dimension of\nthe query and key into the one dimension. In this way, our proposed MetaSeg\noutperforms the previous state-of-the-art methods with more efficient\ncomputational costs on popular semantic segmentation and a medical image\nsegmentation benchmark, including ADE20K, Cityscapes, COCO-stuff, and Synapse.\nThe code is available at https://github.com/hyunwoo137/MetaSeg.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"8KSRtmZej92BIzW7g9m1q7wcAd1YLEosGS5OnBtksSY","pdfSize":"11701409"}
