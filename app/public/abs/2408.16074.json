{"id":"2408.16074","title":"Verification methods for international AI agreements","authors":"Akash R. Wasil, Tom Reed, Jack William Miller, Peter Barnett","authorsParsed":[["Wasil","Akash R.",""],["Reed","Tom",""],["Miller","Jack William",""],["Barnett","Peter",""]],"versions":[{"version":"v1","created":"Wed, 28 Aug 2024 18:15:19 GMT"}],"updateDate":"2024-08-30","timestamp":1724868919000,"abstract":"  What techniques can be used to verify compliance with international\nagreements about advanced AI development? In this paper, we examine 10\nverification methods that could detect two types of potential violations:\nunauthorized AI training (e.g., training runs above a certain FLOP threshold)\nand unauthorized data centers. We divide the verification methods into three\ncategories: (a) national technical means (methods requiring minimal or no\naccess from suspected non-compliant nations), (b) access-dependent methods\n(methods that require approval from the nation suspected of unauthorized\nactivities), and (c) hardware-dependent methods (methods that require rules\naround advanced hardware). For each verification method, we provide a\ndescription, historical precedents, and possible evasion techniques. We\nconclude by offering recommendations for future work related to the\nverification and enforcement of international AI governance agreements.\n","subjects":["Computing Research Repository/Computers and Society","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}