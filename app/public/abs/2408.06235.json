{"id":"2408.06235","title":"Correlation Weighted Prototype-based Self-Supervised One-Shot\n  Segmentation of Medical Images","authors":"Siladittya Manna, Saumik Bhattacharya and Umapada Pal","authorsParsed":[["Manna","Siladittya",""],["Bhattacharya","Saumik",""],["Pal","Umapada",""]],"versions":[{"version":"v1","created":"Mon, 12 Aug 2024 15:38:51 GMT"}],"updateDate":"2024-08-13","timestamp":1723477131000,"abstract":"  Medical image segmentation is one of the domains where sufficient annotated\ndata is not available. This necessitates the application of low-data frameworks\nlike few-shot learning. Contemporary prototype-based frameworks often do not\naccount for the variation in features within the support and query images,\ngiving rise to a large variance in prototype alignment. In this work, we adopt\na prototype-based self-supervised one-way one-shot learning framework using\npseudo-labels generated from superpixels to learn the semantic segmentation\ntask itself. We use a correlation-based probability score to generate a dynamic\nprototype for each query pixel from the bag of prototypes obtained from the\nsupport feature map. This weighting scheme helps to give a higher weightage to\ncontextually related prototypes. We also propose a quadrant masking strategy in\nthe downstream segmentation task by utilizing prior domain information to\ndiscard unwanted false positives. We present extensive experimentations and\nevaluations on abdominal CT and MR datasets to show that the proposed simple\nbut potent framework performs at par with the state-of-the-art methods.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}