{"id":"2407.07700","title":"Split Conformal Prediction under Data Contamination","authors":"Jase Clarkson, Wenkai Xu, Mihai Cucuringu, Gesine Reinert","authorsParsed":[["Clarkson","Jase",""],["Xu","Wenkai",""],["Cucuringu","Mihai",""],["Reinert","Gesine",""]],"versions":[{"version":"v1","created":"Wed, 10 Jul 2024 14:33:28 GMT"},{"version":"v2","created":"Tue, 16 Jul 2024 20:52:54 GMT"}],"updateDate":"2024-07-18","timestamp":1720622008000,"abstract":"  Conformal prediction is a non-parametric technique for constructing\nprediction intervals or sets from arbitrary predictive models under the\nassumption that the data is exchangeable. It is popular as it comes with\ntheoretical guarantees on the marginal coverage of the prediction sets and the\nsplit conformal prediction variant has a very low computational cost compared\nto model training. We study the robustness of split conformal prediction in a\ndata contamination setting, where we assume a small fraction of the calibration\nscores are drawn from a different distribution than the bulk. We quantify the\nimpact of the corrupted data on the coverage and efficiency of the constructed\nsets when evaluated on \"clean\" test points, and verify our results with\nnumerical experiments. Moreover, we propose an adjustment in the classification\nsetting which we call Contamination Robust Conformal Prediction, and verify the\nefficacy of our approach using both synthetic and real datasets.\n","subjects":["Statistics/Machine Learning","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"eq6VT5JREO10TnNtC82wlJ9D_t97gF0-j3BVrCltac8","pdfSize":"462404"}
