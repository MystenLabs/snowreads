{"id":"2407.02956","title":"IncogniText: Privacy-enhancing Conditional Text Anonymization via\n  LLM-based Private Attribute Randomization","authors":"Ahmed Frikha, Nassim Walha, Krishna Kanth Nakka, Ricardo Mendes, Xue\n  Jiang, Xuebing Zhou","authorsParsed":[["Frikha","Ahmed",""],["Walha","Nassim",""],["Nakka","Krishna Kanth",""],["Mendes","Ricardo",""],["Jiang","Xue",""],["Zhou","Xuebing",""]],"versions":[{"version":"v1","created":"Wed, 3 Jul 2024 09:49:03 GMT"}],"updateDate":"2024-07-04","timestamp":1720000143000,"abstract":"  In this work, we address the problem of text anonymization where the goal is\nto prevent adversaries from correctly inferring private attributes of the\nauthor, while keeping the text utility, i.e., meaning and semantics. We propose\nIncogniText, a technique that anonymizes the text to mislead a potential\nadversary into predicting a wrong private attribute value. Our empirical\nevaluation shows a reduction of private attribute leakage by more than 90%.\nFinally, we demonstrate the maturity of IncogniText for real-world applications\nby distilling its anonymization capability into a set of LoRA parameters\nassociated with an on-device model.\n","subjects":["Computing Research Repository/Cryptography and Security","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}