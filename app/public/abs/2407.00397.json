{"id":"2407.00397","title":"Markovian Gaussian Process: A Universal State-Space Representation for\n  Stationary Temporal Gaussian Process","authors":"Weihan Li, Yule Wang, Chengrui Li, Anqi Wu","authorsParsed":[["Li","Weihan",""],["Wang","Yule",""],["Li","Chengrui",""],["Wu","Anqi",""]],"versions":[{"version":"v1","created":"Sat, 29 Jun 2024 10:50:23 GMT"}],"updateDate":"2024-07-02","timestamp":1719658223000,"abstract":"  Gaussian Processes (GPs) and Linear Dynamical Systems (LDSs) are essential\ntime series and dynamic system modeling tools. GPs can handle complex,\nnonlinear dynamics but are computationally demanding, while LDSs offer\nefficient computation but lack the expressive power of GPs. To combine their\nbenefits, we introduce a universal method that allows an LDS to mirror\nstationary temporal GPs. This state-space representation, known as the\nMarkovian Gaussian Process (Markovian GP), leverages the flexibility of kernel\nfunctions while maintaining efficient linear computation. Unlike existing\nGP-LDS conversion methods, which require separability for most multi-output\nkernels, our approach works universally for single- and multi-output stationary\ntemporal kernels. We evaluate our method by computing covariance, performing\nregression tasks, and applying it to a neuroscience application, demonstrating\nthat our method provides an accurate state-space representation for stationary\ntemporal GPs.\n","subjects":["Computing Research Repository/Machine Learning","Statistics/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}