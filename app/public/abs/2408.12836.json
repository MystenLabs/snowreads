{"id":"2408.12836","title":"An Architectural Error Metric for CNN-Oriented Approximate Multipliers","authors":"Ao Liu, Jie Han, Qin Wang, Zhigang Mao, Honglan Jiang","authorsParsed":[["Liu","Ao",""],["Han","Jie",""],["Wang","Qin",""],["Mao","Zhigang",""],["Jiang","Honglan",""]],"versions":[{"version":"v1","created":"Fri, 23 Aug 2024 04:49:34 GMT"}],"updateDate":"2024-08-26","timestamp":1724388574000,"abstract":"  As a potential alternative for implementing the large number of\nmultiplications in convolutional neural networks (CNNs), approximate\nmultipliers (AMs) promise both high hardware efficiency and accuracy. However,\nthe characterization of accuracy and design of appropriate AMs are critical to\nan AM-based CNN (AM-CNN). In this work, the generation and propagation of\nerrors in an AM-CNN are analyzed by considering the CNN architecture. Based on\nthis analysis, a novel AM error metric is proposed to evaluate the accuracy\ndegradation of an AM-CNN, denoted as the architectural mean error (AME). The\neffectiveness of the AME is assessed in VGG and ResNet on CIFAR-10, CIFAR-100,\nand ImageNet datasets. Experimental results show that AME exhibits a strong\ncorrelation with the accuracy of AM-CNNs, outperforming the other AM error\nmetrics. To predict the accuracy of AM-CNNs, quadratic regression models are\nconstructed based on the AME; the predictions show an average of 3% deviation\nfrom the ground-truth values. Compared with a GPU-based simulation, the\nAME-based prediction is about $10^{6}\\times$ faster.\n","subjects":["Computing Research Repository/Hardware Architecture"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}