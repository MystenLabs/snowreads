{"id":"2408.02223","title":"Large Language Model Aided QoS Prediction for Service Recommendation","authors":"Huiying Liu, Zekun Zhang, Honghao Li, Qilin Wu, Yiwen Zhang","authorsParsed":[["Liu","Huiying",""],["Zhang","Zekun",""],["Li","Honghao",""],["Wu","Qilin",""],["Zhang","Yiwen",""]],"versions":[{"version":"v1","created":"Mon, 5 Aug 2024 03:54:52 GMT"},{"version":"v2","created":"Fri, 16 Aug 2024 03:18:12 GMT"}],"updateDate":"2024-08-19","timestamp":1722830092000,"abstract":"  Large language models (LLMs) have seen rapid improvement in the recent years,\nand have been used in a wider range of applications. After being trained on\nlarge text corpus, LLMs obtain the capability of extracting rich features from\ntextual data. Such capability is potentially useful for the web service\nrecommendation task, where the web users and services have intrinsic attributes\nthat can be described using natural language sentences and are useful for\nrecommendation. In this paper, we explore the possibility and practicality of\nusing LLMs for web service recommendation. We propose the large language model\naided QoS prediction (llmQoS) model, which use LLMs to extract useful\ninformation from attributes of web users and services via descriptive\nsentences. This information is then used in combination with the QoS values of\nhistorical interactions of users and services, to predict QoS values for any\ngiven user-service pair. On the WSDream dataset, llmQoS is shown to overcome\nthe data sparsity issue inherent to the QoS prediction problem, and outperforms\ncomparable baseline models consistently.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Distributed, Parallel, and Cluster Computing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}