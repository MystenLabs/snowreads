{"id":"2408.12333","title":"Graph Retrieval Augmented Trustworthiness Reasoning","authors":"Ying Zhu, Shengchang Li, Ziqian Kong, Peilan Xu","authorsParsed":[["Zhu","Ying",""],["Li","Shengchang",""],["Kong","Ziqian",""],["Xu","Peilan",""]],"versions":[{"version":"v1","created":"Thu, 22 Aug 2024 12:21:22 GMT"},{"version":"v2","created":"Wed, 4 Sep 2024 12:00:25 GMT"}],"updateDate":"2024-09-05","timestamp":1724329282000,"abstract":"  Trustworthiness reasoning is crucial in multiplayer games with incomplete\ninformation, enabling agents to identify potential allies and adversaries,\nthereby enhancing reasoning and decision-making processes. Traditional\napproaches relying on pre-trained models necessitate extensive domain-specific\ndata and considerable reward feedback, with their lack of real-time\nadaptability hindering their effectiveness in dynamic environments. In this\npaper, we introduce the Graph Retrieval Augmented Reasoning (GRATR) framework,\nleveraging the Retrieval-Augmented Generation (RAG) technique to bolster\ntrustworthiness reasoning in agents. GRATR constructs a dynamic trustworthiness\ngraph, updating it in real-time with evidential information, and retrieves\nrelevant trust data to augment the reasoning capabilities of Large Language\nModels (LLMs). We validate our approach through experiments on the multiplayer\ngame \"Werewolf,\" comparing GRATR against baseline LLM and LLM enhanced with\nNative RAG and Rerank RAG. Our results demonstrate that GRATR surpasses the\nbaseline methods by over 30\\% in winning rate, with superior reasoning\nperformance. Moreover, GRATR effectively mitigates LLM hallucinations, such as\nidentity and objective amnesia, and crucially, it renders the reasoning process\nmore transparent and traceable through the use of the trustworthiness graph.\n","subjects":["Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}