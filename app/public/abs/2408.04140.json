{"id":"2408.04140","title":"UNLEARN Efficient Removal of Knowledge in Large Language Models","authors":"Tyler Lizzo and Larry Heck","authorsParsed":[["Lizzo","Tyler",""],["Heck","Larry",""]],"versions":[{"version":"v1","created":"Thu, 8 Aug 2024 00:53:31 GMT"}],"updateDate":"2024-08-09","timestamp":1723078411000,"abstract":"  Given the prevalence of large language models (LLMs) and the prohibitive cost\nof training these models from scratch, dynamically forgetting specific\nknowledge e.g., private or proprietary, without retraining the model has become\nan important capability. This paper proposes a novel method to achieve this\nobjective called UNLEARN. The approach builds upon subspace methods to identify\nand specifically target the removal of knowledge without adversely affecting\nother knowledge in the LLM. Results demonstrate 96% of targeted knowledge can\nbe forgotten while maintaining performance on other knowledge within 2.5% of\nthe original model, significantly outperforming the discriminatory abilities of\nthe previous state-of-the-art. A dual method called LEARN is also proposed for\ntargeted knowledge addition. Results show LEARN can match the fine-tuning\naccuracy of Low-Rank Adaptation (LoRA) without adversely affecting similar\ntasks.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}