{"id":"2408.16939","title":"Theoretical Insights into Overparameterized Models in Multi-Task and\n  Replay-Based Continual Learning","authors":"Mohammadamin Banayeeanzade, Mahdi Soltanolkotabi, Mohammad Rostami","authorsParsed":[["Banayeeanzade","Mohammadamin",""],["Soltanolkotabi","Mahdi",""],["Rostami","Mohammad",""]],"versions":[{"version":"v1","created":"Thu, 29 Aug 2024 23:22:40 GMT"}],"updateDate":"2024-09-02","timestamp":1724973760000,"abstract":"  Multi-task learning (MTL) is a machine learning paradigm that aims to improve\nthe generalization performance of a model on multiple related tasks by training\nit simultaneously on those tasks. Unlike MTL, where the model has instant\naccess to the training data of all tasks, continual learning (CL) involves\nadapting to new sequentially arriving tasks over time without forgetting the\npreviously acquired knowledge. Despite the wide practical adoption of CL and\nMTL and extensive literature on both areas, there remains a gap in the\ntheoretical understanding of these methods when used with overparameterized\nmodels such as deep neural networks. This paper studies the overparameterized\nlinear models as a proxy for more complex models. We develop theoretical\nresults describing the effect of various system parameters on the model's\nperformance in an MTL setup. Specifically, we study the impact of model size,\ndataset size, and task similarity on the generalization error and knowledge\ntransfer. Additionally, we present theoretical results to characterize the\nperformance of replay-based CL models. Our results reveal the impact of buffer\nsize and model capacity on the forgetting rate in a CL setup and help shed\nlight on some of the state-of-the-art CL methods. Finally, through extensive\nempirical evaluations, we demonstrate that our theoretical findings are also\napplicable to deep neural networks, offering valuable guidance for designing\nMTL and CL models in practice.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}