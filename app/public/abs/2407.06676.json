{"id":"2407.06676","title":"Games played by Exponential Weights Algorithms","authors":"Maurizio d'Andrea, Fabien Gensbittel (TSE-R), J\\'er\\^ome Renault\n  (TSE-R)","authorsParsed":[["d'Andrea","Maurizio","","TSE-R"],["Gensbittel","Fabien","","TSE-R"],["Renault","Jérôme","","TSE-R"]],"versions":[{"version":"v1","created":"Tue, 9 Jul 2024 08:49:51 GMT"}],"updateDate":"2024-07-10","timestamp":1720514991000,"abstract":"  This paper studies the last-iterate convergence properties of the exponential\nweights algorithm with constant learning rates. We consider a repeated\ninteraction in discrete time, where each player uses an exponential weights\nalgorithm characterized by an initial mixed action and a fixed learning rate,\nso that the mixed action profile $p^t$ played at stage $t$ follows an\nhomogeneous Markov chain. At first, we show that whenever a strict Nash\nequilibrium exists, the probability to play a strict Nash equilibrium at the\nnext stage converges almost surely to 0 or 1. Secondly, we show that the limit\nof $p^t$, whenever it exists, belongs to the set of ``Nash Equilibria with\nEqualizing Payoffs''. Thirdly, we show that in strong coordination games, where\nthe payoff of a player is positive on the diagonal and 0 elsewhere, $p^t$\nconverges almost surely to one of the strict Nash equilibria. We conclude with\nopen questions.\n","subjects":["Computing Research Repository/Artificial Intelligence","Mathematics/Probability"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}