{"id":"2407.12396","title":"Private and Federated Stochastic Convex Optimization: Efficient\n  Strategies for Centralized Systems","authors":"Roie Reshef and Kfir Y. Levy","authorsParsed":[["Reshef","Roie",""],["Levy","Kfir Y.",""]],"versions":[{"version":"v1","created":"Wed, 17 Jul 2024 08:19:58 GMT"}],"updateDate":"2024-07-18","timestamp":1721204398000,"abstract":"  This paper addresses the challenge of preserving privacy in Federated\nLearning (FL) within centralized systems, focusing on both trusted and\nuntrusted server scenarios. We analyze this setting within the Stochastic\nConvex Optimization (SCO) framework, and devise methods that ensure\nDifferential Privacy (DP) while maintaining optimal convergence rates for\nhomogeneous and heterogeneous data distributions. Our approach, based on a\nrecent stochastic optimization technique, offers linear computational\ncomplexity, comparable to non-private FL methods, and reduced gradient\nobfuscation. This work enhances the practicality of DP in FL, balancing\nprivacy, efficiency, and robustness in a variety of server trust environment.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}