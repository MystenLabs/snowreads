{"id":"2408.15621","title":"Convergent Differential Privacy Analysis for General Federated Learning:\n  the f-DP Perspective","authors":"Yan Sun, Li Shen, and Dacheng Tao","authorsParsed":[["Sun","Yan",""],["Shen","Li",""],["Tao","Dacheng",""]],"versions":[{"version":"v1","created":"Wed, 28 Aug 2024 08:22:21 GMT"}],"updateDate":"2024-08-29","timestamp":1724833341000,"abstract":"  Federated learning (FL) is an efficient collaborative training paradigm\nextensively developed with a focus on local privacy protection, and\ndifferential privacy (DP) is a classical approach to capture and ensure the\nreliability of local privacy. The powerful cooperation of FL and DP provides a\npromising learning framework for large-scale private clients, juggling both\nprivacy securing and trustworthy learning. As the predominant algorithm of DP,\nthe noisy perturbation has been widely studied and incorporated into various\nfederated algorithms, theoretically proven to offer significant privacy\nprotections. However, existing analyses in noisy FL-DP mostly rely on the\ncomposition theorem and cannot tightly quantify the privacy leakage challenges,\nwhich is nearly tight for small numbers of communication rounds but yields an\narbitrarily loose and divergent bound under the large communication rounds.\nThis implies a counterintuitive judgment, suggesting that FL may not provide\nadequate privacy protection during long-term training. To further investigate\nthe convergent privacy and reliability of the FL-DP framework, in this paper,\nwe comprehensively evaluate the worst privacy of two classical methods under\nthe non-convex and smooth objectives based on the f-DP analysis, i.e.\nNoisy-FedAvg and Noisy-FedProx methods. With the aid of the\nshifted-interpolation technique, we successfully prove that the worst privacy\nof the Noisy-FedAvg method achieves a tight convergent lower bound. Moreover,\nin the Noisy-FedProx method, with the regularization of the proxy term, the\nworst privacy has a stable constant lower bound. Our analysis further provides\na solid theoretical foundation for the reliability of privacy protection in\nFL-DP. Meanwhile, our conclusions can also be losslessly converted to other\nclassical DP analytical frameworks, e.g. $(\\epsilon,\\delta)$-DP and\nR$\\acute{\\text{e}}$nyi-DP (RDP).\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Cryptography and Security"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"6RcEyjMCiKpUWN5ab_QEHN69pA2t5facHF2UOW_nqbY","pdfSize":"857549"}
