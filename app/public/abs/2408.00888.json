{"id":"2408.00888","title":"Gradient-free optimization via integration","authors":"Christophe Andrieu and Nicolas Chopin and Ettore Fincato and Mathieu\n  Gerber","authorsParsed":[["Andrieu","Christophe",""],["Chopin","Nicolas",""],["Fincato","Ettore",""],["Gerber","Mathieu",""]],"versions":[{"version":"v1","created":"Thu, 1 Aug 2024 19:36:04 GMT"}],"updateDate":"2024-08-05","timestamp":1722540964000,"abstract":"  In this paper we propose a novel, general purpose, algorithm to optimize\nfunctions $l\\colon \\mathbb{R}^d \\rightarrow \\mathbb{R}$ not assumed to be\nconvex or differentiable or even continuous. The main idea is to sequentially\nfit a sequence of parametric probability densities, possessing a concentration\nproperty, to $l$ using a Bayesian update followed by a reprojection back onto\nthe chosen parametric sequence. Remarkably, with the sequence chosen to be from\nthe exponential family, reprojection essentially boils down to the computation\nof expectations. Our algorithm therefore lends itself to Monte Carlo\napproximation, ranging from plain to Sequential Monte Carlo (SMC) methods.\n  The algorithm is therefore particularly simple to implement and we illustrate\nperformance on a challenging Machine Learning classification problem. Our\nmethodology naturally extends to the scenario where only noisy measurements of\n$l$ are available and retains ease of implementation and performance. At a\ntheoretical level we establish, in a fairly general scenario, that our\nframework can be viewed as implicitly implementing a time inhomogeneous\ngradient descent algorithm on a sequence of smoothed approximations of $l$.\nThis opens the door to establishing convergence of the algorithm and provide\ntheoretical guarantees. Along the way, we establish new results for\ninhomogeneous gradient descent algorithms of independent interest.\n","subjects":["Statistics/Computation"],"license":"http://creativecommons.org/licenses/by-sa/4.0/","blobId":"UuiJK7HHrAwYFikHJx1Au4fuf5HALWm7sP9W0hMn06Q","pdfSize":"5530403"}
