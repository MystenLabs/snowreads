{"id":"2408.02391","title":"Kullback-Leibler-based characterizations of score-driven updates","authors":"Ramon de Punder, Timo Dimitriadis, Rutger-Jan Lange","authorsParsed":[["de Punder","Ramon",""],["Dimitriadis","Timo",""],["Lange","Rutger-Jan",""]],"versions":[{"version":"v1","created":"Mon, 5 Aug 2024 11:35:11 GMT"},{"version":"v2","created":"Fri, 13 Sep 2024 09:37:54 GMT"}],"updateDate":"2024-09-16","timestamp":1722857711000,"abstract":"  Score-driven models have been applied in some 400 published articles over the\nlast decade. Much of this literature cites the optimality result in Blasques et\nal. (2015), which, roughly, states that sufficiently small score-driven updates\nare unique in locally reducing the Kullback-Leibler divergence relative to the\ntrue density for every observation. This is at odds with other well-known\noptimality results; the Kalman filter, for example, is optimal in a\nmean-squared-error sense, but occasionally moves away from the true state. We\nshow that score-driven updates are, similarly, not guaranteed to improve the\nlocalized Kullback-Leibler divergence at every observation. The seemingly\nstronger result in Blasques et al. (2015) is due to their use of an improper\n(localized) scoring rule. Even as a guaranteed improvement for every\nobservation is unattainable, we prove that sufficiently small score-driven\nupdates are unique in reducing the Kullback-Leibler divergence relative to the\ntrue density in expectation. This positive, albeit weaker, result justifies the\ncontinued use of score-driven models and places their information-theoretic\nproperties on solid footing.\n","subjects":["Mathematics/Statistics Theory","Economics/Econometrics","Statistics/Statistics Theory"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}