{"id":"2408.17072","title":"MaFeRw: Query Rewriting with Multi-Aspect Feedbacks for\n  Retrieval-Augmented Large Language Models","authors":"Yujing Wang, Hainan Zhang, Liang Pang, Liang Pang, Hongwei Zheng,\n  Zhiming Zheng","authorsParsed":[["Wang","Yujing",""],["Zhang","Hainan",""],["Pang","Liang",""],["Pang","Liang",""],["Zheng","Hongwei",""],["Zheng","Zhiming",""]],"versions":[{"version":"v1","created":"Fri, 30 Aug 2024 07:57:30 GMT"}],"updateDate":"2024-09-02","timestamp":1725004650000,"abstract":"  In a real-world RAG system, the current query often involves spoken ellipses\nand ambiguous references from dialogue contexts, necessitating query rewriting\nto better describe user's information needs. However, traditional context-based\nrewriting has minimal enhancement on downstream generation tasks due to the\nlengthy process from query rewriting to response generation. Some researchers\ntry to utilize reinforcement learning with generation feedback to assist the\nrewriter, but these sparse rewards provide little guidance in most cases,\nleading to unstable training and generation results. We find that user's needs\nare also reflected in the gold document, retrieved documents and ground truth.\nTherefore, by feeding back these multi-aspect dense rewards to query rewriting,\nmore stable and satisfactory responses can be achieved. In this paper, we\npropose a novel query rewriting method MaFeRw, which improves RAG performance\nby integrating multi-aspect feedback from both the retrieval process and\ngenerated results. Specifically, we first use manual data to train a T5 model\nfor the rewriter initialization. Next, we design three metrics as reinforcement\nlearning feedback: the similarity between the rewritten query and the gold\ndocument, the ranking metrics, and ROUGE between the generation and the ground\ntruth. Inspired by RLAIF, we train three kinds of reward models for the above\nmetrics to achieve more efficient training. Finally, we combine the scores of\nthese reward models as feedback, and use PPO algorithm to explore the optimal\nquery rewriting strategy. Experimental results on two conversational RAG\ndatasets demonstrate that MaFeRw achieves superior generation metrics and more\nstable training compared to baselines.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}