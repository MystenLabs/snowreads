{"id":"2408.07537","title":"Usefulness of data flow diagrams and large language models for security\n  threat validation: a registered report","authors":"Winnie Bahati Mbaka and Katja Tuma","authorsParsed":[["Mbaka","Winnie Bahati",""],["Tuma","Katja",""]],"versions":[{"version":"v1","created":"Wed, 14 Aug 2024 13:14:27 GMT"},{"version":"v2","created":"Thu, 15 Aug 2024 09:30:35 GMT"}],"updateDate":"2024-08-16","timestamp":1723641267000,"abstract":"  The arrival of recent cybersecurity standards has raised the bar for security\nassessments in organizations, but existing techniques don't always scale well.\nThreat analysis and risk assessment are used to identify security threats for\nnew or refactored systems. Still, there is a lack of definition-of-done, so\nidentified threats have to be validated which slows down the analysis. Existing\nliterature has focused on the overall performance of threat analysis, but no\nprevious work has investigated how deep must the analysts dig into the material\nbefore they can effectively validate the identified security threats. We\npropose a controlled experiment with practitioners to investigate whether some\nanalysis material (like LLM-generated advice) is better than none and whether\nmore material (the system's data flow diagram and LLM-generated advice) is\nbetter than some material. In addition, we present key findings from running a\npilot with 41 MSc students, which are used to improve the study design.\nFinally, we also provide an initial replication package, including experimental\nmaterial and data analysis scripts and a plan to extend it to include new\nmaterials based on the final data collection campaign with practitioners (e.g.,\npre-screening questions).\n","subjects":["Computing Research Repository/Software Engineering"],"license":"http://creativecommons.org/licenses/by/4.0/"}