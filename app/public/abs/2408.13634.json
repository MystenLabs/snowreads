{"id":"2408.13634","title":"Enhanced Astronomical Source Classification with Integration of\n  Attention Mechanisms and Vision Transformers","authors":"Srinadh Reddy Bhavanam, Sumohana S. Channappayya, P.K. Srijith,\n  Shantanu Desai","authorsParsed":[["Bhavanam","Srinadh Reddy",""],["Channappayya","Sumohana S.",""],["Srijith","P. K.",""],["Desai","Shantanu",""]],"versions":[{"version":"v1","created":"Sat, 24 Aug 2024 17:28:45 GMT"}],"updateDate":"2024-08-29","timestamp":1724520525000,"abstract":"  Accurate classification of celestial objects is essential for advancing our\nunderstanding of the universe. MargNet is a recently developed deep\nlearning-based classifier applied to SDSS DR16 dataset to segregate stars,\nquasars, and compact galaxies using photometric data. MargNet utilizes a\nstacked architecture, combining a Convolutional Neural Network (CNN) for image\nmodelling and an Artificial Neural Network (ANN) for modelling photometric\nparameters. In this study, we propose enhancing MargNet's performance by\nincorporating attention mechanisms and Vision Transformer (ViT)-based models\nfor processing image data. The attention mechanism allows the model to focus on\nrelevant features and capture intricate patterns within images, effectively\ndistinguishing between different classes of celestial objects. Additionally, we\nleverage ViTs, a transformer-based deep learning architecture renowned for\nexceptional performance in image classification tasks. We enhance the model's\nunderstanding of complex astronomical images by utilizing ViT's ability to\ncapture global dependencies and contextual information. Our approach uses a\ncurated dataset comprising 240,000 compact and 150,000 faint objects. The\nmodels learn classification directly from the data, minimizing human\nintervention. Furthermore, we explore ViT as a hybrid architecture that uses\nphotometric features and images together as input to predict astronomical\nobjects. Our results demonstrate that the proposed attention mechanism\naugmented CNN in MargNet marginally outperforms the traditional MargNet and the\nproposed ViT-based MargNet models. Additionally, the ViT-based hybrid model\nemerges as the most lightweight and easy-to-train model with classification\naccuracy similar to that of the best-performing attention-enhanced MargNet.\n","subjects":["Astrophysics/Instrumentation and Methods for Astrophysics"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"fgXDn5eVHEdsQPAYQmgEJDFoE0g_I5-QfcGmsuK0DNA","pdfSize":"1823783"}
