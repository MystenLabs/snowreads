{"id":"2408.02888","title":"VizECGNet: Visual ECG Image Network for Cardiovascular Diseases\n  Classification with Multi-Modal Training and Knowledge Distillation","authors":"Ju-Hyeon Nam, Seo-Hyung Park, Su Jung Kim, Sang-Chul Lee","authorsParsed":[["Nam","Ju-Hyeon",""],["Park","Seo-Hyung",""],["Kim","Su Jung",""],["Lee","Sang-Chul",""]],"versions":[{"version":"v1","created":"Tue, 6 Aug 2024 01:34:43 GMT"}],"updateDate":"2024-08-07","timestamp":1722908083000,"abstract":"  An electrocardiogram (ECG) captures the heart's electrical signal to assess\nvarious heart conditions. In practice, ECG data is stored as either digitized\nsignals or printed images. Despite the emergence of numerous deep learning\nmodels for digitized signals, many hospitals prefer image storage due to cost\nconsiderations. Recognizing the unavailability of raw ECG signals in many\nclinical settings, we propose VizECGNet, which uses only printed ECG graphics\nto determine the prognosis of multiple cardiovascular diseases. During\ntraining, cross-modal attention modules (CMAM) are used to integrate\ninformation from two modalities - image and signal, while self-modality\nattention modules (SMAM) capture inherent long-range dependencies in ECG data\nof each modality. Additionally, we utilize knowledge distillation to improve\nthe similarity between two distinct predictions from each modality stream. This\ninnovative multi-modal deep learning architecture enables the utilization of\nonly ECG images during inference. VizECGNet with image input achieves higher\nperformance in precision, recall, and F1-Score compared to signal-based ECG\nclassification models, with improvements of 3.50%, 8.21%, and 7.38%,\nrespectively.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"_xDm_z2LKPzgVuEcYqeOZCXygQ8kse77SAmKX3YuikU","pdfSize":"2407128"}
