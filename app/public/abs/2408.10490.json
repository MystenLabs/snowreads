{"id":"2408.10490","title":"Analysis of Plan-based Retrieval for Grounded Text Generation","authors":"Ameya Godbole, Nicholas Monath, Seungyeon Kim, Ankit Singh Rawat,\n  Andrew McCallum, Manzil Zaheer","authorsParsed":[["Godbole","Ameya",""],["Monath","Nicholas",""],["Kim","Seungyeon",""],["Rawat","Ankit Singh",""],["McCallum","Andrew",""],["Zaheer","Manzil",""]],"versions":[{"version":"v1","created":"Tue, 20 Aug 2024 02:19:35 GMT"}],"updateDate":"2024-08-21","timestamp":1724120375000,"abstract":"  In text generation, hallucinations refer to the generation of seemingly\ncoherent text that contradicts established knowledge. One compelling hypothesis\nis that hallucinations occur when a language model is given a generation task\noutside its parametric knowledge (due to rarity, recency, domain, etc.). A\ncommon strategy to address this limitation is to infuse the language models\nwith retrieval mechanisms, providing the model with relevant knowledge for the\ntask. In this paper, we leverage the planning capabilities of instruction-tuned\nLLMs and analyze how planning can be used to guide retrieval to further reduce\nthe frequency of hallucinations. We empirically evaluate several variations of\nour proposed approach on long-form text generation tasks. By improving the\ncoverage of relevant facts, plan-guided retrieval and generation can produce\nmore informative responses while providing a higher rate of attribution to\nsource documents.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Information Retrieval"],"license":"http://creativecommons.org/licenses/by/4.0/"}