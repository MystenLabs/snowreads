{"id":"2408.04914","title":"GuidedNet: Semi-Supervised Multi-Organ Segmentation via Labeled Data\n  Guide Unlabeled Data","authors":"Haochen Zhao, Hui Meng, Deqian Yang, Xiaozheng Xie, Xiaoze Wu,\n  Qingfeng Li, Jianwei Niu","authorsParsed":[["Zhao","Haochen",""],["Meng","Hui",""],["Yang","Deqian",""],["Xie","Xiaozheng",""],["Wu","Xiaoze",""],["Li","Qingfeng",""],["Niu","Jianwei",""]],"versions":[{"version":"v1","created":"Fri, 9 Aug 2024 07:46:01 GMT"},{"version":"v2","created":"Mon, 2 Sep 2024 08:45:47 GMT"}],"updateDate":"2024-09-04","timestamp":1723189561000,"abstract":"  Semi-supervised multi-organ medical image segmentation aids physicians in\nimproving disease diagnosis and treatment planning and reduces the time and\neffort required for organ annotation.Existing state-of-the-art methods train\nthe labeled data with ground truths and train the unlabeled data with\npseudo-labels. However, the two training flows are separate, which does not\nreflect the interrelationship between labeled and unlabeled data.To address\nthis issue, we propose a semi-supervised multi-organ segmentation method called\nGuidedNet, which leverages the knowledge from labeled data to guide the\ntraining of unlabeled data. The primary goals of this study are to improve the\nquality of pseudo-labels for unlabeled data and to enhance the network's\nlearning capability for both small and complex organs.A key concept is that\nvoxel features from labeled and unlabeled data that are close to each other in\nthe feature space are more likely to belong to the same class.On this basis, a\n3D Consistent Gaussian Mixture Model (3D-CGMM) is designed to leverage the\nfeature distributions from labeled data to rectify the generated\npseudo-labels.Furthermore, we introduce a Knowledge Transfer Cross Pseudo\nSupervision (KT-CPS) strategy, which leverages the prior knowledge obtained\nfrom the labeled data to guide the training of the unlabeled data, thereby\nimproving the segmentation accuracy for both small and complex organs.\nExtensive experiments on two public datasets, FLARE22 and AMOS, demonstrated\nthat GuidedNet is capable of achieving state-of-the-art performance. The source\ncode with our proposed model are available at\nhttps://github.com/kimjisoo12/GuidedNet.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}