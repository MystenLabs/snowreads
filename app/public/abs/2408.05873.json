{"id":"2408.05873","title":"Defining Boundaries: A Spectrum of Task Feasibility for Large Language\n  Models","authors":"Wenbo Zhang, Zihang Xu, Hengrui Cai","authorsParsed":[["Zhang","Wenbo",""],["Xu","Zihang",""],["Cai","Hengrui",""]],"versions":[{"version":"v1","created":"Sun, 11 Aug 2024 22:58:23 GMT"}],"updateDate":"2024-08-13","timestamp":1723417103000,"abstract":"  Large language models (LLMs) have shown remarkable performance in various\ntasks but often fail to handle queries that exceed their knowledge and\ncapabilities, leading to incorrect or fabricated responses. This paper\naddresses the need for LLMs to recognize and refuse infeasible tasks due to the\nrequired skills surpassing their capabilities. We first systematically\nconceptualize infeasible tasks for LLMs, providing formal definitions and\ncategorizations that cover a spectrum of related hallucinations. We develop and\nbenchmark a new dataset comprising diverse infeasible and feasible tasks to\ntest multiple LLMs' abilities on task feasibility. Furthermore, we explore the\npotential of training enhancements to increase LLMs' refusal capabilities with\nfine-tuning. Experiments validate the effectiveness of our methods, offering\npromising directions for refining the operational boundaries of LLMs in real\napplications.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/"}