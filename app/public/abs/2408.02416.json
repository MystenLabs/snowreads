{"id":"2408.02416","title":"Why Are My Prompts Leaked? Unraveling Prompt Extraction Threats in\n  Customized Large Language Models","authors":"Zi Liang, Haibo Hu, Qingqing Ye, Yaxin Xiao, Haoyang Li","authorsParsed":[["Liang","Zi",""],["Hu","Haibo",""],["Ye","Qingqing",""],["Xiao","Yaxin",""],["Li","Haoyang",""]],"versions":[{"version":"v1","created":"Mon, 5 Aug 2024 12:20:39 GMT"}],"updateDate":"2024-08-06","timestamp":1722860439000,"abstract":"  The drastic increase of large language models' (LLMs) parameters has led to a\nnew research direction of fine-tuning-free downstream customization by prompts,\ni.e., task descriptions. While these prompt-based services (e.g. OpenAI's GPTs)\nplay an important role in many businesses, there has emerged growing concerns\nabout the prompt leakage, which undermines the intellectual properties of these\nservices and causes downstream attacks. In this paper, we analyze the\nunderlying mechanism of prompt leakage, which we refer to as prompt\nmemorization, and develop corresponding defending strategies. By exploring the\nscaling laws in prompt extraction, we analyze key attributes that influence\nprompt extraction, including model sizes, prompt lengths, as well as the types\nof prompts. Then we propose two hypotheses that explain how LLMs expose their\nprompts. The first is attributed to the perplexity, i.e. the familiarity of\nLLMs to texts, whereas the second is based on the straightforward token\ntranslation path in attention matrices. To defend against such threats, we\ninvestigate whether alignments can undermine the extraction of prompts. We find\nthat current LLMs, even those with safety alignments like GPT-4, are highly\nvulnerable to prompt extraction attacks, even under the most straightforward\nuser attacks. Therefore, we put forward several defense strategies with the\ninspiration of our findings, which achieve 83.8\\% and 71.0\\% drop in the prompt\nextraction rate for Llama2-7B and GPT-3.5, respectively. Source code is\navaliable at \\url{https://github.com/liangzid/PromptExtractionEval}.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Cryptography and Security"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"Lgmba9gGbExW9G47XT-VBMGBHr-5SCD6maq6YPw9DD4","pdfSize":"2904646"}
