{"id":"2407.01929","title":"What We Talk About When We Talk About LMs: Implicit Paradigm Shifts and\n  the Ship of Language Models","authors":"Shengqi Zhu and Jeffrey M. Rzeszotarski","authorsParsed":[["Zhu","Shengqi",""],["Rzeszotarski","Jeffrey M.",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 03:45:55 GMT"}],"updateDate":"2024-07-03","timestamp":1719891955000,"abstract":"  The term Language Models (LMs), as a time-specific collection of models of\ninterest, is constantly reinvented, with its referents updated much like the\n$\\textit{Ship of Theseus}$ replaces its parts but remains the same ship in\nessence. In this paper, we investigate this $\\textit{Ship of Language Models}$\nproblem, wherein scientific evolution takes the form of continuous, implicit\nretrofits of key existing terms. We seek to initiate a novel perspective of\nscientific progress, in addition to the more well-studied emergence of new\nterms. To this end, we construct the data infrastructure based on recent NLP\npublications. Then, we perform a series of text-based analyses toward a\ndetailed, quantitative understanding of the use of Language Models as a term of\nart. Our work highlights how systems and theories influence each other in\nscientific discourse, and we call for attention to the transformation of this\nShip that we all are contributing to.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}