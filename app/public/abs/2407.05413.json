{"id":"2407.05413","title":"SBoRA: Low-Rank Adaptation with Regional Weight Updates","authors":"Lai-Man Po, Yuyang Liu, Haoxuan Wu, Tianqi Zhang, Wing-Yin Yu, Zeyu\n  Jiang, and Kun Li","authorsParsed":[["Po","Lai-Man",""],["Liu","Yuyang",""],["Wu","Haoxuan",""],["Zhang","Tianqi",""],["Yu","Wing-Yin",""],["Jiang","Zeyu",""],["Li","Kun",""]],"versions":[{"version":"v1","created":"Sun, 7 Jul 2024 15:37:13 GMT"},{"version":"v2","created":"Wed, 10 Jul 2024 09:01:31 GMT"}],"updateDate":"2024-07-11","timestamp":1720366633000,"abstract":"  This paper introduces Standard Basis LoRA (SBoRA), a novel\nparameter-efficient fine-tuning approach for Large Language Models that builds\nupon the pioneering works of Low-Rank Adaptation (LoRA) and Orthogonal\nAdaptation. SBoRA further reduces the computational and memory requirements of\nLoRA while enhancing learning performance. By leveraging orthogonal standard\nbasis vectors to initialize one of the low-rank matrices, either A or B, SBoRA\nenables regional weight updates and memory-efficient fine-tuning. This approach\ngives rise to two variants, SBoRA-FA and SBoRA-FB, where only one of the\nmatrices is updated, resulting in a sparse update matrix with a majority of\nzero rows or columns. Consequently, the majority of the fine-tuned model's\nweights remain unchanged from the pre-trained weights. This characteristic of\nSBoRA, wherein regional weight updates occur, is reminiscent of the modular\norganization of the human brain, which efficiently adapts to new tasks. Our\nempirical results demonstrate the superiority of SBoRA-FA over LoRA in various\nfine-tuning tasks, including commonsense reasoning and arithmetic reasoning.\nFurthermore, we evaluate the effectiveness of QSBoRA on quantized LLaMA models\nof varying scales, highlighting its potential for efficient adaptation to new\ntasks. Code is available at https://github.com/cityuhkai/SBoRA\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}