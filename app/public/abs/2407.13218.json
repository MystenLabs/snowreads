{"id":"2407.13218","title":"LiNR: Model Based Neural Retrieval on GPUs at LinkedIn","authors":"Fedor Borisyuk, Qingquan Song, Mingzhou Zhou, Ganesh Parameswaran,\n  Madhu Arun, Siva Popuri, Tugrul Bingol, Zhuotao Pei, Kuang-Hsuan Lee, Lu\n  Zheng, Qizhan Shao, Ali Naqvi, Sen Zhou, Aman Gupta","authorsParsed":[["Borisyuk","Fedor",""],["Song","Qingquan",""],["Zhou","Mingzhou",""],["Parameswaran","Ganesh",""],["Arun","Madhu",""],["Popuri","Siva",""],["Bingol","Tugrul",""],["Pei","Zhuotao",""],["Lee","Kuang-Hsuan",""],["Zheng","Lu",""],["Shao","Qizhan",""],["Naqvi","Ali",""],["Zhou","Sen",""],["Gupta","Aman",""]],"versions":[{"version":"v1","created":"Thu, 18 Jul 2024 07:04:33 GMT"},{"version":"v2","created":"Mon, 22 Jul 2024 18:33:25 GMT"},{"version":"v3","created":"Wed, 7 Aug 2024 16:57:06 GMT"}],"updateDate":"2024-08-08","timestamp":1721286273000,"abstract":"  This paper introduces LiNR, LinkedIn's large-scale, GPU-based retrieval\nsystem. LiNR supports a billion-sized index on GPU models. We discuss our\nexperiences and challenges in creating scalable, differentiable search indexes\nusing TensorFlow and PyTorch at production scale. In LiNR, both items and model\nweights are integrated into the model binary. Viewing index construction as a\nform of model training, we describe scaling our system for large indexes,\nincorporating full scans and efficient filtering. A key focus is on enabling\nattribute-based pre-filtering for exhaustive GPU searches, addressing the\ncommon challenge of post-filtering in KNN searches that often reduces system\nquality. We further provide multi-embedding retrieval algorithms and strategies\nfor tackling cold start issues in retrieval. Our advancements in supporting\nlarger indexes through quantization are also discussed. We believe LiNR\nrepresents one of the industry's first Live-updated model-based retrieval\nindexes. Applied to out-of-network post recommendations on LinkedIn Feed, LiNR\nhas contributed to a 3% relative increase in professional daily active users.\nWe envisage LiNR as a step towards integrating retrieval and ranking into a\nsingle GPU model, simplifying complex infrastructures and enabling end-to-end\noptimization of the entire differentiable infrastructure through gradient\ndescent.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/"}