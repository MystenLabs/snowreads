{"id":"2408.09453","title":"Reparameterized Multi-Resolution Convolutions for Long Sequence\n  Modelling","authors":"Harry Jake Cunningham, Giorgio Giannone, Mingtian Zhang, Marc Peter\n  Deisenroth","authorsParsed":[["Cunningham","Harry Jake",""],["Giannone","Giorgio",""],["Zhang","Mingtian",""],["Deisenroth","Marc Peter",""]],"versions":[{"version":"v1","created":"Sun, 18 Aug 2024 12:20:03 GMT"}],"updateDate":"2024-08-20","timestamp":1723983603000,"abstract":"  Global convolutions have shown increasing promise as powerful general-purpose\nsequence models. However, training long convolutions is challenging, and kernel\nparameterizations must be able to learn long-range dependencies without\noverfitting. This work introduces reparameterized multi-resolution convolutions\n($\\texttt{MRConv}$), a novel approach to parameterizing global convolutional\nkernels for long-sequence modelling. By leveraging multi-resolution\nconvolutions, incorporating structural reparameterization and introducing\nlearnable kernel decay, $\\texttt{MRConv}$ learns expressive long-range kernels\nthat perform well across various data modalities. Our experiments demonstrate\nstate-of-the-art performance on the Long Range Arena, Sequential CIFAR, and\nSpeech Commands tasks among convolution models and linear-time transformers.\nMoreover, we report improved performance on ImageNet classification by\nreplacing 2D convolutions with 1D $\\texttt{MRConv}$ layers.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"6eaNcqIU6k-Qbwdccg9SeglYIzgbWnW-K7WqOP9XTCk","pdfSize":"960882"}
