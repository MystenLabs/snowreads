{"id":"2408.04639","title":"Abstractive summarization from Audio Transcription","authors":"Ilia Derkach","authorsParsed":[["Derkach","Ilia",""]],"versions":[{"version":"v1","created":"Tue, 30 Jul 2024 16:38:38 GMT"}],"updateDate":"2024-08-12","timestamp":1722357518000,"abstract":"  Currently, large language models are gaining popularity, their achievements\nare used in many areas, ranging from text translation to generating answers to\nqueries. However, the main problem with these new machine learning algorithms\nis that training such models requires large computing resources that only large\nIT companies have. To avoid this problem, a number of methods (LoRA,\nquantization) have been proposed so that existing models can be effectively\nfine-tuned for specific tasks. In this paper, we propose an E2E (end to end)\naudio summarization model using these techniques. In addition, this paper\nexamines the effectiveness of these approaches to the problem under\nconsideration and draws conclusions about the applicability of these methods.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Information Retrieval","Computing Research Repository/Machine Learning","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}