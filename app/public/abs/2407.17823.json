{"id":"2407.17823","title":"Optimal Hessian/Jacobian-Free Nonconvex-PL Bilevel Optimization","authors":"Feihu Huang","authorsParsed":[["Huang","Feihu",""]],"versions":[{"version":"v1","created":"Thu, 25 Jul 2024 07:25:06 GMT"}],"updateDate":"2024-07-26","timestamp":1721892306000,"abstract":"  Bilevel optimization is widely applied in many machine learning tasks such as\nhyper-parameter learning, meta learning and reinforcement learning. Although\nmany algorithms recently have been developed to solve the bilevel optimization\nproblems, they generally rely on the (strongly) convex lower-level problems.\nMore recently, some methods have been proposed to solve the nonconvex-PL\nbilevel optimization problems, where their upper-level problems are possibly\nnonconvex, and their lower-level problems are also possibly nonconvex while\nsatisfying Polyak-{\\L}ojasiewicz (PL) condition. However, these methods still\nhave a high convergence complexity or a high computation complexity such as\nrequiring compute expensive Hessian/Jacobian matrices and its inverses. In the\npaper, thus, we propose an efficient Hessian/Jacobian-free method (i.e.,\nHJFBiO) with the optimal convergence complexity to solve the nonconvex-PL\nbilevel problems. Theoretically, under some mild conditions, we prove that our\nHJFBiO method obtains an optimal convergence rate of $O(\\frac{1}{T})$, where\n$T$ denotes the number of iterations, and has an optimal gradient complexity of\n$O(\\epsilon^{-1})$ in finding an $\\epsilon$-stationary solution. We conduct\nsome numerical experiments on the bilevel PL game and hyper-representation\nlearning task to demonstrate efficiency of our proposed method.\n","subjects":["Mathematics/Optimization and Control","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"CqTher6KXvOsSbuuoEim22uwLizijGd7unZaQyz-igQ","pdfSize":"888564"}
