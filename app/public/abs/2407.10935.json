{"id":"2407.10935","title":"STARS: Self-supervised Tuning for 3D Action Recognition in Skeleton\n  Sequences","authors":"Soroush Mehraban, Mohammad Javad Rajabi, Babak Taati","authorsParsed":[["Mehraban","Soroush",""],["Rajabi","Mohammad Javad",""],["Taati","Babak",""]],"versions":[{"version":"v1","created":"Mon, 15 Jul 2024 17:35:38 GMT"}],"updateDate":"2024-07-16","timestamp":1721064938000,"abstract":"  Self-supervised pretraining methods with masked prediction demonstrate\nremarkable within-dataset performance in skeleton-based action recognition.\nHowever, we show that, unlike contrastive learning approaches, they do not\nproduce well-separated clusters. Additionally, these methods struggle with\ngeneralization in few-shot settings. To address these issues, we propose\nSelf-supervised Tuning for 3D Action Recognition in Skeleton sequences (STARS).\nSpecifically, STARS first uses a masked prediction stage using an\nencoder-decoder architecture. It then employs nearest-neighbor contrastive\nlearning to partially tune the weights of the encoder, enhancing the formation\nof semantic clusters for different actions. By tuning the encoder for a few\nepochs, and without using hand-crafted data augmentations, STARS achieves\nstate-of-the-art self-supervised results in various benchmarks, including\nNTU-60, NTU-120, and PKU-MMD. In addition, STARS exhibits significantly better\nresults than masked prediction models in few-shot settings, where the model has\nnot seen the actions throughout pretraining. Project page:\nhttps://soroushmehraban.github.io/stars/\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}