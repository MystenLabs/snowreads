{"id":"2408.11448","title":"Lookism: The overlooked bias in computer vision","authors":"Aditya Gulati and Bruno Lepri and Nuria Oliver","authorsParsed":[["Gulati","Aditya",""],["Lepri","Bruno",""],["Oliver","Nuria",""]],"versions":[{"version":"v1","created":"Wed, 21 Aug 2024 09:07:20 GMT"}],"updateDate":"2024-08-22","timestamp":1724231240000,"abstract":"  In recent years, there have been significant advancements in computer vision\nwhich have led to the widespread deployment of image recognition and generation\nsystems in socially relevant applications, from hiring to security screening.\nHowever, the prevalence of biases within these systems has raised significant\nethical and social concerns. The most extensively studied biases in this\ncontext are related to gender, race and age. Yet, other biases are equally\npervasive and harmful, such as lookism, i.e., the preferential treatment of\nindividuals based on their physical appearance. Lookism remains under-explored\nin computer vision but can have profound implications not only by perpetuating\nharmful societal stereotypes but also by undermining the fairness and\ninclusivity of AI technologies. Thus, this paper advocates for the systematic\nstudy of lookism as a critical bias in computer vision models. Through a\ncomprehensive review of existing literature, we identify three areas of\nintersection between lookism and computer vision. We illustrate them by means\nof examples and a user study. We call for an interdisciplinary approach to\naddress lookism, urging researchers, developers, and policymakers to prioritize\nthe development of equitable computer vision systems that respect and reflect\nthe diversity of human appearances.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computers and Society"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"hlZCmwPVQnuSLRUYFsNH2VIpQc6UbXpt5XaBli45UOA","pdfSize":"3416183"}
