{"id":"2408.13516","title":"AnoPLe: Few-Shot Anomaly Detection via Bi-directional Prompt Learning\n  with Only Normal Samples","authors":"Yujin Lee, Seoyoon Jang, Hyunsoo Yoon","authorsParsed":[["Lee","Yujin",""],["Jang","Seoyoon",""],["Yoon","Hyunsoo",""]],"versions":[{"version":"v1","created":"Sat, 24 Aug 2024 08:41:19 GMT"}],"updateDate":"2024-08-27","timestamp":1724488879000,"abstract":"  Few-shot Anomaly Detection (FAD) poses significant challenges due to the\nlimited availability of training samples and the frequent absence of abnormal\nsamples. Previous approaches often rely on annotations or true abnormal samples\nto improve detection, but such textual or visual cues are not always\naccessible. To address this, we introduce AnoPLe, a multi-modal prompt learning\nmethod designed for anomaly detection without prior knowledge of anomalies.\nAnoPLe simulates anomalies and employs bidirectional coupling of textual and\nvisual prompts to facilitate deep interaction between the two modalities.\nAdditionally, we integrate a lightweight decoder with a learnable multi-view\nsignal, trained on multi-scale images to enhance local semantic comprehension.\nTo further improve performance, we align global and local semantics, enriching\nthe image-level understanding of anomalies. The experimental results\ndemonstrate that AnoPLe achieves strong FAD performance, recording 94.1% and\n86.2% Image AUROC on MVTec-AD and VisA respectively, with only around a 1% gap\ncompared to the SoTA, despite not being exposed to true anomalies. Code is\navailable at https://github.com/YoojLee/AnoPLe.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/"}