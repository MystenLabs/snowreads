{"id":"2408.13890","title":"Making Large Language Models Better Planners with Reasoning-Decision\n  Alignment","authors":"Zhijian Huang, Tao Tang, Shaoxiang Chen, Sihao Lin, Zequn Jie, Lin Ma,\n  Guangrun Wang, Xiaodan Liang","authorsParsed":[["Huang","Zhijian",""],["Tang","Tao",""],["Chen","Shaoxiang",""],["Lin","Sihao",""],["Jie","Zequn",""],["Ma","Lin",""],["Wang","Guangrun",""],["Liang","Xiaodan",""]],"versions":[{"version":"v1","created":"Sun, 25 Aug 2024 16:43:47 GMT"}],"updateDate":"2024-08-27","timestamp":1724604227000,"abstract":"  Data-driven approaches for autonomous driving (AD) have been widely adopted\nin the past decade but are confronted with dataset bias and uninterpretability.\nInspired by the knowledge-driven nature of human driving, recent approaches\nexplore the potential of large language models (LLMs) to improve understanding\nand decision-making in traffic scenarios. They find that the pretrain-finetune\nparadigm of LLMs on downstream data with the Chain-of-Thought (CoT) reasoning\nprocess can enhance explainability and scene understanding. However, such a\npopular strategy proves to suffer from the notorious problems of misalignment\nbetween the crafted CoTs against the consequent decision-making, which remains\nuntouched by previous LLM-based AD methods. To address this problem, we\nmotivate an end-to-end decision-making model based on multimodality-augmented\nLLM, which simultaneously executes CoT reasoning and carries out planning\nresults. Furthermore, we propose a reasoning-decision alignment constraint\nbetween the paired CoTs and planning results, imposing the correspondence\nbetween reasoning and decision-making. Moreover, we redesign the CoTs to enable\nthe model to comprehend complex scenarios and enhance decision-making\nperformance. We dub our proposed large language planners with\nreasoning-decision alignment as RDA-Driver. Experimental evaluations on the\nnuScenes and DriveLM-nuScenes benchmarks demonstrate the effectiveness of our\nRDA-Driver in enhancing the performance of end-to-end AD systems. Specifically,\nour RDA-Driver achieves state-of-the-art planning performance on the nuScenes\ndataset with 0.80 L2 error and 0.32 collision rate, and also achieves leading\nresults on challenging DriveLM-nuScenes benchmarks with 0.82 L2 error and 0.38\ncollision rate.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}