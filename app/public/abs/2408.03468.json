{"id":"2408.03468","title":"MultiHateClip: A Multilingual Benchmark Dataset for Hateful Video\n  Detection on YouTube and Bilibili","authors":"Han Wang, Tan Rui Yang, Usman Naseem, Roy Ka-Wei Lee","authorsParsed":[["Wang","Han",""],["Yang","Tan Rui",""],["Naseem","Usman",""],["Lee","Roy Ka-Wei",""]],"versions":[{"version":"v1","created":"Sun, 28 Jul 2024 08:19:09 GMT"},{"version":"v2","created":"Mon, 12 Aug 2024 06:01:33 GMT"}],"updateDate":"2024-08-13","timestamp":1722154749000,"abstract":"  Hate speech is a pressing issue in modern society, with significant effects\nboth online and offline. Recent research in hate speech detection has primarily\ncentered on text-based media, largely overlooking multimodal content such as\nvideos. Existing studies on hateful video datasets have predominantly focused\non English content within a Western context and have been limited to binary\nlabels (hateful or non-hateful), lacking detailed contextual information. This\nstudy presents MultiHateClip1 , an novel multilingual dataset created through\nhate lexicons and human annotation. It aims to enhance the detection of hateful\nvideos on platforms such as YouTube and Bilibili, including content in both\nEnglish and Chinese languages. Comprising 2,000 videos annotated for\nhatefulness, offensiveness, and normalcy, this dataset provides a\ncross-cultural perspective on gender-based hate speech. Through a detailed\nexamination of human annotation results, we discuss the differences between\nChinese and English hateful videos and underscore the importance of different\nmodalities in hateful and offensive video analysis. Evaluations of\nstate-of-the-art video classification models, such as VLM, GPT-4V and Qwen-VL,\non MultiHateClip highlight the existing challenges in accurately distinguishing\nbetween hateful and offensive content and the urgent need for models that are\nboth multimodally and culturally nuanced. MultiHateClip represents a\nfoundational advance in enhancing hateful video detection by underscoring the\nnecessity of a multimodal and culturally sensitive approach in combating online\nhate speech.\n","subjects":["Computing Research Repository/Multimedia","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/"}