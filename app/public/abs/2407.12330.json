{"id":"2407.12330","title":"Uncertainty Calibration with Energy Based Instance-wise Scaling in the\n  Wild Dataset","authors":"Mijoo Kim and Junseok Kwon","authorsParsed":[["Kim","Mijoo",""],["Kwon","Junseok",""]],"versions":[{"version":"v1","created":"Wed, 17 Jul 2024 06:14:55 GMT"}],"updateDate":"2024-07-18","timestamp":1721196895000,"abstract":"  With the rapid advancement in the performance of deep neural networks (DNNs),\nthere has been significant interest in deploying and incorporating artificial\nintelligence (AI) systems into real-world scenarios. However, many DNNs lack\nthe ability to represent uncertainty, often exhibiting excessive confidence\neven when making incorrect predictions. To ensure the reliability of AI\nsystems, particularly in safety-critical cases, DNNs should transparently\nreflect the uncertainty in their predictions. In this paper, we investigate\nrobust post-hoc uncertainty calibration methods for DNNs within the context of\nmulti-class classification tasks. While previous studies have made notable\nprogress, they still face challenges in achieving robust calibration,\nparticularly in scenarios involving out-of-distribution (OOD). We identify that\nprevious methods lack adaptability to individual input data and struggle to\naccurately estimate uncertainty when processing inputs drawn from the wild\ndataset. To address this issue, we introduce a novel instance-wise calibration\nmethod based on an energy model. Our method incorporates energy scores instead\nof softmax confidence scores, allowing for adaptive consideration of DNN\nuncertainty for each prediction within a logit space. In experiments, we show\nthat the proposed method consistently maintains robust performance across the\nspectrum, spanning from in-distribution to OOD scenarios, when compared to\nother state-of-the-art methods.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}