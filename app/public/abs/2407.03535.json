{"id":"2407.03535","title":"BVI-RLV: A Fully Registered Dataset and Benchmarks for Low-Light Video\n  Enhancement","authors":"Ruirui Lin, Nantheera Anantrasirichai, Guoxi Huang, Joanne Lin, Qi\n  Sun, Alexandra Malyugina, David R Bull","authorsParsed":[["Lin","Ruirui",""],["Anantrasirichai","Nantheera",""],["Huang","Guoxi",""],["Lin","Joanne",""],["Sun","Qi",""],["Malyugina","Alexandra",""],["Bull","David R",""]],"versions":[{"version":"v1","created":"Wed, 3 Jul 2024 22:41:49 GMT"},{"version":"v2","created":"Sun, 28 Jul 2024 12:10:16 GMT"}],"updateDate":"2024-07-30","timestamp":1720046509000,"abstract":"  Low-light videos often exhibit spatiotemporal incoherent noise, compromising\nvisibility and performance in computer vision applications. One significant\nchallenge in enhancing such content using deep learning is the scarcity of\ntraining data. This paper introduces a novel low-light video dataset,\nconsisting of 40 scenes with various motion scenarios under two distinct\nlow-lighting conditions, incorporating genuine noise and temporal artifacts. We\nprovide fully registered ground truth data captured in normal light using a\nprogrammable motorized dolly and refine it via an image-based approach for\npixel-wise frame alignment across different light levels. We provide benchmarks\nbased on four different technologies: convolutional neural networks,\ntransformers, diffusion models, and state space models (mamba). Our\nexperimental results demonstrate the significance of fully registered video\npairs for low-light video enhancement (LLVE) and the comprehensive evaluation\nshows that the models trained with our dataset outperform those trained with\nthe existing datasets. Our dataset and links to benchmarks are publicly\navailable at https://doi.org/10.21227/mzny-8c77.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"YhhUCVyxFJt5qiRE4RUasWFNjtVVKkQYLie3JpObQGY","pdfSize":"21178824"}
