{"id":"2407.08083","title":"MambaVision: A Hybrid Mamba-Transformer Vision Backbone","authors":"Ali Hatamizadeh, Jan Kautz","authorsParsed":[["Hatamizadeh","Ali",""],["Kautz","Jan",""]],"versions":[{"version":"v1","created":"Wed, 10 Jul 2024 23:02:45 GMT"}],"updateDate":"2024-07-12","timestamp":1720652565000,"abstract":"  We propose a novel hybrid Mamba-Transformer backbone, denoted as MambaVision,\nwhich is specifically tailored for vision applications. Our core contribution\nincludes redesigning the Mamba formulation to enhance its capability for\nefficient modeling of visual features. In addition, we conduct a comprehensive\nablation study on the feasibility of integrating Vision Transformers (ViT) with\nMamba. Our results demonstrate that equipping the Mamba architecture with\nseveral self-attention blocks at the final layers greatly improves the modeling\ncapacity to capture long-range spatial dependencies. Based on our findings, we\nintroduce a family of MambaVision models with a hierarchical architecture to\nmeet various design criteria. For Image classification on ImageNet-1K dataset,\nMambaVision model variants achieve a new State-of-the-Art (SOTA) performance in\nterms of Top-1 accuracy and image throughput. In downstream tasks such as\nobject detection, instance segmentation and semantic segmentation on MS COCO\nand ADE20K datasets, MambaVision outperforms comparably-sized backbones and\ndemonstrates more favorable performance. Code:\nhttps://github.com/NVlabs/MambaVision.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-sa/4.0/","blobId":"IPj3ZpN3anjUEV0UARLM1zarWoNaagyhd-M80TjFDCk","pdfSize":"1496125","objectId":"0xbbc2c4d474cc6bf8616ac886407cde8e8a033f690fe59e3bfe8940ceb26d5a97","registeredEpoch":"1","certifiedEpoch":"1","startEpoch":"1","endEpoch":"201"}
