{"id":"2407.13647","title":"Weak-to-Strong Reasoning","authors":"Yuqing Yang, Yan Ma, Pengfei Liu","authorsParsed":[["Yang","Yuqing",""],["Ma","Yan",""],["Liu","Pengfei",""]],"versions":[{"version":"v1","created":"Thu, 18 Jul 2024 16:25:17 GMT"}],"updateDate":"2024-07-19","timestamp":1721319917000,"abstract":"  When large language models (LLMs) exceed human-level capabilities, it becomes\nincreasingly challenging to provide full-scale and accurate supervisions for\nthese models. Weak-to-strong learning, which leverages a less capable model to\nunlock the latent abilities of a stronger model, proves valuable in this\ncontext. Yet, the efficacy of this approach for complex reasoning tasks is\nstill untested. Furthermore, tackling reasoning tasks under the weak-to-strong\nsetting currently lacks efficient methods to avoid blindly imitating the weak\nsupervisor including its errors. In this paper, we introduce a progressive\nlearning framework that enables the strong model to autonomously refine its\ntraining data, without requiring input from either a more advanced model or\nhuman-annotated data. This framework begins with supervised fine-tuning on a\nselective small but high-quality dataset, followed by preference optimization\non contrastive samples identified by the strong model itself. Extensive\nexperiments on the GSM8K and MATH datasets demonstrate that our method\nsignificantly enhances the reasoning capabilities of Llama2-70b using three\nseparate weak models. This method is further validated in a forward-looking\nexperimental setup, where Llama3-8b-instruct effectively supervises Llama3-70b\non the highly challenging OlympicArena dataset. This work paves the way for a\nmore scalable and sophisticated strategy to enhance AI reasoning powers. All\nrelevant code and resources are available in\n\\url{https://github.com/GAIR-NLP/weak-to-strong-reasoning}.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}