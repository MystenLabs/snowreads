{"id":"2408.01812","title":"SkyDiffusion: Street-to-Satellite Image Synthesis with Diffusion Models\n  and BEV Paradigm","authors":"Junyan Ye, Jun He, Weijia Li, Zhutao Lv, Jinhua Yu, Haote Yang,\n  Conghui He","authorsParsed":[["Ye","Junyan",""],["He","Jun",""],["Li","Weijia",""],["Lv","Zhutao",""],["Yu","Jinhua",""],["Yang","Haote",""],["He","Conghui",""]],"versions":[{"version":"v1","created":"Sat, 3 Aug 2024 15:43:56 GMT"},{"version":"v2","created":"Sat, 17 Aug 2024 08:05:02 GMT"}],"updateDate":"2024-08-20","timestamp":1722699836000,"abstract":"  Street-to-satellite image synthesis focuses on generating realistic satellite\nimages from corresponding ground street-view images while maintaining a\nconsistent content layout, similar to looking down from the sky. The\nsignificant differences in perspectives create a substantial domain gap between\nthe views, making this cross-view generation task particularly challenging. In\nthis paper, we introduce SkyDiffusion, a novel cross-view generation method for\nsynthesizing satellite images from street-view images, leveraging diffusion\nmodels and Bird's Eye View (BEV) paradigm. First, we design a Curved-BEV method\nto transform street-view images to the satellite view, reformulating the\nchallenging cross-domain image synthesis task into a conditional generation\nproblem. Curved-BEV also includes a \"Multi-to-One\" mapping strategy for\nleveraging multiple street-view images within the same satellite coverage area,\neffectively solving the occlusion issues in dense urban scenes. Next, we design\na BEV-controlled diffusion model to generate satellite images consistent with\nthe street-view content, which also incorporates a light manipulation module to\nmake the lighting conditions of the synthesized satellite images more flexible.\nExperimental results demonstrate that SkyDiffusion outperforms state-of-the-art\nmethods on both suburban (CVUSA & CVACT) and urban (VIGOR-Chicago) cross-view\ndatasets, with an average SSIM increase of 13.96% and a FID reduction of\n20.54%, achieving realistic and content-consistent satellite image generation.\nThe code and models of this work will be released at\nhttps://opendatalab.github.io/skydiffusion\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}