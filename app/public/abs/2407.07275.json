{"id":"2407.07275","title":"Remastering Divide and Remaster: A Cinematic Audio Source Separation\n  Dataset with Multilingual Support","authors":"Karn N. Watcharasupat, Chih-Wei Wu, and Iroro Orife","authorsParsed":[["Watcharasupat","Karn N.",""],["Wu","Chih-Wei",""],["Orife","Iroro",""]],"versions":[{"version":"v1","created":"Tue, 9 Jul 2024 23:39:37 GMT"},{"version":"v2","created":"Mon, 26 Aug 2024 00:55:01 GMT"}],"updateDate":"2024-08-27","timestamp":1720568377000,"abstract":"  Cinematic audio source separation (CASS), as a problem of extracting the\ndialogue, music, and effects stems from their mixture, is a relatively new\nsubtask of audio source separation. To date, only one publicly available\ndataset exists for CASS, that is, the Divide and Remaster (DnR) dataset, which\nis currently at version 2. While DnR v2 has been an incredibly useful resource\nfor CASS, several areas of improvement have been identified, particularly\nthrough its use in the 2023 Sound Demixing Challenge. In this work, we develop\nversion 3 of the DnR dataset, addressing issues relating to vocal content in\nnon-dialogue stems, loudness distributions, mastering process, and linguistic\ndiversity. In particular, the dialogue stem of DnR v3 includes speech content\nfrom more than 30 languages from multiple families including but not limited to\nthe Germanic, Romance, Indo-Aryan, Dravidian, Malayo-Polynesian, and Bantu\nfamilies. Benchmark results using the Bandit model indicated that training on\nmultilingual data yields significant generalizability to the model even in\nlanguages with low data availability. Even in languages with high data\navailability, the multilingual model often performs on par or better than\ndedicated models trained on monolingual CASS datasets. Dataset and model\nimplementation will be made available at\nhttps://github.com/kwatcharasupat/source-separation-landing.\n","subjects":["Electrical Engineering and Systems Science/Audio and Speech Processing","Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning","Computing Research Repository/Sound"],"license":"http://creativecommons.org/licenses/by-sa/4.0/","blobId":"A7BtFlG7llgtvJCRZCT7drrlHEMDoeRVn8lcQ2Mifgk","pdfSize":"423190"}
