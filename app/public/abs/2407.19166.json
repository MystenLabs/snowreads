{"id":"2407.19166","title":"Revisit Self-supervised Depth Estimation with Local\n  Structure-from-Motion","authors":"Shengjie Zhu, Xiaoming Liu","authorsParsed":[["Zhu","Shengjie",""],["Liu","Xiaoming",""]],"versions":[{"version":"v1","created":"Sat, 27 Jul 2024 04:37:16 GMT"},{"version":"v2","created":"Tue, 6 Aug 2024 18:52:04 GMT"}],"updateDate":"2024-08-08","timestamp":1722055036000,"abstract":"  Both self-supervised depth estimation and Structure-from-Motion (SfM) recover\nscene depth from RGB videos. Despite sharing a similar objective, the two\napproaches are disconnected. Prior works of self-supervision backpropagate\nlosses defined within immediate neighboring frames. Instead of\nlearning-through-loss, this work proposes an alternative scheme by performing\nlocal SfM. First, with calibrated RGB or RGB-D images, we employ a depth and\ncorrespondence estimator to infer depthmaps and pair-wise correspondence maps.\nThen, a novel bundle-RANSAC-adjustment algorithm jointly optimizes camera poses\nand one depth adjustment for each depthmap. Finally, we fix camera poses and\nemploy a NeRF, however, without a neural network, for dense triangulation and\ngeometric verification. Poses, depth adjustments, and triangulated sparse\ndepths are our outputs. For the first time, we show self-supervision within $5$\nframes already benefits SoTA supervised depth and correspondence models. The\nproject page is held in the link (https://shngjz.github.io/SSfM.github.io/).\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}