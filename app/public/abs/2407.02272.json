{"id":"2407.02272","title":"Aligning Human Motion Generation with Human Perceptions","authors":"Haoru Wang, Wentao Zhu, Luyi Miao, Yishu Xu, Feng Gao, Qi Tian, Yizhou\n  Wang","authorsParsed":[["Wang","Haoru",""],["Zhu","Wentao",""],["Miao","Luyi",""],["Xu","Yishu",""],["Gao","Feng",""],["Tian","Qi",""],["Wang","Yizhou",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 14:01:59 GMT"}],"updateDate":"2024-07-03","timestamp":1719928919000,"abstract":"  Human motion generation is a critical task with a wide range of applications.\nAchieving high realism in generated motions requires naturalness, smoothness,\nand plausibility. Despite rapid advancements in the field, current generation\nmethods often fall short of these goals. Furthermore, existing evaluation\nmetrics typically rely on ground-truth-based errors, simple heuristics, or\ndistribution distances, which do not align well with human perceptions of\nmotion quality. In this work, we propose a data-driven approach to bridge this\ngap by introducing a large-scale human perceptual evaluation dataset,\nMotionPercept, and a human motion critic model, MotionCritic, that capture\nhuman perceptual preferences. Our critic model offers a more accurate metric\nfor assessing motion quality and could be readily integrated into the motion\ngeneration pipeline to enhance generation quality. Extensive experiments\ndemonstrate the effectiveness of our approach in both evaluating and improving\nthe quality of generated human motions by aligning with human perceptions. Code\nand data are publicly available at https://motioncritic.github.io/.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Graphics"],"license":"http://creativecommons.org/licenses/by/4.0/"}