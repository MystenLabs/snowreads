{"id":"2407.01026","title":"Augmenting Document-level Relation Extraction with Efficient\n  Multi-Supervision","authors":"Xiangyu Lin, Weijia Jia and Zhiguo Gong","authorsParsed":[["Lin","Xiangyu",""],["Jia","Weijia",""],["Gong","Zhiguo",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 07:22:32 GMT"}],"updateDate":"2024-07-02","timestamp":1719818552000,"abstract":"  Despite its popularity in sentence-level relation extraction, distantly\nsupervised data is rarely utilized by existing work in document-level relation\nextraction due to its noisy nature and low information density. Among its\ncurrent applications, distantly supervised data is mostly used as a whole for\npertaining, which is of low time efficiency. To fill in the gap of efficient\nand robust utilization of distantly supervised training data, we propose\nEfficient Multi-Supervision for document-level relation extraction, in which we\nfirst select a subset of informative documents from the massive dataset by\ncombining distant supervision with expert supervision, then train the model\nwith Multi-Supervision Ranking Loss that integrates the knowledge from multiple\nsources of supervision to alleviate the effects of noise. The experiments\ndemonstrate the effectiveness of our method in improving the model performance\nwith higher time efficiency than existing baselines.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"stGDzlFH4bNFxqpCsBIC7Ohi_apXYCdDgYfc5qApiFs","pdfSize":"317585"}
