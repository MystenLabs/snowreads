{"id":"2407.07788","title":"BiGym: A Demo-Driven Mobile Bi-Manual Manipulation Benchmark","authors":"Nikita Chernyadev, Nicholas Backshall, Xiao Ma, Yunfan Lu, Younggyo\n  Seo, Stephen James","authorsParsed":[["Chernyadev","Nikita",""],["Backshall","Nicholas",""],["Ma","Xiao",""],["Lu","Yunfan",""],["Seo","Younggyo",""],["James","Stephen",""]],"versions":[{"version":"v1","created":"Wed, 10 Jul 2024 16:04:18 GMT"},{"version":"v2","created":"Thu, 11 Jul 2024 16:26:09 GMT"}],"updateDate":"2024-07-12","timestamp":1720627458000,"abstract":"  We introduce BiGym, a new benchmark and learning environment for mobile\nbi-manual demo-driven robotic manipulation. BiGym features 40 diverse tasks set\nin home environments, ranging from simple target reaching to complex kitchen\ncleaning. To capture the real-world performance accurately, we provide\nhuman-collected demonstrations for each task, reflecting the diverse modalities\nfound in real-world robot trajectories. BiGym supports a variety of\nobservations, including proprioceptive data and visual inputs such as RGB, and\ndepth from 3 camera views. To validate the usability of BiGym, we thoroughly\nbenchmark the state-of-the-art imitation learning algorithms and demo-driven\nreinforcement learning algorithms within the environment and discuss the future\nopportunities.\n","subjects":["Computing Research Repository/Robotics","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}