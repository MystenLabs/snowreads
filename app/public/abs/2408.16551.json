{"id":"2408.16551","title":"TINA: Acceleration of Non-NN Signal Processing Algorithms Using NN\n  Accelerators","authors":"Christiaan Boerkamp, Steven van der Vlugt, Zaid Al-Ars","authorsParsed":[["Boerkamp","Christiaan",""],["van der Vlugt","Steven",""],["Al-Ars","Zaid",""]],"versions":[{"version":"v1","created":"Thu, 29 Aug 2024 14:14:37 GMT"}],"updateDate":"2024-08-30","timestamp":1724940877000,"abstract":"  This paper introduces TINA, a novel framework for implementing non Neural\nNetwork (NN) signal processing algorithms on NN accelerators such as GPUs, TPUs\nor FPGAs. The key to this approach is the concept of mapping mathematical and\nlogic functions as a series of convolutional and fully connected layers. By\nmapping functions into such a small substack of NN layers, it becomes possible\nto execute non-NN algorithms on NN hardware (HW) accelerators efficiently, as\nwell as to ensure the portability of TINA implementations to any platform that\nsupports such NN accelerators. Results show that TINA is highly competitive\ncompared to alternative frameworks, specifically for complex functions with\niterations. For a Polyphase Filter Bank use case TINA shows GPU speedups of up\nto 80x vs a CPU baseline with NumPy compared to 8x speedup achieved by\nalternative frameworks. The framework is open source and publicly available at\nhttps://github.com/ChristiaanBoe/TINA.\n","subjects":["Computing Research Repository/Performance"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"SRxIQ0ft-lsrZkpPG61Q7tsoKx8l5iHiL6IwOaUb0_g","pdfSize":"4445234"}
