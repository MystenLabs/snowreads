{"id":"2407.15441","title":"Developing a Reliable, General-Purpose Hallucination Detection and\n  Mitigation Service: Insights and Lessons Learned","authors":"Song Wang, Xun Wang, Jie Mei, Yujia Xie, Sean Muarray, Zhang Li,\n  Lingfeng Wu, Si-Qing Chen, Wayne Xiong","authorsParsed":[["Wang","Song",""],["Wang","Xun",""],["Mei","Jie",""],["Xie","Yujia",""],["Muarray","Sean",""],["Li","Zhang",""],["Wu","Lingfeng",""],["Chen","Si-Qing",""],["Xiong","Wayne",""]],"versions":[{"version":"v1","created":"Mon, 22 Jul 2024 07:48:30 GMT"}],"updateDate":"2024-07-23","timestamp":1721634510000,"abstract":"  Hallucination, a phenomenon where large language models (LLMs) produce output\nthat is factually incorrect or unrelated to the input, is a major challenge for\nLLM applications that require accuracy and dependability. In this paper, we\nintroduce a reliable and high-speed production system aimed at detecting and\nrectifying the hallucination issue within LLMs. Our system encompasses named\nentity recognition (NER), natural language inference (NLI), span-based\ndetection (SBD), and an intricate decision tree-based process to reliably\ndetect a wide range of hallucinations in LLM responses. Furthermore, our team\nhas crafted a rewriting mechanism that maintains an optimal mix of precision,\nresponse time, and cost-effectiveness. We detail the core elements of our\nframework and underscore the paramount challenges tied to response time,\navailability, and performance metrics, which are crucial for real-world\ndeployment of these technologies. Our extensive evaluation, utilizing offline\ndata and live production traffic, confirms the efficacy of our proposed\nframework and service.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"So50tZaqX-cJ3wbT97SaNUiVtP3OS8PCTGBddtz70Ec","pdfSize":"503916"}
