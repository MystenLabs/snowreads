{"id":"2407.13509","title":"Spontaneous Style Text-to-Speech Synthesis with Controllable Spontaneous\n  Behaviors Based on Language Models","authors":"Weiqin Li, Peiji Yang, Yicheng Zhong, Yixuan Zhou, Zhisheng Wang,\n  Zhiyong Wu, Xixin Wu, Helen Meng","authorsParsed":[["Li","Weiqin",""],["Yang","Peiji",""],["Zhong","Yicheng",""],["Zhou","Yixuan",""],["Wang","Zhisheng",""],["Wu","Zhiyong",""],["Wu","Xixin",""],["Meng","Helen",""]],"versions":[{"version":"v1","created":"Thu, 18 Jul 2024 13:42:38 GMT"}],"updateDate":"2024-07-19","timestamp":1721310158000,"abstract":"  Spontaneous style speech synthesis, which aims to generate human-like speech,\noften encounters challenges due to the scarcity of high-quality data and\nlimitations in model capabilities. Recent language model-based TTS systems can\nbe trained on large, diverse, and low-quality speech datasets, resulting in\nhighly natural synthesized speech. However, they are limited by the difficulty\nof simulating various spontaneous behaviors and capturing prosody variations in\nspontaneous speech. In this paper, we propose a novel spontaneous speech\nsynthesis system based on language models. We systematically categorize and\nuniformly model diverse spontaneous behaviors. Moreover, fine-grained prosody\nmodeling is introduced to enhance the model's ability to capture subtle prosody\nvariations in spontaneous speech.Experimental results show that our proposed\nmethod significantly outperforms the baseline methods in terms of prosody\nnaturalness and spontaneous behavior naturalness.\n","subjects":["Computing Research Repository/Sound","Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}