{"id":"2408.16896","title":"DLFormer: Enhancing Explainability in Multivariate Time Series\n  Forecasting using Distributed Lag Embedding","authors":"Younghwi Kim, Dohee Kim, Sunghyun Sim","authorsParsed":[["Kim","Younghwi",""],["Kim","Dohee",""],["Sim","Sunghyun",""]],"versions":[{"version":"v1","created":"Thu, 29 Aug 2024 20:39:54 GMT"}],"updateDate":"2024-09-02","timestamp":1724963994000,"abstract":"  . Most real-world variables are multivariate time series influenced by past\nvalues and explanatory factors. Consequently, predicting these time series data\nusing artificial intelligence is ongoing. In particular, in fields such as\nhealthcare and finance, where reliability is crucial, having understandable\nexplanations for predictions is essential. However, achieving a balance between\nhigh prediction accuracy and intuitive explainability has proven challenging.\nAlthough attention-based models have limitations in representing the individual\ninfluences of each variable, these models can influence the temporal\ndependencies in time series prediction and the magnitude of the influence of\nindividual variables. To address this issue, this study introduced DLFormer, an\nattention-based architecture integrated with distributed lag embedding, to\ntemporally embed individual variables and capture their temporal influence.\nThrough validation against various real-world datasets, DLFormer showcased\nsuperior performance improvements compared to existing attention-based\nhigh-performance models. Furthermore, comparing the relationships between\nvariables enhanced the reliability of explainability.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"SwP2IQmt9Ygve6qsYMSOVBY6PH_klyO31O_wK7j-M5Q","pdfSize":"1971813"}
