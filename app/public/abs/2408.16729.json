{"id":"2408.16729","title":"Prediction-Feedback DETR for Temporal Action Detection","authors":"Jihwan Kim, Miso Lee, Cheol-Ho Cho, Jihyun Lee, Jae-Pil Heo","authorsParsed":[["Kim","Jihwan",""],["Lee","Miso",""],["Cho","Cheol-Ho",""],["Lee","Jihyun",""],["Heo","Jae-Pil",""]],"versions":[{"version":"v1","created":"Thu, 29 Aug 2024 17:20:59 GMT"},{"version":"v2","created":"Mon, 9 Sep 2024 16:27:00 GMT"}],"updateDate":"2024-09-10","timestamp":1724952059000,"abstract":"  Temporal Action Detection (TAD) is fundamental yet challenging for real-world\nvideo applications. Leveraging the unique benefits of transformers, various\nDETR-based approaches have been adopted in TAD. However, it has recently been\nidentified that the attention collapse in self-attention causes the performance\ndegradation of DETR for TAD. Building upon previous research, this paper newly\naddresses the attention collapse problem in cross-attention within DETR-based\nTAD methods. Moreover, our findings reveal that cross-attention exhibits\npatterns distinct from predictions, indicating a short-cut phenomenon. To\nresolve this, we propose a new framework, Prediction-Feedback DETR (Pred-DETR),\nwhich utilizes predictions to restore the collapse and align the cross- and\nself-attention with predictions. Specifically, we devise novel\nprediction-feedback objectives using guidance from the relations of the\npredictions. As a result, Pred-DETR significantly alleviates the collapse and\nachieves state-of-the-art performance among DETR-based methods on various\nchallenging benchmarks including THUMOS14, ActivityNet-v1.3, HACS, and\nFineAction.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"EbQvtw1c9Utxw0KBpE7IpxdYwM_AC9eE2TB-tVw5P1o","pdfSize":"2807957"}
