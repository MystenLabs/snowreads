{"id":"2408.03560","title":"In2Core: Leveraging Influence Functions for Coreset Selection in\n  Instruction Finetuning of Large Language Models","authors":"Ayrton San Joaquin, Bin Wang, Zhengyuan Liu, Nicholas Asher, Brian\n  Lim, Philippe Muller, Nancy Chen","authorsParsed":[["Joaquin","Ayrton San",""],["Wang","Bin",""],["Liu","Zhengyuan",""],["Asher","Nicholas",""],["Lim","Brian",""],["Muller","Philippe",""],["Chen","Nancy",""]],"versions":[{"version":"v1","created":"Wed, 7 Aug 2024 05:48:05 GMT"}],"updateDate":"2024-08-08","timestamp":1723009685000,"abstract":"  Despite advancements, fine-tuning Large Language Models (LLMs) remains costly\ndue to the extensive parameter count and substantial data requirements for\nmodel generalization. Accessibility to computing resources remains a barrier\nfor the open-source community. To address this challenge, we propose the\nIn2Core algorithm, which selects a coreset by analyzing the correlation between\ntraining and evaluation samples with a trained model. Notably, we assess the\nmodel's internal gradients to estimate this relationship, aiming to rank the\ncontribution of each training point. To enhance efficiency, we propose an\noptimization to compute influence functions with a reduced number of layers\nwhile achieving similar accuracy. By applying our algorithm to instruction\nfine-tuning data of LLMs, we can achieve similar performance with just 50% of\nthe training data. Meantime, using influence functions to analyze model\ncoverage to certain testing samples could provide a reliable and interpretable\nsignal on the training set's coverage of those test points.\n","subjects":["Computing Research Repository/Machine Learning","Statistics/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}