{"id":"2407.03194","title":"Prediction Instability in Machine Learning Ensembles","authors":"Jeremy Kedziora","authorsParsed":[["Kedziora","Jeremy",""]],"versions":[{"version":"v1","created":"Wed, 3 Jul 2024 15:26:02 GMT"},{"version":"v2","created":"Tue, 30 Jul 2024 18:18:12 GMT"},{"version":"v3","created":"Thu, 1 Aug 2024 14:08:53 GMT"},{"version":"v4","created":"Fri, 16 Aug 2024 16:37:09 GMT"},{"version":"v5","created":"Mon, 26 Aug 2024 16:57:34 GMT"}],"updateDate":"2024-08-27","timestamp":1720020362000,"abstract":"  In machine learning ensembles predictions from multiple models are\naggregated. Despite widespread use and strong performance of ensembles in\napplied problems little is known about the mathematical properties of\naggregating models and associated consequences for safe, explainable use of\nsuch models. In this paper we prove a theorem that shows that any ensemble will\nexhibit at least one of the following forms of prediction instability. It will\neither ignore agreement among all underlying models, change its mind when none\nof the underlying models have done so, or be manipulable through inclusion or\nexclusion of options it would never actually predict. As a consequence,\nensemble aggregation procedures will always need to balance the benefits of\ninformation use against the risk of these prediction instabilities. This\nanalysis also sheds light on what specific forms of prediction instability to\nexpect from particular ensemble algorithms; for example popular tree ensembles\nlike random forest, or xgboost will violate basic, intuitive fairness\nproperties. Finally, we show that this can be ameliorated by using consistent\nmodels in asymptotic conditions.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"lgty_wz1pgGaC9Z2IJi6AHITb21n1ujHkuJ7G1eUNXw","pdfSize":"229058"}
