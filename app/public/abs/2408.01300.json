{"id":"2408.01300","title":"Assessing Robustness of Machine Learning Models using Covariate\n  Perturbations","authors":"Arun Prakash R, Anwesha Bhattacharyya, Joel Vaughan, Vijayan N. Nair","authorsParsed":[["R","Arun Prakash",""],["Bhattacharyya","Anwesha",""],["Vaughan","Joel",""],["Nair","Vijayan N.",""]],"versions":[{"version":"v1","created":"Fri, 2 Aug 2024 14:41:36 GMT"}],"updateDate":"2024-08-05","timestamp":1722609696000,"abstract":"  As machine learning models become increasingly prevalent in critical\ndecision-making models and systems in fields like finance, healthcare, etc.,\nensuring their robustness against adversarial attacks and changes in the input\ndata is paramount, especially in cases where models potentially overfit. This\npaper proposes a comprehensive framework for assessing the robustness of\nmachine learning models through covariate perturbation techniques. We explore\nvarious perturbation strategies to assess robustness and examine their impact\non model predictions, including separate strategies for numeric and non-numeric\nvariables, summaries of perturbations to assess and compare model robustness\nacross different scenarios, and local robustness diagnosis to identify any\nregions in the data where a model is particularly unstable. Through empirical\nstudies on real world dataset, we demonstrate the effectiveness of our approach\nin comparing robustness across models, identifying the instabilities in the\nmodel, and enhancing model robustness.\n","subjects":["Statistics/Machine Learning","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}