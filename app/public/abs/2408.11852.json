{"id":"2408.11852","title":"Fast Training Dataset Attribution via In-Context Learning","authors":"Milad Fotouhi, Mohammad Taha Bahadori, Oluwaseyi Feyisetan, Payman\n  Arabshahi, David Heckerman","authorsParsed":[["Fotouhi","Milad",""],["Bahadori","Mohammad Taha",""],["Feyisetan","Oluwaseyi",""],["Arabshahi","Payman",""],["Heckerman","David",""]],"versions":[{"version":"v1","created":"Wed, 14 Aug 2024 20:48:45 GMT"}],"updateDate":"2024-08-23","timestamp":1723668525000,"abstract":"  We investigate the use of in-context learning and prompt engineering to\nestimate the contributions of training data in the outputs of instruction-tuned\nlarge language models (LLMs). We propose two novel approaches: (1) a\nsimilarity-based approach that measures the difference between LLM outputs with\nand without provided context, and (2) a mixture distribution model approach\nthat frames the problem of identifying contribution scores as a matrix\nfactorization task. Our empirical comparison demonstrates that the mixture\nmodel approach is more robust to retrieval noise in in-context learning,\nproviding a more reliable estimation of data contributions.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}