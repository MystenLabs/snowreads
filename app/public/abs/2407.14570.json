{"id":"2407.14570","title":"Are handcrafted filters helpful for attributing AI-generated images?","authors":"Jialiang Li, Haoyue Wang, Sheng Li, Zhenxing Qian, Xinpeng Zhang and\n  Athanasios V. Vasilakos","authorsParsed":[["Li","Jialiang",""],["Wang","Haoyue",""],["Li","Sheng",""],["Qian","Zhenxing",""],["Zhang","Xinpeng",""],["Vasilakos","Athanasios V.",""]],"versions":[{"version":"v1","created":"Fri, 19 Jul 2024 07:04:57 GMT"},{"version":"v2","created":"Tue, 23 Jul 2024 06:20:43 GMT"}],"updateDate":"2024-07-24","timestamp":1721372697000,"abstract":"  Recently, a vast number of image generation models have been proposed, which\nraises concerns regarding the misuse of these artificial intelligence (AI)\ntechniques for generating fake images. To attribute the AI-generated images,\nexisting schemes usually design and train deep neural networks (DNNs) to learn\nthe model fingerprints, which usually requires a large amount of data for\neffective learning. In this paper, we aim to answer the following two questions\nfor AI-generated image attribution, 1) is it possible to design useful\nhandcrafted filters to facilitate the fingerprint learning? and 2) how we could\nreduce the amount of training data after we incorporate the handcrafted\nfilters? We first propose a set of Multi-Directional High-Pass Filters (MHFs)\nwhich are capable to extract the subtle fingerprints from various directions.\nThen, we propose a Directional Enhanced Feature Learning network (DEFL) to take\nboth the MHFs and randomly-initialized filters into consideration. The output\nof the DEFL is fused with the semantic features to produce a compact\nfingerprint. To make the compact fingerprint discriminative among different\nmodels, we propose a Dual-Margin Contrastive (DMC) loss to tune our DEFL.\nFinally, we propose a reference based fingerprint classification scheme for\nimage attribution. Experimental results demonstrate that it is indeed helpful\nto use our MHFs for attributing the AI-generated images. The performance of our\nproposed method is significantly better than the state-of-the-art for both the\nclosed-set and open-set image attribution, where only a small amount of images\nare required for training.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}