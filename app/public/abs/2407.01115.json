{"id":"2407.01115","title":"Enabling Mixed Effects Neural Networks for Diverse, Clustered Data Using\n  Monte Carlo Methods","authors":"Andrej Tschalzev, Paul Nitschke, Lukas Kirchdorfer, Stefan L\\\"udtke,\n  Christian Bartelt, Heiner Stuckenschmidt","authorsParsed":[["Tschalzev","Andrej",""],["Nitschke","Paul",""],["Kirchdorfer","Lukas",""],["LÃ¼dtke","Stefan",""],["Bartelt","Christian",""],["Stuckenschmidt","Heiner",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 09:24:04 GMT"}],"updateDate":"2024-07-02","timestamp":1719825844000,"abstract":"  Neural networks often assume independence among input data samples,\ndisregarding correlations arising from inherent clustering patterns in\nreal-world datasets (e.g., due to different sites or repeated measurements).\nRecently, mixed effects neural networks (MENNs) which separate cluster-specific\n'random effects' from cluster-invariant 'fixed effects' have been proposed to\nimprove generalization and interpretability for clustered data. However,\nexisting methods only allow for approximate quantification of cluster effects\nand are limited to regression and binary targets with only one clustering\nfeature. We present MC-GMENN, a novel approach employing Monte Carlo methods to\ntrain Generalized Mixed Effects Neural Networks. We empirically demonstrate\nthat MC-GMENN outperforms existing mixed effects deep learning models in terms\nof generalization performance, time complexity, and quantification of\ninter-cluster variance. Additionally, MC-GMENN is applicable to a wide range of\ndatasets, including multi-class classification tasks with multiple\nhigh-cardinality categorical features. For these datasets, we show that\nMC-GMENN outperforms conventional encoding and embedding methods,\nsimultaneously offering a principled methodology for interpreting the effects\nof clustering patterns.\n","subjects":["Computing Research Repository/Machine Learning","Statistics/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}