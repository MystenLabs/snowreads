{"id":"2408.16577","title":"Seeking the Sufficiency and Necessity Causal Features in Multimodal\n  Representation Learning","authors":"Boyu Chen, Junjie Liu, Zhu Li, Mengyue yang","authorsParsed":[["Chen","Boyu",""],["Liu","Junjie",""],["Li","Zhu",""],["yang","Mengyue",""]],"versions":[{"version":"v1","created":"Thu, 29 Aug 2024 14:43:42 GMT"}],"updateDate":"2024-08-30","timestamp":1724942622000,"abstract":"  Learning representations with a high Probability of Necessary and Sufficient\nCauses (PNS) has been shown to enhance deep learning models' ability. This task\ninvolves identifying causal features that are both sufficient (guaranteeing the\noutcome) and necessary (without which the outcome cannot occur). However,\ncurrent research predominantly focuses on unimodal data, and extending PNS\nlearning to multimodal settings presents significant challenges. The challenges\narise as the conditions for PNS identifiability, Exogeneity and Monotonicity,\nneed to be reconsidered in a multimodal context, where sufficient and necessary\ncausal features are distributed across different modalities. To address this,\nwe first propose conceptualizing multimodal representations as comprising\nmodality-invariant and modality-specific components. We then analyze PNS\nidentifiability for each component, while ensuring non-trivial PNS estimation.\nFinally, we formulate tractable optimization objectives that enable multimodal\nmodels to learn high-PNS representations, thereby enhancing their predictive\nperformance. Experiments demonstrate the effectiveness of our method on both\nsynthetic and real-world data.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}