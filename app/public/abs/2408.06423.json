{"id":"2408.06423","title":"Evaluating Language Models on Entity Disambiguation in Tables","authors":"Federico Belotti and Fabio Dadda and Marco Cremaschi and Roberto\n  Avogadro and Riccardo Pozzi and Matteo Palmonari","authorsParsed":[["Belotti","Federico",""],["Dadda","Fabio",""],["Cremaschi","Marco",""],["Avogadro","Roberto",""],["Pozzi","Riccardo",""],["Palmonari","Matteo",""]],"versions":[{"version":"v1","created":"Mon, 12 Aug 2024 18:01:50 GMT"}],"updateDate":"2024-08-14","timestamp":1723485710000,"abstract":"  Tables are crucial containers of information, but understanding their meaning\nmay be challenging. Indeed, recently, there has been a focus on Semantic Table\nInterpretation (STI), i.e., the task that involves the semantic annotation of\ntabular data to disambiguate their meaning. Over the years, there has been a\nsurge in interest in data-driven approaches based on deep learning that have\nincreasingly been combined with heuristic-based approaches. In the last period,\nthe advent of Large Language Models (LLMs) has led to a new category of\napproaches for table annotation. The interest in this research field,\ncharacterised by multiple challenges, has led to a proliferation of approaches\nemploying different techniques. However, these approaches have not been\nconsistently evaluated on a common ground, making evaluation and comparison\ndifficult. This work proposes an extensive evaluation of four state-of-the-art\n(SOTA) approaches - Alligator (formerly s-elBat), Dagobah, TURL, and\nTableLlama; the first two belong to the family of heuristic-based algorithms,\nwhile the others are respectively encoder-only and decoder-only LLMs. The\nprimary objective is to measure the ability of these approaches to solve the\nentity disambiguation task, with the ultimate aim of charting new research\npaths in the field.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"M8OIYZ0cFL08wdUB6k-0GQlhDRZtjuNxL2CekIaaarQ","pdfSize":"940813"}
