{"id":"2408.16765","title":"A Score-Based Density Formula, with Applications in Diffusion Generative\n  Models","authors":"Gen Li, Yuling Yan","authorsParsed":[["Li","Gen",""],["Yan","Yuling",""]],"versions":[{"version":"v1","created":"Thu, 29 Aug 2024 17:59:07 GMT"}],"updateDate":"2024-08-30","timestamp":1724954347000,"abstract":"  Score-based generative models (SGMs) have revolutionized the field of\ngenerative modeling, achieving unprecedented success in generating realistic\nand diverse content. Despite empirical advances, the theoretical basis for why\noptimizing the evidence lower bound (ELBO) on the log-likelihood is effective\nfor training diffusion generative models, such as DDPMs, remains largely\nunexplored. In this paper, we address this question by establishing a density\nformula for a continuous-time diffusion process, which can be viewed as the\ncontinuous-time limit of the forward process in an SGM. This formula reveals\nthe connection between the target density and the score function associated\nwith each step of the forward process. Building on this, we demonstrate that\nthe minimizer of the optimization objective for training DDPMs nearly coincides\nwith that of the true objective, providing a theoretical foundation for\noptimizing DDPMs using the ELBO. Furthermore, we offer new insights into the\nrole of score-matching regularization in training GANs, the use of ELBO in\ndiffusion classifiers, and the recently proposed diffusion loss.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence","Mathematics/Probability","Mathematics/Statistics Theory","Statistics/Machine Learning","Statistics/Statistics Theory"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}