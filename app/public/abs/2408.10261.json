{"id":"2408.10261","title":"Relational Graph Convolutional Networks Do Not Learn Sound Rules","authors":"Matthew Morris, David J. Tena Cucala, Bernardo Cuenca Grau, Ian\n  Horrocks","authorsParsed":[["Morris","Matthew",""],["Cucala","David J. Tena",""],["Grau","Bernardo Cuenca",""],["Horrocks","Ian",""]],"versions":[{"version":"v1","created":"Wed, 14 Aug 2024 15:46:42 GMT"}],"updateDate":"2024-08-21","timestamp":1723650402000,"abstract":"  Graph neural networks (GNNs) are frequently used to predict missing facts in\nknowledge graphs (KGs). Motivated by the lack of explainability for the outputs\nof these models, recent work has aimed to explain their predictions using\nDatalog, a widely used logic-based formalism. However, such work has been\nrestricted to certain subclasses of GNNs. In this paper, we consider one of the\nmost popular GNN architectures for KGs, R-GCN, and we provide two methods to\nextract rules that explain its predictions and are sound, in the sense that\neach fact derived by the rules is also predicted by the GNN, for any input\ndataset. Furthermore, we provide a method that can verify that certain classes\nof Datalog rules are not sound for the R-GCN. In our experiments, we train\nR-GCNs on KG completion benchmarks, and we are able to verify that no Datalog\nrule is sound for these models, even though the models often obtain high to\nnear-perfect accuracy. This raises some concerns about the ability of R-GCN\nmodels to generalise and about the explainability of their predictions. We\nfurther provide two variations to the training paradigm of R-GCN that encourage\nit to learn sound rules and find a trade-off between model accuracy and the\nnumber of learned sound rules.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Logic in Computer Science"],"license":"http://creativecommons.org/licenses/by/4.0/"}