{"id":"2407.16174","title":"Pixel Embedding: Fully Quantized Convolutional Neural Network with\n  Differentiable Lookup Table","authors":"Hiroyuki Tokunaga, Joel Nicholls, Daria Vazhenina, Atsunori Kanemura","authorsParsed":[["Tokunaga","Hiroyuki",""],["Nicholls","Joel",""],["Vazhenina","Daria",""],["Kanemura","Atsunori",""]],"versions":[{"version":"v1","created":"Tue, 23 Jul 2024 04:41:36 GMT"}],"updateDate":"2024-07-24","timestamp":1721709696000,"abstract":"  By quantizing network weights and activations to low bitwidth, we can obtain\nhardware-friendly and energy-efficient networks. However, existing quantization\ntechniques utilizing the straight-through estimator and piecewise constant\nfunctions face the issue of how to represent originally high-bit input data\nwith low-bit values. To fully quantize deep neural networks, we propose pixel\nembedding, which replaces each float-valued input pixel with a vector of\nquantized values by using a lookup table. The lookup table or low-bit\nrepresentation of pixels is differentiable and trainable by backpropagation.\nSuch replacement of inputs with vectors is similar to word embedding in the\nnatural language processing field. Experiments on ImageNet and CIFAR-100 show\nthat pixel embedding reduces the top-5 error gap caused by quantizing the\nfloating points at the first layer to only 1% for the ImageNet dataset, and the\ntop-1 error gap caused by quantizing first and last layers to slightly over 1%\nfor the CIFAR-100 dataset. The usefulness of pixel embedding is further\ndemonstrated by inference time measurements, which demonstrate over 1.7 times\nspeedup compared to floating point precision first layer.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}