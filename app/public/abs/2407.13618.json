{"id":"2407.13618","title":"DDS: DPU-optimized Disaggregated Storage [Extended Report]","authors":"Qizhen Zhang, Philip Bernstein, Badrish Chandramouli, Jiasheng Hu,\n  Yiming Zheng","authorsParsed":[["Zhang","Qizhen",""],["Bernstein","Philip",""],["Chandramouli","Badrish",""],["Hu","Jiasheng",""],["Zheng","Yiming",""]],"versions":[{"version":"v1","created":"Thu, 18 Jul 2024 15:55:52 GMT"},{"version":"v2","created":"Fri, 26 Jul 2024 08:01:30 GMT"},{"version":"v3","created":"Mon, 29 Jul 2024 02:08:49 GMT"},{"version":"v4","created":"Fri, 16 Aug 2024 08:17:25 GMT"},{"version":"v5","created":"Wed, 28 Aug 2024 09:23:40 GMT"}],"updateDate":"2024-08-29","timestamp":1721318152000,"abstract":"  This extended report presents DDS, a novel disaggregated storage architecture\nenabled by emerging networking hardware, namely DPUs (Data Processing Units).\nDPUs can optimize the latency and CPU consumption of disaggregated storage\nservers. However, utilizing DPUs for DBMSs requires careful design of the\nnetwork and storage paths and the interface exposed to the DBMS. To fully\nbenefit from DPUs, DDS heavily uses DMA, zero-copy, and userspace I/O to\nminimize overhead when improving throughput. It also introduces an offload\nengine that eliminates host CPUs by executing client requests directly on the\nDPU. Adopting DDS' API requires minimal DBMS modification. Our experimental\nstudy and production system integration show promising results -- DDS achieves\nhigher disaggregated storage throughput with an order of magnitude lower\nlatency, and saves up to tens of CPU cores per storage server.\n","subjects":["Computing Research Repository/Distributed, Parallel, and Cluster Computing"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/"}