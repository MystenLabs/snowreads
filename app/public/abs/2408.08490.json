{"id":"2408.08490","title":"Accelerating Mini-batch HGNN Training by Reducing CUDA Kernels","authors":"Meng Wu, Jingkai Qiu, Mingyu Yan, Wenming Li, Yang Zhang, Zhimin\n  Zhang, Xiaochun Ye, and Dongrui Fan","authorsParsed":[["Wu","Meng",""],["Qiu","Jingkai",""],["Yan","Mingyu",""],["Li","Wenming",""],["Zhang","Yang",""],["Zhang","Zhimin",""],["Ye","Xiaochun",""],["Fan","Dongrui",""]],"versions":[{"version":"v1","created":"Fri, 16 Aug 2024 02:19:04 GMT"}],"updateDate":"2024-08-19","timestamp":1723774744000,"abstract":"  Heterogeneous graph neural networks (HGNNs) are essential for capturing the\nstructure and semantic information in heterogeneous graphs. However, existing\nGPU-based solutions, such as PyTorch Geometric, suffer from low GPU utilization\ndue to numerous short-execution-time and memory-bound CUDA kernels during HGNN\ntraining.\n  To address this issue, we introduce HiFuse, an enhancement for PyTorch\nGeometric designed to accelerate mini-batch HGNN training on CPU-GPU systems.\nFrom the data perspective, we reorganize and merge multiple smaller vertex\nfeature matrices into larger ones, enabling a single kernel to process larger\ndata chunks. This efficiently exploits data locality, reduces the kernel launch\noverhead, and improves overall GPU utilization. From the workflow perspective,\nwe sophisticatedly offload the construction of semantic graphs from GPU to CPU\nto reduce the number of CUDA kernels. To meet the parallelism requirements on\nCPU and ensure seamless execution between CPU and GPU, we employ\nparallelization techniques including multi-threading and asynchronous pipeline.\nThis allows different stages of the process to overlap, enhancing GPU\nutilization and reducing end-to-end execution latency, leading to a more\nefficient and balanced use of computational resources. Through extensive\nexperiments, HiFuse demonstrates an average 2.38 times speedup compared to a\nstate-of-the-art solution.\n","subjects":["Computing Research Repository/Hardware Architecture"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"Eg6rZqJ30Ek5gY0pvyG4UEN50RLRjl8lcfM_FWQDBMw","pdfSize":"1406888"}
