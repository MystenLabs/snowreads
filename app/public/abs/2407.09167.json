{"id":"2407.09167","title":"SE(3)-bi-equivariant Transformers for Point Cloud Assembly","authors":"Ziming Wang, Rebecka J\\\"ornsten","authorsParsed":[["Wang","Ziming",""],["JÃ¶rnsten","Rebecka",""]],"versions":[{"version":"v1","created":"Fri, 12 Jul 2024 11:01:28 GMT"},{"version":"v2","created":"Sat, 20 Jul 2024 11:04:40 GMT"}],"updateDate":"2024-07-23","timestamp":1720782088000,"abstract":"  Given a pair of point clouds, the goal of assembly is to recover a rigid\ntransformation that aligns one point cloud to the other. This task is\nchallenging because the point clouds may be non-overlapped, and they may have\narbitrary initial positions. To address these difficulties, we propose a\nmethod, called SE(3)-bi-equivariant transformer (BITR), based on the\nSE(3)-bi-equivariance prior of the task: it guarantees that when the inputs are\nrigidly perturbed, the output will transform accordingly. Due to its\nequivariance property, BITR can not only handle non-overlapped PCs, but also\nguarantee robustness against initial positions. Specifically, BITR first\nextracts features of the inputs using a novel $SE(3) \\times SE(3)$-transformer,\nand then projects the learned feature to group SE(3) as the output. Moreover,\nwe theoretically show that swap and scale equivariances can be incorporated\ninto BITR, thus it further guarantees stable performance under scaling and\nswapping the inputs. We experimentally show the effectiveness of BITR in\npractical tasks.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}