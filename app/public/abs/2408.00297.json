{"id":"2408.00297","title":"EmoTalk3D: High-Fidelity Free-View Synthesis of Emotional 3D Talking\n  Head","authors":"Qianyun He and Xinya Ji and Yicheng Gong and Yuanxun Lu and Zhengyu\n  Diao and Linjia Huang and Yao Yao and Siyu Zhu and Zhan Ma and Songcen Xu and\n  Xiaofei Wu and Zixiao Zhang and Xun Cao and Hao Zhu","authorsParsed":[["He","Qianyun",""],["Ji","Xinya",""],["Gong","Yicheng",""],["Lu","Yuanxun",""],["Diao","Zhengyu",""],["Huang","Linjia",""],["Yao","Yao",""],["Zhu","Siyu",""],["Ma","Zhan",""],["Xu","Songcen",""],["Wu","Xiaofei",""],["Zhang","Zixiao",""],["Cao","Xun",""],["Zhu","Hao",""]],"versions":[{"version":"v1","created":"Thu, 1 Aug 2024 05:46:57 GMT"}],"updateDate":"2024-08-02","timestamp":1722491217000,"abstract":"  We present a novel approach for synthesizing 3D talking heads with\ncontrollable emotion, featuring enhanced lip synchronization and rendering\nquality. Despite significant progress in the field, prior methods still suffer\nfrom multi-view consistency and a lack of emotional expressiveness. To address\nthese issues, we collect EmoTalk3D dataset with calibrated multi-view videos,\nemotional annotations, and per-frame 3D geometry. By training on the EmoTalk3D\ndataset, we propose a \\textit{`Speech-to-Geometry-to-Appearance'} mapping\nframework that first predicts faithful 3D geometry sequence from the audio\nfeatures, then the appearance of a 3D talking head represented by 4D Gaussians\nis synthesized from the predicted geometry. The appearance is further\ndisentangled into canonical and dynamic Gaussians, learned from multi-view\nvideos, and fused to render free-view talking head animation. Moreover, our\nmodel enables controllable emotion in the generated talking heads and can be\nrendered in wide-range views. Our method exhibits improved rendering quality\nand stability in lip motion generation while capturing dynamic facial details\nsuch as wrinkles and subtle expressions. Experiments demonstrate the\neffectiveness of our approach in generating high-fidelity and\nemotion-controllable 3D talking heads. The code and EmoTalk3D dataset are\nreleased at https://nju-3dv.github.io/projects/EmoTalk3D.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}