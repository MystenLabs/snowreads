{"id":"2407.04686","title":"Near-optimal hierarchical matrix approximation from matrix-vector\n  products","authors":"Tyler Chen, Feyza Duman Keles, Diana Halikias, Cameron Musco,\n  Christopher Musco, David Persson","authorsParsed":[["Chen","Tyler",""],["Keles","Feyza Duman",""],["Halikias","Diana",""],["Musco","Cameron",""],["Musco","Christopher",""],["Persson","David",""]],"versions":[{"version":"v1","created":"Fri, 5 Jul 2024 17:49:15 GMT"}],"updateDate":"2024-07-08","timestamp":1720201755000,"abstract":"  We describe a randomized algorithm for producing a near-optimal hierarchical\noff-diagonal low-rank (HODLR) approximation to an $n\\times n$ matrix\n$\\mathbf{A}$, accessible only though matrix-vector products with $\\mathbf{A}$\nand $\\mathbf{A}^{\\mathsf{T}}$. We prove that, for the rank-$k$ HODLR\napproximation problem, our method achieves a $(1+\\beta)^{\\log(n)}$-optimal\napproximation in expected Frobenius norm using $O(k\\log(n)/\\beta^3)$\nmatrix-vector products. In particular, the algorithm obtains a\n$(1+\\varepsilon)$-optimal approximation with $O(k\\log^4(n)/\\varepsilon^3)$\nmatrix-vector products, and for any constant $c$, an $n^c$-optimal\napproximation with $O(k \\log(n))$ matrix-vector products. Apart from\nmatrix-vector products, the additional computational cost of our method is just\n$O(n \\operatorname{poly}(\\log(n), k, \\beta))$. We complement the upper bound\nwith a lower bound, which shows that any matrix-vector query algorithm requires\nat least $\\Omega(k\\log(n) + k/\\varepsilon)$ queries to obtain a\n$(1+\\varepsilon)$-optimal approximation.\n  Our algorithm can be viewed as a robust version of widely used \"peeling\"\nmethods for recovering HODLR matrices and is, to the best of our knowledge, the\nfirst matrix-vector query algorithm to enjoy theoretical worst-case guarantees\nfor approximation by any hierarchical matrix class. To control the propagation\nof error between levels of hierarchical approximation, we introduce a new\nperturbation bound for low-rank approximation, which shows that the widely used\nGeneralized Nystr\\\"om method enjoys inherent stability when implemented with\nnoisy matrix-vector products. We also introduced a novel randomly perforated\nmatrix sketching method to further control the error in the peeling algorithm.\n","subjects":["Computing Research Repository/Data Structures and Algorithms","Computing Research Repository/Numerical Analysis","Mathematics/Numerical Analysis"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}