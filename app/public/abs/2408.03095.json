{"id":"2408.03095","title":"TestART: Improving LLM-based Unit Test via Co-evolution of Automated\n  Generation and Repair Iteration","authors":"Siqi Gu, Chunrong Fang, Quanjun Zhang, Fangyuan Tian, Jianyi Zhou and\n  Zhenyu Chen","authorsParsed":[["Gu","Siqi",""],["Fang","Chunrong",""],["Zhang","Quanjun",""],["Tian","Fangyuan",""],["Zhou","Jianyi",""],["Chen","Zhenyu",""]],"versions":[{"version":"v1","created":"Tue, 6 Aug 2024 10:52:41 GMT"},{"version":"v2","created":"Wed, 7 Aug 2024 07:28:48 GMT"},{"version":"v3","created":"Mon, 12 Aug 2024 08:27:56 GMT"}],"updateDate":"2024-08-13","timestamp":1722941561000,"abstract":"  Unit test is crucial for detecting bugs in individual program units but\nconsumes time and effort. The existing automated unit test generation methods\nare mainly based on search-based software testing (SBST) and language models to\nliberate developers. Recently, large language models (LLMs) have demonstrated\nremarkable reasoning and generation capabilities. However, several problems\nlimit their ability to generate high-quality test cases: (1) LLMs may generate\ninvalid test cases under insufficient context, resulting in compilation errors;\n(2) Lack of test and coverage feedback information may cause runtime errors and\nlow coverage rates. (3) The repetitive suppression problem causes LLMs to get\nstuck into the repetition loop of self-repair or re-generation attempts. In\nthis paper, we propose TestART, a novel unit test generation method that\nleverages the strengths of LLMs while overcoming the limitations mentioned.\nTestART improves LLM-based unit test via co-evolution of automated generation\nand repair iteration. TestART leverages the template-based repair technique to\nfix bugs in LLM-generated test cases, using prompt injection to guide the\nnext-step automated generation and avoid repetition suppression. Furthermore,\nTestART extracts coverage information from the passed test cases and utilizes\nit as testing feedback to enhance the sufficiency of the final test case. This\nsynergy between generation and repair elevates the quality, effectiveness, and\nreadability of the produced test cases significantly beyond previous methods.\nIn comparative experiments, the pass rate of TestART-generated test cases is\n78.55%, which is approximately 18% higher than both the ChatGPT-4.0 model and\nthe same ChatGPT-3.5-based method ChatUniTest. It also achieves an impressive\nline coverage rate of 90.96% on the focal methods that passed the test,\nexceeding EvoSuite by 3.4%.\n","subjects":["Computing Research Repository/Software Engineering"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}