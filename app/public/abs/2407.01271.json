{"id":"2407.01271","title":"First Place Solution of 2023 Global Artificial Intelligence Technology\n  Innovation Competition Track 1","authors":"Xiangyu Wu, Hailiang Zhang, Yang Yang, Jianfeng Lu","authorsParsed":[["Wu","Xiangyu",""],["Zhang","Hailiang",""],["Yang","Yang",""],["Lu","Jianfeng",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 13:22:22 GMT"},{"version":"v2","created":"Thu, 4 Jul 2024 03:53:07 GMT"}],"updateDate":"2024-07-08","timestamp":1719840142000,"abstract":"  In this paper, we present our champion solution to the Global Artificial\nIntelligence Technology Innovation Competition Track 1: Medical Imaging\nDiagnosis Report Generation. We select CPT-BASE as our base model for the text\ngeneration task. During the pre-training stage, we delete the mask language\nmodeling task of CPT-BASE and instead reconstruct the vocabulary, adopting a\nspan mask strategy and gradually increasing the number of masking ratios to\nperform the denoising auto-encoder pre-training task. In the fine-tuning stage,\nwe design iterative retrieval augmentation and noise-aware similarity bucket\nprompt strategies. The retrieval augmentation constructs a mini-knowledge base,\nenriching the input information of the model, while the similarity bucket\nfurther perceives the noise information within the mini-knowledge base, guiding\nthe model to generate higher-quality diagnostic reports based on the similarity\nprompts. Surprisingly, our single model has achieved a score of 2.321 on\nleaderboard A, and the multiple model fusion scores are 2.362 and 2.320 on the\nA and B leaderboards respectively, securing first place in the rankings.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/"}