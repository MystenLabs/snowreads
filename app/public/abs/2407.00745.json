{"id":"2407.00745","title":"Posterior Sampling with Denoising Oracles via Tilted Transport","authors":"Joan Bruna and Jiequn Han","authorsParsed":[["Bruna","Joan",""],["Han","Jiequn",""]],"versions":[{"version":"v1","created":"Sun, 30 Jun 2024 16:11:42 GMT"}],"updateDate":"2024-07-02","timestamp":1719763902000,"abstract":"  Score-based diffusion models have significantly advanced high-dimensional\ndata generation across various domains, by learning a denoising oracle (or\nscore) from datasets. From a Bayesian perspective, they offer a realistic\nmodeling of data priors and facilitate solving inverse problems through\nposterior sampling. Although many heuristic methods have been developed\nrecently for this purpose, they lack the quantitative guarantees needed in many\nscientific applications.\n  In this work, we introduce the \\textit{tilted transport} technique, which\nleverages the quadratic structure of the log-likelihood in linear inverse\nproblems in combination with the prior denoising oracle to transform the\noriginal posterior sampling problem into a new `boosted' posterior that is\nprovably easier to sample from. We quantify the conditions under which this\nboosted posterior is strongly log-concave, highlighting the dependencies on the\ncondition number of the measurement matrix and the signal-to-noise ratio. The\nresulting posterior sampling scheme is shown to reach the computational\nthreshold predicted for sampling Ising models [Kunisky'23] with a direct\nanalysis, and is further validated on high-dimensional Gaussian mixture models\nand scalar field $\\varphi^4$ models.\n","subjects":["Computing Research Repository/Machine Learning","Mathematics/Probability","Statistics/Computation","Statistics/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}