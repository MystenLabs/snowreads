{"id":"2407.12025","title":"LLM4DESIGN: An Automated Multi-Modal System for Architectural and\n  Environmental Design","authors":"Ran Chen, Xueqi Yao, Xuhui Jiang","authorsParsed":[["Chen","Ran",""],["Yao","Xueqi",""],["Jiang","Xuhui",""]],"versions":[{"version":"v1","created":"Fri, 28 Jun 2024 10:57:50 GMT"}],"updateDate":"2024-07-18","timestamp":1719572270000,"abstract":"  This study introduces LLM4DESIGN, a highly automated system for generating\narchitectural and environmental design proposals. LLM4DESIGN, relying solely on\nsite conditions and design requirements, employs Multi-Agent systems to foster\ncreativity, Retrieval Augmented Generation (RAG) to ground designs in realism,\nand Visual Language Models (VLM) to synchronize all information. This system\nresulting in coherent, multi-illustrated, and multi-textual design schemes. The\nsystem meets the dual needs of narrative storytelling and objective drawing\npresentation in generating architectural and environmental design proposals.\nExtensive comparative and ablation experiments confirm the innovativeness of\nLLM4DESIGN's narrative and the grounded applicability of its plans,\ndemonstrating its superior performance in the field of urban renewal design.\nLastly, we have created the first cross-modal design scheme dataset covering\narchitecture, landscape, interior, and urban design, providing rich resources\nfor future research.\n","subjects":["Computing Research Repository/Human-Computer Interaction","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}