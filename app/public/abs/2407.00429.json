{"id":"2407.00429","title":"Time Series Clustering with General State Space Models via Stochastic\n  Variational Inference","authors":"Ryoichi Ishizuka, Takashi Imai, Kaoru Kawamoto","authorsParsed":[["Ishizuka","Ryoichi",""],["Imai","Takashi",""],["Kawamoto","Kaoru",""]],"versions":[{"version":"v1","created":"Sat, 29 Jun 2024 12:48:53 GMT"},{"version":"v2","created":"Thu, 22 Aug 2024 14:50:24 GMT"}],"updateDate":"2024-08-23","timestamp":1719665333000,"abstract":"  In this paper, we propose a novel method of model-based time series\nclustering with mixtures of general state space models (MSSMs). Each component\nof MSSMs is associated with each cluster. An advantage of the proposed method\nis that it enables the use of time series models appropriate to the specific\ntime series. This not only improves clustering and prediction accuracy but also\nenhances the interpretability of the estimated parameters. The parameters of\nthe MSSMs are estimated using stochastic variational inference, a subtype of\nvariational inference. The proposed method estimates the latent variables of an\narbitrary state space model by using neural networks with a normalizing flow as\na variational estimator. The number of clusters can be estimated using the\nBayesian information criterion. In addition, to prevent MSSMs from converging\nto the local optimum, we propose several optimization tricks, including an\nadditional penalty term called entropy annealing. To our best knowledge, the\nproposed method is the first computationally feasible one for time series\nclustering based on general (possibly nonlinear, non-Gaussian) state space\nmodels. Experiments on simulated datasets show that the proposed method is\neffective for clustering, parameter estimation, and estimating the number of\nclusters.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}