{"id":"2408.16971","title":"Synthetic Lunar Terrain: A Multimodal Open Dataset for Training and\n  Evaluating Neuromorphic Vision Algorithms","authors":"Marcus M\\\"artens, Kevin Farries, John Culton, Tat-Jun Chin","authorsParsed":[["MÃ¤rtens","Marcus",""],["Farries","Kevin",""],["Culton","John",""],["Chin","Tat-Jun",""]],"versions":[{"version":"v1","created":"Fri, 30 Aug 2024 02:14:33 GMT"}],"updateDate":"2024-09-02","timestamp":1724984073000,"abstract":"  Synthetic Lunar Terrain (SLT) is an open dataset collected from an analogue\ntest site for lunar missions, featuring synthetic craters in a high-contrast\nlighting setup. It includes several side-by-side captures from event-based and\nconventional RGB cameras, supplemented with a high-resolution 3D laser scan for\ndepth estimation. The event-stream recorded from the neuromorphic vision sensor\nof the event-based camera is of particular interest as this emerging technology\nprovides several unique advantages, such as high data rates, low energy\nconsumption and resilience towards scenes of high dynamic range. SLT provides a\nsolid foundation to analyse the limits of RGB-cameras and potential advantages\nor synergies in utilizing neuromorphic visions with the goal of enabling and\nimproving lunar specific applications like rover navigation, landing in\ncratered environments or similar.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}