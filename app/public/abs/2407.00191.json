{"id":"2407.00191","title":"MetaKP: On-Demand Keyphrase Generation","authors":"Di Wu, Xiaoxian Shen, Kai-Wei Chang","authorsParsed":[["Wu","Di",""],["Shen","Xiaoxian",""],["Chang","Kai-Wei",""]],"versions":[{"version":"v1","created":"Fri, 28 Jun 2024 19:02:59 GMT"}],"updateDate":"2024-07-02","timestamp":1719601379000,"abstract":"  Traditional keyphrase prediction methods predict a single set of keyphrases\nper document, failing to cater to the diverse needs of users and downstream\napplications. To bridge the gap, we introduce on-demand keyphrase generation, a\nnovel paradigm that requires keyphrases that conform to specific high-level\ngoals or intents. For this task, we present MetaKP, a large-scale benchmark\ncomprising four datasets, 7500 documents, and 3760 goals across news and\nbiomedical domains with human-annotated keyphrases. Leveraging MetaKP, we\ndesign both supervised and unsupervised methods, including a multi-task\nfine-tuning approach and a self-consistency prompting method with large\nlanguage models. The results highlight the challenges of supervised\nfine-tuning, whose performance is not robust to distribution shifts. By\ncontrast, the proposed self-consistency prompting approach greatly improves the\nperformance of large language models, enabling GPT-4o to achieve 0.548 SemF1,\nsurpassing the performance of a fully fine-tuned BART-base model. Finally, we\ndemonstrate the potential of our method to serve as a general NLP\ninfrastructure, exemplified by its application in epidemic event detection from\nsocial media.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/"}