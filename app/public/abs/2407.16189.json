{"id":"2407.16189","title":"EIANet: A Novel Domain Adaptation Approach to Maximize Class Distinction\n  with Neural Collapse Principles","authors":"Zicheng Pan, Xiaohan Yu, Yongsheng Gao","authorsParsed":[["Pan","Zicheng",""],["Yu","Xiaohan",""],["Gao","Yongsheng",""]],"versions":[{"version":"v1","created":"Tue, 23 Jul 2024 05:31:05 GMT"}],"updateDate":"2024-07-24","timestamp":1721712665000,"abstract":"  Source-free domain adaptation (SFDA) aims to transfer knowledge from a\nlabelled source domain to an unlabelled target domain. A major challenge in\nSFDA is deriving accurate categorical information for the target domain,\nespecially when sample embeddings from different classes appear similar. This\nissue is particularly pronounced in fine-grained visual categorization tasks,\nwhere inter-class differences are subtle. To overcome this challenge, we\nintroduce a novel ETF-Informed Attention Network (EIANet) to separate class\nprototypes by utilizing attention and neural collapse principles. More\nspecifically, EIANet employs a simplex Equiangular Tight Frame (ETF) classifier\nin conjunction with an attention mechanism, facilitating the model to focus on\ndiscriminative features and ensuring maximum class prototype separation. This\ninnovative approach effectively enlarges the feature difference between\ndifferent classes in the latent space by locating salient regions, thereby\npreventing the misclassification of similar but distinct category samples and\nproviding more accurate categorical information to guide the fine-tuning\nprocess on the target domain. Experimental results across four SFDA datasets\nvalidate EIANet's state-of-the-art performance. Code is available at:\nhttps://github.com/zichengpan/EIANet.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}