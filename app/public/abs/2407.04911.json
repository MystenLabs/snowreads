{"id":"2407.04911","title":"Enhanced Long-Tailed Recognition with Contrastive CutMix Augmentation","authors":"Haolin Pan, Yong Guo, Mianjie Yu, Jian Chen","authorsParsed":[["Pan","Haolin",""],["Guo","Yong",""],["Yu","Mianjie",""],["Chen","Jian",""]],"versions":[{"version":"v1","created":"Sat, 6 Jul 2024 01:31:49 GMT"}],"updateDate":"2024-07-09","timestamp":1720229509000,"abstract":"  Real-world data often follows a long-tailed distribution, where a few head\nclasses occupy most of the data and a large number of tail classes only contain\nvery limited samples. In practice, deep models often show poor generalization\nperformance on tail classes due to the imbalanced distribution. To tackle this,\ndata augmentation has become an effective way by synthesizing new samples for\ntail classes. Among them, one popular way is to use CutMix that explicitly\nmixups the images of tail classes and the others, while constructing the labels\naccording to the ratio of areas cropped from two images. However, the\narea-based labels entirely ignore the inherent semantic information of the\naugmented samples, often leading to misleading training signals. To address\nthis issue, we propose a Contrastive CutMix (ConCutMix) that constructs\naugmented samples with semantically consistent labels to boost the performance\nof long-tailed recognition. Specifically, we compute the similarities between\nsamples in the semantic space learned by contrastive learning, and use them to\nrectify the area-based labels. Experiments show that our ConCutMix\nsignificantly improves the accuracy on tail classes as well as the overall\nperformance. For example, based on ResNeXt-50, we improve the overall accuracy\non ImageNet-LT by 3.0% thanks to the significant improvement of 3.3% on tail\nclasses. We highlight that the improvement also generalizes well to other\nbenchmarks and models. Our code and pretrained models are available at\nhttps://github.com/PanHaulin/ConCutMix.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}