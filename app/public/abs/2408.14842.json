{"id":"2408.14842","title":"From Bias to Balance: Detecting Facial Expression Recognition Biases in\n  Large Multimodal Foundation Models","authors":"Kaylee Chhua, Zhoujinyi Wen, Vedant Hathalia, Kevin Zhu, Sean O'Brien","authorsParsed":[["Chhua","Kaylee",""],["Wen","Zhoujinyi",""],["Hathalia","Vedant",""],["Zhu","Kevin",""],["O'Brien","Sean",""]],"versions":[{"version":"v1","created":"Tue, 27 Aug 2024 07:54:01 GMT"}],"updateDate":"2024-08-28","timestamp":1724745241000,"abstract":"  This study addresses the racial biases in facial expression recognition (FER)\nsystems within Large Multimodal Foundation Models (LMFMs). Despite advances in\ndeep learning and the availability of diverse datasets, FER systems often\nexhibit higher error rates for individuals with darker skin tones. Existing\nresearch predominantly focuses on traditional FER models (CNNs, RNNs, ViTs),\nleaving a gap in understanding racial biases in LMFMs. We benchmark four\nleading LMFMs: GPT-4o, PaliGemma, Gemini, and CLIP to assess their performance\nin facial emotion detection across different racial demographics. A linear\nclassifier trained on CLIP embeddings obtains accuracies of 95.9\\% for RADIATE,\n90.3\\% for Tarr, and 99.5\\% for Chicago Face. Furthermore, we identify that\nAnger is misclassified as Disgust 2.1 times more often in Black Females than\nWhite Females. This study highlights the need for fairer FER systems and\nestablishes a foundation for developing unbiased, accurate FER technologies.\nVisit https://kvjvhub.github.io/FERRacialBias/ for further information\nregarding the biases within facial expression recognition.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"3FjsNlhWMkVaGdlLi16_LWdrXssCpNWAIuyr2tjrlq8","pdfSize":"3220553"}
