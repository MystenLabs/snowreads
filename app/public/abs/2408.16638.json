{"id":"2408.16638","title":"3D Pose-Based Temporal Action Segmentation for Figure Skating: A\n  Fine-Grained and Jump Procedure-Aware Annotation Approach","authors":"Ryota Tanaka, Tomohiro Suzuki, and Keisuke Fujii","authorsParsed":[["Tanaka","Ryota",""],["Suzuki","Tomohiro",""],["Fujii","Keisuke",""]],"versions":[{"version":"v1","created":"Thu, 29 Aug 2024 15:42:06 GMT"}],"updateDate":"2024-08-30","timestamp":1724946126000,"abstract":"  Understanding human actions from videos is essential in many domains,\nincluding sports. In figure skating, technical judgments are performed by\nwatching skaters' 3D movements, and its part of the judging procedure can be\nregarded as a Temporal Action Segmentation (TAS) task. TAS tasks in figure\nskating that automatically assign temporal semantics to video are actively\nresearched. However, there is a lack of datasets and effective methods for TAS\ntasks requiring 3D pose data. In this study, we first created the FS-Jump3D\ndataset of complex and dynamic figure skating jumps using optical markerless\nmotion capture. We also propose a new fine-grained figure skating jump TAS\ndataset annotation method with which TAS models can learn jump procedures. In\nthe experimental results, we validated the usefulness of 3D pose features as\ninput and the fine-grained dataset for the TAS model in figure skating.\nFS-Jump3D Dataset is available at https://github.com/ryota-skating/FS-Jump3D.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by-sa/4.0/","blobId":"xTSZcoE4w95RbYJ-PtoOg5WQ8XAsTPhjhWXnMSujE2A","pdfSize":"7563735"}
