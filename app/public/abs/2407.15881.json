{"id":"2407.15881","title":"Data Sharing for Mean Estimation Among Heterogeneous Strategic Agents","authors":"Alex Clinton, Yiding Chen, Xiaojin Zhu, Kirthevasan Kandasamy","authorsParsed":[["Clinton","Alex",""],["Chen","Yiding",""],["Zhu","Xiaojin",""],["Kandasamy","Kirthevasan",""]],"versions":[{"version":"v1","created":"Sat, 20 Jul 2024 17:45:40 GMT"}],"updateDate":"2024-07-24","timestamp":1721497540000,"abstract":"  We study a collaborative learning problem where $m$ agents estimate a vector\n$\\mu\\in\\mathbb{R}^d$ by collecting samples from normal distributions, with each\nagent $i$ incurring a cost $c_{i,k} \\in (0, \\infty]$ to sample from the\n$k^{\\text{th}}$ distribution $\\mathcal{N}(\\mu_k, \\sigma^2)$. Instead of working\non their own, agents can collect data that is cheap to them, and share it with\nothers in exchange for data that is expensive or even inaccessible to them,\nthereby simultaneously reducing data collection costs and estimation error.\nHowever, when agents have different collection costs, we need to first decide\nhow to fairly divide the work of data collection so as to benefit all agents.\nMoreover, in naive sharing protocols, strategic agents may under-collect and/or\nfabricate data, leading to socially undesirable outcomes. Our mechanism\naddresses these challenges by combining ideas from cooperative and\nnon-cooperative game theory. We use ideas from axiomatic bargaining to divide\nthe cost of data collection. Given such a solution, we develop a Nash\nincentive-compatible (NIC) mechanism to enforce truthful reporting. We achieve\na $\\mathcal{O}(\\sqrt{m})$ approximation to the minimum social penalty (sum of\nagent estimation errors and data collection costs) in the worst case, and a\n$\\mathcal{O}(1)$ approximation under favorable conditions. We complement this\nwith a hardness result, showing that $\\Omega(\\sqrt{m})$ is unavoidable in any\nNIC mechanism.\n","subjects":["Computing Research Repository/Computer Science and Game Theory","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}