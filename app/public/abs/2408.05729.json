{"id":"2408.05729","title":"A Training-Free Framework for Video License Plate Tracking and\n  Recognition with Only One-Shot","authors":"Haoxuan Ding, Qi Wang, Junyu Gao, Qiang Li","authorsParsed":[["Ding","Haoxuan",""],["Wang","Qi",""],["Gao","Junyu",""],["Li","Qiang",""]],"versions":[{"version":"v1","created":"Sun, 11 Aug 2024 08:42:02 GMT"}],"updateDate":"2024-08-13","timestamp":1723365722000,"abstract":"  Traditional license plate detection and recognition models are often trained\non closed datasets, limiting their ability to handle the diverse license plate\nformats across different regions. The emergence of large-scale pre-trained\nmodels has shown exceptional generalization capabilities, enabling few-shot and\nzero-shot learning. We propose OneShotLP, a training-free framework for\nvideo-based license plate detection and recognition, leveraging these advanced\nmodels. Starting with the license plate position in the first video frame, our\nmethod tracks this position across subsequent frames using a point tracking\nmodule, creating a trajectory of prompts. These prompts are input into a\nsegmentation module that uses a promptable large segmentation model to generate\nlocal masks of the license plate regions. The segmented areas are then\nprocessed by multimodal large language models (MLLMs) for accurate license\nplate recognition. OneShotLP offers significant advantages, including the\nability to function effectively without extensive training data and\nadaptability to various license plate styles. Experimental results on UFPR-ALPR\nand SSIG-SegPlate datasets demonstrate the superior accuracy of our approach\ncompared to traditional methods. This highlights the potential of leveraging\npre-trained models for diverse real-world applications in intelligent\ntransportation systems. The code is available at\nhttps://github.com/Dinghaoxuan/OneShotLP.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}