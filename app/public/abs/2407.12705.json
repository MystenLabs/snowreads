{"id":"2407.12705","title":"IMAGDressing-v1: Customizable Virtual Dressing","authors":"Fei Shen, Xin Jiang, Xin He, Hu Ye, Cong Wang, Xiaoyu Du, Zechao Li,\n  and Jinhui Tang","authorsParsed":[["Shen","Fei",""],["Jiang","Xin",""],["He","Xin",""],["Ye","Hu",""],["Wang","Cong",""],["Du","Xiaoyu",""],["Li","Zechao",""],["Tang","Jinhui",""]],"versions":[{"version":"v1","created":"Wed, 17 Jul 2024 16:26:30 GMT"},{"version":"v2","created":"Tue, 6 Aug 2024 13:06:26 GMT"}],"updateDate":"2024-08-07","timestamp":1721233590000,"abstract":"  Latest advances have achieved realistic virtual try-on (VTON) through\nlocalized garment inpainting using latent diffusion models, significantly\nenhancing consumers' online shopping experience. However, existing VTON\ntechnologies neglect the need for merchants to showcase garments\ncomprehensively, including flexible control over garments, optional faces,\nposes, and scenes. To address this issue, we define a virtual dressing (VD)\ntask focused on generating freely editable human images with fixed garments and\noptional conditions. Meanwhile, we design a comprehensive affinity metric index\n(CAMI) to evaluate the consistency between generated images and reference\ngarments. Then, we propose IMAGDressing-v1, which incorporates a garment UNet\nthat captures semantic features from CLIP and texture features from VAE. We\npresent a hybrid attention module, including a frozen self-attention and a\ntrainable cross-attention, to integrate garment features from the garment UNet\ninto a frozen denoising UNet, ensuring users can control different scenes\nthrough text. IMAGDressing-v1 can be combined with other extension plugins,\nsuch as ControlNet and IP-Adapter, to enhance the diversity and controllability\nof generated images. Furthermore, to address the lack of data, we release the\ninteractive garment pairing (IGPair) dataset, containing over 300,000 pairs of\nclothing and dressed images, and establish a standard pipeline for data\nassembly. Extensive experiments demonstrate that our IMAGDressing-v1 achieves\nstate-of-the-art human image synthesis performance under various controlled\nconditions. The code and model will be available at\nhttps://github.com/muzishen/IMAGDressing.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"BotfDshkOQSgsL4i3lzxejuorYKKh54sI2gJIZBXETQ","pdfSize":"2950525"}
