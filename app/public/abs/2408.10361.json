{"id":"2408.10361","title":"ASASVIcomtech: The Vicomtech-UGR Speech Deepfake Detection and SASV\n  Systems for the ASVspoof5 Challenge","authors":"Juan M. Mart\\'in-Do\\~nas and Eros Rosell\\'o and Angel M. Gomez and\n  Aitor \\'Alvarez and Iv\\'an L\\'opez-Espejo and Antonio M. Peinado","authorsParsed":[["Martín-Doñas","Juan M.",""],["Roselló","Eros",""],["Gomez","Angel M.",""],["Álvarez","Aitor",""],["López-Espejo","Iván",""],["Peinado","Antonio M.",""]],"versions":[{"version":"v1","created":"Mon, 19 Aug 2024 18:57:34 GMT"}],"updateDate":"2024-08-21","timestamp":1724093854000,"abstract":"  This paper presents the work carried out by the ASASVIcomtech team, made up\nof researchers from Vicomtech and University of Granada, for the ASVspoof5\nChallenge. The team has participated in both Track 1 (speech deepfake\ndetection) and Track 2 (spoofing-aware speaker verification). This work started\nwith an analysis of the challenge available data, which was regarded as an\nessential step to avoid later potential biases of the trained models, and whose\nmain conclusions are presented here. With respect to the proposed approaches, a\nclosed-condition system employing a deep complex convolutional recurrent\narchitecture was developed for Track 1, although, unfortunately, no noteworthy\nresults were achieved. On the other hand, different possibilities of\nopen-condition systems, based on leveraging self-supervised models, augmented\ntraining data from previous challenges, and novel vocoders, were explored for\nboth tracks, finally achieving very competitive results with an ensemble\nsystem.\n","subjects":["Electrical Engineering and Systems Science/Audio and Speech Processing","Computing Research Repository/Sound"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}