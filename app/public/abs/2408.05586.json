{"id":"2408.05586","title":"Meta Clustering of Neural Bandits","authors":"Yikun Ban, Yunzhe Qi, Tianxin Wei, Lihui Liu, Jingrui He","authorsParsed":[["Ban","Yikun",""],["Qi","Yunzhe",""],["Wei","Tianxin",""],["Liu","Lihui",""],["He","Jingrui",""]],"versions":[{"version":"v1","created":"Sat, 10 Aug 2024 16:09:51 GMT"}],"updateDate":"2024-08-13","timestamp":1723306191000,"abstract":"  The contextual bandit has been identified as a powerful framework to\nformulate the recommendation process as a sequential decision-making process,\nwhere each item is regarded as an arm and the objective is to minimize the\nregret of $T$ rounds. In this paper, we study a new problem, Clustering of\nNeural Bandits, by extending previous work to the arbitrary reward function, to\nstrike a balance between user heterogeneity and user correlations in the\nrecommender system. To solve this problem, we propose a novel algorithm called\nM-CNB, which utilizes a meta-learner to represent and rapidly adapt to dynamic\nclusters, along with an informative Upper Confidence Bound (UCB)-based\nexploration strategy. We provide an instance-dependent performance guarantee\nfor the proposed algorithm that withstands the adversarial context, and we\nfurther prove the guarantee is at least as good as state-of-the-art (SOTA)\napproaches under the same assumptions. In extensive experiments conducted in\nboth recommendation and online classification scenarios, M-CNB outperforms SOTA\nbaselines. This shows the effectiveness of the proposed approach in improving\nonline recommendation and online classification performance.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Information Retrieval"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"fK_8zC7wnT11XEQCCbrLW1yTcSPxTORPHA6AKGwZRlk","pdfSize":"5897664"}
