{"id":"2407.02111","title":"Exploring Federated Learning Dynamics for Black-and-White-Box DNN\n  Traitor Tracing","authors":"Elena Rodriguez-Lois and Fernando Perez-Gonzalez","authorsParsed":[["Rodriguez-Lois","Elena",""],["Perez-Gonzalez","Fernando",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 09:54:35 GMT"}],"updateDate":"2024-07-03","timestamp":1719914075000,"abstract":"  As deep learning applications become more prevalent, the need for extensive\ntraining examples raises concerns for sensitive, personal, or proprietary data.\nTo overcome this, Federated Learning (FL) enables collaborative model training\nacross distributed data-owners, but it introduces challenges in safeguarding\nmodel ownership and identifying the origin in case of a leak. Building upon\nprior work, this paper explores the adaptation of black-and-white traitor\ntracing watermarking to FL classifiers, addressing the threat of collusion\nattacks from different data-owners. This study reveals that leak-resistant\nwhite-box fingerprints can be directly implemented without a significant impact\nfrom FL dynamics, while the black-box fingerprints are drastically affected,\nlosing their traitor tracing capabilities. To mitigate this effect, we propose\nincreasing the number of black-box salient neurons through dropout\nregularization. Though there are still some open problems to be explored, such\nas analyzing non-i.i.d. datasets and over-parameterized models, results show\nthat collusion-resistant traitor tracing, identifying all data-owners involved\nin a suspected leak, is feasible in an FL framework, even in early stages of\ntraining.\n","subjects":["Computing Research Repository/Cryptography and Security"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}