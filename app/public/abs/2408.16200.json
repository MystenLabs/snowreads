{"id":"2408.16200","title":"PolarBEVDet: Exploring Polar Representation for Multi-View 3D Object\n  Detection in Bird's-Eye-View","authors":"Zichen Yu, Quanli Liu, Wei Wang, Liyong Zhang, Xiaoguang Zhao","authorsParsed":[["Yu","Zichen",""],["Liu","Quanli",""],["Wang","Wei",""],["Zhang","Liyong",""],["Zhao","Xiaoguang",""]],"versions":[{"version":"v1","created":"Thu, 29 Aug 2024 01:42:38 GMT"}],"updateDate":"2024-08-30","timestamp":1724895758000,"abstract":"  Recently, LSS-based multi-view 3D object detection provides an economical and\ndeployment-friendly solution for autonomous driving. However, all the existing\nLSS-based methods transform multi-view image features into a Cartesian\nBird's-Eye-View(BEV) representation, which does not take into account the\nnon-uniform image information distribution and hardly exploits the view\nsymmetry. In this paper, in order to adapt the image information distribution\nand preserve the view symmetry by regular convolution, we propose to employ the\npolar BEV representation to substitute the Cartesian BEV representation. To\nachieve this, we elaborately tailor three modules: a polar view transformer to\ngenerate the polar BEV representation, a polar temporal fusion module for\nfusing historical polar BEV features and a polar detection head to predict the\npolar-parameterized representation of the object. In addition, we design a 2D\nauxiliary detection head and a spatial attention enhancement module to improve\nthe quality of feature extraction in perspective view and BEV, respectively.\nFinally, we integrate the above improvements into a novel multi-view 3D object\ndetector, PolarBEVDet. Experiments on nuScenes show that PolarBEVDet achieves\nthe superior performance. The code is available at\nhttps://github.com/Yzichen/PolarBEVDet.git.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}