{"id":"2407.08206","title":"System Report for CCL24-Eval Task 7: Multi-Error Modeling and\n  Fluency-Targeted Pre-training for Chinese Essay Evaluation","authors":"Jingshen Zhang, Xiangyu Yang, Xinkai Su, Xinglu Chen, Tianyou Huang,\n  Xinying Qiu","authorsParsed":[["Zhang","Jingshen",""],["Yang","Xiangyu",""],["Su","Xinkai",""],["Chen","Xinglu",""],["Huang","Tianyou",""],["Qiu","Xinying",""]],"versions":[{"version":"v1","created":"Thu, 11 Jul 2024 06:17:08 GMT"}],"updateDate":"2024-07-12","timestamp":1720678628000,"abstract":"  This system report presents our approaches and results for the Chinese Essay\nFluency Evaluation (CEFE) task at CCL-2024. For Track 1, we optimized\npredictions for challenging fine-grained error types using binary\nclassification models and trained coarse-grained models on the Chinese Learner\n4W corpus. In Track 2, we enhanced performance by constructing a pseudo-dataset\nwith multiple error types per sentence. For Track 3, where we achieved first\nplace, we generated fluency-rated pseudo-data via back-translation for\npre-training and used an NSP-based strategy with Symmetric Cross Entropy loss\nto capture context and mitigate long dependencies. Our methods effectively\naddress key challenges in Chinese Essay Fluency Evaluation.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"S1zf9kqf3CX0EYJd1H_JyQimhyKGCPv6NYDUkQYrraY","pdfSize":"2109951","objectId":"0x208e8b803f59358807dac946006ec376876406be3bf87b1289c3970077c07317","registeredEpoch":"1","certifiedEpoch":"1","startEpoch":"1","endEpoch":"201"}
