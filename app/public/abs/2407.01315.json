{"id":"2407.01315","title":"Language Portability Strategies for Open-domain Dialogue with\n  Pre-trained Language Models from High to Low Resource Languages","authors":"Ahmed Njifenjou, Virgile Sucal, Bassam Jabaian and Fabrice Lef\\`evre","authorsParsed":[["Njifenjou","Ahmed",""],["Sucal","Virgile",""],["Jabaian","Bassam",""],["Lef√®vre","Fabrice",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 14:20:54 GMT"}],"updateDate":"2024-07-02","timestamp":1719843654000,"abstract":"  In this paper we propose a study of linguistic portability strategies of\nlarge pre-trained language models (PLMs) used for open-domain dialogue systems\nin a high-resource language for this task. In particular the target\nlow-resource language (L_T) will be simulated with French, as it lacks of\ntask-specific resources and allows our human evaluation, when the source\nlanguage (L_S) is English. For obvious reasons, recent works using such models\nfor open-domain dialogue are mostly developed in English. Yet building specific\nPLMs for each possible target language supposes collecting new datasets and is\ncostly. For this reason, trying to leverage all existing resources (PLMs and\ndata) in both L_S and L_T , we wish to assess the performance achievable in L_T\nwith different approaches. The first two approaches evaluate the usage of\nNeural Machine Translation (NMT) at different levels: TrainOnTarget where a L_S\ndataset is translated before fine-tuning in L_T and TestOnSource where a L_S\nmodel is coupled with NMT modules during inference. Then, the advent of BLOOM\n[2], the world first open-access multilingual large PLM, allow researchers to\ndevelop new approaches aiming to leverage not only the model's full\naccessibility but also its multilingualism and translation abilities. In this\ncontext the task is learned in L_S first and adapted to L_T using the MAD-X\nAdapter architecture [16]. In the two sets of experiments models are evaluated\nin spoken dialogue conditions with human and the strategies can be compared in\nterms of perceived interaction quality.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}