{"id":"2408.15549","title":"WildFeedback: Aligning LLMs With In-situ User Interactions And Feedback","authors":"Taiwei Shi, Zhuoer Wang, Longqi Yang, Ying-Chun Lin, Zexue He,\n  Mengting Wan, Pei Zhou, Sujay Jauhar, Xiaofeng Xu, Xia Song, Jennifer Neville","authorsParsed":[["Shi","Taiwei",""],["Wang","Zhuoer",""],["Yang","Longqi",""],["Lin","Ying-Chun",""],["He","Zexue",""],["Wan","Mengting",""],["Zhou","Pei",""],["Jauhar","Sujay",""],["Xu","Xiaofeng",""],["Song","Xia",""],["Neville","Jennifer",""]],"versions":[{"version":"v1","created":"Wed, 28 Aug 2024 05:53:46 GMT"}],"updateDate":"2024-08-29","timestamp":1724824426000,"abstract":"  As large language models (LLMs) continue to advance, aligning these models\nwith human preferences has emerged as a critical challenge. Traditional\nalignment methods, relying on human or LLM annotated datasets, are limited by\ntheir resource-intensive nature, inherent subjectivity, and the risk of\nfeedback loops that amplify model biases. To overcome these limitations, we\nintroduce WildFeedback, a novel framework that leverages real-time, in-situ\nuser interactions to create preference datasets that more accurately reflect\nauthentic human values. WildFeedback operates through a three-step process:\nfeedback signal identification, preference data construction, and user-guided\nevaluation. We applied this framework to a large corpus of user-LLM\nconversations, resulting in a rich preference dataset that reflects genuine\nuser preferences. This dataset captures the nuances of user preferences by\nidentifying and classifying feedback signals within natural conversations,\nthereby enabling the construction of more representative and context-sensitive\nalignment data. Our extensive experiments demonstrate that LLMs fine-tuned on\nWildFeedback exhibit significantly improved alignment with user preferences, as\nevidenced by both traditional benchmarks and our proposed user-guided\nevaluation. By incorporating real-time feedback from actual users, WildFeedback\naddresses the scalability, subjectivity, and bias challenges that plague\nexisting approaches, marking a significant step toward developing LLMs that are\nmore responsive to the diverse and evolving needs of their users. In summary,\nWildFeedback offers a robust, scalable solution for aligning LLMs with true\nhuman values, setting a new standard for the development and evaluation of\nuser-centric language models.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/"}