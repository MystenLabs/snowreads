{"id":"2407.15590","title":"All rivers run into the sea: Unified Modality Brain-like Emotional\n  Central Mechanism","authors":"Xinji Mai, Junxiong Lin, Haoran Wang, Zeng Tao, Yan Wang, Shaoqi Yan,\n  Xuan Tong, Jiawen Yu, Boyang Wang, Ziheng Zhou, Qing Zhao, Shuyong Gao and\n  Wenqiang Zhang","authorsParsed":[["Mai","Xinji",""],["Lin","Junxiong",""],["Wang","Haoran",""],["Tao","Zeng",""],["Wang","Yan",""],["Yan","Shaoqi",""],["Tong","Xuan",""],["Yu","Jiawen",""],["Wang","Boyang",""],["Zhou","Ziheng",""],["Zhao","Qing",""],["Gao","Shuyong",""],["Zhang","Wenqiang",""]],"versions":[{"version":"v1","created":"Mon, 22 Jul 2024 12:26:31 GMT"}],"updateDate":"2024-07-23","timestamp":1721651191000,"abstract":"  In the field of affective computing, fully leveraging information from a\nvariety of sensory modalities is essential for the comprehensive understanding\nand processing of human emotions. Inspired by the process through which the\nhuman brain handles emotions and the theory of cross-modal plasticity, we\npropose UMBEnet, a brain-like unified modal affective processing network. The\nprimary design of UMBEnet includes a Dual-Stream (DS) structure that fuses\ninherent prompts with a Prompt Pool and a Sparse Feature Fusion (SFF) module.\nThe design of the Prompt Pool is aimed at integrating information from\ndifferent modalities, while inherent prompts are intended to enhance the\nsystem's predictive guidance capabilities and effectively manage knowledge\nrelated to emotion classification. Moreover, considering the sparsity of\neffective information across different modalities, the SSF module aims to make\nfull use of all available sensory data through the sparse integration of\nmodality fusion prompts and inherent prompts, maintaining high adaptability and\nsensitivity to complex emotional states. Extensive experiments on the largest\nbenchmark datasets in the Dynamic Facial Expression Recognition (DFER) field,\nincluding DFEW, FERV39k, and MAFW, have proven that UMBEnet consistently\noutperforms the current state-of-the-art methods. Notably, in scenarios of\nModality Missingness and multimodal contexts, UMBEnet significantly surpasses\nthe leading current methods, demonstrating outstanding performance and\nadaptability in tasks that involve complex emotional understanding with rich\nmultimodal information.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}