{"id":"2408.15591","title":"VFLIP: A Backdoor Defense for Vertical Federated Learning via\n  Identification and Purification","authors":"Yungi Cho, Woorim Han, Miseon Yu, Younghan Lee, Ho Bae, Yunheung Paek","authorsParsed":[["Cho","Yungi",""],["Han","Woorim",""],["Yu","Miseon",""],["Lee","Younghan",""],["Bae","Ho",""],["Paek","Yunheung",""]],"versions":[{"version":"v1","created":"Wed, 28 Aug 2024 07:31:32 GMT"},{"version":"v2","created":"Thu, 29 Aug 2024 02:01:56 GMT"}],"updateDate":"2024-08-30","timestamp":1724830292000,"abstract":"  Vertical Federated Learning (VFL) focuses on handling vertically partitioned\ndata over FL participants. Recent studies have discovered a significant\nvulnerability in VFL to backdoor attacks which specifically target the distinct\ncharacteristics of VFL. Therefore, these attacks may neutralize existing\ndefense mechanisms designed primarily for Horizontal Federated Learning (HFL)\nand deep neural networks. In this paper, we present the first backdoor defense,\ncalled VFLIP, specialized for VFL. VFLIP employs the identification and\npurification techniques that operate at the inference stage, consequently\nimproving the robustness against backdoor attacks to a great extent. VFLIP\nfirst identifies backdoor-triggered embeddings by adopting a participant-wise\nanomaly detection approach. Subsequently, VFLIP conducts purification which\nremoves the embeddings identified as malicious and reconstructs all the\nembeddings based on the remaining embeddings. We conduct extensive experiments\non CIFAR10, CINIC10, Imagenette, NUS-WIDE, and BankMarketing to demonstrate\nthat VFLIP can effectively mitigate backdoor attacks in VFL.\nhttps://github.com/blingcho/VFLIP-esorics24\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}