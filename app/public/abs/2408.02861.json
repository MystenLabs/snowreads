{"id":"2408.02861","title":"A Framework for Fine-Tuning LLMs using Heterogeneous Feedback","authors":"Ryan Aponte (1), Ryan A. Rossi (2), Shunan Guo (2), Franck Dernoncourt\n  (2), Tong Yu (2), Xiang Chen (2), Subrata Mitra (2), Nedim Lipka (2) ((1)\n  Carnegie Mellon University, (2) Adobe Research)","authorsParsed":[["Aponte","Ryan",""],["Rossi","Ryan A.",""],["Guo","Shunan",""],["Dernoncourt","Franck",""],["Yu","Tong",""],["Chen","Xiang",""],["Mitra","Subrata",""],["Lipka","Nedim",""]],"versions":[{"version":"v1","created":"Mon, 5 Aug 2024 23:20:32 GMT"}],"updateDate":"2024-08-07","timestamp":1722900032000,"abstract":"  Large language models (LLMs) have been applied to a wide range of tasks,\nincluding text summarization, web navigation, and chatbots. They have\nbenefitted from supervised fine-tuning (SFT) and reinforcement learning from\nhuman feedback (RLHF) following an unsupervised pretraining. These datasets can\nbe difficult to collect, limited in scope, and vary in sample quality.\nAdditionally, datasets can vary extensively in supervision format, from\nnumerical to binary as well as multi-dimensional with many different values. We\npresent a framework for fine-tuning LLMs using heterogeneous feedback, which\nhas two main components. First, we combine the heterogeneous feedback data into\na single supervision format, compatible with methods like SFT and RLHF. Next,\ngiven this unified feedback dataset, we extract a high-quality and diverse\nsubset to obtain performance increases potentially exceeding the full dataset.\nWe conduct extensive experiments to understand the effectiveness of these\ntechniques for incorporating heterogeneous feedback, and demonstrate\nimprovements from using a high-quality and diverse subset of the data. We find\nthat our framework is able to improve models in multiple areas simultaneously,\nsuch as in instruction following and bias reduction.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}