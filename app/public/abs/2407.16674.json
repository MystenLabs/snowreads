{"id":"2407.16674","title":"KAN or MLP: A Fairer Comparison","authors":"Runpeng Yu and Weihao Yu and Xinchao Wang","authorsParsed":[["Yu","Runpeng",""],["Yu","Weihao",""],["Wang","Xinchao",""]],"versions":[{"version":"v1","created":"Tue, 23 Jul 2024 17:43:35 GMT"},{"version":"v2","created":"Sat, 17 Aug 2024 15:20:31 GMT"}],"updateDate":"2024-08-20","timestamp":1721756615000,"abstract":"  This paper does not introduce a novel method. Instead, it offers a fairer and\nmore comprehensive comparison of KAN and MLP models across various tasks,\nincluding machine learning, computer vision, audio processing, natural language\nprocessing, and symbolic formula representation. Specifically, we control the\nnumber of parameters and FLOPs to compare the performance of KAN and MLP. Our\nmain observation is that, except for symbolic formula representation tasks, MLP\ngenerally outperforms KAN. We also conduct ablation studies on KAN and find\nthat its advantage in symbolic formula representation mainly stems from its\nB-spline activation function. When B-spline is applied to MLP, performance in\nsymbolic formula representation significantly improves, surpassing or matching\nthat of KAN. However, in other tasks where MLP already excels over KAN,\nB-spline does not substantially enhance MLP's performance. Furthermore, we find\nthat KAN's forgetting issue is more severe than that of MLP in a standard\nclass-incremental continual learning setting, which differs from the findings\nreported in the KAN paper. We hope these results provide insights for future\nresearch on KAN and other MLP alternatives. Project link:\nhttps://github.com/yu-rp/KANbeFair\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"8uoG86XH4hHp58cq_HLbASae3DunUvqGT-cWUpycd08","pdfSize":"601848"}
