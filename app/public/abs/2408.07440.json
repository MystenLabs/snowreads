{"id":"2408.07440","title":"BAPLe: Backdoor Attacks on Medical Foundational Models using Prompt\n  Learning","authors":"Asif Hanif, Fahad Shamshad, Muhammad Awais, Muzammal Naseer, Fahad\n  Shahbaz Khan, Karthik Nandakumar, Salman Khan, Rao Muhammad Anwer","authorsParsed":[["Hanif","Asif",""],["Shamshad","Fahad",""],["Awais","Muhammad",""],["Naseer","Muzammal",""],["Khan","Fahad Shahbaz",""],["Nandakumar","Karthik",""],["Khan","Salman",""],["Anwer","Rao Muhammad",""]],"versions":[{"version":"v1","created":"Wed, 14 Aug 2024 10:18:42 GMT"},{"version":"v2","created":"Thu, 15 Aug 2024 10:45:18 GMT"}],"updateDate":"2024-08-16","timestamp":1723630722000,"abstract":"  Medical foundation models are gaining prominence in the medical community for\ntheir ability to derive general representations from extensive collections of\nmedical image-text pairs. Recent research indicates that these models are\nsusceptible to backdoor attacks, which allow them to classify clean images\naccurately but fail when specific triggers are introduced. However, traditional\nbackdoor attacks necessitate a considerable amount of additional data to\nmaliciously pre-train a model. This requirement is often impractical in medical\nimaging applications due to the usual scarcity of data. Inspired by the latest\ndevelopments in learnable prompts, this work introduces a method to embed a\nbackdoor into the medical foundation model during the prompt learning phase. By\nincorporating learnable prompts within the text encoder and introducing\nimperceptible learnable noise trigger to the input images, we exploit the full\ncapabilities of the medical foundation models (Med-FM). Our method, BAPLe,\nrequires only a minimal subset of data to adjust the noise trigger and the text\nprompts for downstream tasks, enabling the creation of an effective backdoor\nattack. Through extensive experiments with four medical foundation models, each\npre-trained on different modalities and evaluated across six downstream\ndatasets, we demonstrate the efficacy of our approach. BAPLe achieves a high\nbackdoor success rate across all models and datasets, outperforming the\nbaseline backdoor attack methods. Our work highlights the vulnerability of\nMed-FMs towards backdoor attacks and strives to promote the safe adoption of\nMed-FMs before their deployment in real-world applications. Code is available\nat https://asif-hanif.github.io/baple/.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}