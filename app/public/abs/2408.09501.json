{"id":"2408.09501","title":"Beyond Local Views: Global State Inference with Diffusion Models for\n  Cooperative Multi-Agent Reinforcement Learning","authors":"Zhiwei Xu, Hangyu Mao, Nianmin Zhang, Xin Xin, Pengjie Ren, Dapeng Li,\n  Bin Zhang, Guoliang Fan, Zhumin Chen, Changwei Wang, Jiangjin Yin","authorsParsed":[["Xu","Zhiwei",""],["Mao","Hangyu",""],["Zhang","Nianmin",""],["Xin","Xin",""],["Ren","Pengjie",""],["Li","Dapeng",""],["Zhang","Bin",""],["Fan","Guoliang",""],["Chen","Zhumin",""],["Wang","Changwei",""],["Yin","Jiangjin",""]],"versions":[{"version":"v1","created":"Sun, 18 Aug 2024 14:49:53 GMT"}],"updateDate":"2024-08-20","timestamp":1723992593000,"abstract":"  In partially observable multi-agent systems, agents typically only have\naccess to local observations. This severely hinders their ability to make\nprecise decisions, particularly during decentralized execution. To alleviate\nthis problem and inspired by image outpainting, we propose State Inference with\nDiffusion Models (SIDIFF), which uses diffusion models to reconstruct the\noriginal global state based solely on local observations. SIDIFF consists of a\nstate generator and a state extractor, which allow agents to choose suitable\nactions by considering both the reconstructed global state and local\nobservations. In addition, SIDIFF can be effortlessly incorporated into current\nmulti-agent reinforcement learning algorithms to improve their performance.\nFinally, we evaluated SIDIFF on different experimental platforms, including\nMulti-Agent Battle City (MABC), a novel and flexible multi-agent reinforcement\nlearning environment we developed. SIDIFF achieved desirable results and\noutperformed other popular algorithms.\n","subjects":["Computing Research Repository/Multiagent Systems","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}