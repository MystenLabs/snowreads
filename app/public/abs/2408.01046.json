{"id":"2408.01046","title":"QUDSELECT: Selective Decoding for Questions Under Discussion Parsing","authors":"Ashima Suvarna, Xiao Liu, Tanmay Parekh, Kai-Wei Chang, Nanyun Peng","authorsParsed":[["Suvarna","Ashima",""],["Liu","Xiao",""],["Parekh","Tanmay",""],["Chang","Kai-Wei",""],["Peng","Nanyun",""]],"versions":[{"version":"v1","created":"Fri, 2 Aug 2024 06:46:08 GMT"}],"updateDate":"2024-08-05","timestamp":1722581168000,"abstract":"  Question Under Discussion (QUD) is a discourse framework that uses implicit\nquestions to reveal discourse relationships between sentences. In QUD parsing,\neach sentence is viewed as an answer to a question triggered by an anchor\nsentence in prior context. The resulting QUD structure is required to conform\nto several theoretical criteria like answer compatibility (how well the\nquestion is answered), making QUD parsing a challenging task. Previous works\nconstruct QUD parsers in a pipelined manner (i.e. detect the trigger sentence\nin context and then generate the question). However, these parsers lack a\nholistic view of the task and can hardly satisfy all the criteria. In this\nwork, we introduce QUDSELECT, a joint-training framework that selectively\ndecodes the QUD dependency structures considering the QUD criteria. Using\ninstruction-tuning, we train models to simultaneously predict the anchor\nsentence and generate the associated question. To explicitly incorporate the\ncriteria, we adopt a selective decoding strategy of sampling multiple QUD\ncandidates during inference, followed by selecting the best one with criteria\nscorers. Our method outperforms the state-of-the-art baseline models by 9% in\nhuman evaluation and 4% in automatic evaluation, demonstrating the\neffectiveness of our framework.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"KgtLz_DKnw751k_vbZRZUy-IHD7kj0hAvgjiXMncrWg","pdfSize":"1413904"}
