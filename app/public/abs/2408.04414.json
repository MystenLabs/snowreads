{"id":"2408.04414","title":"Enhancing Robustness of Retrieval-Augmented Language Models with\n  In-Context Learning","authors":"Seong-Il Park, Seung-Woo Choi, Na-Hyun Kim, Jay-Yoon Lee","authorsParsed":[["Park","Seong-Il",""],["Choi","Seung-Woo",""],["Kim","Na-Hyun",""],["Lee","Jay-Yoon",""]],"versions":[{"version":"v1","created":"Thu, 8 Aug 2024 12:42:43 GMT"}],"updateDate":"2024-08-09","timestamp":1723120963000,"abstract":"  Retrieval-Augmented Language Models (RALMs) have significantly improved\nperformance in open-domain question answering (QA) by leveraging external\nknowledge. However, RALMs still struggle with unanswerable queries, where the\nretrieved contexts do not contain the correct answer, and with conflicting\ninformation, where different sources provide contradictory answers due to\nimperfect retrieval. This study introduces an in-context learning-based\napproach to enhance the reasoning capabilities of RALMs, making them more\nrobust in imperfect retrieval scenarios. Our method incorporates Machine\nReading Comprehension (MRC) demonstrations, referred to as cases, to boost the\nmodel's capabilities to identify unanswerabilities and conflicts among the\nretrieved contexts. Experiments on two open-domain QA datasets show that our\napproach increases accuracy in identifying unanswerable and conflicting\nscenarios without requiring additional fine-tuning. This work demonstrates that\nin-context learning can effectively enhance the robustness of RALMs in\nopen-domain QA tasks.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"trmu-QH889HKL0RZQKC5VjRM98iwdI0xI7ebSPdo9rM","pdfSize":"402074"}
