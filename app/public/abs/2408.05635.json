{"id":"2408.05635","title":"Visual SLAM with 3D Gaussian Primitives and Depth Priors Enabling Novel\n  View Synthesis","authors":"Zhongche Qu, Zhi Zhang, Cong Liu, Jianhua Yin","authorsParsed":[["Qu","Zhongche",""],["Zhang","Zhi",""],["Liu","Cong",""],["Yin","Jianhua",""]],"versions":[{"version":"v1","created":"Sat, 10 Aug 2024 21:23:08 GMT"},{"version":"v2","created":"Wed, 21 Aug 2024 05:24:19 GMT"}],"updateDate":"2024-08-22","timestamp":1723324988000,"abstract":"  Conventional geometry-based SLAM systems lack dense 3D reconstruction\ncapabilities since their data association usually relies on feature\ncorrespondences. Additionally, learning-based SLAM systems often fall short in\nterms of real-time performance and accuracy. Balancing real-time performance\nwith dense 3D reconstruction capabilities is a challenging problem. In this\npaper, we propose a real-time RGB-D SLAM system that incorporates a novel view\nsynthesis technique, 3D Gaussian Splatting, for 3D scene representation and\npose estimation. This technique leverages the real-time rendering performance\nof 3D Gaussian Splatting with rasterization and allows for differentiable\noptimization in real time through CUDA implementation. We also enable mesh\nreconstruction from 3D Gaussians for explicit dense 3D reconstruction. To\nestimate accurate camera poses, we utilize a rotation-translation decoupled\nstrategy with inverse optimization. This involves iteratively updating both in\nseveral iterations through gradient-based optimization. This process includes\ndifferentiably rendering RGB, depth, and silhouette maps and updating the\ncamera parameters to minimize a combined loss of photometric loss, depth\ngeometry loss, and visibility loss, given the existing 3D Gaussian map.\nHowever, 3D Gaussian Splatting (3DGS) struggles to accurately represent\nsurfaces due to the multi-view inconsistency of 3D Gaussians, which can lead to\nreduced accuracy in both camera pose estimation and scene reconstruction. To\naddress this, we utilize depth priors as additional regularization to enforce\ngeometric constraints, thereby improving the accuracy of both pose estimation\nand 3D reconstruction. We also provide extensive experimental results on public\nbenchmark datasets to demonstrate the effectiveness of our proposed methods in\nterms of pose accuracy, geometric accuracy, and rendering performance.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Robotics"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}