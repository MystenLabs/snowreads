{"id":"2408.05438","title":"Convergence Guarantee of Dynamic Programming for LTL Surrogate Reward","authors":"Zetong Xuan, Yu Wang","authorsParsed":[["Xuan","Zetong",""],["Wang","Yu",""]],"versions":[{"version":"v1","created":"Sat, 10 Aug 2024 04:47:35 GMT"}],"updateDate":"2024-08-13","timestamp":1723265255000,"abstract":"  Linear Temporal Logic (LTL) is a formal way of specifying complex objectives\nfor planning problems modeled as Markov Decision Processes (MDPs). The planning\nproblem aims to find the optimal policy that maximizes the satisfaction\nprobability of the LTL objective. One way to solve the planning problem is to\nuse the surrogate reward with two discount factors and dynamic programming,\nwhich bypasses the graph analysis used in traditional model-checking. The\nsurrogate reward is designed such that its value function represents the\nsatisfaction probability. However, in some cases where one of the discount\nfactors is set to $1$ for higher accuracy, the computation of the value\nfunction using dynamic programming is not guaranteed. This work shows that a\nmulti-step contraction always exists during dynamic programming updates,\nguaranteeing that the approximate value function will converge exponentially to\nthe true value function. Thus, the computation of satisfaction probability is\nguaranteed.\n","subjects":["Computing Research Repository/Robotics","Computing Research Repository/Systems and Control","Electrical Engineering and Systems Science/Systems and Control"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}