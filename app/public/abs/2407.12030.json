{"id":"2407.12030","title":"Towards a Harms Taxonomy of AI Likeness Generation","authors":"Ben Bariach, Bernie Hogan, Keegan McBride","authorsParsed":[["Bariach","Ben",""],["Hogan","Bernie",""],["McBride","Keegan",""]],"versions":[{"version":"v1","created":"Sat, 29 Jun 2024 16:00:42 GMT"}],"updateDate":"2024-07-18","timestamp":1719676842000,"abstract":"  Generative artificial intelligence models, when trained on a sufficient\nnumber of a person's images, can replicate their identifying features in a\nphotorealistic manner. We refer to this process as 'likeness generation'.\nLikeness-featuring synthetic outputs often present a person's likeness without\ntheir control or consent, and may lead to harmful consequences. This paper\nexplores philosophical and policy issues surrounding generated likeness. It\nbegins by offering a conceptual framework for understanding likeness generation\nby examining the novel capabilities introduced by generative systems. The paper\nthen establishes a definition of likeness by tracing its historical development\nin legal literature. Building on this foundation, we present a taxonomy of\nharms associated with generated likeness, derived from a comprehensive\nmeta-analysis of relevant literature. This taxonomy categorises harms into\nseven distinct groups, unified by shared characteristics. Utilising this\ntaxonomy, we raise various considerations that need to be addressed for the\ndeployment of appropriate mitigations. Given the multitude of stakeholders\ninvolved in both the creation and distribution of likeness, we introduce\nconcepts such as indexical sufficiency, a distinction between generation and\ndistribution, and harms as having a context-specific nature. This work aims to\nserve industry, policymakers, and future academic researchers in their efforts\nto address the societal challenges posed by likeness generation.\n","subjects":["Computing Research Repository/Computers and Society"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}