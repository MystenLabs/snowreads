{"id":"2408.10618","title":"OMEGA: Efficient Occlusion-Aware Navigation for Air-Ground Robot in\n  Dynamic Environments via State Space Model","authors":"Junming Wang and Dong Huang and Xiuxian Guan and Zekai Sun and\n  Tianxiang Shen and Fangming Liu and Heming Cui","authorsParsed":[["Wang","Junming",""],["Huang","Dong",""],["Guan","Xiuxian",""],["Sun","Zekai",""],["Shen","Tianxiang",""],["Liu","Fangming",""],["Cui","Heming",""]],"versions":[{"version":"v1","created":"Tue, 20 Aug 2024 07:50:29 GMT"}],"updateDate":"2024-08-21","timestamp":1724140229000,"abstract":"  Air-ground robots (AGRs) are widely used in surveillance and disaster\nresponse due to their exceptional mobility and versatility (i.e., flying and\ndriving). Current AGR navigation systems perform well in static occlusion-prone\nenvironments (e.g., indoors) by using 3D semantic occupancy networks to predict\nocclusions for complete local mapping and then computing Euclidean Signed\nDistance Field (ESDF) for path planning. However, these systems face challenges\nin dynamic, severe occlusion scenes (e.g., crowds) due to limitations in\nperception networks' low prediction accuracy and path planners' high\ncomputation overhead. In this paper, we propose OMEGA, which contains OccMamba\nwith an Efficient AGR-Planner to address the above-mentioned problems. OccMamba\nadopts a novel architecture that separates semantic and occupancy prediction\ninto independent branches, incorporating two mamba blocks within these\nbranches. These blocks efficiently extract semantic and geometric features in\n3D environments with linear complexity, ensuring that the network can learn\nlong-distance dependencies to improve prediction accuracy. Semantic and\ngeometric features are combined within the Bird's Eye View (BEV) space to\nminimise computational overhead during feature fusion. The resulting semantic\noccupancy map is then seamlessly integrated into the local map, providing\nocclusion awareness of the dynamic environment. Our AGR-Planner utilizes this\nlocal map and employs kinodynamic A* search and gradient-based trajectory\noptimization to guarantee planning is ESDF-free and energy-efficient. Extensive\nexperiments demonstrate that OccMamba outperforms the state-of-the-art 3D\nsemantic occupancy network with 25.0% mIoU. End-to-end navigation experiments\nin dynamic scenes verify OMEGA's efficiency, achieving a 96% average planning\nsuccess rate. Code and video are available at\nhttps://jmwang0117.github.io/OMEGA/.\n","subjects":["Computing Research Repository/Robotics","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"WYCrmJCOOJgds_GbBbhdSTLFXInfALg3JbPAyj9dDek","pdfSize":"8831705"}
