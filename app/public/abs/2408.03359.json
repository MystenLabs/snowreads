{"id":"2408.03359","title":"LAMPO: Large Language Models as Preference Machines for Few-shot Ordinal\n  Classification","authors":"Zhen Qin and Junru Wu and Jiaming Shen and Tianqi Liu and Xuanhui Wang","authorsParsed":[["Qin","Zhen",""],["Wu","Junru",""],["Shen","Jiaming",""],["Liu","Tianqi",""],["Wang","Xuanhui",""]],"versions":[{"version":"v1","created":"Tue, 6 Aug 2024 15:55:05 GMT"}],"updateDate":"2024-08-08","timestamp":1722959705000,"abstract":"  We introduce LAMPO, a novel paradigm that leverages Large Language Models\n(LLMs) for solving few-shot multi-class ordinal classification tasks. Unlike\nconventional methods, which concatenate all demonstration examples with the\ntest instance and prompt LLMs to produce the pointwise prediction, our\nframework uses the LLM as a preference machine that makes a relative\ncomparative decision between the test instance and each demonstration. A\nself-supervised method is then introduced to aggregate these binary comparisons\ninto the final ordinal decision. LAMPO addresses several limitations inherent\nin previous methods, including context length constraints, ordering biases, and\nchallenges associated with absolute point-wise estimation. Extensive\nexperiments on seven public datasets demonstrate LAMPO's remarkably competitive\nperformance across a diverse spectrum of applications (e.g., movie review\nanalysis and hate speech detection). Notably, in certain applications, the\nimprovement can be substantial, exceeding 20% in an absolute term. Moreover, we\nbelieve LAMPO represents an interesting addition to the non-parametric\napplication layered on top of LLMs, as it supports black-box LLMs without\nnecessitating the outputting of LLM's internal states (e.g., embeddings), as\nseen in previous approaches.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"6uqxZPKwhTNbC88xzpVgBUtexN_F16oREtyJ7BNxUKs","pdfSize":"564775"}
