{"id":"2407.05633","title":"AdaPI: Facilitating DNN Model Adaptivity for Efficient Private Inference\n  in Edge Computing","authors":"Tong Zhou and Jiahui Zhao and Yukui Luo and Xi Xie and Wujie Wen and\n  Caiwen Ding and Xiaolin Xu","authorsParsed":[["Zhou","Tong",""],["Zhao","Jiahui",""],["Luo","Yukui",""],["Xie","Xi",""],["Wen","Wujie",""],["Ding","Caiwen",""],["Xu","Xiaolin",""]],"versions":[{"version":"v1","created":"Mon, 8 Jul 2024 05:58:49 GMT"}],"updateDate":"2024-07-09","timestamp":1720418329000,"abstract":"  Private inference (PI) has emerged as a promising solution to execute\ncomputations on encrypted data, safeguarding user privacy and model parameters\nin edge computing. However, existing PI methods are predominantly developed\nconsidering constant resource constraints, overlooking the varied and dynamic\nresource constraints in diverse edge devices, like energy budgets.\nConsequently, model providers have to design specialized models for different\ndevices, where all of them have to be stored on the edge server, resulting in\ninefficient deployment. To fill this gap, this work presents AdaPI, a novel\napproach that achieves adaptive PI by allowing a model to perform well across\nedge devices with diverse energy budgets. AdaPI employs a PI-aware training\nstrategy that optimizes the model weights alongside weight-level and\nfeature-level soft masks. These soft masks are subsequently transformed into\nmultiple binary masks to enable adjustments in communication and computation\nworkloads. Through sequentially training the model with increasingly dense\nbinary masks, AdaPI attains optimal accuracy for each energy budget, which\noutperforms the state-of-the-art PI methods by 7.3\\% in terms of test accuracy\non CIFAR-100. The code of AdaPI can be accessed via\nhttps://github.com/jiahuiiiiii/AdaPI.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Cryptography and Security"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}