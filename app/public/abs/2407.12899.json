{"id":"2407.12899","title":"DreamStory: Open-Domain Story Visualization by LLM-Guided Multi-Subject\n  Consistent Diffusion","authors":"Huiguo He, Huan Yang, Zixi Tuo, Yuan Zhou, Qiuyue Wang, Yuhang Zhang,\n  Zeyu Liu, Wenhao Huang, Hongyang Chao, Jian Yin","authorsParsed":[["He","Huiguo",""],["Yang","Huan",""],["Tuo","Zixi",""],["Zhou","Yuan",""],["Wang","Qiuyue",""],["Zhang","Yuhang",""],["Liu","Zeyu",""],["Huang","Wenhao",""],["Chao","Hongyang",""],["Yin","Jian",""]],"versions":[{"version":"v1","created":"Wed, 17 Jul 2024 17:54:12 GMT"}],"updateDate":"2024-07-19","timestamp":1721238852000,"abstract":"  Story visualization aims to create visually compelling images or videos\ncorresponding to textual narratives. Despite recent advances in diffusion\nmodels yielding promising results, existing methods still struggle to create a\ncoherent sequence of subject-consistent frames based solely on a story. To this\nend, we propose DreamStory, an automatic open-domain story visualization\nframework by leveraging the LLMs and a novel multi-subject consistent diffusion\nmodel. DreamStory consists of (1) an LLM acting as a story director and (2) an\ninnovative Multi-Subject consistent Diffusion model (MSD) for generating\nconsistent multi-subject across the images. First, DreamStory employs the LLM\nto generate descriptive prompts for subjects and scenes aligned with the story,\nannotating each scene's subjects for subsequent subject-consistent generation.\nSecond, DreamStory utilizes these detailed subject descriptions to create\nportraits of the subjects, with these portraits and their corresponding textual\ninformation serving as multimodal anchors (guidance). Finally, the MSD uses\nthese multimodal anchors to generate story scenes with consistent\nmulti-subject. Specifically, the MSD includes Masked Mutual Self-Attention\n(MMSA) and Masked Mutual Cross-Attention (MMCA) modules. MMSA and MMCA modules\nensure appearance and semantic consistency with reference images and text,\nrespectively. Both modules employ masking mechanisms to prevent subject\nblending. To validate our approach and promote progress in story visualization,\nwe established a benchmark, DS-500, which can assess the overall performance of\nthe story visualization framework, subject-identification accuracy, and the\nconsistency of the generation model. Extensive experiments validate the\neffectiveness of DreamStory in both subjective and objective evaluations.\nPlease visit our project homepage at https://dream-xyz.github.io/dreamstory.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Multimedia"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}