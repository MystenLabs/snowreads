{"id":"2407.12357","title":"Evaluating graph-based explanations for AI-based recommender systems","authors":"Simon Delarue, Astrid Bertrand and Tiphaine Viard","authorsParsed":[["Delarue","Simon",""],["Bertrand","Astrid",""],["Viard","Tiphaine",""]],"versions":[{"version":"v1","created":"Wed, 17 Jul 2024 07:28:49 GMT"}],"updateDate":"2024-07-18","timestamp":1721201329000,"abstract":"  Recent years have witnessed a rapid growth of recommender systems, providing\nsuggestions in numerous applications with potentially high social impact, such\nas health or justice. Meanwhile, in Europe, the upcoming AI Act mentions\n\\emph{transparency} as a requirement for critical AI systems in order to\n``mitigate the risks to fundamental rights''. Post-hoc explanations seamlessly\nalign with this goal and extensive literature on the subject produced several\nforms of such objects, graphs being one of them. Early studies in visualization\ndemonstrated the graphs' ability to improve user understanding, positioning\nthem as potentially ideal explanations. However, it remains unclear how\ngraph-based explanations compare to other explanation designs. In this work, we\naim to determine the effectiveness of graph-based explanations in improving\nusers' perception of AI-based recommendations using a mixed-methods approach.\nWe first conduct a qualitative study to collect users' requirements for graph\nexplanations. We then run a larger quantitative study in which we evaluate the\ninfluence of various explanation designs, including enhanced graph-based ones,\non aspects such as understanding, usability and curiosity toward the AI system.\nWe find that users perceive graph-based explanations as more usable than\ndesigns involving feature importance. However, we also reveal that textual\nexplanations lead to higher objective understanding than graph-based designs.\nMost importantly, we highlight the strong contrast between participants'\nexpressed preferences for graph design and their actual ratings using it, which\nare lower compared to textual design. These findings imply that meeting\nstakeholders' expressed preferences might not alone guarantee ``good''\nexplanations. Therefore, crafting hybrid designs successfully balancing social\nexpectations with downstream performance emerges as a significant challenge.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Human-Computer Interaction"],"license":"http://creativecommons.org/licenses/by/4.0/"}