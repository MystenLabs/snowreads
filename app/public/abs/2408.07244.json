{"id":"2408.07244","title":"Sign language recognition based on deep learning and low-cost\n  handcrafted descriptors","authors":"Alvaro Leandro Cavalcante Carneiro, Denis Henrique Pinheiro Salvadeo,\n  Lucas de Brito Silva","authorsParsed":[["Carneiro","Alvaro Leandro Cavalcante",""],["Salvadeo","Denis Henrique Pinheiro",""],["Silva","Lucas de Brito",""]],"versions":[{"version":"v1","created":"Wed, 14 Aug 2024 00:56:51 GMT"}],"updateDate":"2024-08-15","timestamp":1723597011000,"abstract":"  In recent years, deep learning techniques have been used to develop sign\nlanguage recognition systems, potentially serving as a communication tool for\nmillions of hearing-impaired individuals worldwide. However, there are inherent\nchallenges in creating such systems. Firstly, it is important to consider as\nmany linguistic parameters as possible in gesture execution to avoid ambiguity\nbetween words. Moreover, to facilitate the real-world adoption of the created\nsolution, it is essential to ensure that the chosen technology is realistic,\navoiding expensive, intrusive, or low-mobility sensors, as well as very complex\ndeep learning architectures that impose high computational requirements. Based\non this, our work aims to propose an efficient sign language recognition system\nthat utilizes low-cost sensors and techniques. To this end, an object detection\nmodel was trained specifically for detecting the interpreter's face and hands,\nensuring focus on the most relevant regions of the image and generating inputs\nwith higher semantic value for the classifier. Additionally, we introduced a\nnovel approach to obtain features representing hand location and movement by\nleveraging spatial information derived from centroid positions of bounding\nboxes, thereby enhancing sign discrimination. The results demonstrate the\nefficiency of our handcrafted features, increasing accuracy by 7.96% on the\nAUTSL dataset, while adding fewer than 700 thousand parameters and incurring\nless than 10 milliseconds of additional inference time. These findings\nhighlight the potential of our technique to strike a favorable balance between\ncomputational cost and accuracy, making it a promising approach for practical\nsign language recognition applications.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}