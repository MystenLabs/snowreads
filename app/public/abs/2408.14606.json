{"id":"2408.14606","title":"BreakNet: Discontinuity-Resilient Multi-Scale Transformer Segmentation\n  of Retinal Layers","authors":"Razieh Ganjee, Bingjie Wang, Lingyun Wang, Chengcheng Zhao,\n  Jos\\'e-Alain Sahel, and Shaohua Pi","authorsParsed":[["Ganjee","Razieh",""],["Wang","Bingjie",""],["Wang","Lingyun",""],["Zhao","Chengcheng",""],["Sahel","Jos√©-Alain",""],["Pi","Shaohua",""]],"versions":[{"version":"v1","created":"Mon, 26 Aug 2024 19:59:20 GMT"}],"updateDate":"2024-08-28","timestamp":1724702360000,"abstract":"  Visible light optical coherence tomography (vis-OCT) is gaining traction for\nretinal imaging due to its high resolution and functional capabilities.\nHowever, the significant absorption of hemoglobin in the visible light range\nleads to pronounced shadow artifacts from retinal blood vessels, posing\nchallenges for accurate layer segmentation. In this study, we present BreakNet,\na multi-scale Transformer-based segmentation model designed to address boundary\ndiscontinuities caused by these shadow artifacts. BreakNet utilizes\nhierarchical Transformer and convolutional blocks to extract multi-scale global\nand local feature maps, capturing essential contextual, textural, and edge\ncharacteristics. The model incorporates decoder blocks that expand pathwaproys\nto enhance the extraction of fine details and semantic information, ensuring\nprecise segmentation. Evaluated on rodent retinal images acquired with\nprototype vis-OCT, BreakNet demonstrated superior performance over\nstate-of-the-art segmentation models, such as TCCT-BP and U-Net, even when\nfaced with limited-quality ground truth data. Our findings indicate that\nBreakNet has the potential to significantly improve retinal quantification and\nanalysis.\n","subjects":["Electrical Engineering and Systems Science/Image and Video Processing","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/"}