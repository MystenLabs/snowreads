{"id":"2408.16327","title":"Distributed quantum machine learning via classical communication","authors":"Kiwmann Hwang, Hyang-Tag Lim, Yong-Su Kim, Daniel K. Park, Yosep Kim","authorsParsed":[["Hwang","Kiwmann",""],["Lim","Hyang-Tag",""],["Kim","Yong-Su",""],["Park","Daniel K.",""],["Kim","Yosep",""]],"versions":[{"version":"v1","created":"Thu, 29 Aug 2024 08:05:57 GMT"}],"updateDate":"2024-08-30","timestamp":1724918757000,"abstract":"  Quantum machine learning is emerging as a promising application of quantum\ncomputing due to its distinct way of encoding and processing data. It is\nbelieved that large-scale quantum machine learning demonstrates substantial\nadvantages over classical counterparts, but a reliable scale-up is hindered by\nthe fragile nature of quantum systems. Here we present an experimentally\naccessible distributed quantum machine learning scheme that integrates quantum\nprocessor units via classical communication. As a demonstration, we perform\ndata classification tasks on 8-dimensional synthetic datasets by emulating two\n4-qubit processors and employing quantum convolutional neural networks. Our\nresults indicate that incorporating classical communication notably improves\nclassification accuracy compared to schemes without communication. Furthermore,\nat the tested circuit depths, we observe that the accuracy with classical\ncommunication is no less than that achieved with quantum communication. Our\nwork provides a practical path to demonstrating large-scale quantum machine\nlearning on intermediate-scale quantum processors by leveraging classical\ncommunication that can be implemented through currently available mid-circuit\nmeasurements.\n","subjects":["Physics/Quantum Physics"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"bQRA6PT8CyYgkn9pTVccVJKI86b_LiRzmBC06fCJb0A","pdfSize":"1280793"}
