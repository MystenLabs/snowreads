{"id":"2407.14833","title":"SpatialTouch: Exploring Spatial Data Visualizations in Cross-reality","authors":"Lixiang Zhao, Tobias Isenberg, Fuqi Xie, Hai-Ning Liang, Lingyun Yu","authorsParsed":[["Zhao","Lixiang",""],["Isenberg","Tobias",""],["Xie","Fuqi",""],["Liang","Hai-Ning",""],["Yu","Lingyun",""]],"versions":[{"version":"v1","created":"Sat, 20 Jul 2024 10:23:53 GMT"}],"updateDate":"2024-07-23","timestamp":1721471033000,"abstract":"  We propose and study a novel cross-reality environment that seamlessly\nintegrates a monoscopic 2D surface (an interactive screen with touch and pen\ninput) with a stereoscopic 3D space (an augmented reality HMD) to jointly host\nspatial data visualizations. This innovative approach combines the best of two\nconventional methods of displaying and manipulating spatial 3D data, enabling\nusers to fluidly explore diverse visual forms using tailored interaction\ntechniques. Providing such effective 3D data exploration techniques is pivotal\nfor conveying its intricate spatial structures -- often at multiple spatial or\nsemantic scales -- across various application domains and requiring diverse\nvisual representations for effective visualization. To understand user\nreactions to our new environment, we began with an elicitation user study, in\nwhich we captured their responses and interactions. We observed that users\nadapted their interaction approaches based on perceived visual representations,\nwith natural transitions in spatial awareness and actions while navigating\nacross the physical surface. Our findings then informed the development of a\ndesign space for spatial data exploration in cross-reality. We thus developed\ncross-reality environments tailored to three distinct domains: for 3D molecular\nstructure data, for 3D point cloud data, and for 3D anatomical data. In\nparticular, we designed interaction techniques that account for the inherent\nfeatures of interactions in both spaces, facilitating various forms of\ninteraction, including mid-air gestures, touch interactions, pen interactions,\nand combinations thereof, to enhance the users' sense of presence and\nengagement. We assessed the usability of our environment with biologists,\nfocusing on its use for domain research. In addition, we evaluated our\ninteraction transition designs with virtual and mixed-reality experts to gather\nfurther insights.\n","subjects":["Computing Research Repository/Human-Computer Interaction"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"p1qs2sm1uIIVNDAbP8-c2cPIVOskY3ZhM4O84MztlQw","pdfSize":"48379223"}
