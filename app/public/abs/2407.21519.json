{"id":"2407.21519","title":"PhysFlow: Skin tone transfer for remote heart rate estimation through\n  conditional normalizing flows","authors":"Joaquim Comas, Antonia Alomar, Adria Ruiz and Federico Sukno","authorsParsed":[["Comas","Joaquim",""],["Alomar","Antonia",""],["Ruiz","Adria",""],["Sukno","Federico",""]],"versions":[{"version":"v1","created":"Wed, 31 Jul 2024 10:44:31 GMT"}],"updateDate":"2024-08-01","timestamp":1722422671000,"abstract":"  In recent years, deep learning methods have shown impressive results for\ncamera-based remote physiological signal estimation, clearly surpassing\ntraditional methods. However, the performance and generalization ability of\nDeep Neural Networks heavily depends on rich training data truly representing\ndifferent factors of variation encountered in real applications. Unfortunately,\nmany current remote photoplethysmography (rPPG) datasets lack diversity,\nparticularly in darker skin tones, leading to biased performance of existing\nrPPG approaches. To mitigate this bias, we introduce PhysFlow, a novel method\nfor augmenting skin diversity in remote heart rate estimation using conditional\nnormalizing flows. PhysFlow adopts end-to-end training optimization, enabling\nsimultaneous training of supervised rPPG approaches on both original and\ngenerated data. Additionally, we condition our model using CIELAB color space\nskin features directly extracted from the facial videos without the need for\nskin-tone labels. We validate PhysFlow on publicly available datasets,\nUCLA-rPPG and MMPD, demonstrating reduced heart rate error, particularly in\ndark skin tones. Furthermore, we demonstrate its versatility and adaptability\nacross different data-driven rPPG methods.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}