{"id":"2408.13950","title":"Bridging the Gap between Real-world and Synthetic Images for Testing\n  Autonomous Driving Systems","authors":"Mohammad Hossein Amini and Shiva Nejati","authorsParsed":[["Amini","Mohammad Hossein",""],["Nejati","Shiva",""]],"versions":[{"version":"v1","created":"Sun, 25 Aug 2024 22:07:41 GMT"}],"updateDate":"2024-08-27","timestamp":1724623661000,"abstract":"  Deep Neural Networks (DNNs) for Autonomous Driving Systems (ADS) are\ntypically trained on real-world images and tested using synthetic simulator\nimages. This approach results in training and test datasets with dissimilar\ndistributions, which can potentially lead to erroneously decreased test\naccuracy. To address this issue, the literature suggests applying\ndomain-to-domain translators to test datasets to bring them closer to the\ntraining datasets. However, translating images used for testing may\nunpredictably affect the reliability, effectiveness and efficiency of the\ntesting process. Hence, this paper investigates the following questions in the\ncontext of ADS: Could translators reduce the effectiveness of images used for\nADS-DNN testing and their ability to reveal faults in ADS-DNNs? Can translators\nresult in excessive time overhead during simulation-based testing? To address\nthese questions, we consider three domain-to-domain translators: CycleGAN and\nneural style transfer, from the literature, and SAEVAE, our proposed\ntranslator. Our results for two critical ADS tasks -- lane keeping and object\ndetection -- indicate that translators significantly narrow the gap in ADS test\naccuracy caused by distribution dissimilarities between training and test data,\nwith SAEVAE outperforming the other two translators. We show that, based on the\nrecent diversity, coverage, and fault-revealing ability metrics for testing\ndeep-learning systems, translators do not compromise the diversity and the\ncoverage of test data, nor do they lead to revealing fewer faults in ADS-DNNs.\nFurther, among the translators considered, SAEVAE incurs a negligible overhead\nin simulation time and can be efficiently integrated into simulation-based\ntesting. Finally, we show that translators increase the correlation between\noffline and simulation-based testing results, which can help reduce the cost of\nsimulation-based testing.\n","subjects":["Computing Research Repository/Software Engineering","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/"}