{"id":"2407.01562","title":"Small but Fair! Fairness for Multimodal Human-Human and Robot-Human\n  Mental Wellbeing Coaching","authors":"Jiaee Cheong, Micol Spitale, Hatice Gunes","authorsParsed":[["Cheong","Jiaee",""],["Spitale","Micol",""],["Gunes","Hatice",""]],"versions":[{"version":"v1","created":"Wed, 15 May 2024 10:29:05 GMT"}],"updateDate":"2024-07-03","timestamp":1715768945000,"abstract":"  In recent years, the affective computing (AC) and human-robot interaction\n(HRI) research communities have put fairness at the centre of their research\nagenda. However, none of the existing work has addressed the problem of machine\nlearning (ML) bias in HRI settings. In addition, many of the current datasets\nfor AC and HRI are \"small\", making ML bias and debias analysis challenging.\nThis paper presents the first work to explore ML bias analysis and mitigation\nof three small multimodal datasets collected within both a human-human and\nrobot-human wellbeing coaching settings. The contributions of this work\nincludes: i) being the first to explore the problem of ML bias and fairness\nwithin HRI settings; and ii) providing a multimodal analysis evaluated via\nmodelling performance and fairness metrics across both high and low-level\nfeatures and proposing a simple and effective data augmentation strategy\n(MixFeat) to debias the small datasets presented within this paper; and iii)\nconducting extensive experimentation and analyses to reveal ML fairness\ninsights unique to AC and HRI research in order to distill a set of\nrecommendations to aid AC and HRI researchers to be more engaged with\nfairness-aware ML-based research.\n","subjects":["Computing Research Repository/Robotics"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"Ln7aEC26IVRQiKUZwa3IeKVbYBOcfAa0BF42b7zY9EQ","pdfSize":"1041368"}
