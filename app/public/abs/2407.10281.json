{"id":"2407.10281","title":"Beyond Prompt Learning: Continual Adapter for Efficient Rehearsal-Free\n  Continual Learning","authors":"Xinyuan Gao, Songlin Dong, Yuhang He, Qiang Wang, and Yihong Gong","authorsParsed":[["Gao","Xinyuan",""],["Dong","Songlin",""],["He","Yuhang",""],["Wang","Qiang",""],["Gong","Yihong",""]],"versions":[{"version":"v1","created":"Sun, 14 Jul 2024 17:40:40 GMT"}],"updateDate":"2024-07-16","timestamp":1720978840000,"abstract":"  The problem of Rehearsal-Free Continual Learning (RFCL) aims to continually\nlearn new knowledge while preventing forgetting of the old knowledge, without\nstoring any old samples and prototypes. The latest methods leverage large-scale\npre-trained models as the backbone and use key-query matching to generate\ntrainable prompts to learn new knowledge. However, the domain gap between the\npre-training dataset and the downstream datasets can easily lead to\ninaccuracies in key-query matching prompt selection when directly generating\nqueries using the pre-trained model, which hampers learning new knowledge.\nThus, in this paper, we propose a beyond prompt learning approach to the RFCL\ntask, called Continual Adapter (C-ADA). It mainly comprises a\nparameter-extensible continual adapter layer (CAL) and a scaling and shifting\n(S&S) module in parallel with the pre-trained model. C-ADA flexibly extends\nspecific weights in CAL to learn new knowledge for each task and freezes old\nweights to preserve prior knowledge, thereby avoiding matching errors and\noperational inefficiencies introduced by key-query matching. To reduce the gap,\nC-ADA employs an S&S module to transfer the feature space from pre-trained\ndatasets to downstream datasets. Moreover, we propose an orthogonal loss to\nmitigate the interaction between old and new knowledge. Our approach achieves\nsignificantly improved performance and training speed, outperforming the\ncurrent state-of-the-art (SOTA) method. Additionally, we conduct experiments on\ndomain-incremental learning, surpassing the SOTA, and demonstrating the\ngenerality of our approach in different settings.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}