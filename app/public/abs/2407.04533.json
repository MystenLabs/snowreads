{"id":"2407.04533","title":"Performance Analysis of Speech Encoders for Low-Resource SLU and ASR in\n  Tunisian Dialect","authors":"Salima Mdhaffar and Haroun Elleuch and Fethi Bougares and Yannick\n  Est\\`eve","authorsParsed":[["Mdhaffar","Salima",""],["Elleuch","Haroun",""],["Bougares","Fethi",""],["Est√®ve","Yannick",""]],"versions":[{"version":"v1","created":"Fri, 5 Jul 2024 14:21:36 GMT"},{"version":"v2","created":"Tue, 9 Jul 2024 15:07:35 GMT"}],"updateDate":"2024-07-10","timestamp":1720189296000,"abstract":"  Speech encoders pretrained through self-supervised learning (SSL) have\ndemonstrated remarkable performance in various downstream tasks, including\nSpoken Language Understanding (SLU) and Automatic Speech Recognition (ASR). For\ninstance, fine-tuning SSL models for such tasks has shown significant\npotential, leading to improvements in the SOTA performance across challenging\ndatasets. In contrast to existing research, this paper contributes by comparing\nthe effectiveness of SSL approaches in the context of (i) the low-resource\nspoken Tunisian Arabic dialect and (ii) its combination with a low-resource SLU\nand ASR scenario, where only a few semantic annotations are available for\nfine-tuning. We conduct experiments using many SSL speech encoders on the\nTARIC-SLU dataset. We use speech encoders that were pre-trained on either\nmonolingual or multilingual speech data. Some of them have also been refined\nwithout in-domain nor Tunisian data through multimodal supervised\nteacher-student paradigm. This study yields numerous significant findings that\nwe are discussing in this paper.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Sound","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by/4.0/"}