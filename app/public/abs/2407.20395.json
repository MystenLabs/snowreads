{"id":"2407.20395","title":"Dense Self-Supervised Learning for Medical Image Segmentation","authors":"Maxime Seince, Loic Le Folgoc, Luiz Augusto Facury de Souza and Elsa\n  Angelini","authorsParsed":[["Seince","Maxime",""],["Folgoc","Loic Le",""],["de Souza","Luiz Augusto Facury",""],["Angelini","Elsa",""]],"versions":[{"version":"v1","created":"Mon, 29 Jul 2024 19:42:22 GMT"}],"updateDate":"2024-07-31","timestamp":1722282142000,"abstract":"  Deep learning has revolutionized medical image segmentation, but it relies\nheavily on high-quality annotations. The time, cost and expertise required to\nlabel images at the pixel-level for each new task has slowed down widespread\nadoption of the paradigm. We propose Pix2Rep, a self-supervised learning (SSL)\napproach for few-shot segmentation, that reduces the manual annotation burden\nby learning powerful pixel-level representations directly from unlabeled\nimages. Pix2Rep is a novel pixel-level loss and pre-training paradigm for\ncontrastive SSL on whole images. It is applied to generic encoder-decoder deep\nlearning backbones (e.g., U-Net). Whereas most SSL methods enforce invariance\nof the learned image-level representations under intensity and spatial image\naugmentations, Pix2Rep enforces equivariance of the pixel-level\nrepresentations. We demonstrate the framework on a task of cardiac MRI\nsegmentation. Results show improved performance compared to existing semi- and\nself-supervised approaches; and a 5-fold reduction in the annotation burden for\nequivalent performance versus a fully supervised U-Net baseline. This includes\na 30% (resp. 31%) DICE improvement for one-shot segmentation under\nlinear-probing (resp. fine-tuning). Finally, we also integrate the novel\nPix2Rep concept with the Barlow Twins non-contrastive SSL, which leads to even\nbetter segmentation performance.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}