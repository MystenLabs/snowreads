{"id":"2407.06464","title":"SideSeeing: A multimodal dataset and collection of tools for sidewalk\n  assessment","authors":"R. J. P. Damaceno (1), L. Ferreira (2), F. Miranda (2), M. Hosseini\n  (3) and R. M. Cesar Jr (1) ((1) University of S\\~ao Paulo, (2) University of\n  Illinois Chicago, (3) Massachusetts Institute of Technology)","authorsParsed":[["Damaceno","R. J. P.",""],["Ferreira","L.",""],["Miranda","F.",""],["Hosseini","M.",""],["Cesar","R. M.","Jr"]],"versions":[{"version":"v1","created":"Tue, 9 Jul 2024 00:04:54 GMT"},{"version":"v2","created":"Fri, 12 Jul 2024 14:38:29 GMT"}],"updateDate":"2024-07-15","timestamp":1720483494000,"abstract":"  This paper introduces SideSeeing, a novel initiative that provides tools and\ndatasets for assessing the built environment. We present a framework for\nstreet-level data acquisition, loading, and analysis. Using the framework, we\ncollected a novel dataset that integrates synchronized video footaged captured\nfrom chest-mounted mobile devices with sensor data (accelerometer, gyroscope,\nmagnetometer, and GPS). Each data sample represents a path traversed by a user\nfilming sidewalks near hospitals in Brazil and the USA. The dataset encompasses\nthree hours of content covering 12 kilometers around nine hospitals, and\nincludes 325,000 video frames with corresponding sensor data. Additionally, we\npresent a novel 68-element taxonomy specifically created for sidewalk scene\nidentification. SideSeeing is a step towards a suite of tools that urban\nexperts can use to perform in-depth sidewalk accessibility evaluations.\nSideSeeing data and tools are publicly available at\nhttps://sites.usp.br/sideseeing/.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Computers and Society"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}