{"id":"2407.17167","title":"Zero-Shot vs. Few-Shot Multi-Speaker TTS Using Pre-trained Czech\n  SpeechT5 Model","authors":"Jan Lehe\\v{c}ka, Zden\\v{e}k Hanzl\\'i\\v{c}ek, Jind\\v{r}ich\n  Matou\\v{s}ek, Daniel Tihelka","authorsParsed":[["Lehečka","Jan",""],["Hanzlíček","Zdeněk",""],["Matoušek","Jindřich",""],["Tihelka","Daniel",""]],"versions":[{"version":"v1","created":"Wed, 24 Jul 2024 11:14:06 GMT"}],"updateDate":"2024-07-25","timestamp":1721819646000,"abstract":"  In this paper, we experimented with the SpeechT5 model pre-trained on\nlarge-scale datasets. We pre-trained the foundation model from scratch and\nfine-tuned it on a large-scale robust multi-speaker text-to-speech (TTS) task.\nWe tested the model capabilities in a zero- and few-shot scenario. Based on two\nlistening tests, we evaluated the synthetic audio quality and the similarity of\nhow synthetic voices resemble real voices. Our results showed that the SpeechT5\nmodel can generate a synthetic voice for any speaker using only one minute of\nthe target speaker's data. We successfully demonstrated the high quality and\nsimilarity of our synthetic voices on publicly known Czech politicians and\ncelebrities.\n","subjects":["Computing Research Repository/Sound","Computing Research Repository/Computation and Language","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"YRdqEJVi1HjIlxY8jHfPWwfuuH3fPpCtGrJvF61T4kE","pdfSize":"222619","objectId":"0xc2fb4f42bc6c56d9f0b8c370522cd3479ba859de3367d1fc60d1e30442a1a875","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
