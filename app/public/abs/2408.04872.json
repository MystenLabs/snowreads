{"id":"2408.04872","title":"SCOI: Syntax-augmented Coverage-based In-context Example Selection for\n  Machine Translation","authors":"Chenming Tang, Zhixiang Wang and Yunfang Wu","authorsParsed":[["Tang","Chenming",""],["Wang","Zhixiang",""],["Wu","Yunfang",""]],"versions":[{"version":"v1","created":"Fri, 9 Aug 2024 05:25:17 GMT"}],"updateDate":"2024-08-12","timestamp":1723181117000,"abstract":"  In-context learning (ICL) greatly improves the performance of large language\nmodels (LLMs) on various down-stream tasks, where the improvement highly\ndepends on the quality of demonstrations. In this work, we introduce syntactic\nknowledge to select better in-context examples for machine translation (MT). We\npropose a new strategy, namely Syntax-augmented COverage-based In-context\nexample selection (SCOI), leveraging the deep syntactic structure beyond\nconventional word matching. Specifically, we measure the set-level syntactic\ncoverage by computing the coverage of polynomial terms with the help of a\nsimplified tree-to-polynomial algorithm, and lexical coverage using word\noverlap. Furthermore, we devise an alternate selection approach to combine both\ncoverage measures, taking advantage of syntactic and lexical information. We\nconduct experiments with two multi-lingual LLMs on six translation directions.\nEmpirical results show that our proposed SCOI obtains the highest average COMET\nscore among all learning-free methods, indicating that combining syntactic and\nlexical coverage successfully helps to select better in-context examples for\nMT.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}