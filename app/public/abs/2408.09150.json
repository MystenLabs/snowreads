{"id":"2408.09150","title":"CogLM: Tracking Cognitive Development of Large Language Models","authors":"Xinglin Wang, Peiwen Yuan, Shaoxiong Feng, Yiwei Li, Boyuan Pan, Heda\n  Wang, Yao Hu, Kan Li","authorsParsed":[["Wang","Xinglin",""],["Yuan","Peiwen",""],["Feng","Shaoxiong",""],["Li","Yiwei",""],["Pan","Boyuan",""],["Wang","Heda",""],["Hu","Yao",""],["Li","Kan",""]],"versions":[{"version":"v1","created":"Sat, 17 Aug 2024 09:49:40 GMT"}],"updateDate":"2024-08-20","timestamp":1723888180000,"abstract":"  Piaget's Theory of Cognitive Development (PTC) posits that the development of\ncognitive levels forms the foundation for human learning across various\nabilities. As Large Language Models (LLMs) have recently shown remarkable\nabilities across a wide variety of tasks, we are curious about the cognitive\nlevels of current LLMs: to what extent they have developed and how this\ndevelopment has been achieved. To this end, we construct a benchmark CogLM\n(Cognitive Ability Evaluation for Language Model) based on PTC to assess the\ncognitive levels of LLMs. CogLM comprises 1,220 questions spanning 10 cognitive\nabilities crafted by more than 20 human experts, providing a comprehensive\ntestbed for the cognitive levels of LLMs. Through extensive experiments across\nmultiple mainstream LLMs with CogLM, we find that: (1) Human-like cognitive\nabilities have emerged in advanced LLMs (GPT-4), comparable to those of a\n20-year-old human. (2) The parameter size and optimization objective are two\nkey factors affecting the cognitive levels of LLMs. (3) The performance on\ndownstream tasks is positively correlated with the level of cognitive\nabilities. These findings fill the gap in research on the cognitive abilities\nof LLMs, tracing the development of LLMs from a cognitive perspective and\nguiding the future direction of their evolution.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}