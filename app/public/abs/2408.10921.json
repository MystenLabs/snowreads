{"id":"2408.10921","title":"MTFinEval:A Multi-domain Chinese Financial Benchmark with Eurypalynous\n  questions","authors":"Xinyu Liu and Ke Jin","authorsParsed":[["Liu","Xinyu",""],["Jin","Ke",""]],"versions":[{"version":"v1","created":"Tue, 20 Aug 2024 15:04:38 GMT"}],"updateDate":"2024-08-21","timestamp":1724166278000,"abstract":"  With the emergence of more and more economy-specific LLMS, how to measure\nwhether they can be safely invested in production becomes a problem. Previous\nresearch has primarily focused on evaluating the performance of LLMs within\nspecific application scenarios. However, these benchmarks cannot reflect the\ntheoretical level and generalization ability, and the backward datasets are\nincreasingly unsuitable for problems in real scenarios. In this paper, we have\ncompiled a new benchmark, MTFinEval, focusing on the LLMs' basic knowledge of\neconomics, which can always be used as a basis for judgment. To examine only\ntheoretical knowledge as much as possible, MTFinEval is build with foundational\nquestions from university textbooks,and exam papers in economics and management\nmajor. Aware of the overall performance of LLMs do not depend solely on one\nsubdiscipline of economics, MTFinEval comprise 360 questions refined from six\nmajor disciplines of economics, and reflect capabilities more comprehensively.\nExperiment result shows all LLMs perform poorly on MTFinEval, which proves that\nour benchmark built on basic knowledge is very successful. Our research not\nonly offers guidance for selecting the appropriate LLM for specific use cases,\nbut also put forward increase the rigor reliability of LLMs from the basics.\n","subjects":["Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}