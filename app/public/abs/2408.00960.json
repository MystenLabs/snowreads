{"id":"2408.00960","title":"PERSOMA: PERsonalized SOft ProMpt Adapter Architecture for Personalized\n  Language Prompting","authors":"Liam Hebert, Krishna Sayana, Ambarish Jash, Alexandros Karatzoglou,\n  Sukhdeep Sodhi, Sumanth Doddapaneni, Yanli Cai, Dima Kuzmin","authorsParsed":[["Hebert","Liam",""],["Sayana","Krishna",""],["Jash","Ambarish",""],["Karatzoglou","Alexandros",""],["Sodhi","Sukhdeep",""],["Doddapaneni","Sumanth",""],["Cai","Yanli",""],["Kuzmin","Dima",""]],"versions":[{"version":"v1","created":"Fri, 2 Aug 2024 00:24:22 GMT"}],"updateDate":"2024-08-05","timestamp":1722558262000,"abstract":"  Understanding the nuances of a user's extensive interaction history is key to\nbuilding accurate and personalized natural language systems that can adapt to\nevolving user preferences. To address this, we introduce PERSOMA, Personalized\nSoft Prompt Adapter architecture. Unlike previous personalized prompting\nmethods for large language models, PERSOMA offers a novel approach to\nefficiently capture user history. It achieves this by resampling and\ncompressing interactions as free form text into expressive soft prompt\nembeddings, building upon recent research utilizing embedding representations\nas input for LLMs. We rigorously validate our approach by evaluating various\nadapter architectures, first-stage sampling strategies, parameter-efficient\ntuning techniques like LoRA, and other personalization methods. Our results\ndemonstrate PERSOMA's superior ability to handle large and complex user\nhistories compared to existing embedding-based and text-prompt-based\ntechniques.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Information Retrieval"],"license":"http://creativecommons.org/licenses/by/4.0/"}