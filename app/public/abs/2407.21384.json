{"id":"2407.21384","title":"GEGA: Graph Convolutional Networks and Evidence Retrieval Guided\n  Attention for Enhanced Document-level Relation Extraction","authors":"Yanxu Mao, Xiaohui Chen, Peipei Liu, Tiehan Cui, Zuhui Yue, Zheng Li","authorsParsed":[["Mao","Yanxu",""],["Chen","Xiaohui",""],["Liu","Peipei",""],["Cui","Tiehan",""],["Yue","Zuhui",""],["Li","Zheng",""]],"versions":[{"version":"v1","created":"Wed, 31 Jul 2024 07:15:33 GMT"},{"version":"v2","created":"Sun, 8 Sep 2024 16:42:28 GMT"}],"updateDate":"2024-09-10","timestamp":1722410133000,"abstract":"  Document-level relation extraction (DocRE) aims to extract relations between\nentities from unstructured document text. Compared to sentence-level relation\nextraction, it requires more complex semantic understanding from a broader text\ncontext. Currently, some studies are utilizing logical rules within evidence\nsentences to enhance the performance of DocRE. However, in the data without\nprovided evidence sentences, researchers often obtain a list of evidence\nsentences for the entire document through evidence retrieval (ER). Therefore,\nDocRE suffers from two challenges: firstly, the relevance between evidence and\nentity pairs is weak; secondly, there is insufficient extraction of complex\ncross-relations between long-distance multi-entities. To overcome these\nchallenges, we propose GEGA, a novel model for DocRE. The model leverages graph\nneural networks to construct multiple weight matrices, guiding attention\nallocation to evidence sentences. It also employs multi-scale representation\naggregation to enhance ER. Subsequently, we integrate the most efficient\nevidence information to implement both fully supervised and weakly supervised\ntraining processes for the model. We evaluate the GEGA model on three widely\nused benchmark datasets: DocRED, Re-DocRED, and Revisit-DocRED. The\nexperimental results indicate that our model has achieved comprehensive\nimprovements compared to the existing SOTA model.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}