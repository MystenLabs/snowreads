{"id":"2408.10175","title":"Fairness Under Cover: Evaluating the Impact of Occlusions on Demographic\n  Bias in Facial Recognition","authors":"Rafael M. Mamede, Pedro C. Neto, Ana F. Sequeira","authorsParsed":[["Mamede","Rafael M.",""],["Neto","Pedro C.",""],["Sequeira","Ana F.",""]],"versions":[{"version":"v1","created":"Mon, 19 Aug 2024 17:34:19 GMT"}],"updateDate":"2024-08-20","timestamp":1724088859000,"abstract":"  This study investigates the effects of occlusions on the fairness of face\nrecognition systems, particularly focusing on demographic biases. Using the\nRacial Faces in the Wild (RFW) dataset and synthetically added realistic\nocclusions, we evaluate their effect on the performance of face recognition\nmodels trained on the BUPT-Balanced and BUPT-GlobalFace datasets. We note\nincreases in the dispersion of FMR, FNMR, and accuracy alongside decreases in\nfairness according to Equilized Odds, Demographic Parity, STD of Accuracy, and\nFairness Discrepancy Rate. Additionally, we utilize a pixel attribution method\nto understand the importance of occlusions in model predictions, proposing a\nnew metric, Face Occlusion Impact Ratio (FOIR), that quantifies the extent to\nwhich occlusions affect model performance across different demographic groups.\nOur results indicate that occlusions exacerbate existing demographic biases,\nwith models placing higher importance on occlusions in an unequal fashion,\nparticularly affecting African individuals more severely.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}