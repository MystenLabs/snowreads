{"id":"2408.14603","title":"Biased Dueling Bandits with Stochastic Delayed Feedback","authors":"Bongsoo Yi, Yue Kang, Yao Li","authorsParsed":[["Yi","Bongsoo",""],["Kang","Yue",""],["Li","Yao",""]],"versions":[{"version":"v1","created":"Mon, 26 Aug 2024 19:49:12 GMT"}],"updateDate":"2024-08-28","timestamp":1724701752000,"abstract":"  The dueling bandit problem, an essential variation of the traditional\nmulti-armed bandit problem, has become significantly prominent recently due to\nits broad applications in online advertising, recommendation systems,\ninformation retrieval, and more. However, in many real-world applications, the\nfeedback for actions is often subject to unavoidable delays and is not\nimmediately available to the agent. This partially observable issue poses a\nsignificant challenge to existing dueling bandit literature, as it\nsignificantly affects how quickly and accurately the agent can update their\npolicy on the fly. In this paper, we introduce and examine the biased dueling\nbandit problem with stochastic delayed feedback, revealing that this new\npractical problem will delve into a more realistic and intriguing scenario\ninvolving a preference bias between the selections. We present two algorithms\ndesigned to handle situations involving delay. Our first algorithm, requiring\ncomplete delay distribution information, achieves the optimal regret bound for\nthe dueling bandit problem when there is no delay. The second algorithm is\ntailored for situations where the distribution is unknown, but only the\nexpected value of delay is available. We provide a comprehensive regret\nanalysis for the two proposed algorithms and then evaluate their empirical\nperformance on both synthetic and real datasets.\n","subjects":["Computing Research Repository/Machine Learning","Statistics/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}