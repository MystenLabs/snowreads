{"id":"2408.01826","title":"GLDiTalker: Speech-Driven 3D Facial Animation with Graph Latent\n  Diffusion Transformer","authors":"Yihong Lin, Zhaoxin Fan, Lingyu Xiong, Liang Peng, Xiandong Li,\n  Wenxiong Kang, Xianjia Wu, Songju Lei, Huang Xu","authorsParsed":[["Lin","Yihong",""],["Fan","Zhaoxin",""],["Xiong","Lingyu",""],["Peng","Liang",""],["Li","Xiandong",""],["Kang","Wenxiong",""],["Wu","Xianjia",""],["Lei","Songju",""],["Xu","Huang",""]],"versions":[{"version":"v1","created":"Sat, 3 Aug 2024 17:18:26 GMT"},{"version":"v2","created":"Fri, 16 Aug 2024 14:45:14 GMT"}],"updateDate":"2024-08-19","timestamp":1722705506000,"abstract":"  Speech-driven talking head generation is an important but challenging task\nfor many downstream applications such as augmented reality. Existing methods\nhave achieved remarkable performance by utilizing autoregressive models or\ndiffusion models. However, most still suffer from modality inconsistencies,\nspecifically the misalignment between audio and mesh modalities, which causes\ninconsistencies in motion diversity and lip-sync accuracy. To address this\nissue, this paper introduces GLDiTalker, a novel speech-driven 3D facial\nanimation model that employs a Graph Latent Diffusion Transformer. The core\nidea behind GLDiTalker is that the audio-mesh modality misalignment can be\nresolved by diffusing the signal in a latent quantilized spatial-temporal\nspace. To achieve this, GLDiTalker builds upon a quantilized space-time\ndiffusion training pipeline, which consists of a Graph Enhanced Quantilized\nSpace Learning Stage and a Space-Time Powered Latent Diffusion Stage. The first\nstage ensures lip-sync accuracy, while the second stage enhances motion\ndiversity. Together, these stages enable GLDiTalker to generate temporally and\nspatially stable, realistic models. Extensive evaluations on several widely\nused benchmarks demonstrate that our method achieves superior performance\ncompared to existing methods.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}