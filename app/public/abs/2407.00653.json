{"id":"2407.00653","title":"Chain-of-Knowledge: Integrating Knowledge Reasoning into Large Language\n  Models by Learning from Knowledge Graphs","authors":"Yifei Zhang, Xintao Wang, Jiaqing Liang, Sirui Xia, Lida Chen, Yanghua\n  Xiao","authorsParsed":[["Zhang","Yifei",""],["Wang","Xintao",""],["Liang","Jiaqing",""],["Xia","Sirui",""],["Chen","Lida",""],["Xiao","Yanghua",""]],"versions":[{"version":"v1","created":"Sun, 30 Jun 2024 10:49:32 GMT"}],"updateDate":"2024-07-02","timestamp":1719744572000,"abstract":"  Large Language Models (LLMs) have exhibited impressive proficiency in various\nnatural language processing (NLP) tasks, which involve increasingly complex\nreasoning. Knowledge reasoning, a primary type of reasoning, aims at deriving\nnew knowledge from existing one.While it has been widely studied in the context\nof knowledge graphs (KGs), knowledge reasoning in LLMs remains underexplored.\nIn this paper, we introduce Chain-of-Knowledge, a comprehensive framework for\nknowledge reasoning, including methodologies for both dataset construction and\nmodel learning. For dataset construction, we create KnowReason via rule mining\non KGs. For model learning, we observe rule overfitting induced by naive\ntraining. Hence, we enhance CoK with a trial-and-error mechanism that simulates\nthe human process of internal knowledge exploration. We conduct extensive\nexperiments with KnowReason. Our results show the effectiveness of CoK in\nrefining LLMs in not only knowledge reasoning, but also general reasoning\nbenchmarkms.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}