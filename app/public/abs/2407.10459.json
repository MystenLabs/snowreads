{"id":"2407.10459","title":"DiffStega: Towards Universal Training-Free Coverless Image Steganography\n  with Diffusion Models","authors":"Yiwei Yang, Zheyuan Liu, Jun Jia, Zhongpai Gao, Yunhao Li, Wei Sun,\n  Xiaohong Liu, Guangtao Zhai","authorsParsed":[["Yang","Yiwei",""],["Liu","Zheyuan",""],["Jia","Jun",""],["Gao","Zhongpai",""],["Li","Yunhao",""],["Sun","Wei",""],["Liu","Xiaohong",""],["Zhai","Guangtao",""]],"versions":[{"version":"v1","created":"Mon, 15 Jul 2024 06:15:49 GMT"}],"updateDate":"2024-07-16","timestamp":1721024149000,"abstract":"  Traditional image steganography focuses on concealing one image within\nanother, aiming to avoid steganalysis by unauthorized entities. Coverless image\nsteganography (CIS) enhances imperceptibility by not using any cover image.\nRecent works have utilized text prompts as keys in CIS through diffusion\nmodels. However, this approach faces three challenges: invalidated when private\nprompt is guessed, crafting public prompts for semantic diversity, and the risk\nof prompt leakage during frequent transmission. To address these issues, we\npropose DiffStega, an innovative training-free diffusion-based CIS strategy for\nuniversal application. DiffStega uses a password-dependent reference image as\nan image prompt alongside the text, ensuring that only authorized parties can\nretrieve the hidden information. Furthermore, we develop Noise Flip technique\nto further secure the steganography against unauthorized decryption. To\ncomprehensively assess our method across general CIS tasks, we create a dataset\ncomprising various image steganography instances. Experiments indicate\nsubstantial improvements in our method over existing ones, particularly in\naspects of versatility, password sensitivity, and recovery quality. Codes are\navailable at \\url{https://github.com/evtricks/DiffStega}.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}