{"id":"2407.06697","title":"Certified Continual Learning for Neural Network Regression","authors":"Long H. Pham and Jun Sun","authorsParsed":[["Pham","Long H.",""],["Sun","Jun",""]],"versions":[{"version":"v1","created":"Tue, 9 Jul 2024 09:14:45 GMT"}],"updateDate":"2024-07-10","timestamp":1720516485000,"abstract":"  On the one hand, there has been considerable progress on neural network\nverification in recent years, which makes certifying neural networks a\npossibility. On the other hand, neural networks in practice are often\nre-trained over time to cope with new data distribution or for solving\ndifferent tasks (a.k.a. continual learning). Once re-trained, the verified\ncorrectness of the neural network is likely broken, particularly in the\npresence of the phenomenon known as catastrophic forgetting. In this work, we\npropose an approach called certified continual learning which improves existing\ncontinual learning methods by preserving, as long as possible, the established\ncorrectness properties of a verified network. Our approach is evaluated with\nmultiple neural networks and on two different continual learning methods. The\nresults show that our approach is efficient and the trained models preserve\ntheir certified correctness and often maintain high utility.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}