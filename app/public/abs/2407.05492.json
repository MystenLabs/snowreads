{"id":"2407.05492","title":"Gaussian Approximation and Output Analysis for High-Dimensional MCMC","authors":"Ardjen Pengel and Jun Yang and Zhou Zhou","authorsParsed":[["Pengel","Ardjen",""],["Yang","Jun",""],["Zhou","Zhou",""]],"versions":[{"version":"v1","created":"Sun, 7 Jul 2024 20:43:59 GMT"}],"updateDate":"2024-07-09","timestamp":1720385039000,"abstract":"  The widespread use of Markov Chain Monte Carlo (MCMC) methods for\nhigh-dimensional applications has motivated research into the scalability of\nthese algorithms with respect to the dimension of the problem. Despite this,\nnumerous problems concerning output analysis in high-dimensional settings have\nremained unaddressed. We present novel quantitative Gaussian approximation\nresults for a broad range of MCMC algorithms. Notably, we analyse the\ndependency of the obtained approximation errors on the dimension of both the\ntarget distribution and the feature space. We demonstrate how these Gaussian\napproximations can be applied in output analysis. This includes determining the\nsimulation effort required to guarantee Markov chain central limit theorems and\nconsistent variance estimation in high-dimensional settings. We give\nquantitative convergence bounds for termination criteria and show that the\ntermination time of a wide class of MCMC algorithms scales polynomially in\ndimension while ensuring a desired level of precision. Our results offer\nguidance to practitioners for obtaining appropriate standard errors and\ndeciding the minimum simulation effort of MCMC algorithms in both multivariate\nand high-dimensional settings.\n","subjects":["Statistics/Computation","Statistics/Methodology"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}