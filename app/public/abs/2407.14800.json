{"id":"2407.14800","title":"Towards Realistic Emotional Voice Conversion using Controllable\n  Emotional Intensity","authors":"Tianhua Qi, Shiyan Wang, Cheng Lu, Yan Zhao, Yuan Zong, Wenming Zheng","authorsParsed":[["Qi","Tianhua",""],["Wang","Shiyan",""],["Lu","Cheng",""],["Zhao","Yan",""],["Zong","Yuan",""],["Zheng","Wenming",""]],"versions":[{"version":"v1","created":"Sat, 20 Jul 2024 08:13:58 GMT"}],"updateDate":"2024-07-23","timestamp":1721463238000,"abstract":"  Realistic emotional voice conversion (EVC) aims to enhance emotional\ndiversity of converted audios, making the synthesized voices more authentic and\nnatural. To this end, we propose Emotional Intensity-aware Network (EINet),\ndynamically adjusting intonation and rhythm by incorporating controllable\nemotional intensity. To better capture nuances in emotional intensity, we go\nbeyond mere distance measurements among acoustic features. Instead, an emotion\nevaluator is utilized to precisely quantify speaker's emotional state. By\nemploying an intensity mapper, intensity pseudo-labels are obtained to bridge\nthe gap between emotional speech intensity modeling and run-time conversion. To\nensure high speech quality while retaining controllability, an emotion renderer\nis used for combining linguistic features smoothly with manipulated emotional\nfeatures at frame level. Furthermore, we employ a duration predictor to\nfacilitate adaptive prediction of rhythm changes condition on specifying\nintensity value. Experimental results show EINet's superior performance in\nnaturalness and diversity of emotional expression compared to state-of-the-art\nEVC methods.\n","subjects":["Electrical Engineering and Systems Science/Audio and Speech Processing","Computing Research Repository/Sound","Electrical Engineering and Systems Science/Signal Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}