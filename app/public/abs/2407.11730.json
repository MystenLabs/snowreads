{"id":"2407.11730","title":"Monocular Occupancy Prediction for Scalable Indoor Scenes","authors":"Hongxiao Yu, Yuqi Wang, Yuntao Chen, Zhaoxiang Zhang","authorsParsed":[["Yu","Hongxiao",""],["Wang","Yuqi",""],["Chen","Yuntao",""],["Zhang","Zhaoxiang",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 13:50:40 GMT"},{"version":"v2","created":"Wed, 17 Jul 2024 02:37:07 GMT"}],"updateDate":"2024-07-18","timestamp":1721137840000,"abstract":"  Camera-based 3D occupancy prediction has recently garnered increasing\nattention in outdoor driving scenes. However, research in indoor scenes remains\nrelatively unexplored. The core differences in indoor scenes lie in the\ncomplexity of scene scale and the variance in object size. In this paper, we\npropose a novel method, named ISO, for predicting indoor scene occupancy using\nmonocular images. ISO harnesses the advantages of a pretrained depth model to\nachieve accurate depth predictions. Furthermore, we introduce the Dual Feature\nLine of Sight Projection (D-FLoSP) module within ISO, which enhances the\nlearning of 3D voxel features. To foster further research in this domain, we\nintroduce Occ-ScanNet, a large-scale occupancy benchmark for indoor scenes.\nWith a dataset size 40 times larger than the NYUv2 dataset, it facilitates\nfuture scalable research in indoor scene analysis. Experimental results on both\nNYUv2 and Occ-ScanNet demonstrate that our method achieves state-of-the-art\nperformance. The dataset and code are made publicly at\nhttps://github.com/hongxiaoy/ISO.git.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}