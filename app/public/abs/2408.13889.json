{"id":"2408.13889","title":"LLM with Relation Classifier for Document-Level Relation Extraction","authors":"Xingzuo Li, Kehai Chen, Yunfei Long, Min Zhang","authorsParsed":[["Li","Xingzuo",""],["Chen","Kehai",""],["Long","Yunfei",""],["Zhang","Min",""]],"versions":[{"version":"v1","created":"Sun, 25 Aug 2024 16:43:19 GMT"}],"updateDate":"2024-08-27","timestamp":1724604199000,"abstract":"  Large language models (LLMs) create a new paradigm for natural language\nprocessing. Despite their advancement, LLM-based methods still lag behind\ntraditional approaches in document-level relation extraction (DocRE), a\ncritical task for understanding complex entity relations. This paper\ninvestigates the causes of this performance gap, identifying the dispersion of\nattention by LLMs due to entity pairs without relations as a primary factor. We\nthen introduce a novel classifier-LLM approach to DocRE. The proposed approach\nbegins with a classifier specifically designed to select entity pair candidates\nexhibiting potential relations and thereby feeds them to LLM for the final\nrelation extraction. This method ensures that during inference, the LLM's focus\nis directed primarily at entity pairs with relations. Experiments on DocRE\nbenchmarks reveal that our method significantly outperforms recent LLM-based\nDocRE models and achieves competitive performance with several leading\ntraditional DocRE models.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/"}