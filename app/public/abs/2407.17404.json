{"id":"2407.17404","title":"Grammar-based Game Description Generation using Large Language Models","authors":"Tsunehiko Tanaka, Edgar Simo-Serra","authorsParsed":[["Tanaka","Tsunehiko",""],["Simo-Serra","Edgar",""]],"versions":[{"version":"v1","created":"Wed, 24 Jul 2024 16:36:02 GMT"}],"updateDate":"2024-07-25","timestamp":1721838962000,"abstract":"  To lower the barriers to game design development, automated game design,\nwhich generates game designs through computational processes, has been\nexplored. In automated game design, machine learning-based techniques such as\nevolutionary algorithms have achieved success. Benefiting from the remarkable\nadvancements in deep learning, applications in computer vision and natural\nlanguage processing have progressed in level generation. However, due to the\nlimited amount of data in game design, the application of deep learning has\nbeen insufficient for tasks such as game description generation. To pioneer a\nnew approach for handling limited data in automated game design, we focus on\nthe in-context learning of large language models (LLMs). LLMs can capture the\nfeatures of a task from a few demonstration examples and apply the capabilities\nacquired during pre-training. We introduce the grammar of game descriptions,\nwhich effectively structures the game design space, into the LLMs' reasoning\nprocess. Grammar helps LLMs capture the characteristics of the complex task of\ngame description generation. Furthermore, we propose a decoding method that\niteratively improves the generated output by leveraging the grammar. Our\nexperiments demonstrate that this approach performs well in generating game\ndescriptions.\n","subjects":["Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/"}