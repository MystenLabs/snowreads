{"id":"2407.16837","title":"CompBench: A Comparative Reasoning Benchmark for Multimodal LLMs","authors":"Jihyung Kil, Zheda Mai, Justin Lee, Zihe Wang, Kerrie Cheng, Lemeng\n  Wang, Ye Liu, Arpita Chowdhury, Wei-Lun Chao","authorsParsed":[["Kil","Jihyung",""],["Mai","Zheda",""],["Lee","Justin",""],["Wang","Zihe",""],["Cheng","Kerrie",""],["Wang","Lemeng",""],["Liu","Ye",""],["Chowdhury","Arpita",""],["Chao","Wei-Lun",""]],"versions":[{"version":"v1","created":"Tue, 23 Jul 2024 21:02:38 GMT"}],"updateDate":"2024-07-25","timestamp":1721768558000,"abstract":"  The ability to compare objects, scenes, or situations is crucial for\neffective decision-making and problem-solving in everyday life. For instance,\ncomparing the freshness of apples enables better choices during grocery\nshopping, while comparing sofa designs helps optimize the aesthetics of our\nliving space. Despite its significance, the comparative capability is largely\nunexplored in artificial general intelligence (AGI). In this paper, we\nintroduce CompBench, a benchmark designed to evaluate the comparative reasoning\ncapability of multimodal large language models (MLLMs). CompBench mines and\npairs images through visually oriented questions covering eight dimensions of\nrelative comparison: visual attribute, existence, state, emotion, temporality,\nspatiality, quantity, and quality. We curate a collection of around 40K image\npairs using metadata from diverse vision datasets and CLIP similarity scores.\nThese image pairs span a broad array of visual domains, including animals,\nfashion, sports, and both outdoor and indoor scenes. The questions are\ncarefully crafted to discern relative characteristics between two images and\nare labeled by human annotators for accuracy and relevance. We use CompBench to\nevaluate recent MLLMs, including GPT-4V(ision), Gemini-Pro, and LLaVA-1.6. Our\nresults reveal notable shortcomings in their comparative abilities. We believe\nCompBench not only sheds light on these limitations but also establishes a\nsolid foundation for future enhancements in the comparative capability of\nMLLMs.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}