{"id":"2407.10646","title":"Towards zero-shot amplifier modeling: One-to-many amplifier modeling via\n  tone embedding control","authors":"Yu-Hua Chen, Yen-Tung Yeh, Yuan-Chiao Cheng, Jui-Te Wu, Yu-Hsiang Ho,\n  Jyh-Shing Roger Jang, and Yi-Hsuan Yang","authorsParsed":[["Chen","Yu-Hua",""],["Yeh","Yen-Tung",""],["Cheng","Yuan-Chiao",""],["Wu","Jui-Te",""],["Ho","Yu-Hsiang",""],["Jang","Jyh-Shing Roger",""],["Yang","Yi-Hsuan",""]],"versions":[{"version":"v1","created":"Mon, 15 Jul 2024 12:04:56 GMT"}],"updateDate":"2024-07-16","timestamp":1721045096000,"abstract":"  Replicating analog device circuits through neural audio effect modeling has\ngarnered increasing interest in recent years. Existing work has predominantly\nfocused on a one-to-one emulation strategy, modeling specific devices\nindividually. In this paper, we tackle the less-explored scenario of\none-to-many emulation, utilizing conditioning mechanisms to emulate multiple\nguitar amplifiers through a single neural model. For condition representation,\nwe use contrastive learning to build a tone embedding encoder that extracts\nstyle-related features of various amplifiers, leveraging a dataset of\ncomprehensive amplifier settings. Targeting zero-shot application scenarios, we\nalso examine various strategies for tone embedding representation, evaluating\nreferenced tone embedding against two retrieval-based embedding methods for\namplifiers unseen in the training time. Our findings showcase the efficacy and\npotential of the proposed methods in achieving versatile one-to-many amplifier\nmodeling, contributing a foundational step towards zero-shot audio modeling\napplications.\n","subjects":["Computing Research Repository/Sound","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by/4.0/"}