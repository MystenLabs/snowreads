{"id":"2407.10835","title":"Exploration in Knowledge Transfer Utilizing Reinforcement Learning","authors":"Adam Jedli\\v{c}ka and Tatiana Valentine Guy","authorsParsed":[["Jedliƒçka","Adam",""],["Guy","Tatiana Valentine",""]],"versions":[{"version":"v1","created":"Mon, 15 Jul 2024 15:45:29 GMT"}],"updateDate":"2024-07-16","timestamp":1721058329000,"abstract":"  The contribution focuses on the problem of exploration within the task of\nknowledge transfer. Knowledge transfer refers to the useful application of the\nknowledge gained while learning the source task in the target task. The\nintended benefit of knowledge transfer is to speed up the learning process of\nthe target task. The article aims to compare several exploration methods used\nwithin a deep transfer learning algorithm, particularly Deep Target Transfer\n$Q$-learning. The methods used are $\\epsilon$-greedy, Boltzmann, and upper\nconfidence bound exploration. The aforementioned transfer learning algorithms\nand exploration methods were tested on the virtual drone problem. The results\nhave shown that the upper confidence bound algorithm performs the best out of\nthese options. Its sustainability to other applications is to be checked.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/"}