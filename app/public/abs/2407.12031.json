{"id":"2407.12031","title":"Evaluation of Bias Towards Medical Professionals in Large Language\n  Models","authors":"Xi Chen, Yang Xu, MingKe You, Li Wang, WeiZhi Liu, Jian Li","authorsParsed":[["Chen","Xi",""],["Xu","Yang",""],["You","MingKe",""],["Wang","Li",""],["Liu","WeiZhi",""],["Li","Jian",""]],"versions":[{"version":"v1","created":"Sun, 30 Jun 2024 05:55:55 GMT"}],"updateDate":"2024-07-18","timestamp":1719726955000,"abstract":"  This study evaluates whether large language models (LLMs) exhibit biases\ntowards medical professionals. Fictitious candidate resumes were created to\ncontrol for identity factors while maintaining consistent qualifications. Three\nLLMs (GPT-4, Claude-3-haiku, and Mistral-Large) were tested using a\nstandardized prompt to evaluate resumes for specific residency programs.\nExplicit bias was tested by changing gender and race information, while\nimplicit bias was tested by changing names while hiding race and gender.\nPhysician data from the Association of American Medical Colleges was used to\ncompare with real-world demographics. 900,000 resumes were evaluated. All LLMs\nexhibited significant gender and racial biases across medical specialties.\nGender preferences varied, favoring male candidates in surgery and orthopedics,\nwhile preferring females in dermatology, family medicine, obstetrics and\ngynecology, pediatrics, and psychiatry. Claude-3 and Mistral-Large generally\nfavored Asian candidates, while GPT-4 preferred Black and Hispanic candidates\nin several specialties. Tests revealed strong preferences towards Hispanic\nfemales and Asian males in various specialties. Compared to real-world data,\nLLMs consistently chose higher proportions of female and underrepresented\nracial candidates than their actual representation in the medical workforce.\nGPT-4, Claude-3, and Mistral-Large showed significant gender and racial biases\nwhen evaluating medical professionals for residency selection. These findings\nhighlight the potential for LLMs to perpetuate biases and compromise healthcare\nworkforce diversity if used without proper bias mitigation strategies.\n","subjects":["Computing Research Repository/Computers and Society","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"Kq7K97qsBq1ry7t4NdhwPi85Rpjka_1I5c47H6GJtT4","pdfSize":"3778237"}
