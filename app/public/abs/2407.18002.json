{"id":"2407.18002","title":"Network Inversion of Convolutional Neural Nets","authors":"Pirzada Suhail and Amit Sethi","authorsParsed":[["Suhail","Pirzada",""],["Sethi","Amit",""]],"versions":[{"version":"v1","created":"Thu, 25 Jul 2024 12:53:21 GMT"}],"updateDate":"2024-07-26","timestamp":1721912001000,"abstract":"  Neural networks have emerged as powerful tools across various applications,\nyet their decision-making process often remains opaque, leading to them being\nperceived as \"black boxes.\" This opacity raises concerns about their\ninterpretability and reliability, especially in safety-critical scenarios.\nNetwork inversion techniques offer a solution by allowing us to peek inside\nthese black boxes, revealing the features and patterns learned by the networks\nbehind their decision-making processes and thereby provide valuable insights\ninto how neural networks arrive at their conclusions, making them more\ninterpretable and trustworthy. This paper presents a simple yet effective\napproach to network inversion using a carefully conditioned generator that\nlearns the data distribution in the input space of the trained neural network,\nenabling the reconstruction of inputs that would most likely lead to the\ndesired outputs. To capture the diversity in the input space for a given\noutput, instead of simply revealing the conditioning labels to the generator,\nwe hideously encode the conditioning label information into vectors, further\nexemplified by heavy dropout in the generation process and minimisation of\ncosine similarity between the features corresponding to the generated images.\nThe paper concludes with immediate applications of Network Inversion including\nin interpretability, explainability and generation of adversarial samples.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"-rZR9HaCKNdTOcov6WJdXogaH3xaUaocKLMG6wXsq0s","pdfSize":"1522524"}
