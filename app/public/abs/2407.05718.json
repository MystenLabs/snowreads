{"id":"2407.05718","title":"A Factuality and Diversity Reconciled Decoding Method for\n  Knowledge-Grounded Dialogue Generation","authors":"Chenxu Yang, Zheng Lin, Chong Tian, Liang Pang, Lanrui Wang, Zhengyang\n  Tong, Qirong Ho, Yanan Cao, Weiping Wang","authorsParsed":[["Yang","Chenxu",""],["Lin","Zheng",""],["Tian","Chong",""],["Pang","Liang",""],["Wang","Lanrui",""],["Tong","Zhengyang",""],["Ho","Qirong",""],["Cao","Yanan",""],["Wang","Weiping",""]],"versions":[{"version":"v1","created":"Mon, 8 Jul 2024 08:23:11 GMT"}],"updateDate":"2024-07-09","timestamp":1720426991000,"abstract":"  Grounding external knowledge can enhance the factuality of responses in\ndialogue generation. However, excessive emphasis on it might result in the lack\nof engaging and diverse expressions. Through the introduction of randomness in\nsampling, current approaches can increase the diversity. Nevertheless, such\nsampling method could undermine the factuality in dialogue generation. In this\nstudy, to discover a solution for advancing creativity without relying on\nquestionable randomness and to subtly reconcile the factuality and diversity\nwithin the source-grounded paradigm, a novel method named DoGe is proposed.\nDoGe can dynamically alternate between the utilization of internal parameter\nknowledge and external source knowledge based on the model's factual\nconfidence. Extensive experiments on three widely-used datasets show that DoGe\ncan not only enhance response diversity but also maintain factuality, and it\nsignificantly surpasses other various decoding strategy baselines.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}