{"id":"2407.03598","title":"ASteISR: Adapting Single Image Super-resolution Pre-trained Model for\n  Efficient Stereo Image Super-resolution","authors":"Yuanbo Zhou, Yuyang Xue, Wei Deng, Xinlin Zhang, Qinquan Gao, Tong\n  Tong","authorsParsed":[["Zhou","Yuanbo",""],["Xue","Yuyang",""],["Deng","Wei",""],["Zhang","Xinlin",""],["Gao","Qinquan",""],["Tong","Tong",""]],"versions":[{"version":"v1","created":"Thu, 4 Jul 2024 03:12:05 GMT"}],"updateDate":"2024-07-08","timestamp":1720062725000,"abstract":"  Despite advances in the paradigm of pre-training then fine-tuning in\nlow-level vision tasks, significant challenges persist particularly regarding\nthe increased size of pre-trained models such as memory usage and training\ntime. Another concern often encountered is the unsatisfying results yielded\nwhen directly applying pre-trained single-image models to multi-image domain.\nIn this paper, we propose a efficient method for transferring a pre-trained\nsingle-image super-resolution (SISR) transformer network to the domain of\nstereo image super-resolution (SteISR) through a parameter-efficient\nfine-tuning (PEFT) method. Specifically, we introduce the concept of stereo\nadapters and spatial adapters which are incorporated into the pre-trained SISR\ntransformer network. Subsequently, the pre-trained SISR model is frozen,\nenabling us to fine-tune the adapters using stereo datasets along. By adopting\nthis training method, we enhance the ability of the SISR model to accurately\ninfer stereo images by 0.79dB on the Flickr1024 dataset. This method allows us\nto train only 4.8% of the original model parameters, achieving state-of-the-art\nperformance on four commonly used SteISR benchmarks. Compared to the more\ncomplicated full fine-tuning approach, our method reduces training time and\nmemory consumption by 57% and 15%, respectively.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}