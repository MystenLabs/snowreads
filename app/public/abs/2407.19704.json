{"id":"2407.19704","title":"UNQA: Unified No-Reference Quality Assessment for Audio, Image, Video,\n  and Audio-Visual Content","authors":"Yuqin Cao, Xiongkuo Min, Yixuan Gao, Wei Sun, Weisi Lin, Guangtao Zhai","authorsParsed":[["Cao","Yuqin",""],["Min","Xiongkuo",""],["Gao","Yixuan",""],["Sun","Wei",""],["Lin","Weisi",""],["Zhai","Guangtao",""]],"versions":[{"version":"v1","created":"Mon, 29 Jul 2024 04:56:56 GMT"}],"updateDate":"2024-07-30","timestamp":1722229016000,"abstract":"  As multimedia data flourishes on the Internet, quality assessment (QA) of\nmultimedia data becomes paramount for digital media applications. Since\nmultimedia data includes multiple modalities including audio, image, video, and\naudio-visual (A/V) content, researchers have developed a range of QA methods to\nevaluate the quality of different modality data. While they exclusively focus\non addressing the single modality QA issues, a unified QA model that can handle\ndiverse media across multiple modalities is still missing, whereas the latter\ncan better resemble human perception behaviour and also have a wider range of\napplications. In this paper, we propose the Unified No-reference Quality\nAssessment model (UNQA) for audio, image, video, and A/V content, which tries\nto train a single QA model across different media modalities. To tackle the\nissue of inconsistent quality scales among different QA databases, we develop a\nmulti-modality strategy to jointly train UNQA on multiple QA databases. Based\non the input modality, UNQA selectively extracts the spatial features, motion\nfeatures, and audio features, and calculates a final quality score via the four\ncorresponding modality regression modules. Compared with existing QA methods,\nUNQA has two advantages: 1) the multi-modality training strategy makes the QA\nmodel learn more general and robust quality-aware feature representation as\nevidenced by the superior performance of UNQA compared to state-of-the-art QA\nmethods. 2) UNQA reduces the number of models required to assess multimedia\ndata across different modalities. and is friendly to deploy to practical\napplications.\n","subjects":["Electrical Engineering and Systems Science/Image and Video Processing","Computing Research Repository/Multimedia","Computing Research Repository/Sound","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}