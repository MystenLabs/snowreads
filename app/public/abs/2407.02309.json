{"id":"2407.02309","title":"Semantically Guided Representation Learning For Action Anticipation","authors":"Anxhelo Diko, Danilo Avola, Bardh Prenkaj, Federico Fontana, Luigi\n  Cinque","authorsParsed":[["Diko","Anxhelo",""],["Avola","Danilo",""],["Prenkaj","Bardh",""],["Fontana","Federico",""],["Cinque","Luigi",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 14:44:01 GMT"}],"updateDate":"2024-07-03","timestamp":1719931441000,"abstract":"  Action anticipation is the task of forecasting future activity from a\npartially observed sequence of events. However, this task is exposed to\nintrinsic future uncertainty and the difficulty of reasoning upon\ninterconnected actions. Unlike previous works that focus on extrapolating\nbetter visual and temporal information, we concentrate on learning action\nrepresentations that are aware of their semantic interconnectivity based on\nprototypical action patterns and contextual co-occurrences. To this end, we\npropose the novel Semantically Guided Representation Learning (S-GEAR)\nframework. S-GEAR learns visual action prototypes and leverages language models\nto structure their relationship, inducing semanticity. To gather insights on\nS-GEAR's effectiveness, we test it on four action anticipation benchmarks,\nobtaining improved results compared to previous works: +3.5, +2.7, and +3.5\nabsolute points on Top-1 Accuracy on Epic-Kitchen 55, EGTEA Gaze+ and 50\nSalads, respectively, and +0.8 on Top-5 Recall on Epic-Kitchens 100. We further\nobserve that S-GEAR effectively transfers the geometric associations between\nactions from language to visual prototypes. Finally, S-GEAR opens new research\nfrontiers in anticipation tasks by demonstrating the intricate impact of action\nsemantic interconnectivity.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}