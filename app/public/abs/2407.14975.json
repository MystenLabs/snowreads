{"id":"2407.14975","title":"A Measure for Level of Autonomy Based on Observable System Behavior","authors":"Jason M. Pittman","authorsParsed":[["Pittman","Jason M.",""]],"versions":[{"version":"v1","created":"Sat, 20 Jul 2024 20:34:20 GMT"}],"updateDate":"2024-07-23","timestamp":1721507660000,"abstract":"  Contemporary artificial intelligence systems are pivotal in enhancing human\nefficiency and safety across various domains. One such domain is autonomous\nsystems, especially in automotive and defense use cases. Artificial\nintelligence brings learning and enhanced decision-making to autonomy system\ngoal-oriented behaviors and human independence. However, the lack of clear\nunderstanding of autonomy system capabilities hampers human-machine or\nmachine-machine interaction and interdiction. This necessitates varying degrees\nof human involvement for safety, accountability, and explainability purposes.\nYet, measuring the level autonomous capability in an autonomous system presents\na challenge. Two scales of measurement exist, yet measuring autonomy\npresupposes a variety of elements not available in the wild. This is why\nexisting measures for level of autonomy are operationalized only during design\nor test and evaluation phases. No measure for level of autonomy based on\nobserved system behavior exists at this time. To address this, we outline a\npotential measure for predicting level of autonomy using observable actions. We\nalso present an algorithm incorporating the proposed measure. The measure and\nalgorithm have significance to researchers and practitioners interested in a\nmethod to blind compare autonomous systems at runtime. Defense-based\nimplementations are likewise possible because counter-autonomy depends on\nrobust identification of autonomous systems.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computers and Society"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}