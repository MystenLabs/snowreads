{"id":"2407.20502","title":"Restoring Real-World Degraded Events Improves Deblurring Quality","authors":"Yeqing Shen, Shang Li and Kun Song","authorsParsed":[["Shen","Yeqing",""],["Li","Shang",""],["Song","Kun",""]],"versions":[{"version":"v1","created":"Tue, 30 Jul 2024 02:29:59 GMT"}],"updateDate":"2024-07-31","timestamp":1722306599000,"abstract":"  Due to its high speed and low latency, DVS is frequently employed in motion\ndeblurring. Ideally, high-quality events would adeptly capture intricate motion\ninformation. However, real-world events are generally degraded, thereby\nintroducing significant artifacts into the deblurred results. In response to\nthis challenge, we model the degradation of events and propose RDNet to improve\nthe quality of image deblurring. Specifically, we first analyze the mechanisms\nunderlying degradation and simulate paired events based on that. These paired\nevents are then fed into the first stage of the RDNet for training the\nrestoration model. The events restored in this stage serve as a guide for the\nsecond-stage deblurring process. To better assess the deblurring performance of\ndifferent methods on real-world degraded events, we present a new real-world\ndataset named DavisMCR. This dataset incorporates events with diverse\ndegradation levels, collected by manipulating environmental brightness and\ntarget object contrast. Our experiments are conducted on synthetic datasets\n(GOPRO), real-world datasets (REBlur), and the proposed dataset (DavisMCR). The\nresults demonstrate that RDNet outperforms classical event denoising methods in\nevent restoration. Furthermore, RDNet exhibits better performance in deblurring\ntasks compared to state-of-the-art methods. DavisMCR are available at\nhttps://github.com/Yeeesir/DVS_RDNet.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}