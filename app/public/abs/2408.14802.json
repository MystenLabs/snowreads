{"id":"2408.14802","title":"RAW-Adapter: Adapting Pre-trained Visual Model to Camera RAW Images","authors":"Ziteng Cui and Tatsuya Harada","authorsParsed":[["Cui","Ziteng",""],["Harada","Tatsuya",""]],"versions":[{"version":"v1","created":"Tue, 27 Aug 2024 06:14:54 GMT"}],"updateDate":"2024-08-28","timestamp":1724739294000,"abstract":"  sRGB images are now the predominant choice for pre-training visual models in\ncomputer vision research, owing to their ease of acquisition and efficient\nstorage. Meanwhile, the advantage of RAW images lies in their rich physical\ninformation under variable real-world challenging lighting conditions. For\ncomputer vision tasks directly based on camera RAW data, most existing studies\nadopt methods of integrating image signal processor (ISP) with backend\nnetworks, yet often overlook the interaction capabilities between the ISP\nstages and subsequent networks. Drawing inspiration from ongoing adapter\nresearch in NLP and CV areas, we introduce RAW-Adapter, a novel approach aimed\nat adapting sRGB pre-trained models to camera RAW data. RAW-Adapter comprises\ninput-level adapters that employ learnable ISP stages to adjust RAW inputs, as\nwell as model-level adapters to build connections between ISP stages and\nsubsequent high-level networks. Additionally, RAW-Adapter is a general\nframework that could be used in various computer vision frameworks. Abundant\nexperiments under different lighting conditions have shown our algorithm's\nstate-of-the-art (SOTA) performance, demonstrating its effectiveness and\nefficiency across a range of real-world and synthetic datasets.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"VtYajpzfUVndZ8BHOHFVnvJZsj-8r3oK06RiSJSiQ6Q","pdfSize":"11027565"}
