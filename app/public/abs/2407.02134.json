{"id":"2407.02134","title":"Abstract Markov Random Fields","authors":"Leon Lang, Cl\\'elia de Mulatier, Rick Quax, Patrick Forr\\'e","authorsParsed":[["Lang","Leon",""],["de Mulatier","Clélia",""],["Quax","Rick",""],["Forré","Patrick",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 10:28:32 GMT"}],"updateDate":"2024-07-03","timestamp":1719916112000,"abstract":"  Markov random fields are known to be fully characterized by properties of\ntheir information diagrams, or I-diagrams. In particular, for Markov random\nfields, regions in the I-diagram corresponding to disconnected vertex sets in\nthe graph vanish. Recently, I-diagrams have been generalized to F-diagrams, for\na larger class of functions F satisfying the chain rule beyond Shannon entropy,\nsuch as Kullback-Leibler divergence and cross-entropy. In this work, we\ngeneralize the notion and characterization of Markov random fields to this\nlarger class of functions F and investigate preliminary applications.\n  We define F-independences, F-mutual independences, and F-Markov random fields\nand characterize them by their F-diagram. In the process, we also define F-dual\ntotal correlation and prove that its vanishing is equivalent to F-mutual\nindependence. We then apply our results to information functions F that are\napplied to probability distributions. We show that if the probability\ndistributions are Markov random fields for the same graph, then we formally\nrecover the notion of an F-Markov random field for that graph. We then study\nthe Kullback-Leibler divergence on specific Markov chains, leading to a visual\nrepresentation of the second law of thermodynamics.\n","subjects":["Computing Research Repository/Information Theory","Mathematics/Information Theory"],"license":"http://creativecommons.org/licenses/by/4.0/"}