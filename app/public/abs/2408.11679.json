{"id":"2408.11679","title":"Exploring Robustness of Visual State Space model against Backdoor\n  Attacks","authors":"Cheng-Yi Lee, Cheng-Chang Tsai, Chia-Mu Yu, Chun-Shien Lu","authorsParsed":[["Lee","Cheng-Yi",""],["Tsai","Cheng-Chang",""],["Yu","Chia-Mu",""],["Lu","Chun-Shien",""]],"versions":[{"version":"v1","created":"Wed, 21 Aug 2024 14:58:29 GMT"},{"version":"v2","created":"Thu, 22 Aug 2024 04:36:39 GMT"}],"updateDate":"2024-08-23","timestamp":1724252309000,"abstract":"  Visual State Space Model (VSS) has demonstrated remarkable performance in\nvarious computer vision tasks. However, in the process of development, backdoor\nattacks have brought severe challenges to security. Such attacks cause an\ninfected model to predict target labels when a specific trigger is activated,\nwhile the model behaves normally on benign samples. In this paper, we conduct\nsystematic experiments to comprehend on robustness of VSS through the lens of\nbackdoor attacks, specifically how the state space model (SSM) mechanism\naffects robustness. We first investigate the vulnerability of VSS to different\nbackdoor triggers and reveal that the SSM mechanism, which captures contextual\ninformation within patches, makes the VSS model more susceptible to backdoor\ntriggers compared to models without SSM. Furthermore, we analyze the\nsensitivity of the VSS model to patch processing techniques and discover that\nthese triggers are effectively disrupted. Based on these observations, we\nconsider an effective backdoor for the VSS model that recurs in each patch to\nresist patch perturbations. Extensive experiments across three datasets and\nvarious backdoor attacks reveal that the VSS model performs comparably to\nTransformers (ViTs) but is less robust than the Gated CNNs, which comprise only\nstacked Gated CNN blocks without SSM.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}