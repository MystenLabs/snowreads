{"id":"2407.16826","title":"SINDER: Repairing the Singular Defects of DINOv2","authors":"Haoqi Wang, Tong Zhang, Mathieu Salzmann","authorsParsed":[["Wang","Haoqi",""],["Zhang","Tong",""],["Salzmann","Mathieu",""]],"versions":[{"version":"v1","created":"Tue, 23 Jul 2024 20:34:23 GMT"}],"updateDate":"2024-07-25","timestamp":1721766863000,"abstract":"  Vision Transformer models trained on large-scale datasets, although\neffective, often exhibit artifacts in the patch token they extract. While such\ndefects can be alleviated by re-training the entire model with additional\nclassification tokens, the underlying reasons for the presence of these tokens\nremain unclear. In this paper, we conduct a thorough investigation of this\nphenomenon, combining theoretical analysis with empirical observations. Our\nfindings reveal that these artifacts originate from the pre-trained network\nitself, specifically stemming from the leading left singular vector of the\nnetwork's weights. Furthermore, to mitigate these defects, we propose a novel\nfine-tuning smooth regularization that rectifies structural deficiencies using\nonly a small dataset, thereby avoiding the need for complete re-training. We\nvalidate our method on various downstream tasks, including unsupervised\nsegmentation, classification, supervised segmentation, and depth estimation,\ndemonstrating its effectiveness in improving model performance. Codes and\ncheckpoints are available at https://github.com/haoqiwang/sinder.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"d9AyuSb5K83x5cfEO0Q5BV0q1fMe8WmDHjTiEeyFq08","pdfSize":"11573847","objectId":"0x11dcbe5dcddc1aeac672d12e4dc5f1ca9a8512012e3884789aeb6f388067f6ea","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
