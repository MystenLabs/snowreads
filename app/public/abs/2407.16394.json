{"id":"2407.16394","title":"SEDS: Semantically Enhanced Dual-Stream Encoder for Sign Language\n  Retrieval","authors":"Longtao Jiang, Min Wang, Zecheng Li, Yao Fang, Wengang Zhou, Houqiang\n  Li","authorsParsed":[["Jiang","Longtao",""],["Wang","Min",""],["Li","Zecheng",""],["Fang","Yao",""],["Zhou","Wengang",""],["Li","Houqiang",""]],"versions":[{"version":"v1","created":"Tue, 23 Jul 2024 11:31:11 GMT"}],"updateDate":"2024-07-24","timestamp":1721734271000,"abstract":"  Different from traditional video retrieval, sign language retrieval is more\nbiased towards understanding the semantic information of human actions\ncontained in video clips. Previous works typically only encode RGB videos to\nobtain high-level semantic features, resulting in local action details drowned\nin a large amount of visual information redundancy. Furthermore, existing\nRGB-based sign retrieval works suffer from the huge memory cost of dense visual\ndata embedding in end-to-end training, and adopt offline RGB encoder instead,\nleading to suboptimal feature representation. To address these issues, we\npropose a novel sign language representation framework called Semantically\nEnhanced Dual-Stream Encoder (SEDS), which integrates Pose and RGB modalities\nto represent the local and global information of sign language videos.\nSpecifically, the Pose encoder embeds the coordinates of keypoints\ncorresponding to human joints, effectively capturing detailed action features.\nFor better context-aware fusion of two video modalities, we propose a Cross\nGloss Attention Fusion (CGAF) module to aggregate the adjacent clip features\nwith similar semantic information from intra-modality and inter-modality.\nMoreover, a Pose-RGB Fine-grained Matching Objective is developed to enhance\nthe aggregated fusion feature by contextual matching of fine-grained\ndual-stream features. Besides the offline RGB encoder, the whole framework only\ncontains learnable lightweight networks, which can be trained end-to-end.\nExtensive experiments demonstrate that our framework significantly outperforms\nstate-of-the-art methods on various datasets.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}