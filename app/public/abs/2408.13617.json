{"id":"2408.13617","title":"SiTe CiM: Signed Ternary Computing-in-Memory for Ultra-Low Precision\n  Deep Neural Networks","authors":"Niharika Thakuria, Akul Malhotra, Sandeep K. Thirumala, Reena\n  Elangovan, Anand Raghunathan and Sumeet K. Gupta","authorsParsed":[["Thakuria","Niharika",""],["Malhotra","Akul",""],["Thirumala","Sandeep K.",""],["Elangovan","Reena",""],["Raghunathan","Anand",""],["Gupta","Sumeet K.",""]],"versions":[{"version":"v1","created":"Sat, 24 Aug 2024 16:10:33 GMT"}],"updateDate":"2024-08-27","timestamp":1724515833000,"abstract":"  Ternary Deep Neural Networks (DNN) have shown a large potential for highly\nenergy-constrained systems by virtue of their low power operation (due to\nultra-low precision) with only a mild degradation in accuracy. To enable an\nenergy-efficient hardware substrate for such systems, we propose a\ncompute-enabled memory design, referred to as SiTe-CiM, which features\ncomputing-in-memory (CiM) of dot products between signed ternary (SiTe) inputs\nand weights. SiTe CiM is based on cross-coupling of two bit cells to enable CiM\nof dot products in the signed ternary regime. We explore SiTe CiM with 8T-SRAM,\n3T-embedded DRAM (3T-eDRAM) and 3T-ferroelectric metal FET (FEMFET) memories.\nWe propose two flavors of this technique, namely SiTe CiM I/II. In SiTe CiM I,\nwe employ two additional transistors per cell for cross-coupling, achieving\nfast CiM operations, albeit incurring an area overhead ranging from 18% to 34%\n(compared to standard ternary memories). In SiTe CiM II, four extra transistors\nare utilized for every 16 cells in a column, thereby incurring only 6% area\ncost (but leading to slower CiM than SiTe CiM I). Based on the array analysis,\nour designs achieve up to 88% lower CiM latency and 78% CiM energy savings\nacross various technologies considered, as compared to their respective\nnear-memory computing counterparts. Further, we perform system level analysis\nby incorporating SiTe CiM I/II arrays in a ternary DNN accelerator and show up\nto 7X throughput boost and up to 2.5X energy reduction compared to the\nnear-memory ternary DNN accelerators.\n","subjects":["Computing Research Repository/Hardware Architecture"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"SRAtFevctZ5i4z0JSow_8HoJ7LNh-Lw7QDzvu-ZxP70","pdfSize":"4309690"}
