{"id":"2407.02458","title":"Statistical Advantages of Oblique Randomized Decision Trees and Forests","authors":"Eliza O'Reilly","authorsParsed":[["O'Reilly","Eliza",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 17:35:22 GMT"}],"updateDate":"2024-07-03","timestamp":1719941722000,"abstract":"  This work studies the statistical advantages of using features comprised of\ngeneral linear combinations of covariates to partition the data in randomized\ndecision tree and forest regression algorithms. Using random tessellation\ntheory in stochastic geometry, we provide a theoretical analysis of a class of\nefficiently generated random tree and forest estimators that allow for oblique\nsplits along such features. We call these estimators oblique Mondrian trees and\nforests, as the trees are generated by first selecting a set of features from\nlinear combinations of the covariates and then running a Mondrian process that\nhierarchically partitions the data along these features. Generalization error\nbounds and convergence rates are obtained for the flexible dimension reduction\nmodel class of ridge functions (also known as multi-index models), where the\noutput is assumed to depend on a low dimensional relevant feature subspace of\nthe input domain. The results highlight how the risk of these estimators\ndepends on the choice of features and quantify how robust the risk is with\nrespect to error in the estimation of relevant features. The asymptotic\nanalysis also provides conditions on the selected features along which the data\nis split for these estimators to obtain minimax optimal rates of convergence\nwith respect to the dimension of the relevant feature subspace. Additionally, a\nlower bound on the risk of axis-aligned Mondrian trees (where features are\nrestricted to the set of covariates) is obtained proving that these estimators\nare suboptimal for these linear dimension reduction models in general, no\nmatter how the distribution over the covariates used to divide the data at each\ntree node is weighted.\n","subjects":["Mathematics/Statistics Theory","Statistics/Machine Learning","Statistics/Statistics Theory"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}