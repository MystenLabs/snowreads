{"id":"2408.14397","title":"Uncovering Knowledge Gaps in Radiology Report Generation Models through\n  Knowledge Graphs","authors":"Xiaoman Zhang, Juli\\'an N. Acosta, Hong-Yu Zhou, Pranav Rajpurkar","authorsParsed":[["Zhang","Xiaoman",""],["Acosta","Juli√°n N.",""],["Zhou","Hong-Yu",""],["Rajpurkar","Pranav",""]],"versions":[{"version":"v1","created":"Mon, 26 Aug 2024 16:28:56 GMT"}],"updateDate":"2024-08-27","timestamp":1724689736000,"abstract":"  Recent advancements in artificial intelligence have significantly improved\nthe automatic generation of radiology reports. However, existing evaluation\nmethods fail to reveal the models' understanding of radiological images and\ntheir capacity to achieve human-level granularity in descriptions. To bridge\nthis gap, we introduce a system, named ReXKG, which extracts structured\ninformation from processed reports to construct a comprehensive radiology\nknowledge graph. We then propose three metrics to evaluate the similarity of\nnodes (ReXKG-NSC), distribution of edges (ReXKG-AMS), and coverage of subgraphs\n(ReXKG-SCS) across various knowledge graphs. We conduct an in-depth comparative\nanalysis of AI-generated and human-written radiology reports, assessing the\nperformance of both specialist and generalist models. Our study provides a\ndeeper understanding of the capabilities and limitations of current AI models\nin radiology report generation, offering valuable insights for improving model\nperformance and clinical applicability.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"yPM9gu2MxyM4ehAT0rPOBvPxx9Z0tfLLOpR488RpszE","pdfSize":"1897874"}
