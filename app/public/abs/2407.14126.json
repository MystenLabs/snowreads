{"id":"2407.14126","title":"Mono-ViFI: A Unified Learning Framework for Self-supervised Single- and\n  Multi-frame Monocular Depth Estimation","authors":"Jinfeng Liu and Lingtong Kong and Bo Li and Zerong Wang and Hong Gu\n  and Jinwei Chen","authorsParsed":[["Liu","Jinfeng",""],["Kong","Lingtong",""],["Li","Bo",""],["Wang","Zerong",""],["Gu","Hong",""],["Chen","Jinwei",""]],"versions":[{"version":"v1","created":"Fri, 19 Jul 2024 08:51:51 GMT"}],"updateDate":"2024-07-22","timestamp":1721379111000,"abstract":"  Self-supervised monocular depth estimation has gathered notable interest\nsince it can liberate training from dependency on depth annotations. In\nmonocular video training case, recent methods only conduct view synthesis\nbetween existing camera views, leading to insufficient guidance. To tackle\nthis, we try to synthesize more virtual camera views by flow-based video frame\ninterpolation (VFI), termed as temporal augmentation. For multi-frame\ninference, to sidestep the problem of dynamic objects encountered by explicit\ngeometry-based methods like ManyDepth, we return to the feature fusion paradigm\nand design a VFI-assisted multi-frame fusion module to align and aggregate\nmulti-frame features, using motion and occlusion information obtained by the\nflow-based VFI model. Finally, we construct a unified self-supervised learning\nframework, named Mono-ViFI, to bilaterally connect single- and multi-frame\ndepth. In this framework, spatial data augmentation through image affine\ntransformation is incorporated for data diversity, along with a triplet depth\nconsistency loss for regularization. The single- and multi-frame models can\nshare weights, making our framework compact and memory-efficient. Extensive\nexperiments demonstrate that our method can bring significant improvements to\ncurrent advanced architectures. Source code is available at\nhttps://github.com/LiuJF1226/Mono-ViFI.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}