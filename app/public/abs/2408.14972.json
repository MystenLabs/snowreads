{"id":"2408.14972","title":"AgentMonitor: A Plug-and-Play Framework for Predictive and Secure\n  Multi-Agent Systems","authors":"Chi-Min Chan, Jianxuan Yu, Weize Chen, Chunyang Jiang, Xinyu Liu,\n  Weijie Shi, Zhiyuan Liu, Wei Xue, Yike Guo","authorsParsed":[["Chan","Chi-Min",""],["Yu","Jianxuan",""],["Chen","Weize",""],["Jiang","Chunyang",""],["Liu","Xinyu",""],["Shi","Weijie",""],["Liu","Zhiyuan",""],["Xue","Wei",""],["Guo","Yike",""]],"versions":[{"version":"v1","created":"Tue, 27 Aug 2024 11:24:38 GMT"}],"updateDate":"2024-08-28","timestamp":1724757878000,"abstract":"  The rapid advancement of large language models (LLMs) has led to the rise of\nLLM-based agents. Recent research shows that multi-agent systems (MAS), where\neach agent plays a specific role, can outperform individual LLMs. However,\nconfiguring an MAS for a task remains challenging, with performance only\nobservable post-execution. Inspired by scaling laws in LLM development, we\ninvestigate whether MAS performance can be predicted beforehand. We introduce\nAgentMonitor, a framework that integrates at the agent level to capture inputs\nand outputs, transforming them into statistics for training a regression model\nto predict task performance. Additionally, it can further apply real-time\ncorrections to address security risks posed by malicious agents, mitigating\nnegative impacts and enhancing MAS security. Experiments demonstrate that an\nXGBoost model achieves a Spearman correlation of 0.89 in-domain and 0.58 in\nmore challenging scenarios. Furthermore, using AgentMonitor reduces harmful\ncontent by 6.2% and increases helpful content by 1.8% on average, enhancing\nsafety and reliability. Code is available at\n\\url{https://github.com/chanchimin/AgentMonitor}.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}