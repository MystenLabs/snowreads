{"id":"2407.06025","title":"iLLM-TSC: Integration reinforcement learning and large language model\n  for traffic signal control policy improvement","authors":"Aoyu Pang, Maonan Wang, Man-On Pun, Chung Shue Chen and Xi Xiong","authorsParsed":[["Pang","Aoyu",""],["Wang","Maonan",""],["Pun","Man-On",""],["Chen","Chung Shue",""],["Xiong","Xi",""]],"versions":[{"version":"v1","created":"Mon, 8 Jul 2024 15:22:49 GMT"}],"updateDate":"2024-07-09","timestamp":1720452169000,"abstract":"  Urban congestion remains a critical challenge, with traffic signal control\n(TSC) emerging as a potent solution. TSC is often modeled as a Markov Decision\nProcess problem and then solved using reinforcement learning (RL), which has\nproven effective. However, the existing RL-based TSC system often overlooks\nimperfect observations caused by degraded communication, such as packet loss,\ndelays, and noise, as well as rare real-life events not included in the reward\nfunction, such as unconsidered emergency vehicles. To address these\nlimitations, we introduce a novel integration framework that combines a large\nlanguage model (LLM) with RL. This framework is designed to manage overlooked\nelements in the reward function and gaps in state information, thereby\nenhancing the policies of RL agents. In our approach, RL initially makes\ndecisions based on observed data. Subsequently, LLMs evaluate these decisions\nto verify their reasonableness. If a decision is found to be unreasonable, it\nis adjusted accordingly. Additionally, this integration approach can be\nseamlessly integrated with existing RL-based TSC systems without necessitating\nmodifications. Extensive testing confirms that our approach reduces the average\nwaiting time by $17.5\\%$ in degraded communication conditions as compared to\ntraditional RL methods, underscoring its potential to advance practical RL\napplications in intelligent transportation systems. The related code can be\nfound at \\url{https://github.com/Traffic-Alpha/iLLM-TSC}.\n","subjects":["Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}