{"id":"2407.07402","title":"ActionVOS: Actions as Prompts for Video Object Segmentation","authors":"Liangyang Ouyang, Ruicong Liu, Yifei Huang, Ryosuke Furuta, Yoichi\n  Sato","authorsParsed":[["Ouyang","Liangyang",""],["Liu","Ruicong",""],["Huang","Yifei",""],["Furuta","Ryosuke",""],["Sato","Yoichi",""]],"versions":[{"version":"v1","created":"Wed, 10 Jul 2024 06:57:04 GMT"}],"updateDate":"2024-07-11","timestamp":1720594624000,"abstract":"  Delving into the realm of egocentric vision, the advancement of referring\nvideo object segmentation (RVOS) stands as pivotal in understanding human\nactivities. However, existing RVOS task primarily relies on static attributes\nsuch as object names to segment target objects, posing challenges in\ndistinguishing target objects from background objects and in identifying\nobjects undergoing state changes. To address these problems, this work proposes\na novel action-aware RVOS setting called ActionVOS, aiming at segmenting only\nactive objects in egocentric videos using human actions as a key language\nprompt. This is because human actions precisely describe the behavior of\nhumans, thereby helping to identify the objects truly involved in the\ninteraction and to understand possible state changes. We also build a method\ntailored to work under this specific setting. Specifically, we develop an\naction-aware labeling module with an efficient action-guided focal loss. Such\ndesigns enable ActionVOS model to prioritize active objects with existing\nreadily-available annotations. Experimental results on VISOR dataset reveal\nthat ActionVOS significantly reduces the mis-segmentation of inactive objects,\nconfirming that actions help the ActionVOS model understand objects'\ninvolvement. Further evaluations on VOST and VSCOS datasets show that the novel\nActionVOS setting enhances segmentation performance when encountering\nchallenging circumstances involving object state changes. We will make our\nimplementation available at https://github.com/ut-vision/ActionVOS.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}