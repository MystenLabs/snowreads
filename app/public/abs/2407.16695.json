{"id":"2407.16695","title":"Stress-Testing Long-Context Language Models with Lifelong ICL and Task\n  Haystack","authors":"Xiaoyue Xu, Qinyuan Ye, Xiang Ren","authorsParsed":[["Xu","Xiaoyue",""],["Ye","Qinyuan",""],["Ren","Xiang",""]],"versions":[{"version":"v1","created":"Tue, 23 Jul 2024 17:57:41 GMT"}],"updateDate":"2024-07-24","timestamp":1721757461000,"abstract":"  We introduce Lifelong ICL, a problem setting that challenges long-context\nlanguage models (LMs) to learn from a sequence of language tasks through\nin-context learning (ICL). We further introduce Task Haystack, an evaluation\nsuite dedicated to assessing and diagnosing how long-context LMs utilizes\ncontexts in Lifelong ICL. When given a task instruction and test inputs,\nlong-context LMs are expected to leverage the relevant demonstrations in the\nLifelong ICL prompt, avoid distraction and interference from other tasks, and\nachieve test accuracies that are not significantly worse than the Single-task\nICL baseline.\n  Task Haystack draws inspiration from the widely-adopted\n\"needle-in-a-haystack\" (NIAH) evaluation, but presents new and unique\nchallenges. It demands that models (1) utilize the contexts with deeper\nunderstanding, rather than resorting to simple copying and pasting; (2)\nnavigate through long streams of evolving topics and tasks, which closely\napproximates the complexities of real-world usage of long-context LMs.\nAdditionally, Task Haystack inherits the controllability aspect of NIAH,\nproviding model developers with tools and visualizations to identify model\nvulnerabilities effectively.\n  We benchmark 12 long-context LMs using Task Haystack. We find that\nstate-of-the-art closed models such as GPT-4o still struggle in this setting,\nfailing 15% of the cases on average, while all open-weight models we evaluate\nfurther lack behind by a large margin, failing up to 61% of the cases. In our\ncontrolled analysis, we identify factors such as distraction and recency bias\nas contributors to these failure cases. Further, we observe declines in\nperformance when task instructions are paraphrased at test time or when ICL\ndemonstrations are repeated excessively, raising concerns about the robustness,\ninstruction understanding, and true context utilization of current long-context\nLMs.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"Ymy2v-w2mxvxL1yVG1nYo7axjvHBsmPLTEvaG0ehhAk","pdfSize":"1306355"}
