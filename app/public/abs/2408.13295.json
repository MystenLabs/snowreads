{"id":"2408.13295","title":"Exploring Bias and Prediction Metrics to Characterise the Fairness of\n  Machine Learning for Equity-Centered Public Health Decision-Making: A\n  Narrative Review","authors":"Shaina Raza, Arash Shaban-Nejad, Elham Dolatabadi, Hiroshi Mamiya","authorsParsed":[["Raza","Shaina",""],["Shaban-Nejad","Arash",""],["Dolatabadi","Elham",""],["Mamiya","Hiroshi",""]],"versions":[{"version":"v1","created":"Fri, 23 Aug 2024 14:47:10 GMT"},{"version":"v2","created":"Mon, 2 Sep 2024 17:00:05 GMT"}],"updateDate":"2024-09-04","timestamp":1724424430000,"abstract":"  Background: The rapid advancement of Machine Learning (ML) represents novel\nopportunities to enhance public health research, surveillance, and\ndecision-making. However, there is a lack of comprehensive understanding of\nalgorithmic bias, systematic errors in predicted population health outcomes,\nresulting from the public health application of ML. The objective of this\nnarrative review is to explore the types of bias generated by ML and\nquantitative metrics to assess these biases.\n  Methods : We performed search on PubMed, MEDLINE, IEEE (Institute of\nElectrical and Electronics Engineers), ACM (Association for Computing\nMachinery) Digital Library, Science Direct, and Springer Nature. We used\nkeywords to identify studies describing types of bias and metrics to measure\nthese in the domain of ML and public and population health published in English\nbetween 2008 and 2023, inclusive.\n  Results: A total of 72 articles met the inclusion criteria. Our review\nidentified the commonly described types of bias and quantitative metrics to\nassess these biases from an equity perspective.\n  Conclusion : The review will help formalize the evaluation framework for ML\non public health from an equity perspective.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/"}