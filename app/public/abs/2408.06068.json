{"id":"2408.06068","title":"Online Optimization of Curriculum Learning Schedules using Evolutionary\n  Optimization","authors":"Mohit Jiwatode, Leon Schlecht, Alexander Dockhorn","authorsParsed":[["Jiwatode","Mohit",""],["Schlecht","Leon",""],["Dockhorn","Alexander",""]],"versions":[{"version":"v1","created":"Mon, 12 Aug 2024 11:39:50 GMT"}],"updateDate":"2024-08-13","timestamp":1723462790000,"abstract":"  We propose RHEA CL, which combines Curriculum Learning (CL) with Rolling\nHorizon Evolutionary Algorithms (RHEA) to automatically produce effective\ncurricula during the training of a reinforcement learning agent. RHEA CL\noptimizes a population of curricula, using an evolutionary algorithm, and\nselects the best-performing curriculum as the starting point for the next\ntraining epoch. Performance evaluations are conducted after every curriculum\nstep in all environments. We evaluate the algorithm on the \\textit{DoorKey} and\n\\textit{DynamicObstacles} environments within the Minigrid framework. It\ndemonstrates adaptability and consistent improvement, particularly in the early\nstages, while reaching a stable performance later that is capable of\noutperforming other curriculum learners. In comparison to other curriculum\nschedules, RHEA CL has been shown to yield performance improvements for the\nfinal Reinforcement learning (RL) agent at the cost of additional evaluation\nduring training.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Neural and Evolutionary Computing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}