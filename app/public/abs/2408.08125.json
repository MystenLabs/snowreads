{"id":"2408.08125","title":"Category-Prompt Refined Feature Learning for Long-Tailed Multi-Label\n  Image Classification","authors":"Jiexuan Yan and Sheng Huang and Nankun Mu and Luwen Huangfu and Bo Liu","authorsParsed":[["Yan","Jiexuan",""],["Huang","Sheng",""],["Mu","Nankun",""],["Huangfu","Luwen",""],["Liu","Bo",""]],"versions":[{"version":"v1","created":"Thu, 15 Aug 2024 12:51:57 GMT"}],"updateDate":"2024-08-16","timestamp":1723726317000,"abstract":"  Real-world data consistently exhibits a long-tailed distribution, often\nspanning multiple categories. This complexity underscores the challenge of\ncontent comprehension, particularly in scenarios requiring Long-Tailed\nMulti-Label image Classification (LTMLC). In such contexts, imbalanced data\ndistribution and multi-object recognition pose significant hurdles. To address\nthis issue, we propose a novel and effective approach for LTMLC, termed\nCategory-Prompt Refined Feature Learning (CPRFL), utilizing semantic\ncorrelations between different categories and decoupling category-specific\nvisual representations for each category. Specifically, CPRFL initializes\ncategory-prompts from the pretrained CLIP's embeddings and decouples\ncategory-specific visual representations through interaction with visual\nfeatures, thereby facilitating the establishment of semantic correlations\nbetween the head and tail classes. To mitigate the visual-semantic domain bias,\nwe design a progressive Dual-Path Back-Propagation mechanism to refine the\nprompts by progressively incorporating context-related visual information into\nprompts. Simultaneously, the refinement process facilitates the progressive\npurification of the category-specific visual representations under the guidance\nof the refined prompts. Furthermore, taking into account the negative-positive\nsample imbalance, we adopt the Asymmetric Loss as our optimization objective to\nsuppress negative samples across all classes and potentially enhance the\nhead-to-tail recognition performance. We validate the effectiveness of our\nmethod on two LTMLC benchmarks and extensive experiments demonstrate the\nsuperiority of our work over baselines.\n  The code is available at https://github.com/jiexuanyan/CPRFL.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/"}