{"id":"2407.17927","title":"Invariance of deep image quality metrics to affine transformations","authors":"Nuria Alabau-Bosque and Paula Daud\\'en-Oliver and Jorge Vila-Tom\\'as\n  and Valero Laparra and Jes\\'us Malo","authorsParsed":[["Alabau-Bosque","Nuria",""],["Daudén-Oliver","Paula",""],["Vila-Tomás","Jorge",""],["Laparra","Valero",""],["Malo","Jesús",""]],"versions":[{"version":"v1","created":"Thu, 25 Jul 2024 10:24:54 GMT"},{"version":"v2","created":"Mon, 29 Jul 2024 11:55:53 GMT"}],"updateDate":"2024-07-30","timestamp":1721903094000,"abstract":"  Deep architectures are the current state-of-the-art in predicting subjective\nimage quality. Usually, these models are evaluated according to their ability\nto correlate with human opinion in databases with a range of distortions that\nmay appear in digital media. However, these oversee affine transformations\nwhich may represent better the changes in the images actually happening in\nnatural conditions. Humans can be particularly invariant to these natural\ntransformations, as opposed to the digital ones. In this work, we evaluate\nstate-of-the-art deep image quality metrics by assessing their invariance to\naffine transformations, specifically: rotation, translation, scaling, and\nchanges in spectral illumination. Here invariance of a metric refers to the\nfact that certain distances should be neglected (considered to be zero) if\ntheir values are below a threshold. This is what we call invisibility threshold\nof a metric. We propose a methodology to assign such invisibility thresholds\nfor any perceptual metric. This methodology involves transformations to a\ndistance space common to any metric, and psychophysical measurements of\nthresholds in this common space. By doing so, we allow the analyzed metrics to\nbe directly comparable with actual human thresholds. We find that none of the\nstate-of-the-art metrics shows human-like results under this strong test based\non invisibility thresholds. This means that tuning the models exclusively to\npredict the visibility of generic distortions may disregard other properties of\nhuman vision as for instance invariances or invisibility thresholds.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/"}