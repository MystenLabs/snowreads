{"id":"2407.13141","title":"Out-of-Distribution Detection through Soft Clustering with Non-Negative\n  Kernel Regression","authors":"Aryan Gulati, Xingjian Dong, Carlos Hurtado, Sarath Shekkizhar, Swabha\n  Swayamdipta, Antonio Ortega","authorsParsed":[["Gulati","Aryan",""],["Dong","Xingjian",""],["Hurtado","Carlos",""],["Shekkizhar","Sarath",""],["Swayamdipta","Swabha",""],["Ortega","Antonio",""]],"versions":[{"version":"v1","created":"Thu, 18 Jul 2024 03:57:08 GMT"}],"updateDate":"2024-07-19","timestamp":1721275028000,"abstract":"  As language models become more general purpose, increased attention needs to\nbe paid to detecting out-of-distribution (OOD) instances, i.e., those not\nbelonging to any of the distributions seen during training. Existing methods\nfor detecting OOD data are computationally complex and storage-intensive. We\npropose a novel soft clustering approach for OOD detection based on\nnon-negative kernel regression. Our approach greatly reduces computational and\nspace complexities (up to 11x improvement in inference time and 87% reduction\nin storage requirements) and outperforms existing approaches by up to 4 AUROC\npoints on four different benchmarks. We also introduce an entropy-constrained\nversion of our algorithm, which leads to further reductions in storage\nrequirements (up to 97% lower than comparable approaches) while retaining\ncompetitive performance. Our soft clustering approach for OOD detection\nhighlights its potential for detecting tail-end phenomena in extreme-scale data\nsettings.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}