{"id":"2408.05326","title":"A Psychology-based Unified Dynamic Framework for Curriculum Learning","authors":"Guangyu Meng, Qingkai Zeng, John P. Lalor, Hong Yu","authorsParsed":[["Meng","Guangyu",""],["Zeng","Qingkai",""],["Lalor","John P.",""],["Yu","Hong",""]],"versions":[{"version":"v1","created":"Fri, 9 Aug 2024 20:30:37 GMT"}],"updateDate":"2024-08-13","timestamp":1723235437000,"abstract":"  Directly learning from examples of random difficulty levels is often\nchallenging for both humans and machine learning models. A more effective\nstrategy involves exposing learners to examples in a progressive order, from\neasy to difficult. Curriculum Learning (CL) has been proposed to implement this\nstrategy in machine learning model training. However, two key challenges\npersist in CL framework design: defining the difficulty of training data and\ndetermining the appropriate amount of data to input at each training step. This\npaper presents a Psychology-based Unified Dynamic Framework for Curriculum\nLearning (PUDF), drawing inspiration from psychometrics. We quantify the\ndifficulty of training data by applying Item Response Theory (IRT) to responses\nfrom Artificial Crowds (AC). This theory-driven IRT-AC approach leads to global\n(i.e., model-independent) and interpretable difficulty values. Leveraging IRT,\nwe propose a Dynamic Data Selection via Model Ability Estimation (DDS-MAE)\nstrategy to schedule the appropriate amount of data during model training.\nSince our difficulty labeling and model ability estimation are based on a\nconsistent theory, namely IRT, their values are comparable within the same\nscope, potentially leading to a faster convergence compared to the other CL\nmethods. Experimental results demonstrate that fine-tuning pre-trained language\nmodels with PUDF enhances their performance on the GLUE benchmark. Moreover,\nPUDF surpasses other state-of-the-art (SOTA) CL methods on the GLUE benchmark.\nWe further explore the components of PUDF, namely the difficulty measurer\n(IRT-AC) and the training scheduler (DDS-MAE) qualitatively and quantitatively.\nLastly, we conduct an ablation study to clarify which components of PUDF\ncontribute to faster convergence and higher accuracy.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/"}