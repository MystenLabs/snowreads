{"id":"2408.07966","title":"Addressing Skewed Heterogeneity via Federated Prototype Rectification\n  with Personalization","authors":"Shunxin Guo, Hongsong Wang, Shuxia Lin, Zhiqiang Kou, Xin Geng","authorsParsed":[["Guo","Shunxin",""],["Wang","Hongsong",""],["Lin","Shuxia",""],["Kou","Zhiqiang",""],["Geng","Xin",""]],"versions":[{"version":"v1","created":"Thu, 15 Aug 2024 06:26:46 GMT"},{"version":"v2","created":"Fri, 23 Aug 2024 02:03:54 GMT"}],"updateDate":"2024-08-26","timestamp":1723703206000,"abstract":"  Federated learning is an efficient framework designed to facilitate\ncollaborative model training across multiple distributed devices while\npreserving user data privacy. A significant challenge of federated learning is\ndata-level heterogeneity, i.e., skewed or long-tailed distribution of private\ndata. Although various methods have been proposed to address this challenge,\nmost of them assume that the underlying global data is uniformly distributed\nacross all clients. This paper investigates data-level heterogeneity federated\nlearning with a brief review and redefines a more practical and challenging\nsetting called Skewed Heterogeneous Federated Learning (SHFL). Accordingly, we\npropose a novel Federated Prototype Rectification with Personalization which\nconsists of two parts: Federated Personalization and Federated Prototype\nRectification. The former aims to construct balanced decision boundaries\nbetween dominant and minority classes based on private data, while the latter\nexploits both inter-class discrimination and intra-class consistency to rectify\nempirical prototypes. Experiments on three popular benchmarks show that the\nproposed approach outperforms current state-of-the-art methods and achieves\nbalanced performance in both personalization and generalization.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Distributed, Parallel, and Cluster Computing"],"license":"http://creativecommons.org/licenses/by/4.0/"}