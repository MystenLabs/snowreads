{"id":"2407.09064","title":"Multi-Modal Dataset Creation for Federated Learning with DICOM\n  Structured Reports","authors":"Malte T\\\"olle, Lukas Burger, Halvar Kelm, Florian Andr\\'e, Peter\n  Bannas, Gerhard Diller, Norbert Frey, Philipp Garthe, Stefan Gro{\\ss}, Anja\n  Hennemuth, Lars Kaderali, Nina Kr\\\"uger, Andreas Leha, Simon Martin,\n  Alexander Meyer, Eike Nagel, Stefan Orwat, Clemens Scherer, Moritz Seiffert,\n  Jan Moritz Seliger, Stefan Simm, Tim Friede, Tim Seidler, Sandy Engelhardt","authorsParsed":[["Tölle","Malte",""],["Burger","Lukas",""],["Kelm","Halvar",""],["André","Florian",""],["Bannas","Peter",""],["Diller","Gerhard",""],["Frey","Norbert",""],["Garthe","Philipp",""],["Groß","Stefan",""],["Hennemuth","Anja",""],["Kaderali","Lars",""],["Krüger","Nina",""],["Leha","Andreas",""],["Martin","Simon",""],["Meyer","Alexander",""],["Nagel","Eike",""],["Orwat","Stefan",""],["Scherer","Clemens",""],["Seiffert","Moritz",""],["Seliger","Jan Moritz",""],["Simm","Stefan",""],["Friede","Tim",""],["Seidler","Tim",""],["Engelhardt","Sandy",""]],"versions":[{"version":"v1","created":"Fri, 12 Jul 2024 07:34:10 GMT"},{"version":"v2","created":"Tue, 6 Aug 2024 11:43:53 GMT"}],"updateDate":"2024-08-07","timestamp":1720769650000,"abstract":"  Purpose: Federated training is often hindered by heterogeneous datasets due\nto divergent data storage options, inconsistent naming schemes, varied\nannotation procedures, and disparities in label quality. This is particularly\nevident in the emerging multi-modal learning paradigms, where dataset\nharmonization including a uniform data representation and filtering options are\nof paramount importance.\n  Methods: DICOM structured reports enable the standardized linkage of\narbitrary information beyond the imaging domain and can be used within Python\ndeep learning pipelines with highdicom. Building on this, we developed an open\nplatform for data integration and interactive filtering capabilities that\nsimplifies the process of assembling multi-modal datasets.\n  Results: In this study, we extend our prior work by showing its applicability\nto more and divergent data types, as well as streamlining datasets for\nfederated training within an established consortium of eight university\nhospitals in Germany. We prove its concurrent filtering ability by creating\nharmonized multi-modal datasets across all locations for predicting the outcome\nafter minimally invasive heart valve replacement. The data includes DICOM data\n(i.e. computed tomography images, electrocardiography scans) as well as\nannotations (i.e. calcification segmentations, pointsets and pacemaker\ndependency), and metadata (i.e. prosthesis and diagnoses).\n  Conclusion: Structured reports bridge the traditional gap between imaging\nsystems and information systems. Utilizing the inherent DICOM reference system\narbitrary data types can be queried concurrently to create meaningful cohorts\nfor clinical studies. The graphical interface as well as example structured\nreport templates will be made publicly available.\n","subjects":["Computing Research Repository/Information Retrieval","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"hwQTo4OeQ3x97YDBoiF3Wf4snRJFDlVvieR_uMagKPY","pdfSize":"3761915"}
