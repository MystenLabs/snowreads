{"id":"2408.13147","title":"ShapeICP: Iterative Category-level Object Pose and Shape Estimation from\n  Depth","authors":"Yihao Zhang and John J. Leonard","authorsParsed":[["Zhang","Yihao",""],["Leonard","John J.",""]],"versions":[{"version":"v1","created":"Fri, 23 Aug 2024 15:12:55 GMT"}],"updateDate":"2024-08-26","timestamp":1724425975000,"abstract":"  Category-level object pose and shape estimation from a single depth image has\nrecently drawn research attention due to its wide applications in robotics and\nself-driving. The task is particularly challenging because the three unknowns,\nobject pose, object shape, and model-to-measurement correspondences, are\ncompounded together but only a single view of depth measurements is provided.\nThe vast majority of the prior work heavily relies on data-driven approaches to\nobtain solutions to at least one of the unknowns and typically two, running\nwith the risk of failing to generalize to unseen domains. The shape\nrepresentations used in the prior work also mainly focus on point cloud and\nsigned distance field (SDF). In stark contrast to the prior work, we approach\nthe problem using an iterative estimation method that does not require learning\nfrom any pose-annotated data. In addition, we adopt a novel mesh-based object\nactive shape model that has not been explored by the previous literature. Our\nalgorithm, named ShapeICP, has its foundation in the iterative closest point\n(ICP) algorithm but is equipped with additional features for the category-level\npose and shape estimation task. The results show that even without using any\npose-annotated data, ShapeICP surpasses many data-driven approaches that rely\non the pose data for training, opening up new solution space for researchers to\nconsider.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Robotics"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}