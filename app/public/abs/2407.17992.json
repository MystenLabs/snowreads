{"id":"2407.17992","title":"Amortized Active Learning for Nonparametric Functions","authors":"Cen-You Li, Marc Toussaint, Barbara Rakitsch, Christoph Zimmer","authorsParsed":[["Li","Cen-You",""],["Toussaint","Marc",""],["Rakitsch","Barbara",""],["Zimmer","Christoph",""]],"versions":[{"version":"v1","created":"Thu, 25 Jul 2024 12:38:08 GMT"},{"version":"v2","created":"Tue, 10 Sep 2024 21:51:23 GMT"}],"updateDate":"2024-09-12","timestamp":1721911088000,"abstract":"  Active learning (AL) is a sequential learning scheme aiming to select the\nmost informative data. AL reduces data consumption and avoids the cost of\nlabeling large amounts of data. However, AL trains the model and solves an\nacquisition optimization for each selection. It becomes expensive when the\nmodel training or acquisition optimization is challenging. In this paper, we\nfocus on active nonparametric function learning, where the gold standard\nGaussian process (GP) approaches suffer from cubic time complexity. We propose\nan amortized AL method, where new data are suggested by a neural network which\nis trained up-front without any real data (Figure 1). Our method avoids\nrepeated model training and requires no acquisition optimization during the AL\ndeployment. We (i) utilize GPs as function priors to construct an AL simulator,\n(ii) train an AL policy that can zero-shot generalize from simulation to real\nlearning problems of nonparametric functions and (iii) achieve real-time data\nselection and comparable learning performances to time-consuming baseline\nmethods.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}