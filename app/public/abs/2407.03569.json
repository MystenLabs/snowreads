{"id":"2407.03569","title":"Safety-Critical Control with Uncertainty Quantification using Adaptive\n  Conformal Prediction","authors":"Hao Zhou, Yanze Zhang, Wenhao Luo","authorsParsed":[["Zhou","Hao",""],["Zhang","Yanze",""],["Luo","Wenhao",""]],"versions":[{"version":"v1","created":"Thu, 4 Jul 2024 01:44:06 GMT"},{"version":"v2","created":"Mon, 8 Jul 2024 16:35:45 GMT"}],"updateDate":"2024-07-09","timestamp":1720057446000,"abstract":"  Safety assurance is critical in the planning and control of robotic systems.\nFor robots operating in the real world, the safety-critical design often needs\nto explicitly address uncertainties and the pre-computed guarantees often rely\non the assumption of the particular distribution of the uncertainty. However,\nit is difficult to characterize the actual uncertainty distribution beforehand\nand thus the established safety guarantee may be violated due to possible\ndistribution mismatch. In this paper, we propose a novel safe control framework\nthat provides a high-probability safety guarantee for stochastic dynamical\nsystems following unknown distributions of motion noise. Specifically, this\nframework adopts adaptive conformal prediction to dynamically quantify the\nprediction uncertainty from online observations and combines that with the\nprobabilistic extension of the control barrier functions (CBFs) to characterize\nthe uncertainty-aware control constraints. By integrating the constraints in\nthe model predictive control scheme, it allows robots to adaptively capture the\ntrue prediction uncertainty online in a distribution-free setting and enjoys\nformally provable high-probability safety assurance. Simulation results on\nmulti-robot systems with stochastic single-integrator dynamics and unicycle\ndynamics are provided to demonstrate the effectiveness of our framework.\n","subjects":["Computing Research Repository/Robotics"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}