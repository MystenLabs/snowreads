{"id":"2407.08914","title":"Multi-objective Aerial Collaborative Secure Communication Optimization\n  via Generative Diffusion Model-enabled Deep Reinforcement Learning","authors":"Chuang Zhang, Geng Sun, Jiahui Li, Qingqing Wu, Jiacheng Wang, Dusit\n  Niyato and Yuanwei Liu","authorsParsed":[["Zhang","Chuang",""],["Sun","Geng",""],["Li","Jiahui",""],["Wu","Qingqing",""],["Wang","Jiacheng",""],["Niyato","Dusit",""],["Liu","Yuanwei",""]],"versions":[{"version":"v1","created":"Fri, 12 Jul 2024 01:11:02 GMT"}],"updateDate":"2024-07-15","timestamp":1720746662000,"abstract":"  Due to flexibility and low-cost, unmanned aerial vehicles (UAVs) are\nincreasingly crucial for enhancing coverage and functionality of wireless\nnetworks. However, incorporating UAVs into next-generation wireless\ncommunication systems poses significant challenges, particularly in sustaining\nhigh-rate and long-range secure communications against eavesdropping attacks.\nIn this work, we consider a UAV swarm-enabled secure surveillance network\nsystem, where a UAV swarm forms a virtual antenna array to transmit sensitive\nsurveillance data to a remote base station (RBS) via collaborative beamforming\n(CB) so as to resist mobile eavesdroppers. Specifically, we formulate an aerial\nsecure communication and energy efficiency multi-objective optimization problem\n(ASCEE-MOP) to maximize the secrecy rate of the system and to minimize the\nflight energy consumption of the UAV swarm. To address the non-convex, NP-hard\nand dynamic ASCEE-MOP, we propose a generative diffusion model-enabled twin\ndelayed deep deterministic policy gradient (GDMTD3) method. Specifically,\nGDMTD3 leverages an innovative application of diffusion models to determine\noptimal excitation current weights and position decisions of UAVs. The\ndiffusion models can better capture the complex dynamics and the trade-off of\nthe ASCEE-MOP, thereby yielding promising solutions. Simulation results\nhighlight the superior performance of the proposed approach compared with\ntraditional deployment strategies and some other deep reinforcement learning\n(DRL) benchmarks. Moreover, performance analysis under various parameter\nsettings of GDMTD3 and different numbers of UAVs verifies the robustness of the\nproposed approach.\n","subjects":["Computing Research Repository/Networking and Internet Architecture","Electrical Engineering and Systems Science/Signal Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}