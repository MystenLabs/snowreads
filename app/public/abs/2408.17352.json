{"id":"2408.17352","title":"AASIST3: KAN-Enhanced AASIST Speech Deepfake Detection using SSL\n  Features and Additional Regularization for the ASVspoof 2024 Challenge","authors":"Kirill Borodin and Vasiliy Kudryavtsev and Dmitrii Korzh and Alexey\n  Efimenko and Grach Mkrtchian and Mikhail Gorodnichev and Oleg Y. Rogov","authorsParsed":[["Borodin","Kirill",""],["Kudryavtsev","Vasiliy",""],["Korzh","Dmitrii",""],["Efimenko","Alexey",""],["Mkrtchian","Grach",""],["Gorodnichev","Mikhail",""],["Rogov","Oleg Y.",""]],"versions":[{"version":"v1","created":"Fri, 30 Aug 2024 15:30:01 GMT"}],"updateDate":"2024-09-02","timestamp":1725031801000,"abstract":"  Automatic Speaker Verification (ASV) systems, which identify speakers based\non their voice characteristics, have numerous applications, such as user\nauthentication in financial transactions, exclusive access control in smart\ndevices, and forensic fraud detection. However, the advancement of deep\nlearning algorithms has enabled the generation of synthetic audio through\nText-to-Speech (TTS) and Voice Conversion (VC) systems, exposing ASV systems to\npotential vulnerabilities. To counteract this, we propose a novel architecture\nnamed AASIST3. By enhancing the existing AASIST framework with\nKolmogorov-Arnold networks, additional layers, encoders, and pre-emphasis\ntechniques, AASIST3 achieves a more than twofold improvement in performance. It\ndemonstrates minDCF results of 0.5357 in the closed condition and 0.1414 in the\nopen condition, significantly enhancing the detection of synthetic voices and\nimproving ASV security.\n","subjects":["Computing Research Repository/Sound","Computing Research Repository/Artificial Intelligence","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"6xuws99S8fg3pEl8IP3Zn0m73Xz7f1-m_rEKCSWm44s","pdfSize":"1532781"}
