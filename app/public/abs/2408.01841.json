{"id":"2408.01841","title":"BEVPlace++: Fast, Robust, and Lightweight LiDAR Global Localization for\n  Unmanned Ground Vehicles","authors":"Lun Luo, Si-Yuan Cao, Xiaorui Li, Jintao Xu, Rui Ai, Zhu Yu, and\n  Xieyuanli Chen","authorsParsed":[["Luo","Lun",""],["Cao","Si-Yuan",""],["Li","Xiaorui",""],["Xu","Jintao",""],["Ai","Rui",""],["Yu","Zhu",""],["Chen","Xieyuanli",""]],"versions":[{"version":"v1","created":"Sat, 3 Aug 2024 18:48:41 GMT"},{"version":"v2","created":"Fri, 9 Aug 2024 06:42:37 GMT"}],"updateDate":"2024-08-12","timestamp":1722710921000,"abstract":"  This article introduces BEVPlace++, a novel, fast, and robust LiDAR global\nlocalization method for unmanned ground vehicles. It uses lightweight\nconvolutional neural networks (CNNs) on Bird's Eye View (BEV) image-like\nrepresentations of LiDAR data to achieve accurate global localization through\nplace recognition followed by 3-DoF pose estimation. Our detailed analyses\nreveal an interesting fact that CNNs are inherently effective at extracting\ndistinctive features from LiDAR BEV images. Remarkably, keypoints of two BEV\nimages with large translations can be effectively matched using CNN-extracted\nfeatures. Building on this insight, we design a rotation equivariant module\n(REM) to obtain distinctive features while enhancing robustness to rotational\nchanges. A Rotation Equivariant and Invariant Network (REIN) is then developed\nby cascading REM and a descriptor generator, NetVLAD, to sequentially generate\nrotation equivariant local features and rotation invariant global descriptors.\nThe global descriptors are used first to achieve robust place recognition, and\nthe local features are used for accurate pose estimation. Experimental results\non multiple public datasets demonstrate that BEVPlace++, even when trained on a\nsmall dataset (3000 frames of KITTI) only with place labels, generalizes well\nto unseen environments, performs consistently across different days and years,\nand adapts to various types of LiDAR scanners. BEVPlace++ achieves\nstate-of-the-art performance in subtasks of global localization including place\nrecognition, loop closure detection, and global localization. Additionally,\nBEVPlace++ is lightweight, runs in real-time, and does not require accurate\npose supervision, making it highly convenient for deployment. The source codes\nare publicly available at https://github.com/zjuluolun/BEVPlace.\n","subjects":["Computing Research Repository/Robotics"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}