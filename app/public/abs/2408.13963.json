{"id":"2408.13963","title":"Shifted Window Fourier Transform And Retention For Image Captioning","authors":"Jia Cheng Hu, Roberto Cavicchioli, Alessandro Capotondi","authorsParsed":[["Hu","Jia Cheng",""],["Cavicchioli","Roberto",""],["Capotondi","Alessandro",""]],"versions":[{"version":"v1","created":"Sun, 25 Aug 2024 23:57:07 GMT"}],"updateDate":"2024-08-27","timestamp":1724630227000,"abstract":"  Image Captioning is an important Language and Vision task that finds\napplication in a variety of contexts, ranging from healthcare to autonomous\nvehicles. As many real-world applications rely on devices with limited\nresources, much effort in the field was put into the development of lighter and\nfaster models. However, much of the current optimizations focus on the\nTransformer architecture in contrast to the existence of more efficient\nmethods. In this work, we introduce SwiFTeR, an architecture almost entirely\nbased on Fourier Transform and Retention, to tackle the main efficiency\nbottlenecks of current light image captioning models, being the visual\nbackbone's onerosity, and the decoder's quadratic cost. SwiFTeR is made of only\n20M parameters, and requires 3.1 GFLOPs for a single forward pass.\nAdditionally, it showcases superior scalability to the caption length and its\nsmall memory requirements enable more images to be processed in parallel,\ncompared to the traditional transformer-based architectures. For instance, it\ncan generate 400 captions in one second. Although, for the time being, the\ncaption quality is lower (110.2 CIDEr-D), most of the decrease is not\nattributed to the architecture but rather an incomplete training practice which\ncurrently leaves much room for improvements. Overall, SwiFTeR points toward a\npromising direction to new efficient architectural design. The implementation\ncode will be released in the future.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"HSqlz_wF_VAjRv9Z5K8thNLVXwYparnGlZWsC8PjugE","pdfSize":"828597"}
