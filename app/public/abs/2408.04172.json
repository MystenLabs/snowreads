{"id":"2408.04172","title":"MultiColor: Image Colorization by Learning from Multiple Color Spaces","authors":"Xiangcheng Du, Zhao Zhou, Yanlong Wang, Zhuoyao Wang, Yingbin Zheng,\n  Cheng Jin","authorsParsed":[["Du","Xiangcheng",""],["Zhou","Zhao",""],["Wang","Yanlong",""],["Wang","Zhuoyao",""],["Zheng","Yingbin",""],["Jin","Cheng",""]],"versions":[{"version":"v1","created":"Thu, 8 Aug 2024 02:34:41 GMT"}],"updateDate":"2024-08-09","timestamp":1723084481000,"abstract":"  Deep networks have shown impressive performance in the image restoration\ntasks, such as image colorization. However, we find that previous approaches\nrely on the digital representation from single color model with a specific\nmapping function, a.k.a., color space, during the colorization pipeline. In\nthis paper, we first investigate the modeling of different color spaces, and\nfind each of them exhibiting distinctive characteristics with unique\ndistribution of colors. The complementarity among multiple color spaces leads\nto benefits for the image colorization task.\n  We present MultiColor, a new learning-based approach to automatically\ncolorize grayscale images that combines clues from multiple color spaces.\nSpecifically, we employ a set of dedicated colorization modules for individual\ncolor space. Within each module, a transformer decoder is first employed to\nrefine color query embeddings and then a color mapper produces color channel\nprediction using the embeddings and semantic features. With these predicted\ncolor channels representing various color spaces, a complementary network is\ndesigned to exploit the complementarity and generate pleasing and reasonable\ncolorized images. We conduct extensive experiments on real-world datasets, and\nthe results demonstrate superior performance over the state-of-the-arts.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Multimedia"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}