{"id":"2408.15578","title":"FireFly-S: Exploiting Dual-Side Sparsity for Spiking Neural Networks\n  Acceleration with Reconfigurable Spatial Architecture","authors":"Tenglong Li, Jindong Li, Guobin Shen, Dongcheng Zhao, Qian Zhang, Yi\n  Zeng","authorsParsed":[["Li","Tenglong",""],["Li","Jindong",""],["Shen","Guobin",""],["Zhao","Dongcheng",""],["Zhang","Qian",""],["Zeng","Yi",""]],"versions":[{"version":"v1","created":"Wed, 28 Aug 2024 07:02:01 GMT"}],"updateDate":"2024-08-29","timestamp":1724828521000,"abstract":"  Spiking Neural Networks (SNNs), with their brain-inspired structure using\ndiscrete spikes instead of continuous activations, are gaining attention for\ntheir potential of efficient processing on neuromorphic chips. While current\nSNN hardware accelerators often prioritize temporal spike sparsity, exploiting\nsparse synaptic weights offers significant untapped potential for even greater\nefficiency. To address this, we propose FireFly-S, a Sparse extension of the\nFireFly series. This co-optimized software-hardware design focusing on\nleveraging dual-side sparsity for acceleration. On the software side, we\npropose a novel algorithmic optimization framework that combines gradient\nrewiring for pruning and modified Learned Step Size Quantization (LSQ) tailored\nfor SNNs, which achieves remarkable weight sparsity exceeding 85\\% and enables\nefficient 4-bit quantization with negligible accuracy loss. On the hardware\nside, we present an efficient dual-side sparsity detector employing a\nBitmap-based sparse decoding logic to pinpoint the positions of non-zero\nweights and input spikes. The logic allows for the direct bypassing of\nredundant computations, thereby enhancing computational efficiency. Different\nfrom the overlay architecture adopted by previous FireFly series, we adopt a\nspatial architecture with inter-layer pipelining that can fully exploit the\nnature of Field-Programmable Gate Arrays (FPGAs). A spatial-temporal dataflow\nis also proposed to support such inter-layer pipelining and avoid long-term\ntemporal dependencies. In experiments conducted on the MNIST, DVS-Gesture and\nCIFAR-10 datasets, the FireFly-S model achieves 85-95\\% sparsity with 4-bit\nquantization and the hardware accelerator effectively leverages the dual-side\nsparsity, delivering outstanding performance metrics of 10,047 FPS/W on MNIST,\n3,683 FPS/W on DVS-Gesture, and 2,327 FPS/W on CIFAR-10.\n","subjects":["Computing Research Repository/Hardware Architecture"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}