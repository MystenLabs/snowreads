{"id":"2408.05562","title":"What Matters in Autonomous Driving Anomaly Detection: A Weakly\n  Supervised Horizon","authors":"Utkarsh Tiwari, Snehashis Majhi, Michal Balazia, and Fran\\c{c}ois\n  Br\\'emond","authorsParsed":[["Tiwari","Utkarsh",""],["Majhi","Snehashis",""],["Balazia","Michal",""],["Brémond","François",""]],"versions":[{"version":"v1","created":"Sat, 10 Aug 2024 14:04:52 GMT"}],"updateDate":"2024-08-13","timestamp":1723298692000,"abstract":"  Video anomaly detection (VAD) in autonomous driving scenario is an important\ntask, however it involves several challenges due to the ego-centric views and\nmoving camera. Due to this, it remains largely under-explored. While recent\ndevelopments in weakly-supervised VAD methods have shown remarkable progress in\ndetecting critical real-world anomalies in static camera scenario, the\ndevelopment and validation of such methods are yet to be explored for moving\ncamera VAD. This is mainly due to existing datasets like DoTA not following\ntraining pre-conditions of weakly-supervised learning. In this paper, we aim to\npromote weakly-supervised method development for autonomous driving VAD. We\nreorganize the DoTA dataset and aim to validate recent powerful\nweakly-supervised VAD methods on moving camera scenarios. Further, we provide a\ndetailed analysis of what modifications on state-of-the-art methods can\nsignificantly improve the detection performance. Towards this, we propose a\n\"feature transformation block\" and through experimentation we show that our\npropositions can empower existing weakly-supervised VAD methods significantly\nin improving the VAD in autonomous driving. Our codes/dataset/demo will be\nreleased at github.com/ut21/WSAD-Driving\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"6ORGyPDEiA5Q6ftcU0mvsJwtFK-k7bu0guvQC6I2I9M","pdfSize":"6784433"}
