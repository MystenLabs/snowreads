{"id":"2408.14817","title":"A Comprehensive Benchmark of Machine and Deep Learning Across Diverse\n  Tabular Datasets","authors":"Assaf Shmuel, Oren Glickman, Teddy Lazebnik","authorsParsed":[["Shmuel","Assaf",""],["Glickman","Oren",""],["Lazebnik","Teddy",""]],"versions":[{"version":"v1","created":"Tue, 27 Aug 2024 06:58:52 GMT"}],"updateDate":"2024-08-28","timestamp":1724741932000,"abstract":"  The analysis of tabular datasets is highly prevalent both in scientific\nresearch and real-world applications of Machine Learning (ML). Unlike many\nother ML tasks, Deep Learning (DL) models often do not outperform traditional\nmethods in this area. Previous comparative benchmarks have shown that DL\nperformance is frequently equivalent or even inferior to models such as\nGradient Boosting Machines (GBMs). In this study, we introduce a comprehensive\nbenchmark aimed at better characterizing the types of datasets where DL models\nexcel. Although several important benchmarks for tabular datasets already\nexist, our contribution lies in the variety and depth of our comparison: we\nevaluate 111 datasets with 20 different models, including both regression and\nclassification tasks. These datasets vary in scale and include both those with\nand without categorical variables. Importantly, our benchmark contains a\nsufficient number of datasets where DL models perform best, allowing for a\nthorough analysis of the conditions under which DL models excel. Building on\nthe results of this benchmark, we train a model that predicts scenarios where\nDL models outperform alternative methods with 86.1% accuracy (AUC 0.78). We\npresent insights derived from this characterization and compare these findings\nto previous benchmarks.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/"}