{"id":"2407.13796","title":"Continuous Embedding Attacks via Clipped Inputs in Jailbreaking Large\n  Language Models","authors":"Zihao Xu, Yi Liu, Gelei Deng, Kailong Wang, Yuekang Li, Ling Shi,\n  Stjepan Picek","authorsParsed":[["Xu","Zihao",""],["Liu","Yi",""],["Deng","Gelei",""],["Wang","Kailong",""],["Li","Yuekang",""],["Shi","Ling",""],["Picek","Stjepan",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 20:53:00 GMT"}],"updateDate":"2024-07-22","timestamp":1721163180000,"abstract":"  Security concerns for large language models (LLMs) have recently escalated,\nfocusing on thwarting jailbreaking attempts in discrete prompts. However, the\nexploration of jailbreak vulnerabilities arising from continuous embeddings has\nbeen limited, as prior approaches primarily involved appending discrete or\ncontinuous suffixes to inputs. Our study presents a novel channel for\nconducting direct attacks on LLM inputs, eliminating the need for suffix\naddition or specific questions provided that the desired output is predefined.\nWe additionally observe that extensive iterations often lead to overfitting,\ncharacterized by repetition in the output. To counteract this, we propose a\nsimple yet effective strategy named CLIP. Our experiments show that for an\ninput length of 40 at iteration 1000, applying CLIP improves the ASR from 62%\nto 83%\n","subjects":["Computing Research Repository/Cryptography and Security","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}