{"id":"2408.13493","title":"Thresholded Lexicographic Ordered Multiobjective Reinforcement Learning","authors":"Alperen Tercan and Vinayak S. Prabhu","authorsParsed":[["Tercan","Alperen",""],["Prabhu","Vinayak S.",""]],"versions":[{"version":"v1","created":"Sat, 24 Aug 2024 06:32:30 GMT"},{"version":"v2","created":"Wed, 4 Sep 2024 01:00:12 GMT"}],"updateDate":"2024-09-05","timestamp":1724481150000,"abstract":"  Lexicographic multi-objective problems, which impose a lexicographic\nimportance order over the objectives, arise in many real-life scenarios.\nExisting Reinforcement Learning work directly addressing lexicographic tasks\nhas been scarce. The few proposed approaches were all noted to be heuristics\nwithout theoretical guarantees as the Bellman equation is not applicable to\nthem. Additionally, the practical applicability of these prior approaches also\nsuffers from various issues such as not being able to reach the goal state.\nWhile some of these issues have been known before, in this work we investigate\nfurther shortcomings, and propose fixes for improving practical performance in\nmany cases. We also present a policy optimization approach using our\nLexicographic Projection Optimization (LPO) algorithm that has the potential to\naddress these theoretical and practical concerns. Finally, we demonstrate our\nproposed algorithms on benchmark problems.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/"}