{"id":"2408.03945","title":"Impacts of Anthropomorphizing Large Language Models in Learning\n  Environments","authors":"Kristina Schaaff and Marc-Andr\\'e Heidelmann","authorsParsed":[["Schaaff","Kristina",""],["Heidelmann","Marc-Andr√©",""]],"versions":[{"version":"v1","created":"Mon, 22 Jul 2024 06:28:54 GMT"}],"updateDate":"2024-08-09","timestamp":1721629734000,"abstract":"  Large Language Models (LLMs) are increasingly being used in learning\nenvironments to support teaching-be it as learning companions or as tutors.\nWith our contribution, we aim to discuss the implications of the\nanthropomorphization of LLMs in learning environments on educational theory to\nbuild a foundation for more effective learning outcomes and understand their\nemotional impact on learners. According to the media equation, people tend to\nrespond to media in the same way as they would respond to another person. A\nstudy conducted by the Georgia Institute of Technology showed that chatbots can\nbe successfully implemented in learning environments. In this study, learners\nin selected online courses were unable to distinguish the chatbot from a \"real\"\nteacher. As LLM-based chatbots such as OpenAI's GPT series are increasingly\nused in educational tools, it is important to understand how the attribution\nprocesses to LLM-based chatbots in terms of anthropomorphization affect\nlearners' emotions.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computers and Society","Computing Research Repository/Human-Computer Interaction"],"license":"http://creativecommons.org/licenses/by/4.0/"}