{"id":"2407.03034","title":"Attention Incorporated Network for Sharing Low-rank, Image and K-space\n  Information during MR Image Reconstruction to Achieve Single Breath-hold\n  Cardiac Cine Imaging","authors":"Siying Xu, Kerstin Hammernik, Andreas Lingg, Jens Kuebler, Patrick\n  Krumm, Daniel Rueckert, Sergios Gatidis, Thomas Kuestner","authorsParsed":[["Xu","Siying",""],["Hammernik","Kerstin",""],["Lingg","Andreas",""],["Kuebler","Jens",""],["Krumm","Patrick",""],["Rueckert","Daniel",""],["Gatidis","Sergios",""],["Kuestner","Thomas",""]],"versions":[{"version":"v1","created":"Wed, 3 Jul 2024 11:54:43 GMT"}],"updateDate":"2024-07-04","timestamp":1720007683000,"abstract":"  Cardiac Cine Magnetic Resonance Imaging (MRI) provides an accurate assessment\nof heart morphology and function in clinical practice. However, MRI requires\nlong acquisition times, with recent deep learning-based methods showing great\npromise to accelerate imaging and enhance reconstruction quality. Existing\nnetworks exhibit some common limitations that constrain further acceleration\npossibilities, including single-domain learning, reliance on a single\nregularization term, and equal feature contribution. To address these\nlimitations, we propose to embed information from multiple domains, including\nlow-rank, image, and k-space, in a novel deep learning network for MRI\nreconstruction, which we denote as A-LIKNet. A-LIKNet adopts a parallel-branch\nstructure, enabling independent learning in the k-space and image domain.\nCoupled information sharing layers realize the information exchange between\ndomains. Furthermore, we introduce attention mechanisms into the network to\nassign greater weights to more critical coils or important temporal frames.\nTraining and testing were conducted on an in-house dataset, including 91\ncardiovascular patients and 38 healthy subjects scanned with 2D cardiac Cine\nusing retrospective undersampling. Additionally, we evaluated A-LIKNet on the\nreal-time 8x prospectively undersampled data from the OCMR dataset. The results\ndemonstrate that our proposed A-LIKNet outperforms existing methods and\nprovides high-quality reconstructions. The network can effectively reconstruct\nhighly retrospectively undersampled dynamic MR images up to 24x accelerations,\nindicating its potential for single breath-hold imaging.\n","subjects":["Electrical Engineering and Systems Science/Image and Video Processing","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}