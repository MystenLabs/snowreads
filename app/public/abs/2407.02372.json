{"id":"2407.02372","title":"Finer-Grained Hardness of Kernel Density Estimation","authors":"Josh Alman, Yunfeng Guan","authorsParsed":[["Alman","Josh",""],["Guan","Yunfeng",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 15:41:47 GMT"}],"updateDate":"2024-07-03","timestamp":1719934907000,"abstract":"  In batch Kernel Density Estimation (KDE) for a kernel function $f$, we are\ngiven as input $2n$ points $x^{(1)}, \\cdots, x^{(n)}, y^{(1)}, \\cdots, y^{(n)}$\nin dimension $m$, as well as a vector $v \\in \\mathbb{R}^n$. These inputs\nimplicitly define the $n \\times n$ kernel matrix $K$ given by $K[i,j] =\nf(x^{(i)}, y^{(j)})$. The goal is to compute a vector $v$ which approximates $K\nw$ with $|| Kw - v||_\\infty < \\varepsilon ||w||_1$. A recent line of work has\nproved fine-grained lower bounds conditioned on SETH. Backurs et al. first\nshowed the hardness of KDE for Gaussian-like kernels with high dimension $m =\n\\Omega(\\log n)$ and large scale $B = \\Omega(\\log n)$. Alman et al. later\ndeveloped new reductions in roughly this same parameter regime, leading to\nlower bounds for more general kernels, but only for very small error\n$\\varepsilon < 2^{- \\log^{\\Omega(1)} (n)}$.\n  In this paper, we refine the approach of Alman et al. to show new lower\nbounds in all parameter regimes, closing gaps between the known algorithms and\nlower bounds. In the setting where $m = C\\log n$ and $B = o(\\log n)$, we prove\nGaussian KDE requires $n^{2-o(1)}$ time to achieve additive error $\\varepsilon\n< \\Omega(m/B)^{-m}$, matching the performance of the polynomial method up to\nlow-order terms. In the low dimensional setting $m = o(\\log n)$, we show that\nGaussian KDE requires $n^{2-o(1)}$ time to achieve $\\varepsilon$ such that\n$\\log \\log (\\varepsilon^{-1}) > \\tilde \\Omega ((\\log n)/m)$, matching the error\nbound achievable by FMM up to low-order terms. To our knowledge, no nontrivial\nlower bound was previously known in this regime.\n  Our new lower bounds make use of an intricate analysis of a special case of\nthe kernel matrix -- the `counting matrix'. As a key technical lemma, we give a\nnovel approach to bounding the entries of its inverse by using Schur\npolynomials from algebraic combinatorics.\n","subjects":["Computing Research Repository/Data Structures and Algorithms","Computing Research Repository/Numerical Analysis","Mathematics/Numerical Analysis"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/"}