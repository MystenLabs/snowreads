{"id":"2408.07151","title":"Alpha-Trimming: Locally Adaptive Tree Pruning for Random Forests","authors":"Nikola Surjanovic, Andrew Henrey, Thomas M. Loughin","authorsParsed":[["Surjanovic","Nikola",""],["Henrey","Andrew",""],["Loughin","Thomas M.",""]],"versions":[{"version":"v1","created":"Tue, 13 Aug 2024 18:41:09 GMT"}],"updateDate":"2024-08-15","timestamp":1723574469000,"abstract":"  We demonstrate that adaptively controlling the size of individual regression\ntrees in a random forest can improve predictive performance, contrary to the\nconventional wisdom that trees should be fully grown. A fast pruning algorithm,\nalpha-trimming, is proposed as an effective approach to pruning trees within a\nrandom forest, where more aggressive pruning is performed in regions with a low\nsignal-to-noise ratio. The amount of overall pruning is controlled by adjusting\nthe weight on an information criterion penalty as a tuning parameter, with the\nstandard random forest being a special case of our alpha-trimmed random forest.\nA remarkable feature of alpha-trimming is that its tuning parameter can be\nadjusted without refitting the trees in the random forest once the trees have\nbeen fully grown once. In a benchmark suite of 46 example data sets, mean\nsquared prediction error is often substantially lowered by using our pruning\nalgorithm and is never substantially increased compared to a random forest with\nfully-grown trees at default parameter settings.\n","subjects":["Statistics/Machine Learning","Computing Research Repository/Machine Learning","Statistics/Computation"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}