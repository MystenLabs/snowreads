{"id":"2407.03361","title":"PianoBART: Symbolic Piano Music Generation and Understanding with\n  Large-Scale Pre-Training","authors":"Xiao Liang, Zijian Zhao, Weichao Zeng, Yutong He, Fupeng He, Yiyi\n  Wang, Chengying Gao","authorsParsed":[["Liang","Xiao",""],["Zhao","Zijian",""],["Zeng","Weichao",""],["He","Yutong",""],["He","Fupeng",""],["Wang","Yiyi",""],["Gao","Chengying",""]],"versions":[{"version":"v1","created":"Wed, 26 Jun 2024 03:35:54 GMT"}],"updateDate":"2024-07-08","timestamp":1719372954000,"abstract":"  Learning musical structures and composition patterns is necessary for both\nmusic generation and understanding, but current methods do not make uniform use\nof learned features to generate and comprehend music simultaneously. In this\npaper, we propose PianoBART, a pre-trained model that uses BART for both\nsymbolic piano music generation and understanding. We devise a multi-level\nobject selection strategy for different pre-training tasks of PianoBART, which\ncan prevent information leakage or loss and enhance learning ability. The\nmusical semantics captured in pre-training are fine-tuned for music generation\nand understanding tasks. Experiments demonstrate that PianoBART efficiently\nlearns musical patterns and achieves outstanding performance in generating\nhigh-quality coherent pieces and comprehending music. Our code and\nsupplementary material are available at https://github.com/RS2002/PianoBart.\n","subjects":["Computing Research Repository/Sound","Computing Research Repository/Artificial Intelligence","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}