{"id":"2408.11052","title":"Accelerating Goal-Conditioned RL Algorithms and Research","authors":"Micha{\\l} Bortkiewicz, W{\\l}adek Pa{\\l}ucki, Vivek Myers, Tadeusz\n  Dziarmaga, Tomasz Arczewski, {\\L}ukasz Kuci\\'nski, Benjamin Eysenbach","authorsParsed":[["Bortkiewicz","Michał",""],["Pałucki","Władek",""],["Myers","Vivek",""],["Dziarmaga","Tadeusz",""],["Arczewski","Tomasz",""],["Kuciński","Łukasz",""],["Eysenbach","Benjamin",""]],"versions":[{"version":"v1","created":"Tue, 20 Aug 2024 17:58:40 GMT"}],"updateDate":"2024-08-21","timestamp":1724176720000,"abstract":"  Self-supervision has the potential to transform reinforcement learning (RL),\nparalleling the breakthroughs it has enabled in other areas of machine\nlearning. While self-supervised learning in other domains aims to find patterns\nin a fixed dataset, self-supervised goal-conditioned reinforcement learning\n(GCRL) agents discover new behaviors by learning from the goals achieved during\nunstructured interaction with the environment. However, these methods have\nfailed to see similar success, both due to a lack of data from slow\nenvironments as well as a lack of stable algorithms. We take a step toward\naddressing both of these issues by releasing a high-performance codebase and\nbenchmark JaxGCRL for self-supervised GCRL, enabling researchers to train\nagents for millions of environment steps in minutes on a single GPU. The key to\nthis performance is a combination of GPU-accelerated environments and a stable,\nbatched version of the contrastive reinforcement learning algorithm, based on\nan infoNCE objective, that effectively makes use of this increased data\nthroughput. With this approach, we provide a foundation for future research in\nself-supervised GCRL, enabling researchers to quickly iterate on new ideas and\nevaluate them in a diverse set of challenging environments. Website + Code:\nhttps://github.com/MichalBortkiewicz/JaxGCRL\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}