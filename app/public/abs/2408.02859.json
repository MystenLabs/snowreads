{"id":"2408.02859","title":"Multistain Pretraining for Slide Representation Learning in Pathology","authors":"Guillaume Jaume and Anurag Vaidya and Andrew Zhang and Andrew H. Song\n  and Richard J. Chen and Sharifa Sahai and Dandan Mo and Emilio Madrigal and\n  Long Phi Le and Faisal Mahmood","authorsParsed":[["Jaume","Guillaume",""],["Vaidya","Anurag",""],["Zhang","Andrew",""],["Song","Andrew H.",""],["Chen","Richard J.",""],["Sahai","Sharifa",""],["Mo","Dandan",""],["Madrigal","Emilio",""],["Le","Long Phi",""],["Mahmood","Faisal",""]],"versions":[{"version":"v1","created":"Mon, 5 Aug 2024 22:59:50 GMT"}],"updateDate":"2024-08-07","timestamp":1722898790000,"abstract":"  Developing self-supervised learning (SSL) models that can learn universal and\ntransferable representations of H&E gigapixel whole-slide images (WSIs) is\nbecoming increasingly valuable in computational pathology. These models hold\nthe potential to advance critical tasks such as few-shot classification, slide\nretrieval, and patient stratification. Existing approaches for slide\nrepresentation learning extend the principles of SSL from small images (e.g.,\n224 x 224 patches) to entire slides, usually by aligning two different\naugmentations (or views) of the slide. Yet the resulting representation remains\nconstrained by the limited clinical and biological diversity of the views.\nInstead, we postulate that slides stained with multiple markers, such as\nimmunohistochemistry, can be used as different views to form a rich\ntask-agnostic training signal. To this end, we introduce Madeleine, a\nmultimodal pretraining strategy for slide representation learning. Madeleine is\ntrained with a dual global-local cross-stain alignment objective on large\ncohorts of breast cancer samples (N=4,211 WSIs across five stains) and kidney\ntransplant samples (N=12,070 WSIs across four stains). We demonstrate the\nquality of slide representations learned by Madeleine on various downstream\nevaluations, ranging from morphological and molecular classification to\nprognostic prediction, comprising 21 tasks using 7,299 WSIs from multiple\nmedical centers. Code is available at https://github.com/mahmoodlab/MADELEINE.\n","subjects":["Electrical Engineering and Systems Science/Image and Video Processing","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/"}