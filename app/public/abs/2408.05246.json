{"id":"2408.05246","title":"Differentially Private Data Release on Graphs: Inefficiencies and\n  Unfairness","authors":"Ferdinando Fioretto, Diptangshu Sen and Juba Ziani","authorsParsed":[["Fioretto","Ferdinando",""],["Sen","Diptangshu",""],["Ziani","Juba",""]],"versions":[{"version":"v1","created":"Thu, 8 Aug 2024 08:37:37 GMT"}],"updateDate":"2024-08-13","timestamp":1723106257000,"abstract":"  Networks are crucial components of many sectors, including\ntelecommunications, healthcare, finance, energy, and transportation.The\ninformation carried in such networks often contains sensitive user data, like\nlocation data for commuters and packet data for online users. Therefore, when\nconsidering data release for networks, one must ensure that data release\nmechanisms do not leak information about individuals, quantified in a precise\nmathematical sense. Differential Privacy (DP) is the widely accepted, formal,\nstate-of-the-art technique, which has found use in a variety of real-life\nsettings including the 2020 U.S. Census, Apple users' device data, or Google's\nlocation data. Yet, the use of DP comes with new challenges, as the noise added\nfor privacy introduces inaccuracies or biases and further, DP techniques can\nalso distribute these biases disproportionately across different populations,\ninducing fairness issues. The goal of this paper is to characterize the impact\nof DP on bias and unfairness in the context of releasing information about\nnetworks, taking a departure from previous work which has studied these effects\nin the context of private population counts release (such as in the U.S.\nCensus). To this end, we consider a network release problem where the network\nstructure is known to all, but the weights on edges must be released privately.\nWe consider the impact of this private release on a simple downstream\ndecision-making task run by a third-party, which is to find the shortest path\nbetween any two pairs of nodes and recommend the best route to users. This\nsetting is of highly practical relevance, mirroring scenarios in transportation\nnetworks, where preserving privacy while providing accurate routing information\nis crucial. Our work provides theoretical foundations and empirical evidence\ninto the bias and unfairness arising due to privacy in these networked decision\nproblems.\n","subjects":["Computing Research Repository/Cryptography and Security","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computers and Society","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}