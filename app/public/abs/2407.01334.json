{"id":"2407.01334","title":"Protecting Privacy in Classifiers by Token Manipulation","authors":"Re'em Harel, Yair Elboher, Yuval Pinter","authorsParsed":[["Harel","Re'em",""],["Elboher","Yair",""],["Pinter","Yuval",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 14:41:59 GMT"},{"version":"v2","created":"Wed, 3 Jul 2024 16:31:52 GMT"}],"updateDate":"2024-07-04","timestamp":1719844919000,"abstract":"  Using language models as a remote service entails sending private information\nto an untrusted provider. In addition, potential eavesdroppers can intercept\nthe messages, thereby exposing the information. In this work, we explore the\nprospects of avoiding such data exposure at the level of text manipulation. We\nfocus on text classification models, examining various token mapping and\ncontextualized manipulation functions in order to see whether classifier\naccuracy may be maintained while keeping the original text unrecoverable. We\nfind that although some token mapping functions are easy and straightforward to\nimplement, they heavily influence performance on the downstream task, and via a\nsophisticated attacker can be reconstructed. In comparison, the contextualized\nmanipulation provides an improvement in performance.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Cryptography and Security"],"license":"http://creativecommons.org/licenses/by/4.0/"}