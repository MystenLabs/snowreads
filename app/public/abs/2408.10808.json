{"id":"2408.10808","title":"ColBERT Retrieval and Ensemble Response Scoring for Language Model\n  Question Answering","authors":"Alex Gichamba, Tewodros Kederalah Idris, Brian Ebiyau, Eric Nyberg,\n  Teruko Mitamura","authorsParsed":[["Gichamba","Alex",""],["Idris","Tewodros Kederalah",""],["Ebiyau","Brian",""],["Nyberg","Eric",""],["Mitamura","Teruko",""]],"versions":[{"version":"v1","created":"Tue, 20 Aug 2024 12:58:16 GMT"}],"updateDate":"2024-08-21","timestamp":1724158696000,"abstract":"  Domain-specific question answering remains challenging for language models,\ngiven the deep technical knowledge required to answer questions correctly. This\ndifficulty is amplified for smaller language models that cannot encode as much\ninformation in their parameters as larger models. The \"Specializing Large\nLanguage Models for Telecom Networks\" challenge aimed to enhance the\nperformance of two small language models, Phi-2 and Falcon-7B in\ntelecommunication question answering. In this paper, we present our question\nanswering systems for this challenge. Our solutions achieved leading marks of\n81.9% accuracy for Phi-2 and 57.3% for Falcon-7B. We have publicly released our\ncode and fine-tuned models.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Information Retrieval"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"Jk8g23BKfHauiS5J7CpxjY0IIdnrHvyMhDZ2NqzL1u8","pdfSize":"840266"}
