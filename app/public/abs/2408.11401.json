{"id":"2408.11401","title":"Revisiting FunnyBirds evaluation framework for prototypical parts\n  networks","authors":"Szymon Op{\\l}atek, Dawid Rymarczyk, Bartosz Zieli\\'nski","authorsParsed":[["Opłatek","Szymon",""],["Rymarczyk","Dawid",""],["Zieliński","Bartosz",""]],"versions":[{"version":"v1","created":"Wed, 21 Aug 2024 07:58:34 GMT"}],"updateDate":"2024-08-22","timestamp":1724227114000,"abstract":"  Prototypical parts networks, such as ProtoPNet, became popular due to their\npotential to produce more genuine explanations than post-hoc methods. However,\nfor a long time, this potential has been strictly theoretical, and no\nsystematic studies have existed to support it. That changed recently with the\nintroduction of the FunnyBirds benchmark, which includes metrics for evaluating\ndifferent aspects of explanations.\n  However, this benchmark employs attribution maps visualization for all\nexplanation techniques except for the ProtoPNet, for which the bounding boxes\nare used. This choice significantly influences the metric scores and questions\nthe conclusions stated in FunnyBirds publication.\n  In this study, we comprehensively compare metric scores obtained for two\ntypes of ProtoPNet visualizations: bounding boxes and similarity maps. Our\nanalysis indicates that employing similarity maps aligns better with the\nessence of ProtoPNet, as evidenced by different metric scores obtained from\nFunnyBirds. Therefore, we advocate using similarity maps as a visualization\ntechnique for prototypical parts networks in explainability evaluation\nbenchmarks.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}