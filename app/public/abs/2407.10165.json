{"id":"2407.10165","title":"The Hidden Influence of Latent Feature Magnitude When Learning with\n  Imbalanced Data","authors":"Damien A. Dablain and Nitesh V. Chawla","authorsParsed":[["Dablain","Damien A.",""],["Chawla","Nitesh V.",""]],"versions":[{"version":"v1","created":"Sun, 14 Jul 2024 11:20:50 GMT"}],"updateDate":"2024-07-16","timestamp":1720956050000,"abstract":"  Machine learning (ML) models have difficulty generalizing when the number of\ntraining class instances are numerically imbalanced. The problem of\ngeneralization in the face of data imbalance has largely been attributed to the\nlack of training data for under-represented classes and to feature overlap. The\ntypical remedy is to implement data augmentation for classes with fewer\ninstances or to assign a higher cost to minority class prediction errors or to\nundersample the prevalent class. However, we show that one of the central\ncauses of impaired generalization when learning with imbalanced data is the\ninherent manner in which ML models perform inference. These models have\ndifficulty generalizing due to their heavy reliance on the magnitude of encoded\nsignals. During inference, the models predict classes based on a combination of\nencoded signal magnitudes that linearly sum to the largest scalar. We\ndemonstrate that even with aggressive data augmentation, which generally\nimproves minority class prediction accuracy, parametric ML models still\nassociate a class label with a limited number of feature combinations that sum\nto a prediction, which can affect generalization.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"e_dd4Gx7qWGk6Y_gvMmX7nREE8VACEoxvGD4YPN8PGw","pdfSize":"852651","objectId":"0x02421b42e064b8145cecdd7280ea77fec715dda654b329dcd553f62b5664f912","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
