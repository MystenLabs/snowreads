{"id":"2408.03208","title":"Personalizing Federated Instrument Segmentation with Visual Trait Priors\n  in Robotic Surgery","authors":"Jialang Xu, Jiacheng Wang, Lequan Yu, Danail Stoyanov, Yueming Jin,\n  Evangelos B. Mazomenos","authorsParsed":[["Xu","Jialang",""],["Wang","Jiacheng",""],["Yu","Lequan",""],["Stoyanov","Danail",""],["Jin","Yueming",""],["Mazomenos","Evangelos B.",""]],"versions":[{"version":"v1","created":"Tue, 6 Aug 2024 14:06:53 GMT"},{"version":"v2","created":"Thu, 15 Aug 2024 19:57:59 GMT"}],"updateDate":"2024-08-19","timestamp":1722953213000,"abstract":"  Personalized federated learning (PFL) for surgical instrument segmentation\n(SIS) is a promising approach. It enables multiple clinical sites to\ncollaboratively train a series of models in privacy, with each model tailored\nto the individual distribution of each site. Existing PFL methods rarely\nconsider the personalization of multi-headed self-attention, and do not account\nfor appearance diversity and instrument shape similarity, both inherent in\nsurgical scenes. We thus propose PFedSIS, a novel PFL method with visual trait\npriors for SIS, incorporating global-personalized disentanglement (GPD),\nappearance-regulation personalized enhancement (APE), and shape-similarity\nglobal enhancement (SGE), to boost SIS performance in each site. GPD represents\nthe first attempt at head-wise assignment for multi-headed self-attention\npersonalization. To preserve the unique appearance representation of each site\nand gradually leverage the inter-site difference, APE introduces appearance\nregulation and provides customized layer-wise aggregation solutions via\nhypernetworks for each site's personalized parameters. The mutual shape\ninformation of instruments is maintained and shared via SGE, which enhances the\ncross-style shape consistency on the image level and computes the\nshape-similarity contribution of each site on the prediction level for updating\nthe global parameters. PFedSIS outperforms state-of-the-art methods with +1.51%\nDice, +2.11% IoU, -2.79 ASSD, -15.55 HD95 performance gains. The corresponding\ncode and models will be released at https://github.com/wzjialang/PFedSIS.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Robotics","Physics/Medical Physics"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}