{"id":"2407.17754","title":"DualFed: Enjoying both Generalization and Personalization in Federated\n  Learning via Hierachical Representations","authors":"Guogang Zhu, Xuefeng Liu, Jianwei Niu, Shaojie Tang, Xinghao Wu,\n  Jiayuan Zhang","authorsParsed":[["Zhu","Guogang",""],["Liu","Xuefeng",""],["Niu","Jianwei",""],["Tang","Shaojie",""],["Wu","Xinghao",""],["Zhang","Jiayuan",""]],"versions":[{"version":"v1","created":"Thu, 25 Jul 2024 04:09:12 GMT"}],"updateDate":"2024-07-26","timestamp":1721880552000,"abstract":"  In personalized federated learning (PFL), it is widely recognized that\nachieving both high model generalization and effective personalization poses a\nsignificant challenge due to their conflicting nature. As a result, existing\nPFL methods can only manage a trade-off between these two objectives. This\nraises an interesting question: Is it feasible to develop a model capable of\nachieving both objectives simultaneously? Our paper presents an affirmative\nanswer, and the key lies in the observation that deep models inherently exhibit\nhierarchical architectures, which produce representations with various levels\nof generalization and personalization at different stages. A straightforward\napproach stemming from this observation is to select multiple representations\nfrom these layers and combine them to concurrently achieve generalization and\npersonalization. However, the number of candidate representations is commonly\nhuge, which makes this method infeasible due to high computational costs.To\naddress this problem, we propose DualFed, a new method that can directly yield\ndual representations correspond to generalization and personalization\nrespectively, thereby simplifying the optimization task. Specifically, DualFed\ninserts a personalized projection network between the encoder and classifier.\nThe pre-projection representations are able to capture generalized information\nshareable across clients, and the post-projection representations are effective\nto capture task-specific information on local clients. This design minimizes\nthe mutual interference between generalization and personalization, thereby\nachieving a win-win situation. Extensive experiments show that DualFed can\noutperform other FL methods. Code is available at\nhttps://github.com/GuogangZhu/DualFed.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Distributed, Parallel, and Cluster Computing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}