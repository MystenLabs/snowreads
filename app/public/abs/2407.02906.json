{"id":"2407.02906","title":"Single Image Rolling Shutter Removal with Diffusion Models","authors":"Zhanglei Yang, Haipeng Li, Mingbo Hong, Bing Zeng, Shuaicheng Liu","authorsParsed":[["Yang","Zhanglei",""],["Li","Haipeng",""],["Hong","Mingbo",""],["Zeng","Bing",""],["Liu","Shuaicheng",""]],"versions":[{"version":"v1","created":"Wed, 3 Jul 2024 08:25:02 GMT"}],"updateDate":"2024-07-04","timestamp":1719995102000,"abstract":"  We present RS-Diffusion, the first Diffusion Models-based method for\nsingle-frame Rolling Shutter (RS) correction. RS artifacts compromise visual\nquality of frames due to the row wise exposure of CMOS sensors. Most previous\nmethods have focused on multi-frame approaches, using temporal information from\nconsecutive frames for the motion rectification. However, few approaches\naddress the more challenging but important single frame RS correction. In this\nwork, we present an ``image-to-motion'' framework via diffusion techniques,\nwith a designed patch-attention module. In addition, we present the RS-Real\ndataset, comprised of captured RS frames alongside their corresponding Global\nShutter (GS) ground-truth pairs. The GS frames are corrected from the RS ones,\nguided by the corresponding Inertial Measurement Unit (IMU) gyroscope data\nacquired during capture. Experiments show that our RS-Diffusion surpasses\nprevious single RS correction methods. Our method and proposed RS-Real dataset\nlay a solid foundation for advancing the field of RS correction.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}