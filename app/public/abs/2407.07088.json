{"id":"2407.07088","title":"Safe and Reliable Training of Learning-Based Aerospace Controllers","authors":"Udayan Mandal, Guy Amir, Haoze Wu, Ieva Daukantas, Fletcher Lee\n  Newell, Umberto Ravaioli, Baoluo Meng, Michael Durling, Kerianne Hobbs, Milan\n  Ganai, Tobey Shim, Guy Katz, Clark Barrett","authorsParsed":[["Mandal","Udayan",""],["Amir","Guy",""],["Wu","Haoze",""],["Daukantas","Ieva",""],["Newell","Fletcher Lee",""],["Ravaioli","Umberto",""],["Meng","Baoluo",""],["Durling","Michael",""],["Hobbs","Kerianne",""],["Ganai","Milan",""],["Shim","Tobey",""],["Katz","Guy",""],["Barrett","Clark",""]],"versions":[{"version":"v1","created":"Tue, 9 Jul 2024 17:58:50 GMT"}],"updateDate":"2024-07-10","timestamp":1720547930000,"abstract":"  In recent years, deep reinforcement learning (DRL) approaches have generated\nhighly successful controllers for a myriad of complex domains. However, the\nopaque nature of these models limits their applicability in aerospace systems\nand safety-critical domains, in which a single mistake can have dire\nconsequences. In this paper, we present novel advancements in both the training\nand verification of DRL controllers, which can help ensure their safe behavior.\nWe showcase a design-for-verification approach utilizing k-induction and\ndemonstrate its use in verifying liveness properties. In addition, we also give\na brief overview of neural Lyapunov Barrier certificates and summarize their\ncapabilities on a case study. Finally, we describe several other novel\nreachability-based approaches which, despite failing to provide guarantees of\ninterest, could be effective for verification of other DRL systems, and could\nbe of further interest to the community.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Logic in Computer Science","Computing Research Repository/Systems and Control","Electrical Engineering and Systems Science/Systems and Control"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}