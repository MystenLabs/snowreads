{"id":"2407.21001","title":"GABInsight: Exploring Gender-Activity Binding Bias in Vision-Language\n  Models","authors":"Ali Abdollahi, Mahdi Ghaznavi, Mohammad Reza Karimi Nejad, Arash Mari\n  Oriyad, Reza Abbasi, Ali Salesi, Melika Behjati, Mohammad Hossein Rohban and\n  Mahdieh Soleymani Baghshah","authorsParsed":[["Abdollahi","Ali",""],["Ghaznavi","Mahdi",""],["Nejad","Mohammad Reza Karimi",""],["Oriyad","Arash Mari",""],["Abbasi","Reza",""],["Salesi","Ali",""],["Behjati","Melika",""],["Rohban","Mohammad Hossein",""],["Baghshah","Mahdieh Soleymani",""]],"versions":[{"version":"v1","created":"Tue, 30 Jul 2024 17:46:06 GMT"},{"version":"v2","created":"Sun, 18 Aug 2024 12:21:32 GMT"}],"updateDate":"2024-08-20","timestamp":1722361566000,"abstract":"  Vision-language models (VLMs) are intensively used in many downstream tasks,\nincluding those requiring assessments of individuals appearing in the images.\nWhile VLMs perform well in simple single-person scenarios, in real-world\napplications, we often face complex situations in which there are persons of\ndifferent genders doing different activities. We show that in such cases, VLMs\nare biased towards identifying the individual with the expected gender\n(according to ingrained gender stereotypes in the model or other forms of\nsample selection bias) as the performer of the activity. We refer to this bias\nin associating an activity with the gender of its actual performer in an image\nor text as the Gender-Activity Binding (GAB) bias and analyze how this bias is\ninternalized in VLMs. To assess this bias, we have introduced the GAB dataset\nwith approximately 5500 AI-generated images that represent a variety of\nactivities, addressing the scarcity of real-world images for some scenarios. To\nhave extensive quality control, the generated images are evaluated for their\ndiversity, quality, and realism. We have tested 12 renowned pre-trained VLMs on\nthis dataset in the context of text-to-image and image-to-text retrieval to\nmeasure the effect of this bias on their predictions. Additionally, we have\ncarried out supplementary experiments to quantify the bias in VLMs' text\nencoders and to evaluate VLMs' capability to recognize activities. Our\nexperiments indicate that VLMs experience an average performance decline of\nabout 13.2% when confronted with gender-activity binding bias.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}