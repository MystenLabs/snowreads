{"id":"2407.07551","title":"Arabic Automatic Story Generation with Large Language Models","authors":"Ahmed Oumar El-Shangiti and Fakhraddin Alwajih and Muhammad\n  Abdul-Mageed","authorsParsed":[["El-Shangiti","Ahmed Oumar",""],["Alwajih","Fakhraddin",""],["Abdul-Mageed","Muhammad",""]],"versions":[{"version":"v1","created":"Wed, 10 Jul 2024 11:26:10 GMT"}],"updateDate":"2024-07-11","timestamp":1720610770000,"abstract":"  Large language models (LLMs) have recently emerged as a powerful tool for a\nwide range of language generation tasks. Nevertheless, this progress has been\nslower in Arabic. In this work, we focus on the task of generating stories from\nLLMs. For our training, we use stories acquired through machine translation\n(MT) as well as GPT-4. For the MT data, we develop a careful pipeline that\nensures we acquire high-quality stories. For our GPT-41 data, we introduce\ncrafted prompts that allow us to generate data well-suited to the Arabic\ncontext in both Modern Standard Arabic (MSA) and two Arabic dialects (Egyptian\nand Moroccan). For example, we generate stories tailored to various Arab\ncountries on a wide host of topics. Our manual evaluation shows that our model\nfine-tuned on these training datasets can generate coherent stories that adhere\nto our instructions. We also conduct an extensive automatic and human\nevaluation comparing our models against state-of-the-art proprietary and\nopen-source models. Our datasets and models will be made publicly available at\nhttps: //github.com/UBC-NLP/arastories.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"giPHYA6q_-tO_TS-t4w2qlU-uaFPl6tXiNG-d2WYKJk","pdfSize":"5468403","objectId":"0xe4ce168adc07b6936adde040d8e24d2cb683c5954595976c920270bf595d1104","registeredEpoch":"1","certifiedEpoch":"1","startEpoch":"1","endEpoch":"201"}
