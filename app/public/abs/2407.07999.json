{"id":"2407.07999","title":"Fusion of Short-term and Long-term Attention for Video Mirror Detection","authors":"Mingchen Xu, Jing Wu, Yukun Lai, Ze Ji","authorsParsed":[["Xu","Mingchen",""],["Wu","Jing",""],["Lai","Yukun",""],["Ji","Ze",""]],"versions":[{"version":"v1","created":"Wed, 10 Jul 2024 19:04:52 GMT"}],"updateDate":"2024-07-12","timestamp":1720638292000,"abstract":"  Techniques for detecting mirrors from static images have witnessed rapid\ngrowth in recent years. However, these methods detect mirrors from single input\nimages. Detecting mirrors from video requires further consideration of temporal\nconsistency between frames. We observe that humans can recognize mirror\ncandidates, from just one or two frames, based on their appearance (e.g. shape,\ncolor). However, to ensure that the candidate is indeed a mirror (not a picture\nor a window), we often need to observe more frames for a global view. This\nobservation motivates us to detect mirrors by fusing appearance features\nextracted from a short-term attention module and context information extracted\nfrom a long-term attention module. To evaluate the performance, we build a\nchallenging benchmark dataset of 19,255 frames from 281 videos. Experimental\nresults demonstrate that our method achieves state-of-the-art performance on\nthe benchmark dataset.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}