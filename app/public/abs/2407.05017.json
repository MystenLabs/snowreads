{"id":"2407.05017","title":"VIPS-Odom: Visual-Inertial Odometry Tightly-coupled with Parking Slots\n  for Autonomous Parking","authors":"Xuefeng Jiang, Fangyuan Wang, Rongzhang Zheng, Han Liu, Yixiong Huo,\n  Jinzhang Peng, Lu Tian, Emad Barsoum","authorsParsed":[["Jiang","Xuefeng",""],["Wang","Fangyuan",""],["Zheng","Rongzhang",""],["Liu","Han",""],["Huo","Yixiong",""],["Peng","Jinzhang",""],["Tian","Lu",""],["Barsoum","Emad",""]],"versions":[{"version":"v1","created":"Sat, 6 Jul 2024 09:21:25 GMT"}],"updateDate":"2024-07-09","timestamp":1720257685000,"abstract":"  Precise localization is of great importance for autonomous parking task since\nit provides service for the downstream planning and control modules, which\nsignificantly affects the system performance. For parking scenarios, dynamic\nlighting, sparse textures, and the instability of global positioning system\n(GPS) signals pose challenges for most traditional localization methods. To\naddress these difficulties, we propose VIPS-Odom, a novel semantic\nvisual-inertial odometry framework for underground autonomous parking, which\nadopts tightly-coupled optimization to fuse measurements from multi-modal\nsensors and solves odometry. Our VIPS-Odom integrates parking slots detected\nfrom the synthesized bird-eye-view (BEV) image with traditional feature points\nin the frontend, and conducts tightly-coupled optimization with joint\nconstraints introduced by measurements from the inertial measurement unit,\nwheel speed sensor and parking slots in the backend. We develop a multi-object\ntracking framework to robustly track parking slots' states. To prove the\nsuperiority of our method, we equip an electronic vehicle with related sensors\nand build an experimental platform based on ROS2 system. Extensive experiments\ndemonstrate the efficacy and advantages of our method compared with other\nbaselines for parking scenarios.\n","subjects":["Computing Research Repository/Robotics"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}