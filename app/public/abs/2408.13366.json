{"id":"2408.13366","title":"CodeRefine: A Pipeline for Enhancing LLM-Generated Code Implementations\n  of Research Papers","authors":"Ekaterina Trofimova, Emil Sataev, Abhijit Singh Jowhari","authorsParsed":[["Trofimova","Ekaterina",""],["Sataev","Emil",""],["Jowhari","Abhijit Singh",""]],"versions":[{"version":"v1","created":"Fri, 23 Aug 2024 20:51:04 GMT"}],"updateDate":"2024-08-27","timestamp":1724446264000,"abstract":"  This paper presents CodeRefine, a novel framework for automatically\ntransforming research paper methodologies into functional code using Large\nLanguage Models (LLMs). Our multi-step approach first extracts and summarizes\nkey text chunks from papers, analyzes their code relevance, and creates a\nknowledge graph using a predefined ontology. Code is then generated from this\nstructured representation and enhanced through a proposed retrospective\nretrieval-augmented generation approach. CodeRefine addresses the challenge of\nbridging theoretical research and practical implementation, offering a more\naccurate alternative to LLM zero-shot prompting. Evaluations on diverse\nscientific papers demonstrate CodeRefine's ability to improve code\nimplementation from the paper, potentially accelerating the adoption of\ncutting-edge algorithms in real-world applications.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"b28TaPcF2k50uLFDYfVEv9C04phdMNY7nk7A2uANvbI","pdfSize":"1133464"}
