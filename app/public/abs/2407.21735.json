{"id":"2407.21735","title":"Unifying Event-based Flow, Stereo and Depth Estimation via Feature\n  Similarity Matching","authors":"Pengjie Zhang, Lin Zhu, Lizhi Wang, Hua Huang","authorsParsed":[["Zhang","Pengjie",""],["Zhu","Lin",""],["Wang","Lizhi",""],["Huang","Hua",""]],"versions":[{"version":"v1","created":"Wed, 31 Jul 2024 16:43:20 GMT"}],"updateDate":"2024-08-01","timestamp":1722444200000,"abstract":"  As an emerging vision sensor, the event camera has gained popularity in\nvarious vision tasks such as optical flow estimation, stereo matching, and\ndepth estimation due to its high-speed, sparse, and asynchronous event streams.\nUnlike traditional approaches that use specialized architectures for each\nspecific task, we propose a unified framework, EventMatch, that reformulates\nthese tasks as an event-based dense correspondence matching problem, allowing\nthem to be solved with a single model by directly comparing feature\nsimilarities. By utilizing a shared feature similarities module, which\nintegrates knowledge from other event flows via temporal or spatial\ninteractions, and distinct task heads, our network can concurrently perform\noptical flow estimation from temporal inputs (e.g., two segments of event\nstreams in the temporal domain) and stereo matching from spatial inputs (e.g.,\ntwo segments of event streams from different viewpoints in the spatial domain).\nMoreover, we further demonstrate that our unified model inherently supports\ncross-task transfer since the architecture and parameters are shared across\ntasks. Without the need for retraining on each task, our model can effectively\nhandle both optical flow and disparity estimation simultaneously. The\nexperiment conducted on the DSEC benchmark demonstrates that our model exhibits\nsuperior performance in both optical flow and disparity estimation tasks,\noutperforming existing state-of-the-art methods. Our unified approach not only\nadvances event-based models but also opens new possibilities for cross-task\ntransfer and inter-task fusion in both spatial and temporal dimensions. Our\ncode will be available later.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}