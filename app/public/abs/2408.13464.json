{"id":"2408.13464","title":"Uncovering Biases with Reflective Large Language Models","authors":"Edward Y. Chang","authorsParsed":[["Chang","Edward Y.",""]],"versions":[{"version":"v1","created":"Sat, 24 Aug 2024 04:48:32 GMT"}],"updateDate":"2024-08-28","timestamp":1724474912000,"abstract":"  Biases inherent in human endeavors pose significant challenges for machine\nlearning, particularly in supervised learning that relies on potentially biased\n\"ground truth\" data. This reliance, coupled with models' tendency to generalize\nbased on statistical maximal likelihood, can propagate and amplify biases,\nexacerbating societal issues. To address this, our study proposes a reflective\nmethodology utilizing multiple Large Language Models (LLMs) engaged in a\ndynamic dialogue to uncover diverse perspectives. By leveraging conditional\nstatistics, information theory, and divergence metrics, this novel approach\nfosters context-dependent linguistic behaviors, promoting unbiased outputs.\nFurthermore, it enables measurable progress tracking and explainable\nremediation actions to address identified biases.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}