{"id":"2408.00098","title":"Adaptive Transit Signal Priority based on Deep Reinforcement Learning\n  and Connected Vehicles in a Traffic Microsimulation Environment","authors":"Dickness Kwesiga, Angshuman Guin, and Michael Hunter","authorsParsed":[["Kwesiga","Dickness",""],["Guin","Angshuman",""],["Hunter","Michael",""]],"versions":[{"version":"v1","created":"Wed, 31 Jul 2024 18:17:22 GMT"}],"updateDate":"2024-08-02","timestamp":1722449842000,"abstract":"  Model free reinforcement learning (RL) provides a potential alternative to\nearlier formulations of adaptive transit signal priority (TSP) algorithms based\non mathematical programming that require complex and nonlinear objective\nfunctions. This study extends RL - based traffic control to include TSP. Using\na microscopic simulation environment and connected vehicle data, the study\ndevelops and tests a TSP event-based RL agent that assumes control from another\ndeveloped RL - based general traffic signal controller. The TSP agent assumes\ncontrol when transit buses enter the dedicated short-range communication (DSRC)\nzone of the intersection. This agent is shown to reduce the bus travel time by\nabout 21%, with marginal impacts to general traffic at a saturation rate of\n0.95. The TSP agent also shows slightly better bus travel time compared to\nactuated signal control with TSP. The architecture of the agent and simulation\nis selected considering the need to improve simulation run time efficiency.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/publicdomain/zero/1.0/","blobId":"9QmclznBW66cZCF1xESvjXFKvj3BUP8dY1B7k7RYABc","pdfSize":"567621"}
