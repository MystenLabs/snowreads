{"id":"2408.13424","title":"Enabling Humanitarian Applications with Targeted Differential Privacy","authors":"Nitin Kohli and Joshua Blumenstock","authorsParsed":[["Kohli","Nitin",""],["Blumenstock","Joshua",""]],"versions":[{"version":"v1","created":"Sat, 24 Aug 2024 01:34:37 GMT"}],"updateDate":"2024-08-27","timestamp":1724463277000,"abstract":"  The proliferation of mobile phones in low- and middle-income countries has\nsuddenly and dramatically increased the extent to which the world's poorest and\nmost vulnerable populations can be observed and tracked by governments and\ncorporations. Millions of historically \"off the grid\" individuals are now\npassively generating digital data; these data, in turn, are being used to make\nlife-altering decisions about those individuals -- including whether or not\nthey receive government benefits, and whether they qualify for a consumer loan.\n  This paper develops an approach to implementing algorithmic decisions based\non personal data, while also providing formal privacy guarantees to data\nsubjects. The approach adapts differential privacy to applications that require\ndecisions about individuals, and gives decision makers granular control over\nthe level of privacy guaranteed to data subjects. We show that stronger privacy\nguarantees typically come at some cost, and use data from two real-world\napplications -- an anti-poverty program in Togo and a consumer lending platform\nin Nigeria -- to illustrate those costs. Our empirical results quantify the\ntradeoff between privacy and predictive accuracy, and characterize how\ndifferent privacy guarantees impact overall program effectiveness. More\nbroadly, our results demonstrate a way for humanitarian programs to responsibly\nuse personal data, and better equip program designers to make informed\ndecisions about data privacy.\n","subjects":["Computing Research Repository/Cryptography and Security"],"license":"http://creativecommons.org/licenses/by/4.0/"}