{"id":"2407.18782","title":"Understanding XAI Through the Philosopher's Lens: A Historical\n  Perspective","authors":"Martina Mattioli, Antonio Emanuele Cin\\`a, Marcello Pelillo","authorsParsed":[["Mattioli","Martina",""],["Cin√†","Antonio Emanuele",""],["Pelillo","Marcello",""]],"versions":[{"version":"v1","created":"Fri, 26 Jul 2024 14:44:49 GMT"}],"updateDate":"2024-07-29","timestamp":1722005089000,"abstract":"  Despite explainable AI (XAI) has recently become a hot topic and several\ndifferent approaches have been developed, there is still a widespread belief\nthat it lacks a convincing unifying foundation. On the other hand, over the\npast centuries, the very concept of explanation has been the subject of\nextensive philosophical analysis in an attempt to address the fundamental\nquestion of \"why\" in the context of scientific law. However, this discussion\nhas rarely been connected with XAI. This paper tries to fill in this gap and\naims to explore the concept of explanation in AI through an epistemological\nlens. By comparing the historical development of both the philosophy of science\nand AI, an intriguing picture emerges. Specifically, we show that a gradual\nprogression has independently occurred in both domains from logical-deductive\nto statistical models of explanation, thereby experiencing in both cases a\nparadigm shift from deterministic to nondeterministic and probabilistic\ncausality. Interestingly, we also notice that similar concepts have\nindependently emerged in both realms such as, for example, the relation between\nexplanation and understanding and the importance of pragmatic factors. Our\nstudy aims to be the first step towards understanding the philosophical\nunderpinnings of the notion of explanation in AI, and we hope that our findings\nwill shed some fresh light on the elusive nature of XAI.\n","subjects":["Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}