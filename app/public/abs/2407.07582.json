{"id":"2407.07582","title":"TIP: Tabular-Image Pre-training for Multimodal Classification with\n  Incomplete Data","authors":"Siyi Du, Shaoming Zheng, Yinsong Wang, Wenjia Bai, Declan P. O'Regan,\n  Chen Qin","authorsParsed":[["Du","Siyi",""],["Zheng","Shaoming",""],["Wang","Yinsong",""],["Bai","Wenjia",""],["O'Regan","Declan P.",""],["Qin","Chen",""]],"versions":[{"version":"v1","created":"Wed, 10 Jul 2024 12:16:15 GMT"}],"updateDate":"2024-07-11","timestamp":1720613775000,"abstract":"  Images and structured tables are essential parts of real-world databases.\nThough tabular-image representation learning is promising to create new\ninsights, it remains a challenging task, as tabular data is typically\nheterogeneous and incomplete, presenting significant modality disparities with\nimages. Earlier works have mainly focused on simple modality fusion strategies\nin complete data scenarios, without considering the missing data issue, and\nthus are limited in practice. In this paper, we propose TIP, a novel\ntabular-image pre-training framework for learning multimodal representations\nrobust to incomplete tabular data. Specifically, TIP investigates a novel\nself-supervised learning (SSL) strategy, including a masked tabular\nreconstruction task for tackling data missingness, and image-tabular matching\nand contrastive learning objectives to capture multimodal information.\nMoreover, TIP proposes a versatile tabular encoder tailored for incomplete,\nheterogeneous tabular data and a multimodal interaction module for\ninter-modality representation learning. Experiments are performed on downstream\nmultimodal classification tasks using both natural and medical image datasets.\nThe results show that TIP outperforms state-of-the-art supervised/SSL\nimage/multimodal algorithms in both complete and incomplete data scenarios. Our\ncode is available at https://github.com/siyi-wind/TIP.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}