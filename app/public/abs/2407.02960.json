{"id":"2407.02960","title":"ObfuscaTune: Obfuscated Offsite Fine-tuning and Inference of Proprietary\n  LLMs on Private Datasets","authors":"Ahmed Frikha, Nassim Walha, Ricardo Mendes, Krishna Kanth Nakka, Xue\n  Jiang, Xuebing Zhou","authorsParsed":[["Frikha","Ahmed",""],["Walha","Nassim",""],["Mendes","Ricardo",""],["Nakka","Krishna Kanth",""],["Jiang","Xue",""],["Zhou","Xuebing",""]],"versions":[{"version":"v1","created":"Wed, 3 Jul 2024 09:54:08 GMT"}],"updateDate":"2024-07-04","timestamp":1720000448000,"abstract":"  This work addresses the timely yet underexplored problem of performing\ninference and finetuning of a proprietary LLM owned by a model provider entity\non the confidential/private data of another data owner entity, in a way that\nensures the confidentiality of both the model and the data. Hereby, the\nfinetuning is conducted offsite, i.e., on the computation infrastructure of a\nthird-party cloud provider. We tackle this problem by proposing ObfuscaTune, a\nnovel, efficient and fully utility-preserving approach that combines a simple\nyet effective obfuscation technique with an efficient usage of confidential\ncomputing (only 5% of the model parameters are placed on TEE). We empirically\ndemonstrate the effectiveness of ObfuscaTune by validating it on GPT-2 models\nwith different sizes on four NLP benchmark datasets. Finally, we compare to a\nna\\\"ive version of our approach to highlight the necessity of using random\nmatrices with low condition numbers in our approach to reduce errors induced by\nthe obfuscation.\n","subjects":["Computing Research Repository/Cryptography and Security","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}