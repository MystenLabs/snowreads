{"id":"2408.09818","title":"Liquid Fourier Latent Dynamics Networks for fast GPU-based numerical\n  simulations in computational cardiology","authors":"Matteo Salvador and Alison L. Marsden","authorsParsed":[["Salvador","Matteo",""],["Marsden","Alison L.",""]],"versions":[{"version":"v1","created":"Mon, 19 Aug 2024 09:14:25 GMT"}],"updateDate":"2024-08-20","timestamp":1724058865000,"abstract":"  Scientific Machine Learning (ML) is gaining momentum as a cost-effective\nalternative to physics-based numerical solvers in many engineering\napplications. In fact, scientific ML is currently being used to build accurate\nand efficient surrogate models starting from high-fidelity numerical\nsimulations, effectively encoding the parameterized temporal dynamics\nunderlying Ordinary Differential Equations (ODEs), or even the spatio-temporal\nbehavior underlying Partial Differential Equations (PDEs), in appropriately\ndesigned neural networks. We propose an extension of Latent Dynamics Networks\n(LDNets), namely Liquid Fourier LDNets (LFLDNets), to create parameterized\nspace-time surrogate models for multiscale and multiphysics sets of highly\nnonlinear differential equations on complex geometries. LFLDNets employ a\nneurologically-inspired, sparse, liquid neural network for temporal dynamics,\nrelaxing the requirement of a numerical solver for time advancement and leading\nto superior performance in terms of tunable parameters, accuracy, efficiency\nand learned trajectories with respect to neural ODEs based on feedforward\nfully-connected neural networks. Furthermore, in our implementation of\nLFLDNets, we use a Fourier embedding with a tunable kernel in the\nreconstruction network to learn high-frequency functions better and faster than\nusing space coordinates directly as input. We challenge LFLDNets in the\nframework of computational cardiology and evaluate their capabilities on two\n3-dimensional test cases arising from multiscale cardiac electrophysiology and\ncardiovascular hemodynamics. This paper illustrates the capability to run\nArtificial Intelligence-based numerical simulations on single or multiple GPUs\nin a matter of minutes and represents a significant step forward in the\ndevelopment of physics-informed digital twins.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Computational Engineering, Finance, and Science","Computing Research Repository/Neural and Evolutionary Computing"],"license":"http://creativecommons.org/licenses/by/4.0/"}