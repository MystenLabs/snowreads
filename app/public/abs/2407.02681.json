{"id":"2407.02681","title":"Uniform Transformation: Refining Latent Representation in Variational\n  Autoencoders","authors":"Ye Shi and C.S. George Lee","authorsParsed":[["Shi","Ye",""],["Lee","C. S. George",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 21:46:23 GMT"}],"updateDate":"2024-07-04","timestamp":1719956783000,"abstract":"  Irregular distribution in latent space causes posterior collapse,\nmisalignment between posterior and prior, and ill-sampling problem in\nVariational Autoencoders (VAEs). In this paper, we introduce a novel adaptable\nthree-stage Uniform Transformation (UT) module -- Gaussian Kernel Density\nEstimation (G-KDE) clustering, non-parametric Gaussian Mixture (GM) Modeling,\nand Probability Integral Transform (PIT) -- to address irregular latent\ndistributions. By reconfiguring irregular distributions into a uniform\ndistribution in the latent space, our approach significantly enhances the\ndisentanglement and interpretability of latent representations, overcoming the\nlimitation of traditional VAE models in capturing complex data structures.\nEmpirical evaluations demonstrated the efficacy of our proposed UT module in\nimproving disentanglement metrics across benchmark datasets -- dSprites and\nMNIST. Our findings suggest a promising direction for advancing representation\nlearning techniques, with implication for future research in extending this\nframework to more sophisticated datasets and downstream tasks.\n","subjects":["Computing Research Repository/Machine Learning","Electrical Engineering and Systems Science/Image and Video Processing","Mathematics/Optimization and Control","Statistics/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}