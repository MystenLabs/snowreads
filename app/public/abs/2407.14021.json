{"id":"2407.14021","title":"GE2E-AC: Generalized End-to-End Loss Training for Accent Classification","authors":"Chihiro Watanabe, Hirokazu Kameoka","authorsParsed":[["Watanabe","Chihiro",""],["Kameoka","Hirokazu",""]],"versions":[{"version":"v1","created":"Fri, 19 Jul 2024 04:44:16 GMT"}],"updateDate":"2024-07-22","timestamp":1721364256000,"abstract":"  Accent classification or AC is a task to predict the accent type of an input\nutterance, and it can be used as a preliminary step toward accented speech\nrecognition and accent conversion. Existing studies have often achieved such\nclassification by training a neural network model to minimize the\nclassification error of the predicted accent label, which can be obtained as a\nmodel output. Since we optimize the entire model only from the perspective of\nclassification loss during training time in this approach, the model might\nlearn to predict the accent type from irrelevant features, such as individual\nspeaker identity, which are not informative during test time. To address this\nproblem, we propose a GE2E-AC, in which we train a model to extract accent\nembedding or AE of an input utterance such that the AEs of the same accent\nclass get closer, instead of directly minimizing the classification loss. We\nexperimentally show the effectiveness of the proposed GE2E-AC, compared to the\nbaseline model trained with the conventional cross-entropy-based loss.\n","subjects":["Electrical Engineering and Systems Science/Audio and Speech Processing","Computing Research Repository/Sound","Statistics/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}