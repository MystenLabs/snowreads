{"id":"2408.10468","title":"Tracing Privacy Leakage of Language Models to Training Data via Adjusted\n  Influence Functions","authors":"Jinxin Liu and Zao Yang","authorsParsed":[["Liu","Jinxin",""],["Yang","Zao",""]],"versions":[{"version":"v1","created":"Tue, 20 Aug 2024 00:40:49 GMT"},{"version":"v2","created":"Wed, 21 Aug 2024 14:35:48 GMT"},{"version":"v3","created":"Mon, 26 Aug 2024 17:28:23 GMT"},{"version":"v4","created":"Thu, 5 Sep 2024 15:47:45 GMT"}],"updateDate":"2024-09-06","timestamp":1724114449000,"abstract":"  The responses generated by Large Language Models (LLMs) can include sensitive\ninformation from individuals and organizations, leading to potential privacy\nleakage. This work implements Influence Functions (IFs) to trace privacy\nleakage back to the training data, thereby mitigating privacy concerns of\nLanguage Models (LMs). However, we notice that current IFs struggle to\naccurately estimate the influence of tokens with large gradient norms,\npotentially overestimating their influence. When tracing the most influential\nsamples, this leads to frequently tracing back to samples with large gradient\nnorm tokens, overshadowing the actual most influential samples even if their\ninfluences are well estimated. To address this issue, we propose Heuristically\nAdjusted IF (HAIF), which reduces the weight of tokens with large gradient\nnorms, thereby significantly improving the accuracy of tracing the most\ninfluential samples. To establish easily obtained groundtruth for tracing\nprivacy leakage, we construct two datasets, PII-E and PII-CR, representing two\ndistinct scenarios: one with identical text in the model outputs and\npre-training data, and the other where models leverage their reasoning\nabilities to generate text divergent from pre-training data. HAIF significantly\nimproves tracing accuracy, enhancing it by 20.96% to 73.71% on the PII-E\ndataset and 3.21% to 45.93% on the PII-CR dataset, compared to the best SOTA\nIFs against various GPT-2 and QWen-1.5 models. HAIF also outperforms SOTA IFs\non real-world pretraining data CLUECorpus2020, demonstrating strong robustness\nregardless prompt and response lengths.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Computation and Language","Computing Research Repository/Cryptography and Security"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"DHyvlyqsp2b9Dh2u6CSIHsHd_-5DQvkyOumGbFia5Xc","pdfSize":"662474"}
