{"id":"2407.03131","title":"MVGT: A Multi-view Graph Transformer Based on Spatial Relations for EEG\n  Emotion Recognition","authors":"Yanjie Cui, Xiaohong Liu, Jing Liang, Yamin Fu","authorsParsed":[["Cui","Yanjie",""],["Liu","Xiaohong",""],["Liang","Jing",""],["Fu","Yamin",""]],"versions":[{"version":"v1","created":"Wed, 3 Jul 2024 14:13:00 GMT"},{"version":"v2","created":"Mon, 8 Jul 2024 13:11:53 GMT"},{"version":"v3","created":"Tue, 6 Aug 2024 09:21:47 GMT"}],"updateDate":"2024-08-07","timestamp":1720015980000,"abstract":"  Electroencephalography (EEG), a medical imaging technique that captures scalp\nelectrical activity of brain structures via electrodes, has been widely used in\naffective computing. The spatial domain of EEG is rich in affective\ninformation. However, few of the existing studies have simultaneously analyzed\nEEG signals from multiple perspectives of geometric and anatomical structures\nin spatial domain. In this paper, we propose a multi-view Graph Transformer\n(MVGT) based on spatial relations, which integrates information from the\ntemporal, frequency and spatial domains, including geometric and anatomical\nstructures, so as to enhance the expressive power of the model comprehensively.\nWe incorporate the spatial information of EEG channels into the model as\nencoding, thereby improving its ability to perceive the spatial structure of\nthe channels. Meanwhile, experimental results based on publicly available\ndatasets demonstrate that our proposed model outperforms state-of-the-art\nmethods in recent years. In addition, the results also show that the MVGT could\nextract information from multiple domains and capture inter-channel\nrelationships in EEG emotion recognition tasks effectively.\n","subjects":["Computing Research Repository/Neural and Evolutionary Computing","Computing Research Repository/Artificial Intelligence","Electrical Engineering and Systems Science/Signal Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}