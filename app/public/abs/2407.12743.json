{"id":"2407.12743","title":"TalTech-IRIT-LIS Speaker and Language Diarization Systems for DISPLACE\n  2024","authors":"Joonas Kalda, Tanel Alum\\\"ae, Martin Lebourdais, Herv\\'e Bredin,\n  S\\'everin Baroudi, Ricard Marxer","authorsParsed":[["Kalda","Joonas",""],["Alumäe","Tanel",""],["Lebourdais","Martin",""],["Bredin","Hervé",""],["Baroudi","Séverin",""],["Marxer","Ricard",""]],"versions":[{"version":"v1","created":"Wed, 17 Jul 2024 17:02:21 GMT"}],"updateDate":"2024-07-18","timestamp":1721235741000,"abstract":"  This paper describes the submissions of team TalTech-IRIT-LIS to the DISPLACE\n2024 challenge. Our team participated in the speaker diarization and language\ndiarization tracks of the challenge. In the speaker diarization track, our best\nsubmission was an ensemble of systems based on the pyannote.audio speaker\ndiarization pipeline utilizing powerset training and our recently proposed\nPixIT method that performs joint diarization and speech separation. We improve\nupon PixIT by using the separation outputs for speaker embedding extraction.\nOur ensemble achieved a diarization error rate of 27.1% on the evaluation\ndataset. In the language diarization track, we fine-tuned a pre-trained\nWav2Vec2-BERT language embedding model on in-domain data, and clustered short\nsegments using AHC and VBx, based on similarity scores from LDA/PLDA. This led\nto a language diarization error rate of 27.6% on the evaluation data. Both\nresults were ranked first in their respective challenge tracks.\n","subjects":["Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/"}