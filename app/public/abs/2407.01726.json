{"id":"2407.01726","title":"Grouped Discrete Representation Guides Object-Centric Learning","authors":"Rongzhen Zhao, Vivienne Wang, Juho Kannala, Joni Pajarinen","authorsParsed":[["Zhao","Rongzhen",""],["Wang","Vivienne",""],["Kannala","Juho",""],["Pajarinen","Joni",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 19:00:40 GMT"}],"updateDate":"2024-07-03","timestamp":1719860440000,"abstract":"  Similar to humans perceiving visual scenes as objects, Object-Centric\nLearning (OCL) can abstract dense images or videos into sparse object-level\nfeatures. Transformer-based OCL handles complex textures well due to the\ndecoding guidance of discrete representation, obtained by discretizing noisy\nfeatures in image or video feature maps using template features from a\ncodebook. However, treating features as minimal units overlooks their composing\nattributes, thus impeding model generalization; indexing features with natural\nnumbers loses attribute-level commonalities and characteristics, thus\ndiminishing heuristics for model convergence. We propose \\textit{Grouped\nDiscrete Representation} (GDR) to address these issues by grouping features\ninto attributes and indexing them with tuple numbers. In extensive experiments\nacross different query initializations, dataset modalities, and model\narchitectures, GDR consistently improves convergence and generalizability.\nVisualizations show that our method effectively captures attribute-level\ninformation in features. The source code will be available upon acceptance.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}