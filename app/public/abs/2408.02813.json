{"id":"2408.02813","title":"Mitigating Malicious Attacks in Federated Learning via Confidence-aware\n  Defense","authors":"Qilei Li, Ahmed M. Abdelmoniem","authorsParsed":[["Li","Qilei",""],["Abdelmoniem","Ahmed M.",""]],"versions":[{"version":"v1","created":"Mon, 5 Aug 2024 20:27:45 GMT"},{"version":"v2","created":"Fri, 16 Aug 2024 19:02:39 GMT"}],"updateDate":"2024-08-20","timestamp":1722889665000,"abstract":"  Federated Learning (FL) is a distributed machine learning diagram that\nenables multiple clients to collaboratively train a global model without\nsharing their private local data. However, FL systems are vulnerable to attacks\nthat are happening in malicious clients through data poisoning and model\npoisoning, which can deteriorate the performance of aggregated global model.\nExisting defense methods typically focus on mitigating specific types of\npoisoning and are often ineffective against unseen types of attack. These\nmethods also assume an attack happened moderately while is not always holds\ntrue in real. Consequently, these methods can significantly fail in terms of\naccuracy and robustness when detecting and addressing updates from attacked\nmalicious clients. To overcome these challenges, in this work, we propose a\nsimple yet effective framework to detect malicious clients, namely\nConfidence-Aware Defense (CAD), that utilizes the confidence scores of local\nmodels as criteria to evaluate the reliability of local updates. Our key\ninsight is that malicious attacks, regardless of attack type, will cause the\nmodel to deviate from its previous state, thus leading to increased uncertainty\nwhen making predictions. Therefore, CAD is comprehensively effective for both\nmodel poisoning and data poisoning attacks by accurately identifying and\nmitigating potential malicious updates, even under varying degrees of attacks\nand data heterogeneity. Experimental results demonstrate that our method\nsignificantly enhances the robustness of FL systems against various types of\nattacks across various scenarios by achieving higher model accuracy and\nstability.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Cryptography and Security","Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Distributed, Parallel, and Cluster Computing"],"license":"http://creativecommons.org/licenses/by/4.0/"}