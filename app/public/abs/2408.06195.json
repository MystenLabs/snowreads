{"id":"2408.06195","title":"Mutual Reasoning Makes Smaller LLMs Stronger Problem-Solvers","authors":"Zhenting Qi, Mingyuan Ma, Jiahang Xu, Li Lyna Zhang, Fan Yang, Mao\n  Yang","authorsParsed":[["Qi","Zhenting",""],["Ma","Mingyuan",""],["Xu","Jiahang",""],["Zhang","Li Lyna",""],["Yang","Fan",""],["Yang","Mao",""]],"versions":[{"version":"v1","created":"Mon, 12 Aug 2024 14:42:13 GMT"}],"updateDate":"2024-08-13","timestamp":1723473733000,"abstract":"  This paper introduces rStar, a self-play mutual reasoning approach that\nsignificantly improves reasoning capabilities of small language models (SLMs)\nwithout fine-tuning or superior models. rStar decouples reasoning into a\nself-play mutual generation-discrimination process. First, a target SLM\naugments the Monte Carlo Tree Search (MCTS) with a rich set of human-like\nreasoning actions to construct higher quality reasoning trajectories. Next,\nanother SLM, with capabilities similar to the target SLM, acts as a\ndiscriminator to verify each trajectory generated by the target SLM. The\nmutually agreed reasoning trajectories are considered mutual consistent, thus\nare more likely to be correct. Extensive experiments across five SLMs\ndemonstrate rStar can effectively solve diverse reasoning problems, including\nGSM8K, GSM-Hard, MATH, SVAMP, and StrategyQA. Remarkably, rStar boosts GSM8K\naccuracy from 12.51% to 63.91% for LLaMA2-7B, from 36.46% to 81.88% for\nMistral-7B, from 74.53% to 91.13% for LLaMA3-8B-Instruct. Code will be\navailable at https://github.com/zhentingqi/rStar.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"ueGFpfaRmedvu_B41I2qvHrxhMl3gaQoFb9ZPY13-0I","pdfSize":"1106056"}
