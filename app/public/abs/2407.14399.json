{"id":"2407.14399","title":"PolySinger: Singing-Voice to Singing-Voice Translation from English to\n  Japanese","authors":"Silas Antonisen and Iv\\'an L\\'opez-Espejo","authorsParsed":[["Antonisen","Silas",""],["López-Espejo","Iván",""]],"versions":[{"version":"v1","created":"Fri, 19 Jul 2024 15:21:14 GMT"}],"updateDate":"2024-07-22","timestamp":1721402474000,"abstract":"  The speech domain prevails in the spotlight for several natural language\nprocessing (NLP) tasks while the singing domain remains less explored. The\nculmination of NLP is the speech-to-speech translation (S2ST) task, referring\nto translation and synthesis of human speech. A disparity between S2ST and the\npossible adaptation to the singing domain, which we describe as singing-voice\nto singing-voice translation (SV2SVT), is becoming prominent as the former is\nprogressing ever faster, while the latter is at a standstill. Singing-voice\nsynthesis systems are overcoming the barrier of multi-lingual synthesis,\ndespite limited attention has been paid to multi-lingual songwriting and song\ntranslation. This paper endeavors to determine what is required for successful\nSV2SVT and proposes PolySinger (Polyglot Singer): the first system for SV2SVT,\nperforming lyrics translation from English to Japanese. A cascaded approach is\nproposed to establish a framework with a high degree of control which can\npotentially diminish the disparity between SV2SVT and S2ST. The performance of\nPolySinger is evaluated by a mean opinion score test with native Japanese\nspeakers. Results and in-depth discussions with test subjects suggest a solid\nfoundation for SV2SVT, but several shortcomings must be overcome, which are\ndiscussed for the future of SV2SVT.\n","subjects":["Electrical Engineering and Systems Science/Audio and Speech Processing","Computing Research Repository/Information Retrieval"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}