{"id":"2407.02457","title":"Volume Tracking Based Reference Mesh Extraction for Time-Varying Mesh\n  Compression","authors":"Guodong Chen, Libor Vasa, Fulin Wang, Mallesham Dasari","authorsParsed":[["Chen","Guodong",""],["Vasa","Libor",""],["Wang","Fulin",""],["Dasari","Mallesham",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 17:33:37 GMT"}],"updateDate":"2024-07-03","timestamp":1719941617000,"abstract":"  Time-Varying meshes (TVMs), characterized by their varying connectivity and\nnumber of vertices, hold significant potential in immersive media and other\nvarious applications. However, their practical utilization is challenging due\nto their time-varying features and large file sizes. Creating a reference mesh\nthat contains the most essential information is a promising approach to\nutilizing shared information within TVMs to reduce storage and transmission\ncosts. We propose a novel method that employs volume tracking to extract\nreference meshes. First, we adopt as-rigid-as-possible (ARAP) volume tracking\non TVMs to get the volume centers for each mesh. Then, we use multidimensional\nscaling (MDS) to get reference centers that ensure the reference mesh avoids\nself-contact regions. Finally, we map the vertices of the meshes to reference\ncenters and extract the reference mesh. Our approach offers a feasible solution\nfor extracting reference meshes that can serve multiple purposes such as\nestablishing surface correspondence, deforming the reference mesh to different\nshapes for I-frame based mesh compression, or defining the global shape of the\nTVMs.\n","subjects":["Computing Research Repository/Multimedia"],"license":"http://creativecommons.org/publicdomain/zero/1.0/"}