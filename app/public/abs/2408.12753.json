{"id":"2408.12753","title":"Contrastive Representation Learning for Dynamic Link Prediction in\n  Temporal Networks","authors":"Amirhossein Nouranizadeh, Fatemeh Tabatabaei Far, Mohammad Rahmati","authorsParsed":[["Nouranizadeh","Amirhossein",""],["Far","Fatemeh Tabatabaei",""],["Rahmati","Mohammad",""]],"versions":[{"version":"v1","created":"Thu, 22 Aug 2024 22:50:46 GMT"}],"updateDate":"2024-08-26","timestamp":1724367046000,"abstract":"  Evolving networks are complex data structures that emerge in a wide range of\nsystems in science and engineering. Learning expressive representations for\nsuch networks that encode their structural connectivity and temporal evolution\nis essential for downstream data analytics and machine learning applications.\nIn this study, we introduce a self-supervised method for learning\nrepresentations of temporal networks and employ these representations in the\ndynamic link prediction task. While temporal networks are typically\ncharacterized as a sequence of interactions over the continuous time domain,\nour study focuses on their discrete-time versions. This enables us to balance\nthe trade-off between computational complexity and precise modeling of the\ninteractions. We propose a recurrent message-passing neural network\narchitecture for modeling the information flow over time-respecting paths of\ntemporal networks. The key feature of our method is the contrastive training\nobjective of the model, which is a combination of three loss functions: link\nprediction, graph reconstruction, and contrastive predictive coding losses. The\ncontrastive predictive coding objective is implemented using infoNCE losses at\nboth local and global scales of the input graphs. We empirically show that the\nadditional self-supervised losses enhance the training and improve the model's\nperformance in the dynamic link prediction task. The proposed method is tested\non Enron, COLAB, and Facebook datasets and exhibits superior results compared\nto existing models.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Neural and Evolutionary Computing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}