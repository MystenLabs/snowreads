{"id":"2408.03490","title":"Simultaneous and Meshfree Topology Optimization with Physics-informed\n  Gaussian Processes","authors":"Amin Yousefpour, Shirin Hosseinmardi, Carlos Mora, Ramin Bostanabad","authorsParsed":[["Yousefpour","Amin",""],["Hosseinmardi","Shirin",""],["Mora","Carlos",""],["Bostanabad","Ramin",""]],"versions":[{"version":"v1","created":"Wed, 7 Aug 2024 01:01:35 GMT"}],"updateDate":"2024-08-08","timestamp":1722992495000,"abstract":"  Topology optimization (TO) provides a principled mathematical approach for\noptimizing the performance of a structure by designing its material spatial\ndistribution in a pre-defined domain and subject to a set of constraints. The\nmajority of existing TO approaches leverage numerical solvers for design\nevaluations during the optimization and hence have a nested nature and rely on\ndiscretizing the design variables. Contrary to these approaches, herein we\ndevelop a new class of TO methods based on the framework of Gaussian processes\n(GPs) whose mean functions are parameterized via deep neural networks.\nSpecifically, we place GP priors on all design and state variables to represent\nthem via parameterized continuous functions. These GPs share a deep neural\nnetwork as their mean function but have as many independent kernels as there\nare state and design variables. We estimate all the parameters of our model in\na single for loop that optimizes a penalized version of the performance metric\nwhere the penalty terms correspond to the state equations and design\nconstraints. Attractive features of our approach include $(1)$ having a\nbuilt-in continuation nature since the performance metric is optimized at the\nsame time that the state equations are solved, and $(2)$ being\ndiscretization-invariant and accommodating complex domains and topologies. To\ntest our method against conventional TO approaches implemented in commercial\nsoftware, we evaluate it on four problems involving the minimization of\ndissipated power in Stokes flow. The results indicate that our approach does\nnot need filtering techniques, has consistent computational costs, and is\nhighly robust against random initializations and problem setup.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}