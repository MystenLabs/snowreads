{"id":"2407.10811","title":"GuideLight: \"Industrial Solution\" Guidance for More Practical Traffic\n  Signal Control Agents","authors":"Haoyuan Jiang, Xuantang Xiong, Ziyue Li, Hangyu Mao, Guanghu Sui,\n  Jingqing Ruan, Yuheng Cheng, Hua Wei, Wolfgang Ketter, Rui Zhao","authorsParsed":[["Jiang","Haoyuan",""],["Xiong","Xuantang",""],["Li","Ziyue",""],["Mao","Hangyu",""],["Sui","Guanghu",""],["Ruan","Jingqing",""],["Cheng","Yuheng",""],["Wei","Hua",""],["Ketter","Wolfgang",""],["Zhao","Rui",""]],"versions":[{"version":"v1","created":"Mon, 15 Jul 2024 15:26:10 GMT"}],"updateDate":"2024-07-16","timestamp":1721057170000,"abstract":"  Currently, traffic signal control (TSC) methods based on reinforcement\nlearning (RL) have proven superior to traditional methods. However, most RL\nmethods face difficulties when applied in the real world due to three factors:\ninput, output, and the cycle-flow relation. The industry's observable input is\nmuch more limited than simulation-based RL methods. For real-world solutions,\nonly flow can be reliably collected, whereas common RL methods need more. For\nthe output action, most RL methods focus on acyclic control, which real-world\nsignal controllers do not support. Most importantly, industry standards require\na consistent cycle-flow relationship: non-decreasing and different response\nstrategies for low, medium, and high-level flows, which is ignored by the RL\nmethods. To narrow the gap between RL methods and industry standards, we\ninnovatively propose to use industry solutions to guide the RL agent.\nSpecifically, we design behavior cloning and curriculum learning to guide the\nagent to mimic and meet industry requirements and, at the same time, leverage\nthe power of exploration and exploitation in RL for better performance. We\ntheoretically prove that such guidance can largely decrease the sample\ncomplexity to polynomials in the horizon when searching for an optimal policy.\nOur rigid experiments show that our method has good cycle-flow relation and\nsuperior performance.\n","subjects":["Computing Research Repository/Multiagent Systems","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}