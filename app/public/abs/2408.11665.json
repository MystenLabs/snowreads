{"id":"2408.11665","title":"Online state vector reduction during model predictive control with\n  gradient-based trajectory optimisation","authors":"David Russell, Rafael Papallas, Mehmet Dogar","authorsParsed":[["Russell","David",""],["Papallas","Rafael",""],["Dogar","Mehmet",""]],"versions":[{"version":"v1","created":"Wed, 21 Aug 2024 14:39:14 GMT"},{"version":"v2","created":"Thu, 12 Sep 2024 14:23:43 GMT"}],"updateDate":"2024-09-13","timestamp":1724251154000,"abstract":"  Non-prehensile manipulation in high-dimensional systems is challenging for a\nvariety of reasons. One of the main reasons is the computationally long\nplanning times that come with a large state space. Trajectory optimisation\nalgorithms have proved their utility in a wide variety of tasks, but, like most\nmethods struggle scaling to the high dimensional systems ubiquitous to\nnon-prehensile manipulation in clutter as well as deformable object\nmanipulation. We reason that, during manipulation, different degrees of freedom\nwill become more or less important to the task over time as the system evolves.\nWe leverage this idea to reduce the number of degrees of freedom considered in\na trajectory optimisation problem, to reduce planning times. This idea is\nparticularly relevant in the context of model predictive control (MPC) where\nthe cost landscape of the optimisation problem is constantly evolving. We\nprovide simulation results under asynchronous MPC and show our methods are\ncapable of achieving better overall performance due to the decreased policy lag\nwhilst still being able to optimise trajectories effectively.\n","subjects":["Computing Research Repository/Robotics"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}