{"id":"2407.02870","title":"Membership Inference Attacks Against Time-Series Models","authors":"Noam Koren, Abigail Goldsteen, Ariel Farkash, Guy Amit","authorsParsed":[["Koren","Noam",""],["Goldsteen","Abigail",""],["Farkash","Ariel",""],["Amit","Guy",""]],"versions":[{"version":"v1","created":"Wed, 3 Jul 2024 07:34:49 GMT"}],"updateDate":"2024-07-04","timestamp":1719992089000,"abstract":"  Analyzing time-series data that may contain personal information,\nparticularly in the medical field, presents serious privacy concerns. Sensitive\nhealth data from patients is often used to train machine-learning models for\ndiagnostics and ongoing care. Assessing the privacy risk of such models is\ncrucial to making knowledgeable decisions on whether to use a model in\nproduction, share it with third parties, or deploy it in patients homes.\nMembership Inference Attacks (MIA) are a key method for this kind of\nevaluation, however time-series prediction models have not been thoroughly\nstudied in this context. We explore existing MIA techniques on time-series\nmodels, and introduce new features, focusing on the seasonality and trend\ncomponents of the data. Seasonality is estimated using a multivariate Fourier\ntransform, and a low-degree polynomial is used to approximate trends. We\napplied these techniques to various types of time-series models, using datasets\nfrom the health domain. Our results demonstrate that these new features enhance\nthe effectiveness of MIAs in identifying membership, improving the\nunderstanding of privacy risks in medical data applications.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/"}