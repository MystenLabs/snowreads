{"id":"2407.04258","title":"Unsupervised Video Summarization via Reinforcement Learning and a\n  Trained Evaluator","authors":"Mehryar Abbasi, Hadi Hadizadeh, Parvaneh Saeedi","authorsParsed":[["Abbasi","Mehryar",""],["Hadizadeh","Hadi",""],["Saeedi","Parvaneh",""]],"versions":[{"version":"v1","created":"Fri, 5 Jul 2024 05:08:06 GMT"}],"updateDate":"2024-07-08","timestamp":1720156086000,"abstract":"  This paper presents a novel approach for unsupervised video summarization\nusing reinforcement learning. It aims to address the existing limitations of\ncurrent unsupervised methods, including unstable training of adversarial\ngenerator-discriminator architectures and reliance on hand-crafted reward\nfunctions for quality evaluation. The proposed method is based on the concept\nthat a concise and informative summary should result in a reconstructed video\nthat closely resembles the original. The summarizer model assigns an importance\nscore to each frame and generates a video summary. In the proposed scheme,\nreinforcement learning, coupled with a unique reward generation pipeline, is\nemployed to train the summarizer model. The reward generation pipeline trains\nthe summarizer to create summaries that lead to improved reconstructions. It\ncomprises a generator model capable of reconstructing masked frames from a\npartially masked video, along with a reward mechanism that compares the\nreconstructed video from the summary against the original. The video generator\nis trained in a self-supervised manner to reconstruct randomly masked frames,\nenhancing its ability to generate accurate summaries. This training pipeline\nresults in a summarizer model that better mimics human-generated video\nsummaries compared to methods relying on hand-crafted rewards. The training\nprocess consists of two stable and isolated training steps, unlike adversarial\narchitectures. Experimental results demonstrate promising performance, with\nF-scores of 62.3 and 54.5 on TVSum and SumMe datasets, respectively.\nAdditionally, the inference stage is 300 times faster than our previously\nreported state-of-the-art method.\n","subjects":["Computing Research Repository/Multimedia","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}