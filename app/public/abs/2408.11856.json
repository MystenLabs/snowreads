{"id":"2408.11856","title":"Dynamic Adaptive Optimization for Effective Sentiment Analysis\n  Fine-Tuning on Large Language Models","authors":"Hongcheng Ding, Xuanze Zhao, Shamsul Nahar Abdullah, Deshinta Arrova\n  Dewi, Zixiao Jiang","authorsParsed":[["Ding","Hongcheng",""],["Zhao","Xuanze",""],["Abdullah","Shamsul Nahar",""],["Dewi","Deshinta Arrova",""],["Jiang","Zixiao",""]],"versions":[{"version":"v1","created":"Thu, 15 Aug 2024 19:13:38 GMT"}],"updateDate":"2024-08-26","timestamp":1723749218000,"abstract":"  Sentiment analysis plays a crucial role in various domains, such as business\nintelligence and financial forecasting. Large language models (LLMs) have\nbecome a popular paradigm for sentiment analysis, leveraging multi-task\nlearning to address specific tasks concurrently. However, LLMs with fine-tuning\nfor sentiment analysis often underperforms due to the inherent challenges in\nmanaging diverse task complexities. Moreover, constant-weight approaches in\nmulti-task learning struggle to adapt to variations in data characteristics,\nfurther complicating model effectiveness. To address these issues, we propose a\nnovel multi-task learning framework with a dynamic adaptive optimization (DAO)\nmodule. This module is designed as a plug-and-play component that can be\nseamlessly integrated into existing models, providing an effective and flexible\nsolution for multi-task learning. The key component of the DAO module is\ndynamic adaptive loss, which dynamically adjusts the weights assigned to\ndifferent tasks based on their relative importance and data characteristics\nduring training. Sentiment analyses on a standard and customized financial text\ndataset demonstrate that the proposed framework achieves superior performance.\nSpecifically, this work improves the Mean Squared Error (MSE) and Accuracy\n(ACC) by 15.58% and 1.24% respectively, compared with previous work.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}