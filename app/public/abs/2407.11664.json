{"id":"2407.11664","title":"Mask-guided cross-image attention for zero-shot in-silico\n  histopathologic image generation with a diffusion model","authors":"Dominik Winter, Nicolas Triltsch, Marco Rosati, Anatoliy Shumilov,\n  Ziya Kokaragac, Yuri Popov, Thomas Padel, Laura Sebastian Monasor, Ross Hill,\n  Markus Schick, Nicolas Brieu","authorsParsed":[["Winter","Dominik",""],["Triltsch","Nicolas",""],["Rosati","Marco",""],["Shumilov","Anatoliy",""],["Kokaragac","Ziya",""],["Popov","Yuri",""],["Padel","Thomas",""],["Monasor","Laura Sebastian",""],["Hill","Ross",""],["Schick","Markus",""],["Brieu","Nicolas",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 12:36:26 GMT"}],"updateDate":"2024-07-17","timestamp":1721133386000,"abstract":"  Creating in-silico data with generative AI promises a cost-effective\nalternative to staining, imaging, and annotating whole slide images in\ncomputational pathology. Diffusion models are the state-of-the-art solution for\ngenerating in-silico images, offering unparalleled fidelity and realism. Using\nappearance transfer diffusion models allows for zero-shot image generation,\nfacilitating fast application and making model training unnecessary. However\ncurrent appearance transfer diffusion models are designed for natural images,\nwhere the main task is to transfer the foreground object from an origin to a\ntarget domain, while the background is of insignificant importance. In\ncomputational pathology, specifically in oncology, it is however not\nstraightforward to define which objects in an image should be classified as\nforeground and background, as all objects in an image may be of critical\nimportance for the detailed understanding the tumor micro-environment. We\ncontribute to the applicability of appearance transfer diffusion models to\nimmunohistochemistry-stained images by modifying the appearance transfer\nguidance to alternate between class-specific AdaIN feature statistics matchings\nusing existing segmentation masks. The performance of the proposed method is\ndemonstrated on the downstream task of supervised epithelium segmentation,\nshowing that the number of manual annotations required for model training can\nbe reduced by 75%, outperforming the baseline approach. Additionally, we\nconsulted with a certified pathologist to investigate future improvements. We\nanticipate this work to inspire the application of zero-shot diffusion models\nin computational pathology, providing an efficient method to generate in-silico\nimages with unmatched fidelity and realism, which prove meaningful for\ndownstream tasks, such as training existing deep learning models or finetuning\nfoundation models.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"WNmsrDpnRtvrjsmqRB8ZwjPnnee06j7CkQmytXvufZk","pdfSize":"4014124"}
