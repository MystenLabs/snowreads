{"id":"2407.00943","title":"FedEx: Expediting Federated Learning over Heterogeneous Mobile Devices\n  by Overlapping and Participant Selection","authors":"Jiaxiang Geng, Boyu Li, Xiaoqi Qin, Yixuan Li, Liang Li, Yanzhao Hou,\n  Miao Pan","authorsParsed":[["Geng","Jiaxiang",""],["Li","Boyu",""],["Qin","Xiaoqi",""],["Li","Yixuan",""],["Li","Liang",""],["Hou","Yanzhao",""],["Pan","Miao",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 03:52:22 GMT"},{"version":"v2","created":"Tue, 2 Jul 2024 06:16:36 GMT"}],"updateDate":"2024-07-04","timestamp":1719805942000,"abstract":"  Training latency is critical for the success of numerous intrigued\napplications ignited by federated learning (FL) over heterogeneous mobile\ndevices. By revolutionarily overlapping local gradient transmission with\ncontinuous local computing, FL can remarkably reduce its training latency over\nhomogeneous clients, yet encounter severe model staleness, model drifts, memory\ncost and straggler issues in heterogeneous environments. To unleash the full\npotential of overlapping, we propose, FedEx, a novel \\underline{fed}erated\nlearning approach to \\underline{ex}pedite FL training over mobile devices under\ndata, computing and wireless heterogeneity. FedEx redefines the overlapping\nprocedure with staleness ceilings to constrain memory consumption and make\noverlapping compatible with participation selection (PS) designs. Then, FedEx\ncharacterizes the PS utility function by considering the latency reduced by\noverlapping, and provides a holistic PS solution to address the straggler\nissue. FedEx also introduces a simple but effective metric to trigger\noverlapping, in order to avoid model drifts. Experimental results show that\ncompared with its peer designs, FedEx demonstrates substantial reductions in FL\ntraining latency over heterogeneous mobile devices with limited memory cost.\n","subjects":["Computing Research Repository/Distributed, Parallel, and Cluster Computing","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}