{"id":"2407.05623","title":"Momentum Auxiliary Network for Supervised Local Learning","authors":"Junhao Su, Changpeng Cai, Feiyu Zhu, Chenghao He, Xiaojie Xu, Dongzhi\n  Guan, Chenyang Si","authorsParsed":[["Su","Junhao",""],["Cai","Changpeng",""],["Zhu","Feiyu",""],["He","Chenghao",""],["Xu","Xiaojie",""],["Guan","Dongzhi",""],["Si","Chenyang",""]],"versions":[{"version":"v1","created":"Mon, 8 Jul 2024 05:31:51 GMT"},{"version":"v2","created":"Tue, 9 Jul 2024 15:21:35 GMT"},{"version":"v3","created":"Thu, 25 Jul 2024 01:59:16 GMT"},{"version":"v4","created":"Mon, 12 Aug 2024 12:47:11 GMT"}],"updateDate":"2024-08-13","timestamp":1720416711000,"abstract":"  Deep neural networks conventionally employ end-to-end backpropagation for\ntheir training process, which lacks biological credibility and triggers a\nlocking dilemma during network parameter updates, leading to significant GPU\nmemory use. Supervised local learning, which segments the network into multiple\nlocal blocks updated by independent auxiliary networks. However, these methods\ncannot replace end-to-end training due to lower accuracy, as gradients only\npropagate within their local block, creating a lack of information exchange\nbetween blocks. To address this issue and establish information transfer across\nblocks, we propose a Momentum Auxiliary Network (MAN) that establishes a\ndynamic interaction mechanism. The MAN leverages an exponential moving average\n(EMA) of the parameters from adjacent local blocks to enhance information flow.\nThis auxiliary network, updated through EMA, helps bridge the informational gap\nbetween blocks. Nevertheless, we observe that directly applying EMA parameters\nhas certain limitations due to feature discrepancies among local blocks. To\novercome this, we introduce learnable biases, further boosting performance. We\nhave validated our method on four image classification datasets (CIFAR-10,\nSTL-10, SVHN, ImageNet), attaining superior performance and substantial memory\nsavings. Notably, our method can reduce GPU memory usage by more than 45\\% on\nthe ImageNet dataset compared to end-to-end training, while achieving higher\nperformance. The Momentum Auxiliary Network thus offers a new perspective for\nsupervised local learning. Our code is available at:\nhttps://github.com/JunhaoSu0/MAN.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}