{"id":"2408.06816","title":"MAQA: Evaluating Uncertainty Quantification in LLMs Regarding Data\n  Uncertainty","authors":"Yongjin Yang, Haneul Yoo, Hwaran Lee","authorsParsed":[["Yang","Yongjin",""],["Yoo","Haneul",""],["Lee","Hwaran",""]],"versions":[{"version":"v1","created":"Tue, 13 Aug 2024 11:17:31 GMT"}],"updateDate":"2024-08-14","timestamp":1723547851000,"abstract":"  Although large language models (LLMs) are capable of performing various\ntasks, they still suffer from producing plausible but incorrect responses. To\nimprove the reliability of LLMs, recent research has focused on uncertainty\nquantification to predict whether a response is correct or not. However, most\nuncertainty quantification methods have been evaluated on questions requiring a\nsingle clear answer, ignoring the existence of data uncertainty that arises\nfrom irreducible randomness. Instead, these methods only consider model\nuncertainty, which arises from a lack of knowledge. In this paper, we\ninvestigate previous uncertainty quantification methods under the presence of\ndata uncertainty. Our contributions are two-fold: 1) proposing a new\nMulti-Answer Question Answering dataset, MAQA, consisting of world knowledge,\nmathematical reasoning, and commonsense reasoning tasks to evaluate uncertainty\nquantification regarding data uncertainty, and 2) assessing 5 uncertainty\nquantification methods of diverse white- and black-box LLMs. Our findings show\nthat entropy and consistency-based methods estimate the model uncertainty well\neven under data uncertainty, while other methods for white- and black-box LLMs\nstruggle depending on the tasks. Additionally, methods designed for white-box\nLLMs suffer from overconfidence in reasoning tasks compared to simple knowledge\nqueries. We believe our observations will pave the way for future work on\nuncertainty quantification in realistic setting.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/"}