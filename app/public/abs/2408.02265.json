{"id":"2408.02265","title":"Explain via Any Concept: Concept Bottleneck Model with Open Vocabulary\n  Concepts","authors":"Andong Tan, Fengtao Zhou, Hao Chen","authorsParsed":[["Tan","Andong",""],["Zhou","Fengtao",""],["Chen","Hao",""]],"versions":[{"version":"v1","created":"Mon, 5 Aug 2024 06:42:00 GMT"}],"updateDate":"2024-08-06","timestamp":1722840120000,"abstract":"  The concept bottleneck model (CBM) is an interpretable-by-design framework\nthat makes decisions by first predicting a set of interpretable concepts, and\nthen predicting the class label based on the given concepts. Existing CBMs are\ntrained with a fixed set of concepts (concepts are either annotated by the\ndataset or queried from language models). However, this closed-world assumption\nis unrealistic in practice, as users may wonder about the role of any desired\nconcept in decision-making after the model is deployed. Inspired by the large\nsuccess of recent vision-language pre-trained models such as CLIP in zero-shot\nclassification, we propose \"OpenCBM\" to equip the CBM with open vocabulary\nconcepts via: (1) Aligning the feature space of a trainable image feature\nextractor with that of a CLIP's image encoder via a prototype based feature\nalignment; (2) Simultaneously training an image classifier on the downstream\ndataset; (3) Reconstructing the trained classification head via any set of\nuser-desired textual concepts encoded by CLIP's text encoder. To reveal\npotentially missing concepts from users, we further propose to iteratively find\nthe closest concept embedding to the residual parameters during the\nreconstruction until the residual is small enough. To the best of our\nknowledge, our \"OpenCBM\" is the first CBM with concepts of open vocabularies,\nproviding users the unique benefit such as removing, adding, or replacing any\ndesired concept to explain the model's prediction even after a model is\ntrained. Moreover, our model significantly outperforms the previous\nstate-of-the-art CBM by 9% in the classification accuracy on the benchmark\ndataset CUB-200-2011.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}