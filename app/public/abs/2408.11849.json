{"id":"2408.11849","title":"Style-Talker: Finetuning Audio Language Model and Style-Based\n  Text-to-Speech Model for Fast Spoken Dialogue Generation","authors":"Yinghao Aaron Li, Xilin Jiang, Jordan Darefsky, Ge Zhu, Nima Mesgarani","authorsParsed":[["Li","Yinghao Aaron",""],["Jiang","Xilin",""],["Darefsky","Jordan",""],["Zhu","Ge",""],["Mesgarani","Nima",""]],"versions":[{"version":"v1","created":"Tue, 13 Aug 2024 04:35:11 GMT"}],"updateDate":"2024-08-23","timestamp":1723523711000,"abstract":"  The rapid advancement of large language models (LLMs) has significantly\npropelled the development of text-based chatbots, demonstrating their\ncapability to engage in coherent and contextually relevant dialogues. However,\nextending these advancements to enable end-to-end speech-to-speech conversation\nbots remains a formidable challenge, primarily due to the extensive dataset and\ncomputational resources required. The conventional approach of cascading\nautomatic speech recognition (ASR), LLM, and text-to-speech (TTS) models in a\npipeline, while effective, suffers from unnatural prosody because it lacks\ndirect interactions between the input audio and its transcribed text and the\noutput audio. These systems are also limited by their inherent latency from the\nASR process for real-time applications. This paper introduces Style-Talker, an\ninnovative framework that fine-tunes an audio LLM alongside a style-based TTS\nmodel for fast spoken dialog generation. Style-Talker takes user input audio\nand uses transcribed chat history and speech styles to generate both the\nspeaking style and text for the response. Subsequently, the TTS model\nsynthesizes the speech, which is then played back to the user. While the\nresponse speech is being played, the input speech undergoes ASR processing to\nextract the transcription and speaking style, serving as the context for the\nensuing dialogue turn. This novel pipeline accelerates the traditional cascade\nASR-LLM-TTS systems while integrating rich paralinguistic information from\ninput speech. Our experimental results show that Style-Talker significantly\noutperforms the conventional cascade and speech-to-speech baselines in terms of\nboth dialogue naturalness and coherence while being more than 50% faster.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"g7rqxsMw26k2oBkQO6vSk1ehVFwXxRx95lfqVOAwjdk","pdfSize":"2607572"}
