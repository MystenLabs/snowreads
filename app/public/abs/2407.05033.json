{"id":"2407.05033","title":"Preference Distillation for Personalized Generative Recommendation","authors":"Jerome Ramos, Bin Wu, Aldo Lipani","authorsParsed":[["Ramos","Jerome",""],["Wu","Bin",""],["Lipani","Aldo",""]],"versions":[{"version":"v1","created":"Sat, 6 Jul 2024 09:58:58 GMT"}],"updateDate":"2024-07-09","timestamp":1720259938000,"abstract":"  Recently, researchers have investigated the capabilities of Large Language\nModels (LLMs) for generative recommender systems. Existing LLM-based\nrecommender models are trained by adding user and item IDs to a discrete prompt\ntemplate. However, the disconnect between IDs and natural language makes it\ndifficult for the LLM to learn the relationship between users. To address this\nissue, we propose a PErsonAlized PrOmpt Distillation (PeaPOD) approach, to\ndistill user preferences as personalized soft prompts. Considering the\ncomplexities of user preferences in the real world, we maintain a shared set of\nlearnable prompts that are dynamically weighted based on the user's interests\nto construct the user-personalized prompt in a compositional manner.\nExperimental results on three real-world datasets demonstrate the effectiveness\nof our PeaPOD model on sequential recommendation, top-n recommendation, and\nexplanation generation tasks.\n","subjects":["Computing Research Repository/Information Retrieval"],"license":"http://creativecommons.org/licenses/by/4.0/"}