{"id":"2408.01668","title":"Multiple Contexts and Frequencies Aggregation Network forDeepfake\n  Detection","authors":"Zifeng Li, Wenzhong Tang, Shijun Gao, Shuai Wang, Yanxiang Wang","authorsParsed":[["Li","Zifeng",""],["Tang","Wenzhong",""],["Gao","Shijun",""],["Wang","Shuai",""],["Wang","Yanxiang",""]],"versions":[{"version":"v1","created":"Sat, 3 Aug 2024 05:34:53 GMT"}],"updateDate":"2024-08-06","timestamp":1722663293000,"abstract":"  Deepfake detection faces increasing challenges since the fast growth of\ngenerative models in developing massive and diverse Deepfake technologies.\nRecent advances rely on introducing heuristic features from spatial or\nfrequency domains rather than modeling general forgery features within\nbackbones. To address this issue, we turn to the backbone design with two\nintuitive priors from spatial and frequency detectors, \\textit{i.e.,} learning\nrobust spatial attributes and frequency distributions that are discriminative\nfor real and fake samples. To this end, we propose an efficient network for\nface forgery detection named MkfaNet, which consists of two core modules. For\nspatial contexts, we design a Multi-Kernel Aggregator that adaptively selects\norgan features extracted by multiple convolutions for modeling subtle facial\ndifferences between real and fake faces. For the frequency components, we\npropose a Multi-Frequency Aggregator to process different bands of frequency\ncomponents by adaptively reweighing high-frequency and low-frequency features.\nComprehensive experiments on seven popular deepfake detection benchmarks\ndemonstrate that our proposed MkfaNet variants achieve superior performances in\nboth within-domain and across-domain evaluations with impressive efficiency of\nparameter usage.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Multimedia"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"SXNmzSi2sq0SguD0TvrUDhHze4dmS4F9FjsYkB2-GfI","pdfSize":"5245862"}
