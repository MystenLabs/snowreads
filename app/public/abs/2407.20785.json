{"id":"2407.20785","title":"Retinex-Diffusion: On Controlling Illumination Conditions in Diffusion\n  Models via Retinex Theory","authors":"Xiaoyan Xing, Vincent Tao Hu, Jan Hendrik Metzen, Konrad Groh, Sezer\n  Karaoglu, Theo Gevers","authorsParsed":[["Xing","Xiaoyan",""],["Hu","Vincent Tao",""],["Metzen","Jan Hendrik",""],["Groh","Konrad",""],["Karaoglu","Sezer",""],["Gevers","Theo",""]],"versions":[{"version":"v1","created":"Mon, 29 Jul 2024 03:15:07 GMT"}],"updateDate":"2024-07-31","timestamp":1722222907000,"abstract":"  This paper introduces a novel approach to illumination manipulation in\ndiffusion models, addressing the gap in conditional image generation with a\nfocus on lighting conditions. We conceptualize the diffusion model as a\nblack-box image render and strategically decompose its energy function in\nalignment with the image formation model. Our method effectively separates and\ncontrols illumination-related properties during the generative process. It\ngenerates images with realistic illumination effects, including cast shadow,\nsoft shadow, and inter-reflections. Remarkably, it achieves this without the\nnecessity for learning intrinsic decomposition, finding directions in latent\nspace, or undergoing additional training with new datasets.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"NR1ZEvOvp85J_NZVZmUpD95Z4q011ZH62yZuS91G38U","pdfSize":"2474901"}
