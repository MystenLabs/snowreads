{"id":"2408.02529","title":"Explaining Reinforcement Learning: A Counterfactual Shapley Values\n  Approach","authors":"Yiwei Shi, Qi Zhang, Kevin McAreavey, Weiru Liu","authorsParsed":[["Shi","Yiwei",""],["Zhang","Qi",""],["McAreavey","Kevin",""],["Liu","Weiru",""]],"versions":[{"version":"v1","created":"Mon, 5 Aug 2024 14:49:12 GMT"},{"version":"v2","created":"Tue, 6 Aug 2024 07:32:02 GMT"}],"updateDate":"2024-08-07","timestamp":1722869352000,"abstract":"  This paper introduces a novel approach Counterfactual Shapley Values (CSV),\nwhich enhances explainability in reinforcement learning (RL) by integrating\ncounterfactual analysis with Shapley Values. The approach aims to quantify and\ncompare the contributions of different state dimensions to various action\nchoices. To more accurately analyze these impacts, we introduce new\ncharacteristic value functions, the ``Counterfactual Difference Characteristic\nValue\" and the ``Average Counterfactual Difference Characteristic Value.\" These\nfunctions help calculate the Shapley values to evaluate the differences in\ncontributions between optimal and non-optimal actions. Experiments across\nseveral RL domains, such as GridWorld, FrozenLake, and Taxi, demonstrate the\neffectiveness of the CSV method. The results show that this method not only\nimproves transparency in complex RL systems but also quantifies the differences\nacross various decisions.\n","subjects":["Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"gJPbHksiD7IwmbnRZEhGDrVEm-i7sMuEheNVmQghD-U","pdfSize":"6743514","txDigest":"F3HqJ686Vg8oJZ2cNvr1SY8MrmhuuGPrKGt9crmNbgPw","endEpoch":"1","status":"CERTIFIED"}
