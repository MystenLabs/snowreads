{"id":"2407.08049","title":"Deep Learning-Based Robust Multi-Object Tracking via Fusion of mmWave\n  Radar and Camera Sensors","authors":"Lei Cheng, Arindam Sengupta, and Siyang Cao","authorsParsed":[["Cheng","Lei",""],["Sengupta","Arindam",""],["Cao","Siyang",""]],"versions":[{"version":"v1","created":"Wed, 10 Jul 2024 21:09:09 GMT"}],"updateDate":"2024-07-12","timestamp":1720645749000,"abstract":"  Autonomous driving holds great promise in addressing traffic safety concerns\nby leveraging artificial intelligence and sensor technology. Multi-Object\nTracking plays a critical role in ensuring safer and more efficient navigation\nthrough complex traffic scenarios. This paper presents a novel deep\nlearning-based method that integrates radar and camera data to enhance the\naccuracy and robustness of Multi-Object Tracking in autonomous driving systems.\nThe proposed method leverages a Bi-directional Long Short-Term Memory network\nto incorporate long-term temporal information and improve motion prediction. An\nappearance feature model inspired by FaceNet is used to establish associations\nbetween objects across different frames, ensuring consistent tracking. A\ntri-output mechanism is employed, consisting of individual outputs for radar\nand camera sensors and a fusion output, to provide robustness against sensor\nfailures and produce accurate tracking results. Through extensive evaluations\nof real-world datasets, our approach demonstrates remarkable improvements in\ntracking accuracy, ensuring reliable performance even in low-visibility\nscenarios.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Systems and Control","Electrical Engineering and Systems Science/Signal Processing","Electrical Engineering and Systems Science/Systems and Control"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}