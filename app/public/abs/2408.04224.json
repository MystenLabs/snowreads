{"id":"2408.04224","title":"Cross-View Meets Diffusion: Aerial Image Synthesis with Geometry and\n  Text Guidance","authors":"Ahmad Arrabi, Xiaohan Zhang, Waqas Sultani, Chen Chen, Safwan Wshah","authorsParsed":[["Arrabi","Ahmad",""],["Zhang","Xiaohan",""],["Sultani","Waqas",""],["Chen","Chen",""],["Wshah","Safwan",""]],"versions":[{"version":"v1","created":"Thu, 8 Aug 2024 05:17:27 GMT"},{"version":"v2","created":"Tue, 20 Aug 2024 19:13:08 GMT"}],"updateDate":"2024-08-22","timestamp":1723094247000,"abstract":"  Aerial imagery analysis is critical for many research fields. However,\nobtaining frequent high-quality aerial images is not always accessible due to\nits high effort and cost requirements. One solution is to use the\nGround-to-Aerial (G2A) technique to synthesize aerial images from easily\ncollectible ground images. However, G2A is rarely studied, because of its\nchallenges, including but not limited to, the drastic view changes, occlusion,\nand range of visibility. In this paper, we present a novel Geometric Preserving\nGround-to-Aerial (G2A) image synthesis (GPG2A) model that can generate\nrealistic aerial images from ground images. GPG2A consists of two stages. The\nfirst stage predicts the Bird's Eye View (BEV) segmentation (referred to as the\nBEV layout map) from the ground image. The second stage synthesizes the aerial\nimage from the predicted BEV layout map and text descriptions of the ground\nimage. To train our model, we present a new multi-modal cross-view dataset,\nnamely VIGORv2 which is built upon VIGOR with newly collected aerial images,\nmaps, and text descriptions. Our extensive experiments illustrate that GPG2A\nsynthesizes better geometry-preserved aerial images than existing models. We\nalso present two applications, data augmentation for cross-view\ngeo-localization and sketch-based region search, to further verify the\neffectiveness of our GPG2A. The code and data will be publicly available.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}