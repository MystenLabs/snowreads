{"id":"2407.07516","title":"HDKD: Hybrid Data-Efficient Knowledge Distillation Network for Medical\n  Image Classification","authors":"Omar S. EL-Assiouti, Ghada Hamed, Dina Khattab, Hala M. Ebied","authorsParsed":[["EL-Assiouti","Omar S.",""],["Hamed","Ghada",""],["Khattab","Dina",""],["Ebied","Hala M.",""]],"versions":[{"version":"v1","created":"Wed, 10 Jul 2024 10:09:12 GMT"}],"updateDate":"2024-07-11","timestamp":1720606152000,"abstract":"  Vision Transformers (ViTs) have achieved significant advancement in computer\nvision tasks due to their powerful modeling capacity. However, their\nperformance notably degrades when trained with insufficient data due to lack of\ninherent inductive biases. Distilling knowledge and inductive biases from a\nConvolutional Neural Network (CNN) teacher has emerged as an effective strategy\nfor enhancing the generalization of ViTs on limited datasets. Previous\napproaches to Knowledge Distillation (KD) have pursued two primary paths: some\nfocused solely on distilling the logit distribution from CNN teacher to ViT\nstudent, neglecting the rich semantic information present in intermediate\nfeatures due to the structural differences between them. Others integrated\nfeature distillation along with logit distillation, yet this introduced\nalignment operations that limits the amount of knowledge transferred due to\nmismatched architectures and increased the computational overhead. To this end,\nthis paper presents Hybrid Data-efficient Knowledge Distillation (HDKD)\nparadigm which employs a CNN teacher and a hybrid student. The choice of hybrid\nstudent serves two main aspects. First, it leverages the strengths of both\nconvolutions and transformers while sharing the convolutional structure with\nthe teacher model. Second, this shared structure enables the direct application\nof feature distillation without any information loss or additional\ncomputational overhead. Additionally, we propose an efficient light-weight\nconvolutional block named Mobile Channel-Spatial Attention (MBCSA), which\nserves as the primary convolutional block in both teacher and student models.\nExtensive experiments on two medical public datasets showcase the superiority\nof HDKD over other state-of-the-art models and its computational efficiency.\nSource code at: https://github.com/omarsherif200/HDKD\n","subjects":["Electrical Engineering and Systems Science/Image and Video Processing","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}