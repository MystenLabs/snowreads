{"id":"2407.21172","title":"Learning Stable Robot Grasping with Transformer-based Tactile Control\n  Policies","authors":"En Yen Puang, Zechen Li, Chee Meng Chew, Shan Luo, Yan Wu","authorsParsed":[["Puang","En Yen",""],["Li","Zechen",""],["Chew","Chee Meng",""],["Luo","Shan",""],["Wu","Yan",""]],"versions":[{"version":"v1","created":"Tue, 30 Jul 2024 20:25:46 GMT"}],"updateDate":"2024-08-01","timestamp":1722371146000,"abstract":"  Measuring grasp stability is an important skill for dexterous robot\nmanipulation tasks, which can be inferred from haptic information with a\ntactile sensor. Control policies have to detect rotational displacement and\nslippage from tactile feedback, and determine a re-grasp strategy in term of\nlocation and force. Classic stable grasp task only trains control policies to\nsolve for re-grasp location with objects of fixed center of gravity. In this\nwork, we propose a revamped version of stable grasp task that optimises both\nre-grasp location and gripping force for objects with unknown and moving center\nof gravity. We tackle this task with a model-free, end-to-end Transformer-based\nreinforcement learning framework. We show that our approach is able to solve\nboth objectives after training in both simulation and in a real-world setup\nwith zero-shot transfer. We also provide performance analysis of different\nmodels to understand the dynamics of optimizing two opposing objectives.\n","subjects":["Computing Research Repository/Robotics"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}