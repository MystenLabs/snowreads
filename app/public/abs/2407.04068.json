{"id":"2407.04068","title":"CLIP-DR: Textual Knowledge-Guided Diabetic Retinopathy Grading with\n  Ranking-aware Prompting","authors":"Qinkai Yu, Jianyang Xie, Anh Nguyen, He Zhao, Jiong Zhang, Huazhu Fu,\n  Yitian Zhao, Yalin Zheng, Yanda Meng","authorsParsed":[["Yu","Qinkai",""],["Xie","Jianyang",""],["Nguyen","Anh",""],["Zhao","He",""],["Zhang","Jiong",""],["Fu","Huazhu",""],["Zhao","Yitian",""],["Zheng","Yalin",""],["Meng","Yanda",""]],"versions":[{"version":"v1","created":"Thu, 4 Jul 2024 17:14:18 GMT"}],"updateDate":"2024-07-08","timestamp":1720113258000,"abstract":"  Diabetic retinopathy (DR) is a complication of diabetes and usually takes\ndecades to reach sight-threatening levels. Accurate and robust detection of DR\nseverity is critical for the timely management and treatment of diabetes.\nHowever, most current DR grading methods suffer from insufficient robustness to\ndata variability (\\textit{e.g.} colour fundus images), posing a significant\ndifficulty for accurate and robust grading. In this work, we propose a novel DR\ngrading framework CLIP-DR based on three observations: 1) Recent pre-trained\nvisual language models, such as CLIP, showcase a notable capacity for\ngeneralisation across various downstream tasks, serving as effective baseline\nmodels. 2) The grading of image-text pairs for DR often adheres to a\ndiscernible natural sequence, yet most existing DR grading methods have\nprimarily overlooked this aspect. 3) A long-tailed distribution among DR\nseverity levels complicates the grading process. This work proposes a novel\nranking-aware prompting strategy to help the CLIP model exploit the ordinal\ninformation. Specifically, we sequentially design learnable prompts between\nneighbouring text-image pairs in two different ranking directions.\nAdditionally, we introduce a Similarity Matrix Smooth module into the structure\nof CLIP to balance the class distribution. Finally, we perform extensive\ncomparisons with several state-of-the-art methods on the GDRBench benchmark,\ndemonstrating our CLIP-DR's robustness and superior performance. The\nimplementation code is available\n\\footnote{\\url{https://github.com/Qinkaiyu/CLIP-DR}\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}