{"id":"2408.10593","title":"An Efficient Sign Language Translation Using Spatial Configuration and\n  Motion Dynamics with LLMs","authors":"Eui Jun Hwang, Sukmin Cho, Junmyeong Lee, Jong C. Park","authorsParsed":[["Hwang","Eui Jun",""],["Cho","Sukmin",""],["Lee","Junmyeong",""],["Park","Jong C.",""]],"versions":[{"version":"v1","created":"Tue, 20 Aug 2024 07:10:40 GMT"}],"updateDate":"2024-08-21","timestamp":1724137840000,"abstract":"  Gloss-free Sign Language Translation (SLT) converts sign videos directly into\nspoken language sentences without relying on glosses. Recently, Large Language\nModels (LLMs) have shown remarkable translation performance in gloss-free\nmethods by harnessing their powerful natural language generation capabilities.\nHowever, these methods often rely on domain-specific fine-tuning of visual\nencoders to achieve optimal results. By contrast, this paper emphasizes the\nimportance of capturing the spatial configurations and motion dynamics inherent\nin sign language. With this in mind, we introduce Spatial and Motion-based Sign\nLanguage Translation (SpaMo), a novel LLM-based SLT framework. The core idea of\nSpaMo is simple yet effective. We first extract spatial and motion features\nusing off-the-shelf visual encoders and then input these features into an LLM\nwith a language prompt. Additionally, we employ a visual-text alignment process\nas a warm-up before the SLT supervision. Our experiments demonstrate that SpaMo\nachieves state-of-the-art performance on two popular datasets, PHOENIX14T and\nHow2Sign.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}