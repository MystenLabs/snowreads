{"id":"2408.06633","title":"A lightweight YOLOv5-FFM model for occlusion pedestrian detection","authors":"Xiangjie Luo, Bo Shao, Zhihao Cai, Yingxun Wang","authorsParsed":[["Luo","Xiangjie",""],["Shao","Bo",""],["Cai","Zhihao",""],["Wang","Yingxun",""]],"versions":[{"version":"v1","created":"Tue, 13 Aug 2024 04:42:02 GMT"}],"updateDate":"2024-08-14","timestamp":1723524122000,"abstract":"  The development of autonomous driving technology must be inseparable from\npedestrian detection. Because of the fast speed of the vehicle, the accuracy\nand real-time performance of the pedestrian detection algorithm are very\nimportant. YOLO, as an efficient and simple one-stage target detection method,\nis often used for pedestrian detection in various environments. However, this\nseries of detectors face some challenges, such as excessive computation and\nundesirable detection rate when facing occluded pedestrians. In this paper, we\npropose an improved lightweight YOLOv5 model to deal with these problems. This\nmodel can achieve better pedestrian detection accuracy with fewer\nfloating-point operations (FLOPs), especially for occluded targets. In order to\nachieve the above goals, we made improvements based on the YOLOv5 model\nframework and introduced Ghost module and SE block. Furthermore, we designed a\nlocal feature fusion module (FFM) to deal with occlusion in pedestrian\ndetection. To verify the validity of our method, two datasets, Citypersons and\nCUHK Occlusion, were selected for the experiment. The experimental results show\nthat, compared with the original yolov5s model, the average precision (AP) of\nour method is significantly improved, while the number of parameters is reduced\nby 27.9% and FLOPs are reduced by 19.0%.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}