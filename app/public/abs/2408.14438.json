{"id":"2408.14438","title":"Evaluating Large Language Models on Spatial Tasks: A Multi-Task\n  Benchmarking Study","authors":"Liuchang Xu, Shuo Zhao, Qingming Lin, Luyao Chen, Qianqian Luo, Sensen\n  Wu, Xinyue Ye, Hailin Feng, Zhenhong Du","authorsParsed":[["Xu","Liuchang",""],["Zhao","Shuo",""],["Lin","Qingming",""],["Chen","Luyao",""],["Luo","Qianqian",""],["Wu","Sensen",""],["Ye","Xinyue",""],["Feng","Hailin",""],["Du","Zhenhong",""]],"versions":[{"version":"v1","created":"Mon, 26 Aug 2024 17:25:16 GMT"},{"version":"v2","created":"Wed, 28 Aug 2024 13:19:36 GMT"},{"version":"v3","created":"Mon, 2 Sep 2024 11:59:05 GMT"}],"updateDate":"2024-09-04","timestamp":1724693116000,"abstract":"  The advent of large language models such as ChatGPT, Gemini, and others has\nunderscored the importance of evaluating their diverse capabilities, ranging\nfrom natural language understanding to code generation. However, their\nperformance on spatial tasks has not been comprehensively assessed. This study\naddresses this gap by introducing a novel multi-task spatial evaluation\ndataset, designed to systematically explore and compare the performance of\nseveral advanced models on spatial tasks. The dataset encompasses twelve\ndistinct task types, including spatial understanding and path planning, each\nwith verified, accurate answers. We evaluated multiple models, including\nOpenAI's gpt-3.5-turbo, gpt-4o, and ZhipuAI's glm-4, through a two-phase\ntesting approach. Initially, we conducted zero-shot testing, followed by\ncategorizing the dataset by difficulty and performing prompt tuning tests.\nResults indicate that gpt-4o achieved the highest overall accuracy in the first\nphase, with an average of 71.3%. Although moonshot-v1-8k slightly\nunderperformed overall, it surpassed gpt-4o in place name recognition tasks.\nThe study also highlights the impact of prompt strategies on model performance\nin specific tasks. For example, the Chain-of-Thought (COT) strategy increased\ngpt-4o's accuracy in path planning from 12.4% to 87.5%, while a one-shot\nstrategy enhanced moonshot-v1-8k's accuracy in mapping tasks from 10.1% to\n76.3%.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Computers and Society"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}