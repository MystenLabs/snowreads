{"id":"2407.14452","title":"Undermining Mental Proof: How AI Can Make Cooperation Harder by Making\n  Thinking Easier","authors":"Zachary Wojtowicz and Simon DeDeo","authorsParsed":[["Wojtowicz","Zachary",""],["DeDeo","Simon",""]],"versions":[{"version":"v1","created":"Fri, 19 Jul 2024 16:48:16 GMT"}],"updateDate":"2024-07-22","timestamp":1721407696000,"abstract":"  Large language models and other highly capable AI systems ease the burdens of\ndeciding what to say or do, but this very ease can undermine the effectiveness\nof our actions in social contexts. We explain this apparent tension by\nintroducing the integrative theoretical concept of \"mental proof,\" which occurs\nwhen observable actions are used to certify unobservable mental facts. From\nhiring to dating, mental proofs enable people to credibly communicate values,\nintentions, states of knowledge, and other private features of their minds to\none another in low-trust environments where honesty cannot be easily enforced.\nDrawing on results from economics, theoretical biology, and computer science,\nwe describe the core theoretical mechanisms that enable people to effect mental\nproofs. An analysis of these mechanisms clarifies when and how artificial\nintelligence can make low-trust cooperation harder despite making thinking\neasier.\n","subjects":["Computing Research Repository/Computers and Society"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}