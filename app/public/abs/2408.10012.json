{"id":"2408.10012","title":"CLIPCleaner: Cleaning Noisy Labels with CLIP","authors":"Chen Feng, Georgios Tzimiropoulos, Ioannis Patras","authorsParsed":[["Feng","Chen",""],["Tzimiropoulos","Georgios",""],["Patras","Ioannis",""]],"versions":[{"version":"v1","created":"Mon, 19 Aug 2024 14:05:58 GMT"},{"version":"v2","created":"Mon, 16 Sep 2024 11:46:36 GMT"}],"updateDate":"2024-09-17","timestamp":1724076358000,"abstract":"  Learning with Noisy labels (LNL) poses a significant challenge for the\nMachine Learning community. Some of the most widely used approaches that select\nas clean samples for which the model itself (the in-training model) has high\nconfidence, e.g., `small loss', can suffer from the so called\n`self-confirmation' bias. This bias arises because the in-training model, is at\nleast partially trained on the noisy labels. Furthermore, in the classification\ncase, an additional challenge arises because some of the label noise is between\nclasses that are visually very similar (`hard noise'). This paper addresses\nthese challenges by proposing a method (\\textit{CLIPCleaner}) that leverages\nCLIP, a powerful Vision-Language (VL) model for constructing a zero-shot\nclassifier for efficient, offline, clean sample selection. This has the\nadvantage that the sample selection is decoupled from the in-training model and\nthat the sample selection is aware of the semantic and visual similarities\nbetween the classes due to the way that CLIP is trained. We provide theoretical\njustifications and empirical evidence to demonstrate the advantages of CLIP for\nLNL compared to conventional pre-trained models. Compared to current methods\nthat combine iterative sample selection with various techniques,\n\\textit{CLIPCleaner} offers a simple, single-step approach that achieves\ncompetitive or superior performance on benchmark datasets. To the best of our\nknowledge, this is the first time a VL model has been used for sample selection\nto address the problem of Learning with Noisy Labels (LNL), highlighting their\npotential in the domain.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}