{"id":"2407.01911","title":"Investigating the Effects of Large-Scale Pseudo-Stereo Data and\n  Different Speech Foundation Model on Dialogue Generative Spoken Language\n  Model","authors":"Yu-Kuan Fu, Cheng-Kuang Lee, Hsiu-Hsuan Wang, Hung-yi Lee","authorsParsed":[["Fu","Yu-Kuan",""],["Lee","Cheng-Kuang",""],["Wang","Hsiu-Hsuan",""],["Lee","Hung-yi",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 03:22:41 GMT"}],"updateDate":"2024-07-03","timestamp":1719890561000,"abstract":"  Recent efforts in Spoken Dialogue Modeling aim to synthesize spoken dialogue\nwithout the need for direct transcription, thereby preserving the wealth of\nnon-textual information inherent in speech. However, this approach faces a\nchallenge when speakers talk simultaneously, requiring stereo dialogue data\nwith speakers recorded on separate channels, a notably scarce resource. To\naddress this, we have developed an innovative pipeline capable of transforming\nsingle-channel dialogue data into pseudo-stereo data. This expanded our\ntraining dataset from a mere 2,000 to an impressive 17,600 hours, significantly\nenriching the diversity and quality of the training examples available. The\ninclusion of this pseudo-stereo data has proven to be effective in improving\nthe performance of spoken dialogue language models. Additionally, we explored\nthe use of discrete units of different speech foundation models for spoken\ndialogue generation.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Human-Computer Interaction","Computing Research Repository/Sound","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by/4.0/"}