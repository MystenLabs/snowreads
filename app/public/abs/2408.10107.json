{"id":"2408.10107","title":"Perturb-and-Compare Approach for Detecting Out-of-Distribution Samples\n  in Constrained Access Environments","authors":"Heeyoung Lee, Hoyoon Byun, Changdae Oh, JinYeong Bak, Kyungwoo Song","authorsParsed":[["Lee","Heeyoung",""],["Byun","Hoyoon",""],["Oh","Changdae",""],["Bak","JinYeong",""],["Song","Kyungwoo",""]],"versions":[{"version":"v1","created":"Mon, 19 Aug 2024 15:51:31 GMT"}],"updateDate":"2024-08-20","timestamp":1724082691000,"abstract":"  Accessing machine learning models through remote APIs has been gaining\nprevalence following the recent trend of scaling up model parameters for\nincreased performance. Even though these models exhibit remarkable ability,\ndetecting out-of-distribution (OOD) samples remains a crucial safety concern\nfor end users as these samples may induce unreliable outputs from the model. In\nthis work, we propose an OOD detection framework, MixDiff, that is applicable\neven when the model's parameters or its activations are not accessible to the\nend user. To bypass the access restriction, MixDiff applies an identical\ninput-level perturbation to a given target sample and a similar in-distribution\n(ID) sample, then compares the relative difference in the model outputs of\nthese two samples. MixDiff is model-agnostic and compatible with existing\noutput-based OOD detection methods. We provide theoretical analysis to\nillustrate MixDiff's effectiveness in discerning OOD samples that induce\noverconfident outputs from the model and empirically demonstrate that MixDiff\nconsistently enhances the OOD detection performance on various datasets in\nvision and text domains.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence","Statistics/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}