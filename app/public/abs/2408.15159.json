{"id":"2408.15159","title":"Empowering Sign Language Communication: Integrating Sentiment and\n  Semantics for Facial Expression Synthesis","authors":"Rafael Azevedo, Thiago Coutinho, Jo\\~ao Ferreira, Thiago Gomes,\n  Erickson Nascimento","authorsParsed":[["Azevedo","Rafael",""],["Coutinho","Thiago",""],["Ferreira","Jo√£o",""],["Gomes","Thiago",""],["Nascimento","Erickson",""]],"versions":[{"version":"v1","created":"Tue, 27 Aug 2024 15:55:18 GMT"}],"updateDate":"2024-08-28","timestamp":1724774118000,"abstract":"  Translating written sentences from oral languages to a sequence of manual and\nnon-manual gestures plays a crucial role in building a more inclusive society\nfor deaf and hard-of-hearing people. Facial expressions (non-manual), in\nparticular, are responsible for encoding the grammar of the sentence to be\nspoken, applying punctuation, pronouns, or emphasizing signs. These non-manual\ngestures are closely related to the semantics of the sentence being spoken and\nalso to the utterance of the speaker's emotions. However, most Sign Language\nProduction (SLP) approaches are centered on synthesizing manual gestures and do\nnot focus on modeling the speakers expression. This paper introduces a new\nmethod focused in synthesizing facial expressions for sign language. Our goal\nis to improve sign language production by integrating sentiment information in\nfacial expression generation. The approach leverages a sentence sentiment and\nsemantic features to sample from a meaningful representation space, integrating\nthe bias of the non-manual components into the sign language production\nprocess. To evaluate our method, we extend the Frechet Gesture Distance (FGD)\nand propose a new metric called Frechet Expression Distance (FED) and apply an\nextensive set of metrics to assess the quality of specific regions of the face.\nThe experimental results showed that our method achieved state of the art,\nbeing superior to the competitors on How2Sign and PHOENIX14T datasets.\nMoreover, our architecture is based on a carefully designed graph pyramid that\nmakes it simpler, easier to train, and capable of leveraging emotions to\nproduce facial expressions.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}