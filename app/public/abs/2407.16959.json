{"id":"2407.16959","title":"Dynamic Graph Transformer with Correlated Spatial-Temporal Positional\n  Encoding","authors":"Zhe Wang, Sheng Zhou, Jiawei Chen, Zhen Zhang, Binbin Hu, Yan Feng,\n  Chun Chen, Can Wang","authorsParsed":[["Wang","Zhe",""],["Zhou","Sheng",""],["Chen","Jiawei",""],["Zhang","Zhen",""],["Hu","Binbin",""],["Feng","Yan",""],["Chen","Chun",""],["Wang","Can",""]],"versions":[{"version":"v1","created":"Wed, 24 Jul 2024 02:56:22 GMT"}],"updateDate":"2024-07-25","timestamp":1721789782000,"abstract":"  Learning effective representations for Continuous-Time Dynamic Graphs (CTDGs)\nhas garnered significant research interest, largely due to its powerful\ncapabilities in modeling complex interactions between nodes. A fundamental and\ncrucial requirement for representation learning in CTDGs is the appropriate\nestimation and preservation of proximity. However, due to the sparse and\nevolving characteristics of CTDGs, the spatial-temporal properties inherent in\nhigh-order proximity remain largely unexplored. Despite its importance, this\nproperty presents significant challenges due to the computationally intensive\nnature of personalized interaction intensity estimation and the dynamic\nattributes of CTDGs. To this end, we propose a novel Correlated\nSpatial-Temporal Positional encoding that incorporates a parameter-free\npersonalized interaction intensity estimation under the weak assumption of the\nPoisson Point Process. Building on this, we introduce the Dynamic Graph\nTransformer with \\Correlated Spatial-Temporal Positional Encoding (CorDGT),\nwhich efficiently retains the evolving spatial-temporal high-order proximity\nfor effective node representation learning in CTDGs. Extensive experiments on\nseven small and two large-scale datasets demonstrate the superior performance\nand scalability of the proposed CorDGT.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}