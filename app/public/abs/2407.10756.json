{"id":"2407.10756","title":"GTPT: Group-based Token Pruning Transformer for Efficient Human Pose\n  Estimation","authors":"Haonan Wang, Jie Liu, Jie Tang, Gangshan Wu, Bo Xu, Yanbing Chou, Yong\n  Wang","authorsParsed":[["Wang","Haonan",""],["Liu","Jie",""],["Tang","Jie",""],["Wu","Gangshan",""],["Xu","Bo",""],["Chou","Yanbing",""],["Wang","Yong",""]],"versions":[{"version":"v1","created":"Mon, 15 Jul 2024 14:32:45 GMT"},{"version":"v2","created":"Tue, 16 Jul 2024 14:32:21 GMT"}],"updateDate":"2024-07-17","timestamp":1721053965000,"abstract":"  In recent years, 2D human pose estimation has made significant progress on\npublic benchmarks. However, many of these approaches face challenges of less\napplicability in the industrial community due to the large number of parametric\nquantities and computational overhead. Efficient human pose estimation remains\na hurdle, especially for whole-body pose estimation with numerous keypoints.\nWhile most current methods for efficient human pose estimation primarily rely\non CNNs, we propose the Group-based Token Pruning Transformer (GTPT) that fully\nharnesses the advantages of the Transformer. GTPT alleviates the computational\nburden by gradually introducing keypoints in a coarse-to-fine manner. It\nminimizes the computation overhead while ensuring high performance. Besides,\nGTPT groups keypoint tokens and prunes visual tokens to improve model\nperformance while reducing redundancy. We propose the Multi-Head Group\nAttention (MHGA) between different groups to achieve global interaction with\nlittle computational overhead. We conducted experiments on COCO and\nCOCO-WholeBody. Compared to other methods, the experimental results show that\nGTPT can achieve higher performance with less computation, especially in\nwhole-body with numerous keypoints.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}