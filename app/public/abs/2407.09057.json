{"id":"2407.09057","title":"PersonificationNet: Making customized subject act like a person","authors":"Tianchu Guo, Pengyu Li, Biao Wang, Xiansheng Hua","authorsParsed":[["Guo","Tianchu",""],["Li","Pengyu",""],["Wang","Biao",""],["Hua","Xiansheng",""]],"versions":[{"version":"v1","created":"Fri, 12 Jul 2024 07:27:07 GMT"}],"updateDate":"2024-07-15","timestamp":1720769227000,"abstract":"  Recently customized generation has significant potential, which uses as few\nas 3-5 user-provided images to train a model to synthesize new images of a\nspecified subject. Though subsequent applications enhance the flexibility and\ndiversity of customized generation, fine-grained control over the given subject\nacting like the person's pose is still lack of study. In this paper, we propose\na PersonificationNet, which can control the specified subject such as a cartoon\ncharacter or plush toy to act the same pose as a given referenced person's\nimage. It contains a customized branch, a pose condition branch and a structure\nalignment module. Specifically, first, the customized branch mimics specified\nsubject appearance. Second, the pose condition branch transfers the body\nstructure information from the human to variant instances. Last, the structure\nalignment module bridges the structure gap between human and specified subject\nin the inference stage. Experimental results show our proposed\nPersonificationNet outperforms the state-of-the-art methods.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}