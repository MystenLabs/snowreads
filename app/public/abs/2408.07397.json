{"id":"2408.07397","title":"Bridging Training and Execution via Dynamic Directed Graph-Based\n  Communication in Cooperative Multi-Agent Systems","authors":"Zhuohui Zhang, Bin He, Bin Cheng, Gang Li","authorsParsed":[["Zhang","Zhuohui",""],["He","Bin",""],["Cheng","Bin",""],["Li","Gang",""]],"versions":[{"version":"v1","created":"Wed, 14 Aug 2024 09:16:42 GMT"}],"updateDate":"2024-08-15","timestamp":1723627002000,"abstract":"  Multi-agent systems must learn to communicate and understand interactions\nbetween agents to achieve cooperative goals in partially observed tasks.\nHowever, existing approaches lack a dynamic directed communication mechanism\nand rely on global states, thus diminishing the role of communication in\ncentralized training. Thus, we propose the transformer-based graph coarsening\nnetwork (TGCNet), a novel multi-agent reinforcement learning (MARL) algorithm.\nTGCNet learns the topological structure of a dynamic directed graph to\nrepresent the communication policy and integrates graph coarsening networks to\napproximate the representation of global state during training. It also\nutilizes the transformer decoder for feature extraction during execution.\nExperiments on multiple cooperative MARL benchmarks demonstrate\nstate-of-the-art performance compared to popular MARL algorithms. Further\nablation studies validate the effectiveness of our dynamic directed graph\ncommunication mechanism and graph coarsening networks.\n","subjects":["Computing Research Repository/Multiagent Systems"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}