{"id":"2408.16471","title":"Improving 3D deep learning segmentation with biophysically motivated\n  cell synthesis","authors":"Roman Bruch, Mario Vitacolonna, Elina N\\\"urnberg, Simeon Sauer,\n  R\\\"udiger Rudolf, Markus Reischl","authorsParsed":[["Bruch","Roman",""],["Vitacolonna","Mario",""],["Nürnberg","Elina",""],["Sauer","Simeon",""],["Rudolf","Rüdiger",""],["Reischl","Markus",""]],"versions":[{"version":"v1","created":"Thu, 29 Aug 2024 12:01:23 GMT"}],"updateDate":"2024-08-30","timestamp":1724932883000,"abstract":"  Biomedical research increasingly relies on 3D cell culture models and\nAI-based analysis can potentially facilitate a detailed and accurate feature\nextraction on a single-cell level. However, this requires for a precise\nsegmentation of 3D cell datasets, which in turn demands high-quality ground\ntruth for training. Manual annotation, the gold standard for ground truth data,\nis too time-consuming and thus not feasible for the generation of large 3D\ntraining datasets. To address this, we present a novel framework for generating\n3D training data, which integrates biophysical modeling for realistic cell\nshape and alignment. Our approach allows the in silico generation of coherent\nmembrane and nuclei signals, that enable the training of segmentation models\nutilizing both channels for improved performance. Furthermore, we present a new\nGAN training scheme that generates not only image data but also matching\nlabels. Quantitative evaluation shows superior performance of biophysical\nmotivated synthetic training data, even outperforming manual annotation and\npretrained models. This underscores the potential of incorporating biophysical\nmodeling for enhancing synthetic training data quality.\n","subjects":["Electrical Engineering and Systems Science/Image and Video Processing","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}