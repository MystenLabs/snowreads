{"id":"2407.02585","title":"Novel Human Machine Interface via Robust Hand Gesture Recognition System\n  using Channel Pruned YOLOv5s Model","authors":"Abir Sen, Tapas Kumar Mishra and Ratnakar Dash","authorsParsed":[["Sen","Abir",""],["Mishra","Tapas Kumar",""],["Dash","Ratnakar",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 18:10:20 GMT"}],"updateDate":"2024-07-04","timestamp":1719943820000,"abstract":"  Hand gesture recognition (HGR) is a vital component in enhancing the\nhuman-computer interaction experience, particularly in multimedia applications,\nsuch as virtual reality, gaming, smart home automation systems, etc. Users can\ncontrol and navigate through these applications seamlessly by accurately\ndetecting and recognizing gestures. However, in a real-time scenario, the\nperformance of the gesture recognition system is sometimes affected due to the\npresence of complex background, low-light illumination, occlusion problems,\netc. Another issue is building a fast and robust gesture-controlled\nhuman-computer interface (HCI) in the real-time scenario. The overall objective\nof this paper is to develop an efficient hand gesture detection and\nclassification model using a channel-pruned YOLOv5-small model and utilize the\nmodel to build a gesture-controlled HCI with a quick response time (in ms) and\nhigher detection speed (in fps). First, the YOLOv5s model is chosen for the\ngesture detection task. Next, the model is simplified by using a channel-pruned\nalgorithm. After that, the pruned model is further fine-tuned to ensure\ndetection efficiency. We have compared our suggested scheme with other\nstate-of-the-art works, and it is observed that our model has shown superior\nresults in terms of mAP (mean average precision), precision (\\%), recall (\\%),\nand F1-score (\\%), fast inference time (in ms), and detection speed (in fps).\nOur proposed method paves the way for deploying a pruned YOLOv5s model for a\nreal-time gesture-command-based HCI to control some applications, such as the\nVLC media player, Spotify player, etc., using correctly classified gesture\ncommands in real-time scenarios. The average detection speed of our proposed\nsystem has reached more than 60 frames per second (fps) in real-time, which\nmeets the perfect requirement in real-time application control.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}