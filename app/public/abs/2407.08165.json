{"id":"2407.08165","title":"Explicit-NeRF-QA: A Quality Assessment Database for Explicit NeRF Model\n  Compression","authors":"Yuke Xing, Qi Yang, Kaifa Yang, Yilin Xu, Zhu Li","authorsParsed":[["Xing","Yuke",""],["Yang","Qi",""],["Yang","Kaifa",""],["Xu","Yilin",""],["Li","Zhu",""]],"versions":[{"version":"v1","created":"Thu, 11 Jul 2024 04:02:05 GMT"},{"version":"v2","created":"Thu, 18 Jul 2024 15:52:26 GMT"}],"updateDate":"2024-07-19","timestamp":1720670525000,"abstract":"  In recent years, Neural Radiance Fields (NeRF) have demonstrated significant\nadvantages in representing and synthesizing 3D scenes. Explicit NeRF models\nfacilitate the practical NeRF applications with faster rendering speed, and\nalso attract considerable attention in NeRF compression due to its huge storage\ncost. To address the challenge of the NeRF compression study, in this paper, we\nconstruct a new dataset, called Explicit-NeRF-QA. We use 22 3D objects with\ndiverse geometries, textures, and material complexities to train four typical\nexplicit NeRF models across five parameter levels. Lossy compression is\nintroduced during the model generation, pivoting the selection of key\nparameters such as hash table size for InstantNGP and voxel grid resolution for\nPlenoxels. By rendering NeRF samples to processed video sequences (PVS), a\nlarge scale subjective experiment with lab environment is conducted to collect\nsubjective scores from 21 viewers. The diversity of content, accuracy of mean\nopinion scores (MOS), and characteristics of NeRF distortion are\ncomprehensively presented, establishing the heterogeneity of the proposed\ndataset. The state-of-the-art objective metrics are tested in the new dataset.\nBest Person correlation, which is around 0.85, is collected from the\nfull-reference objective metric. All tested no-reference metrics report very\npoor results with 0.4 to 0.6 correlations, demonstrating the need for further\ndevelopment of more robust no-reference metrics. The dataset, including NeRF\nsamples, source 3D objects, multiview images for NeRF generation, PVSs, MOS, is\nmade publicly available at the following location:\nhttps://github.com/LittlericeChloe/Explicit_NeRF_QA.\n","subjects":["Electrical Engineering and Systems Science/Image and Video Processing","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}