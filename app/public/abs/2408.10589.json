{"id":"2408.10589","title":"Bidirectional Intent Communication: A Role for Large Foundation Models","authors":"Tim Schreiter, Rishi Hazra, Jens R\\\"uppel, Andrey Rudenko","authorsParsed":[["Schreiter","Tim",""],["Hazra","Rishi",""],["RÃ¼ppel","Jens",""],["Rudenko","Andrey",""]],"versions":[{"version":"v1","created":"Tue, 20 Aug 2024 06:52:27 GMT"}],"updateDate":"2024-08-21","timestamp":1724136747000,"abstract":"  Integrating multimodal foundation models has significantly enhanced\nautonomous agents' language comprehension, perception, and planning\ncapabilities. However, while existing works adopt a \\emph{task-centric}\napproach with minimal human interaction, applying these models to developing\nassistive \\emph{user-centric} robots that can interact and cooperate with\nhumans remains underexplored. This paper introduces ``Bident'', a framework\ndesigned to integrate robots seamlessly into shared spaces with humans. Bident\nenhances the interactive experience by incorporating multimodal inputs like\nspeech and user gaze dynamics. Furthermore, Bident supports verbal utterances\nand physical actions like gestures, making it versatile for bidirectional\nhuman-robot interactions. Potential applications include personalized\neducation, where robots can adapt to individual learning styles and paces, and\nhealthcare, where robots can offer personalized support, companionship, and\neveryday assistance in the home and workplace environments.\n","subjects":["Computing Research Repository/Robotics","Computing Research Repository/Human-Computer Interaction"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}