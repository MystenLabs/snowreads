{"id":"2408.04963","title":"LiD-FL: Towards List-Decodable Federated Learning","authors":"Hong Liu, Liren Shan, Han Bao, Ronghui You, Yuhao Yi, Jiancheng Lv","authorsParsed":[["Liu","Hong",""],["Shan","Liren",""],["Bao","Han",""],["You","Ronghui",""],["Yi","Yuhao",""],["Lv","Jiancheng",""]],"versions":[{"version":"v1","created":"Fri, 9 Aug 2024 09:29:02 GMT"},{"version":"v2","created":"Thu, 15 Aug 2024 08:26:56 GMT"}],"updateDate":"2024-08-16","timestamp":1723195742000,"abstract":"  Federated learning is often used in environments with many unverified\nparticipants. Therefore, federated learning under adversarial attacks receives\nsignificant attention. This paper proposes an algorithmic framework for\nlist-decodable federated learning, where a central server maintains a list of\nmodels, with at least one guaranteed to perform well. The framework has no\nstrict restriction on the fraction of honest workers, extending the\napplicability of Byzantine federated learning to the scenario with more than\nhalf adversaries. Under proper assumptions on the loss function, we prove a\nconvergence theorem for our method. Experimental results, including image\nclassification tasks with both convex and non-convex losses, demonstrate that\nthe proposed algorithm can withstand the malicious majority under various\nattacks.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}