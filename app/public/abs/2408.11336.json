{"id":"2408.11336","title":"FATE: Focal-modulated Attention Encoder for Temperature Prediction","authors":"Tajamul Ashraf, Janibul Bashir","authorsParsed":[["Ashraf","Tajamul",""],["Bashir","Janibul",""]],"versions":[{"version":"v1","created":"Wed, 21 Aug 2024 04:40:18 GMT"}],"updateDate":"2024-08-22","timestamp":1724215218000,"abstract":"  One of the major challenges of the twenty-first century is climate change,\nevidenced by rising sea levels, melting glaciers, and increased storm\nfrequency. Accurate temperature forecasting is vital for understanding and\nmitigating these impacts. Traditional data-driven models often use recurrent\nneural networks (RNNs) but face limitations in parallelization, especially with\nlonger sequences. To address this, we introduce a novel approach based on the\nFocalNet Transformer architecture. Our Focal modulation Attention Encoder\n(FATE) framework operates in a multi-tensor format, utilizing tensorized\nmodulation to capture spatial and temporal nuances in meteorological data.\nComparative evaluations against existing transformer encoders, 3D CNNs, LSTM,\nand ConvLSTM models show that FATE excels at identifying complex patterns in\ntemperature data. Additionally, we present a new labeled dataset, the Climate\nChange Parameter dataset (CCPD), containing 40 years of data from Jammu and\nKashmir on seven climate-related parameters. Experiments with real-world\ntemperature datasets from the USA, Canada, and Europe show accuracy\nimprovements of 12\\%, 23\\%, and 28\\%, respectively, over current\nstate-of-the-art models. Our CCPD dataset also achieved a 24\\% improvement in\naccuracy. To support reproducible research, we have released the source code\nand pre-trained FATE model at\n\\href{https://github.com/Tajamul21/FATE}{https://github.com/Tajamul21/FATE}.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"Y9qkqd1teERzUrYY51y1zia7OLAsVY1tKo9RBYbuyr0","pdfSize":"1650783"}
