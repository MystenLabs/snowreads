{"id":"2407.04325","title":"Understanding the Role of Invariance in Transfer Learning","authors":"Till Speicher, Vedant Nanda, Krishna P. Gummadi","authorsParsed":[["Speicher","Till",""],["Nanda","Vedant",""],["Gummadi","Krishna P.",""]],"versions":[{"version":"v1","created":"Fri, 5 Jul 2024 07:53:52 GMT"}],"updateDate":"2024-07-08","timestamp":1720166032000,"abstract":"  Transfer learning is a powerful technique for knowledge-sharing between\ndifferent tasks. Recent work has found that the representations of models with\ncertain invariances, such as to adversarial input perturbations, achieve higher\nperformance on downstream tasks. These findings suggest that invariance may be\nan important property in the context of transfer learning. However, the\nrelationship of invariance with transfer performance is not fully understood\nyet and a number of questions remain. For instance, how important is invariance\ncompared to other factors of the pretraining task? How transferable is learned\ninvariance? In this work, we systematically investigate the importance of\nrepresentational invariance for transfer learning, as well as how it interacts\nwith other parameters during pretraining. To do so, we introduce a family of\nsynthetic datasets that allow us to precisely control factors of variation both\nin training and test data. Using these datasets, we a) show that for learning\nrepresentations with high transfer performance, invariance to the right\ntransformations is as, or often more, important than most other factors such as\nthe number of training samples, the model architecture and the identity of the\npretraining classes, b) show conditions under which invariance can harm the\nability to transfer representations and c) explore how transferable invariance\nis between tasks. The code is available at\n\\url{https://github.com/tillspeicher/representation-invariance-transfer}.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}