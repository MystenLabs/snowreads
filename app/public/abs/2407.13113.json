{"id":"2407.13113","title":"Multiobjective Vehicle Routing Optimization with Time Windows: A Hybrid\n  Approach Using Deep Reinforcement Learning and NSGA-II","authors":"Rixin Wu, Ran Wang, Jie Hao, Qiang Wu, Ping Wang, Dusit Niyato","authorsParsed":[["Wu","Rixin",""],["Wang","Ran",""],["Hao","Jie",""],["Wu","Qiang",""],["Wang","Ping",""],["Niyato","Dusit",""]],"versions":[{"version":"v1","created":"Thu, 18 Jul 2024 02:46:06 GMT"}],"updateDate":"2024-07-19","timestamp":1721270766000,"abstract":"  This paper proposes a weight-aware deep reinforcement learning (WADRL)\napproach designed to address the multiobjective vehicle routing problem with\ntime windows (MOVRPTW), aiming to use a single deep reinforcement learning\n(DRL) model to solve the entire multiobjective optimization problem. The\nNon-dominated sorting genetic algorithm-II (NSGA-II) method is then employed to\noptimize the outcomes produced by the WADRL, thereby mitigating the limitations\nof both approaches. Firstly, we design an MOVRPTW model to balance the\nminimization of travel cost and the maximization of customer satisfaction.\nSubsequently, we present a novel DRL framework that incorporates a\ntransformer-based policy network. This network is composed of an encoder\nmodule, a weight embedding module where the weights of the objective functions\nare incorporated, and a decoder module. NSGA-II is then utilized to optimize\nthe solutions generated by WADRL. Finally, extensive experimental results\ndemonstrate that our method outperforms the existing and traditional methods.\nDue to the numerous constraints in VRPTW, generating initial solutions of the\nNSGA-II algorithm can be time-consuming. However, using solutions generated by\nthe WADRL as initial solutions for NSGA-II significantly reduces the time\nrequired for generating initial solutions. Meanwhile, the NSGA-II algorithm can\nenhance the quality of solutions generated by WADRL, resulting in solutions\nwith better scalability. Notably, the weight-aware strategy significantly\nreduces the training time of DRL while achieving better results, enabling a\nsingle DRL model to solve the entire multiobjective optimization problem.\n","subjects":["Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/"}