{"id":"2408.14672","title":"Physically Feasible Semantic Segmentation","authors":"Shamik Basu, Luc Van Gool, Christos Sakaridis","authorsParsed":[["Basu","Shamik",""],["Van Gool","Luc",""],["Sakaridis","Christos",""]],"versions":[{"version":"v1","created":"Mon, 26 Aug 2024 22:39:08 GMT"},{"version":"v2","created":"Wed, 11 Sep 2024 17:26:06 GMT"}],"updateDate":"2024-09-12","timestamp":1724711948000,"abstract":"  State-of-the-art semantic segmentation models are typically optimized in a\ndata-driven fashion, minimizing solely per-pixel classification objectives on\ntheir training data. This purely data-driven paradigm often leads to absurd\nsegmentations, especially when the domain of input images is shifted from the\none encountered during training. For instance, state-of-the-art models may\nassign the label ``road'' to a segment which is located above a segment that is\nrespectively labeled as ``sky'', although our knowledge of the physical world\ndictates that such a configuration is not feasible for images captured by\nforward-facing upright cameras. Our method, Physically Feasible Semantic\nSegmentation (PhyFea), extracts explicit physical constraints that govern\nspatial class relations from the training sets of semantic segmentation\ndatasets and enforces a differentiable loss function that penalizes violations\nof these constraints to promote prediction feasibility. PhyFea yields\nsignificant performance improvements in mIoU over each state-of-the-art network\nwe use as baseline across ADE20K, Cityscapes and ACDC, notably a $1.5\\%$\nimprovement on ADE20K and a $2.1\\%$ improvement on ACDC.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}