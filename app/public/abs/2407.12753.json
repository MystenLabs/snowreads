{"id":"2407.12753","title":"LookupViT: Compressing visual information to a limited number of tokens","authors":"Rajat Koner, Gagan Jain, Prateek Jain, Volker Tresp, Sujoy Paul","authorsParsed":[["Koner","Rajat",""],["Jain","Gagan",""],["Jain","Prateek",""],["Tresp","Volker",""],["Paul","Sujoy",""]],"versions":[{"version":"v1","created":"Wed, 17 Jul 2024 17:22:43 GMT"}],"updateDate":"2024-07-18","timestamp":1721236963000,"abstract":"  Vision Transformers (ViT) have emerged as the de-facto choice for numerous\nindustry grade vision solutions. But their inference cost can be prohibitive\nfor many settings, as they compute self-attention in each layer which suffers\nfrom quadratic computational complexity in the number of tokens. On the other\nhand, spatial information in images and spatio-temporal information in videos\nis usually sparse and redundant. In this work, we introduce LookupViT, that\naims to exploit this information sparsity to reduce ViT inference cost.\nLookupViT provides a novel general purpose vision transformer block that\noperates by compressing information from higher resolution tokens to a fixed\nnumber of tokens. These few compressed tokens undergo meticulous processing,\nwhile the higher-resolution tokens are passed through computationally cheaper\nlayers. Information sharing between these two token sets is enabled through a\nbidirectional cross-attention mechanism. The approach offers multiple\nadvantages - (a) easy to implement on standard ML accelerators (GPUs/TPUs) via\nstandard high-level operators, (b) applicable to standard ViT and its variants,\nthus generalizes to various tasks, (c) can handle different tokenization and\nattention approaches. LookupViT also offers flexibility for the compressed\ntokens, enabling performance-computation trade-offs in a single trained model.\nWe show LookupViT's effectiveness on multiple domains - (a) for\nimage-classification (ImageNet-1K and ImageNet-21K), (b) video classification\n(Kinetics400 and Something-Something V2), (c) image captioning (COCO-Captions)\nwith a frozen encoder. LookupViT provides $2\\times$ reduction in FLOPs while\nupholding or improving accuracy across these domains. In addition, LookupViT\nalso demonstrates out-of-the-box robustness and generalization on image\nclassification (ImageNet-C,R,A,O), improving by up to $4\\%$ over ViT.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}