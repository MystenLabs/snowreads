{"id":"2408.09687","title":"TESL-Net: A Transformer-Enhanced CNN for Accurate Skin Lesion\n  Segmentation","authors":"Shahzaib Iqbal, Muhammad Zeeshan, Mehwish Mehmood, Tariq M. Khan,\n  Imran Razzak","authorsParsed":[["Iqbal","Shahzaib",""],["Zeeshan","Muhammad",""],["Mehmood","Mehwish",""],["Khan","Tariq M.",""],["Razzak","Imran",""]],"versions":[{"version":"v1","created":"Mon, 19 Aug 2024 03:49:48 GMT"}],"updateDate":"2024-08-20","timestamp":1724039388000,"abstract":"  Early detection of skin cancer relies on precise segmentation of dermoscopic\nimages of skin lesions. However, this task is challenging due to the irregular\nshape of the lesion, the lack of sharp borders, and the presence of artefacts\nsuch as marker colours and hair follicles. Recent methods for melanoma\nsegmentation are U-Nets and fully connected networks (FCNs). As the depth of\nthese neural network models increases, they can face issues like the vanishing\ngradient problem and parameter redundancy, potentially leading to a decrease in\nthe Jaccard index of the segmentation model. In this study, we introduced a\nnovel network named TESL-Net for the segmentation of skin lesions. The proposed\nTESL-Net involves a hybrid network that combines the local features of a CNN\nencoder-decoder architecture with long-range and temporal dependencies using\nbi-convolutional long-short-term memory (Bi-ConvLSTM) networks and a Swin\ntransformer. This enables the model to account for the uncertainty of\nsegmentation over time and capture contextual channel relationships in the\ndata. We evaluated the efficacy of TESL-Net in three commonly used datasets\n(ISIC 2016, ISIC 2017, and ISIC 2018) for the segmentation of skin lesions. The\nproposed TESL-Net achieves state-of-the-art performance, as evidenced by a\nsignificantly elevated Jaccard index demonstrated by empirical results.\n","subjects":["Electrical Engineering and Systems Science/Image and Video Processing","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}