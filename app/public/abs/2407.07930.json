{"id":"2407.07930","title":"Token-Mol 1.0: Tokenized drug design with large language model","authors":"Jike Wang, Rui Qin, Mingyang Wang, Meijing Fang, Yangyang Zhang,\n  Yuchen Zhu, Qun Su, Qiaolin Gou, Chao Shen, Odin Zhang, Zhenxing Wu, Dejun\n  Jiang, Xujun Zhang, Huifeng Zhao, Xiaozhe Wan, Zhourui Wu, Liwei Liu, Yu\n  Kang, Chang-Yu Hsieh, Tingjun Hou","authorsParsed":[["Wang","Jike",""],["Qin","Rui",""],["Wang","Mingyang",""],["Fang","Meijing",""],["Zhang","Yangyang",""],["Zhu","Yuchen",""],["Su","Qun",""],["Gou","Qiaolin",""],["Shen","Chao",""],["Zhang","Odin",""],["Wu","Zhenxing",""],["Jiang","Dejun",""],["Zhang","Xujun",""],["Zhao","Huifeng",""],["Wan","Xiaozhe",""],["Wu","Zhourui",""],["Liu","Liwei",""],["Kang","Yu",""],["Hsieh","Chang-Yu",""],["Hou","Tingjun",""]],"versions":[{"version":"v1","created":"Wed, 10 Jul 2024 07:22:15 GMT"},{"version":"v2","created":"Mon, 19 Aug 2024 07:32:25 GMT"}],"updateDate":"2024-08-20","timestamp":1720596135000,"abstract":"  Significant interests have recently risen in leveraging sequence-based large\nlanguage models (LLMs) for drug design. However, most current applications of\nLLMs in drug discovery lack the ability to comprehend three-dimensional (3D)\nstructures, thereby limiting their effectiveness in tasks that explicitly\ninvolve molecular conformations. In this study, we introduced Token-Mol, a\ntoken-only 3D drug design model. This model encodes all molecular information,\nincluding 2D and 3D structures, as well as molecular property data, into\ntokens, which transforms classification and regression tasks in drug discovery\ninto probabilistic prediction problems, thereby enabling learning through a\nunified paradigm. Token-Mol is built on the transformer decoder architecture\nand trained using random causal masking techniques. Additionally, we proposed\nthe Gaussian cross-entropy (GCE) loss function to overcome the challenges in\nregression tasks, significantly enhancing the capacity of LLMs to learn\ncontinuous numerical values. Through a combination of fine-tuning and\nreinforcement learning (RL), Token-Mol achieves performance comparable to or\nsurpassing existing task-specific methods across various downstream tasks,\nincluding pocket-based molecular generation, conformation generation, and\nmolecular property prediction. Compared to existing molecular pre-trained\nmodels, Token-Mol exhibits superior proficiency in handling a wider range of\ndownstream tasks essential for drug design. Notably, our approach improves\nregression task accuracy by approximately 30% compared to similar token-only\nmethods. Token-Mol overcomes the precision limitations of token-only models and\nhas the potential to integrate seamlessly with general models such as ChatGPT,\npaving the way for the development of a universal artificial intelligence drug\ndesign model that facilitates rapid and high-quality drug design by experts.\n","subjects":["Quantitative Biology/Biomolecules","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}