{"id":"2407.18613","title":"Dilated Strip Attention Network for Image Restoration","authors":"Fangwei Hao, Jiesheng Wu, Ji Du, Yinjie Wang, Jing Xu","authorsParsed":[["Hao","Fangwei",""],["Wu","Jiesheng",""],["Du","Ji",""],["Wang","Yinjie",""],["Xu","Jing",""]],"versions":[{"version":"v1","created":"Fri, 26 Jul 2024 09:12:30 GMT"}],"updateDate":"2024-07-29","timestamp":1721985150000,"abstract":"  Image restoration is a long-standing task that seeks to recover the latent\nsharp image from its deteriorated counterpart. Due to the robust capacity of\nself-attention to capture long-range dependencies, transformer-based methods or\nsome attention-based convolutional neural networks have demonstrated promising\nresults on many image restoration tasks in recent years. However, existing\nattention modules encounters limited receptive fields or abundant parameters.\nIn order to integrate contextual information more effectively and efficiently,\nin this paper, we propose a dilated strip attention network (DSAN) for image\nrestoration. Specifically, to gather more contextual information for each pixel\nfrom its neighboring pixels in the same row or column, a dilated strip\nattention (DSA) mechanism is elaborately proposed. By employing the DSA\noperation horizontally and vertically, each location can harvest the contextual\ninformation from a much wider region. In addition, we utilize multi-scale\nreceptive fields across different feature groups in DSA to improve\nrepresentation learning. Extensive experiments show that our DSAN outperforms\nstate-of-the-art algorithms on several image restoration tasks.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Electrical Engineering and Systems Science/Image and Video Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}