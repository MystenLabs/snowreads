{"id":"2407.13745","title":"MaRINeR: Enhancing Novel Views by Matching Rendered Images with Nearby\n  References","authors":"Lukas B\\\"osiger, Mihai Dusmanu, Marc Pollefeys, and Zuria Bauer","authorsParsed":[["BÃ¶siger","Lukas",""],["Dusmanu","Mihai",""],["Pollefeys","Marc",""],["Bauer","Zuria",""]],"versions":[{"version":"v1","created":"Thu, 18 Jul 2024 17:50:03 GMT"}],"updateDate":"2024-07-19","timestamp":1721325003000,"abstract":"  Rendering realistic images from 3D reconstruction is an essential task of\nmany Computer Vision and Robotics pipelines, notably for mixed-reality\napplications as well as training autonomous agents in simulated environments.\nHowever, the quality of novel views heavily depends of the source\nreconstruction which is often imperfect due to noisy or missing geometry and\nappearance. Inspired by the recent success of reference-based super-resolution\nnetworks, we propose MaRINeR, a refinement method that leverages information of\na nearby mapping image to improve the rendering of a target viewpoint. We first\nestablish matches between the raw rendered image of the scene geometry from the\ntarget viewpoint and the nearby reference based on deep features, followed by\nhierarchical detail transfer. We show improved renderings in quantitative\nmetrics and qualitative examples from both explicit and implicit scene\nrepresentations. We further employ our method on the downstream tasks of\npseudo-ground-truth validation, synthetic data enhancement and detail recovery\nfor renderings of reduced 3D reconstructions.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}