{"id":"2407.03072","title":"On finite termination of quasi-Newton methods on quadratic problems","authors":"Aban Ansari-\\\"Onnestam, Anders Forsgren","authorsParsed":[["Ansari-Ã–nnestam","Aban",""],["Forsgren","Anders",""]],"versions":[{"version":"v1","created":"Wed, 3 Jul 2024 12:46:58 GMT"}],"updateDate":"2024-07-04","timestamp":1720010818000,"abstract":"  Quasi-Newton methods form an important class of methods for solving nonlinear\noptimization problems. In such methods, first order information is used to\napproximate the second derivative. The aim is to mimic the fast convergence\nthat can be guaranteed by Newton-based methods. In the best case, quasi-Newton\nmethods will far outperform steepest descent and other first order methods,\nwithout the computational cost of calculating the exact second derivative.\nThese convergence guarantees hold locally, which follows closely from the fact\nthat if the objective function is strongly convex it can be approximated well\nby a quadratic function close to the solution. Understanding the performance of\nquasi-Newton methods on quadratic problems with a symmetric positive definite\nHessian is therefore of vital importance. In the classic case, an approximation\nof the Hessian is updated at every iteration and exact line search is used. It\nis well known that the algorithm terminates finitely, even when the Hessian\napproximation is memoryless, i.e. requires only the most recent information. In\nthis paper, we explore the possibilities in which reliance on exact line search\nand dependence on conjugate search directions can be relaxed, while preserving\nfinite termination properties of quasi-Newton methods on quadratic problems.\n","subjects":["Mathematics/Optimization and Control"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}