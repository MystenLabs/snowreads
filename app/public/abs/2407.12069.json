{"id":"2407.12069","title":"One-Shot Unlearning of Personal Identities","authors":"Thomas De Min, Subhankar Roy, Massimiliano Mancini, St\\'ephane\n  Lathuili\\`ere, Elisa Ricci","authorsParsed":[["De Min","Thomas",""],["Roy","Subhankar",""],["Mancini","Massimiliano",""],["Lathuilière","Stéphane",""],["Ricci","Elisa",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 10:00:54 GMT"}],"updateDate":"2024-07-18","timestamp":1721124054000,"abstract":"  Machine unlearning (MU) aims to erase data from a model as if it never saw\nthem during training. To this extent, existing MU approaches assume complete or\npartial access to the training data, which can be limited over time due to\nprivacy regulations. However, no setting or benchmark exists to probe the\neffectiveness of MU methods in such scenarios, i.e. when training data is\nmissing. To fill this gap, we propose a novel task we call One-Shot Unlearning\nof Personal Identities (O-UPI) that evaluates unlearning models when the\ntraining data is not accessible. Specifically, we focus on the identity\nunlearning case, which is relevant due to current regulations requiring data\ndeletion after training. To cope with data absence, we expect users to provide\na portraiting picture to perform unlearning. To evaluate methods in O-UPI, we\nbenchmark the forgetting on CelebA and CelebA-HQ datasets with different\nunlearning set sizes. We test applicable methods on this challenging benchmark,\nproposing also an effective method that meta-learns to forget identities from a\nsingle image. Our findings indicate that existing approaches struggle when data\navailability is limited, with greater difficulty when there is dissimilarity\nbetween provided samples and data used at training time. We will release the\ncode and benchmark upon acceptance.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/"}