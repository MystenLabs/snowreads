{"id":"2407.20987","title":"PIXELMOD: Improving Soft Moderation of Visual Misleading Information on\n  Twitter","authors":"Pujan Paudel, Chen Ling, Jeremy Blackburn, and Gianluca Stringhini","authorsParsed":[["Paudel","Pujan",""],["Ling","Chen",""],["Blackburn","Jeremy",""],["Stringhini","Gianluca",""]],"versions":[{"version":"v1","created":"Tue, 30 Jul 2024 17:21:32 GMT"}],"updateDate":"2024-07-31","timestamp":1722360092000,"abstract":"  Images are a powerful and immediate vehicle to carry misleading or outright\nfalse messages, yet identifying image-based misinformation at scale poses\nunique challenges. In this paper, we present PIXELMOD, a system that leverages\nperceptual hashes, vector databases, and optical character recognition (OCR) to\nefficiently identify images that are candidates to receive soft moderation\nlabels on Twitter. We show that PIXELMOD outperforms existing image similarity\napproaches when applied to soft moderation, with negligible performance\noverhead. We then test PIXELMOD on a dataset of tweets surrounding the 2020 US\nPresidential Election, and find that it is able to identify visually misleading\nimages that are candidates for soft moderation with 0.99% false detection and\n2.06% false negatives.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Computers and Society"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}