{"id":"2408.12025","title":"Exploring Large Language Models for Feature Selection: A Data-centric\n  Perspective","authors":"Dawei Li, Zhen Tan, Huan Liu","authorsParsed":[["Li","Dawei",""],["Tan","Zhen",""],["Liu","Huan",""]],"versions":[{"version":"v1","created":"Wed, 21 Aug 2024 22:35:19 GMT"}],"updateDate":"2024-08-23","timestamp":1724279719000,"abstract":"  The rapid advancement of Large Language Models (LLMs) has significantly\ninfluenced various domains, leveraging their exceptional few-shot and zero-shot\nlearning capabilities. In this work, we aim to explore and understand the\nLLMs-based feature selection methods from a data-centric perspective. We begin\nby categorizing existing feature selection methods with LLMs into two groups:\ndata-driven feature selection which requires samples values to do statistical\ninference and text-based feature selection which utilizes prior knowledge of\nLLMs to do semantical associations using descriptive context. We conduct\nextensive experiments in both classification and regression tasks with LLMs in\nvarious sizes (e.g., GPT-4, ChatGPT and LLaMA-2). Our findings emphasize the\neffectiveness and robustness of text-based feature selection methods and\nshowcase their potentials using a real-world medical application. We also\ndiscuss the challenges and future opportunities in employing LLMs for feature\nselection, offering insights for further research and development in this\nemerging field.\n","subjects":["Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"n6l9erOSnNmtgklN_uauCNA0blba-9EpHGK5aJTZUPo","pdfSize":"619489"}
