{"id":"2408.02623","title":"YOWOv3: An Efficient and Generalized Framework for Human Action\n  Detection and Recognition","authors":"Duc Manh Nguyen Dang, Viet Hang Duong, Jia Ching Wang, Nhan Bui Duc","authorsParsed":[["Dang","Duc Manh Nguyen",""],["Duong","Viet Hang",""],["Wang","Jia Ching",""],["Duc","Nhan Bui",""]],"versions":[{"version":"v1","created":"Mon, 5 Aug 2024 16:48:03 GMT"},{"version":"v2","created":"Fri, 9 Aug 2024 00:17:51 GMT"}],"updateDate":"2024-08-12","timestamp":1722876483000,"abstract":"  In this paper, we propose a new framework called YOWOv3, which is an improved\nversion of YOWOv2, designed specifically for the task of Human Action Detection\nand Recognition. This framework is designed to facilitate extensive\nexperimentation with different configurations and supports easy customization\nof various components within the model, reducing efforts required for\nunderstanding and modifying the code. YOWOv3 demonstrates its superior\nperformance compared to YOWOv2 on two widely used datasets for Human Action\nDetection and Recognition: UCF101-24 and AVAv2.2. Specifically, the predecessor\nmodel YOWOv2 achieves an mAP of 85.2% and 20.3% on UCF101-24 and AVAv2.2,\nrespectively, with 109.7M parameters and 53.6 GFLOPs. In contrast, our model -\nYOWOv3, with only 59.8M parameters and 39.8 GFLOPs, achieves an mAP of 88.33%\nand 20.31% on UCF101-24 and AVAv2.2, respectively. The results demonstrate that\nYOWOv3 significantly reduces the number of parameters and GFLOPs while still\nachieving comparable performance.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"7Oiul30UL2SNwginFtnJmOOnMTcNXrso7prJAhAjgyA","pdfSize":"3902265","txDigest":"ctwLSxEV9ciVQS29vDdnaVvMWztgKrnsD4frdsb5q3H","endEpoch":"1","status":"CERTIFIED"}
