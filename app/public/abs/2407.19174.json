{"id":"2407.19174","title":"Reducing Spurious Correlation for Federated Domain Generalization","authors":"Shuran Ma, Weiying Xie, Daixun Li, Haowei Li, Yunsong Li","authorsParsed":[["Ma","Shuran",""],["Xie","Weiying",""],["Li","Daixun",""],["Li","Haowei",""],["Li","Yunsong",""]],"versions":[{"version":"v1","created":"Sat, 27 Jul 2024 05:06:31 GMT"}],"updateDate":"2024-07-30","timestamp":1722056791000,"abstract":"  The rapid development of multimedia has provided a large amount of data with\ndifferent distributions for visual tasks, forming different domains. Federated\nLearning (FL) can efficiently use this diverse data distributed on different\nclient media in a decentralized manner through model sharing. However, in\nopen-world scenarios, there is a challenge: global models may struggle to\npredict well on entirely new domain data captured by certain media, which were\nnot encountered during training. Existing methods still rely on strong\nstatistical correlations between samples and labels to address this issue,\nwhich can be misleading, as some features may establish spurious short-cut\ncorrelations with the predictions. To comprehensively address this challenge,\nwe introduce FedCD (Cross-Domain Invariant Federated Learning), an overall\noptimization framework at both the local and global levels. We introduce the\nSpurious Correlation Intervener (SCI), which employs invariance theory to\nlocally generate interventers for features in a self-supervised manner to\nreduce the model's susceptibility to spurious correlated features. Our approach\nrequires no sharing of data or features, only the gradients related to the\nmodel. Additionally, we develop the simple yet effective Risk Extrapolation\nAggregation strategy (REA), determining aggregation coefficients through\nmathematical optimization to facilitate global causal invariant predictions.\nExtensive experiments and ablation studies highlight the effectiveness of our\napproach. In both classification and object detection generalization tasks, our\nmethod outperforms the baselines by an average of at least 1.45% in Acc, 4.8%\nand 1.27% in mAP50.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}