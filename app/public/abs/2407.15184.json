{"id":"2407.15184","title":"Decoding Multilingual Moral Preferences: Unveiling LLM's Biases Through\n  the Moral Machine Experiment","authors":"Karina Vida and Fabian Damken and Anne Lauscher","authorsParsed":[["Vida","Karina",""],["Damken","Fabian",""],["Lauscher","Anne",""]],"versions":[{"version":"v1","created":"Sun, 21 Jul 2024 14:48:13 GMT"}],"updateDate":"2024-07-23","timestamp":1721573293000,"abstract":"  Large language models (LLMs) increasingly find their way into the most\ndiverse areas of our everyday lives. They indirectly influence people's\ndecisions or opinions through their daily use. Therefore, understanding how and\nwhich moral judgements these LLMs make is crucial. However, morality is not\nuniversal and depends on the cultural background. This raises the question of\nwhether these cultural preferences are also reflected in LLMs when prompted in\ndifferent languages or whether moral decision-making is consistent across\ndifferent languages. So far, most research has focused on investigating the\ninherent values of LLMs in English. While a few works conduct multilingual\nanalyses of moral bias in LLMs in a multilingual setting, these analyses do not\ngo beyond atomic actions. To the best of our knowledge, a multilingual analysis\nof moral bias in dilemmas has not yet been conducted.\n  To address this, our paper builds on the moral machine experiment (MME) to\ninvestigate the moral preferences of five LLMs, Falcon, Gemini, Llama, GPT, and\nMPT, in a multilingual setting and compares them with the preferences collected\nfrom humans belonging to different cultures. To accomplish this, we generate\n6500 scenarios of the MME and prompt the models in ten languages on which\naction to take. Our analysis reveals that all LLMs inhibit different moral\nbiases to some degree and that they not only differ from the human preferences\nbut also across multiple languages within the models themselves. Moreover, we\nfind that almost all models, particularly Llama 3, divert greatly from human\nvalues and, for instance, prefer saving fewer people over saving more.\n","subjects":["Computing Research Repository/Computers and Society","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}