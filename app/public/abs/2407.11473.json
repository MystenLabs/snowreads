{"id":"2407.11473","title":"Quantum Maximum Entropy Inference and Hamiltonian Learning","authors":"Minbo Gao, Zhengfeng Ji, Fuchao Wei","authorsParsed":[["Gao","Minbo",""],["Ji","Zhengfeng",""],["Wei","Fuchao",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 08:11:34 GMT"}],"updateDate":"2024-07-17","timestamp":1721117494000,"abstract":"  Maximum entropy inference and learning of graphical models are pivotal tasks\nin learning theory and optimization. This work extends algorithms for these\nproblems, including generalized iterative scaling (GIS) and gradient descent\n(GD), to the quantum realm. While the generalization, known as quantum\niterative scaling (QIS), is straightforward, the key challenge lies in the\nnon-commutative nature of quantum problem instances, rendering the convergence\nrate analysis significantly more challenging than the classical case. Our\nprincipal technical contribution centers on a rigorous analysis of the\nconvergence rates, involving the establishment of both lower and upper bounds\non the spectral radius of the Jacobian matrix for each iteration of these\nalgorithms. Furthermore, we explore quasi-Newton methods to enhance the\nperformance of QIS and GD. Specifically, we propose using Anderson mixing and\nthe L-BFGS method for QIS and GD, respectively. These quasi-Newton techniques\nexhibit remarkable efficiency gains, resulting in orders of magnitude\nimprovements in performance. As an application, our algorithms provide a viable\napproach to designing Hamiltonian learning algorithms.\n","subjects":["Computing Research Repository/Machine Learning","Physics/Quantum Physics"],"license":"http://creativecommons.org/licenses/by/4.0/"}