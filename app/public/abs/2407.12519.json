{"id":"2407.12519","title":"Causality-inspired Discriminative Feature Learning in Triple Domains for\n  Gait Recognition","authors":"Haijun Xiong, Bin Feng, Xinggang Wang and Wenyu Liu","authorsParsed":[["Xiong","Haijun",""],["Feng","Bin",""],["Wang","Xinggang",""],["Liu","Wenyu",""]],"versions":[{"version":"v1","created":"Wed, 17 Jul 2024 12:16:44 GMT"}],"updateDate":"2024-07-18","timestamp":1721218604000,"abstract":"  Gait recognition is a biometric technology that distinguishes individuals by\ntheir walking patterns. However, previous methods face challenges when\naccurately extracting identity features because they often become entangled\nwith non-identity clues. To address this challenge, we propose CLTD, a\ncausality-inspired discriminative feature learning module designed to\neffectively eliminate the influence of confounders in triple domains, \\ie,\nspatial, temporal, and spectral. Specifically, we utilize the Cross Pixel-wise\nAttention Generator (CPAG) to generate attention distributions for factual and\ncounterfactual features in spatial and temporal domains. Then, we introduce the\nFourier Projection Head (FPH) to project spatial features into the spectral\nspace, which preserves essential information while reducing computational\ncosts. Additionally, we employ an optimization method with contrastive learning\nto enforce semantic consistency constraints across sequences from the same\nsubject. Our approach has demonstrated significant performance improvements on\nchallenging datasets, proving its effectiveness. Moreover, it can be seamlessly\nintegrated into existing gait recognition methods.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}