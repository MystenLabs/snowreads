{"id":"2407.15835","title":"dMel: Speech Tokenization made Simple","authors":"He Bai, Tatiana Likhomanenko, Ruixiang Zhang, Zijin Gu, Zakaria\n  Aldeneh, Navdeep Jaitly","authorsParsed":[["Bai","He",""],["Likhomanenko","Tatiana",""],["Zhang","Ruixiang",""],["Gu","Zijin",""],["Aldeneh","Zakaria",""],["Jaitly","Navdeep",""]],"versions":[{"version":"v1","created":"Mon, 22 Jul 2024 17:51:53 GMT"}],"updateDate":"2024-07-23","timestamp":1721670713000,"abstract":"  Large language models have revolutionized natural language processing by\nleveraging self-supervised pretraining on vast textual data. Inspired by this\nsuccess, researchers have investigated complicated speech tokenization methods\nto discretize continuous speech signals so that language modeling techniques\ncan be applied to speech data. However, existing approaches either model\nsemantic tokens, potentially losing acoustic information, or model acoustic\ntokens, risking the loss of semantic information. Having multiple token types\nalso complicates the architecture and requires additional pretraining. Here we\nshow that discretizing mel-filterbank channels into discrete intensity bins\nproduces a simple representation (dMel), that performs better than other\nexisting speech tokenization methods. Using a transformer decoder-only\narchitecture for speech-text modeling, we comprehensively evaluate different\nspeech tokenization methods on speech recognition (ASR), speech synthesis\n(TTS). Our results demonstrate the effectiveness of dMel in achieving high\nperformance on both tasks within a unified framework, paving the way for\nefficient and effective joint modeling of speech and text.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Sound","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}