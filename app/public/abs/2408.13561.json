{"id":"2408.13561","title":"Variational Autoencoder for Anomaly Detection: A Comparative Study","authors":"Huy Hoang Nguyen, Cuong Nhat Nguyen, Xuan Tung Dao, Quoc Trung Duong,\n  Dzung Pham Thi Kim, Minh-Tan Pham","authorsParsed":[["Nguyen","Huy Hoang",""],["Nguyen","Cuong Nhat",""],["Dao","Xuan Tung",""],["Duong","Quoc Trung",""],["Kim","Dzung Pham Thi",""],["Pham","Minh-Tan",""]],"versions":[{"version":"v1","created":"Sat, 24 Aug 2024 12:07:57 GMT"}],"updateDate":"2024-08-27","timestamp":1724501277000,"abstract":"  This paper aims to conduct a comparative analysis of contemporary Variational\nAutoencoder (VAE) architectures employed in anomaly detection, elucidating\ntheir performance and behavioral characteristics within this specific task. The\narchitectural configurations under consideration encompass the original VAE\nbaseline, the VAE with a Gaussian Random Field prior (VAE-GRF), and the VAE\nincorporating a vision transformer (ViT-VAE). The findings reveal that ViT-VAE\nexhibits exemplary performance across various scenarios, whereas VAE-GRF may\nnecessitate more intricate hyperparameter tuning to attain its optimal\nperformance state. Additionally, to mitigate the propensity for over-reliance\non results derived from the widely used MVTec dataset, this paper leverages the\nrecently-public MiAD dataset for benchmarking. This deliberate inclusion seeks\nto enhance result competitiveness by alleviating the impact of domain-specific\nmodels tailored exclusively for MVTec, thereby contributing to a more robust\nevaluation framework. Codes is available at\nhttps://github.com/endtheme123/VAE-compare.git.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Electrical Engineering and Systems Science/Image and Video Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}