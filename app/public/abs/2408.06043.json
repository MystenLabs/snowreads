{"id":"2408.06043","title":"Enhancing Dialogue Speech Recognition with Robust Contextual Awareness\n  via Noise Representation Learning","authors":"Wonjun Lee, San Kim, Gary Geunbae Lee","authorsParsed":[["Lee","Wonjun",""],["Kim","San",""],["Lee","Gary Geunbae",""]],"versions":[{"version":"v1","created":"Mon, 12 Aug 2024 10:21:09 GMT"}],"updateDate":"2024-08-13","timestamp":1723458069000,"abstract":"  Recent dialogue systems rely on turn-based spoken interactions, requiring\naccurate Automatic Speech Recognition (ASR). Errors in ASR can significantly\nimpact downstream dialogue tasks. To address this, using dialogue context from\nuser and agent interactions for transcribing subsequent utterances has been\nproposed. This method incorporates the transcription of the user's speech and\nthe agent's response as model input, using the accumulated context generated by\neach turn. However, this context is susceptible to ASR errors because it is\ngenerated by the ASR model in an auto-regressive fashion. Such noisy context\ncan further degrade the benefits of context input, resulting in suboptimal ASR\nperformance. In this paper, we introduce Context Noise Representation Learning\n(CNRL) to enhance robustness against noisy context, ultimately improving\ndialogue speech recognition accuracy. To maximize the advantage of context\nawareness, our approach includes decoder pre-training using text-based dialogue\ndata and noise representation learning for a context encoder. Based on the\nevaluation of speech dialogues, our method shows superior results compared to\nbaselines. Furthermore, the strength of our approach is highlighted in noisy\nenvironments where user speech is barely audible due to real-world noise,\nrelying on contextual information to transcribe the input accurately.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Sound","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by/4.0/"}