{"id":"2407.15212","title":"Surfel-based Gaussian Inverse Rendering for Fast and Relightable Dynamic\n  Human Reconstruction from Monocular Video","authors":"Yiqun Zhao, Chenming Wu, Binbin Huang, Yihao Zhi, Chen Zhao, Jingdong\n  Wang and Shenghua Gao","authorsParsed":[["Zhao","Yiqun",""],["Wu","Chenming",""],["Huang","Binbin",""],["Zhi","Yihao",""],["Zhao","Chen",""],["Wang","Jingdong",""],["Gao","Shenghua",""]],"versions":[{"version":"v1","created":"Sun, 21 Jul 2024 16:34:03 GMT"},{"version":"v2","created":"Tue, 23 Jul 2024 12:57:32 GMT"}],"updateDate":"2024-07-24","timestamp":1721579643000,"abstract":"  Efficient and accurate reconstruction of a relightable, dynamic clothed human\navatar from a monocular video is crucial for the entertainment industry. This\npaper introduces the Surfel-based Gaussian Inverse Avatar (SGIA) method, which\nintroduces efficient training and rendering for relightable dynamic human\nreconstruction. SGIA advances previous Gaussian Avatar methods by\ncomprehensively modeling Physically-Based Rendering (PBR) properties for\nclothed human avatars, allowing for the manipulation of avatars into novel\nposes under diverse lighting conditions. Specifically, our approach integrates\npre-integration and image-based lighting for fast light calculations that\nsurpass the performance of existing implicit-based techniques. To address\nchallenges related to material lighting disentanglement and accurate geometry\nreconstruction, we propose an innovative occlusion approximation strategy and a\nprogressive training approach. Extensive experiments demonstrate that SGIA not\nonly achieves highly accurate physical properties but also significantly\nenhances the realistic relighting of dynamic human avatars, providing a\nsubstantial speed advantage. We exhibit more results in our project page:\nhttps://GS-IA.github.io.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Graphics"],"license":"http://creativecommons.org/licenses/by/4.0/"}