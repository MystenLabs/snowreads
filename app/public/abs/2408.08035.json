{"id":"2408.08035","title":"An Advanced Deep Learning Based Three-Stream Hybrid Model for Dynamic\n  Hand Gesture Recognition","authors":"Md Abdur Rahim, Abu Saleh Musa Miah, Hemel Sharker Akash, Jungpil\n  Shin, Md. Imran Hossain and Md. Najmul Hossain","authorsParsed":[["Rahim","Md Abdur",""],["Miah","Abu Saleh Musa",""],["Akash","Hemel Sharker",""],["Shin","Jungpil",""],["Hossain","Md. Imran",""],["Hossain","Md. Najmul",""]],"versions":[{"version":"v1","created":"Thu, 15 Aug 2024 09:05:00 GMT"}],"updateDate":"2024-08-16","timestamp":1723712700000,"abstract":"  In the modern context, hand gesture recognition has emerged as a focal point.\nThis is due to its wide range of applications, which include comprehending sign\nlanguage, factories, hands-free devices, and guiding robots. Many researchers\nhave attempted to develop more effective techniques for recognizing these hand\ngestures. However, there are challenges like dataset limitations, variations in\nhand forms, external environments, and inconsistent lighting conditions. To\naddress these challenges, we proposed a novel three-stream hybrid model that\ncombines RGB pixel and skeleton-based features to recognize hand gestures. In\nthe procedure, we preprocessed the dataset, including augmentation, to make\nrotation, translation, and scaling independent systems. We employed a\nthree-stream hybrid model to extract the multi-feature fusion using the power\nof the deep learning module. In the first stream, we extracted the initial\nfeature using the pre-trained Imagenet module and then enhanced this feature by\nusing a multi-layer of the GRU and LSTM modules. In the second stream, we\nextracted the initial feature with the pre-trained ReseNet module and enhanced\nit with the various combinations of the GRU and LSTM modules. In the third\nstream, we extracted the hand pose key points using the media pipe and then\nenhanced them using the stacked LSTM to produce the hierarchical feature. After\nthat, we concatenated the three features to produce the final. Finally, we\nemployed a classification module to produce the probabilistic map to generate\npredicted output. We mainly produced a powerful feature vector by taking\nadvantage of the pixel-based deep learning feature and pos-estimation-based\nstacked deep learning feature, including a pre-trained model with a scratched\ndeep learning model for unequalled gesture detection capabilities.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"h8dVJVxZMgJbAzihCxCwiEdhvXsmwfGT55EUXIzJYKM","pdfSize":"1270727"}
