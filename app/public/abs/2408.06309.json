{"id":"2408.06309","title":"A distance theorem for inhomogenous random rectangular matrices","authors":"Manuel Fernandez V","authorsParsed":[["Fernandez","Manuel","V"]],"versions":[{"version":"v1","created":"Mon, 12 Aug 2024 17:24:08 GMT"}],"updateDate":"2024-08-13","timestamp":1723483448000,"abstract":"  Let $A \\in \\mathbb{R}^{n \\times (n - d)}$ be a random matrix with independent\nuniformly anti-concentrated entries satisfying $\\mathbb{E}\\lvert A\\rvert_{HS}^2\n\\leq Kn(n-d)$ and let $H$ be the subspace spanned by $H$. Let $X \\in\n\\mathbb{R}^n$ be a random vector with uniformly anti-concentrated entries. We\nshow that when $1 \\leq d \\leq \\lambda n/\\log n$ the distance between between\n$X$ and $H$ satisfies the following following small ball probability estimate:\n  \\[\n  \\Pr\\left( \\text{dis}(X,H) \\leq t\\sqrt{d} \\right)\n  \\leq (Ct)^{d} + e^{-cn},\n  \\]\n  for some constants $\\lambda,c,C > 0$. This extends the distance theorems of\nRudelson and Vershynin, Livshyts, and Livshyts,Tikhomirov, and Vershynin by\ndropping any identical distribution assumptions about the entries of $X$ and\n$A$. Furthermore it can be applied to prove numerous results about random\nmatrices in the inhomogenous setting. These include lower tail estimates on the\nsmallest singular value of rectangular matrices and upper tail estimates on the\nsmallest singular value of square matrices. To obtain a distance theorem for\ninhomogenous rectangular matrices we introduce a new tool for this new general\nensemble of random matrices, Randomized Logarithmic LCD, a natural combination\nof the Randomized LCD, used in study of smallest singular values of\ninhomogenous square matrices, and of the Logarithmic LCD, used in the study of\nno-gaps delocalization of eigenvectors and the smallest singular values of\nHermitian random matrices.\n","subjects":["Mathematics/Probability","Mathematics/Metric Geometry"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}