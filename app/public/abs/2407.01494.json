{"id":"2407.01494","title":"FoleyCrafter: Bring Silent Videos to Life with Lifelike and Synchronized\n  Sounds","authors":"Yiming Zhang, Yicheng Gu, Yanhong Zeng, Zhening Xing, Yuancheng Wang,\n  Zhizheng Wu, Kai Chen","authorsParsed":[["Zhang","Yiming",""],["Gu","Yicheng",""],["Zeng","Yanhong",""],["Xing","Zhening",""],["Wang","Yuancheng",""],["Wu","Zhizheng",""],["Chen","Kai",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 17:35:56 GMT"}],"updateDate":"2024-07-02","timestamp":1719855356000,"abstract":"  We study Neural Foley, the automatic generation of high-quality sound effects\nsynchronizing with videos, enabling an immersive audio-visual experience.\nDespite its wide range of applications, existing approaches encounter\nlimitations when it comes to simultaneously synthesizing high-quality and\nvideo-aligned (i.e.,, semantic relevant and temporal synchronized) sounds. To\novercome these limitations, we propose FoleyCrafter, a novel framework that\nleverages a pre-trained text-to-audio model to ensure high-quality audio\ngeneration. FoleyCrafter comprises two key components: the semantic adapter for\nsemantic alignment and the temporal controller for precise audio-video\nsynchronization. The semantic adapter utilizes parallel cross-attention layers\nto condition audio generation on video features, producing realistic sound\neffects that are semantically relevant to the visual content. Meanwhile, the\ntemporal controller incorporates an onset detector and a timestampbased adapter\nto achieve precise audio-video alignment. One notable advantage of FoleyCrafter\nis its compatibility with text prompts, enabling the use of text descriptions\nto achieve controllable and diverse video-to-audio generation according to user\nintents. We conduct extensive quantitative and qualitative experiments on\nstandard benchmarks to verify the effectiveness of FoleyCrafter. Models and\ncodes are available at https://github.com/open-mmlab/FoleyCrafter.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Sound","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"StoOXrpWA2dcEJ19hHpIIL3mJVJArHtHObKpWUTtn28","pdfSize":"26422310"}
