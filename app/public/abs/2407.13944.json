{"id":"2407.13944","title":"PowerTrain: Fast, Generalizable Time and Power Prediction Models to\n  Optimize DNN Training on Accelerated Edges","authors":"Prashanthi S.K., Saisamarth Taluri, Beautlin S, Lakshya Karwa, Yogesh\n  Simmhan","authorsParsed":[["K.","Prashanthi S.",""],["Taluri","Saisamarth",""],["S","Beautlin",""],["Karwa","Lakshya",""],["Simmhan","Yogesh",""]],"versions":[{"version":"v1","created":"Thu, 18 Jul 2024 23:41:44 GMT"}],"updateDate":"2024-07-22","timestamp":1721346104000,"abstract":"  Accelerated edge devices, like Nvidia's Jetson with 1000+ CUDA cores, are\nincreasingly used for DNN training and federated learning, rather than just for\ninferencing workloads. A unique feature of these compact devices is their\nfine-grained control over CPU, GPU, memory frequencies, and active CPU cores,\nwhich can limit their power envelope in a constrained setting while throttling\nthe compute performance. Given this vast 10k+ parameter space, selecting a\npower mode for dynamically arriving training workloads to exploit\npower-performance trade-offs requires costly profiling for each new workload,\nor is done \\textit{ad hoc}. We propose \\textit{PowerTrain}, a transfer-learning\napproach to accurately predict the power and time consumed when training a\ngiven DNN workload (model + dataset) using any specified power mode\n(CPU/GPU/memory frequencies, core-count). It requires a one-time offline\nprofiling of $1000$s of power modes for a reference DNN workload on a single\nJetson device (Orin AGX) to build Neural Network (NN) based prediction models\nfor time and power. These NN models are subsequently transferred (retrained)\nfor a new DNN workload, or even a different Jetson device, with minimal\nadditional profiling of just $50$ power modes to make accurate time and power\npredictions. These are then used to rapidly construct the Pareto front and\nselect the optimal power mode for the new workload. PowerTrain's predictions\nare robust to new workloads, exhibiting a low MAPE of $<6\\%$ for power and\n$<15\\%$ for time on six new training workloads for up to $4400$ power modes,\nwhen transferred from a ResNet reference workload on Orin AGX. It is also\nresilient when transferred to two entirely new Jetson devices with prediction\nerrors of $<14.5\\%$ and $<11\\%$. These outperform baseline predictions by more\nthan $10\\%$ and baseline optimizations by up to $45\\%$ on time and $88\\%$ on\npower.\n","subjects":["Computing Research Repository/Distributed, Parallel, and Cluster Computing","Electrical Engineering and Systems Science/Signal Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}