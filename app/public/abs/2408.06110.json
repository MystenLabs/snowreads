{"id":"2408.06110","title":"RISurConv: Rotation Invariant Surface Attention-Augmented Convolutions\n  for 3D Point Cloud Classification and Segmentation","authors":"Zhiyuan Zhang, Licheng Yang, Zhiyu Xiang","authorsParsed":[["Zhang","Zhiyuan",""],["Yang","Licheng",""],["Xiang","Zhiyu",""]],"versions":[{"version":"v1","created":"Mon, 12 Aug 2024 12:47:37 GMT"}],"updateDate":"2024-08-13","timestamp":1723466857000,"abstract":"  Despite the progress on 3D point cloud deep learning, most prior works focus\non learning features that are invariant to translation and point permutation,\nand very limited efforts have been devoted for rotation invariant property.\nSeveral recent studies achieve rotation invariance at the cost of lower\naccuracies. In this work, we close this gap by proposing a novel yet effective\nrotation invariant architecture for 3D point cloud classification and\nsegmentation. Instead of traditional pointwise operations, we construct local\ntriangle surfaces to capture more detailed surface structure, based on which we\ncan extract highly expressive rotation invariant surface properties which are\nthen integrated into an attention-augmented convolution operator named\nRISurConv to generate refined attention features via self-attention layers.\nBased on RISurConv we build an effective neural network for 3D point cloud\nanalysis that is invariant to arbitrary rotations while maintaining high\naccuracy. We verify the performance on various benchmarks with supreme results\nobtained surpassing the previous state-of-the-art by a large margin. We achieve\nan overall accuracy of 96.0% (+4.7%) on ModelNet40, 93.1% (+12.8%) on\nScanObjectNN, and class accuracies of 91.5% (+3.6%), 82.7% (+5.1%), and 78.5%\n(+9.2%) on the three categories of the FG3D dataset for the fine-grained\nclassification task. Additionally, we achieve 81.5% (+1.0%) mIoU on ShapeNet\nfor the segmentation task. Code is available here:\nhttps://github.com/cszyzhang/RISurConv\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}