{"id":"2408.08437","title":"PQV-Mobile: A Combined Pruning and Quantization Toolkit to Optimize\n  Vision Transformers for Mobile Applications","authors":"Kshitij Bhardwaj","authorsParsed":[["Bhardwaj","Kshitij",""]],"versions":[{"version":"v1","created":"Thu, 15 Aug 2024 22:10:10 GMT"}],"updateDate":"2024-08-19","timestamp":1723759810000,"abstract":"  While Vision Transformers (ViTs) are extremely effective at computer vision\ntasks and are replacing convolutional neural networks as the new\nstate-of-the-art, they are complex and memory-intensive models. In order to\neffectively run these models on resource-constrained mobile/edge systems, there\nis a need to not only compress these models but also to optimize them and\nconvert them into deployment-friendly formats. To this end, this paper presents\na combined pruning and quantization tool, called PQV-Mobile, to optimize vision\ntransformers for mobile applications. The tool is able to support different\ntypes of structured pruning based on magnitude importance, Taylor importance,\nand Hessian importance. It also supports quantization from FP32 to FP16 and\nint8, targeting different mobile hardware backends. We demonstrate the\ncapabilities of our tool and show important latency-memory-accuracy trade-offs\nfor different amounts of pruning and int8 quantization with Facebook Data\nEfficient Image Transformer (DeiT) models. Our results show that even pruning a\nDeiT model by 9.375% and quantizing it to int8 from FP32 followed by optimizing\nfor mobile applications, we find a latency reduction by 7.18X with a small\naccuracy loss of 2.24%. The tool is open source.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"DJ_zI-Eq1R4jqK7-MvDexVPQCv3BoVzKwpzMcILnuoc","pdfSize":"1396515"}
