{"id":"2408.04651","title":"Knowledge AI: Fine-tuning NLP Models for Facilitating Scientific\n  Knowledge Extraction and Understanding","authors":"Balaji Muralidharan, Hayden Beadles, Reza Marzban, Kalyan Sashank\n  Mupparaju","authorsParsed":[["Muralidharan","Balaji",""],["Beadles","Hayden",""],["Marzban","Reza",""],["Mupparaju","Kalyan Sashank",""]],"versions":[{"version":"v1","created":"Sun, 4 Aug 2024 01:32:09 GMT"}],"updateDate":"2024-08-12","timestamp":1722735129000,"abstract":"  This project investigates the efficacy of Large Language Models (LLMs) in\nunderstanding and extracting scientific knowledge across specific domains and\nto create a deep learning framework: Knowledge AI. As a part of this framework,\nwe employ pre-trained models and fine-tune them on datasets in the scientific\ndomain. The models are adapted for four key Natural Language Processing (NLP)\ntasks: summarization, text generation, question answering, and named entity\nrecognition. Our results indicate that domain-specific fine-tuning\nsignificantly enhances model performance in each of these tasks, thereby\nimproving their applicability for scientific contexts. This adaptation enables\nnon-experts to efficiently query and extract information within targeted\nscientific fields, demonstrating the potential of fine-tuned LLMs as a tool for\nknowledge discovery in the sciences.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/"}