{"id":"2407.19449","title":"A High-Throughput FPGA Accelerator for Lightweight CNNs With Balanced\n  Dataflow","authors":"Zhiyuan Zhao, Yihao Chen, Pengcheng Feng, Jixing Li, Gang Chen,\n  Rongxuan Shen, Huaxiang Lu","authorsParsed":[["Zhao","Zhiyuan",""],["Chen","Yihao",""],["Feng","Pengcheng",""],["Li","Jixing",""],["Chen","Gang",""],["Shen","Rongxuan",""],["Lu","Huaxiang",""]],"versions":[{"version":"v1","created":"Sun, 28 Jul 2024 09:53:03 GMT"},{"version":"v2","created":"Tue, 30 Jul 2024 00:56:38 GMT"}],"updateDate":"2024-07-31","timestamp":1722160383000,"abstract":"  FPGA accelerators for lightweight neural convolutional networks (LWCNNs) have\nrecently attracted significant attention. Most existing LWCNN accelerators\nfocus on single-Computing-Engine (CE) architecture with local optimization.\nHowever, these designs typically suffer from high on-chip/off-chip memory\noverhead and low computational efficiency due to their layer-by-layer dataflow\nand unified resource mapping mechanisms. To tackle these issues, a novel\nmulti-CE-based accelerator with balanced dataflow is proposed to efficiently\naccelerate LWCNN through memory-oriented and computing-oriented optimizations.\nFirstly, a streaming architecture with hybrid CEs is designed to minimize\noff-chip memory access while maintaining a low cost of on-chip buffer size.\nSecondly, a balanced dataflow strategy is introduced for streaming\narchitectures to enhance computational efficiency by improving efficient\nresource mapping and mitigating data congestion. Furthermore, a resource-aware\nmemory and parallelism allocation methodology is proposed, based on a\nperformance model, to achieve better performance and scalability. The proposed\naccelerator is evaluated on Xilinx ZC706 platform using MobileNetV2 and\nShuffleNetV2.Implementation results demonstrate that the proposed accelerator\ncan save up to 68.3% of on-chip memory size with reduced off-chip memory access\ncompared to the reference design. It achieves an impressive performance of up\nto 2092.4 FPS and a state-of-the-art MAC efficiency of up to 94.58%, while\nmaintaining a high DSP utilization of 95%, thus significantly outperforming\ncurrent LWCNN accelerators.\n","subjects":["Computing Research Repository/Hardware Architecture"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}