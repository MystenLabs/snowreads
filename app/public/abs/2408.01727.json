{"id":"2408.01727","title":"A Robust Compressed Push-Pull Method for Decentralized Nonconvex\n  Optimization","authors":"Yiwei Liao, Zhuorui Li, Shi Pu, and Tsung-Hui Chang","authorsParsed":[["Liao","Yiwei",""],["Li","Zhuorui",""],["Pu","Shi",""],["Chang","Tsung-Hui",""]],"versions":[{"version":"v1","created":"Sat, 3 Aug 2024 09:51:22 GMT"}],"updateDate":"2024-08-06","timestamp":1722678682000,"abstract":"  In the modern paradigm of multi-agent networks, communication has become one\nof the main bottlenecks for decentralized optimization, where a large number of\nagents are involved in minimizing the average of the local cost functions. In\nthis paper, we propose a robust compressed push-pull algorithm (RCPP) that\ncombines gradient tracking with communication compression. In particular, RCPP\nis robust under a much more general class of compression operators that allow\nboth relative and absolute compression errors, in contrast to the existing\nworks which can handle either one of them or assume convex problems. We show\nthat RCPP enjoys sublinear convergence rate for smooth and possibly nonconvex\nobjective functions over general directed networks. Moreover, under the\nadditional Polyak-{\\L}ojasiewicz condition, linear convergence rate can be\nachieved for RCPP. Numerical examples verify the theoretical findings and\ndemonstrate the efficiency, flexibility, and robustness of the proposed\nalgorithm.\n","subjects":["Mathematics/Optimization and Control"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}