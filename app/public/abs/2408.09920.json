{"id":"2408.09920","title":"Sliced Maximal Information Coefficient: A Training-Free Approach for\n  Image Quality Assessment Enhancement","authors":"Kang Xiao, Xu Wang, Yulin He, Baoliang Chen, Xuelin Shen","authorsParsed":[["Xiao","Kang",""],["Wang","Xu",""],["He","Yulin",""],["Chen","Baoliang",""],["Shen","Xuelin",""]],"versions":[{"version":"v1","created":"Mon, 19 Aug 2024 11:55:32 GMT"}],"updateDate":"2024-08-20","timestamp":1724068532000,"abstract":"  Full-reference image quality assessment (FR-IQA) models generally operate by\nmeasuring the visual differences between a degraded image and its reference.\nHowever, existing FR-IQA models including both the classical ones (eg, PSNR and\nSSIM) and deep-learning based measures (eg, LPIPS and DISTS) still exhibit\nlimitations in capturing the full perception characteristics of the human\nvisual system (HVS). In this paper, instead of designing a new FR-IQA measure,\nwe aim to explore a generalized human visual attention estimation strategy to\nmimic the process of human quality rating and enhance existing IQA models. In\nparticular, we model human attention generation by measuring the statistical\ndependency between the degraded image and the reference image. The dependency\nis captured in a training-free manner by our proposed sliced maximal\ninformation coefficient and exhibits surprising generalization in different IQA\nmeasures. Experimental results verify the performance of existing IQA models\ncan be consistently improved when our attention module is incorporated. The\nsource code is available at https://github.com/KANGX99/SMIC.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Multimedia","Electrical Engineering and Systems Science/Image and Video Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}