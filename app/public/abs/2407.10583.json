{"id":"2407.10583","title":"Three Dogmas of Reinforcement Learning","authors":"David Abel, Mark K. Ho, Anna Harutyunyan","authorsParsed":[["Abel","David",""],["Ho","Mark K.",""],["Harutyunyan","Anna",""]],"versions":[{"version":"v1","created":"Mon, 15 Jul 2024 10:03:24 GMT"}],"updateDate":"2024-07-16","timestamp":1721037804000,"abstract":"  Modern reinforcement learning has been conditioned by at least three dogmas.\nThe first is the environment spotlight, which refers to our tendency to focus\non modeling environments rather than agents. The second is our treatment of\nlearning as finding the solution to a task, rather than adaptation. The third\nis the reward hypothesis, which states that all goals and purposes can be well\nthought of as maximization of a reward signal. These three dogmas shape much of\nwhat we think of as the science of reinforcement learning. While each of the\ndogmas have played an important role in developing the field, it is time we\nbring them to the surface and reflect on whether they belong as basic\ningredients of our scientific paradigm. In order to realize the potential of\nreinforcement learning as a canonical frame for researching intelligent agents,\nwe suggest that it is time we shed dogmas one and two entirely, and embrace a\nnuanced approach to the third.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}