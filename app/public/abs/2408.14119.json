{"id":"2408.14119","title":"Contrastive Learning Subspace for Text Clustering","authors":"Qian Yong, Chen Chen, Xiabing Zhou","authorsParsed":[["Yong","Qian",""],["Chen","Chen",""],["Zhou","Xiabing",""]],"versions":[{"version":"v1","created":"Mon, 26 Aug 2024 09:08:26 GMT"}],"updateDate":"2024-08-27","timestamp":1724663306000,"abstract":"  Contrastive learning has been frequently investigated to learn effective\nrepresentations for text clustering tasks. While existing contrastive\nlearning-based text clustering methods only focus on modeling instance-wise\nsemantic similarity relationships, they ignore contextual information and\nunderlying relationships among all instances that needs to be clustered. In\nthis paper, we propose a novel text clustering approach called Subspace\nContrastive Learning (SCL) which models cluster-wise relationships among\ninstances. Specifically, the proposed SCL consists of two main modules: (1) a\nself-expressive module that constructs virtual positive samples and (2) a\ncontrastive learning module that further learns a discriminative subspace to\ncapture task-specific cluster-wise relationships among texts. Experimental\nresults show that the proposed SCL method not only has achieved superior\nresults on multiple task clustering datasets but also has less complexity in\npositive sample construction.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}