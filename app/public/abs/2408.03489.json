{"id":"2408.03489","title":"Harnessing the Power of LLMs in Source Code Vulnerability Detection","authors":"Andrew A Mahyari","authorsParsed":[["Mahyari","Andrew A",""]],"versions":[{"version":"v1","created":"Wed, 7 Aug 2024 00:48:49 GMT"}],"updateDate":"2024-08-08","timestamp":1722991729000,"abstract":"  Software vulnerabilities, caused by unintentional flaws in source code, are a\nprimary root cause of cyberattacks. Static analysis of source code has been\nwidely used to detect these unintentional defects introduced by software\ndevelopers. Large Language Models (LLMs) have demonstrated human-like\nconversational abilities due to their capacity to capture complex patterns in\nsequential data, such as natural languages. In this paper, we harness LLMs'\ncapabilities to analyze source code and detect known vulnerabilities. To ensure\nthe proposed vulnerability detection method is universal across multiple\nprogramming languages, we convert source code to LLVM IR and train LLMs on\nthese intermediate representations. We conduct extensive experiments on various\nLLM architectures and compare their accuracy. Our comprehensive experiments on\nreal-world and synthetic codes from NVD and SARD demonstrate high accuracy in\nidentifying source code vulnerabilities.\n","subjects":["Computing Research Repository/Software Engineering","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Cryptography and Security"],"license":"http://creativecommons.org/licenses/by/4.0/"}