{"id":"2408.13355","title":"Disentangled Training with Adversarial Examples For Robust\n  Small-footprint Keyword Spotting","authors":"Zhenyu Wang, Li Wan, Biqiao Zhang, Yiteng Huang, Shang-Wen Li, Ming\n  Sun, Xin Lei, Zhaojun Yang","authorsParsed":[["Wang","Zhenyu",""],["Wan","Li",""],["Zhang","Biqiao",""],["Huang","Yiteng",""],["Li","Shang-Wen",""],["Sun","Ming",""],["Lei","Xin",""],["Yang","Zhaojun",""]],"versions":[{"version":"v1","created":"Fri, 23 Aug 2024 20:03:51 GMT"}],"updateDate":"2024-08-27","timestamp":1724443431000,"abstract":"  A keyword spotting (KWS) engine that is continuously running on device is\nexposed to various speech signals that are usually unseen before. It is a\nchallenging problem to build a small-footprint and high-performing KWS model\nwith robustness under different acoustic environments. In this paper, we\nexplore how to effectively apply adversarial examples to improve KWS\nrobustness. We propose datasource-aware disentangled learning with adversarial\nexamples to reduce the mismatch between the original and adversarial data as\nwell as the mismatch across original training datasources. The KWS model\narchitecture is based on depth-wise separable convolution and a simple\nattention module. Experimental results demonstrate that the proposed learning\nstrategy improves false reject rate by $40.31%$ at $1%$ false accept rate on\nthe internal dataset, compared to the strongest baseline without using\nadversarial examples. Our best-performing system achieves $98.06%$ accuracy on\nthe Google Speech Commands V1 dataset.\n","subjects":["Computing Research Repository/Sound","Computing Research Repository/Artificial Intelligence","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/"}