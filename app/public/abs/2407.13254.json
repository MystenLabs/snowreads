{"id":"2407.13254","title":"Make a Strong Teacher with Label Assistance: A Novel Knowledge\n  Distillation Approach for Semantic Segmentation","authors":"Shoumeng Qiu, Jie Chen, Xinrun Li, Ru Wan, Xiangyang Xue, and Jian Pu","authorsParsed":[["Qiu","Shoumeng",""],["Chen","Jie",""],["Li","Xinrun",""],["Wan","Ru",""],["Xue","Xiangyang",""],["Pu","Jian",""]],"versions":[{"version":"v1","created":"Thu, 18 Jul 2024 08:08:04 GMT"}],"updateDate":"2024-07-19","timestamp":1721290084000,"abstract":"  In this paper, we introduce a novel knowledge distillation approach for the\nsemantic segmentation task. Unlike previous methods that rely on power-trained\nteachers or other modalities to provide additional knowledge, our approach does\nnot require complex teacher models or information from extra sensors.\nSpecifically, for the teacher model training, we propose to noise the label and\nthen incorporate it into input to effectively boost the lightweight teacher\nperformance. To ensure the robustness of the teacher model against the\nintroduced noise, we propose a dual-path consistency training strategy\nfeaturing a distance loss between the outputs of two paths. For the student\nmodel training, we keep it consistent with the standard distillation for\nsimplicity. Our approach not only boosts the efficacy of knowledge distillation\nbut also increases the flexibility in selecting teacher and student models. To\ndemonstrate the advantages of our Label Assisted Distillation (LAD) method, we\nconduct extensive experiments on five challenging datasets including\nCityscapes, ADE20K, PASCAL-VOC, COCO-Stuff 10K, and COCO-Stuff 164K, five\npopular models: FCN, PSPNet, DeepLabV3, STDC, and OCRNet, and results show the\neffectiveness and generalization of our approach. We posit that incorporating\nlabels into the input, as demonstrated in our work, will provide valuable\ninsights into related fields. Code is available at\nhttps://github.com/skyshoumeng/Label_Assisted_Distillation.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}