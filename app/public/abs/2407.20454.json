{"id":"2407.20454","title":"CoMMIT: Coordinated Instruction Tuning for Multimodal Large Language\n  Models","authors":"Junda Wu, Xintong Li, Tong Yu, Yu Wang, Xiang Chen, Jiuxiang Gu, Lina\n  Yao, Jingbo Shang, Julian McAuley","authorsParsed":[["Wu","Junda",""],["Li","Xintong",""],["Yu","Tong",""],["Wang","Yu",""],["Chen","Xiang",""],["Gu","Jiuxiang",""],["Yao","Lina",""],["Shang","Jingbo",""],["McAuley","Julian",""]],"versions":[{"version":"v1","created":"Mon, 29 Jul 2024 23:18:55 GMT"}],"updateDate":"2024-07-31","timestamp":1722295135000,"abstract":"  Instruction tuning in multimodal large language models (MLLMs) aims to\nsmoothly integrate a backbone LLM with a pre-trained feature encoder for\ndownstream tasks. The major challenge is how to efficiently find the synergy\nthrough cooperative learning where LLMs adapt their reasoning abilities in\ndownstream tasks while feature encoders adjust their encoding to provide more\nrelevant modal information. In this paper, we analyze the MLLM instruction\ntuning from both theoretical and empirical perspectives, where we find\nunbalanced learning between the two components, i.e., the feature encoder and\nthe LLM, can cause diminishing learning gradients that slow the model\nconvergence and often lead to sub-optimal results due to insufficient learning.\nInspired by our findings, we propose a measurement to quantitatively evaluate\nthe learning balance, based on which we further design a dynamic learning\nscheduler that better coordinates the learning. In addition, we introduce an\nauxiliary loss regularization method to promote updating of the generation\ndistribution of MLLMs considering the learning state of each model component,\nwhich potentially prevents each component from gradient diminishing and enables\na more accurate estimation of the learning balance coefficient. We conduct\nexperiments with multiple LLM backbones and feature encoders, where our\ntechniques are model-agnostic and can be generically integrated with various\nMLLM backbones. Experiment results on multiple downstream tasks and modalities\nin vision and audio, demonstrate the proposed method's better efficiency and\neffectiveness in MLLM instruction tuning.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}