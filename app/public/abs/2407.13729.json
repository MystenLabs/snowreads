{"id":"2407.13729","title":"Baba Is AI: Break the Rules to Beat the Benchmark","authors":"Nathan Cloos, Meagan Jens, Michelangelo Naim, Yen-Ling Kuo, Ignacio\n  Cases, Andrei Barbu, Christopher J. Cueva","authorsParsed":[["Cloos","Nathan",""],["Jens","Meagan",""],["Naim","Michelangelo",""],["Kuo","Yen-Ling",""],["Cases","Ignacio",""],["Barbu","Andrei",""],["Cueva","Christopher J.",""]],"versions":[{"version":"v1","created":"Thu, 18 Jul 2024 17:30:48 GMT"}],"updateDate":"2024-07-19","timestamp":1721323848000,"abstract":"  Humans solve problems by following existing rules and procedures, and also by\nleaps of creativity to redefine those rules and objectives. To probe these\nabilities, we developed a new benchmark based on the game Baba Is You where an\nagent manipulates both objects in the environment and rules, represented by\nmovable tiles with words written on them, to reach a specified goal and win the\ngame. We test three state-of-the-art multi-modal large language models (OpenAI\nGPT-4o, Google Gemini-1.5-Pro and Gemini-1.5-Flash) and find that they fail\ndramatically when generalization requires that the rules of the game must be\nmanipulated and combined.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/"}