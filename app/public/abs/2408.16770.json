{"id":"2408.16770","title":"3D Whole-body Grasp Synthesis with Directional Controllability","authors":"Georgios Paschalidis, Romana Wilschut, Dimitrije Anti\\'c, Omid Taheri,\n  Dimitrios Tzionas","authorsParsed":[["Paschalidis","Georgios",""],["Wilschut","Romana",""],["AntiÄ‡","Dimitrije",""],["Taheri","Omid",""],["Tzionas","Dimitrios",""]],"versions":[{"version":"v1","created":"Thu, 29 Aug 2024 17:59:54 GMT"}],"updateDate":"2024-08-30","timestamp":1724954394000,"abstract":"  Synthesizing 3D whole-bodies that realistically grasp objects is useful for\nanimation, mixed reality, and robotics. This is challenging, because the hands\nand body need to look natural w.r.t. each other, the grasped object, as well as\nthe local scene (i.e., a receptacle supporting the object). Only recent work\ntackles this, with a divide-and-conquer approach; it first generates a\n\"guiding\" right-hand grasp, and then searches for bodies that match this.\nHowever, the guiding-hand synthesis lacks controllability and receptacle\nawareness, so it likely has an implausible direction (i.e., a body can't match\nthis without penetrating the receptacle) and needs corrections through major\npost-processing. Moreover, the body search needs exhaustive sampling and is\nexpensive. These are strong limitations. We tackle these with a novel method\ncalled CWGrasp. Our key idea is that performing geometry-based reasoning \"early\non,\" instead of \"too late,\" provides rich \"control\" signals for inference. To\nthis end, CWGrasp first samples a plausible reaching-direction vector (used\nlater for both the arm and hand) from a probabilistic model built via\nraycasting from the object and collision checking. Then, it generates a\nreaching body with a desired arm direction, as well as a \"guiding\" grasping\nhand with a desired palm direction that complies with the arm's one.\nEventually, CWGrasp refines the body to match the \"guiding\" hand, while\nplausibly contacting the scene. Notably, generating already-compatible \"parts\"\ngreatly simplifies the \"whole.\" Moreover, CWGrasp uniquely tackles both right-\nand left-hand grasps. We evaluate on the GRAB and ReplicaGrasp datasets.\nCWGrasp outperforms baselines, at lower runtime and budget, while all\ncomponents help performance. Code and models will be released.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Robotics"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}