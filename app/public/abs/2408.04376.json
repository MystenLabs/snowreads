{"id":"2408.04376","title":"Deep Reinforcement Learning for the Design of Metamaterial Mechanisms\n  with Functional Compliance Control","authors":"Yejun Choi, Yeoneung Kim, Keun Park","authorsParsed":[["Choi","Yejun",""],["Kim","Yeoneung",""],["Park","Keun",""]],"versions":[{"version":"v1","created":"Thu, 8 Aug 2024 11:18:40 GMT"}],"updateDate":"2024-08-09","timestamp":1723115920000,"abstract":"  Metamaterial mechanisms are micro-architectured compliant structures that\noperate through the elastic deformation of specially designed flexible members.\nThis study develops an efficient design methodology for compliant mechanisms\nusing deep reinforcement learning (RL). For this purpose, design domains are\ndigitized into finite cells with various hinge connections, and finite element\nanalyses (FEAs) are conducted to evaluate the deformation behaviors of the\ncompliance mechanism with different cell combinations. The FEA data are learned\nthrough the RL method to obtain optimal compliant mechanisms for desired\nfunctional requirements. The RL algorithm is applied to the design of a\ncompliant door-latch mechanism, exploring the effect of human guidance and\ntiling direction. The optimal result is achieved with minimal human guidance\nand inward tiling, resulting in a threefold increase in the predefined reward\ncompared to human-designed mechanisms. The proposed approach is extended to the\ndesign of a soft gripper mechanism, where the effect of hinge connections is\nadditionally considered. The optimal design under hinge penalization reveals\nremarkably enhanced compliance, and its performance is validated by\nexperimental tests using an additively manufactured gripper. These findings\ndemonstrate that RL-optimized designs outperform those developed with human\ninsight, providing an efficient design methodology for cell-based compliant\nmechanisms in practical applications.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}