{"id":"2407.17261","title":"Embedding-Free Transformer with Inference Spatial Reduction for\n  Efficient Semantic Segmentation","authors":"Hyunwoo Yu, Yubin Cho, Beoungwoo Kang, Seunghun Moon, Kyeongbo Kong,\n  Suk-Ju Kang","authorsParsed":[["Yu","Hyunwoo",""],["Cho","Yubin",""],["Kang","Beoungwoo",""],["Moon","Seunghun",""],["Kong","Kyeongbo",""],["Kang","Suk-Ju",""]],"versions":[{"version":"v1","created":"Wed, 24 Jul 2024 13:24:25 GMT"}],"updateDate":"2024-07-25","timestamp":1721827465000,"abstract":"  We present an Encoder-Decoder Attention Transformer, EDAFormer, which\nconsists of the Embedding-Free Transformer (EFT) encoder and the all-attention\ndecoder leveraging our Embedding-Free Attention (EFA) structure. The proposed\nEFA is a novel global context modeling mechanism that focuses on functioning\nthe global non-linearity, not the specific roles of the query, key and value.\nFor the decoder, we explore the optimized structure for considering the\nglobality, which can improve the semantic segmentation performance. In\naddition, we propose a novel Inference Spatial Reduction (ISR) method for the\ncomputational efficiency. Different from the previous spatial reduction\nattention methods, our ISR method further reduces the key-value resolution at\nthe inference phase, which can mitigate the computation-performance trade-off\ngap for the efficient semantic segmentation. Our EDAFormer shows the\nstate-of-the-art performance with the efficient computation compared to the\nexisting transformer-based semantic segmentation models in three public\nbenchmarks, including ADE20K, Cityscapes and COCO-Stuff. Furthermore, our ISR\nmethod reduces the computational cost by up to 61% with minimal mIoU\nperformance degradation on Cityscapes dataset. The code is available at\nhttps://github.com/hyunwoo137/EDAFormer.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}