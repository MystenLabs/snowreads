{"id":"2407.14009","title":"Scale Disparity of Instances in Interactive Point Cloud Segmentation","authors":"Chenrui Han, Xuan Yu, Yuxuan Xie, Yili Liu, Sitong Mao, Shunbo Zhou,\n  Rong Xiong, Yue Wang","authorsParsed":[["Han","Chenrui",""],["Yu","Xuan",""],["Xie","Yuxuan",""],["Liu","Yili",""],["Mao","Sitong",""],["Zhou","Shunbo",""],["Xiong","Rong",""],["Wang","Yue",""]],"versions":[{"version":"v1","created":"Fri, 19 Jul 2024 03:45:48 GMT"}],"updateDate":"2024-07-22","timestamp":1721360748000,"abstract":"  Interactive point cloud segmentation has become a pivotal task for\nunderstanding 3D scenes, enabling users to guide segmentation models with\nsimple interactions such as clicks, therefore significantly reducing the effort\nrequired to tailor models to diverse scenarios and new categories. However, in\nthe realm of interactive segmentation, the meaning of instance diverges from\nthat in instance segmentation, because users might desire to segment instances\nof both thing and stuff categories that vary greatly in scale. Existing methods\nhave focused on thing categories, neglecting the segmentation of stuff\ncategories and the difficulties arising from scale disparity. To bridge this\ngap, we propose ClickFormer, an innovative interactive point cloud segmentation\nmodel that accurately segments instances of both thing and stuff categories. We\npropose a query augmentation module to augment click queries by a global query\nsampling strategy, thus maintaining consistent performance across different\ninstance scales. Additionally, we employ global attention in the query-voxel\ntransformer to mitigate the risk of generating false positives, along with\nseveral other network structure improvements to further enhance the model's\nsegmentation performance. Experiments demonstrate that ClickFormer outperforms\nexisting interactive point cloud segmentation methods across both indoor and\noutdoor datasets, providing more accurate segmentation results with fewer user\nclicks in an open-world setting.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}