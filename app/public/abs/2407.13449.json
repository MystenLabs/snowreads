{"id":"2407.13449","title":"All Roads Lead to Rome? Exploring Representational Similarities Between\n  Latent Spaces of Generative Image Models","authors":"Charumathi Badrinath, Usha Bhalla, Alex Oesterling, Suraj Srinivas,\n  Himabindu Lakkaraju","authorsParsed":[["Badrinath","Charumathi",""],["Bhalla","Usha",""],["Oesterling","Alex",""],["Srinivas","Suraj",""],["Lakkaraju","Himabindu",""]],"versions":[{"version":"v1","created":"Thu, 18 Jul 2024 12:23:57 GMT"}],"updateDate":"2024-07-19","timestamp":1721305437000,"abstract":"  Do different generative image models secretly learn similar underlying\nrepresentations? We investigate this by measuring the latent space similarity\nof four different models: VAEs, GANs, Normalizing Flows (NFs), and Diffusion\nModels (DMs). Our methodology involves training linear maps between frozen\nlatent spaces to \"stitch\" arbitrary pairs of encoders and decoders and\nmeasuring output-based and probe-based metrics on the resulting \"stitched''\nmodels. Our main findings are that linear maps between latent spaces of\nperformant models preserve most visual information even when latent sizes\ndiffer; for CelebA models, gender is the most similarly represented probe-able\nattribute. Finally we show on an NF that latent space representations converge\nearly in training.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"euFkcrajdnUFg0JLCNvCQ4NPiftVEIWay_3pPF8fYz4","pdfSize":"3859252"}
