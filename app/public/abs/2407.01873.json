{"id":"2407.01873","title":"Automated Text Scoring in the Age of Generative AI for the GPU-poor","authors":"Christopher Michael Ormerod, Alexander Kwako","authorsParsed":[["Ormerod","Christopher Michael",""],["Kwako","Alexander",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 01:17:01 GMT"}],"updateDate":"2024-07-03","timestamp":1719883021000,"abstract":"  Current research on generative language models (GLMs) for automated text\nscoring (ATS) has focused almost exclusively on querying proprietary models via\nApplication Programming Interfaces (APIs). Yet such practices raise issues\naround transparency and security, and these methods offer little in the way of\nefficiency or customizability. With the recent proliferation of smaller,\nopen-source models, there is the option to explore GLMs with computers equipped\nwith modest, consumer-grade hardware, that is, for the \"GPU poor.\" In this\nstudy, we analyze the performance and efficiency of open-source, small-scale\nGLMs for ATS. Results show that GLMs can be fine-tuned to achieve adequate,\nthough not state-of-the-art, performance. In addition to ATS, we take small\nsteps towards analyzing models' capacity for generating feedback by prompting\nGLMs to explain their scores. Model-generated feedback shows promise, but\nrequires more rigorous evaluation focused on targeted use cases.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"Uj1z4fHChoUqXFenet_CJWkYBSsSDihhyl7lj-HMjiM","pdfSize":"255149"}
