{"id":"2407.00635","title":"Dense Retrieval with Continuous Explicit Feedback for Systematic Review\n  Screening Prioritisation","authors":"Xinyu Mao, Shengyao Zhuang, Bevan Koopman, Guido Zuccon","authorsParsed":[["Mao","Xinyu",""],["Zhuang","Shengyao",""],["Koopman","Bevan",""],["Zuccon","Guido",""]],"versions":[{"version":"v1","created":"Sun, 30 Jun 2024 09:25:42 GMT"},{"version":"v2","created":"Wed, 17 Jul 2024 10:26:36 GMT"}],"updateDate":"2024-07-18","timestamp":1719739542000,"abstract":"  The goal of screening prioritisation in systematic reviews is to identify\nrelevant documents with high recall and rank them in early positions for\nreview. This saves reviewing effort if paired with a stopping criterion, and\nspeeds up review completion if performed alongside downstream tasks. Recent\nstudies have shown that neural models have good potential on this task, but\ntheir time-consuming fine-tuning and inference discourage their widespread use\nfor screening prioritisation. In this paper, we propose an alternative approach\nthat still relies on neural models, but leverages dense representations and\nrelevance feedback to enhance screening prioritisation, without the need for\ncostly model fine-tuning and inference. This method exploits continuous\nrelevance feedback from reviewers during document screening to efficiently\nupdate the dense query representation, which is then applied to rank the\nremaining documents to be screened. We evaluate this approach across the CLEF\nTAR datasets for this task. Results suggest that the investigated dense\nquery-driven approach is more efficient than directly using neural models and\nshows promising effectiveness compared to previous methods developed on the\nconsidered datasets. Our code is available at\nhttps://github.com/ielab/dense-screening-feedback.\n","subjects":["Computing Research Repository/Information Retrieval"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/"}