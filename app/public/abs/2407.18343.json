{"id":"2407.18343","title":"Introducing {\\delta}-XAI: a novel sensitivity-based method for local AI\n  explanations","authors":"Alessandro De Carlo, Enea Parimbelli, Nicola Melillo, Giovanna Nicora","authorsParsed":[["De Carlo","Alessandro",""],["Parimbelli","Enea",""],["Melillo","Nicola",""],["Nicora","Giovanna",""]],"versions":[{"version":"v1","created":"Thu, 25 Jul 2024 19:07:49 GMT"},{"version":"v2","created":"Mon, 29 Jul 2024 13:25:41 GMT"}],"updateDate":"2024-07-30","timestamp":1721934469000,"abstract":"  Explainable Artificial Intelligence (XAI) is central to the debate on\nintegrating Artificial Intelligence (AI) and Machine Learning (ML) algorithms\ninto clinical practice. High-performing AI/ML models, such as ensemble learners\nand deep neural networks, often lack interpretability, hampering clinicians'\ntrust in their predictions. To address this, XAI techniques are being developed\nto describe AI/ML predictions in human-understandable terms. One promising\ndirection is the adaptation of sensitivity analysis (SA) and global sensitivity\nanalysis (GSA), which inherently rank model inputs by their impact on\npredictions. Here, we introduce a novel delta-XAI method that provides local\nexplanations of ML model predictions by extending the delta index, a GSA\nmetric. The delta-XAI index assesses the impact of each feature's value on the\npredicted output for individual instances in both regression and classification\nproblems. We formalize the delta-XAI index and provide code for its\nimplementation. The delta-XAI method was evaluated on simulated scenarios using\nlinear regression models, with Shapley values serving as a benchmark. Results\nshowed that the delta-XAI index is generally consistent with Shapley values,\nwith notable discrepancies in models with highly impactful or extreme feature\nvalues. The delta-XAI index demonstrated higher sensitivity in detecting\ndominant features and handling extreme feature values. Qualitatively, the\ndelta-XAI provides intuitive explanations by leveraging probability density\nfunctions, making feature rankings clearer and more explainable for\npractitioners. Overall, the delta-XAI method appears promising for robustly\nobtaining local explanations of ML model predictions. Further investigations in\nreal-world clinical settings will be conducted to evaluate its impact on\nAI-assisted clinical workflows.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"nqLwIsutIbypxhxpCdp4mjA33cbDlW1FOXV99EQkkA4","pdfSize":"1381821"}
