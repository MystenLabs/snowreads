{"id":"2407.00942","title":"ProductAgent: Benchmarking Conversational Product Search Agent with\n  Asking Clarification Questions","authors":"Jingheng Ye, Yong Jiang, Xiaobin Wang, Yinghui Li, Yangning Li,\n  Hai-Tao Zheng, Pengjun Xie, Fei Huang","authorsParsed":[["Ye","Jingheng",""],["Jiang","Yong",""],["Wang","Xiaobin",""],["Li","Yinghui",""],["Li","Yangning",""],["Zheng","Hai-Tao",""],["Xie","Pengjun",""],["Huang","Fei",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 03:50:23 GMT"}],"updateDate":"2024-07-02","timestamp":1719805823000,"abstract":"  This paper introduces the task of product demand clarification within an\ne-commercial scenario, where the user commences the conversation with ambiguous\nqueries and the task-oriented agent is designed to achieve more accurate and\ntailored product searching by asking clarification questions. To address this\ntask, we propose ProductAgent, a conversational information seeking agent\nequipped with abilities of strategic clarification question generation and\ndynamic product retrieval. Specifically, we develop the agent with strategies\nfor product feature summarization, query generation, and product retrieval.\nFurthermore, we propose the benchmark called PROCLARE to evaluate the agent's\nperformance both automatically and qualitatively with the aid of a LLM-driven\nuser simulator. Experiments show that ProductAgent interacts positively with\nthe user and enhances retrieval performance with increasing dialogue turns,\nwhere user demands become gradually more explicit and detailed. All the source\ncodes will be released after the review anonymity period.\n","subjects":["Computing Research Repository/Information Retrieval","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}