{"id":"2407.05470","title":"Bayesian Finite Mixture Models","authors":"Bettina Gr\\\"un and Gertraud Malsiner-Walli","authorsParsed":[["Gr√ºn","Bettina",""],["Malsiner-Walli","Gertraud",""]],"versions":[{"version":"v1","created":"Sun, 7 Jul 2024 19:03:53 GMT"}],"updateDate":"2024-07-09","timestamp":1720379033000,"abstract":"  Finite mixture models are a useful statistical model class for clustering and\ndensity approximation. In the Bayesian framework finite mixture models require\nthe specification of suitable priors in addition to the data model. These\npriors allow to avoid spurious results and provide a principled way to define\ncluster shapes and a preference for specific cluster solutions. A generic model\nestimation scheme for finite mixtures with a fixed number of components is\navailable using Markov chain Monte Carlo (MCMC) sampling with data\naugmentation. The posterior allows to assess uncertainty in a comprehensive\nway, but component-specific posterior inference requires resolving the label\nswitching issue.\n  In this paper we focus on the application of Bayesian finite mixture models\nfor clustering. We start with discussing suitable specification, estimation and\ninference of the model if the number of components is assumed to be known. We\nthen continue to explain suitable strategies for fitting Bayesian finite\nmixture models when the number of components is not known. In addition, all\nsteps required to perform Bayesian finite mixture modeling are illustrated on a\ndata example where a finite mixture model of multivariate Gaussian\ndistributions is fitted. Suitable prior specification, estimation using MCMC\nand posterior inference are discussed for this example assuming the number of\ncomponents to be known as well as unknown.\n","subjects":["Statistics/Methodology"],"license":"http://creativecommons.org/licenses/by/4.0/"}