{"id":"2408.12959","title":"Multimodal Contrastive In-Context Learning","authors":"Yosuke Miyanishi, Minh Le Nguyen","authorsParsed":[["Miyanishi","Yosuke",""],["Nguyen","Minh Le",""]],"versions":[{"version":"v1","created":"Fri, 23 Aug 2024 10:10:01 GMT"}],"updateDate":"2024-08-26","timestamp":1724407801000,"abstract":"  The rapid growth of Large Language Models (LLMs) usage has highlighted the\nimportance of gradient-free in-context learning (ICL). However, interpreting\ntheir inner workings remains challenging. This paper introduces a novel\nmultimodal contrastive in-context learning framework to enhance our\nunderstanding of ICL in LLMs. First, we present a contrastive learning-based\ninterpretation of ICL in real-world settings, marking the distance of the\nkey-value representation as the differentiator in ICL. Second, we develop an\nanalytical framework to address biases in multimodal input formatting for\nreal-world datasets. We demonstrate the effectiveness of ICL examples where\nbaseline performance is poor, even when they are represented in unseen formats.\nLastly, we propose an on-the-fly approach for ICL (Anchored-by-Text ICL) that\ndemonstrates effectiveness in detecting hateful memes, a task where typical ICL\nstruggles due to resource limitations. Extensive experiments on multimodal\ndatasets reveal that our approach significantly improves ICL performance across\nvarious scenarios, such as challenging tasks and resource-constrained\nenvironments. Moreover, it provides valuable insights into the mechanisms of\nin-context learning in LLMs. Our findings have important implications for\ndeveloping more interpretable, efficient, and robust multimodal AI systems,\nespecially in challenging tasks and resource-constrained environments.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/"}