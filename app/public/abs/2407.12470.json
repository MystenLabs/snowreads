{"id":"2407.12470","title":"Continual Learning for Temporal-Sensitive Question Answering","authors":"Wanqi Yang, Yunqiu Xu, Yanda Li, Kunze Wang, Binbin Huang, Ling Chen","authorsParsed":[["Yang","Wanqi",""],["Xu","Yunqiu",""],["Li","Yanda",""],["Wang","Kunze",""],["Huang","Binbin",""],["Chen","Ling",""]],"versions":[{"version":"v1","created":"Wed, 17 Jul 2024 10:47:43 GMT"}],"updateDate":"2024-07-18","timestamp":1721213263000,"abstract":"  In this study, we explore an emerging research area of Continual Learning for\nTemporal Sensitive Question Answering (CLTSQA). Previous research has primarily\nfocused on Temporal Sensitive Question Answering (TSQA), often overlooking the\nunpredictable nature of future events. In real-world applications, it's crucial\nfor models to continually acquire knowledge over time, rather than relying on a\nstatic, complete dataset. Our paper investigates strategies that enable models\nto adapt to the ever-evolving information landscape, thereby addressing the\nchallenges inherent in CLTSQA. To support our research, we first create a novel\ndataset, divided into five subsets, designed specifically for various stages of\ncontinual learning. We then propose a training framework for CLTSQA that\nintegrates temporal memory replay and temporal contrastive learning. Our\nexperimental results highlight two significant insights: First, the CLTSQA task\nintroduces unique challenges for existing models. Second, our proposed\nframework effectively navigates these challenges, resulting in improved\nperformance.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/"}