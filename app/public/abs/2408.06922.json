{"id":"2408.06922","title":"Temporal Variability and Multi-Viewed Self-Supervised Representations to\n  Tackle the ASVspoof5 Deepfake Challenge","authors":"Yuankun Xie, Xiaopeng Wang, Zhiyong Wang, Ruibo Fu, Zhengqi Wen,\n  Haonan Cheng, Long Ye","authorsParsed":[["Xie","Yuankun",""],["Wang","Xiaopeng",""],["Wang","Zhiyong",""],["Fu","Ruibo",""],["Wen","Zhengqi",""],["Cheng","Haonan",""],["Ye","Long",""]],"versions":[{"version":"v1","created":"Tue, 13 Aug 2024 14:15:15 GMT"}],"updateDate":"2024-08-14","timestamp":1723558515000,"abstract":"  ASVspoof5, the fifth edition of the ASVspoof series, is one of the largest\nglobal audio security challenges. It aims to advance the development of\ncountermeasure (CM) to discriminate bonafide and spoofed speech utterances. In\nthis paper, we focus on addressing the problem of open-domain audio deepfake\ndetection, which corresponds directly to the ASVspoof5 Track1 open condition.\nAt first, we comprehensively investigate various CM on ASVspoof5, including\ndata expansion, data augmentation, and self-supervised learning (SSL) features.\nDue to the high-frequency gaps characteristic of the ASVspoof5 dataset, we\nintroduce Frequency Mask, a data augmentation method that masks specific\nfrequency bands to improve CM robustness. Combining various scale of temporal\ninformation with multiple SSL features, our experiments achieved a minDCF of\n0.0158 and an EER of 0.55% on the ASVspoof 5 Track 1 evaluation progress set.\n","subjects":["Computing Research Repository/Sound","Computing Research Repository/Artificial Intelligence","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"0zTnRGAhl0xiQKMG8LU4fT_6yBguXpiUUlE6bzydRXE","pdfSize":"1644492"}
