{"id":"2408.15037","title":"Evidence-Enhanced Triplet Generation Framework for Hallucination\n  Alleviation in Generative Question Answering","authors":"Haowei Du, Huishuai Zhang, Dongyan Zhao","authorsParsed":[["Du","Haowei",""],["Zhang","Huishuai",""],["Zhao","Dongyan",""]],"versions":[{"version":"v1","created":"Tue, 27 Aug 2024 13:07:07 GMT"}],"updateDate":"2024-08-28","timestamp":1724764027000,"abstract":"  To address the hallucination in generative question answering (GQA) where the\nanswer can not be derived from the document, we propose a novel\nevidence-enhanced triplet generation framework, EATQA, encouraging the model to\npredict all the combinations of (Question, Evidence, Answer) triplet by\nflipping the source pair and the target label to understand their logical\nrelationships, i.e., predict Answer(A), Question(Q), and Evidence(E) given a\nQE, EA, and QA pairs, respectively. Furthermore, we bridge the distribution gap\nto distill the knowledge from evidence in inference stage. Our framework\nensures the model to learn the logical relation between query, evidence and\nanswer, which simultaneously improves the evidence generation and query\nanswering. In this paper, we apply EATQA to LLama and it outperforms other\nLLMs-based methods and hallucination mitigation approaches on two challenging\nGQA benchmarks. Further analysis shows that our method not only keeps prior\nknowledge within LLM, but also mitigates hallucination and generates faithful\nanswers.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/"}