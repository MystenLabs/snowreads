{"id":"2408.02078","title":"LDFaceNet: Latent Diffusion-based Network for High-Fidelity Deepfake\n  Generation","authors":"Dwij Mehta, Aditya Mehta, Pratik Narang","authorsParsed":[["Mehta","Dwij",""],["Mehta","Aditya",""],["Narang","Pratik",""]],"versions":[{"version":"v1","created":"Sun, 4 Aug 2024 16:09:04 GMT"}],"updateDate":"2024-08-06","timestamp":1722787744000,"abstract":"  Over the past decade, there has been tremendous progress in the domain of\nsynthetic media generation. This is mainly due to the powerful methods based on\ngenerative adversarial networks (GANs). Very recently, diffusion probabilistic\nmodels, which are inspired by non-equilibrium thermodynamics, have taken the\nspotlight. In the realm of image generation, diffusion models (DMs) have\nexhibited remarkable proficiency in producing both realistic and heterogeneous\nimagery through their stochastic sampling procedure. This paper proposes a\nnovel facial swapping module, termed as LDFaceNet (Latent Diffusion based Face\nSwapping Network), which is based on a guided latent diffusion model that\nutilizes facial segmentation and facial recognition modules for a conditioned\ndenoising process. The model employs a unique loss function to offer\ndirectional guidance to the diffusion process. Notably, LDFaceNet can\nincorporate supplementary facial guidance for desired outcomes without any\nretraining. To the best of our knowledge, this represents the first application\nof the latent diffusion model in the face-swapping task without prior training.\nThe results of this study demonstrate that the proposed method can generate\nextremely realistic and coherent images by leveraging the potential of the\ndiffusion model for facial swapping, thereby yielding superior visual outcomes\nand greater diversity.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}