{"id":"2407.18247","title":"RegionDrag: Fast Region-Based Image Editing with Diffusion Models","authors":"Jingyi Lu, Xinghui Li and Kai Han","authorsParsed":[["Lu","Jingyi",""],["Li","Xinghui",""],["Han","Kai",""]],"versions":[{"version":"v1","created":"Thu, 25 Jul 2024 17:59:13 GMT"}],"updateDate":"2024-07-26","timestamp":1721930353000,"abstract":"  Point-drag-based image editing methods, like DragDiffusion, have attracted\nsignificant attention. However, point-drag-based approaches suffer from\ncomputational overhead and misinterpretation of user intentions due to the\nsparsity of point-based editing instructions. In this paper, we propose a\nregion-based copy-and-paste dragging method, RegionDrag, to overcome these\nlimitations. RegionDrag allows users to express their editing instructions in\nthe form of handle and target regions, enabling more precise control and\nalleviating ambiguity. In addition, region-based operations complete editing in\none iteration and are much faster than point-drag-based methods. We also\nincorporate the attention-swapping technique for enhanced stability during\nediting. To validate our approach, we extend existing point-drag-based datasets\nwith region-based dragging instructions. Experimental results demonstrate that\nRegionDrag outperforms existing point-drag-based approaches in terms of speed,\naccuracy, and alignment with user intentions. Remarkably, RegionDrag completes\nthe edit on an image with a resolution of 512x512 in less than 2 seconds, which\nis more than 100x faster than DragDiffusion, while achieving better\nperformance. Project page: https://visual-ai.github.io/regiondrag.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}