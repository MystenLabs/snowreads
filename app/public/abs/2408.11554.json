{"id":"2408.11554","title":"Differentiating Choices via Commonality for Multiple-Choice Question\n  Answering","authors":"Wenqing Deng, Zhe Wang, Kewen Wang, Shirui Pan, Xiaowang Zhang,\n  Zhiyong Feng","authorsParsed":[["Deng","Wenqing",""],["Wang","Zhe",""],["Wang","Kewen",""],["Pan","Shirui",""],["Zhang","Xiaowang",""],["Feng","Zhiyong",""]],"versions":[{"version":"v1","created":"Wed, 21 Aug 2024 12:05:21 GMT"}],"updateDate":"2024-08-22","timestamp":1724241921000,"abstract":"  Multiple-choice question answering (MCQA) becomes particularly challenging\nwhen all choices are relevant to the question and are semantically similar. Yet\nthis setting of MCQA can potentially provide valuable clues for choosing the\nright answer. Existing models often rank each choice separately, overlooking\nthe context provided by other choices. Specifically, they fail to leverage the\nsemantic commonalities and nuances among the choices for reasoning. In this\npaper, we propose a novel MCQA model by differentiating choices through\nidentifying and eliminating their commonality, called DCQA. Our model captures\ntoken-level attention of each choice to the question, and separates tokens of\nthe question attended to by all the choices (i.e., commonalities) from those by\nindividual choices (i.e., nuances). Using the nuances as refined contexts for\nthe choices, our model can effectively differentiate choices with subtle\ndifferences and provide justifications for choosing the correct answer. We\nconduct comprehensive experiments across five commonly used MCQA benchmarks,\ndemonstrating that DCQA consistently outperforms baseline models. Furthermore,\nour case study illustrates the effectiveness of the approach in directing the\nattention of the model to more differentiating features.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}