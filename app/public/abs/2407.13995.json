{"id":"2407.13995","title":"Track-MDP: Reinforcement Learning for Target Tracking with Controlled\n  Sensing","authors":"Adarsh M. Subramaniam, Argyrios Gerogiannis, James Z. Hare, Venugopal\n  V. Veeravalli","authorsParsed":[["Subramaniam","Adarsh M.",""],["Gerogiannis","Argyrios",""],["Hare","James Z.",""],["Veeravalli","Venugopal V.",""]],"versions":[{"version":"v1","created":"Fri, 19 Jul 2024 02:58:51 GMT"}],"updateDate":"2024-07-22","timestamp":1721357931000,"abstract":"  State of the art methods for target tracking with sensor management (or\ncontrolled sensing) are model-based and are obtained through solutions to\nPartially Observable Markov Decision Process (POMDP) formulations. In this\npaper a Reinforcement Learning (RL) approach to the problem is explored for the\nsetting where the motion model for the object/target to be tracked is unknown\nto the observer. It is assumed that the target dynamics are stationary in time,\nthe state space and the observation space are discrete, and there is complete\nobservability of the location of the target under certain (a priori unknown)\nsensor control actions. Then, a novel Markov Decision Process (MDP) rather than\nPOMDP formulation is proposed for the tracking problem with controlled sensing,\nwhich is termed as Track-MDP. In contrast to the POMDP formulation, the\nTrack-MDP formulation is amenable to an RL based solution. It is shown that the\noptimal policy for the Track-MDP formulation, which is approximated through RL,\nis guaranteed to track all significant target paths with certainty. The\nTrack-MDP method is then compared with the optimal POMDP policy, and it is\nshown that the infinite horizon tracking reward of the optimal Track-MDP policy\nis the same as that of the optimal POMDP policy. In simulations it is\ndemonstrated that Track-MDP based RL leads to a policy that can track the\ntarget with high accuracy.\n","subjects":["Electrical Engineering and Systems Science/Signal Processing","Statistics/Machine Learning"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/"}