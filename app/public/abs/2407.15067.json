{"id":"2407.15067","title":"VoxDepth: Rectification of Depth Images on Edge Devices","authors":"Yashashwee Chakrabarty, Smruti Ranjan Sarangi","authorsParsed":[["Chakrabarty","Yashashwee",""],["Sarangi","Smruti Ranjan",""]],"versions":[{"version":"v1","created":"Sun, 21 Jul 2024 05:51:05 GMT"}],"updateDate":"2024-07-23","timestamp":1721541065000,"abstract":"  Autonomous mobile robots like self-flying drones and industrial robots\nheavily depend on depth images to perform tasks such as 3D reconstruction and\nvisual SLAM. However, the presence of inaccuracies in these depth images can\ngreatly hinder the effectiveness of these applications, resulting in\nsub-optimal results. Depth images produced by commercially available cameras\nfrequently exhibit noise, which manifests as flickering pixels and erroneous\npatches. ML-based methods to rectify these images are unsuitable for edge\ndevices that have very limited computational resources. Non-ML methods are much\nfaster but have limited accuracy, especially for correcting errors that are a\nresult of occlusion and camera movement. We propose a scheme called VoxDepth\nthat is fast, accurate, and runs very well on edge devices. It relies on a host\nof novel techniques: 3D point cloud construction and fusion, and using it to\ncreate a template that can fix erroneous depth images. VoxDepth shows superior\nresults on both synthetic and real-world datasets. We demonstrate a 31%\nimprovement in quality as compared to state-of-the-art methods on real-world\ndepth datasets, while maintaining a competitive framerate of 27 FPS (frames per\nsecond).\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}