{"id":"2408.12047","title":"Do Responsible AI Artifacts Advance Stakeholder Goals? Four Key Barriers\n  Perceived by Legal and Civil Stakeholders","authors":"Anna Kawakami, Daricia Wilkinson, Alexandra Chouldechova","authorsParsed":[["Kawakami","Anna",""],["Wilkinson","Daricia",""],["Chouldechova","Alexandra",""]],"versions":[{"version":"v1","created":"Thu, 22 Aug 2024 00:14:37 GMT"}],"updateDate":"2024-08-23","timestamp":1724285677000,"abstract":"  The responsible AI (RAI) community has introduced numerous processes and\nartifacts (e.g., Model Cards, Transparency Notes, Data Cards) to facilitate\ntransparency and support the governance of AI systems. While originally\ndesigned to scaffold and document AI development processes in technology\ncompanies, these artifacts are becoming central components of regulatory\ncompliance under recent regulations such as the EU AI Act. Much prior work has\nexplored the design of new RAI artifacts or their use by practitioners within\ntechnology companies. However, as RAI artifacts begin to play key roles in\nenabling external oversight, it becomes critical to understand how\nstakeholders--particularly those situated outside of technology companies who\ngovern and audit industry AI deployments--perceive the efficacy of RAI\nartifacts. In this study, we conduct semi-structured interviews and design\nactivities with 19 government, legal, and civil society stakeholders who inform\npolicy and advocacy around responsible AI efforts. While participants believe\nthat RAI artifacts are a valuable contribution to the broader AI governance\necosystem, many are concerned about their potential unintended, longer-term\nimpacts on actors outside of technology companies (e.g., downstream end-users,\npolicymakers, civil society stakeholders). We organize these beliefs into four\nbarriers that help explain how RAI artifacts may (inadvertently) reconfigure\npower relations across civil society, government, and industry, impeding civil\nsociety and legal stakeholders' ability to protect downstream end-users from\npotential AI harms. Participants envision how structural changes, along with\nchanges in how RAI artifacts are designed, used, and governed, could help\nredirect the role of artifacts to support more collaborative and proactive\nexternal oversight of AI systems. We discuss research and policy implications\nfor RAI artifacts.\n","subjects":["Computing Research Repository/Computers and Society","Computing Research Repository/Human-Computer Interaction"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/"}