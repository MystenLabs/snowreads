{"id":"2407.12667","title":"SG-NeRF: Neural Surface Reconstruction with Scene Graph Optimization","authors":"Yiyang Chen, Siyan Dong, Xulong Wang, Lulu Cai, Youyi Zheng, Yanchao\n  Yang","authorsParsed":[["Chen","Yiyang",""],["Dong","Siyan",""],["Wang","Xulong",""],["Cai","Lulu",""],["Zheng","Youyi",""],["Yang","Yanchao",""]],"versions":[{"version":"v1","created":"Wed, 17 Jul 2024 15:50:17 GMT"}],"updateDate":"2024-07-18","timestamp":1721231417000,"abstract":"  3D surface reconstruction from images is essential for numerous applications.\nRecently, Neural Radiance Fields (NeRFs) have emerged as a promising framework\nfor 3D modeling. However, NeRFs require accurate camera poses as input, and\nexisting methods struggle to handle significantly noisy pose estimates (i.e.,\noutliers), which are commonly encountered in real-world scenarios. To tackle\nthis challenge, we present a novel approach that optimizes radiance fields with\nscene graphs to mitigate the influence of outlier poses. Our method\nincorporates an adaptive inlier-outlier confidence estimation scheme based on\nscene graphs, emphasizing images of high compatibility with the neighborhood\nand consistency in the rendering quality. We also introduce an effective\nintersection-over-union (IoU) loss to optimize the camera pose and surface\ngeometry, together with a coarse-to-fine strategy to facilitate the training.\nFurthermore, we propose a new dataset containing typical outlier poses for a\ndetailed evaluation. Experimental results on various datasets consistently\ndemonstrate the effectiveness and superiority of our method over existing\napproaches, showcasing its robustness in handling outliers and producing\nhigh-quality 3D reconstructions. Our code and data are available at:\n\\url{https://github.com/Iris-cyy/SG-NeRF}.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}