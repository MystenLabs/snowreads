{"id":"2408.12793","title":"La-SoftMoE CLIP for Unified Physical-Digital Face Attack Detection","authors":"Hang Zou, Chenxi Du, Hui Zhang, Yuan Zhang, Ajian Liu, Jun Wan, Zhen\n  Lei","authorsParsed":[["Zou","Hang",""],["Du","Chenxi",""],["Zhang","Hui",""],["Zhang","Yuan",""],["Liu","Ajian",""],["Wan","Jun",""],["Lei","Zhen",""]],"versions":[{"version":"v1","created":"Fri, 23 Aug 2024 02:12:13 GMT"}],"updateDate":"2024-08-26","timestamp":1724379133000,"abstract":"  Facial recognition systems are susceptible to both physical and digital\nattacks, posing significant security risks. Traditional approaches often treat\nthese two attack types separately due to their distinct characteristics. Thus,\nwhen being combined attacked, almost all methods could not deal. Some studies\nattempt to combine the sparse data from both types of attacks into a single\ndataset and try to find a common feature space, which is often impractical due\nto the space is difficult to be found or even non-existent. To overcome these\nchallenges, we propose a novel approach that uses the sparse model to handle\nsparse data, utilizing different parameter groups to process distinct regions\nof the sparse feature space. Specifically, we employ the Mixture of Experts\n(MoE) framework in our model, expert parameters are matched to tokens with\nvarying weights during training and adaptively activated during testing.\nHowever, the traditional MoE struggles with the complex and irregular\nclassification boundaries of this problem. Thus, we introduce a flexible\nself-adapting weighting mechanism, enabling the model to better fit and adapt.\nIn this paper, we proposed La-SoftMoE CLIP, which allows for more flexible\nadaptation to the Unified Attack Detection (UAD) task, significantly enhancing\nthe model's capability to handle diversity attacks. Experiment results\ndemonstrate that our proposed method has SOTA performance.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}