{"id":"2407.16139","title":"Tackling Feature-Classifier Mismatch in Federated Learning via\n  Prompt-Driven Feature Transformation","authors":"Xinghao Wu, Jianwei Niu, Xuefeng Liu, Mingjia Shi, Guogang Zhu, and\n  Shaojie Tang","authorsParsed":[["Wu","Xinghao",""],["Niu","Jianwei",""],["Liu","Xuefeng",""],["Shi","Mingjia",""],["Zhu","Guogang",""],["Tang","Shaojie",""]],"versions":[{"version":"v1","created":"Tue, 23 Jul 2024 02:52:52 GMT"}],"updateDate":"2024-07-24","timestamp":1721703172000,"abstract":"  In traditional Federated Learning approaches like FedAvg, the global model\nunderperforms when faced with data heterogeneity. Personalized Federated\nLearning (PFL) enables clients to train personalized models to fit their local\ndata distribution better. However, we surprisingly find that the feature\nextractor in FedAvg is superior to those in most PFL methods. More\ninterestingly, by applying a linear transformation on local features extracted\nby the feature extractor to align with the classifier, FedAvg can surpass the\nmajority of PFL methods. This suggests that the primary cause of FedAvg's\ninadequate performance stems from the mismatch between the locally extracted\nfeatures and the classifier. While current PFL methods mitigate this issue to\nsome extent, their designs compromise the quality of the feature extractor,\nthus limiting the full potential of PFL. In this paper, we propose a new PFL\nframework called FedPFT to address the mismatch problem while enhancing the\nquality of the feature extractor. FedPFT integrates a feature transformation\nmodule, driven by personalized prompts, between the global feature extractor\nand classifier. In each round, clients first train prompts to transform local\nfeatures to match the global classifier, followed by training model parameters.\nThis approach can also align the training objectives of clients, reducing the\nimpact of data heterogeneity on model collaboration. Moreover, FedPFT's feature\ntransformation module is highly scalable, allowing for the use of different\nprompts to tailor local features to various tasks. Leveraging this, we\nintroduce a collaborative contrastive learning task to further refine feature\nextractor quality. Our experiments demonstrate that FedPFT outperforms\nstate-of-the-art methods by up to 7.08%.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}