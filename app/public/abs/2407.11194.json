{"id":"2407.11194","title":"AstroMLab 1: Who Wins Astronomy Jeopardy!?","authors":"Yuan-Sen Ting, Tuan Dung Nguyen, Tirthankar Ghosal, Rui Pan, Hardik\n  Arora, Zechang Sun, Tijmen de Haan, Nesar Ramachandra, Azton Wells, Sandeep\n  Madireddy, Alberto Accomazzi","authorsParsed":[["Ting","Yuan-Sen",""],["Nguyen","Tuan Dung",""],["Ghosal","Tirthankar",""],["Pan","Rui",""],["Arora","Hardik",""],["Sun","Zechang",""],["de Haan","Tijmen",""],["Ramachandra","Nesar",""],["Wells","Azton",""],["Madireddy","Sandeep",""],["Accomazzi","Alberto",""]],"versions":[{"version":"v1","created":"Mon, 15 Jul 2024 19:28:14 GMT"}],"updateDate":"2024-07-17","timestamp":1721071694000,"abstract":"  We present a comprehensive evaluation of proprietary and open-weights large\nlanguage models using the first astronomy-specific benchmarking dataset. This\ndataset comprises 4,425 multiple-choice questions curated from the Annual\nReview of Astronomy and Astrophysics, covering a broad range of astrophysical\ntopics. Our analysis examines model performance across various astronomical\nsubfields and assesses response calibration, crucial for potential deployment\nin research environments. Claude-3.5-Sonnet outperforms competitors by up to\n4.6 percentage points, achieving 85.0% accuracy. For proprietary models, we\nobserved a universal reduction in cost every 3-to-12 months to achieve similar\nscore in this particular astronomy benchmark. Open-source models have rapidly\nimproved, with LLaMA-3-70b (80.6%) and Qwen-2-72b (77.7%) now competing with\nsome of the best proprietary models. We identify performance variations across\ntopics, with non-English-focused models generally struggling more in\nexoplanet-related fields, stellar astrophysics, and instrumentation related\nquestions. These challenges likely stem from less abundant training data,\nlimited historical context, and rapid recent developments in these areas. This\npattern is observed across both open-weights and proprietary models, with\nregional dependencies evident, highlighting the impact of training data\ndiversity on model performance in specialized scientific domains.\nTop-performing models demonstrate well-calibrated confidence, with correlations\nabove 0.9 between confidence and correctness, though they tend to be slightly\nunderconfident. The development for fast, low-cost inference of open-weights\nmodels presents new opportunities for affordable deployment in astronomy. The\nrapid progress observed suggests that LLM-driven research in astronomy may\nbecome feasible in the near future.\n","subjects":["Astrophysics/Instrumentation and Methods for Astrophysics","Astrophysics/Earth and Planetary Astrophysics","Astrophysics/Astrophysics of Galaxies","Astrophysics/Solar and Stellar Astrophysics","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"kRPshU4doCelBN9UPOZX8jPJTvmGQPeqCfb-pURgEaw","pdfSize":"10801564"}
