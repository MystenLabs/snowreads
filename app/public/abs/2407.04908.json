{"id":"2407.04908","title":"SID: Stereo Image Dataset for Autonomous Driving in Adverse Conditions","authors":"Zaid A. El-Shair, Abdalmalek Abu-raddaha, Aaron Cofield, Hisham\n  Alawneh, Mohamed Aladem, Yazan Hamzeh, Samir A. Rawashdeh","authorsParsed":[["El-Shair","Zaid A.",""],["Abu-raddaha","Abdalmalek",""],["Cofield","Aaron",""],["Alawneh","Hisham",""],["Aladem","Mohamed",""],["Hamzeh","Yazan",""],["Rawashdeh","Samir A.",""]],"versions":[{"version":"v1","created":"Sat, 6 Jul 2024 00:58:31 GMT"}],"updateDate":"2024-07-09","timestamp":1720227511000,"abstract":"  Robust perception is critical for autonomous driving, especially under\nadverse weather and lighting conditions that commonly occur in real-world\nenvironments. In this paper, we introduce the Stereo Image Dataset (SID), a\nlarge-scale stereo-image dataset that captures a wide spectrum of challenging\nreal-world environmental scenarios. Recorded at a rate of 20 Hz using a ZED\nstereo camera mounted on a vehicle, SID consists of 27 sequences totaling over\n178k stereo image pairs that showcase conditions from clear skies to heavy\nsnow, captured during the day, dusk, and night. The dataset includes detailed\nsequence-level annotations for weather conditions, time of day, location, and\nroad conditions, along with instances of camera lens soiling, offering a\nrealistic representation of the challenges in autonomous navigation. Our work\naims to address a notable gap in research for autonomous driving systems by\npresenting high-fidelity stereo images essential for the development and\ntesting of advanced perception algorithms. These algorithms support consistent\nand reliable operation across variable weather and lighting conditions, even\nwhen handling challenging situations like lens soiling. SID is publicly\navailable at: https://doi.org/10.7302/esz6-nv83.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}