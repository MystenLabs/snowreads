{"id":"2407.03824","title":"Emergent Interpretable Symbols and Content-Style Disentanglement via\n  Variance-Invariance Constraints","authors":"Yuxuan Wu, Ziyu Wang, Bhiksha Raj, Gus Xia","authorsParsed":[["Wu","Yuxuan",""],["Wang","Ziyu",""],["Raj","Bhiksha",""],["Xia","Gus",""]],"versions":[{"version":"v1","created":"Thu, 4 Jul 2024 10:52:02 GMT"}],"updateDate":"2024-07-08","timestamp":1720090322000,"abstract":"  We contribute an unsupervised method that effectively learns from raw\nobservation and disentangles its latent space into content and style\nrepresentations. Unlike most disentanglement algorithms that rely on\ndomain-specific labels and knowledge, our method is based on the insight of\ndomain-general statistical differences between content and style -- content\nvaries more among different fragments within a sample but maintains an\ninvariant vocabulary across data samples, whereas style remains relatively\ninvariant within a sample but exhibits more significant variation across\ndifferent samples. We integrate such inductive bias into an encoder-decoder\narchitecture and name our method after V3 (variance-versus-invariance).\nExperimental results show that V3 generalizes across two distinct domains in\ndifferent modalities, music audio and images of written digits, successfully\nlearning pitch-timbre and digit-color disentanglements, respectively. Also, the\ndisentanglement robustness significantly outperforms baseline unsupervised\nmethods and is even comparable to supervised counterparts. Furthermore,\nsymbolic-level interpretability emerges in the learned codebook of content,\nforging a near one-to-one alignment between machine representation and human\nknowledge.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}