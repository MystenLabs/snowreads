{"id":"2408.10053","title":"Privacy Checklist: Privacy Violation Detection Grounding on Contextual\n  Integrity Theory","authors":"Haoran Li, Wei Fan, Yulin Chen, Jiayang Cheng, Tianshu Chu, Xuebing\n  Zhou, Peizhao Hu, Yangqiu Song","authorsParsed":[["Li","Haoran",""],["Fan","Wei",""],["Chen","Yulin",""],["Cheng","Jiayang",""],["Chu","Tianshu",""],["Zhou","Xuebing",""],["Hu","Peizhao",""],["Song","Yangqiu",""]],"versions":[{"version":"v1","created":"Mon, 19 Aug 2024 14:48:04 GMT"}],"updateDate":"2024-08-20","timestamp":1724078884000,"abstract":"  Privacy research has attracted wide attention as individuals worry that their\nprivate data can be easily leaked during interactions with smart devices,\nsocial platforms, and AI applications. Computer science researchers, on the\nother hand, commonly study privacy issues through privacy attacks and defenses\non segmented fields. Privacy research is conducted on various sub-fields,\nincluding Computer Vision (CV), Natural Language Processing (NLP), and Computer\nNetworks. Within each field, privacy has its own formulation. Though pioneering\nworks on attacks and defenses reveal sensitive privacy issues, they are\nnarrowly trapped and cannot fully cover people's actual privacy concerns.\nConsequently, the research on general and human-centric privacy research\nremains rather unexplored. In this paper, we formulate the privacy issue as a\nreasoning problem rather than simple pattern matching. We ground on the\nContextual Integrity (CI) theory which posits that people's perceptions of\nprivacy are highly correlated with the corresponding social context. Based on\nsuch an assumption, we develop the first comprehensive checklist that covers\nsocial identities, private attributes, and existing privacy regulations. Unlike\nprior works on CI that either cover limited expert annotated norms or model\nincomplete social context, our proposed privacy checklist uses the whole Health\nInsurance Portability and Accountability Act of 1996 (HIPAA) as an example, to\nshow that we can resort to large language models (LLMs) to completely cover the\nHIPAA's regulations. Additionally, our checklist also gathers expert\nannotations across multiple ontologies to determine private information\nincluding but not limited to personally identifiable information (PII). We use\nour preliminary results on the HIPAA to shed light on future context-centric\nprivacy research to cover more privacy regulations, social norms and standards.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Cryptography and Security"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}