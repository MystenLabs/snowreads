{"id":"2407.18328","title":"Unveiling Scoring Processes: Dissecting the Differences between LLMs and\n  Human Graders in Automatic Scoring","authors":"Xuansheng Wu, Padmaja Pravin Saraf, Gyeong-Geon Lee, Ehsan Latif,\n  Ninghao Liu, Xiaoming Zhai","authorsParsed":[["Wu","Xuansheng",""],["Saraf","Padmaja Pravin",""],["Lee","Gyeong-Geon",""],["Latif","Ehsan",""],["Liu","Ninghao",""],["Zhai","Xiaoming",""]],"versions":[{"version":"v1","created":"Thu, 4 Jul 2024 22:26:20 GMT"}],"updateDate":"2024-07-29","timestamp":1720131980000,"abstract":"  Large language models (LLMs) have demonstrated strong potential in performing\nautomatic scoring for constructed response assessments. While constructed\nresponses graded by humans are usually based on given grading rubrics, the\nmethods by which LLMs assign scores remain largely unclear. It is also\nuncertain how closely AI's scoring process mirrors that of humans, or if it\nadheres to the same grading criteria. To address this gap, this paper uncovers\nthe grading rubrics that LLMs used to score students' written responses to\nscience tasks and their alignment with human scores. We also examine whether\nenhancing the alignments can improve scoring accuracy. Specifically, we prompt\nLLMs to generate analytic rubrics that they use to assign scores and study the\nalignment gap with human grading rubrics. Based on a series of experiments with\nvarious configurations of LLM settings, we reveal a notable alignment gap\nbetween human and LLM graders. While LLMs can adapt quickly to scoring tasks,\nthey often resort to shortcuts, bypassing deeper logical reasoning expected in\nhuman grading. We found that incorporating high-quality analytical rubrics\ndesigned to reflect human grading logic can mitigate this gap and enhance LLMs'\nscoring accuracy. These results caution against the simplistic application of\nLLMs in science education and highlight the importance of aligning LLM outputs\nwith human expectations to ensure efficient and accurate automatic scoring.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Computers and Society"],"license":"http://creativecommons.org/licenses/by/4.0/"}