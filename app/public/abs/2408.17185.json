{"id":"2408.17185","title":"Short-term Wind Speed Forecasting for Power Integration in Smart Grids\n  based on Hybrid LSSVM-SVMD Method","authors":"Ephrem Admasu Yekun, Alem H. Fitwib, Selvi Karpaga Subramaniand,\n  Anubhav Kumard and Teshome Goa Tella","authorsParsed":[["Yekun","Ephrem Admasu",""],["Fitwib","Alem H.",""],["Subramaniand","Selvi Karpaga",""],["Kumard","Anubhav",""],["Tella","Teshome Goa",""]],"versions":[{"version":"v1","created":"Fri, 30 Aug 2024 10:35:59 GMT"}],"updateDate":"2024-09-02","timestamp":1725014159000,"abstract":"  Owing to its minimal pollution and efficient energy use, wind energy has\nbecome one of the most widely exploited renewable energy resources. The\nsuccessful integration of wind power into the grid system is contingent upon\naccurate wind speed forecasting models. However, the task of wind speed\nforecasting is challenging due to the inherent intermittent characteristics of\nwind speed. In this paper, a hybrid machine learning approach is developed for\npredicting short-term wind speed. First, the wind data was decomposed into\nmodal components using Successive Variational Mode Decomposition (SVMD). Then,\neach sub-signal was fitted into a Least Squares Support Vector Machines (LSSVM)\nmodel, with its hyperparameter optimized by a novel variant of Quantum-behaved\nParticle Swarm Optimization (QPSO), QPSO with elitist breeding (EBQPSO).\nSecond, the residuals making up for the differences between the original wind\nseries and the aggregate of the SVMD modes were modeled using long short-term\nmodel (LSTM). Then, the overall predicted values were computed using the\naggregate of the LSSVM and the LSTM models. Finally, the performance of the\nproposed model was compared against state-of-the-art benchmark models for\nforecasting wind speed using two separate data sets collected from a local wind\nfarm. Empirical results show significant improvement in performance by the\nproposed method, achieving a 1.21% to 32.76% reduction in root mean square\nerror (RMSE) and a 2.05% to 40.75% reduction in mean average error (MAE)\ncompared to the benchmark methods. The entire code implementation of this work\nis freely available in Github.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"JoFAbJ6QHXssCjmVDVbOu2gYVgpSzDjPv7k-VOdKtHI","pdfSize":"6777833"}
