{"id":"2407.16239","title":"Identifiable latent bandits: Combining observational data and\n  exploration for personalized healthcare","authors":"Ahmet Zahid Balc{\\i}o\\u{g}lu, Emil Carlsson, Fredrik D. Johansson","authorsParsed":[["Balcıoğlu","Ahmet Zahid",""],["Carlsson","Emil",""],["Johansson","Fredrik D.",""]],"versions":[{"version":"v1","created":"Tue, 23 Jul 2024 07:26:38 GMT"},{"version":"v2","created":"Mon, 29 Jul 2024 14:04:20 GMT"}],"updateDate":"2024-07-30","timestamp":1721719598000,"abstract":"  Bandit algorithms hold great promise for improving personalized\ndecision-making but are notoriously sample-hungry. In most health applications,\nit is infeasible to fit a new bandit for each patient, and observable variables\nare often insufficient to determine optimal treatments, ruling out applying\ncontextual bandits learned from multiple patients. Latent bandits offer both\nrapid exploration and personalization beyond what context variables can reveal\nbut require that a latent variable model can be learned consistently. In this\nwork, we propose bandit algorithms based on nonlinear independent component\nanalysis that can be provably identified from observational data to a degree\nsufficient to infer the optimal action in a new bandit instance consistently.\nWe verify this strategy in simulated data, showing substantial improvement over\nlearning independent multi-armed bandits for every instance.\n","subjects":["Computing Research Repository/Machine Learning","Statistics/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}