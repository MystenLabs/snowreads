{"id":"2408.08754","title":"SE-SGformer: A Self-Explainable Signed Graph Transformer for Link Sign\n  Prediction","authors":"Lu Li, Jiale Liu, Xingyu Ji, Maojun Wang, Zeyu Zhang","authorsParsed":[["Li","Lu",""],["Liu","Jiale",""],["Ji","Xingyu",""],["Wang","Maojun",""],["Zhang","Zeyu",""]],"versions":[{"version":"v1","created":"Fri, 16 Aug 2024 13:54:50 GMT"}],"updateDate":"2024-08-19","timestamp":1723816490000,"abstract":"  Signed Graph Neural Networks (SGNNs) have been shown to be effective in\nanalyzing complex patterns in real-world situations where positive and negative\nlinks coexist. However, SGNN models suffer from poor explainability, which\nlimit their adoptions in critical scenarios that require understanding the\nrationale behind predictions. To the best of our knowledge, there is currently\nno research work on the explainability of the SGNN models. Our goal is to\naddress the explainability of decision-making for the downstream task of link\nsign prediction specific to signed graph neural networks. Since post-hoc\nexplanations are not derived directly from the models, they may be biased and\nmisrepresent the true explanations. Therefore, in this paper we introduce a\nSelf-Explainable Signed Graph transformer (SE-SGformer) framework, which can\nnot only outputs explainable information while ensuring high prediction\naccuracy. Specifically, We propose a new Transformer architecture for signed\ngraphs and theoretically demonstrate that using positional encoding based on\nsigned random walks has greater expressive power than current SGNN methods and\nother positional encoding graph Transformer-based approaches. We constructs a\nnovel explainable decision process by discovering the $K$-nearest (farthest)\npositive (negative) neighbors of a node to replace the neural network-based\ndecoder for predicting edge signs. These $K$ positive (negative) neighbors\nrepresent crucial information about the formation of positive (negative) edges\nbetween nodes and thus can serve as important explanatory information in the\ndecision-making process. We conducted experiments on several real-world\ndatasets to validate the effectiveness of SE-SGformer, which outperforms the\nstate-of-the-art methods by improving 2.2\\% prediction accuracy and 73.1\\%\nexplainablity accuracy in the best-case scenario.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}