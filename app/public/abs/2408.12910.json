{"id":"2408.12910","title":"What Do You Want? User-centric Prompt Generation for Text-to-image\n  Synthesis via Multi-turn Guidance","authors":"Yilun Liu, Minggui He, Feiyu Yao, Yuhe Ji, Shimin Tao, Jingzhou Du,\n  Duan Li, Jian Gao, Li Zhang, Hao Yang, Boxing Chen, Osamu Yoshie","authorsParsed":[["Liu","Yilun",""],["He","Minggui",""],["Yao","Feiyu",""],["Ji","Yuhe",""],["Tao","Shimin",""],["Du","Jingzhou",""],["Li","Duan",""],["Gao","Jian",""],["Zhang","Li",""],["Yang","Hao",""],["Chen","Boxing",""],["Yoshie","Osamu",""]],"versions":[{"version":"v1","created":"Fri, 23 Aug 2024 08:35:35 GMT"}],"updateDate":"2024-08-26","timestamp":1724402135000,"abstract":"  The emergence of text-to-image synthesis (TIS) models has significantly\ninfluenced digital image creation by producing high-quality visuals from\nwritten descriptions. Yet these models heavily rely on the quality and\nspecificity of textual prompts, posing a challenge for novice users who may not\nbe familiar with TIS-model-preferred prompt writing. Existing solutions relieve\nthis via automatic model-preferred prompt generation from user queries.\nHowever, this single-turn manner suffers from limited user-centricity in terms\nof result interpretability and user interactivity. To address these issues, we\npropose DialPrompt, a multi-turn dialogue-based TIS prompt generation model\nthat emphasises user-centricity. DialPrompt is designed to follow a multi-turn\nguidance workflow, where in each round of dialogue the model queries user with\ntheir preferences on possible optimization dimensions before generating the\nfinal TIS prompt. To achieve this, we mined 15 essential dimensions for\nhigh-quality prompts from advanced users and curated a multi-turn dataset.\nThrough training on this dataset, DialPrompt can improve interpretability by\nallowing users to understand the correlation between specific phrases and image\nattributes. Additionally, it enables greater user control and engagement in the\nprompt generation process, leading to more personalized and visually satisfying\noutputs. Experiments indicate that DialPrompt achieves a competitive result in\nthe quality of synthesized images, outperforming existing prompt engineering\napproaches by 5.7%. Furthermore, in our user evaluation, DialPrompt outperforms\nexisting approaches by 46.5% in user-centricity score and is rated 7.9/10 by 19\nhuman reviewers.\n","subjects":["Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}