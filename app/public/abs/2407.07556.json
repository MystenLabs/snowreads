{"id":"2407.07556","title":"Mini-batch descent in semiflows","authors":"Alberto Dom\\'inguez Corella, Mart\\'in Hern\\'andez","authorsParsed":[["Corella","Alberto Domínguez",""],["Hernández","Martín",""]],"versions":[{"version":"v1","created":"Wed, 10 Jul 2024 11:29:43 GMT"}],"updateDate":"2024-07-11","timestamp":1720610983000,"abstract":"  This paper investigates the application of mini-batch gradient descent to\nsemiflows. Given a loss function, we introduce a continuous version of\nmini-batch gradient descent by randomly selecting sub-loss functions over time,\ndefining a piecewise flow. We prove that, under suitable assumptions on the\ngradient flow, the mini-batch descent flow trajectory closely approximates the\noriginal gradient flow trajectory on average. Additionally, we propose a\nrandomized minimizing movement scheme that also approximates the gradient flow\nof the loss function. We illustrate the versatility of this approach across\nvarious problems, including constrained optimization, sparse inversion, and\ndomain decomposition. Finally, we validate our results with several numerical\nexamples.\n","subjects":["Mathematics/Optimization and Control","Computing Research Repository/Numerical Analysis","Mathematics/Numerical Analysis"],"license":"http://creativecommons.org/licenses/by/4.0/"}