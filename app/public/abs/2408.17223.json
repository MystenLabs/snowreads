{"id":"2408.17223","title":"OG-Mapping: Octree-based Structured 3D Gaussians for Online Dense\n  Mapping","authors":"Meng Wang, Junyi Wang, Changqun Xia, Chen Wang, Yue Qi","authorsParsed":[["Wang","Meng",""],["Wang","Junyi",""],["Xia","Changqun",""],["Wang","Chen",""],["Qi","Yue",""]],"versions":[{"version":"v1","created":"Fri, 30 Aug 2024 12:01:59 GMT"}],"updateDate":"2024-09-02","timestamp":1725019319000,"abstract":"  3D Gaussian splatting (3DGS) has recently demonstrated promising advancements\nin RGB-D online dense mapping. Nevertheless, existing methods excessively rely\non per-pixel depth cues to perform map densification, which leads to\nsignificant redundancy and increased sensitivity to depth noise. Additionally,\nexplicitly storing 3D Gaussian parameters of room-scale scene poses a\nsignificant storage challenge. In this paper, we introduce OG-Mapping, which\nleverages the robust scene structural representation capability of sparse\noctrees, combined with structured 3D Gaussian representations, to achieve\nefficient and robust online dense mapping. Moreover, OG-Mapping employs an\nanchor-based progressive map refinement strategy to recover the scene\nstructures at multiple levels of detail. Instead of maintaining a small number\nof active keyframes with a fixed keyframe window as previous approaches do, a\ndynamic keyframe window is employed to allow OG-Mapping to better tackle false\nlocal minima and forgetting issues. Experimental results demonstrate that\nOG-Mapping delivers more robust and superior realism mapping results than\nexisting Gaussian-based RGB-D online mapping methods with a compact model, and\nno additional post-processing is required.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}