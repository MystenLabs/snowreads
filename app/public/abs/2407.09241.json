{"id":"2407.09241","title":"The Sociolinguistic Foundations of Language Modeling","authors":"Jack Grieve, Sara Bartl, Matteo Fuoli, Jason Grafmiller, Weihang\n  Huang, Alejandro Jawerbaum, Akira Murakami, Marcus Perlman, Dana Roemling,\n  Bodo Winter","authorsParsed":[["Grieve","Jack",""],["Bartl","Sara",""],["Fuoli","Matteo",""],["Grafmiller","Jason",""],["Huang","Weihang",""],["Jawerbaum","Alejandro",""],["Murakami","Akira",""],["Perlman","Marcus",""],["Roemling","Dana",""],["Winter","Bodo",""]],"versions":[{"version":"v1","created":"Fri, 12 Jul 2024 13:12:55 GMT"}],"updateDate":"2024-07-15","timestamp":1720789975000,"abstract":"  In this paper, we introduce a sociolinguistic perspective on language\nmodeling. We claim that large language models are inherently models of\nvarieties of language, and we consider how this insight can inform the\ndevelopment and deployment of large language models. We begin by presenting a\ntechnical definition of the concept of a variety of language as developed in\nsociolinguistics. We then discuss how this perspective can help address five\nbasic challenges in language modeling: social bias, domain adaptation,\nalignment, language change, and scale. Ultimately, we argue that it is crucial\nto carefully define and compile training corpora that accurately represent the\nspecific varieties of language being modeled to maximize the performance and\nsocietal value of large language models.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"jWwoCMDUQtw6aMqy0p5lXVJvmoQkGGui9gTIlPWlaxo","pdfSize":"4197170"}
