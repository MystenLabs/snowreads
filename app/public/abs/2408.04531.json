{"id":"2408.04531","title":"AExGym: Benchmarks and Environments for Adaptive Experimentation","authors":"Jimmy Wang, Ethan Che, Daniel R. Jiang, Hongseok Namkoong","authorsParsed":[["Wang","Jimmy",""],["Che","Ethan",""],["Jiang","Daniel R.",""],["Namkoong","Hongseok",""]],"versions":[{"version":"v1","created":"Thu, 8 Aug 2024 15:32:12 GMT"}],"updateDate":"2024-08-09","timestamp":1723131132000,"abstract":"  Innovations across science and industry are evaluated using randomized trials\n(a.k.a. A/B tests). While simple and robust, such static designs are\ninefficient or infeasible for testing many hypotheses. Adaptive designs can\ngreatly improve statistical power in theory, but they have seen limited\nadoption due to their fragility in practice. We present a benchmark for\nadaptive experimentation based on real-world datasets, highlighting prominent\npractical challenges to operationalizing adaptivity: non-stationarity,\nbatched/delayed feedback, multiple outcomes and objectives, and external\nvalidity. Our benchmark aims to spur methodological development that puts\npractical performance (e.g., robustness) as a central concern, rather than\nmathematical guarantees on contrived instances. We release an open source\nlibrary, AExGym, which is designed with modularity and extensibility in mind to\nallow experimentation practitioners to develop custom environments and\nalgorithms.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}