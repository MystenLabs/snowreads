{"id":"2407.15749","title":"Robustness of Speech Separation Models for Similar-pitch Speakers","authors":"Bunlong Lay, Sebastian Zaczek, Kristina Tesch, Timo Gerkmann","authorsParsed":[["Lay","Bunlong",""],["Zaczek","Sebastian",""],["Tesch","Kristina",""],["Gerkmann","Timo",""]],"versions":[{"version":"v1","created":"Mon, 22 Jul 2024 15:55:08 GMT"}],"updateDate":"2024-07-23","timestamp":1721663708000,"abstract":"  Single-channel speech separation is a crucial task for enhancing speech\nrecognition systems in multi-speaker environments. This paper investigates the\nrobustness of state-of-the-art Neural Network models in scenarios where the\npitch differences between speakers are minimal. Building on earlier findings by\nDitter and Gerkmann, which identified a significant performance drop for the\n2018 Chimera++ under similar-pitch conditions, our study extends the analysis\nto more recent and sophisticated Neural Network models. Our experiments reveal\nthat modern models have substantially reduced the performance gap for matched\ntraining and testing conditions. However, a substantial performance gap\npersists under mismatched conditions, with models performing well for large\npitch differences but showing worse performance if the speakers' pitches are\nsimilar. These findings motivate further research into the generalizability of\nspeech separation models to similar-pitch speakers and unseen data.\n","subjects":["Electrical Engineering and Systems Science/Audio and Speech Processing","Computing Research Repository/Machine Learning","Electrical Engineering and Systems Science/Signal Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}