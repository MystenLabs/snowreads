{"id":"2407.03280","title":"Cooperative Multi-Agent Deep Reinforcement Learning Methods for\n  UAV-aided Mobile Edge Computing Networks","authors":"Mintae Kim, Hoon Lee, Sangwon Hwang, Merouane Debbah, Inkyu Lee","authorsParsed":[["Kim","Mintae",""],["Lee","Hoon",""],["Hwang","Sangwon",""],["Debbah","Merouane",""],["Lee","Inkyu",""]],"versions":[{"version":"v1","created":"Wed, 3 Jul 2024 17:04:47 GMT"}],"updateDate":"2024-07-04","timestamp":1720026287000,"abstract":"  This paper presents a cooperative multi-agent deep reinforcement learning\n(MADRL) approach for unmmaned aerial vehicle (UAV)-aided mobile edge computing\n(MEC) networks. An UAV with computing capability can provide task offlaoding\nservices to ground internet-of-things devices (IDs). With partial observation\nof the entire network state, the UAV and the IDs individually determine their\nMEC strategies, i.e., UAV trajectory, resource allocation, and task offloading\npolicy. This requires joint optimization of decision-making process and\ncoordination strategies among the UAV and the IDs. To address this difficulty,\nthe proposed cooperative MADRL approach computes two types of action variables,\nnamely message action and solution action, each of which is generated by\ndedicated actor neural networks (NNs). As a result, each agent can\nautomatically encapsulate its coordination messages to enhance the MEC\nperformance in the decentralized manner. The proposed actor structure is\ndesigned based on graph attention networks such that operations are possible\nregardless of the number of IDs. A scalable training algorithm is also proposed\nto train a group of NNs for arbitrary network configurations. Numerical results\ndemonstrate the superiority of the proposed cooperative MADRL approach over\nconventional methods.\n","subjects":["Computing Research Repository/Information Theory","Mathematics/Information Theory"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}