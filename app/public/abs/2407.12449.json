{"id":"2407.12449","title":"Close the Sim2real Gap via Physically-based Structured Light Synthetic\n  Data Simulation","authors":"Kaixin Bai, Lei Zhang, Zhaopeng Chen, Fang Wan, Jianwei Zhang","authorsParsed":[["Bai","Kaixin",""],["Zhang","Lei",""],["Chen","Zhaopeng",""],["Wan","Fang",""],["Zhang","Jianwei",""]],"versions":[{"version":"v1","created":"Wed, 17 Jul 2024 09:57:14 GMT"}],"updateDate":"2024-07-18","timestamp":1721210234000,"abstract":"  Despite the substantial progress in deep learning, its adoption in industrial\nrobotics projects remains limited, primarily due to challenges in data\nacquisition and labeling. Previous sim2real approaches using domain\nrandomization require extensive scene and model optimization. To address these\nissues, we introduce an innovative physically-based structured light simulation\nsystem, generating both RGB and physically realistic depth images, surpassing\nprevious dataset generation tools. We create an RGBD dataset tailored for\nrobotic industrial grasping scenarios and evaluate it across various tasks,\nincluding object detection, instance segmentation, and embedding sim2real\nvisual perception in industrial robotic grasping. By reducing the sim2real gap\nand enhancing deep learning training, we facilitate the application of deep\nlearning models in industrial settings. Project details are available at\nhttps://baikaixinpublic.github.io/structured light 3D synthesizer/.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}