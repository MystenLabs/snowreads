{"id":"2408.17401","title":"Exploring the Effect of Explanation Content and Format on User\n  Comprehension and Trust","authors":"Antonio Rago, Bence Palfi, Purin Sukpanichnant, Hannibal Nabli,\n  Kavyesh Vivek, Olga Kostopoulou, James Kinross and Francesca Toni","authorsParsed":[["Rago","Antonio",""],["Palfi","Bence",""],["Sukpanichnant","Purin",""],["Nabli","Hannibal",""],["Vivek","Kavyesh",""],["Kostopoulou","Olga",""],["Kinross","James",""],["Toni","Francesca",""]],"versions":[{"version":"v1","created":"Fri, 30 Aug 2024 16:36:53 GMT"}],"updateDate":"2024-09-02","timestamp":1725035813000,"abstract":"  In recent years, various methods have been introduced for explaining the\noutputs of \"black-box\" AI models. However, it is not well understood whether\nusers actually comprehend and trust these explanations. In this paper, we focus\non explanations for a regression tool for assessing cancer risk and examine the\neffect of the explanations' content and format on the user-centric metrics of\ncomprehension and trust. Regarding content, we experiment with two explanation\nmethods: the popular SHAP, based on game-theoretic notions and thus potentially\ncomplex for everyday users to comprehend, and occlusion-1, based on feature\nocclusion which may be more comprehensible. Regarding format, we present SHAP\nexplanations as charts (SC), as is conventional, and occlusion-1 explanations\nas charts (OC) as well as text (OT), to which their simpler nature also lends\nitself. The experiments amount to user studies questioning participants, with\ntwo different levels of expertise (the general population and those with some\nmedical training), on their subjective and objective comprehension of and trust\nin explanations for the outputs of the regression tool. In both studies we\nfound a clear preference in terms of subjective comprehension and trust for\nocclusion-1 over SHAP explanations in general, when comparing based on content.\nHowever, direct comparisons of explanations when controlling for format only\nrevealed evidence for OT over SC explanations in most cases, suggesting that\nthe dominance of occlusion-1 over SHAP explanations may be driven by a\npreference for text over charts as explanations. Finally, we found no evidence\nof a difference between the explanation types in terms of objective\ncomprehension. Thus overall, the choice of the content and format of\nexplanations needs careful attention, since in some contexts format, rather\nthan content, may play the critical role in improving user experience.\n","subjects":["Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"mSzuiO5BjEBaMd36vE1MhIRiV249REMAN-1jxqDXQBg","pdfSize":"1969676"}
