{"id":"2408.09940","title":"ML-CrAIST: Multi-scale Low-high Frequency Information-based Cross black\n  Attention with Image Super-resolving Transformer","authors":"Alik Pramanick, Utsav Bheda and Arijit Sur","authorsParsed":[["Pramanick","Alik",""],["Bheda","Utsav",""],["Sur","Arijit",""]],"versions":[{"version":"v1","created":"Mon, 19 Aug 2024 12:23:15 GMT"}],"updateDate":"2024-08-20","timestamp":1724070195000,"abstract":"  Recently, transformers have captured significant interest in the area of\nsingle-image super-resolution tasks, demonstrating substantial gains in\nperformance. Current models heavily depend on the network's extensive ability\nto extract high-level semantic details from images while overlooking the\neffective utilization of multi-scale image details and intermediate information\nwithin the network. Furthermore, it has been observed that high-frequency areas\nin images present significant complexity for super-resolution compared to\nlow-frequency areas. This work proposes a transformer-based super-resolution\narchitecture called ML-CrAIST that addresses this gap by utilizing low-high\nfrequency information in multiple scales. Unlike most of the previous work\n(either spatial or channel), we operate spatial and channel self-attention,\nwhich concurrently model pixel interaction from both spatial and channel\ndimensions, exploiting the inherent correlations across spatial and channel\naxis. Further, we devise a cross-attention block for super-resolution, which\nexplores the correlations between low and high-frequency information.\nQuantitative and qualitative assessments indicate that our proposed ML-CrAIST\nsurpasses state-of-the-art super-resolution methods (e.g., 0.15 dB gain\n@Manga109 $\\times$4). Code is available on:\nhttps://github.com/Alik033/ML-CrAIST.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Electrical Engineering and Systems Science/Image and Video Processing"],"license":"http://creativecommons.org/licenses/by/4.0/"}