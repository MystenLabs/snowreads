{"id":"2407.03442","title":"Fisher-aware Quantization for DETR Detectors with Critical-category\n  Objectives","authors":"Huanrui Yang, Yafeng Huang, Zhen Dong, Denis A Gudovskiy, Tomoyuki\n  Okuno, Yohei Nakata, Yuan Du, Kurt Keutzer, Shanghang Zhang","authorsParsed":[["Yang","Huanrui",""],["Huang","Yafeng",""],["Dong","Zhen",""],["Gudovskiy","Denis A",""],["Okuno","Tomoyuki",""],["Nakata","Yohei",""],["Du","Yuan",""],["Keutzer","Kurt",""],["Zhang","Shanghang",""]],"versions":[{"version":"v1","created":"Wed, 3 Jul 2024 18:35:53 GMT"}],"updateDate":"2024-07-08","timestamp":1720031753000,"abstract":"  The impact of quantization on the overall performance of deep learning models\nis a well-studied problem. However, understanding and mitigating its effects on\na more fine-grained level is still lacking, especially for harder tasks such as\nobject detection with both classification and regression objectives. This work\ndefines the performance for a subset of task-critical categories, i.e. the\ncritical-category performance, as a crucial yet largely overlooked fine-grained\nobjective for detection tasks. We analyze the impact of quantization at the\ncategory-level granularity, and propose methods to improve performance for the\ncritical categories. Specifically, we find that certain critical categories\nhave a higher sensitivity to quantization, and are prone to overfitting after\nquantization-aware training (QAT). To explain this, we provide theoretical and\nempirical links between their performance gaps and the corresponding loss\nlandscapes with the Fisher information framework. Using this evidence, we apply\na Fisher-aware mixed-precision quantization scheme, and a Fisher-trace\nregularization for the QAT on the critical-category loss landscape. The\nproposed methods improve critical-category metrics of the quantized\ntransformer-based DETR detectors. They are even more significant in case of\nlarger models and higher number of classes where the overfitting becomes more\nsevere. For example, our methods lead to 10.4% and 14.5% mAP gains for,\ncorrespondingly, 4-bit DETR-R50 and Deformable DETR on the most impacted\ncritical classes in the COCO Panoptic dataset.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}