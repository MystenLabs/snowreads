{"id":"2407.17230","title":"Improving ICD coding using Chapter based Named Entities and Attentional\n  Models","authors":"Abhijith R. Beeravolu, Mirjam Jonkman, Sami Azam, Friso De Boer","authorsParsed":[["Beeravolu","Abhijith R.",""],["Jonkman","Mirjam",""],["Azam","Sami",""],["De Boer","Friso",""]],"versions":[{"version":"v1","created":"Wed, 24 Jul 2024 12:34:23 GMT"}],"updateDate":"2024-07-25","timestamp":1721824463000,"abstract":"  Recent advancements in natural language processing (NLP) have led to\nautomation in various domains. However, clinical NLP often relies on benchmark\ndatasets that may not reflect real-world scenarios accurately. Automatic ICD\ncoding, a vital NLP task, typically uses outdated and imbalanced datasets like\nMIMIC-III, with existing methods yielding micro-averaged F1 scores between 0.4\nand 0.7 due to many false positives. Our research introduces an enhanced\napproach to ICD coding that improves F1 scores by using chapter-based named\nentities and attentional models. This method categorizes discharge summaries\ninto ICD-9 Chapters and develops attentional models with chapter-specific data,\neliminating the need to consider external data for code identification. For\ncategorization, we use Chapter-IV to de-bias and influence key entities and\nweights without neural networks, creating accurate thresholds and providing\ninterpretability for human validation. Post-validation, we develop attentional\nmodels for three frequent and three non-frequent codes from Chapter-IV using\nBidirectional-Gated Recurrent Units (GRUs) with Attention and Transformer with\nMulti-head Attention architectures. The average Micro-F1 scores of 0.79 and\n0.81 from these models demonstrate significant performance improvements in ICD\ncoding.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"FN5mkC4H5YTqXke1PUI_jtoRAnpj3de_048qrhC5_KY","pdfSize":"1381112"}
