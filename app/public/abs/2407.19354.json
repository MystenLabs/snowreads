{"id":"2407.19354","title":"The Emerged Security and Privacy of LLM Agent: A Survey with Case\n  Studies","authors":"Feng He, Tianqing Zhu, Dayong Ye, Bo Liu, Wanlei Zhou, Philip S. Yu","authorsParsed":[["He","Feng",""],["Zhu","Tianqing",""],["Ye","Dayong",""],["Liu","Bo",""],["Zhou","Wanlei",""],["Yu","Philip S.",""]],"versions":[{"version":"v1","created":"Sun, 28 Jul 2024 00:26:24 GMT"}],"updateDate":"2024-07-30","timestamp":1722126384000,"abstract":"  Inspired by the rapid development of Large Language Models (LLMs), LLM agents\nhave evolved to perform complex tasks. LLM agents are now extensively applied\nacross various domains, handling vast amounts of data to interact with humans\nand execute tasks. The widespread applications of LLM agents demonstrate their\nsignificant commercial value; however, they also expose security and privacy\nvulnerabilities. At the current stage, comprehensive research on the security\nand privacy of LLM agents is highly needed. This survey aims to provide a\ncomprehensive overview of the newly emerged privacy and security issues faced\nby LLM agents. We begin by introducing the fundamental knowledge of LLM agents,\nfollowed by a categorization and analysis of the threats. We then discuss the\nimpacts of these threats on humans, environment, and other agents.\nSubsequently, we review existing defensive strategies, and finally explore\nfuture trends. Additionally, the survey incorporates diverse case studies to\nfacilitate a more accessible understanding. By highlighting these critical\nsecurity and privacy issues, the survey seeks to stimulate future research\ntowards enhancing the security and privacy of LLM agents, thereby increasing\ntheir reliability and trustworthiness in future applications.\n","subjects":["Computing Research Repository/Cryptography and Security"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}