{"id":"2408.01269","title":"A General Framework to Boost 3D GS Initialization for Text-to-3D\n  Generation by Lexical Richness","authors":"Lutao Jiang, Hangyu Li and Lin Wang","authorsParsed":[["Jiang","Lutao",""],["Li","Hangyu",""],["Wang","Lin",""]],"versions":[{"version":"v1","created":"Fri, 2 Aug 2024 13:46:15 GMT"}],"updateDate":"2024-08-05","timestamp":1722606375000,"abstract":"  Text-to-3D content creation has recently received much attention, especially\nwith the prevalence of 3D Gaussians Splatting. In general, GS-based methods\ncomprise two key stages: initialization and rendering optimization. To achieve\ninitialization, existing works directly apply random sphere initialization or\n3D diffusion models, e.g., Point-E, to derive the initial shapes. However, such\nstrategies suffer from two critical yet challenging problems: 1) the final\nshapes are still similar to the initial ones even after training; 2) shapes can\nbe produced only from simple texts, e.g., \"a dog\", not for lexically richer\ntexts, e.g., \"a dog is sitting on the top of the airplane\". To address these\nproblems, this paper proposes a novel general framework to boost the 3D GS\nInitialization for text-to-3D generation upon the lexical richness. Our key\nidea is to aggregate 3D Gaussians into spatially uniform voxels to represent\ncomplex shapes while enabling the spatial interaction among the 3D Gaussians\nand semantic interaction between Gaussians and texts. Specifically, we first\nconstruct a voxelized representation, where each voxel holds a 3D Gaussian with\nits position, scale, and rotation fixed while setting opacity as the sole\nfactor to determine a position's occupancy. We then design an initialization\nnetwork mainly consisting of two novel components: 1) Global Information\nPerception (GIP) block and 2) Gaussians-Text Fusion (GTF) block. Such a design\nenables each 3D Gaussian to assimilate the spatial information from other areas\nand semantic information from texts. Extensive experiments show the superiority\nof our framework of high-quality 3D GS initialization against the existing\nmethods, e.g., Shap-E, by taking lexically simple, medium, and hard texts.\nAlso, our framework can be seamlessly plugged into SoTA training frameworks,\ne.g., LucidDreamer, for semantically consistent text-to-3D generation.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}