{"id":"2407.14108","title":"GaussianBeV: 3D Gaussian Representation meets Perception Models for BeV\n  Segmentation","authors":"Florian Chabot, Nicolas Granger, Guillaume Lapouge","authorsParsed":[["Chabot","Florian",""],["Granger","Nicolas",""],["Lapouge","Guillaume",""]],"versions":[{"version":"v1","created":"Fri, 19 Jul 2024 08:24:36 GMT"}],"updateDate":"2024-07-22","timestamp":1721377476000,"abstract":"  The Bird's-eye View (BeV) representation is widely used for 3D perception\nfrom multi-view camera images. It allows to merge features from different\ncameras into a common space, providing a unified representation of the 3D\nscene. The key component is the view transformer, which transforms image views\ninto the BeV. However, actual view transformer methods based on geometry or\ncross-attention do not provide a sufficiently detailed representation of the\nscene, as they use a sub-sampling of the 3D space that is non-optimal for\nmodeling the fine structures of the environment. In this paper, we propose\nGaussianBeV, a novel method for transforming image features to BeV by finely\nrepresenting the scene using a set of 3D gaussians located and oriented in 3D\nspace. This representation is then splattered to produce the BeV feature map by\nadapting recent advances in 3D representation rendering based on gaussian\nsplatting. GaussianBeV is the first approach to use this 3D gaussian modeling\nand 3D scene rendering process online, i.e. without optimizing it on a specific\nscene and directly integrated into a single stage model for BeV scene\nunderstanding. Experiments show that the proposed representation is highly\neffective and place GaussianBeV as the new state-of-the-art on the BeV semantic\nsegmentation task on the nuScenes dataset.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}