{"id":"2408.10328","title":"Decoding Human Emotions: Analyzing Multi-Channel EEG Data using LSTM\n  Networks","authors":"Shyam K Sateesh, Sparsh BK, Uma D","authorsParsed":[["Sateesh","Shyam K",""],["BK","Sparsh",""],["D","Uma",""]],"versions":[{"version":"v1","created":"Mon, 19 Aug 2024 18:10:47 GMT"}],"updateDate":"2024-08-21","timestamp":1724091047000,"abstract":"  Emotion recognition from electroencephalogram (EEG) signals is a thriving\nfield, particularly in neuroscience and Human-Computer Interaction (HCI). This\nstudy aims to understand and improve the predictive accuracy of emotional state\nclassification through metrics such as valence, arousal, dominance, and\nlikeness by applying a Long Short-Term Memory (LSTM) network to analyze EEG\nsignals. Using a popular dataset of multi-channel EEG recordings known as DEAP,\nwe look towards leveraging LSTM networks' properties to handle temporal\ndependencies within EEG signal data. This allows for a more comprehensive\nunderstanding and classification of emotional parameter states. We obtain\naccuracies of 89.89%, 90.33%, 90.70%, and 90.54% for arousal, valence,\ndominance, and likeness, respectively, demonstrating significant improvements\nin emotion recognition model capabilities. This paper elucidates the\nmethodology and architectural specifics of our LSTM model and provides a\nbenchmark analysis with existing papers.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Human-Computer Interaction"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/"}