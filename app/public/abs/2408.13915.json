{"id":"2408.13915","title":"LLMs are Superior Feedback Providers: Bootstrapping Reasoning for Lie\n  Detection with Self-Generated Feedback","authors":"Tanushree Banerjee, Richard Zhu, Runzhe Yang, Karthik Narasimhan","authorsParsed":[["Banerjee","Tanushree",""],["Zhu","Richard",""],["Yang","Runzhe",""],["Narasimhan","Karthik",""]],"versions":[{"version":"v1","created":"Sun, 25 Aug 2024 18:47:55 GMT"}],"updateDate":"2024-08-27","timestamp":1724611675000,"abstract":"  Large Language Models (LLMs) excel at generating human-like dialogues and\ncomprehending text. However, understanding the subtleties of complex exchanges\nin language remains a challenge. We propose a bootstrapping framework that\nleverages self-generated feedback to enhance LLM reasoning capabilities for lie\ndetection. The framework consists of three stages: suggestion, feedback\ncollection, and modification. In the suggestion stage, a cost-effective\nlanguage model generates initial predictions based on game state and dialogue.\nThe feedback-collection stage involves a language model providing feedback on\nthese predictions. In the modification stage, a more advanced language model\nrefines the initial predictions using the auto-generated feedback. We\ninvestigate the application of the proposed framework for detecting betrayal\nand deception in Diplomacy games, and compare it with feedback from\nprofessional human players. The LLM-generated feedback exhibits superior\nquality and significantly enhances the performance of the model. Our approach\nachieves a 39% improvement over the zero-shot baseline in lying-F1 without the\nneed for any training data, rivaling state-of-the-art supervised learning\nresults.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/publicdomain/zero/1.0/","blobId":"le11az4rEGmcRtvt6fUoO20oTwgcuXhOk2rKw3dqjV4","pdfSize":"1848820"}
