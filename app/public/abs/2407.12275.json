{"id":"2407.12275","title":"When can transformers compositionally generalize in-context?","authors":"Seijin Kobayashi, Simon Schug, Yassir Akram, Florian Redhardt,\n  Johannes von Oswald, Razvan Pascanu, Guillaume Lajoie, Jo\\~ao Sacramento","authorsParsed":[["Kobayashi","Seijin",""],["Schug","Simon",""],["Akram","Yassir",""],["Redhardt","Florian",""],["von Oswald","Johannes",""],["Pascanu","Razvan",""],["Lajoie","Guillaume",""],["Sacramento","Jo√£o",""]],"versions":[{"version":"v1","created":"Wed, 17 Jul 2024 02:49:27 GMT"}],"updateDate":"2024-07-18","timestamp":1721184567000,"abstract":"  Many tasks can be composed from a few independent components. This gives rise\nto a combinatorial explosion of possible tasks, only some of which might be\nencountered during training. Under what circumstances can transformers\ncompositionally generalize from a subset of tasks to all possible combinations\nof tasks that share similar components? Here we study a modular multitask\nsetting that allows us to precisely control compositional structure in the data\ngeneration process. We present evidence that transformers learning in-context\nstruggle to generalize compositionally on this task despite being in principle\nexpressive enough to do so. Compositional generalization becomes possible only\nwhen introducing a bottleneck that enforces an explicit separation between task\ninference and task execution.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Neural and Evolutionary Computing"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"lYS42R5tJjcnArtmaKPFrIoDTenJqkYEpbV0n-TaTHg","pdfSize":"537436","objectId":"0x3388fbfd2dd60e09d4c69524ee9da93f963152c14922af99ac42fafdbf7599a5","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
