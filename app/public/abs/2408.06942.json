{"id":"2408.06942","title":"Speech-based Mark for Data Sonification","authors":"Yichun Zhao, Jingyi Lu, Miguel A Nacenta","authorsParsed":[["Zhao","Yichun",""],["Lu","Jingyi",""],["Nacenta","Miguel A",""]],"versions":[{"version":"v1","created":"Tue, 13 Aug 2024 15:01:03 GMT"}],"updateDate":"2024-08-14","timestamp":1723561263000,"abstract":"  Sonification serves as a powerful tool for data accessibility, especially for\npeople with vision loss. Among various modalities, speech is a familiar means\nof communication similar to the role of text in visualization. However,\nspeech-based sonification is underexplored. We introduce SpeechTone, a novel\nspeech-based mark for data sonification and extension to the existing Erie\ndeclarative grammar for sonification. It encodes data into speech attributes\nsuch as pitch, speed, voice and speech content. We demonstrate the efficacy of\nSpeechTone through three examples.\n","subjects":["Computing Research Repository/Human-Computer Interaction"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}