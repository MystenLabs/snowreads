{"id":"2408.08977","title":"FedFQ: Federated Learning with Fine-Grained Quantization","authors":"Haowei Li, Weiying Xie, Hangyu Ye, Jitao Ma, Shuran Ma, Yunsong Li","authorsParsed":[["Li","Haowei",""],["Xie","Weiying",""],["Ye","Hangyu",""],["Ma","Jitao",""],["Ma","Shuran",""],["Li","Yunsong",""]],"versions":[{"version":"v1","created":"Fri, 16 Aug 2024 19:00:36 GMT"}],"updateDate":"2024-08-20","timestamp":1723834836000,"abstract":"  Federated learning (FL) is a decentralized approach, enabling multiple\nparticipants to collaboratively train a model while ensuring the protection of\ndata privacy. The transmission of updates from numerous edge clusters to the\nserver creates a significant communication bottleneck in FL. Quantization is an\neffective compression technology, showcasing immense potential in addressing\nthis bottleneck problem. The Non-IID nature of FL renders it sensitive to\nquantization. Existing quantized FL frameworks inadequately balance high\ncompression ratios and superior convergence performance by roughly employing a\nuniform quantization bit-width on the client-side. In this work, we propose a\ncommunication-efficient FL algorithm with a fine-grained adaptive quantization\nstrategy (FedFQ). FedFQ addresses the trade-off between achieving high\ncommunication compression ratios and maintaining superior convergence\nperformance by introducing parameter-level quantization. Specifically, we have\ndesigned a Constraint-Guided Simulated Annealing algorithm to determine\nspecific quantization schemes. We derive the convergence of FedFQ,\ndemonstrating its superior convergence performance compared to existing\nquantized FL algorithms. We conducted extensive experiments on multiple\nbenchmarks and demonstrated that, while maintaining lossless performance, FedFQ\nachieves a compression ratio of 27 times to 63 times compared to the baseline\nexperiment.\n","subjects":["Computing Research Repository/Distributed, Parallel, and Cluster Computing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}