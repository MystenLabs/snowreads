{"id":"2408.14327","title":"Learning Topic Hierarchies by Tree-Directed Latent Variable Models","authors":"Sunrit Chakraborty, Rayleigh Lei and XuanLong Nguyen","authorsParsed":[["Chakraborty","Sunrit",""],["Lei","Rayleigh",""],["Nguyen","XuanLong",""]],"versions":[{"version":"v1","created":"Mon, 26 Aug 2024 14:54:46 GMT"}],"updateDate":"2024-08-27","timestamp":1724684086000,"abstract":"  We study a parametric family of latent variable models, namely topic models,\nequipped with a hierarchical structure among the topic variables. Such models\nmay be viewed as a finite mixture of the latent Dirichlet allocation (LDA)\ninduced distributions, but the LDA components are constrained by a latent\nhierarchy, specifically a rooted and directed tree structure, which enables the\nlearning of interpretable and latent topic hierarchies of interest. A\nmathematical framework is developed in order to establish identifiability of\nthe latent topic hierarchy under suitable regularity conditions, and to derive\nbounds for posterior contraction rates of the model and its parameters. We\ndemonstrate the usefulness of such models and validate its theoretical\nproperties through a careful simulation study and a real data example using the\nNew York Times articles.\n","subjects":["Mathematics/Statistics Theory","Statistics/Statistics Theory"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"_0vqD10bCVBOHVcvddpY0Y5kcC4niNAl2R46Ax3dj6Y","pdfSize":"2112923"}
