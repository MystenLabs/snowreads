{"id":"2407.02732","title":"Supporting Cross-language Cross-project Bug Localization Using\n  Pre-trained Language Models","authors":"Mahinthan Chandramohan, Dai Quoc Nguyen, Padmanabhan Krishnan, and\n  Jovan Jancic","authorsParsed":[["Chandramohan","Mahinthan",""],["Nguyen","Dai Quoc",""],["Krishnan","Padmanabhan",""],["Jancic","Jovan",""]],"versions":[{"version":"v1","created":"Wed, 3 Jul 2024 01:09:36 GMT"}],"updateDate":"2024-07-04","timestamp":1719968976000,"abstract":"  Automatically locating a bug within a large codebase remains a significant\nchallenge for developers. Existing techniques often struggle with\ngeneralizability and deployment due to their reliance on application-specific\ndata and large model sizes. This paper proposes a novel pre-trained language\nmodel (PLM) based technique for bug localization that transcends project and\nlanguage boundaries. Our approach leverages contrastive learning to enhance the\nrepresentation of bug reports and source code. It then utilizes a novel ranking\napproach that combines commit messages and code segments. Additionally, we\nintroduce a knowledge distillation technique that reduces model size for\npractical deployment without compromising performance.\n  This paper presents several key benefits. By incorporating code segment and\ncommit message analysis alongside traditional file-level examination, our\ntechnique achieves better bug localization accuracy. Furthermore, our model\nexcels at generalizability - trained on code from various projects and\nlanguages, it can effectively identify bugs in unseen codebases. To address\ncomputational limitations, we propose a CPU-compatible solution. In essence,\nproposed work presents a highly effective, generalizable, and efficient bug\nlocalization technique with the potential to real-world deployment.\n","subjects":["Computing Research Repository/Software Engineering","Computing Research Repository/Information Retrieval"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}