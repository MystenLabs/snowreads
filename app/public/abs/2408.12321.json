{"id":"2408.12321","title":"MaVEn: An Effective Multi-granularity Hybrid Visual Encoding Framework\n  for Multimodal Large Language Model","authors":"Chaoya Jiang, Jia Hongrui, Haiyang Xu, Wei Ye, Mengfan Dong, Ming Yan,\n  Ji Zhang, Fei Huang, Shikun Zhang","authorsParsed":[["Jiang","Chaoya",""],["Hongrui","Jia",""],["Xu","Haiyang",""],["Ye","Wei",""],["Dong","Mengfan",""],["Yan","Ming",""],["Zhang","Ji",""],["Huang","Fei",""],["Zhang","Shikun",""]],"versions":[{"version":"v1","created":"Thu, 22 Aug 2024 11:57:16 GMT"},{"version":"v2","created":"Mon, 26 Aug 2024 04:27:54 GMT"}],"updateDate":"2024-08-27","timestamp":1724327836000,"abstract":"  This paper presents MaVEn, an innovative Multi-granularity Visual Encoding\nframework designed to enhance the capabilities of Multimodal Large Language\nModels (MLLMs) in multi-image reasoning. Current MLLMs primarily focus on\nsingle-image visual understanding, limiting their ability to interpret and\nintegrate information across multiple images. MaVEn addresses this limitation\nby combining discrete visual symbol sequences, which abstract coarse-grained\nsemantic concepts, with traditional continuous representation sequences that\nmodel fine-grained features. This dual approach bridges the semantic gap\nbetween visual and textual data, thereby improving the model's ability to\nprocess and interpret information from multiple images effectively.\nAdditionally, we design a dynamic reduction mechanism by for long-sequence\ncontinuous features to enhance multi-image processing efficiency. Experimental\nresults demonstrate that MaVEn significantly enhances MLLMs' understanding in\ncomplex multi-image scenarios, while also improving performance in single-image\ncontexts.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Multimedia"],"license":"http://creativecommons.org/licenses/by/4.0/"}