{"id":"2407.00567","title":"A Contextual Combinatorial Bandit Approach to Negotiation","authors":"Yexin Li and Zhancun Mu and Siyuan Qi","authorsParsed":[["Li","Yexin",""],["Mu","Zhancun",""],["Qi","Siyuan",""]],"versions":[{"version":"v1","created":"Sun, 30 Jun 2024 02:43:15 GMT"}],"updateDate":"2024-07-02","timestamp":1719715395000,"abstract":"  Learning effective negotiation strategies poses two key challenges: the\nexploration-exploitation dilemma and dealing with large action spaces. However,\nthere is an absence of learning-based approaches that effectively address these\nchallenges in negotiation. This paper introduces a comprehensive formulation to\ntackle various negotiation problems. Our approach leverages contextual\ncombinatorial multi-armed bandits, with the bandits resolving the\nexploration-exploitation dilemma, and the combinatorial nature handles large\naction spaces. Building upon this formulation, we introduce NegUCB, a novel\nmethod that also handles common issues such as partial observations and complex\nreward functions in negotiation. NegUCB is contextual and tailored for\nfull-bandit feedback without constraints on the reward functions. Under mild\nassumptions, it ensures a sub-linear regret upper bound. Experiments conducted\non three negotiation tasks demonstrate the superiority of our approach.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}