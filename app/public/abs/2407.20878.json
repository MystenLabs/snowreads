{"id":"2407.20878","title":"S3PET: Semi-supervised Standard-dose PET Image Reconstruction via\n  Dose-aware Token Swap","authors":"Jiaqi Cui, Pinxian Zeng, Yuanyuan Xu, Xi Wu, Jiliu Zhou, Yan Wang","authorsParsed":[["Cui","Jiaqi",""],["Zeng","Pinxian",""],["Xu","Yuanyuan",""],["Wu","Xi",""],["Zhou","Jiliu",""],["Wang","Yan",""]],"versions":[{"version":"v1","created":"Tue, 30 Jul 2024 14:56:06 GMT"}],"updateDate":"2024-07-31","timestamp":1722351366000,"abstract":"  To acquire high-quality positron emission tomography (PET) images while\nreducing the radiation tracer dose, numerous efforts have been devoted to\nreconstructing standard-dose PET (SPET) images from low-dose PET (LPET).\nHowever, the success of current fully-supervised approaches relies on abundant\npaired LPET and SPET images, which are often unavailable in clinic. Moreover,\nthese methods often mix the dose-invariant content with dose level-related\ndose-specific details during reconstruction, resulting in distorted images. To\nalleviate these problems, in this paper, we propose a two-stage Semi-Supervised\nSPET reconstruction framework, namely S3PET, to accommodate the training of\nabundant unpaired and limited paired SPET and LPET images. Our S3PET involves\nan un-supervised pre-training stage (Stage I) to extract representations from\nunpaired images, and a supervised dose-aware reconstruction stage (Stage II) to\nachieve LPET-to-SPET reconstruction by transferring the dose-specific knowledge\nbetween paired images. Specifically, in stage I, two independent dose-specific\nmasked autoencoders (DsMAEs) are adopted to comprehensively understand the\nunpaired SPET and LPET images. Then, in Stage II, the pre-trained DsMAEs are\nfurther finetuned using paired images. To prevent distortions in both content\nand details, we introduce two elaborate modules, i.e., a dose knowledge\ndecouple module to disentangle the respective dose-specific and dose-invariant\nknowledge of LPET and SPET, and a dose-specific knowledge learning module to\ntransfer the dose-specific information from SPET to LPET, thereby achieving\nhigh-quality SPET reconstruction from LPET images. Experiments on two datasets\ndemonstrate that our S3PET achieves state-of-the-art performance quantitatively\nand qualitatively.\n","subjects":["Electrical Engineering and Systems Science/Image and Video Processing","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/"}