{"id":"2408.16913","title":"Analyzing Inference Privacy Risks Through Gradients in Machine Learning","authors":"Zhuohang Li, Andrew Lowy, Jing Liu, Toshiaki Koike-Akino, Kieran\n  Parsons, Bradley Malin, Ye Wang","authorsParsed":[["Li","Zhuohang",""],["Lowy","Andrew",""],["Liu","Jing",""],["Koike-Akino","Toshiaki",""],["Parsons","Kieran",""],["Malin","Bradley",""],["Wang","Ye",""]],"versions":[{"version":"v1","created":"Thu, 29 Aug 2024 21:21:53 GMT"}],"updateDate":"2024-09-02","timestamp":1724966513000,"abstract":"  In distributed learning settings, models are iteratively updated with shared\ngradients computed from potentially sensitive user data. While previous work\nhas studied various privacy risks of sharing gradients, our paper aims to\nprovide a systematic approach to analyze private information leakage from\ngradients. We present a unified game-based framework that encompasses a broad\nrange of attacks including attribute, property, distributional, and user\ndisclosures. We investigate how different uncertainties of the adversary affect\ntheir inferential power via extensive experiments on five datasets across\nvarious data modalities. Our results demonstrate the inefficacy of solely\nrelying on data aggregation to achieve privacy against inference attacks in\ndistributed learning. We further evaluate five types of defenses, namely,\ngradient pruning, signed gradient descent, adversarial perturbations,\nvariational information bottleneck, and differential privacy, under both static\nand adaptive adversary settings. We provide an information-theoretic view for\nanalyzing the effectiveness of these defenses against inference from gradients.\nFinally, we introduce a method for auditing attribute inference privacy,\nimproving the empirical estimation of worst-case privacy through crafting\nadversarial canary records.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Cryptography and Security","Statistics/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}