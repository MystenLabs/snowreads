{"id":"2408.03771","title":"Methodological Explainability Evaluation of an Interpretable Deep\n  Learning Model for Post-Hepatectomy Liver Failure Prediction Incorporating\n  Counterfactual Explanations and Layerwise Relevance Propagation: A\n  Prospective In Silico Trial","authors":"Xian Zhong, Zohaib Salahuddin, Yi Chen, Henry C Woodruff, Haiyi Long,\n  Jianyun Peng, Nuwan Udawatte, Roberto Casale, Ayoub Mokhtari, Xiaoer Zhang,\n  Jiayao Huang, Qingyu Wu, Li Tan, Lili Chen, Dongming Li, Xiaoyan Xie, Manxia\n  Lin, Philippe Lambin","authorsParsed":[["Zhong","Xian",""],["Salahuddin","Zohaib",""],["Chen","Yi",""],["Woodruff","Henry C",""],["Long","Haiyi",""],["Peng","Jianyun",""],["Udawatte","Nuwan",""],["Casale","Roberto",""],["Mokhtari","Ayoub",""],["Zhang","Xiaoer",""],["Huang","Jiayao",""],["Wu","Qingyu",""],["Tan","Li",""],["Chen","Lili",""],["Li","Dongming",""],["Xie","Xiaoyan",""],["Lin","Manxia",""],["Lambin","Philippe",""]],"versions":[{"version":"v1","created":"Wed, 7 Aug 2024 13:47:32 GMT"}],"updateDate":"2024-08-08","timestamp":1723038452000,"abstract":"  Artificial intelligence (AI)-based decision support systems have demonstrated\nvalue in predicting post-hepatectomy liver failure (PHLF) in hepatocellular\ncarcinoma (HCC). However, they often lack transparency, and the impact of model\nexplanations on clinicians' decisions has not been thoroughly evaluated.\nBuilding on prior research, we developed a variational autoencoder-multilayer\nperceptron (VAE-MLP) model for preoperative PHLF prediction. This model\nintegrated counterfactuals and layerwise relevance propagation (LRP) to provide\ninsights into its decision-making mechanism. Additionally, we proposed a\nmethodological framework for evaluating the explainability of AI systems. This\nframework includes qualitative and quantitative assessments of explanations\nagainst recognized biomarkers, usability evaluations, and an in silico clinical\ntrial. Our evaluations demonstrated that the model's explanation correlated\nwith established biomarkers and exhibited high usability at both the case and\nsystem levels. Furthermore, results from the three-track in silico clinical\ntrial showed that clinicians' prediction accuracy and confidence increased when\nAI explanations were provided.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"ncAKa9r72SFfGn6C83kSr_8FPOY5G_1pNN9KQAIgYhY","pdfSize":"12121617"}
