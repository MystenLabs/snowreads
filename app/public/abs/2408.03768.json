{"id":"2408.03768","title":"HDPlanner: Advancing Autonomous Deployments in Unknown Environments\n  through Hierarchical Decision Networks","authors":"Jingsong Liang, Yuhong Cao, Yixiao Ma, Hanqi Zhao, Guillaume\n  Sartoretti","authorsParsed":[["Liang","Jingsong",""],["Cao","Yuhong",""],["Ma","Yixiao",""],["Zhao","Hanqi",""],["Sartoretti","Guillaume",""]],"versions":[{"version":"v1","created":"Wed, 7 Aug 2024 13:38:53 GMT"}],"updateDate":"2024-08-08","timestamp":1723037933000,"abstract":"  In this paper, we introduce HDPlanner, a deep reinforcement learning (DRL)\nbased framework designed to tackle two core and challenging tasks for mobile\nrobots: autonomous exploration and navigation, where the robot must optimize\nits trajectory adaptively to achieve the task objective through continuous\ninteractions in unknown environments. Specifically, HDPlanner relies on novel\nhierarchical attention networks to empower the robot to reason about its belief\nacross multiple spatial scales and sequence collaborative decisions, where our\nnetworks decompose long-term objectives into short-term informative task\nassignments and informative path plannings. We further propose a contrastive\nlearning-based joint optimization to enhance the robustness of HDPlanner. We\nempirically demonstrate that HDPlanner significantly outperforms\nstate-of-the-art conventional and learning-based baselines on an extensive set\nof simulations, including hundreds of test maps and large-scale, complex Gazebo\nenvironments. Notably, HDPlanner achieves real-time planning with travel\ndistances reduced by up to 35.7% compared to exploration benchmarks and by up\nto 16.5% than navigation benchmarks. Furthermore, we validate our approach on\nhardware, where it generates high-quality, adaptive trajectories in both indoor\nand outdoor environments, highlighting its real-world applicability without\nadditional training.\n","subjects":["Computing Research Repository/Robotics"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}