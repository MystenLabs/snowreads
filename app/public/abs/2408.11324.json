{"id":"2408.11324","title":"HITS: High-coverage LLM-based Unit Test Generation via Method Slicing","authors":"Zejun Wang, Kaibo Liu, Ge Li, Zhi Jin","authorsParsed":[["Wang","Zejun",""],["Liu","Kaibo",""],["Li","Ge",""],["Jin","Zhi",""]],"versions":[{"version":"v1","created":"Wed, 21 Aug 2024 04:14:26 GMT"}],"updateDate":"2024-08-22","timestamp":1724213666000,"abstract":"  Large language models (LLMs) have behaved well in generating unit tests for\nJava projects. However, the performance for covering the complex focal methods\nwithin the projects is poor. Complex methods comprise many conditions and\nloops, requiring the test cases to be various enough to cover all lines and\nbranches. However, existing test generation methods with LLMs provide the whole\nmethod-to-test to the LLM without assistance on input analysis. The LLM has\ndifficulty inferring the test inputs to cover all conditions, resulting in\nmissing lines and branches. To tackle the problem, we propose decomposing the\nfocal methods into slices and asking the LLM to generate test cases slice by\nslice. Our method simplifies the analysis scope, making it easier for the LLM\nto cover more lines and branches in each slice. We build a dataset comprising\ncomplex focal methods collected from the projects used by existing\nstate-of-the-art approaches. Our experiment results show that our method\nsignificantly outperforms current test case generation methods with LLMs and\nthe typical SBST method Evosuite regarding both line and branch coverage\nscores.\n","subjects":["Computing Research Repository/Software Engineering"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"xafA251ZTOkcQtaZYFBppmVeCYHWLQiLaO1Q35TFdkI","pdfSize":"747006"}
