{"id":"2408.01817","title":"State-dependent Filtering of the Ring Model","authors":"Jing Yan, Yunxuan Feng, Wei Dai and Yaoyu Zhang","authorsParsed":[["Yan","Jing",""],["Feng","Yunxuan",""],["Dai","Wei",""],["Zhang","Yaoyu",""]],"versions":[{"version":"v1","created":"Sat, 3 Aug 2024 16:22:19 GMT"}],"updateDate":"2024-08-06","timestamp":1722702139000,"abstract":"  Robustness is a measure of functional reliability of a system against\nperturbations. To achieve a good and robust performance, a system must filter\nout external perturbations by its internal priors. These priors are usually\ndistilled in the structure and the states of the system. Biophysical neural\nnetwork are known to be robust but the exact mechanisms are still elusive. In\nthis paper, we probe how orientation-selective neurons organized on a 1-D ring\nnetwork respond to perturbations in the hope of gaining some insights on the\nrobustness of visual system in brain. We analyze the steady-state of the\nrate-based network and prove that the activation state of neurons, rather than\ntheir firing rates, determines how the model respond to perturbations. We then\nidentify specific perturbation patterns that induce the largest responses for\ndifferent configurations of activation states, and find them to be sinusoidal\nor sinusoidal-like while other patterns are largely attenuated. Similar results\nare observed in a spiking ring model. Finally, we remap the perturbations in\norientation back into the 2-D image space using Gabor functions. The resulted\noptimal perturbation patterns mirror adversarial attacks in deep learning that\nexploit the priors of the system. Our results suggest that based on different\nstate configurations, these priors could underlie some of the illusionary\nexperiences as the cost of visual robustness.\n","subjects":["Quantitative Biology/Neurons and Cognition"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/"}