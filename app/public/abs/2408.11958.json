{"id":"2408.11958","title":"CARLA Drone: Monocular 3D Object Detection from a Different Perspective","authors":"Johannes Meier and Luca Scalerandi and Oussema Dhaouadi and Jacques\n  Kaiser and Nikita Araslanov and Daniel Cremers","authorsParsed":[["Meier","Johannes",""],["Scalerandi","Luca",""],["Dhaouadi","Oussema",""],["Kaiser","Jacques",""],["Araslanov","Nikita",""],["Cremers","Daniel",""]],"versions":[{"version":"v1","created":"Wed, 21 Aug 2024 19:25:03 GMT"}],"updateDate":"2024-08-23","timestamp":1724268303000,"abstract":"  Existing techniques for monocular 3D detection have a serious restriction.\nThey tend to perform well only on a limited set of benchmarks, faring well\neither on ego-centric car views or on traffic camera views, but rarely on both.\nTo encourage progress, this work advocates for an extended evaluation of 3D\ndetection frameworks across different camera perspectives. We make two key\ncontributions. First, we introduce the CARLA Drone dataset, CDrone. Simulating\ndrone views, it substantially expands the diversity of camera perspectives in\nexisting benchmarks. Despite its synthetic nature, CDrone represents a\nreal-world challenge. To show this, we confirm that previous techniques\nstruggle to perform well both on CDrone and a real-world 3D drone dataset.\nSecond, we develop an effective data augmentation pipeline called GroundMix.\nIts distinguishing element is the use of the ground for creating 3D-consistent\naugmentation of a training image. GroundMix significantly boosts the detection\naccuracy of a lightweight one-stage detector. In our expanded evaluation, we\nachieve the average precision on par with or substantially higher than the\nprevious state of the art across all tested datasets.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}