{"id":"2407.11933","title":"Fairly Accurate: Optimizing Accuracy Parity in Fair Target-Group\n  Detection","authors":"Soumyajit Gupta, Venelin Kovatchev, Maria De-Arteaga, Matthew Lease","authorsParsed":[["Gupta","Soumyajit",""],["Kovatchev","Venelin",""],["De-Arteaga","Maria",""],["Lease","Matthew",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 17:23:41 GMT"}],"updateDate":"2024-07-17","timestamp":1721150621000,"abstract":"  In algorithmic toxicity detection pipelines, it is important to identify\nwhich demographic group(s) are the subject of a post, a task commonly known as\n\\textit{target (group) detection}. While accurate detection is clearly\nimportant, we further advocate a fairness objective: to provide equal\nprotection to all groups who may be targeted. To this end, we adopt\n\\textit{Accuracy Parity} (AP) -- balanced detection accuracy across groups --\nas our fairness objective. However, in order to align model training with our\nAP fairness objective, we require an equivalent loss function. Moreover, for\ngradient-based models such as neural networks, this loss function needs to be\ndifferentiable. Because no such loss function exists today for AP, we propose\n\\emph{Group Accuracy Parity} (GAP): the first differentiable loss function\nhaving a one-on-one mapping to AP. We empirically show that GAP addresses\ndisparate impact on groups for target detection. Furthermore, because a single\npost often targets multiple groups in practice, we also provide a mathematical\nextension of GAP to larger multi-group settings, something typically requiring\nheuristics in prior work. Our findings show that by optimizing AP, GAP better\nmitigates bias in comparison with other commonly employed loss functions.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}