{"id":"2408.07896","title":"The doctor will polygraph you now: ethical concerns with AI for\n  fact-checking patients","authors":"James Anibal, Jasmine Gunkel, Hannah Huth, Hang Nguyen, Shaheen Awan,\n  Yael Bensoussan, Bradford Wood","authorsParsed":[["Anibal","James",""],["Gunkel","Jasmine",""],["Huth","Hannah",""],["Nguyen","Hang",""],["Awan","Shaheen",""],["Bensoussan","Yael",""],["Wood","Bradford",""]],"versions":[{"version":"v1","created":"Thu, 15 Aug 2024 02:55:30 GMT"}],"updateDate":"2024-08-16","timestamp":1723690530000,"abstract":"  Clinical artificial intelligence (AI) methods have been proposed for\npredicting social behaviors which could be reasonably understood from\npatient-reported data. This raises ethical concerns about respect, privacy, and\npatient awareness/control over how their health data is used. Ethical concerns\nsurrounding clinical AI systems for social behavior verification were divided\ninto three main categories: (1) the use of patient data retrospectively without\ninformed consent for the specific task of verification, (2) the potential for\ninaccuracies or biases within such systems, and (3) the impact on trust in\npatient-provider relationships with the introduction of automated AI systems\nfor fact-checking. Additionally, this report showed the simulated misuse of a\nverification system and identified a potential LLM bias against\npatient-reported information in favor of multimodal data, published literature,\nand the outputs of other AI methods (i.e., AI self-trust). Finally,\nrecommendations were presented for mitigating the risk that AI verification\nsystems will cause harm to patients or undermine the purpose of the healthcare\nsystem.\n","subjects":["Computing Research Repository/Computers and Society"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"vX4k6Fb66K9HJJABC2x_Y2imE6lW4S-90omY2bzO9AA","pdfSize":"194731"}
