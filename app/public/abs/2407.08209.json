{"id":"2407.08209","title":"Enriching Information and Preserving Semantic Consistency in Expanding\n  Curvilinear Object Segmentation Datasets","authors":"Qin Lei, Jiang Zhong, Qizhu Dai","authorsParsed":[["Lei","Qin",""],["Zhong","Jiang",""],["Dai","Qizhu",""]],"versions":[{"version":"v1","created":"Thu, 11 Jul 2024 06:25:26 GMT"}],"updateDate":"2024-07-12","timestamp":1720679126000,"abstract":"  Curvilinear object segmentation plays a crucial role across various\napplications, yet datasets in this domain often suffer from small scale due to\nthe high costs associated with data acquisition and annotation. To address\nthese challenges, this paper introduces a novel approach for expanding\ncurvilinear object segmentation datasets, focusing on enhancing the\ninformativeness of generated data and the consistency between semantic maps and\ngenerated images.\n  Our method enriches synthetic data informativeness by generating curvilinear\nobjects through their multiple textual features. By combining textual features\nfrom each sample in original dataset, we obtain synthetic images that beyond\nthe original dataset's distribution. This initiative necessitated the creation\nof the Curvilinear Object Segmentation based on Text Generation (COSTG)\ndataset. Designed to surpass the limitations of conventional datasets, COSTG\nincorporates not only standard semantic maps but also some textual descriptions\nof curvilinear object features.\n  To ensure consistency between synthetic semantic maps and images, we\nintroduce the Semantic Consistency Preserving ControlNet (SCP ControlNet). This\ninvolves an adaptation of ControlNet with Spatially-Adaptive Normalization\n(SPADE), allowing it to preserve semantic information that would typically be\nwashed away in normalization layers. This modification facilitates more\naccurate semantic image synthesis.\n  Experimental results demonstrate the efficacy of our approach across three\ntypes of curvilinear objects (angiography, crack and retina) and six public\ndatasets (CHUAC, XCAD, DCA1, DRIVE, CHASEDB1 and Crack500). The synthetic data\ngenerated by our method not only expand the dataset, but also effectively\nimproves the performance of other curvilinear object segmentation models.\nSource code and dataset are available at\n\\url{https://github.com/tanlei0/COSTG}.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}