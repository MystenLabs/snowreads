{"id":"2408.10663","title":"REInstruct: Building Instruction Data from Unlabeled Corpus","authors":"Shu Chen, Xinyan Guan, Yaojie Lu, Hongyu Lin, Xianpei Han, Le Sun","authorsParsed":[["Chen","Shu",""],["Guan","Xinyan",""],["Lu","Yaojie",""],["Lin","Hongyu",""],["Han","Xianpei",""],["Sun","Le",""]],"versions":[{"version":"v1","created":"Tue, 20 Aug 2024 09:05:03 GMT"}],"updateDate":"2024-08-21","timestamp":1724144703000,"abstract":"  Manually annotating instruction data for large language models is difficult,\ncostly, and hard to scale. Meanwhile, current automatic annotation methods\ntypically rely on distilling synthetic data from proprietary LLMs, which not\nonly limits the upper bound of the quality of the instruction data but also\nraises potential copyright issues. In this paper, we propose REInstruct, a\nsimple and scalable method to automatically build instruction data from an\nunlabeled corpus without heavy reliance on proprietary LLMs and human\nannotation. Specifically, REInstruct first selects a subset of unlabeled texts\nthat potentially contain well-structured helpful and insightful content and\nthen generates instructions for these texts. To generate accurate and relevant\nresponses for effective and robust training, REInstruct further proposes a\nrewriting-based approach to improve the quality of the generated instruction\ndata. By training Llama-7b on a combination of 3k seed data and 32k synthetic\ndata from REInstruct, fine-tuned model achieves a 65.41\\% win rate on\nAlpacaEval leaderboard against text-davinci-003, outperforming other\nopen-source, non-distilled instruction data construction methods. The code is\npublicly available at \\url{https://github.com/cs32963/REInstruct}.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}