{"id":"2407.05315","title":"Topological Persistence Guided Knowledge Distillation for Wearable\n  Sensor Data","authors":"Eun Som Jeon, Hongjun Choi, Ankita Shukla, Yuan Wang, Hyunglae Lee,\n  Matthew P. Buman, Pavan Turaga","authorsParsed":[["Jeon","Eun Som",""],["Choi","Hongjun",""],["Shukla","Ankita",""],["Wang","Yuan",""],["Lee","Hyunglae",""],["Buman","Matthew P.",""],["Turaga","Pavan",""]],"versions":[{"version":"v1","created":"Sun, 7 Jul 2024 10:08:34 GMT"}],"updateDate":"2024-07-09","timestamp":1720346914000,"abstract":"  Deep learning methods have achieved a lot of success in various applications\ninvolving converting wearable sensor data to actionable health insights. A\ncommon application areas is activity recognition, where deep-learning methods\nstill suffer from limitations such as sensitivity to signal quality, sensor\ncharacteristic variations, and variability between subjects. To mitigate these\nissues, robust features obtained by topological data analysis (TDA) have been\nsuggested as a potential solution. However, there are two significant obstacles\nto using topological features in deep learning: (1) large computational load to\nextract topological features using TDA, and (2) different signal\nrepresentations obtained from deep learning and TDA which makes fusion\ndifficult. In this paper, to enable integration of the strengths of topological\nmethods in deep-learning for time-series data, we propose to use two teacher\nnetworks, one trained on the raw time-series data, and another trained on\npersistence images generated by TDA methods. The distilled student model\nutilizes only the raw time-series data at test-time. This approach addresses\nboth issues. The use of KD with multiple teachers utilizes complementary\ninformation, and results in a compact model with strong supervisory features\nand an integrated richer representation. To assimilate desirable information\nfrom different modalities, we design new constraints, including orthogonality\nimposed on feature correlation maps for improving feature expressiveness and\nallowing the student to easily learn from the teacher. Also, we apply an\nannealing strategy in KD for fast saturation and better accommodation from\ndifferent features, while the knowledge gap between the teachers and student is\nreduced. Finally, a robust student model is distilled, which uses only the\ntime-series data as an input, while implicitly preserving topological features.\n","subjects":["Electrical Engineering and Systems Science/Signal Processing","Computing Research Repository/Machine Learning","Mathematics/Algebraic Topology"],"license":"http://creativecommons.org/licenses/by/4.0/"}