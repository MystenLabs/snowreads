{"id":"2408.08332","title":"TurboEdit: Instant text-based image editing","authors":"Zongze Wu, Nicholas Kolkin, Jonathan Brandt, Richard Zhang, Eli\n  Shechtman","authorsParsed":[["Wu","Zongze",""],["Kolkin","Nicholas",""],["Brandt","Jonathan",""],["Zhang","Richard",""],["Shechtman","Eli",""]],"versions":[{"version":"v1","created":"Wed, 14 Aug 2024 18:02:24 GMT"}],"updateDate":"2024-08-19","timestamp":1723658544000,"abstract":"  We address the challenges of precise image inversion and disentangled image\nediting in the context of few-step diffusion models. We introduce an encoder\nbased iterative inversion technique. The inversion network is conditioned on\nthe input image and the reconstructed image from the previous step, allowing\nfor correction of the next reconstruction towards the input image. We\ndemonstrate that disentangled controls can be easily achieved in the few-step\ndiffusion model by conditioning on an (automatically generated) detailed text\nprompt. To manipulate the inverted image, we freeze the noise maps and modify\none attribute in the text prompt (either manually or via instruction based\nediting driven by an LLM), resulting in the generation of a new image similar\nto the input image with only one attribute changed. It can further control the\nediting strength and accept instructive text prompt. Our approach facilitates\nrealistic text-guided image edits in real-time, requiring only 8 number of\nfunctional evaluations (NFEs) in inversion (one-time cost) and 4 NFEs per edit.\nOur method is not only fast, but also significantly outperforms\nstate-of-the-art multi-step diffusion editing techniques.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}