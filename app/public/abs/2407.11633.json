{"id":"2407.11633","title":"Scaling Diffusion Transformers to 16 Billion Parameters","authors":"Zhengcong Fei, Mingyuan Fan, Changqian Yu, Debang Li, Junshi Huang","authorsParsed":[["Fei","Zhengcong",""],["Fan","Mingyuan",""],["Yu","Changqian",""],["Li","Debang",""],["Huang","Junshi",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 11:55:23 GMT"},{"version":"v2","created":"Fri, 6 Sep 2024 06:00:42 GMT"},{"version":"v3","created":"Mon, 9 Sep 2024 02:17:12 GMT"}],"updateDate":"2024-09-10","timestamp":1721130923000,"abstract":"  In this paper, we present DiT-MoE, a sparse version of the diffusion\nTransformer, that is scalable and competitive with dense networks while\nexhibiting highly optimized inference. The DiT-MoE includes two simple designs:\nshared expert routing and expert-level balance loss, thereby capturing common\nknowledge and reducing redundancy among the different routed experts. When\napplied to conditional image generation, a deep analysis of experts\nspecialization gains some interesting observations: (i) Expert selection shows\npreference with spatial position and denoising time step, while insensitive\nwith different class-conditional information; (ii) As the MoE layers go deeper,\nthe selection of experts gradually shifts from specific spacial position to\ndispersion and balance. (iii) Expert specialization tends to be more\nconcentrated at the early time step and then gradually uniform after half. We\nattribute it to the diffusion process that first models the low-frequency\nspatial information and then high-frequency complex information. Based on the\nabove guidance, a series of DiT-MoE experimentally achieves performance on par\nwith dense networks yet requires much less computational load during inference.\nMore encouragingly, we demonstrate the potential of DiT-MoE with synthesized\nimage data, scaling diffusion model at a 16.5B parameter that attains a new\nSoTA FID-50K score of 1.80 in 512$\\times$512 resolution settings. The project\npage: https://github.com/feizc/DiT-MoE.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}