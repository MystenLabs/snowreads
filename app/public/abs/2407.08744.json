{"id":"2407.08744","title":"Toward Efficient Deep Spiking Neuron Networks:A Survey On Compression","authors":"Hui Xie, Ge Yang and Wenjuan Gao","authorsParsed":[["Xie","Hui",""],["Yang","Ge",""],["Gao","Wenjuan",""]],"versions":[{"version":"v1","created":"Mon, 3 Jun 2024 15:11:54 GMT"}],"updateDate":"2024-07-15","timestamp":1717427514000,"abstract":"  With the rapid development of deep learning, Deep Spiking Neural Networks\n(DSNNs) have emerged as promising due to their unique spike event processing\nand asynchronous computation. When deployed on neuromorphic chips, DSNNs offer\nsignificant power advantages over Deep Artificial Neural Networks (DANNs) and\neliminate time and energy consuming multiplications due to the binary nature of\nspikes (0 or 1). Additionally, DSNNs excel in processing temporal information,\nmaking them potentially superior for handling temporal data compared to DANNs.\nHowever, their deep network structure and numerous parameters result in high\ncomputational costs and energy consumption, limiting real-life deployment. To\nenhance DSNNs efficiency, researchers have adapted methods from DANNs, such as\npruning, quantization, and knowledge distillation, and developed specific\ntechniques like reducing spike firing and pruning time steps. While previous\nsurveys have covered DSNNs algorithms, hardware deployment, and general\noverviews, focused research on DSNNs compression and efficiency has been\nlacking. This survey addresses this gap by concentrating on efficient DSNNs and\ntheir compression methods. It begins with an exploration of DSNNs' biological\nbackground and computational units, highlighting differences from DANNs. It\nthen delves into various compression methods, including pruning, quantization,\nknowledge distillation, and reducing spike firing, and concludes with\nsuggestions for future research directions.\n","subjects":["Computing Research Repository/Neural and Evolutionary Computing","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"slJOh2W7PLiUymZ14CV4h1bJyyUh5ywvE7Y1lmBa6PI","pdfSize":"178290"}
