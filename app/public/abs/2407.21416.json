{"id":"2407.21416","title":"VIPeR: Visual Incremental Place Recognition with Adaptive Mining and\n  Lifelong Learning","authors":"Yuhang Ming, Minyang Xu, Xingrui Yang, Weicai Ye, Weihan Wang, Yong\n  Peng, Weichen Dai, Wanzeng Kong","authorsParsed":[["Ming","Yuhang",""],["Xu","Minyang",""],["Yang","Xingrui",""],["Ye","Weicai",""],["Wang","Weihan",""],["Peng","Yong",""],["Dai","Weichen",""],["Kong","Wanzeng",""]],"versions":[{"version":"v1","created":"Wed, 31 Jul 2024 08:04:32 GMT"}],"updateDate":"2024-08-01","timestamp":1722413072000,"abstract":"  Visual place recognition (VPR) is an essential component of many autonomous\nand augmented/virtual reality systems. It enables the systems to robustly\nlocalize themselves in large-scale environments. Existing VPR methods\ndemonstrate attractive performance at the cost of heavy pre-training and\nlimited generalizability. When deployed in unseen environments, these methods\nexhibit significant performance drops. Targeting this issue, we present VIPeR,\na novel approach for visual incremental place recognition with the ability to\nadapt to new environments while retaining the performance of previous\nenvironments. We first introduce an adaptive mining strategy that balances the\nperformance within a single environment and the generalizability across\nmultiple environments. Then, to prevent catastrophic forgetting in lifelong\nlearning, we draw inspiration from human memory systems and design a novel\nmemory bank for our VIPeR. Our memory bank contains a sensory memory, a working\nmemory and a long-term memory, with the first two focusing on the current\nenvironment and the last one for all previously visited environments.\nAdditionally, we propose a probabilistic knowledge distillation to explicitly\nsafeguard the previously learned knowledge. We evaluate our proposed VIPeR on\nthree large-scale datasets, namely Oxford Robotcar, Nordland, and TartanAir.\nFor comparison, we first set a baseline performance with naive finetuning.\nThen, several more recent lifelong learning methods are compared. Our VIPeR\nachieves better performance in almost all aspects with the biggest improvement\nof 13.65% in average performance.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Robotics"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}