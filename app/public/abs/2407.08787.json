{"id":"2407.08787","title":"Data Adaptive Traceback for Vision-Language Foundation Models in Image\n  Classification","authors":"Wenshuo Peng, Kaipeng Zhang, Yue Yang, Hao Zhang, Yu Qiao","authorsParsed":[["Peng","Wenshuo",""],["Zhang","Kaipeng",""],["Yang","Yue",""],["Zhang","Hao",""],["Qiao","Yu",""]],"versions":[{"version":"v1","created":"Thu, 11 Jul 2024 18:01:58 GMT"}],"updateDate":"2024-07-15","timestamp":1720720918000,"abstract":"  Vision-language foundation models have been incredibly successful in a wide\nrange of downstream computer vision tasks using adaptation methods. However,\ndue to the high cost of obtaining pre-training datasets, pairs with weak\nimage-text correlation in the data exist in large numbers. We call them\nweak-paired samples. Due to the limitations of these weak-paired samples, the\npre-training model are unable to mine all the knowledge from pre-training data.\nThe existing adaptation methods do not consider the missing knowledge, which\nmay lead to crucial task-related knowledge for the downstream tasks being\nignored. To address this issue, we propose a new adaptation framework called\nData Adaptive Traceback (DAT). Specifically, we utilize a zero-shot-based\nmethod to extract the most downstream task-related subset of the pre-training\ndata to enable the downstream tasks. Furthermore, we adopt a pseudo-label-based\nsemi-supervised technique to reuse the pre-training images and a\nvision-language contrastive learning method to address the confirmation bias\nissue in semi-supervised learning. We conduct extensive experiments that show\nour proposed DAT approach meaningfully improves various benchmark datasets\nperformance over traditional adaptation methods by simply.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}