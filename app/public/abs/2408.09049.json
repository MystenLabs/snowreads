{"id":"2408.09049","title":"Language Models Show Stable Value Orientations Across Diverse Role-Plays","authors":"Bruce W. Lee, Yeongheon Lee, Hyunsoo Cho","authorsParsed":[["Lee","Bruce W.",""],["Lee","Yeongheon",""],["Cho","Hyunsoo",""]],"versions":[{"version":"v1","created":"Fri, 16 Aug 2024 23:24:10 GMT"}],"updateDate":"2024-08-20","timestamp":1723850650000,"abstract":"  We demonstrate that large language models (LLMs) exhibit consistent value\norientations despite adopting diverse personas, revealing a persistent inertia\nin their responses that remains stable across the variety of roles they are\nprompted to assume. To systematically explore this phenomenon, we introduce the\nrole-play-at-scale methodology, which involves prompting LLMs with randomized,\ndiverse personas and analyzing the macroscopic trend of their responses. Unlike\nprevious works that simply feed these questions to LLMs as if testing human\nsubjects, our role-play-at-scale methodology diagnoses inherent tendencies in a\nsystematic and scalable manner by: (1) prompting the model to act in different\nrandom personas and (2) asking the same question multiple times for each random\npersona. This approach reveals consistent patterns in LLM responses across\ndiverse role-play scenarios, indicating deeply encoded inherent tendencies. Our\nfindings contribute to the discourse on value alignment in foundation models\nand demonstrate the efficacy of role-play-at-scale as a diagnostic tool for\nuncovering encoded biases in LLMs.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Human-Computer Interaction"],"license":"http://creativecommons.org/licenses/by-sa/4.0/","blobId":"HlUadSJfFQ6s0cWYAohma7XcEstRtJ-CCrJazXVNL28","pdfSize":"7556485"}
