{"id":"2407.01376","title":"Badllama 3: removing safety finetuning from Llama 3 in minutes","authors":"Dmitrii Volkov","authorsParsed":[["Volkov","Dmitrii",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 15:29:45 GMT"}],"updateDate":"2024-07-02","timestamp":1719847785000,"abstract":"  We show that extensive LLM safety fine-tuning is easily subverted when an\nattacker has access to model weights. We evaluate three state-of-the-art\nfine-tuning methods-QLoRA, ReFT, and Ortho-and show how algorithmic advances\nenable constant jailbreaking performance with cuts in FLOPs and optimisation\npower. We strip safety fine-tuning from Llama 3 8B in one minute and Llama 3\n70B in 30 minutes on a single GPU, and sketch ways to reduce this further.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language","Computing Research Repository/Cryptography and Security"],"license":"http://creativecommons.org/licenses/by/4.0/"}