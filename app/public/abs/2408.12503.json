{"id":"2408.12503","title":"The Russian-focused embedders' exploration: ruMTEB benchmark and Russian\n  embedding model design","authors":"Artem Snegirev, Maria Tikhonova, Anna Maksimova, Alena Fenogenova,\n  Alexander Abramov","authorsParsed":[["Snegirev","Artem",""],["Tikhonova","Maria",""],["Maksimova","Anna",""],["Fenogenova","Alena",""],["Abramov","Alexander",""]],"versions":[{"version":"v1","created":"Thu, 22 Aug 2024 15:53:23 GMT"}],"updateDate":"2024-08-23","timestamp":1724342003000,"abstract":"  Embedding models play a crucial role in Natural Language Processing (NLP) by\ncreating text embeddings used in various tasks such as information retrieval\nand assessing semantic text similarity. This paper focuses on research related\nto embedding models in the Russian language. It introduces a new\nRussian-focused embedding model called ru-en-RoSBERTa and the ruMTEB benchmark,\nthe Russian version extending the Massive Text Embedding Benchmark (MTEB). Our\nbenchmark includes seven categories of tasks, such as semantic textual\nsimilarity, text classification, reranking, and retrieval. The research also\nassesses a representative set of Russian and multilingual models on the\nproposed benchmark. The findings indicate that the new model achieves results\nthat are on par with state-of-the-art models in Russian. We release the model\nru-en-RoSBERTa, and the ruMTEB framework comes with open-source code,\nintegration into the original framework and a public leaderboard.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/"}