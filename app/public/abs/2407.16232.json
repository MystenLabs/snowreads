{"id":"2407.16232","title":"Channel-Partitioned Windowed Attention And Frequency Learning for Single\n  Image Super-Resolution","authors":"Dinh Phu Tran, Dao Duy Hung, Daeyoung Kim","authorsParsed":[["Tran","Dinh Phu",""],["Hung","Dao Duy",""],["Kim","Daeyoung",""]],"versions":[{"version":"v1","created":"Tue, 23 Jul 2024 07:17:10 GMT"},{"version":"v2","created":"Tue, 27 Aug 2024 07:31:37 GMT"}],"updateDate":"2024-08-28","timestamp":1721719030000,"abstract":"  Recently, window-based attention methods have shown great potential for\ncomputer vision tasks, particularly in Single Image Super-Resolution (SISR).\nHowever, it may fall short in capturing long-range dependencies and\nrelationships between distant tokens. Additionally, we find that learning on\nspatial domain does not convey the frequency content of the image, which is a\ncrucial aspect in SISR. To tackle these issues, we propose a new\nChannel-Partitioned Attention Transformer (CPAT) to better capture long-range\ndependencies by sequentially expanding windows along the height and width of\nfeature maps. In addition, we propose a novel Spatial-Frequency Interaction\nModule (SFIM), which incorporates information from spatial and frequency\ndomains to provide a more comprehensive information from feature maps. This\nincludes information about the frequency content and enhances the receptive\nfield across the entire image. Experimental findings show the effectiveness of\nour proposed modules and architecture. In particular, CPAT surpasses current\nstate-of-the-art methods by up to 0.31dB at x2 SR on Urban100.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"5iALIH-UBgPW7L9uEQ86vvAkXTNTmueGetzmAAWrxac","pdfSize":"6504813","objectId":"0x599edef16ae6742efb546e7e90e1b7618dec56e59419dc082321e79a45c9abb5","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
