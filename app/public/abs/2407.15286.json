{"id":"2407.15286","title":"Intrinsic Self-correction for Enhanced Morality: An Analysis of Internal\n  Mechanisms and the Superficial Hypothesis","authors":"Guangliang Liu, Haitao Mao, Jiliang Tang, Kristen Marie Johnson","authorsParsed":[["Liu","Guangliang",""],["Mao","Haitao",""],["Tang","Jiliang",""],["Johnson","Kristen Marie",""]],"versions":[{"version":"v1","created":"Sun, 21 Jul 2024 22:50:11 GMT"},{"version":"v2","created":"Mon, 12 Aug 2024 18:42:22 GMT"}],"updateDate":"2024-08-14","timestamp":1721602211000,"abstract":"  Large Language Models (LLMs) are capable of producing content that\nperpetuates stereotypes, discrimination, and toxicity. The recently proposed\nmoral self-correction is a computationally efficient method for reducing\nharmful content in the responses of LLMs. However, the process of how injecting\nself-correction instructions can modify the behavior of LLMs remains\nunder-explored. In this paper, we explore the effectiveness of moral\nself-correction by answering three research questions: (1) In what scenarios\ndoes moral self-correction work? (2) What are the internal mechanisms of LLMs,\ne.g., hidden states, that are influenced by moral self-correction instructions?\n(3) Is intrinsic moral self-correction actually superficial? We argue that\nself-correction can help LLMs find a shortcut to more morally correct output,\nrather than truly reducing the immorality stored in hidden states. Through\nempirical investigation with tasks of language generation and multi-choice\nquestion answering, we conclude: (i) LLMs exhibit good performance across both\ntasks, and self-correction instructions are particularly beneficial when the\ncorrect answer is already top-ranked; (ii) The morality levels in intermediate\nhidden states are strong indicators as to whether one instruction would be more\neffective than another; (iii) Based on our analysis of intermediate hidden\nstates and task case studies of self-correction behaviors, we are first to\npropose the hypothesis that intrinsic moral self-correction is in fact\nsuperficial.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}