{"id":"2408.12888","title":"Accelerated Markov Chain Monte Carlo Using Adaptive Weighting Scheme","authors":"Yanbo Wang, Wenyu Chen, and Shimin Shan","authorsParsed":[["Wang","Yanbo",""],["Chen","Wenyu",""],["Shan","Shimin",""]],"versions":[{"version":"v1","created":"Fri, 23 Aug 2024 07:45:32 GMT"}],"updateDate":"2024-08-26","timestamp":1724399132000,"abstract":"  Gibbs sampling is one of the most commonly used Markov Chain Monte Carlo\n(MCMC) algorithms due to its simplicity and efficiency. It cycles through the\nlatent variables, sampling each one from its distribution conditional on the\ncurrent values of all the other variables. Conventional Gibbs sampling is based\non the systematic scan (with a deterministic order of variables). In contrast,\nin recent years, Gibbs sampling with random scan has shown its advantage in\nsome scenarios. However, almost all the analyses of Gibbs sampling with the\nrandom scan are based on uniform selection of variables. In this paper, we\nfocus on a random scan Gibbs sampling method that selects each latent variable\nnon-uniformly. Firstly, we show that this non-uniform scan Gibbs sampling\nleaves the target posterior distribution invariant. Then we explore how to\ndetermine the selection probability for latent variables. In particular, we\nconstruct an objective as a function of the selection probability and solve the\nconstrained optimization problem. We further derive an analytic solution of the\nselection probability, which can be estimated easily. Our algorithm relies on\nthe simple intuition that choosing the variable updates according to their\nmarginal probabilities enhances the mixing time of the Markov chain. Finally,\nwe validate the effectiveness of the proposed Gibbs sampler by conducting a set\nof experiments on real-world applications.\n","subjects":["Computing Research Repository/Machine Learning","Statistics/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}