{"id":"2408.06286","title":"Mipmap-GS: Let Gaussians Deform with Scale-specific Mipmap for\n  Anti-aliasing Rendering","authors":"Jiameng Li, Yue Shi, Jiezhang Cao, Bingbing Ni, Wenjun Zhang, Kai\n  Zhang, Luc Van Gool","authorsParsed":[["Li","Jiameng",""],["Shi","Yue",""],["Cao","Jiezhang",""],["Ni","Bingbing",""],["Zhang","Wenjun",""],["Zhang","Kai",""],["Van Gool","Luc",""]],"versions":[{"version":"v1","created":"Mon, 12 Aug 2024 16:49:22 GMT"}],"updateDate":"2024-08-13","timestamp":1723481362000,"abstract":"  3D Gaussian Splatting (3DGS) has attracted great attention in novel view\nsynthesis because of its superior rendering efficiency and high fidelity.\nHowever, the trained Gaussians suffer from severe zooming degradation due to\nnon-adjustable representation derived from single-scale training. Though some\nmethods attempt to tackle this problem via post-processing techniques such as\nselective rendering or filtering techniques towards primitives, the\nscale-specific information is not involved in Gaussians. In this paper, we\npropose a unified optimization method to make Gaussians adaptive for arbitrary\nscales by self-adjusting the primitive properties (e.g., color, shape and size)\nand distribution (e.g., position). Inspired by the mipmap technique, we design\npseudo ground-truth for the target scale and propose a scale-consistency\nguidance loss to inject scale information into 3D Gaussians. Our method is a\nplug-in module, applicable for any 3DGS models to solve the zoom-in and\nzoom-out aliasing. Extensive experiments demonstrate the effectiveness of our\nmethod. Notably, our method outperforms 3DGS in PSNR by an average of 9.25 dB\nfor zoom-in and 10.40 dB for zoom-out on the NeRF Synthetic dataset.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}