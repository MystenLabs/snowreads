{"id":"2407.01826","title":"Statistical Analysis of ZFP: Understanding Bias","authors":"Alyson Fox and Peter Lindstrom","authorsParsed":[["Fox","Alyson",""],["Lindstrom","Peter",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 21:57:29 GMT"}],"updateDate":"2024-07-03","timestamp":1719871049000,"abstract":"  The amount of data generated and gathered in scientific simulations and data\ncollection applications is continuously growing, putting mounting pressure on\nstorage and bandwidth concerns. A means of reducing such issues is data\ncompression; however, lossless data compression is typically ineffective when\napplied to floating-point data. Thus, users tend to apply a lossy data\ncompressor, which allows for small deviations from the original data. It is\nessential to understand how the error from lossy compression impacts the\naccuracy of the data analytics. Thus, we must analyze not only the compression\nproperties but the error as well. In this paper, we provide a statistical\nanalysis of the error caused by ZFP compression, a state-of-the-art, lossy\ncompression algorithm explicitly designed for floating-point data. We show that\nthe error is indeed biased and propose simple modifications to the algorithm to\nneutralize the bias and further reduce the resulting error.\n","subjects":["Mathematics/Numerical Analysis","Computing Research Repository/Numerical Analysis"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}