{"id":"2407.19402","title":"NVC-1B: A Large Neural Video Coding Model","authors":"Xihua Sheng, Chuanbo Tang, Li Li, Dong Liu, Feng Wu","authorsParsed":[["Sheng","Xihua",""],["Tang","Chuanbo",""],["Li","Li",""],["Liu","Dong",""],["Wu","Feng",""]],"versions":[{"version":"v1","created":"Sun, 28 Jul 2024 05:12:22 GMT"}],"updateDate":"2024-07-30","timestamp":1722143542000,"abstract":"  The emerging large models have achieved notable progress in the fields of\nnatural language processing and computer vision. However, large models for\nneural video coding are still unexplored. In this paper, we try to explore how\nto build a large neural video coding model. Based on a small baseline model, we\ngradually scale up the model sizes of its different coding parts, including the\nmotion encoder-decoder, motion entropy model, contextual encoder-decoder,\ncontextual entropy model, and temporal context mining module, and analyze the\ninfluence of model sizes on video compression performance. Then, we explore to\nuse different architectures, including CNN, mixed CNN-Transformer, and\nTransformer architectures, to implement the neural video coding model and\nanalyze the influence of model architectures on video compression performance.\nBased on our exploration results, we design the first neural video coding model\nwith more than 1 billion parameters -- NVC-1B. Experimental results show that\nour proposed large model achieves a significant video compression performance\nimprovement over the small baseline model, and represents the state-of-the-art\ncompression efficiency. We anticipate large models may bring up the video\ncoding technologies to the next level.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Electrical Engineering and Systems Science/Image and Video Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}