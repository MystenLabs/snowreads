{"id":"2408.10573","title":"Putting People in LLMs' Shoes: Generating Better Answers via Question\n  Rewriter","authors":"Junhao Chen and Bowen Wang and Zhouqiang jiang and Yuta Nakashima","authorsParsed":[["Chen","Junhao",""],["Wang","Bowen",""],["jiang","Zhouqiang",""],["Nakashima","Yuta",""]],"versions":[{"version":"v1","created":"Tue, 20 Aug 2024 06:24:47 GMT"}],"updateDate":"2024-08-21","timestamp":1724135087000,"abstract":"  Large Language Models (LLMs) have demonstrated significant capabilities,\nparticularly in the domain of question answering (QA). However, their\neffectiveness in QA is often undermined by the vagueness of user questions. To\naddress this issue, we introduce single-round instance-level prompt\noptimization, referred to as question rewriter. By enhancing the\nintelligibility of human questions for black-box LLMs, our question rewriter\nimproves the quality of generated answers. The rewriter is optimized using\ndirect preference optimization based on feedback collected from automatic\ncriteria for evaluating generated answers; therefore, its training does not\nrequire costly human annotations. The experiments across multiple black-box\nLLMs and long-form question answering (LFQA) datasets demonstrate the efficacy\nof our method. This paper provides a practical framework for training question\nrewriters and sets a precedent for future explorations in prompt optimization\nwithin LFQA tasks. Code is available at\n\\url{https://github.com/3244we/Question-Rewriter}.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/"}