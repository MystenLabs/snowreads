{"id":"2407.00985","title":"Object Segmentation from Open-Vocabulary Manipulation Instructions Based\n  on Optimal Transport Polygon Matching with Multimodal Foundation Models","authors":"Takayuki Nishimura, Katsuyuki Kuyo, Motonari Kambara and Komei Sugiura","authorsParsed":[["Nishimura","Takayuki",""],["Kuyo","Katsuyuki",""],["Kambara","Motonari",""],["Sugiura","Komei",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 05:48:48 GMT"}],"updateDate":"2024-07-02","timestamp":1719812928000,"abstract":"  We consider the task of generating segmentation masks for the target object\nfrom an object manipulation instruction, which allows users to give open\nvocabulary instructions to domestic service robots. Conventional segmentation\ngeneration approaches often fail to account for objects outside the camera's\nfield of view and cases in which the order of vertices differs but still\nrepresents the same polygon, which leads to erroneous mask generation. In this\nstudy, we propose a novel method that generates segmentation masks from open\nvocabulary instructions. We implement a novel loss function using optimal\ntransport to prevent significant loss where the order of vertices differs but\nstill represents the same polygon. To evaluate our approach, we constructed a\nnew dataset based on the REVERIE dataset and Matterport3D dataset. The results\ndemonstrated the effectiveness of the proposed method compared with existing\nmask generation methods. Remarkably, our best model achieved a +16.32%\nimprovement on the dataset compared with a representative polygon-based method.\n","subjects":["Computing Research Repository/Robotics","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}