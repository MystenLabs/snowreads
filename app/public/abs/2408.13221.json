{"id":"2408.13221","title":"Protecting against simultaneous data poisoning attacks","authors":"Neel Alex, Shoaib Ahmed Siddiqui, Amartya Sanyal, David Krueger","authorsParsed":[["Alex","Neel",""],["Siddiqui","Shoaib Ahmed",""],["Sanyal","Amartya",""],["Krueger","David",""]],"versions":[{"version":"v1","created":"Fri, 23 Aug 2024 16:57:27 GMT"}],"updateDate":"2024-08-26","timestamp":1724432247000,"abstract":"  Current backdoor defense methods are evaluated against a single attack at a\ntime. This is unrealistic, as powerful machine learning systems are trained on\nlarge datasets scraped from the internet, which may be attacked multiple times\nby one or more attackers. We demonstrate that simultaneously executed data\npoisoning attacks can effectively install multiple backdoors in a single model\nwithout substantially degrading clean accuracy. Furthermore, we show that\nexisting backdoor defense methods do not effectively prevent attacks in this\nsetting. Finally, we leverage insights into the nature of backdoor attacks to\ndevelop a new defense, BaDLoss, that is effective in the multi-attack setting.\nWith minimal clean accuracy degradation, BaDLoss attains an average attack\nsuccess rate in the multi-attack setting of 7.98% in CIFAR-10 and 10.29% in\nGTSRB, compared to the average of other defenses at 64.48% and 84.28%\nrespectively.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"t2Op0yV4Zz4kzYYUwW3jg2FCzlxTMyT26fiI1X3DoUk","pdfSize":"2735247"}
