{"id":"2407.20003","title":"On the Effects of Irrelevant Variables in Treatment Effect Estimation\n  with Deep Disentanglement","authors":"Ahmad Saeed Khan, Erik Schaffernicht, Johannes Andreas Stork","authorsParsed":[["Khan","Ahmad Saeed",""],["Schaffernicht","Erik",""],["Stork","Johannes Andreas",""]],"versions":[{"version":"v1","created":"Mon, 29 Jul 2024 13:34:34 GMT"},{"version":"v2","created":"Mon, 26 Aug 2024 08:10:56 GMT"}],"updateDate":"2024-08-27","timestamp":1722260074000,"abstract":"  Estimating treatment effects from observational data is paramount in\nhealthcare, education, and economics, but current deep disentanglement-based\nmethods to address selection bias are insufficiently handling irrelevant\nvariables. We demonstrate in experiments that this leads to prediction errors.\nWe disentangle pre-treatment variables with a deep embedding method and\nexplicitly identify and represent irrelevant variables, additionally to\ninstrumental, confounding and adjustment latent factors. To this end, we\nintroduce a reconstruction objective and create an embedding space for\nirrelevant variables using an attached autoencoder. Instead of relying on\nserendipitous suppression of irrelevant variables as in previous deep\ndisentanglement approaches, we explicitly force irrelevant variables into this\nembedding space and employ orthogonalization to prevent irrelevant information\nfrom leaking into the latent space representations of the other factors. Our\nexperiments with synthetic and real-world benchmark datasets show that we can\nbetter identify irrelevant variables and more precisely predict treatment\neffects than previous methods, while prediction quality degrades less when\nadditional irrelevant variables are introduced.\n","subjects":["Computing Research Repository/Machine Learning","Statistics/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}