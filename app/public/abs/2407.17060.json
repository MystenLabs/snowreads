{"id":"2407.17060","title":"High Efficiency Image Compression for Large Visual-Language Models","authors":"Binzhe Li, Shurun Wang, Shiqi Wang, Yan Ye","authorsParsed":[["Li","Binzhe",""],["Wang","Shurun",""],["Wang","Shiqi",""],["Ye","Yan",""]],"versions":[{"version":"v1","created":"Wed, 24 Jul 2024 07:37:12 GMT"}],"updateDate":"2024-07-25","timestamp":1721806632000,"abstract":"  In recent years, large visual language models (LVLMs) have shown impressive\nperformance and promising generalization capability in multi-modal tasks, thus\nreplacing humans as receivers of visual information in various application\nscenarios. In this paper, we pioneer to propose a variable bitrate image\ncompression framework consisting of a pre-editing module and an end-to-end\ncodec to achieve promising rate-accuracy performance for different LVLMs. In\nparticular, instead of optimizing an adaptive pre-editing network towards a\nparticular task or several representative tasks, we propose a new optimization\nstrategy tailored for LVLMs, which is designed based on the representation and\ndiscrimination capability with token-level distortion and rank. The pre-editing\nmodule and the variable bitrate end-to-end image codec are jointly trained by\nthe losses based on semantic tokens of the large model, which introduce\nenhanced generalization capability for various data and tasks. {Experimental\nresults demonstrate that the proposed framework could efficiently achieve much\nbetter rate-accuracy performance compared to the state-of-the-art coding\nstandard, Versatile Video Coding.} Meanwhile, experiments with multi-modal\ntasks have revealed the robustness and generalization capability of the\nproposed framework.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language","Electrical Engineering and Systems Science/Image and Video Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}