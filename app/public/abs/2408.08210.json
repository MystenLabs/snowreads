{"id":"2408.08210","title":"Does Reasoning Emerge? Examining the Probabilities of Causation in Large\n  Language Models","authors":"Javier Gonz\\'alez and Aditya V. Nori","authorsParsed":[["Gonz√°lez","Javier",""],["Nori","Aditya V.",""]],"versions":[{"version":"v1","created":"Thu, 15 Aug 2024 15:19:11 GMT"}],"updateDate":"2024-08-16","timestamp":1723735151000,"abstract":"  Recent advances in AI have been significantly driven by the capabilities of\nlarge language models (LLMs) to solve complex problems in ways that resemble\nhuman thinking. However, there is an ongoing debate about the extent to which\nLLMs are capable of actual reasoning. Central to this debate are two key\nprobabilistic concepts that are essential for connecting causes to their\neffects: the probability of necessity (PN) and the probability of sufficiency\n(PS). This paper introduces a framework that is both theoretical and practical,\naimed at assessing how effectively LLMs are able to replicate real-world\nreasoning mechanisms using these probabilistic measures. By viewing LLMs as\nabstract machines that process information through a natural language\ninterface, we examine the conditions under which it is possible to compute\nsuitable approximations of PN and PS. Our research marks an important step\ntowards gaining a deeper understanding of when LLMs are capable of reasoning,\nas illustrated by a series of math examples.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"xkdShUwFROiU5hPElguVAd_9jbC2hrNYvY_tAkRM6PY","pdfSize":"6823684"}
