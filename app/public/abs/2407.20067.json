{"id":"2407.20067","title":"xAI-Drop: Don't Use What You Cannot Explain","authors":"Vincenzo Marco De Luca, Antonio Longa, Andrea Passerini, Pietro Li\\`o","authorsParsed":[["De Luca","Vincenzo Marco",""],["Longa","Antonio",""],["Passerini","Andrea",""],["Li√≤","Pietro",""]],"versions":[{"version":"v1","created":"Mon, 29 Jul 2024 14:53:45 GMT"}],"updateDate":"2024-07-30","timestamp":1722264825000,"abstract":"  Graph Neural Networks (GNNs) have emerged as the predominant paradigm for\nlearning from graph-structured data, offering a wide range of applications from\nsocial network analysis to bioinformatics. Despite their versatility, GNNs face\nchallenges such as oversmoothing, lack of generalization and poor\ninterpretability, which hinder their wider adoption and reliability in critical\napplications. Dropping has emerged as an effective paradigm for reducing noise\nduring training and improving robustness of GNNs. However, existing approaches\noften rely on random or heuristic-based selection criteria, lacking a\nprincipled method to identify and exclude nodes that contribute to noise and\nover-complexity in the model. In this work, we argue that explainability should\nbe a key indicator of a model's robustness throughout its training phase. To\nthis end, we introduce xAI-Drop, a novel topological-level dropping regularizer\nthat leverages explainability to pinpoint noisy network elements to be excluded\nfrom the GNN propagation mechanism. An empirical evaluation on diverse\nreal-world datasets demonstrates that our method outperforms current\nstate-of-the-art dropping approaches in accuracy, effectively reduces\nover-smoothing, and improves explanation quality.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"OTljb9ajjfm6Ih3vwBHszbxDh6GaqiNBF9C-86c1M_I","pdfSize":"710981"}
