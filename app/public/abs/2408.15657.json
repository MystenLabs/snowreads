{"id":"2408.15657","title":"TeFF: Tracking-enhanced Forgetting-free Few-shot 3D LiDAR Semantic\n  Segmentation","authors":"Junbao Zhou, Jilin Mei, Pengze Wu, Liang Chen, Fangzhou Zhao, Xijun\n  Zhao, Yu Hu","authorsParsed":[["Zhou","Junbao",""],["Mei","Jilin",""],["Wu","Pengze",""],["Chen","Liang",""],["Zhao","Fangzhou",""],["Zhao","Xijun",""],["Hu","Yu",""]],"versions":[{"version":"v1","created":"Wed, 28 Aug 2024 09:18:36 GMT"}],"updateDate":"2024-08-29","timestamp":1724836716000,"abstract":"  In autonomous driving, 3D LiDAR plays a crucial role in understanding the\nvehicle's surroundings. However, the newly emerged, unannotated objects\npresents few-shot learning problem for semantic segmentation. This paper\naddresses the limitations of current few-shot semantic segmentation by\nexploiting the temporal continuity of LiDAR data. Employing a tracking model to\ngenerate pseudo-ground-truths from a sequence of LiDAR frames, our method\nsignificantly augments the dataset, enhancing the model's ability to learn on\nnovel classes. However, this approach introduces a data imbalance biased to\nnovel data that presents a new challenge of catastrophic forgetting. To\nmitigate this, we incorporate LoRA, a technique that reduces the number of\ntrainable parameters, thereby preserving the model's performance on base\nclasses while improving its adaptability to novel classes. This work represents\na significant step forward in few-shot 3D LiDAR semantic segmentation for\nautonomous driving. Our code is available at\nhttps://github.com/junbao-zhou/Track-no-forgetting.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Robotics"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"clFxA5FM9kwGWh21fBc3gaXSr__C7OnpSx8o7jUZK6U","pdfSize":"1177650"}
