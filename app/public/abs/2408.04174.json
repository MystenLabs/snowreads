{"id":"2408.04174","title":"wav2graph: A Framework for Supervised Learning Knowledge Graph from\n  Speech","authors":"Khai Le-Duc, Quy-Anh Dang, Tan-Hanh Pham, Truong-Son Hy","authorsParsed":[["Le-Duc","Khai",""],["Dang","Quy-Anh",""],["Pham","Tan-Hanh",""],["Hy","Truong-Son",""]],"versions":[{"version":"v1","created":"Thu, 8 Aug 2024 02:36:04 GMT"}],"updateDate":"2024-08-09","timestamp":1723084564000,"abstract":"  Knowledge graphs (KGs) enhance the performance of large language models\n(LLMs) and search engines by providing structured, interconnected data that\nimproves reasoning and context-awareness. However, KGs only focus on text data,\nthereby neglecting other modalities such as speech. In this work, we introduce\nwav2graph, the first framework for supervised learning knowledge graph from\nspeech data. Our pipeline are straightforward: (1) constructing a KG based on\ntranscribed spoken utterances and a named entity database, (2) converting KG\ninto embedding vectors, and (3) training graph neural networks (GNNs) for node\nclassification and link prediction tasks. Through extensive experiments\nconducted in inductive and transductive learning contexts using\nstate-of-the-art GNN models, we provide baseline results and error analysis for\nnode classification and link prediction tasks on human transcripts and\nautomatic speech recognition (ASR) transcripts, including evaluations using\nboth encoder-based and decoder-based node embeddings, as well as monolingual\nand multilingual acoustic pre-trained models. All related code, data, and\nmodels are published online.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Information Retrieval","Computing Research Repository/Machine Learning","Computing Research Repository/Sound","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by/4.0/"}