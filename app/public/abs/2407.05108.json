{"id":"2407.05108","title":"The Role of Depth, Width, and Tree Size in Expressiveness of Deep Forest","authors":"Shen-Huan Lyu, Jin-Hui Wu, Qin-Cheng Zheng, Baoliu Ye","authorsParsed":[["Lyu","Shen-Huan",""],["Wu","Jin-Hui",""],["Zheng","Qin-Cheng",""],["Ye","Baoliu",""]],"versions":[{"version":"v1","created":"Sat, 6 Jul 2024 15:32:54 GMT"}],"updateDate":"2024-07-10","timestamp":1720279974000,"abstract":"  Random forests are classical ensemble algorithms that construct multiple\nrandomized decision trees and aggregate their predictions using naive\naveraging. \\citet{zhou2019deep} further propose a deep forest algorithm with\nmulti-layer forests, which outperforms random forests in various tasks. The\nperformance of deep forests is related to three hyperparameters in practice:\ndepth, width, and tree size, but little has been known about its theoretical\nexplanation. This work provides the first upper and lower bounds on the\napproximation complexity of deep forests concerning the three hyperparameters.\nOur results confirm the distinctive role of depth, which can exponentially\nenhance the expressiveness of deep forests compared with width and tree size.\nExperiments confirm the theoretical findings.\n","subjects":["Computing Research Repository/Machine Learning","Statistics/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}