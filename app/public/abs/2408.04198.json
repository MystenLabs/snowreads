{"id":"2408.04198","title":"F1tenth Autonomous Racing With Offline Reinforcement Learning Methods","authors":"Prajwal Koirala and Cody Fleming","authorsParsed":[["Koirala","Prajwal",""],["Fleming","Cody",""]],"versions":[{"version":"v1","created":"Thu, 8 Aug 2024 03:49:22 GMT"}],"updateDate":"2024-08-09","timestamp":1723088962000,"abstract":"  Autonomous racing serves as a critical platform for evaluating automated\ndriving systems and enhancing vehicle mobility intelligence. This work\ninvestigates offline reinforcement learning methods to train agents within the\ndynamic F1tenth racing environment. The study begins by exploring the\nchallenges of online training in the Austria race track environment, where\nagents consistently fail to complete the laps. Consequently, this research\npivots towards an offline strategy, leveraging `expert' demonstration dataset\nto facilitate agent training. A waypoint-based suboptimal controller is\ndeveloped to gather data with successful lap episodes. This data is then\nemployed to train offline learning-based algorithms, with a subsequent analysis\nof the agents' cross-track performance, evaluating their zero-shot\ntransferability from seen to unseen scenarios and their capacity to adapt to\nchanges in environment dynamics. Beyond mere algorithm benchmarking in\nautonomous racing scenarios, this study also introduces and describes the\nmachinery of our return-conditioned decision tree-based policy, comparing its\nperformance with methods that employ fully connected neural networks,\nTransformers, and Diffusion Policies and highlighting some insights into method\nselection for training autonomous agents in driving interactions.\n","subjects":["Computing Research Repository/Robotics","Computing Research Repository/Systems and Control","Electrical Engineering and Systems Science/Systems and Control"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}