{"id":"2408.08628","title":"A survey on secure decentralized optimization and learning","authors":"Changxin Liu, Nicola Bastianello, Wei Huo, Yang Shi, Karl H. Johansson","authorsParsed":[["Liu","Changxin",""],["Bastianello","Nicola",""],["Huo","Wei",""],["Shi","Yang",""],["Johansson","Karl H.",""]],"versions":[{"version":"v1","created":"Fri, 16 Aug 2024 09:42:19 GMT"}],"updateDate":"2024-08-19","timestamp":1723801339000,"abstract":"  Decentralized optimization has become a standard paradigm for solving\nlarge-scale decision-making problems and training large machine learning models\nwithout centralizing data. However, this paradigm introduces new privacy and\nsecurity risks, with malicious agents potentially able to infer private data or\nimpair the model accuracy. Over the past decade, significant advancements have\nbeen made in developing secure decentralized optimization and learning\nframeworks and algorithms. This survey provides a comprehensive tutorial on\nthese advancements. We begin with the fundamentals of decentralized\noptimization and learning, highlighting centralized aggregation and distributed\nconsensus as key modules exposed to security risks in federated and distributed\noptimization, respectively. Next, we focus on privacy-preserving algorithms,\ndetailing three cryptographic tools and their integration into decentralized\noptimization and learning systems. Additionally, we examine resilient\nalgorithms, exploring the design and analysis of resilient aggregation and\nconsensus protocols that support these systems. We conclude the survey by\ndiscussing current trends and potential future directions.\n","subjects":["Computing Research Repository/Machine Learning","Mathematics/Optimization and Control"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}