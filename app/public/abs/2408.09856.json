{"id":"2408.09856","title":"TeamLoRA: Boosting Low-Rank Adaptation with Expert Collaboration and\n  Competition","authors":"Tianwei Lin, Jiang Liu, Wenqiao Zhang, Zhaocheng Li, Yang Dai, Haoyuan\n  Li, Zhelun Yu, Wanggui He, Juncheng Li, Hao Jiang, Siliang Tang, Yueting\n  Zhuang","authorsParsed":[["Lin","Tianwei",""],["Liu","Jiang",""],["Zhang","Wenqiao",""],["Li","Zhaocheng",""],["Dai","Yang",""],["Li","Haoyuan",""],["Yu","Zhelun",""],["He","Wanggui",""],["Li","Juncheng",""],["Jiang","Hao",""],["Tang","Siliang",""],["Zhuang","Yueting",""]],"versions":[{"version":"v1","created":"Mon, 19 Aug 2024 09:58:53 GMT"}],"updateDate":"2024-08-20","timestamp":1724061533000,"abstract":"  While Parameter-Efficient Fine-Tuning (PEFT) methods like LoRA have\neffectively addressed GPU memory constraints during fine-tuning, their\nperformance often falls short, especially in multidimensional task scenarios.\nTo address this issue, one straightforward solution is to introduce\ntask-specific LoRA modules as domain experts, leveraging the modeling of\nmultiple experts' capabilities and thus enhancing the general capability of\nmulti-task learning. Despite promising, these additional components often add\ncomplexity to the training and inference process, contravening the efficient\ncharacterization of PEFT designed for. Considering this, we introduce an\ninnovative PEFT method, TeamLoRA, consisting of a collaboration and competition\nmodule for experts, and thus achieving the right balance of effectiveness and\nefficiency: (i) For collaboration, a novel knowledge-sharing and -organizing\nmechanism is devised to appropriately reduce the scale of matrix operations,\nthereby boosting the training and inference speed. (ii) For competition, we\npropose leveraging a game-theoretic interaction mechanism for experts,\nencouraging experts to transfer their domain-specific knowledge while facing\ndiverse downstream tasks, and thus enhancing the performance. By doing so,\nTeamLoRA elegantly connects the experts as a \"Team\" with internal collaboration\nand competition, enabling a faster and more accurate PEFT paradigm for\nmulti-task learning. To validate the superiority of TeamLoRA, we curate a\ncomprehensive multi-task evaluation(CME) benchmark to thoroughly assess the\ncapability of multi-task learning. Experiments conducted on our CME and other\nbenchmarks indicate the effectiveness and efficiency of TeamLoRA. Our project\nis available at https://github.com/Lin-Tianwei/TeamLoRA.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}