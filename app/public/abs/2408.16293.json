{"id":"2408.16293","title":"Physics of Language Models: Part 2.2, How to Learn From Mistakes on\n  Grade-School Math Problems","authors":"Tian Ye, Zicheng Xu, Yuanzhi Li, Zeyuan Allen-Zhu","authorsParsed":[["Ye","Tian",""],["Xu","Zicheng",""],["Li","Yuanzhi",""],["Allen-Zhu","Zeyuan",""]],"versions":[{"version":"v1","created":"Thu, 29 Aug 2024 06:49:20 GMT"}],"updateDate":"2024-08-30","timestamp":1724914160000,"abstract":"  Language models have demonstrated remarkable performance in solving reasoning\ntasks; however, even the strongest models still occasionally make reasoning\nmistakes. Recently, there has been active research aimed at improving reasoning\naccuracy, particularly by using pretrained language models to \"self-correct\"\ntheir mistakes via multi-round prompting. In this paper, we follow this line of\nwork but focus on understanding the usefulness of incorporating\n\"error-correction\" data directly into the pretraining stage. This data consists\nof erroneous solution steps immediately followed by their corrections. Using a\nsynthetic math dataset, we show promising results: this type of pretrain data\ncan help language models achieve higher reasoning accuracy directly (i.e.,\nthrough simple auto-regression, without multi-round prompting) compared to\npretraining on the same amount of error-free data. We also delve into many\ndetails, such as (1) how this approach differs from beam search, (2) how such\ndata can be prepared, (3) whether masking is needed on the erroneous tokens,\n(4) the amount of error required, (5) whether such data can be deferred to the\nfine-tuning stage, and many others.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}