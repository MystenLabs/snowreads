{"id":"2407.07998","title":"What's the score? Automated Denoising Score Matching for Nonlinear\n  Diffusions","authors":"Raghav Singhal, Mark Goldstein, Rajesh Ranganath","authorsParsed":[["Singhal","Raghav",""],["Goldstein","Mark",""],["Ranganath","Rajesh",""]],"versions":[{"version":"v1","created":"Wed, 10 Jul 2024 19:02:19 GMT"}],"updateDate":"2024-07-12","timestamp":1720638139000,"abstract":"  Reversing a diffusion process by learning its score forms the heart of\ndiffusion-based generative modeling and for estimating properties of scientific\nsystems. The diffusion processes that are tractable center on linear processes\nwith a Gaussian stationary distribution. This limits the kinds of models that\ncan be built to those that target a Gaussian prior or more generally limits the\nkinds of problems that can be generically solved to those that have\nconditionally linear score functions. In this work, we introduce a family of\ntractable denoising score matching objectives, called local-DSM, built using\nlocal increments of the diffusion process. We show how local-DSM melded with\nTaylor expansions enables automated training and score estimation with\nnonlinear diffusion processes. To demonstrate these ideas, we use automated-DSM\nto train generative models using non-Gaussian priors on challenging low\ndimensional distributions and the CIFAR10 image dataset. Additionally, we use\nthe automated-DSM to learn the scores for nonlinear processes studied in\nstatistical physics.\n","subjects":["Computing Research Repository/Machine Learning","Statistics/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}