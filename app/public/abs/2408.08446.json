{"id":"2408.08446","title":"Lifelong Reinforcement Learning via Neuromodulation","authors":"Sebastian Lee, Samuel Liebana Garcia, Claudia Clopath, Will Dabney","authorsParsed":[["Lee","Sebastian",""],["Garcia","Samuel Liebana",""],["Clopath","Claudia",""],["Dabney","Will",""]],"versions":[{"version":"v1","created":"Thu, 15 Aug 2024 22:53:35 GMT"}],"updateDate":"2024-08-19","timestamp":1723762415000,"abstract":"  Navigating multiple tasks$\\unicode{x2014}$for instance in succession as in\ncontinual or lifelong learning, or in distributions as in meta or multi-task\nlearning$\\unicode{x2014}$requires some notion of adaptation. Evolution over\ntimescales of millennia has imbued humans and other animals with highly\neffective adaptive learning and decision-making strategies. Central to these\nfunctions are so-called neuromodulatory systems. In this work we introduce an\nabstract framework for integrating theories and evidence from neuroscience and\nthe cognitive sciences into the design of adaptive artificial reinforcement\nlearning algorithms. We give a concrete instance of this framework built on\nliterature surrounding the neuromodulators Acetylcholine (ACh) and\nNoradrenaline (NA), and empirically validate the effectiveness of the resulting\nadaptive algorithm in a non-stationary multi-armed bandit problem. We conclude\nwith a theory-based experiment proposal providing an avenue to link our\nframework back to efforts in experimental neuroscience.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}