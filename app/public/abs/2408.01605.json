{"id":"2408.01605","title":"CYBERSECEVAL 3: Advancing the Evaluation of Cybersecurity Risks and\n  Capabilities in Large Language Models","authors":"Shengye Wan, Cyrus Nikolaidis, Daniel Song, David Molnar, James\n  Crnkovich, Jayson Grace, Manish Bhatt, Sahana Chennabasappa, Spencer Whitman,\n  Stephanie Ding, Vlad Ionescu, Yue Li, Joshua Saxe","authorsParsed":[["Wan","Shengye",""],["Nikolaidis","Cyrus",""],["Song","Daniel",""],["Molnar","David",""],["Crnkovich","James",""],["Grace","Jayson",""],["Bhatt","Manish",""],["Chennabasappa","Sahana",""],["Whitman","Spencer",""],["Ding","Stephanie",""],["Ionescu","Vlad",""],["Li","Yue",""],["Saxe","Joshua",""]],"versions":[{"version":"v1","created":"Fri, 2 Aug 2024 23:47:27 GMT"},{"version":"v2","created":"Fri, 6 Sep 2024 18:17:07 GMT"}],"updateDate":"2024-09-10","timestamp":1722642447000,"abstract":"  We are releasing a new suite of security benchmarks for LLMs, CYBERSECEVAL 3,\nto continue the conversation on empirically measuring LLM cybersecurity risks\nand capabilities. CYBERSECEVAL 3 assesses 8 different risks across two broad\ncategories: risk to third parties, and risk to application developers and end\nusers. Compared to previous work, we add new areas focused on offensive\nsecurity capabilities: automated social engineering, scaling manual offensive\ncyber operations, and autonomous offensive cyber operations. In this paper we\ndiscuss applying these benchmarks to the Llama 3 models and a suite of\ncontemporaneous state-of-the-art LLMs, enabling us to contextualize risks both\nwith and without mitigations in place.\n","subjects":["Computing Research Repository/Cryptography and Security","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"HXDrvU0lFqECkkUKlfWBDDNLrvDT1X6LytIbuQ-JhYA","pdfSize":"1305433","txDigest":"6bZWoH1TBtF9VmYsvcoh1kkJkz6DJ2YP93hzpuaT3sEc","endEpoch":"1","status":"CERTIFIED"}
