{"id":"2407.08333","title":"SR-Mamba: Effective Surgical Phase Recognition with State Space Model","authors":"Rui Cao, Jiangliu Wang, Yun-Hui Liu","authorsParsed":[["Cao","Rui",""],["Wang","Jiangliu",""],["Liu","Yun-Hui",""]],"versions":[{"version":"v1","created":"Thu, 11 Jul 2024 09:34:31 GMT"}],"updateDate":"2024-07-12","timestamp":1720690471000,"abstract":"  Surgical phase recognition is crucial for enhancing the efficiency and safety\nof computer-assisted interventions. One of the fundamental challenges involves\nmodeling the long-distance temporal relationships present in surgical videos.\nInspired by the recent success of Mamba, a state space model with linear\nscalability in sequence length, this paper presents SR-Mamba, a novel\nattention-free model specifically tailored to meet the challenges of surgical\nphase recognition. In SR-Mamba, we leverage a bidirectional Mamba decoder to\neffectively model the temporal context in overlong sequences. Moreover, the\nefficient optimization of the proposed Mamba decoder facilitates single-step\nneural network training, eliminating the need for separate training steps as in\nprevious works. This single-step training approach not only simplifies the\ntraining process but also ensures higher accuracy, even with a lighter spatial\nfeature extractor. Our SR-Mamba establishes a new benchmark in surgical video\nanalysis by demonstrating state-of-the-art performance on the Cholec80 and\nCATARACTS Challenge datasets. The code is accessible at\nhttps://github.com/rcao-hk/SR-Mamba.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}