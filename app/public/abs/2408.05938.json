{"id":"2408.05938","title":"Deep Geometric Moments Promote Shape Consistency in Text-to-3D\n  Generation","authors":"Utkarsh Nath, Rajeev Goel, Eun Som Jeon, Changhoon Kim, Kyle Min,\n  Yezhou Yang, Yingzhen Yang, Pavan Turaga","authorsParsed":[["Nath","Utkarsh",""],["Goel","Rajeev",""],["Jeon","Eun Som",""],["Kim","Changhoon",""],["Min","Kyle",""],["Yang","Yezhou",""],["Yang","Yingzhen",""],["Turaga","Pavan",""]],"versions":[{"version":"v1","created":"Mon, 12 Aug 2024 06:25:44 GMT"}],"updateDate":"2024-08-13","timestamp":1723443944000,"abstract":"  To address the data scarcity associated with 3D assets, 2D-lifting techniques\nsuch as Score Distillation Sampling (SDS) have become a widely adopted practice\nin text-to-3D generation pipelines. However, the diffusion models used in these\ntechniques are prone to viewpoint bias and thus lead to geometric\ninconsistencies such as the Janus problem. To counter this, we introduce MT3D,\na text-to-3D generative model that leverages a high-fidelity 3D object to\novercome viewpoint bias and explicitly infuse geometric understanding into the\ngeneration pipeline. Firstly, we employ depth maps derived from a high-quality\n3D model as control signals to guarantee that the generated 2D images preserve\nthe fundamental shape and structure, thereby reducing the inherent viewpoint\nbias. Next, we utilize deep geometric moments to ensure geometric consistency\nin the 3D representation explicitly. By incorporating geometric details from a\n3D asset, MT3D enables the creation of diverse and geometrically consistent\nobjects, thereby improving the quality and usability of our 3D representations.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/publicdomain/zero/1.0/"}