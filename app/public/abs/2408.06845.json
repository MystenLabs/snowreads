{"id":"2408.06845","title":"DracoGPT: Extracting Visualization Design Preferences from Large\n  Language Models","authors":"Huichen Will Wang, Mitchell Gordon, Leilani Battle, Jeffrey Heer","authorsParsed":[["Wang","Huichen Will",""],["Gordon","Mitchell",""],["Battle","Leilani",""],["Heer","Jeffrey",""]],"versions":[{"version":"v1","created":"Tue, 13 Aug 2024 12:11:47 GMT"}],"updateDate":"2024-08-14","timestamp":1723551107000,"abstract":"  Trained on vast corpora, Large Language Models (LLMs) have the potential to\nencode visualization design knowledge and best practices. However, if they fail\nto do so, they might provide unreliable visualization recommendations. What\nvisualization design preferences, then, have LLMs learned? We contribute\nDracoGPT, a method for extracting, modeling, and assessing visualization design\npreferences from LLMs. To assess varied tasks, we develop two\npipelines--DracoGPT-Rank and DracoGPT-Recommend--to model LLMs prompted to\neither rank or recommend visual encoding specifications. We use Draco as a\nshared knowledge base in which to represent LLM design preferences and compare\nthem to best practices from empirical research. We demonstrate that DracoGPT\ncan accurately model the preferences expressed by LLMs, enabling analysis in\nterms of Draco design constraints. Across a suite of backing LLMs, we find that\nDracoGPT-Rank and DracoGPT-Recommend moderately agree with each other, but both\nsubstantially diverge from guidelines drawn from human subjects experiments.\nFuture work can build on our approach to expand Draco's knowledge base to model\na richer set of preferences and to provide a robust and cost-effective stand-in\nfor LLMs.\n","subjects":["Computing Research Repository/Human-Computer Interaction"],"license":"http://creativecommons.org/licenses/by/4.0/"}