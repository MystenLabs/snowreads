{"id":"2407.07504","title":"Pan-cancer Histopathology WSI Pre-training with Position-aware Masked\n  Autoencoder","authors":"Kun Wu, Zhiguo Jiang, Kunming Tang, Jun Shi, Fengying Xie, Wei Wang,\n  Haibo Wu, and Yushan Zheng","authorsParsed":[["Wu","Kun",""],["Jiang","Zhiguo",""],["Tang","Kunming",""],["Shi","Jun",""],["Xie","Fengying",""],["Wang","Wei",""],["Wu","Haibo",""],["Zheng","Yushan",""]],"versions":[{"version":"v1","created":"Wed, 10 Jul 2024 09:42:41 GMT"},{"version":"v2","created":"Mon, 15 Jul 2024 12:15:50 GMT"}],"updateDate":"2024-07-16","timestamp":1720604561000,"abstract":"  Large-scale pre-training models have promoted the development of\nhistopathology image analysis. However, existing self-supervised methods for\nhistopathology images focus on learning patch features, while there is still a\nlack of available pre-training models for WSI-level feature learning. In this\npaper, we propose a novel self-supervised learning framework for pan-cancer\nWSI-level representation pre-training with the designed position-aware masked\nautoencoder (PAMA). Meanwhile, we propose the position-aware cross-attention\n(PACA) module with a kernel reorientation (KRO) strategy and an anchor dropout\n(AD) mechanism. The KRO strategy can capture the complete semantic structure\nand eliminate ambiguity in WSIs, and the AD contributes to enhancing the\nrobustness and generalization of the model. We evaluated our method on 6\nlarge-scale datasets from multiple organs for pan-cancer classification tasks.\nThe results have demonstrated the effectiveness of PAMA in generalized and\ndiscriminative WSI representation learning and pan-cancer WSI pre-training. The\nproposed method was also compared with 7 WSI analysis methods. The experimental\nresults have indicated that our proposed PAMA is superior to the\nstate-of-the-art methods.The code and checkpoints are available at\nhttps://github.com/WkEEn/PAMA.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}