{"id":"2407.06937","title":"HumanRefiner: Benchmarking Abnormal Human Generation and Refining with\n  Coarse-to-fine Pose-Reversible Guidance","authors":"Guian Fang, Wenbiao Yan, Yuanfan Guo, Jianhua Han, Zutao Jiang, Hang\n  Xu, Shengcai Liao, Xiaodan Liang","authorsParsed":[["Fang","Guian",""],["Yan","Wenbiao",""],["Guo","Yuanfan",""],["Han","Jianhua",""],["Jiang","Zutao",""],["Xu","Hang",""],["Liao","Shengcai",""],["Liang","Xiaodan",""]],"versions":[{"version":"v1","created":"Tue, 9 Jul 2024 15:14:41 GMT"}],"updateDate":"2024-07-10","timestamp":1720538081000,"abstract":"  Text-to-image diffusion models have significantly advanced in conditional\nimage generation. However, these models usually struggle with accurately\nrendering images featuring humans, resulting in distorted limbs and other\nanomalies. This issue primarily stems from the insufficient recognition and\nevaluation of limb qualities in diffusion models. To address this issue, we\nintroduce AbHuman, the first large-scale synthesized human benchmark focusing\non anatomical anomalies. This benchmark consists of 56K synthesized human\nimages, each annotated with detailed, bounding-box level labels identifying\n147K human anomalies in 18 different categories. Based on this, the recognition\nof human anomalies can be established, which in turn enhances image generation\nthrough traditional techniques such as negative prompting and guidance. To\nfurther boost the improvement, we propose HumanRefiner, a novel plug-and-play\napproach for the coarse-to-fine refinement of human anomalies in text-to-image\ngeneration. Specifically, HumanRefiner utilizes a self-diagnostic procedure to\ndetect and correct issues related to both coarse-grained abnormal human poses\nand fine-grained anomaly levels, facilitating pose-reversible diffusion\ngeneration. Experimental results on the AbHuman benchmark demonstrate that\nHumanRefiner significantly reduces generative discrepancies, achieving a 2.9x\nimprovement in limb quality compared to the state-of-the-art open-source\ngenerator SDXL and a 1.4x improvement over DALL-E 3 in human evaluations. Our\ndata and code are available at https://github.com/Enderfga/HumanRefiner.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}