{"id":"2407.15840","title":"QueST: Self-Supervised Skill Abstractions for Learning Continuous\n  Control","authors":"Atharva Mete, Haotian Xue, Albert Wilcox, Yongxin Chen, Animesh Garg","authorsParsed":[["Mete","Atharva",""],["Xue","Haotian",""],["Wilcox","Albert",""],["Chen","Yongxin",""],["Garg","Animesh",""]],"versions":[{"version":"v1","created":"Mon, 22 Jul 2024 17:57:59 GMT"},{"version":"v2","created":"Tue, 23 Jul 2024 03:24:12 GMT"},{"version":"v3","created":"Wed, 11 Sep 2024 13:02:48 GMT"}],"updateDate":"2024-09-12","timestamp":1721671079000,"abstract":"  Generalization capabilities, or rather a lack thereof, is one of the most\nimportant unsolved problems in the field of robot learning, and while several\nlarge scale efforts have set out to tackle this problem, unsolved it remains.\nIn this paper, we hypothesize that learning temporal action abstractions using\nlatent variable models (LVMs), which learn to map data to a compressed latent\nspace and back, is a promising direction towards low-level skills that can\nreadily be used for new tasks. Although several works have attempted to show\nthis, they have generally been limited by architectures that do not faithfully\ncapture shareable representations. To address this we present Quantized Skill\nTransformer (QueST), which learns a larger and more flexible latent encoding\nthat is more capable of modeling the breadth of low-level skills necessary for\na variety of tasks. To make use of this extra flexibility, QueST imparts causal\ninductive bias from the action sequence data into the latent space, leading to\nmore semantically useful and transferable representations. We compare to\nstate-of-the-art imitation learning and LVM baselines and see that QueST's\narchitecture leads to strong performance on several multitask and few-shot\nlearning benchmarks. Further results and videos are available at\nhttps://quest-model.github.io/\n","subjects":["Computing Research Repository/Robotics"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"AQNzVXZyCOE7ctvGzBNY7Clp33-RARtgu69GWPd4nwE","pdfSize":"3439679","objectId":"0x8a40676ecba02c4086270e55677a2747d62b2557081605cb6c268ae6de3abadd","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
