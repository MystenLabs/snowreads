{"id":"2407.11596","title":"HyperAggregation: Aggregating over Graph Edges with Hypernetworks","authors":"Nicolas Lell, Ansgar Scherp","authorsParsed":[["Lell","Nicolas",""],["Scherp","Ansgar",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 10:52:03 GMT"}],"updateDate":"2024-07-17","timestamp":1721127123000,"abstract":"  HyperAggregation is a hypernetwork-based aggregation function for Graph\nNeural Networks. It uses a hypernetwork to dynamically generate weights in the\nsize of the current neighborhood, which are then used to aggregate this\nneighborhood. This aggregation with the generated weights is done like an\nMLP-Mixer channel mixing over variable-sized vertex neighborhoods. We\ndemonstrate HyperAggregation in two models, GraphHyperMixer is a model based on\nMLP-Mixer while GraphHyperConv is derived from a GCN but with a\nhypernetwork-based aggregation function. We perform experiments on diverse\nbenchmark datasets for the vertex classification, graph classification, and\ngraph regression tasks. The results show that HyperAggregation can be\neffectively used for homophilic and heterophilic datasets in both inductive and\ntransductive settings. GraphHyperConv performs better than GraphHyperMixer and\nis especially strong in the transductive setting. On the heterophilic dataset\nRoman-Empire it reaches a new state of the art. On the graph-level tasks our\nmodels perform in line with similarly sized models. Ablation studies\ninvestigate the robustness against various hyperparameter choices. The\nimplementation of HyperAggregation as well code to reproduce all experiments is\navailable under https://github.com/Foisunt/HyperAggregation .\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}