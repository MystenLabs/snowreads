{"id":"2407.10768","title":"ISMRNN: An Implicitly Segmented RNN Method with Mamba for Long-Term Time\n  Series Forecasting","authors":"GaoXiang Zhao and Li Zhou and XiaoQiang Wang","authorsParsed":[["Zhao","GaoXiang",""],["Zhou","Li",""],["Wang","XiaoQiang",""]],"versions":[{"version":"v1","created":"Mon, 15 Jul 2024 14:50:15 GMT"},{"version":"v2","created":"Mon, 22 Jul 2024 10:26:41 GMT"},{"version":"v3","created":"Mon, 29 Jul 2024 12:19:10 GMT"},{"version":"v4","created":"Tue, 30 Jul 2024 07:06:05 GMT"},{"version":"v5","created":"Sun, 4 Aug 2024 07:53:03 GMT"}],"updateDate":"2024-08-06","timestamp":1721055015000,"abstract":"  Long time series forecasting aims to utilize historical information to\nforecast future states over extended horizons. Traditional RNN-based series\nforecasting methods struggle to effectively address long-term dependencies and\ngradient issues in long time series problems. Recently, SegRNN has emerged as a\nleading RNN-based model tailored for long-term series forecasting,\ndemonstrating state-of-the-art performance while maintaining a streamlined\narchitecture through innovative segmentation and parallel decoding techniques.\nNevertheless, SegRNN has several limitations: its fixed segmentation disrupts\ndata continuity and fails to effectively leverage information across different\nsegments, the segmentation strategy employed by SegRNN does not fundamentally\naddress the issue of information loss within the recurrent structure. To\naddress these issues, we propose the ISMRNN method with three key enhancements:\nwe introduce an implicit segmentation structure to decompose the time series\nand map it to segmented hidden states, resulting in denser information exchange\nduring the segmentation phase. Additionally, we incorporate residual structures\nin the encoding layer to mitigate information loss within the recurrent\nstructure. To extract information more effectively, we further integrate the\nMamba architecture to enhance time series information extraction. Experiments\non several real-world long time series forecasting datasets demonstrate that\nour model surpasses the performance of current state-of-the-art models.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}