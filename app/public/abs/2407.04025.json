{"id":"2407.04025","title":"Efficient optimization of ODE neuron models using gradient descent","authors":"Ilenna Simone Jones and Konrad Paul Kording","authorsParsed":[["Jones","Ilenna Simone",""],["Kording","Konrad Paul",""]],"versions":[{"version":"v1","created":"Thu, 4 Jul 2024 16:10:27 GMT"},{"version":"v2","created":"Sat, 20 Jul 2024 19:49:09 GMT"}],"updateDate":"2024-07-23","timestamp":1720109427000,"abstract":"  Neuroscientists fit morphologically and biophysically detailed neuron\nsimulations to physiological data, often using evolutionary algorithms.\nHowever, such gradient-free approaches are computationally expensive, making\nconvergence slow when neuron models have many parameters. Here we introduce a\ngradient-based algorithm using differentiable ODE solvers that scales well to\nhigh-dimensional problems. GPUs make parallel simulations fast and gradient\ncalculations make optimization efficient. We verify the utility of our approach\noptimizing neuron models with active dendrites with heterogeneously distributed\nion channel densities. We find that individually stimulating and recording all\ndendritic compartments makes such model parameters identifiable. Identification\nbreaks down gracefully as fewer stimulation and recording sites are given.\nDifferentiable neuron models, which should be added to popular neuron\nsimulation packages, promise a new era of optimizable neuron models with many\nfree parameters, a key feature of real neurons.\n","subjects":["Quantitative Biology/Neurons and Cognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}