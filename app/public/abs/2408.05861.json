{"id":"2408.05861","title":"Leveraging Knowledge Graph-Based Human-Like Memory Systems to Solve\n  Partially Observable Markov Decision Processes","authors":"Taewoon Kim, Vincent Fran\\c{c}ois-Lavet, Michael Cochez","authorsParsed":[["Kim","Taewoon",""],["Fran√ßois-Lavet","Vincent",""],["Cochez","Michael",""]],"versions":[{"version":"v1","created":"Sun, 11 Aug 2024 21:04:14 GMT"},{"version":"v2","created":"Sun, 18 Aug 2024 19:32:35 GMT"}],"updateDate":"2024-08-20","timestamp":1723410254000,"abstract":"  Humans observe only part of their environment at any moment but can still\nmake complex, long-term decisions thanks to our long-term memory. To test how\nan AI can learn and utilize its long-term memory, we have developed a partially\nobservable Markov decision processes (POMDP) environment, where the agent has\nto answer questions while navigating a maze. The environment is completely\nknowledge graph (KG) based, where the hidden states are dynamic KGs. A KG is\nboth human- and machine-readable, making it easy to see what the agents\nremember and forget. We train and compare agents with different memory systems,\nto shed light on how human brains work when it comes to managing its own\nmemory. By repurposing the given learning objective as learning a memory\nmanagement policy, we were able to capture the most likely hidden state, which\nis not only interpretable but also reusable.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}