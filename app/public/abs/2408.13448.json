{"id":"2408.13448","title":"ALIAS: DAG Learning with Efficient Unconstrained Policies","authors":"Bao Duong, Hung Le, Thin Nguyen","authorsParsed":[["Duong","Bao",""],["Le","Hung",""],["Nguyen","Thin",""]],"versions":[{"version":"v1","created":"Sat, 24 Aug 2024 03:12:21 GMT"},{"version":"v2","created":"Tue, 27 Aug 2024 03:28:50 GMT"}],"updateDate":"2024-08-28","timestamp":1724469141000,"abstract":"  Recently, reinforcement learning (RL) has proved a promising alternative for\nconventional local heuristics in score-based approaches to learning directed\nacyclic causal graphs (DAGs) from observational data. However, the intricate\nacyclicity constraint still challenges the efficient exploration of the vast\nspace of DAGs in existing methods. In this study, we introduce ALIAS\n(reinforced dAg Learning wIthout Acyclicity conStraints), a novel approach to\ncausal discovery powered by the RL machinery. Our method features an efficient\npolicy for generating DAGs in just a single step with an optimal quadratic\ncomplexity, fueled by a novel parametrization of DAGs that directly translates\na continuous space to the space of all DAGs, bypassing the need for explicitly\nenforcing acyclicity constraints. This approach enables us to navigate the\nsearch space more effectively by utilizing policy gradient methods and\nestablished scoring functions. In addition, we provide compelling empirical\nevidence for the strong performance of ALIAS in comparison with\nstate-of-the-arts in causal discovery over increasingly difficult experiment\nconditions on both synthetic and real datasets.\n","subjects":["Computing Research Repository/Machine Learning","Statistics/Methodology","Statistics/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}