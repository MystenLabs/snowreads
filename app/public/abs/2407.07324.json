{"id":"2407.07324","title":"Event-Aided Time-to-Collision Estimation for Autonomous Driving","authors":"Jinghang Li, Bangyan Liao, Xiuyuan LU, Peidong Liu, Shaojie Shen, Yi\n  Zhou","authorsParsed":[["Li","Jinghang",""],["Liao","Bangyan",""],["LU","Xiuyuan",""],["Liu","Peidong",""],["Shen","Shaojie",""],["Zhou","Yi",""]],"versions":[{"version":"v1","created":"Wed, 10 Jul 2024 02:37:36 GMT"},{"version":"v2","created":"Tue, 16 Jul 2024 06:14:30 GMT"}],"updateDate":"2024-07-17","timestamp":1720579056000,"abstract":"  Predicting a potential collision with leading vehicles is an essential\nfunctionality of any autonomous/assisted driving system. One bottleneck of\nexisting vision-based solutions is that their updating rate is limited to the\nframe rate of standard cameras used. In this paper, we present a novel method\nthat estimates the time to collision using a neuromorphic event-based camera, a\nbiologically inspired visual sensor that can sense at exactly the same rate as\nscene dynamics. The core of the proposed algorithm consists of a two-step\napproach for efficient and accurate geometric model fitting on event data in a\ncoarse-to-fine manner. The first step is a robust linear solver based on a\nnovel geometric measurement that overcomes the partial observability of\nevent-based normal flow. The second step further refines the resulting model\nvia a spatio-temporal registration process formulated as a nonlinear\noptimization problem. Experiments on both synthetic and real data demonstrate\nthe effectiveness of the proposed method, outperforming other alternative\nmethods in terms of efficiency and accuracy.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}