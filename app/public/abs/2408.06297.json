{"id":"2408.06297","title":"LEARN: An Invex Loss for Outlier Oblivious Robust Online Optimization","authors":"Adarsh Barik, Anand Krishna, Vincent Y. F. Tan","authorsParsed":[["Barik","Adarsh",""],["Krishna","Anand",""],["Tan","Vincent Y. F.",""]],"versions":[{"version":"v1","created":"Mon, 12 Aug 2024 17:08:31 GMT"}],"updateDate":"2024-08-13","timestamp":1723482511000,"abstract":"  We study a robust online convex optimization framework, where an adversary\ncan introduce outliers by corrupting loss functions in an arbitrary number of\nrounds k, unknown to the learner. Our focus is on a novel setting allowing\nunbounded domains and large gradients for the losses without relying on a\nLipschitz assumption. We introduce the Log Exponential Adjusted Robust and\niNvex (LEARN) loss, a non-convex (invex) robust loss function to mitigate the\neffects of outliers and develop a robust variant of the online gradient descent\nalgorithm by leveraging the LEARN loss. We establish tight regret guarantees\n(up to constants), in a dynamic setting, with respect to the uncorrupted rounds\nand conduct experiments to validate our theory. Furthermore, we present a\nunified analysis framework for developing online optimization algorithms for\nnon-convex (invex) losses, utilizing it to provide regret bounds with respect\nto the LEARN loss, which may be of independent interest.\n","subjects":["Computing Research Repository/Machine Learning","Mathematics/Optimization and Control"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}