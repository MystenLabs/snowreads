{"id":"2408.12282","title":"Subsurface Scattering for 3D Gaussian Splatting","authors":"Jan-Niklas Dihlmann, Arjun Majumdar, Andreas Engelhardt, Raphael\n  Braun, Hendrik P.A. Lensch","authorsParsed":[["Dihlmann","Jan-Niklas",""],["Majumdar","Arjun",""],["Engelhardt","Andreas",""],["Braun","Raphael",""],["Lensch","Hendrik P. A.",""]],"versions":[{"version":"v1","created":"Thu, 22 Aug 2024 10:34:01 GMT"}],"updateDate":"2024-08-23","timestamp":1724322841000,"abstract":"  3D reconstruction and relighting of objects made from scattering materials\npresent a significant challenge due to the complex light transport beneath the\nsurface. 3D Gaussian Splatting introduced high-quality novel view synthesis at\nreal-time speeds. While 3D Gaussians efficiently approximate an object's\nsurface, they fail to capture the volumetric properties of subsurface\nscattering. We propose a framework for optimizing an object's shape together\nwith the radiance transfer field given multi-view OLAT (one light at a time)\ndata. Our method decomposes the scene into an explicit surface represented as\n3D Gaussians, with a spatially varying BRDF, and an implicit volumetric\nrepresentation of the scattering component. A learned incident light field\naccounts for shadowing. We optimize all parameters jointly via ray-traced\ndifferentiable rendering. Our approach enables material editing, relighting and\nnovel view synthesis at interactive rates. We show successful application on\nsynthetic data and introduce a newly acquired multi-view multi-light dataset of\nobjects in a light-stage setup. Compared to previous work we achieve comparable\nor better results at a fraction of optimization and rendering time while\nenabling detailed control over material attributes. Project page\nhttps://sss.jdihlmann.com/\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Graphics"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}