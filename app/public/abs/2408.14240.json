{"id":"2408.14240","title":"Celtibero: Robust Layered Aggregation for Federated Learning","authors":"Borja Molina-Coronado","authorsParsed":[["Molina-Coronado","Borja",""]],"versions":[{"version":"v1","created":"Mon, 26 Aug 2024 12:54:00 GMT"}],"updateDate":"2024-08-27","timestamp":1724676840000,"abstract":"  Federated Learning (FL) is an innovative approach to distributed machine\nlearning. While FL offers significant privacy advantages, it also faces\nsecurity challenges, particularly from poisoning attacks where adversaries\ndeliberately manipulate local model updates to degrade model performance or\nintroduce hidden backdoors. Existing defenses against these attacks have been\nshown to be effective when the data on the nodes is identically and\nindependently distributed (i.i.d.), but they often fail under less restrictive,\nnon-i.i.d data conditions. To overcome these limitations, we introduce\nCeltibero, a novel defense mechanism that integrates layered aggregation to\nenhance robustness against adversarial manipulation. Through extensive\nexperiments on the MNIST and IMDB datasets, we demonstrate that Celtibero\nconsistently achieves high main task accuracy (MTA) while maintaining minimal\nattack success rates (ASR) across a range of untargeted and targeted poisoning\nattacks. Our results highlight the superiority of Celtibero over existing\ndefenses such as FL-Defender, LFighter, and FLAME, establishing it as a highly\neffective solution for securing federated learning systems against\nsophisticated poisoning attacks.\n","subjects":["Computing Research Repository/Cryptography and Security","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Distributed, Parallel, and Cluster Computing"],"license":"http://creativecommons.org/licenses/by-sa/4.0/"}