{"id":"2407.16677","title":"From Imitation to Refinement -- Residual RL for Precise Visual Assembly","authors":"Lars Ankile, Anthony Simeonov, Idan Shenfeld, Marcel Torne, Pulkit\n  Agrawal","authorsParsed":[["Ankile","Lars",""],["Simeonov","Anthony",""],["Shenfeld","Idan",""],["Torne","Marcel",""],["Agrawal","Pulkit",""]],"versions":[{"version":"v1","created":"Tue, 23 Jul 2024 17:44:54 GMT"}],"updateDate":"2024-07-24","timestamp":1721756694000,"abstract":"  Behavior cloning (BC) currently stands as a dominant paradigm for learning\nreal-world visual manipulation. However, in tasks that require locally\ncorrective behaviors like multi-part assembly, learning robust policies purely\nfrom human demonstrations remains challenging. Reinforcement learning (RL) can\nmitigate these limitations by allowing policies to acquire locally corrective\nbehaviors through task reward supervision and exploration. This paper explores\nthe use of RL fine-tuning to improve upon BC-trained policies in precise\nmanipulation tasks. We analyze and overcome technical challenges associated\nwith using RL to directly train policy networks that incorporate modern\narchitectural components like diffusion models and action chunking. We propose\ntraining residual policies on top of frozen BC-trained diffusion models using\nstandard policy gradient methods and sparse rewards, an approach we call ResiP\n(Residual for Precise manipulation). Our experimental results demonstrate that\nthis residual learning framework can significantly improve success rates beyond\nthe base BC-trained models in high-precision assembly tasks by learning\ncorrective actions. We also show that by combining ResiP with teacher-student\ndistillation and visual domain randomization, our method can enable learning\nreal-world policies for robotic assembly directly from RGB images. Find videos\nand code at \\url{https://residual-assembly.github.io}.\n","subjects":["Computing Research Repository/Robotics","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}