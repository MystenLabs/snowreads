{"id":"2408.03220","title":"Masked Random Noise for Communication Efficient Federaetd Learning","authors":"Shiwei Li and Yingyi Cheng and Haozhao Wang and Xing Tang and Shijie\n  Xu and Weihong Luo and Yuhua Li and Dugang Liu and Xiuqiang He and and\n  Ruixuan Li","authorsParsed":[["Li","Shiwei",""],["Cheng","Yingyi",""],["Wang","Haozhao",""],["Tang","Xing",""],["Xu","Shijie",""],["Luo","Weihong",""],["Li","Yuhua",""],["Liu","Dugang",""],["He","Xiuqiang",""],["Li","and Ruixuan",""]],"versions":[{"version":"v1","created":"Tue, 6 Aug 2024 14:26:09 GMT"}],"updateDate":"2024-08-07","timestamp":1722954369000,"abstract":"  Federated learning is a promising distributed training paradigm that\neffectively safeguards data privacy. However, it may involve significant\ncommunication costs, which hinders training efficiency. In this paper, we aim\nto enhance communication efficiency from a new perspective. Specifically, we\nrequest the distributed clients to find optimal model updates relative to\nglobal model parameters within predefined random noise. For this purpose, we\npropose Federated Masked Random Noise (FedMRN), a novel framework that enables\nclients to learn a 1-bit mask for each model parameter and apply masked random\nnoise (i.e., the Hadamard product of random noise and masks) to represent model\nupdates. To make FedMRN feasible, we propose an advanced mask training\nstrategy, called progressive stochastic masking (PSM). After local training,\neach client only need to transmit local masks and a random seed to the server.\nAdditionally, we provide theoretical guarantees for the convergence of FedMRN\nunder both strongly convex and non-convex assumptions. Extensive experiments\nare conducted on four popular datasets. The results show that FedMRN exhibits\nsuperior convergence speed and test accuracy compared to relevant baselines,\nwhile attaining a similar level of accuracy as FedAvg.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Distributed, Parallel, and Cluster Computing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}