{"id":"2407.21460","title":"Multi-agent Assessment with QoS Enhancement for HD Map Updates in a\n  Vehicular Network","authors":"Jeffrey Redondo, Nauman Aslam, Juan Zhang, and Zhenhui Yuan","authorsParsed":[["Redondo","Jeffrey",""],["Aslam","Nauman",""],["Zhang","Juan",""],["Yuan","Zhenhui",""]],"versions":[{"version":"v1","created":"Wed, 31 Jul 2024 09:17:09 GMT"}],"updateDate":"2024-08-01","timestamp":1722417429000,"abstract":"  Reinforcement Learning (RL) algorithms have been used to address the\nchallenging problems in the offloading process of vehicular ad hoc networks\n(VANET). More recently, they have been utilized to improve the dissemination of\nhigh-definition (HD) Maps. Nevertheless, implementing solutions such as deep\nQ-learning (DQN) and Actor-critic at the autonomous vehicle (AV) may lead to an\nincrease in the computational load, causing a heavy burden on the computational\ndevices and higher costs. Moreover, their implementation might raise\ncompatibility issues between technologies due to the required modifications to\nthe standards. Therefore, in this paper, we assess the scalability of an\napplication utilizing a Q-learning single-agent solution in a distributed\nmulti-agent environment. This application improves the network performance by\ntaking advantage of a smaller state, and action space whilst using a\nmulti-agent approach. The proposed solution is extensively evaluated with\ndifferent test cases involving reward function considering individual or\noverall network performance, number of agents, and centralized and distributed\nlearning comparison. The experimental results demonstrate that the time\nlatencies of our proposed solution conducted in voice, video, HD Map, and\nbest-effort cases have significant improvements, with 40.4%, 36%, 43%, and 12%\nrespectively, compared to the performances with the single-agent approach.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}