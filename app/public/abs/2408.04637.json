{"id":"2408.04637","title":"APE: Active Learning-based Tooling for Finding Informative Few-shot\n  Examples for LLM-based Entity Matching","authors":"Kun Qian and Yisi Sang and Farima Fatahi Bayat and Anton Belyi and\n  Xianqi Chu and Yash Govind and Samira Khorshidi and Rahul Khot and Katherine\n  Luna and Azadeh Nikfarjam and Xiaoguang Qi and Fei Wu and Xianhan Zhang and\n  Yunyao Li","authorsParsed":[["Qian","Kun",""],["Sang","Yisi",""],["Bayat","Farima Fatahi",""],["Belyi","Anton",""],["Chu","Xianqi",""],["Govind","Yash",""],["Khorshidi","Samira",""],["Khot","Rahul",""],["Luna","Katherine",""],["Nikfarjam","Azadeh",""],["Qi","Xiaoguang",""],["Wu","Fei",""],["Zhang","Xianhan",""],["Li","Yunyao",""]],"versions":[{"version":"v1","created":"Mon, 29 Jul 2024 22:22:50 GMT"}],"updateDate":"2024-08-12","timestamp":1722291770000,"abstract":"  Prompt engineering is an iterative procedure often requiring extensive manual\neffort to formulate suitable instructions for effectively directing large\nlanguage models (LLMs) in specific tasks. Incorporating few-shot examples is a\nvital and effective approach to providing LLMs with precise instructions,\nleading to improved LLM performance. Nonetheless, identifying the most\ninformative demonstrations for LLMs is labor-intensive, frequently entailing\nsifting through an extensive search space. In this demonstration, we showcase a\nhuman-in-the-loop tool called APE (Active Prompt Engineering) designed for\nrefining prompts through active learning. Drawing inspiration from active\nlearning, APE iteratively selects the most ambiguous examples for human\nfeedback, which will be transformed into few-shot examples within the prompt.\nThe demo recording can be found with the submission or be viewed at\nhttps://youtu.be/OwQ6MQx53-Y.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/"}