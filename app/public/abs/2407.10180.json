{"id":"2407.10180","title":"Defending Against Repetitive-based Backdoor Attacks on Semi-supervised\n  Learning through Lens of Rate-Distortion-Perception Trade-off","authors":"Cheng-Yi Lee, Ching-Chia Kao, Cheng-Han Yeh, Chun-Shien Lu, Chia-Mu Yu\n  and Chu-Song Chen","authorsParsed":[["Lee","Cheng-Yi",""],["Kao","Ching-Chia",""],["Yeh","Cheng-Han",""],["Lu","Chun-Shien",""],["Yu","Chia-Mu",""],["Chen","Chu-Song",""]],"versions":[{"version":"v1","created":"Sun, 14 Jul 2024 12:42:11 GMT"}],"updateDate":"2024-07-16","timestamp":1720960931000,"abstract":"  Semi-supervised learning (SSL) has achieved remarkable performance with a\nsmall fraction of labeled data by leveraging vast amounts of unlabeled data\nfrom the Internet. However, this large pool of untrusted data is extremely\nvulnerable to data poisoning, leading to potential backdoor attacks. Current\nbackdoor defenses are not yet effective against such a vulnerability in SSL. In\nthis study, we propose a novel method, Unlabeled Data Purification (UPure), to\ndisrupt the association between trigger patterns and target classes by\nintroducing perturbations in the frequency domain. By leveraging the Rate-\nDistortion-Perception (RDP) trade-off, we further identify the frequency band,\nwhere the perturbations are added, and justify this selection. Notably, UPure\npurifies poisoned unlabeled data without the need of extra clean labeled data.\nExtensive experiments on four benchmark datasets and five SSL algorithms\ndemonstrate that UPure effectively reduces the attack success rate from 99.78%\nto 0% while maintaining model accuracy\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}