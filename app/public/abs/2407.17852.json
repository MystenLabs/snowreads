{"id":"2407.17852","title":"Scaling A Simple Approach to Zero-Shot Speech Recognition","authors":"Jinming Zhao, Vineel Pratap, Michael Auli","authorsParsed":[["Zhao","Jinming",""],["Pratap","Vineel",""],["Auli","Michael",""]],"versions":[{"version":"v1","created":"Thu, 25 Jul 2024 08:08:55 GMT"}],"updateDate":"2024-07-26","timestamp":1721894935000,"abstract":"  Despite rapid progress in increasing the language coverage of automatic\nspeech recognition, the field is still far from covering all languages with a\nknown writing script. Recent work showed promising results with a zero-shot\napproach requiring only a small amount of text data, however, accuracy heavily\ndepends on the quality of the used phonemizer which is often weak for unseen\nlanguages. In this paper, we present MMS Zero-shot a conceptually simpler\napproach based on romanization and an acoustic model trained on data in 1,078\ndifferent languages or three orders of magnitude more than prior art. MMS\nZero-shot reduces the average character error rate by a relative 46% over 100\nunseen languages compared to the best previous work. Moreover, the error rate\nof our approach is only 2.5x higher compared to in-domain supervised baselines,\nwhile our approach uses no labeled data for the evaluation languages at all.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}