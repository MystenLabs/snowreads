{"id":"2407.17085","title":"OVR: A Dataset for Open Vocabulary Temporal Repetition Counting in\n  Videos","authors":"Debidatta Dwibedi, Yusuf Aytar, Jonathan Tompson, Andrew Zisserman","authorsParsed":[["Dwibedi","Debidatta",""],["Aytar","Yusuf",""],["Tompson","Jonathan",""],["Zisserman","Andrew",""]],"versions":[{"version":"v1","created":"Wed, 24 Jul 2024 08:22:49 GMT"}],"updateDate":"2024-07-25","timestamp":1721809369000,"abstract":"  We introduce a dataset of annotations of temporal repetitions in videos. The\ndataset, OVR (pronounced as over), contains annotations for over 72K videos,\nwith each annotation specifying the number of repetitions, the start and end\ntime of the repetitions, and also a free-form description of what is repeating.\nThe annotations are provided for videos sourced from Kinetics and Ego4D, and\nconsequently cover both Exo and Ego viewing conditions, with a huge variety of\nactions and activities. Moreover, OVR is almost an order of magnitude larger\nthan previous datasets for video repetition. We also propose a baseline\ntransformer-based counting model, OVRCounter, that can localise and count\nrepetitions in videos that are up to 320 frames long. The model is trained and\nevaluated on the OVR dataset, and its performance assessed with and without\nusing text to specify the target class to count. The performance is also\ncompared to a prior repetition counting model. The dataset is available for\ndownload at: https://sites.google.com/view/openvocabreps/\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}