{"id":"2408.03292","title":"Static IR Drop Prediction with Attention U-Net and Saliency-Based\n  Explainability","authors":"Lizi Zhang, Azadeh Davoodi","authorsParsed":[["Zhang","Lizi",""],["Davoodi","Azadeh",""]],"versions":[{"version":"v1","created":"Tue, 6 Aug 2024 16:41:33 GMT"}],"updateDate":"2024-08-07","timestamp":1722962493000,"abstract":"  There has been significant recent progress to reduce the computational effort\nof static IR drop analysis using neural networks, and modeling as an\nimage-to-image translation task. A crucial issue is the lack of sufficient data\nfrom real industry designs to train these networks. Additionally, there is no\nmethodology to explain a high-drop pixel in a predicted IR drop image to its\nspecific root-causes. In this work, we first propose a U-Net neural network\nmodel with attention gates which is specifically tailored to achieve fast and\naccurate image-based static IR drop prediction. Attention gates allow selective\nemphasis on relevant parts of the input data without supervision which is\ndesired because of the often sparse nature of the IR drop map. We propose a\ntwo-phase training process which utilizes a mix of artificially-generated data\nand a limited number of points from real designs. The results are, on-average,\n18% (53%) better in MAE and 14% (113%) in F1 score compared to the winner of\nthe ICCAD 2023 contest (and U-Net only) when tested on real designs. Second, we\npropose a fast method using saliency maps which can explain a predicted IR drop\nin terms of specific input pixels contributing the most to a drop. In our\nexperiments, we show the number of high IR drop pixels can be reduced\non-average by 18% by mimicking upsize of a tiny portion of PDN's resistive\nedges.\n","subjects":["Computing Research Repository/Hardware Architecture","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}