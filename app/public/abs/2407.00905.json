{"id":"2407.00905","title":"Learning Robust 3D Representation from CLIP via Dual Denoising","authors":"Shuqing Luo, Bowen Qu and Wei Gao","authorsParsed":[["Luo","Shuqing",""],["Qu","Bowen",""],["Gao","Wei",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 02:15:03 GMT"}],"updateDate":"2024-07-02","timestamp":1719800103000,"abstract":"  In this paper, we explore a critical yet under-investigated issue: how to\nlearn robust and well-generalized 3D representation from pre-trained vision\nlanguage models such as CLIP. Previous works have demonstrated that cross-modal\ndistillation can provide rich and useful knowledge for 3D data. However, like\nmost deep learning models, the resultant 3D learning network is still\nvulnerable to adversarial attacks especially the iterative attack. In this\nwork, we propose Dual Denoising, a novel framework for learning robust and\nwell-generalized 3D representations from CLIP. It combines a denoising-based\nproxy task with a novel feature denoising network for 3D pre-training.\nAdditionally, we propose utilizing parallel noise inference to enhance the\ngeneralization of point cloud features under cross domain settings. Experiments\nshow that our model can effectively improve the representation learning\nperformance and adversarial robustness of the 3D learning network under\nzero-shot settings without adversarial training. Our code is available at\nhttps://github.com/luoshuqing2001/Dual_Denoising.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}