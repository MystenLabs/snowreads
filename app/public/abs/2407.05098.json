{"id":"2407.05098","title":"FedTSA: A Cluster-based Two-Stage Aggregation Method for\n  Model-heterogeneous Federated Learning","authors":"Boyu Fan, Chenrui Wu, Xiang Su and Pan Hui","authorsParsed":[["Fan","Boyu",""],["Wu","Chenrui",""],["Su","Xiang",""],["Hui","Pan",""]],"versions":[{"version":"v1","created":"Sat, 6 Jul 2024 14:59:55 GMT"},{"version":"v2","created":"Mon, 15 Jul 2024 08:19:30 GMT"}],"updateDate":"2024-07-16","timestamp":1720277995000,"abstract":"  Despite extensive research into data heterogeneity in federated learning\n(FL), system heterogeneity remains a significant yet often overlooked\nchallenge. Traditional FL approaches typically assume homogeneous hardware\nresources across FL clients, implying that clients can train a global model\nwithin a comparable time frame. However, in practical FL systems, clients often\nhave heterogeneous resources, which impacts their training capacity. This\ndiscrepancy underscores the importance of exploring model-heterogeneous FL, a\nparadigm allowing clients to train different models based on their resource\ncapabilities. To address this challenge, we introduce FedTSA, a cluster-based\ntwo-stage aggregation method tailored for system heterogeneity in FL. FedTSA\nbegins by clustering clients based on their capabilities, then performs a\ntwo-stage aggregation: conventional weight averaging for homogeneous models in\nStage 1, and deep mutual learning with a diffusion model for aggregating\nheterogeneous models in Stage 2. Extensive experiments demonstrate that FedTSA\nnot only outperforms the baselines but also explores various factors\ninfluencing model performance, validating FedTSA as a promising approach for\nmodel-heterogeneous FL.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}