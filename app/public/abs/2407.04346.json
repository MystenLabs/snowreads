{"id":"2407.04346","title":"MobileFlow: A Multimodal LLM For Mobile GUI Agent","authors":"Songqin Nong, Jiali Zhu, Rui Wu, Jiongchao Jin, Shuo Shan, Xiutian\n  Huang, Wenhao Xu","authorsParsed":[["Nong","Songqin",""],["Zhu","Jiali",""],["Wu","Rui",""],["Jin","Jiongchao",""],["Shan","Shuo",""],["Huang","Xiutian",""],["Xu","Wenhao",""]],"versions":[{"version":"v1","created":"Fri, 5 Jul 2024 08:37:10 GMT"},{"version":"v2","created":"Wed, 7 Aug 2024 04:00:57 GMT"}],"updateDate":"2024-08-08","timestamp":1720168630000,"abstract":"  Currently, the integration of mobile Graphical User Interfaces (GUIs) is\nubiquitous in most people's daily lives. And the ongoing evolution of\nmultimodal large-scale models, such as GPT-4v, Qwen-VL-Max, has significantly\nbolstered the capabilities of GUI comprehension and user action analysis,\nshowcasing the potentiality of intelligent GUI assistants. However, current GUI\nAgents often need to access page layout information through calling system\nAPIs, which may pose privacy risks. Fixing GUI (such as mobile interfaces) to a\ncertain low resolution might result in the loss of fine-grained image details.\nAt the same time, the multimodal large models built for GUI Agents currently\nhave poor understanding and decision-making abilities for Chinese GUI\ninterfaces, making them difficult to apply to a large number of Chinese apps.\nThis paper introduces MobileFlow, a multimodal large language model\nmeticulously crafted for mobile GUI agents. Transforming from the open-source\nmodel Qwen-VL-Chat into GUI domain, MobileFlow contains approximately 21\nbillion parameters and is equipped with novel hybrid visual encoders, making it\npossible for variable resolutions of image inputs and good support for\nmultilingual GUI. By incorporating Mixture of Experts (MoE) expansions and\npioneering alignment training strategies, MobileFlow has the capacity to fully\ninterpret image data and comprehend user instructions for GUI interaction\ntasks. Finally, MobileFlow outperforms Qwen-VL-Max and GPT-4v in terms of task\nexecution by GUI agents on both public and our proposed evaluation metrics, and\nhas been successfully deployed in real-world business contexts, proving its\neffectiveness for practical applications.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}