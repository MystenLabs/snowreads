{"id":"2407.16245","title":"Exploring the Effectiveness and Consistency of Task Selection in\n  Intermediate-Task Transfer Learning","authors":"Pin-Jie Lin, Miaoran Zhang, Marius Mosbach, Dietrich Klakow","authorsParsed":[["Lin","Pin-Jie",""],["Zhang","Miaoran",""],["Mosbach","Marius",""],["Klakow","Dietrich",""]],"versions":[{"version":"v1","created":"Tue, 23 Jul 2024 07:31:43 GMT"}],"updateDate":"2024-07-24","timestamp":1721719903000,"abstract":"  Identifying beneficial tasks to transfer from is a critical step toward\nsuccessful intermediate-task transfer learning. In this work, we experiment\nwith 130 source-target task combinations and demonstrate that the transfer\nperformance exhibits severe variance across different source tasks and training\nseeds, highlighting the crucial role of intermediate-task selection in a\nbroader context. We compare four representative task selection methods in a\nunified setup, focusing on their effectiveness and consistency. Compared to\nembedding-free methods and text embeddings, task embeddings constructed from\nfine-tuned weights can better estimate task transferability by improving task\nprediction scores from 2.59% to 3.96%. Despite their strong performance, we\nobserve that the task embeddings do not consistently demonstrate superiority\nfor tasks requiring reasoning abilities. Furthermore, we introduce a novel\nmethod that measures pairwise token similarity using maximum inner product\nsearch, leading to the highest performance in task prediction. Our findings\nsuggest that token-wise similarity is better predictive for predicting\ntransferability compared to averaging weights.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/"}