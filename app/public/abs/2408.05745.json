{"id":"2408.05745","title":"Improving Adversarial Transferability with Neighbourhood Gradient\n  Information","authors":"Haijing Guo, Jiafeng Wang, Zhaoyu Chen, Kaixun Jiang, Lingyi Hong,\n  Pinxue Guo, Jinglun Li, Wenqiang Zhang","authorsParsed":[["Guo","Haijing",""],["Wang","Jiafeng",""],["Chen","Zhaoyu",""],["Jiang","Kaixun",""],["Hong","Lingyi",""],["Guo","Pinxue",""],["Li","Jinglun",""],["Zhang","Wenqiang",""]],"versions":[{"version":"v1","created":"Sun, 11 Aug 2024 10:46:49 GMT"}],"updateDate":"2024-08-13","timestamp":1723373209000,"abstract":"  Deep neural networks (DNNs) are known to be susceptible to adversarial\nexamples, leading to significant performance degradation. In black-box attack\nscenarios, a considerable attack performance gap between the surrogate model\nand the target model persists. This work focuses on enhancing the\ntransferability of adversarial examples to narrow this performance gap. We\nobserve that the gradient information around the clean image, i.e.\nNeighbourhood Gradient Information, can offer high transferability. Leveraging\nthis, we propose the NGI-Attack, which incorporates Example Backtracking and\nMultiplex Mask strategies, to use this gradient information and enhance\ntransferability fully. Specifically, we first adopt Example Backtracking to\naccumulate Neighbourhood Gradient Information as the initial momentum term.\nMultiplex Mask, which forms a multi-way attack strategy, aims to force the\nnetwork to focus on non-discriminative regions, which can obtain richer\ngradient information during only a few iterations. Extensive experiments\ndemonstrate that our approach significantly enhances adversarial\ntransferability. Especially, when attacking numerous defense models, we achieve\nan average attack success rate of 95.8%. Notably, our method can plugin with\nany off-the-shelf algorithm to improve their attack performance without\nadditional time cost.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Cryptography and Security"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}