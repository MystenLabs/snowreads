{"id":"2407.04615","title":"ARM: Efficient Guided Decoding with Autoregressive Reward Models","authors":"Sergey Troshin, Vlad Niculae, Antske Fokkens","authorsParsed":[["Troshin","Sergey",""],["Niculae","Vlad",""],["Fokkens","Antske",""]],"versions":[{"version":"v1","created":"Fri, 5 Jul 2024 16:11:03 GMT"}],"updateDate":"2024-07-08","timestamp":1720195863000,"abstract":"  Language models trained on large amounts of data require careful tuning to be\nsafely deployed in real world. We revisit the guided decoding paradigm, where\nthe goal is to augment the logits of the base language model using the scores\nfrom a task-specific reward model. We propose a simple but efficient\nparameterization of the autoregressive reward model enabling fast and effective\nguided decoding. On detoxification and sentiment control tasks, we show that\nour efficient parameterization performs on par with RAD, a strong but less\nefficient guided decoding approach.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}