{"id":"2407.02534","title":"Image-to-Text Logic Jailbreak: Your Imagination can Help You Do Anything","authors":"Xiaotian Zou and Ke Li and Yongkang Chen","authorsParsed":[["Zou","Xiaotian",""],["Li","Ke",""],["Chen","Yongkang",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 16:58:55 GMT"},{"version":"v2","created":"Mon, 26 Aug 2024 22:56:28 GMT"}],"updateDate":"2024-08-28","timestamp":1719853135000,"abstract":"  Large Visual Language Model\\textbfs (VLMs) such as GPT-4V have achieved\nremarkable success in generating comprehensive and nuanced responses.\nResearchers have proposed various benchmarks for evaluating the capabilities of\nVLMs. With the integration of visual and text inputs in VLMs, new security\nissues emerge, as malicious attackers can exploit multiple modalities to\nachieve their objectives. This has led to increasing attention on the\nvulnerabilities of VLMs to jailbreak. Most existing research focuses on\ngenerating adversarial images or nonsensical image to jailbreak these models.\nHowever, no researchers evaluate whether logic understanding capabilities of\nVLMs in flowchart can influence jailbreak. Therefore, to fill this gap, this\npaper first introduces a novel dataset Flow-JD specifically designed to\nevaluate the logic-based flowchart jailbreak capabilities of VLMs. We conduct\nan extensive evaluation on GPT-4o, GPT-4V, other 5 SOTA open source VLMs and\nthe jailbreak rate is up to 92.8%. Our research reveals significant\nvulnerabilities in current VLMs concerning image-to-text jailbreak and these\nfindings underscore the the urgency for the development of robust and effective\nfuture defenses.\n","subjects":["Computing Research Repository/Cryptography and Security","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}