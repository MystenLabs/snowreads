{"id":"2407.11585","title":"QVD: Post-training Quantization for Video Diffusion Models","authors":"Shilong Tian, Hong Chen, Chengtao Lv, Yu Liu, Jinyang Guo, Xianglong\n  Liu, Shengxi Li, Hao Yang, Tao Xie","authorsParsed":[["Tian","Shilong",""],["Chen","Hong",""],["Lv","Chengtao",""],["Liu","Yu",""],["Guo","Jinyang",""],["Liu","Xianglong",""],["Li","Shengxi",""],["Yang","Hao",""],["Xie","Tao",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 10:47:27 GMT"},{"version":"v2","created":"Wed, 17 Jul 2024 05:27:04 GMT"}],"updateDate":"2024-07-18","timestamp":1721126847000,"abstract":"  Recently, video diffusion models (VDMs) have garnered significant attention\ndue to their notable advancements in generating coherent and realistic video\ncontent. However, processing multiple frame features concurrently, coupled with\nthe considerable model size, results in high latency and extensive memory\nconsumption, hindering their broader application. Post-training quantization\n(PTQ) is an effective technique to reduce memory footprint and improve\ncomputational efficiency. Unlike image diffusion, we observe that the temporal\nfeatures, which are integrated into all frame features, exhibit pronounced\nskewness. Furthermore, we investigate significant inter-channel disparities and\nasymmetries in the activation of video diffusion models, resulting in low\ncoverage of quantization levels by individual channels and increasing the\nchallenge of quantization. To address these issues, we introduce the first PTQ\nstrategy tailored for video diffusion models, dubbed QVD. Specifically, we\npropose the High Temporal Discriminability Quantization (HTDQ) method, designed\nfor temporal features, which retains the high discriminability of quantized\nfeatures, providing precise temporal guidance for all video frames. In\naddition, we present the Scattered Channel Range Integration (SCRI) method\nwhich aims to improve the coverage of quantization levels across individual\nchannels. Experimental validations across various models, datasets, and\nbit-width settings demonstrate the effectiveness of our QVD in terms of diverse\nmetrics. In particular, we achieve near-lossless performance degradation on\nW8A8, outperforming the current methods by 205.12 in FVD.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}