{"id":"2408.16029","title":"Meta-Learn Unimodal Signals with Weak Supervision for Multimodal\n  Sentiment Analysis","authors":"Sijie Mai, Yu Zhao, Ying Zeng, Jianhua Yao, Haifeng Hu","authorsParsed":[["Mai","Sijie",""],["Zhao","Yu",""],["Zeng","Ying",""],["Yao","Jianhua",""],["Hu","Haifeng",""]],"versions":[{"version":"v1","created":"Wed, 28 Aug 2024 03:43:01 GMT"},{"version":"v2","created":"Fri, 13 Sep 2024 02:51:18 GMT"}],"updateDate":"2024-09-16","timestamp":1724816581000,"abstract":"  Multimodal sentiment analysis aims to effectively integrate information from\nvarious sources to infer sentiment, where in many cases there are no\nannotations for unimodal labels. Therefore, most works rely on multimodal\nlabels for training. However, there exists the noisy label problem for the\nlearning of unimodal signals as multimodal annotations are not always the ideal\nsubstitutes for the unimodal ones, failing to achieve finer optimization for\nindividual modalities. In this paper, we explore the learning of unimodal\nlabels under the weak supervision from the annotated multimodal labels.\nSpecifically, we propose a novel meta uni-label generation (MUG) framework to\naddress the above problem, which leverages the available multimodal labels to\nlearn the corresponding unimodal labels by the meta uni-label correction\nnetwork (MUCN). We first design a contrastive-based projection module to bridge\nthe gap between unimodal and multimodal representations, so as to use\nmultimodal annotations to guide the learning of MUCN. Afterwards, we propose\nunimodal and multimodal denoising tasks to train MUCN with explicit supervision\nvia a bi-level optimization strategy. We then jointly train unimodal and\nmultimodal learning tasks to extract discriminative unimodal features for\nmultimodal inference. Experimental results suggest that MUG outperforms\ncompetitive baselines and can learn accurate unimodal labels.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}