{"id":"2408.11545","title":"UNetMamba: An Efficient UNet-Like Mamba for Semantic Segmentation of\n  High-Resolution Remote Sensing Images","authors":"Enze Zhu, Zhan Chen, Dingkai Wang, Hanru Shi, Xiaoxuan Liu and Lei\n  Wang","authorsParsed":[["Zhu","Enze",""],["Chen","Zhan",""],["Wang","Dingkai",""],["Shi","Hanru",""],["Liu","Xiaoxuan",""],["Wang","Lei",""]],"versions":[{"version":"v1","created":"Wed, 21 Aug 2024 11:53:53 GMT"},{"version":"v2","created":"Mon, 26 Aug 2024 05:21:35 GMT"}],"updateDate":"2024-08-27","timestamp":1724241233000,"abstract":"  Semantic segmentation of high-resolution remote sensing images is vital in\ndownstream applications such as land-cover mapping, urban planning and disaster\nassessment.Existing Transformer-based methods suffer from the constraint\nbetween accuracy and efficiency, while the recently proposed Mamba is renowned\nfor being efficient. Therefore, to overcome the dilemma, we propose UNetMamba,\na UNet-like semantic segmentation model based on Mamba. It incorporates a mamba\nsegmentation decoder (MSD) that can efficiently decode the complex information\nwithin high-resolution images, and a local supervision module (LSM), which is\ntrain-only but can significantly enhance the perception of local contents.\nExtensive experiments demonstrate that UNetMamba outperforms the\nstate-of-the-art methods with mIoU increased by 0.87% on LoveDA and 0.36% on\nISPRS Vaihingen, while achieving high efficiency through the lightweight\ndesign, less memory footprint and reduced computational cost. The source code\nis available at https://github.com/EnzeZhu2001/UNetMamba.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}