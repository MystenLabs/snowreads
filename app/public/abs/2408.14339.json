{"id":"2408.14339","title":"ConceptMix: A Compositional Image Generation Benchmark with Controllable\n  Difficulty","authors":"Xindi Wu, Dingli Yu, Yangsibo Huang, Olga Russakovsky, Sanjeev Arora","authorsParsed":[["Wu","Xindi",""],["Yu","Dingli",""],["Huang","Yangsibo",""],["Russakovsky","Olga",""],["Arora","Sanjeev",""]],"versions":[{"version":"v1","created":"Mon, 26 Aug 2024 15:08:12 GMT"}],"updateDate":"2024-08-27","timestamp":1724684892000,"abstract":"  Compositionality is a critical capability in Text-to-Image (T2I) models, as\nit reflects their ability to understand and combine multiple concepts from text\ndescriptions. Existing evaluations of compositional capability rely heavily on\nhuman-designed text prompts or fixed templates, limiting their diversity and\ncomplexity, and yielding low discriminative power. We propose ConceptMix, a\nscalable, controllable, and customizable benchmark which automatically\nevaluates compositional generation ability of T2I models. This is done in two\nstages. First, ConceptMix generates the text prompts: concretely, using\ncategories of visual concepts (e.g., objects, colors, shapes, spatial\nrelationships), it randomly samples an object and k-tuples of visual concepts,\nthen uses GPT4-o to generate text prompts for image generation based on these\nsampled concepts. Second, ConceptMix evaluates the images generated in response\nto these prompts: concretely, it checks how many of the k concepts actually\nappeared in the image by generating one question per visual concept and using a\nstrong VLM to answer them. Through administering ConceptMix to a diverse set of\nT2I models (proprietary as well as open ones) using increasing values of k, we\nshow that our ConceptMix has higher discrimination power than earlier\nbenchmarks. Specifically, ConceptMix reveals that the performance of several\nmodels, especially open models, drops dramatically with increased k.\nImportantly, it also provides insight into the lack of prompt diversity in\nwidely-used training datasets. Additionally, we conduct extensive human studies\nto validate the design of ConceptMix and compare our automatic grading with\nhuman judgement. We hope it will guide future T2I model development.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}