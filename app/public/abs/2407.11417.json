{"id":"2407.11417","title":"SPINACH: SPARQL-Based Information Navigation for Challenging Real-World\n  Questions","authors":"Shicheng Liu, Sina J. Semnani, Harold Triedman, Jialiang Xu, Isaac Dan\n  Zhao, Monica S. Lam","authorsParsed":[["Liu","Shicheng",""],["Semnani","Sina J.",""],["Triedman","Harold",""],["Xu","Jialiang",""],["Zhao","Isaac Dan",""],["Lam","Monica S.",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 06:18:21 GMT"}],"updateDate":"2024-07-17","timestamp":1721110701000,"abstract":"  Recent work integrating Large Language Models (LLMs) has led to significant\nimprovements in the Knowledge Base Question Answering (KBQA) task. However, we\nposit that existing KBQA datasets that either have simple questions, use\nsynthetically generated logical forms, or are based on small knowledge base\n(KB) schemas, do not capture the true complexity of KBQA tasks.\n  To address this, we introduce the SPINACH dataset, an expert-annotated KBQA\ndataset collected from forum discussions on Wikidata's \"Request a Query\" forum\nwith 320 decontextualized question-SPARQL pairs. Much more complex than\nexisting datasets, SPINACH calls for strong KBQA systems that do not rely on\ntraining data to learn the KB schema, but can dynamically explore large and\noften incomplete schemas and reason about them.\n  Along with the dataset, we introduce the SPINACH agent, a new KBQA approach\nthat mimics how a human expert would write SPARQLs for such challenging\nquestions. Experiments on existing datasets show SPINACH's capability in KBQA,\nachieving a new state of the art on the QALD-7, QALD-9 Plus and QALD-10\ndatasets by 30.1%, 27.0%, and 10.0% in F1, respectively, and coming within 1.6%\nof the fine-tuned LLaMA SOTA model on WikiWebQuestions. On our new SPINACH\ndataset, SPINACH agent outperforms all baselines, including the best\nGPT-4-based KBQA agent, by 38.1% in F1.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}