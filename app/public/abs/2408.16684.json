{"id":"2408.16684","title":"PartFormer: Awakening Latent Diverse Representation from Vision\n  Transformer for Object Re-Identification","authors":"Lei Tan, Pingyang Dai, Jie Chen, Liujuan Cao, Yongjian Wu, Rongrong Ji","authorsParsed":[["Tan","Lei",""],["Dai","Pingyang",""],["Chen","Jie",""],["Cao","Liujuan",""],["Wu","Yongjian",""],["Ji","Rongrong",""]],"versions":[{"version":"v1","created":"Thu, 29 Aug 2024 16:31:05 GMT"}],"updateDate":"2024-08-30","timestamp":1724949065000,"abstract":"  Extracting robust feature representation is critical for object\nre-identification to accurately identify objects across non-overlapping\ncameras. Although having a strong representation ability, the Vision\nTransformer (ViT) tends to overfit on most distinct regions of training data,\nlimiting its generalizability and attention to holistic object features.\nMeanwhile, due to the structural difference between CNN and ViT, fine-grained\nstrategies that effectively address this issue in CNN do not continue to be\nsuccessful in ViT. To address this issue, by observing the latent diverse\nrepresentation hidden behind the multi-head attention, we present PartFormer,\nan innovative adaptation of ViT designed to overcome the granularity\nlimitations in object Re-ID tasks. The PartFormer integrates a Head\nDisentangling Block (HDB) that awakens the diverse representation of multi-head\nself-attention without the typical loss of feature richness induced by\nconcatenation and FFN layers post-attention. To avoid the homogenization of\nattention heads and promote robust part-based feature learning, two head\ndiversity constraints are imposed: attention diversity constraint and\ncorrelation diversity constraint. These constraints enable the model to exploit\ndiverse and discriminative feature representations from different attention\nheads. Comprehensive experiments on various object Re-ID benchmarks demonstrate\nthe superiority of the PartFormer. Specifically, our framework significantly\noutperforms state-of-the-art by 2.4\\% mAP scores on the most challenging MSMT17\ndataset.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}