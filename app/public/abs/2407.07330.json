{"id":"2407.07330","title":"Interpretable Differential Diagnosis with Dual-Inference Large Language\n  Models","authors":"Shuang Zhou, Sirui Ding, Jiashuo Wang, Mingquan Lin, Genevieve B.\n  Melton, Rui Zhang","authorsParsed":[["Zhou","Shuang",""],["Ding","Sirui",""],["Wang","Jiashuo",""],["Lin","Mingquan",""],["Melton","Genevieve B.",""],["Zhang","Rui",""]],"versions":[{"version":"v1","created":"Wed, 10 Jul 2024 02:58:37 GMT"}],"updateDate":"2024-07-11","timestamp":1720580317000,"abstract":"  Methodological advancements to automate the generation of differential\ndiagnosis (DDx) to predict a list of potential diseases as differentials given\npatients' symptom descriptions are critical to clinical reasoning and\napplications such as decision support. However, providing reasoning or\ninterpretation for these differential diagnoses is more meaningful.\nFortunately, large language models (LLMs) possess powerful language processing\nabilities and have been proven effective in various related tasks. Motivated by\nthis potential, we investigate the use of LLMs for interpretable DDx. First, we\ndevelop a new DDx dataset with expert-derived interpretation on 570 public\nclinical notes. Second, we propose a novel framework, named Dual-Inf, that\nenables LLMs to conduct bidirectional inference for interpretation. Both human\nand automated evaluation demonstrate the effectiveness of Dual-Inf in\npredicting differentials and diagnosis explanations. Specifically, the\nperformance improvement of Dual-Inf over the baseline methods exceeds 32%\nw.r.t. BERTScore in DDx interpretation. Furthermore, experiments verify that\nDual-Inf (1) makes fewer errors in interpretation, (2) has great\ngeneralizability, (3) is promising for rare disease diagnosis and explanation.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}