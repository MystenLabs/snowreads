{"id":"2407.14257","title":"SparseCraft: Few-Shot Neural Reconstruction through Stereopsis Guided\n  Geometric Linearization","authors":"Mae Younes, Amine Ouasfi, Adnane Boukhayma","authorsParsed":[["Younes","Mae",""],["Ouasfi","Amine",""],["Boukhayma","Adnane",""]],"versions":[{"version":"v1","created":"Fri, 19 Jul 2024 12:36:36 GMT"}],"updateDate":"2024-07-22","timestamp":1721392596000,"abstract":"  We present a novel approach for recovering 3D shape and view dependent\nappearance from a few colored images, enabling efficient 3D reconstruction and\nnovel view synthesis. Our method learns an implicit neural representation in\nthe form of a Signed Distance Function (SDF) and a radiance field. The model is\ntrained progressively through ray marching enabled volumetric rendering, and\nregularized with learning-free multi-view stereo (MVS) cues. Key to our\ncontribution is a novel implicit neural shape function learning strategy that\nencourages our SDF field to be as linear as possible near the level-set, hence\nrobustifying the training against noise emanating from the supervision and\nregularization signals. Without using any pretrained priors, our method, called\nSparseCraft, achieves state-of-the-art performances both in novel-view\nsynthesis and reconstruction from sparse views in standard benchmarks, while\nrequiring less than 10 minutes for training.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"JrjUsO94KiUcIgGDCbRJL26u9BDx4TdXN-gdoLEob2M","pdfSize":"5020083"}
