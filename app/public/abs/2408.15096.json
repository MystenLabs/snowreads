{"id":"2408.15096","title":"Post-processing fairness with minimal changes","authors":"Federico Di Gennaro, Thibault Laugel, Vincent Grari, Xavier Renard,\n  Marcin Detyniecki","authorsParsed":[["Di Gennaro","Federico",""],["Laugel","Thibault",""],["Grari","Vincent",""],["Renard","Xavier",""],["Detyniecki","Marcin",""]],"versions":[{"version":"v1","created":"Tue, 27 Aug 2024 14:26:56 GMT"},{"version":"v2","created":"Thu, 29 Aug 2024 15:59:13 GMT"}],"updateDate":"2024-08-30","timestamp":1724768816000,"abstract":"  In this paper, we introduce a novel post-processing algorithm that is both\nmodel-agnostic and does not require the sensitive attribute at test time. In\naddition, our algorithm is explicitly designed to enforce minimal changes\nbetween biased and debiased predictions; a property that, while highly\ndesirable, is rarely prioritized as an explicit objective in fairness\nliterature. Our approach leverages a multiplicative factor applied to the logit\nvalue of probability scores produced by a black-box classifier. We demonstrate\nthe efficacy of our method through empirical evaluations, comparing its\nperformance against other four debiasing algorithms on two widely used datasets\nin fairness research.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}