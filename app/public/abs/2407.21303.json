{"id":"2407.21303","title":"Can expected error costs justify testing a hypothesis at multiple alpha\n  levels rather than searching for an elusive optimal alpha?","authors":"Janet Aisbett","authorsParsed":[["Aisbett","Janet",""]],"versions":[{"version":"v1","created":"Wed, 31 Jul 2024 03:05:33 GMT"}],"updateDate":"2024-08-01","timestamp":1722395133000,"abstract":"  Simultaneous testing of one hypothesis at multiple alpha levels can be\nperformed within a conventional Neyman-Pearson framework. This is achieved by\ntreating the hypothesis as a family of hypotheses, each member of which\nexplicitly concerns test level as well as effect size. Such testing encourages\nresearchers to think about error rates and strength of evidence in both the\nstatistical design and reporting stages of a study. Here, we show that these\nmulti-alpha level tests can deliver acceptable expected total error costs. We\nfirst present formulas for expected error costs from single alpha and multiple\nalpha level tests, given prior probabilities of effect sizes that have either\ndichotomous or continuous distributions. Error costs are tied to decisions,\nwith different decisions assumed for each of the potential outcomes in the\nmulti-alpha level case. Expected total costs for tests at single and multiple\nalpha levels are then compared with optimal costs. This comparison highlights\nhow sensitive optimization is to estimated error costs and to assumptions about\nprevalence. Testing at multiple default thresholds removes the need to formally\nidentify decisions, or to model costs and prevalence as required in\noptimization approaches. Although total expected error costs with this approach\nwill not be optimal, our results suggest they may be lower, on average, than\nwhen so-called optimal test levels are based on mis-specified models.\n","subjects":["Statistics/Applications"],"license":"http://creativecommons.org/licenses/by/4.0/"}