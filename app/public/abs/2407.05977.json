{"id":"2407.05977","title":"Exploring Human-LLM Conversations: Mental Models and the Originator of\n  Toxicity","authors":"Johannes Schneider, Arianna Casanova Flores, Anne-Catherine Kranz","authorsParsed":[["Schneider","Johannes",""],["Flores","Arianna Casanova",""],["Kranz","Anne-Catherine",""]],"versions":[{"version":"v1","created":"Mon, 8 Jul 2024 14:20:05 GMT"}],"updateDate":"2024-07-09","timestamp":1720448405000,"abstract":"  This study explores real-world human interactions with large language models\n(LLMs) in diverse, unconstrained settings in contrast to most prior research\nfocusing on ethically trimmed models like ChatGPT for specific tasks. We aim to\nunderstand the originator of toxicity. Our findings show that although LLMs are\nrightfully accused of providing toxic content, it is mostly demanded or at\nleast provoked by humans who actively seek such content. Our manual analysis of\nhundreds of conversations judged as toxic by APIs commercial vendors, also\nraises questions with respect to current practices of what user requests are\nrefused to answer. Furthermore, we conjecture based on multiple empirical\nindicators that humans exhibit a change of their mental model, switching from\nthe mindset of interacting with a machine more towards interacting with a\nhuman.\n","subjects":["Computing Research Repository/Human-Computer Interaction","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/"}