{"id":"2408.08461","title":"TEXTOC: Text-driven Object-Centric Style Transfer","authors":"Jihun Park, Jongmin Gim, Kyoungmin Lee, Seunghun Lee and Sunghoon Im","authorsParsed":[["Park","Jihun",""],["Gim","Jongmin",""],["Lee","Kyoungmin",""],["Lee","Seunghun",""],["Im","Sunghoon",""]],"versions":[{"version":"v1","created":"Fri, 16 Aug 2024 00:05:16 GMT"},{"version":"v2","created":"Thu, 22 Aug 2024 04:49:23 GMT"}],"updateDate":"2024-08-26","timestamp":1723766716000,"abstract":"  We present Text-driven Object-Centric Style Transfer (TEXTOC), a novel method\nthat guides style transfer at an object-centric level using textual inputs. The\ncore of TEXTOC is our Patch-wise Co-Directional (PCD) loss, meticulously\ndesigned for precise object-centric transformations that are closely aligned\nwith the input text. This loss combines a patch directional loss for\ntext-guided style direction and a patch distribution consistency loss for even\nCLIP embedding distribution across object regions. It ensures a seamless and\nharmonious style transfer across object regions. Key to our method are the\nText-Matched Patch Selection (TMPS) and Pre-fixed Region Selection (PRS)\nmodules for identifying object locations via text, eliminating the need for\nsegmentation masks. Lastly, we introduce an Adaptive Background Preservation\n(ABP) loss to maintain the original style and structural essence of the image's\nbackground. This loss is applied to dynamically identified background areas.\nExtensive experiments underline the effectiveness of our approach in creating\nvisually coherent and textually aligned style transfers.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}