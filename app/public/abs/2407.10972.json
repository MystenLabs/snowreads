{"id":"2407.10972","title":"VGBench: Evaluating Large Language Models on Vector Graphics\n  Understanding and Generation","authors":"Bocheng Zou, Mu Cai, Jianrui Zhang, Yong Jae Lee","authorsParsed":[["Zou","Bocheng",""],["Cai","Mu",""],["Zhang","Jianrui",""],["Lee","Yong Jae",""]],"versions":[{"version":"v1","created":"Mon, 15 Jul 2024 17:59:55 GMT"},{"version":"v2","created":"Thu, 29 Aug 2024 17:55:52 GMT"}],"updateDate":"2024-08-30","timestamp":1721066395000,"abstract":"  In the realm of vision models, the primary mode of representation is using\npixels to rasterize the visual world. Yet this is not always the best or unique\nway to represent visual content, especially for designers and artists who\ndepict the world using geometry primitives such as polygons. Vector graphics\n(VG), on the other hand, offer a textual representation of visual content,\nwhich can be more concise and powerful for content like cartoons, sketches and\nscientific figures. Recent studies have shown promising results on processing\nvector graphics with capable Large Language Models (LLMs). However, such works\nfocus solely on qualitative results, understanding, or a specific type of\nvector graphics. We propose VGBench, a comprehensive benchmark for LLMs on\nhandling vector graphics through diverse aspects, including (a) both visual\nunderstanding and generation, (b) evaluation of various vector graphics\nformats, (c) diverse question types, (d) wide range of prompting techniques,\n(e) under multiple LLMs and (f) comparison with VLMs on rasterized\nrepresentations. Evaluating on our collected 4279 understanding and 5845\ngeneration samples, we find that LLMs show strong capability on both aspects\nwhile exhibiting less desirable performance on low-level formats (SVG). Both\ndata and evaluation pipeline will be open-sourced at https://vgbench.github.io.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"jXjBPUEY0cBWzRO1C7gjPmJeqcvTmp3To0Jvj4Igx2Y","pdfSize":"1510087"}
