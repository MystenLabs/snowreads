{"id":"2408.17347","title":"LSMS: Language-guided Scale-aware MedSegmentor for Medical Image\n  Referring Segmentation","authors":"Shuyi Ouyang, Jinyang Zhang, Xiangye Lin, Xilai Wang, Qingqing Chen,\n  Yen-Wei Chen, Lanfen Lin","authorsParsed":[["Ouyang","Shuyi",""],["Zhang","Jinyang",""],["Lin","Xiangye",""],["Wang","Xilai",""],["Chen","Qingqing",""],["Chen","Yen-Wei",""],["Lin","Lanfen",""]],"versions":[{"version":"v1","created":"Fri, 30 Aug 2024 15:22:13 GMT"},{"version":"v2","created":"Mon, 2 Sep 2024 16:08:32 GMT"}],"updateDate":"2024-09-04","timestamp":1725031333000,"abstract":"  Conventional medical image segmentation methods have been found inadequate in\nfacilitating physicians with the identification of specific lesions for\ndiagnosis and treatment. Given the utility of text as an instructional format,\nwe introduce a novel task termed Medical Image Referring Segmentation (MIRS),\nwhich requires segmenting specified lesions in images based on the given\nlanguage expressions. Due to the varying object scales in medical images, MIRS\ndemands robust vision-language modeling and comprehensive multi-scale\ninteraction for precise localization and segmentation under linguistic\nguidance. However, existing medical image segmentation methods fall short in\nmeeting these demands, resulting in insufficient segmentation accuracy. In\nresponse, we propose an approach named Language-guided Scale-aware MedSegmentor\n(LSMS), incorporating two appealing designs: (1)~a Scale-aware Vision-Language\nAttention module that leverages diverse convolutional kernels to acquire rich\nvisual knowledge and interact closely with linguistic features, thereby\nenhancing lesion localization capability; (2)~a Full-Scale Decoder that\nglobally models multi-modal features across various scales, capturing\ncomplementary information between scales to accurately outline lesion\nboundaries. Addressing the lack of suitable datasets for MIRS, we constructed a\nvision-language medical dataset called Reference Hepatic Lesion Segmentation\n(RefHL-Seg). This dataset comprises 2,283 abdominal CT slices from 231 cases,\nwith corresponding textual annotations and segmentation masks for various liver\nlesions in images. We validated the performance of LSMS for MIRS and\nconventional medical image segmentation tasks across various datasets. Our LSMS\nconsistently outperforms on all datasets with lower computational costs. The\ncode and datasets will be released.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}