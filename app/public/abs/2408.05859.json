{"id":"2408.05859","title":"The Cognitive Revolution in Interpretability: From Explaining Behavior\n  to Interpreting Representations and Algorithms","authors":"Adam Davies, Ashkan Khakzar","authorsParsed":[["Davies","Adam",""],["Khakzar","Ashkan",""]],"versions":[{"version":"v1","created":"Sun, 11 Aug 2024 20:50:16 GMT"}],"updateDate":"2024-08-13","timestamp":1723409416000,"abstract":"  Artificial neural networks have long been understood as \"black boxes\": though\nwe know their computation graphs and learned parameters, the knowledge encoded\nby these weights and functions they perform are not inherently interpretable.\nAs such, from the early days of deep learning, there have been efforts to\nexplain these models' behavior and understand them internally; and recently,\nmechanistic interpretability (MI) has emerged as a distinct research area\nstudying the features and implicit algorithms learned by foundation models such\nas large language models. In this work, we aim to ground MI in the context of\ncognitive science, which has long struggled with analogous questions in\nstudying and explaining the behavior of \"black box\" intelligent systems like\nthe human brain. We leverage several important ideas and developments in the\nhistory of cognitive science to disentangle divergent objectives in MI and\nindicate a clear path forward. First, we argue that current methods are ripe to\nfacilitate a transition in deep learning interpretation echoing the \"cognitive\nrevolution\" in 20th-century psychology that shifted the study of human\npsychology from pure behaviorism toward mental representations and processing.\nSecond, we propose a taxonomy mirroring key parallels in computational\nneuroscience to describe two broad categories of MI research, semantic\ninterpretation (what latent representations are learned and used) and\nalgorithmic interpretation (what operations are performed over representations)\nto elucidate their divergent goals and objects of study. Finally, we elaborate\nthe parallels and distinctions between various approaches in both categories,\nanalyze the respective strengths and weaknesses of representative works,\nclarify underlying assumptions, outline key challenges, and discuss the\npossibility of unifying these modes of interpretation under a common framework.\n","subjects":["Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}