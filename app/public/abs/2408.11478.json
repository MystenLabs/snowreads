{"id":"2408.11478","title":"LAKD-Activation Mapping Distillation Based on Local Learning","authors":"Yaoze Zhang and Yuming Zhang and Yu Zhao and Yue Zhang and Feiyu Zhu","authorsParsed":[["Zhang","Yaoze",""],["Zhang","Yuming",""],["Zhao","Yu",""],["Zhang","Yue",""],["Zhu","Feiyu",""]],"versions":[{"version":"v1","created":"Wed, 21 Aug 2024 09:43:27 GMT"},{"version":"v2","created":"Thu, 22 Aug 2024 04:29:58 GMT"}],"updateDate":"2024-08-23","timestamp":1724233407000,"abstract":"  Knowledge distillation is widely applied in various fundamental vision models\nto enhance the performance of compact models. Existing knowledge distillation\nmethods focus on designing different distillation targets to acquire knowledge\nfrom teacher models. However, these methods often overlook the efficient\nutilization of distilled information, crudely coupling different types of\ninformation, making it difficult to explain how the knowledge from the teacher\nnetwork aids the student network in learning. This paper proposes a novel\nknowledge distillation framework, Local Attention Knowledge Distillation\n(LAKD), which more efficiently utilizes the distilled information from teacher\nnetworks, achieving higher interpretability and competitive performance. The\nframework establishes an independent interactive training mechanism through a\nseparation-decoupling mechanism and non-directional activation mapping. LAKD\ndecouples the teacher's features and facilitates progressive interaction\ntraining from simple to complex. Specifically, the student network is divided\ninto local modules with independent gradients to decouple the knowledge\ntransferred from the teacher. The non-directional activation mapping helps the\nstudent network integrate knowledge from different local modules by learning\ncoarse-grained feature knowledge. We conducted experiments on the CIFAR-10,\nCIFAR-100, and ImageNet datasets, and the results show that our LAKD method\nsignificantly outperforms existing methods, consistently achieving\nstate-of-the-art performance across different datasets.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}