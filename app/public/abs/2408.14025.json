{"id":"2408.14025","title":"An Item Response Theory-based R Module for Algorithm Portfolio Analysis","authors":"Brodie Oldfield, Sevvandi Kandanaarachchi, Ziqi Xu, Mario Andr\\'es\n  Mu\\~noz","authorsParsed":[["Oldfield","Brodie",""],["Kandanaarachchi","Sevvandi",""],["Xu","Ziqi",""],["Muñoz","Mario Andrés",""]],"versions":[{"version":"v1","created":"Mon, 26 Aug 2024 05:31:46 GMT"},{"version":"v2","created":"Tue, 27 Aug 2024 04:36:52 GMT"}],"updateDate":"2024-08-28","timestamp":1724650306000,"abstract":"  Experimental evaluation is crucial in AI research, especially for assessing\nalgorithms across diverse tasks. Many studies often evaluate a limited set of\nalgorithms, failing to fully understand their strengths and weaknesses within a\ncomprehensive portfolio. This paper introduces an Item Response Theory (IRT)\nbased analysis tool for algorithm portfolio evaluation called AIRT-Module.\nTraditionally used in educational psychometrics, IRT models test question\ndifficulty and student ability using responses to test questions. Adapting IRT\nto algorithm evaluation, the AIRT-Module contains a Shiny web application and\nthe R package airt. AIRT-Module uses algorithm performance measures to compute\nanomalousness, consistency, and difficulty limits for an algorithm and the\ndifficulty of test instances. The strengths and weaknesses of algorithms are\nvisualised using the difficulty spectrum of the test instances. AIRT-Module\noffers a detailed understanding of algorithm capabilities across varied test\ninstances, thus enhancing comprehensive AI method assessment. It is available\nat https://sevvandi.shinyapps.io/AIRT/ .\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"yF3DVEDp5CBMrI0M454jWMarZWjtfpJshA42K_66COU","pdfSize":"485795"}
