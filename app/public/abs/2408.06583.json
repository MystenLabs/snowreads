{"id":"2408.06583","title":"A Structure-aware Generative Model for Biomedical Event Extraction","authors":"Haohan Yuan, Siu Cheung Hui, Haopeng Zhang","authorsParsed":[["Yuan","Haohan",""],["Hui","Siu Cheung",""],["Zhang","Haopeng",""]],"versions":[{"version":"v1","created":"Tue, 13 Aug 2024 02:43:19 GMT"},{"version":"v2","created":"Wed, 14 Aug 2024 15:44:07 GMT"},{"version":"v3","created":"Thu, 15 Aug 2024 15:24:10 GMT"},{"version":"v4","created":"Tue, 20 Aug 2024 04:32:37 GMT"}],"updateDate":"2024-08-21","timestamp":1723516999000,"abstract":"  Biomedical Event Extraction (BEE) is a challenging task that involves\nmodeling complex relationships between fine-grained entities in biomedical\ntext. BEE has traditionally been formulated as a classification problem. With\nthe recent technological advancements in large language models (LLMs),\ngeneration-based models that cast event extraction as a sequence generation\nproblem have attracted much attention from the NLP research communities.\nHowever, current generative models often overlook the importance of\ncross-instance information from complex event structures such as nested events\nand overlapping events, which contribute to over 20% of the events in the\nbenchmark datasets. In this paper, we propose an event structure-aware\ngenerative model named GenBEE, which can capture complex event structures in\nbiomedical text for biomedical event extraction. In particular, GenBEE\nconstructs event prompts that distill knowledge from LLMs for incorporating\nboth label semantics and argument dependency relationships into the proposed\nmodel. In addition, GenBEE also generates prefixes with event structural\nprompts to incorporate structural features for improving the model's overall\nperformance. We have evaluated the proposed GenBEE model on three widely used\nbiomedical event extraction benchmark datasets, namely MLEE, GE11, and PHEE.\nExperimental results show that GenBEE has achieved state-of-the-art performance\non the MLEE and GE11 datasets, and achieved competitive results when compared\nto the state-of-the-art classification-based models on the PHEE dataset.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}