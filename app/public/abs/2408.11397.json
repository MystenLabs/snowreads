{"id":"2408.11397","title":"EAGLE: Elevating Geometric Reasoning through LLM-empowered Visual\n  Instruction Tuning","authors":"Zhihao Li, Yao Du, Yang Liu, Yan Zhang, Yufang Liu, Mengdi Zhang,\n  Xunliang Cai","authorsParsed":[["Li","Zhihao",""],["Du","Yao",""],["Liu","Yang",""],["Zhang","Yan",""],["Liu","Yufang",""],["Zhang","Mengdi",""],["Cai","Xunliang",""]],"versions":[{"version":"v1","created":"Wed, 21 Aug 2024 07:43:50 GMT"}],"updateDate":"2024-08-22","timestamp":1724226230000,"abstract":"  Multi-modal Large Language Models have recently experienced rapid\ndevelopments and excel in various multi-modal tasks. However, they still\nstruggle with mathematical geometric problem solving, which requires\nexceptional visual perception proficiency. Existing MLLMs mostly optimize the\nLLM backbone to acquire geometric reasoning capabilities, while rarely\nemphasizing improvements in visual comprehension. In this paper, we first\ninvestigate the visual perception performance of MLLMs when facing geometric\ndiagrams. Our findings reveal that current MLLMs severely suffer from\ninaccurate geometric perception and hallucinations. To address these\nlimitations, we propose EAGLE, a novel two-stage end-to-end visual enhancement\nMLLM framework designed to ElevAte Geometric reasoning through LLM-Empowered\nvisual instruction tuning. Specifically, in the preliminary stage, we feed\ngeometric image-caption pairs into our MLLM that contains a fully fine-tuning\nCLIP ViT and a frozen LLM, aiming to endow our model with basic geometric\nknowledge. In the subsequent advanced stage, we incorporate LoRA modules into\nthe vision encoder and unfreeze the LLM backbone. This enables the model to\nleverage the inherent CoT rationales within question-answer pairs, guiding the\nMLLM to focus on nuanced visual cues and enhancing its overall perceptual\ncapacity. Moreover, we optimize the cross-modal projector in both stages to\nfoster adaptive visual-linguistic alignments. After the two-stage visual\nenhancement, we develop the geometry expert model EAGLE-7B. Extensive\nexperiments on popular benchmarks demonstrate the effectiveness of our model.\nFor example, on the GeoQA benchmark, EAGLE-7B not only surpasses the exemplary\nG-LLaVA 7B model by 2.9%, but also marginally outperforms the larger G-LLaVA\n13B model. On the MathVista benchmark, EAGLE-7B achieves remarkable 3.8%\nimprovements compared with the proprietary model GPT-4V.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}