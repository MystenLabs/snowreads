{"id":"2407.13660","title":"CogniVoice: Multimodal and Multilingual Fusion Networks for Mild\n  Cognitive Impairment Assessment from Spontaneous Speech","authors":"Jiali Cheng, Mohamed Elgaar, Nidhi Vakil, Hadi Amiri","authorsParsed":[["Cheng","Jiali",""],["Elgaar","Mohamed",""],["Vakil","Nidhi",""],["Amiri","Hadi",""]],"versions":[{"version":"v1","created":"Thu, 18 Jul 2024 16:38:24 GMT"}],"updateDate":"2024-07-19","timestamp":1721320704000,"abstract":"  Mild Cognitive Impairment (MCI) is a medical condition characterized by\nnoticeable declines in memory and cognitive abilities, potentially affecting\nindividual's daily activities. In this paper, we introduce CogniVoice, a novel\nmultilingual and multimodal framework to detect MCI and estimate Mini-Mental\nState Examination (MMSE) scores by analyzing speech data and its textual\ntranscriptions. The key component of CogniVoice is an ensemble multimodal and\nmultilingual network based on ``Product of Experts'' that mitigates reliance on\nshortcut solutions. Using a comprehensive dataset containing both English and\nChinese languages from TAUKADIAL challenge, CogniVoice outperforms the best\nperforming baseline model on MCI classification and MMSE regression tasks by\n2.8 and 4.1 points in F1 and RMSE respectively, and can effectively reduce the\nperformance gap across different language groups by 0.7 points in F1.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Sound","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/"}