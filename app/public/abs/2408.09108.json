{"id":"2408.09108","title":"Temporal Reversed Training for Spiking Neural Networks with Generalized\n  Spatio-Temporal Representation","authors":"Lin Zuo, Yongqi Ding, Wenwei Luo, Mengmeng Jing, Xianlong Tian,\n  Kunshan Yang","authorsParsed":[["Zuo","Lin",""],["Ding","Yongqi",""],["Luo","Wenwei",""],["Jing","Mengmeng",""],["Tian","Xianlong",""],["Yang","Kunshan",""]],"versions":[{"version":"v1","created":"Sat, 17 Aug 2024 06:23:38 GMT"}],"updateDate":"2024-08-20","timestamp":1723875818000,"abstract":"  Spiking neural networks (SNNs) have received widespread attention as an\nultra-low energy computing paradigm. Recent studies have focused on improving\nthe feature extraction capability of SNNs, but they suffer from inefficient\ninference and suboptimal performance. In this paper, we propose a simple yet\neffective temporal reversed training (TRT) method to optimize the\nspatio-temporal performance of SNNs and circumvent these problems. We perturb\nthe input temporal data by temporal reversal, prompting the SNN to produce\noriginal-reversed consistent output logits and to learn perturbation-invariant\nrepresentations. For static data without temporal dimension, we generalize this\nstrategy by exploiting the inherent temporal property of spiking neurons for\nspike feature temporal reversal. In addition, we utilize the lightweight ``star\noperation\" (element-wise multiplication) to hybridize the original and\ntemporally reversed spike firing rates and expand the implicit dimensions,\nwhich serves as spatio-temporal regularization to further enhance the\ngeneralization of the SNN. Our method involves only an additional temporal\nreversal operation and element-wise multiplication during training, thus\nincurring negligible training overhead and not affecting the inference\nefficiency at all. Extensive experiments on static/neuromorphic object/action\nrecognition, and 3D point cloud classification tasks demonstrate the\neffectiveness and generalizability of our method. In particular, with only two\ntimesteps, our method achieves 74.77\\% and 90.57\\% accuracy on ImageNet and\nModelNet40, respectively.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/"}