{"id":"2408.04842","title":"Counterfactual Explanations with Probabilistic Guarantees on their\n  Robustness to Model Change","authors":"Ignacy St\\k{e}pka, Mateusz Lango, Jerzy Stefanowski","authorsParsed":[["StÄ™pka","Ignacy",""],["Lango","Mateusz",""],["Stefanowski","Jerzy",""]],"versions":[{"version":"v1","created":"Fri, 9 Aug 2024 03:35:53 GMT"}],"updateDate":"2024-08-12","timestamp":1723174553000,"abstract":"  Counterfactual explanations (CFEs) guide users on how to adjust inputs to\nmachine learning models to achieve desired outputs. While existing research\nprimarily addresses static scenarios, real-world applications often involve\ndata or model changes, potentially invalidating previously generated CFEs and\nrendering user-induced input changes ineffective. Current methods addressing\nthis issue often support only specific models or change types, require\nextensive hyperparameter tuning, or fail to provide probabilistic guarantees on\nCFE robustness to model changes. This paper proposes a novel approach for\ngenerating CFEs that provides probabilistic guarantees for any model and change\ntype, while offering interpretable and easy-to-select hyperparameters. We\nestablish a theoretical framework for probabilistically defining robustness to\nmodel change and demonstrate how our BetaRCE method directly stems from it.\nBetaRCE is a post-hoc method applied alongside a chosen base CFE generation\nmethod to enhance the quality of the explanation beyond robustness. It\nfacilitates a transition from the base explanation to a more robust one with\nuser-adjusted probability bounds. Through experimental comparisons with\nbaselines, we show that BetaRCE yields robust, most plausible, and closest to\nbaseline counterfactual explanations.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/"}