{"id":"2407.13553","title":"SAM-Driven Weakly Supervised Nodule Segmentation with Uncertainty-Aware\n  Cross Teaching","authors":"Xingyue Zhao, Peiqi Li, Xiangde Luo, Meng Yang, Shi Chang, Zhongyu Li","authorsParsed":[["Zhao","Xingyue",""],["Li","Peiqi",""],["Luo","Xiangde",""],["Yang","Meng",""],["Chang","Shi",""],["Li","Zhongyu",""]],"versions":[{"version":"v1","created":"Thu, 18 Jul 2024 14:27:54 GMT"}],"updateDate":"2024-07-19","timestamp":1721312874000,"abstract":"  Automated nodule segmentation is essential for computer-assisted diagnosis in\nultrasound images. Nevertheless, most existing methods depend on precise\npixel-level annotations by medical professionals, a process that is both costly\nand labor-intensive. Recently, segmentation foundation models like SAM have\nshown impressive generalizability on natural images, suggesting their potential\nas pseudo-labelers. However, accurate prompts remain crucial for their success\nin medical images. In this work, we devise a novel weakly supervised framework\nthat effectively utilizes the segmentation foundation model to generate\npseudo-labels from aspect ration annotations for automatic nodule segmentation.\nSpecifically, we develop three types of bounding box prompts based on scalable\nshape priors, followed by an adaptive pseudo-label selection module to fully\nexploit the prediction capabilities of the foundation model for nodules. We\nalso present a SAM-driven uncertainty-aware cross-teaching strategy. This\napproach integrates SAM-based uncertainty estimation and label-space\nperturbations into cross-teaching to mitigate the impact of pseudo-label\ninaccuracies on model training. Extensive experiments on two clinically\ncollected ultrasound datasets demonstrate the superior performance of our\nproposed method.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}