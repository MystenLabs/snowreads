{"id":"2408.14864","title":"Dynamic operator management in meta-heuristics using reinforcement\n  learning: an application to permutation flowshop scheduling problems","authors":"Maryam Karimi Mamaghan, Mehrdad Mohammadi, Wout Dullaert, Daniele\n  Vigo, Amir Pirayesh","authorsParsed":[["Mamaghan","Maryam Karimi",""],["Mohammadi","Mehrdad",""],["Dullaert","Wout",""],["Vigo","Daniele",""],["Pirayesh","Amir",""]],"versions":[{"version":"v1","created":"Tue, 27 Aug 2024 08:38:17 GMT"}],"updateDate":"2024-08-28","timestamp":1724747897000,"abstract":"  This study develops a framework based on reinforcement learning to\ndynamically manage a large portfolio of search operators within\nmeta-heuristics. Using the idea of tabu search, the framework allows for\ncontinuous adaptation by temporarily excluding less efficient operators and\nupdating the portfolio composition during the search. A Q-learning-based\nadaptive operator selection mechanism is used to select the most suitable\noperator from the dynamically updated portfolio at each stage. Unlike\ntraditional approaches, the proposed framework requires no input from the\nexperts regarding the search operators, allowing domain-specific non-experts to\neffectively use the framework. The performance of the proposed framework is\nanalyzed through an application to the permutation flowshop scheduling problem.\nThe results demonstrate the superior performance of the proposed framework\nagainst state-of-the-art algorithms in terms of optimality gap and convergence\nspeed.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"xdygMVOO09AeZzZ6kSO1LDQYkJOa9Nr9JOdJaTNP7lw","pdfSize":"2728774"}
