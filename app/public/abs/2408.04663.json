{"id":"2408.04663","title":"Dopamin: Transformer-based Comment Classifiers through Domain\n  Post-Training and Multi-level Layer Aggregation","authors":"Nam Le Hai and Nghi D. Q. Bui","authorsParsed":[["Hai","Nam Le",""],["Bui","Nghi D. Q.",""]],"versions":[{"version":"v1","created":"Tue, 6 Aug 2024 08:08:43 GMT"}],"updateDate":"2024-08-12","timestamp":1722931723000,"abstract":"  Code comments provide important information for understanding the source\ncode. They can help developers understand the overall purpose of a function or\nclass, as well as identify bugs and technical debt. However, an overabundance\nof comments is meaningless and counterproductive. As a result, it is critical\nto automatically filter out these comments for specific purposes. In this\npaper, we present Dopamin, a Transformer-based tool for dealing with this\nissue. Our model excels not only in presenting knowledge sharing of common\ncategories across multiple languages, but also in achieving robust performance\nin comment classification by improving comment representation. As a result, it\noutperforms the STACC baseline by 3% on the NLBSE'24 Tool Competition dataset\nin terms of average F1-score, while maintaining a comparable inference time for\npractical use. The source code is publicity available at\nhttps://github.com/FSoft-AI4Code/Dopamin.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by-sa/4.0/"}