{"id":"2407.13520","title":"EaDeblur-GS: Event assisted 3D Deblur Reconstruction with Gaussian\n  Splatting","authors":"Yuchen Weng, Zhengwen Shen, Ruofan Chen, Qi Wang and Jun Wang","authorsParsed":[["Weng","Yuchen",""],["Shen","Zhengwen",""],["Chen","Ruofan",""],["Wang","Qi",""],["Wang","Jun",""]],"versions":[{"version":"v1","created":"Thu, 18 Jul 2024 13:55:54 GMT"},{"version":"v2","created":"Thu, 29 Aug 2024 02:52:46 GMT"},{"version":"v3","created":"Thu, 5 Sep 2024 13:16:23 GMT"}],"updateDate":"2024-09-06","timestamp":1721310954000,"abstract":"  3D deblurring reconstruction techniques have recently seen significant\nadvancements with the development of Neural Radiance Fields (NeRF) and 3D\nGaussian Splatting (3DGS). Although these techniques can recover relatively\nclear 3D reconstructions from blurry image inputs, they still face limitations\nin handling severe blurring and complex camera motion. To address these issues,\nwe propose Event-assisted 3D Deblur Reconstruction with Gaussian Splatting\n(EaDeblur-GS), which integrates event camera data to enhance the robustness of\n3DGS against motion blur. By employing an Adaptive Deviation Estimator (ADE)\nnetwork to estimate Gaussian center deviations and using novel loss functions,\nEaDeblur-GS achieves sharp 3D reconstructions in real-time, demonstrating\nperformance comparable to state-of-the-art methods.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}