{"id":"2407.08811","title":"CXR-Agent: Vision-language models for chest X-ray interpretation with\n  uncertainty aware radiology reporting","authors":"Naman Sharma","authorsParsed":[["Sharma","Naman",""]],"versions":[{"version":"v1","created":"Thu, 11 Jul 2024 18:39:19 GMT"}],"updateDate":"2024-07-15","timestamp":1720723159000,"abstract":"  Recently large vision-language models have shown potential when interpreting\ncomplex images and generating natural language descriptions using advanced\nreasoning. Medicine's inherently multimodal nature incorporating scans and\ntext-based medical histories to write reports makes it conducive to benefit\nfrom these leaps in AI capabilities. We evaluate the publicly available, state\nof the art, foundational vision-language models for chest X-ray interpretation\nacross several datasets and benchmarks. We use linear probes to evaluate the\nperformance of various components including CheXagent's vision transformer and\nQ-former, which outperform the industry-standard Torch X-ray Vision models\nacross many different datasets showing robust generalisation capabilities.\nImportantly, we find that vision-language models often hallucinate with\nconfident language, which slows down clinical interpretation. Based on these\nfindings, we develop an agent-based vision-language approach for report\ngeneration using CheXagent's linear probes and BioViL-T's phrase grounding\ntools to generate uncertainty-aware radiology reports with pathologies\nlocalised and described based on their likelihood. We thoroughly evaluate our\nvision-language agents using NLP metrics, chest X-ray benchmarks and clinical\nevaluations by developing an evaluation platform to perform a user study with\nrespiratory specialists. Our results show considerable improvements in\naccuracy, interpretability and safety of the AI-generated reports. We stress\nthe importance of analysing results for normal and abnormal scans separately.\nFinally, we emphasise the need for larger paired (scan and report) datasets\nalongside data augmentation to tackle overfitting seen in these large\nvision-language models.\n","subjects":["Electrical Engineering and Systems Science/Image and Video Processing","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"57t1jkusT4sgzSsHdw21bI5lTR6V6IwOUhjMwY3LvHM","pdfSize":"2044065"}
