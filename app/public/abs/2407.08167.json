{"id":"2407.08167","title":"DSCENet: Dynamic Screening and Clinical-Enhanced Multimodal Fusion for\n  MPNs Subtype Classification","authors":"Yuan Zhang, Yaolei Qi, Xiaoming Qi, Yongyue Wei, Guanyu Yang","authorsParsed":[["Zhang","Yuan",""],["Qi","Yaolei",""],["Qi","Xiaoming",""],["Wei","Yongyue",""],["Yang","Guanyu",""]],"versions":[{"version":"v1","created":"Thu, 11 Jul 2024 04:13:58 GMT"}],"updateDate":"2024-07-12","timestamp":1720671238000,"abstract":"  The precise subtype classification of myeloproliferative neoplasms (MPNs)\nbased on multimodal information, which assists clinicians in diagnosis and\nlong-term treatment plans, is of great clinical significance. However, it\nremains a great challenging task due to the lack of diagnostic\nrepresentativeness for local patches and the absence of diagnostic-relevant\nfeatures from a single modality. In this paper, we propose a Dynamic Screening\nand Clinical-Enhanced Network (DSCENet) for the subtype classification of MPNs\non the multimodal fusion of whole slide images (WSIs) and clinical information.\n(1) A dynamic screening module is proposed to flexibly adapt the feature\nlearning of local patches, reducing the interference of irrelevant features and\nenhancing their diagnostic representativeness. (2) A clinical-enhanced fusion\nmodule is proposed to integrate clinical indicators to explore complementary\nfeatures across modalities, providing comprehensive diagnostic information. Our\napproach has been validated on the real clinical data, achieving an increase of\n7.91% AUC and 16.89% accuracy compared with the previous state-of-the-art\n(SOTA) methods. The code is available at https://github.com/yuanzhang7/DSCENet.\n","subjects":["Electrical Engineering and Systems Science/Image and Video Processing","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}