{"id":"2407.07850","title":"Harnessing Integrated CPU-GPU System Memory for HPC: a first look into\n  Grace Hopper","authors":"Gabin Schieffer, Jacob Wahlgren, Jie Ren, Jennifer Faj, Ivy Peng","authorsParsed":[["Schieffer","Gabin",""],["Wahlgren","Jacob",""],["Ren","Jie",""],["Faj","Jennifer",""],["Peng","Ivy",""]],"versions":[{"version":"v1","created":"Wed, 10 Jul 2024 17:12:57 GMT"}],"updateDate":"2024-07-11","timestamp":1720631577000,"abstract":"  Memory management across discrete CPU and GPU physical memory is\ntraditionally achieved through explicit GPU allocations and data copy or\nunified virtual memory. The Grace Hopper Superchip, for the first time,\nsupports an integrated CPU-GPU system page table, hardware-level addressing of\nsystem allocated memory, and cache-coherent NVLink-C2C interconnect, bringing\nan alternative solution for enabling a Unified Memory system. In this work, we\nprovide the first in-depth study of the system memory management on the Grace\nHopper Superchip, in both in-memory and memory oversubscription scenarios. We\nprovide a suite of six representative applications, including the Qiskit\nquantum computing simulator, using system memory and managed memory. Using our\nmemory utilization profiler and hardware counters, we quantify and characterize\nthe impact of the integrated CPU-GPU system page table on GPU applications. Our\nstudy focuses on first-touch policy, page table entry initialization, page\nsizes, and page migration. We identify practical optimization strategies for\ndifferent access patterns. Our results show that as a new solution for unified\nmemory, the system-allocated memory can benefit most use cases with minimal\nporting efforts.\n","subjects":["Computing Research Repository/Distributed, Parallel, and Cluster Computing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}