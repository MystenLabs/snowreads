{"id":"2408.02651","title":"Can Reinforcement Learning Unlock the Hidden Dangers in Aligned Large\n  Language Models?","authors":"Mohammad Bahrami Karkevandi, Nishant Vishwamitra, Peyman Najafirad","authorsParsed":[["Karkevandi","Mohammad Bahrami",""],["Vishwamitra","Nishant",""],["Najafirad","Peyman",""]],"versions":[{"version":"v1","created":"Mon, 5 Aug 2024 17:27:29 GMT"}],"updateDate":"2024-08-06","timestamp":1722878849000,"abstract":"  Large Language Models (LLMs) have demonstrated impressive capabilities in\nnatural language tasks, but their safety and morality remain contentious due to\ntheir training on internet text corpora. To address these concerns, alignment\ntechniques have been developed to improve the public usability and safety of\nLLMs. Yet, the potential for generating harmful content through these models\nseems to persist. This paper explores the concept of jailbreaking\nLLMs-reversing their alignment through adversarial triggers. Previous methods,\nsuch as soft embedding prompts, manually crafted prompts, and gradient-based\nautomatic prompts, have had limited success on black-box models due to their\nrequirements for model access and for producing a low variety of manually\ncrafted prompts, making them susceptible to being blocked. This paper\nintroduces a novel approach using reinforcement learning to optimize\nadversarial triggers, requiring only inference API access to the target model\nand a small surrogate model. Our method, which leverages a BERTScore-based\nreward function, enhances the transferability and effectiveness of adversarial\ntriggers on new black-box models. We demonstrate that this approach improves\nthe performance of adversarial triggers on a previously untested language\nmodel.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Cryptography and Security"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"d1muCEFNO55MdCPCB6Lj9pFoU8X3p5zGH4M9A5DLHBY","pdfSize":"676538"}
