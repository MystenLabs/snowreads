{"id":"2408.11680","title":"First line of defense: A robust first layer mitigates adversarial\n  attacks","authors":"Janani Suresh, Nancy Nayak, and Sheetal Kalyani","authorsParsed":[["Suresh","Janani",""],["Nayak","Nancy",""],["Kalyani","Sheetal",""]],"versions":[{"version":"v1","created":"Wed, 21 Aug 2024 15:00:16 GMT"}],"updateDate":"2024-08-22","timestamp":1724252416000,"abstract":"  Adversarial training (AT) incurs significant computational overhead, leading\nto growing interest in designing inherently robust architectures. We\ndemonstrate that a carefully designed first layer of the neural network can\nserve as an implicit adversarial noise filter (ANF). This filter is created\nusing a combination of large kernel size, increased convolution filters, and a\nmaxpool operation. We show that integrating this filter as the first layer in\narchitectures such as ResNet, VGG, and EfficientNet results in adversarially\nrobust networks. Our approach achieves higher adversarial accuracies than\nexisting natively robust architectures without AT and is competitive with\nadversarial-trained architectures across a wide range of datasets. Supporting\nour findings, we show that (a) the decision regions for our method have better\nmargins, (b) the visualized loss surfaces are smoother, (c) the modified peak\nsignal-to-noise ratio (mPSNR) values at the output of the ANF are higher, (d)\nhigh-frequency components are more attenuated, and (e) architectures\nincorporating ANF exhibit better denoising in Gaussian noise compared to\nbaseline architectures. Code for all our experiments are available at\n\\url{https://github.com/janani-suresh-97/first-line-defence.git}.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}