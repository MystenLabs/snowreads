{"id":"2407.04382","title":"Self-Supervised Representation Learning for Adversarial Attack Detection","authors":"Yi Li, Plamen Angelov, Neeraj Suri","authorsParsed":[["Li","Yi",""],["Angelov","Plamen",""],["Suri","Neeraj",""]],"versions":[{"version":"v1","created":"Fri, 5 Jul 2024 09:37:16 GMT"}],"updateDate":"2024-07-08","timestamp":1720172236000,"abstract":"  Supervised learning-based adversarial attack detection methods rely on a\nlarge number of labeled data and suffer significant performance degradation\nwhen applying the trained model to new domains. In this paper, we propose a\nself-supervised representation learning framework for the adversarial attack\ndetection task to address this drawback. Firstly, we map the pixels of\naugmented input images into an embedding space. Then, we employ the\nprototype-wise contrastive estimation loss to cluster prototypes as latent\nvariables. Additionally, drawing inspiration from the concept of memory banks,\nwe introduce a discrimination bank to distinguish and learn representations for\neach individual instance that shares the same or a similar prototype,\nestablishing a connection between instances and their associated prototypes. We\npropose a parallel axial-attention (PAA)-based encoder to facilitate the\ntraining process by parallel training over height- and width-axis of attention\nmaps. Experimental results show that, compared to various benchmark\nself-supervised vision learning models and supervised adversarial attack\ndetection methods, the proposed model achieves state-of-the-art performance on\nthe adversarial attack detection task across a wide range of images.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}