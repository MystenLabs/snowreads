{"id":"2407.15791","title":"RADA: Robust and Accurate Feature Learning with Domain Adaptation","authors":"Jingtai He, Gehao Zhang, Tingting Liu, Songlin Du","authorsParsed":[["He","Jingtai",""],["Zhang","Gehao",""],["Liu","Tingting",""],["Du","Songlin",""]],"versions":[{"version":"v1","created":"Mon, 22 Jul 2024 16:49:58 GMT"}],"updateDate":"2024-07-23","timestamp":1721666998000,"abstract":"  Recent advancements in keypoint detection and descriptor extraction have\nshown impressive performance in local feature learning tasks. However, existing\nmethods generally exhibit suboptimal performance under extreme conditions such\nas significant appearance changes and domain shifts. In this study, we\nintroduce a multi-level feature aggregation network that incorporates two\npivotal components to facilitate the learning of robust and accurate features\nwith domain adaptation. First, we employ domain adaptation supervision to align\nhigh-level feature distributions across different domains to achieve invariant\ndomain representations. Second, we propose a Transformer-based booster that\nenhances descriptor robustness by integrating visual and geometric information\nthrough wave position encoding concepts, effectively handling complex\nconditions. To ensure the accuracy and robustness of features, we adopt a\nhierarchical architecture to capture comprehensive information and apply\nmeticulous targeted supervision to keypoint detection, descriptor extraction,\nand their coupled processing. Extensive experiments demonstrate that our\nmethod, RADA, achieves excellent results in image matching, camera pose\nestimation, and visual localization tasks.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}