{"id":"2407.18141","title":"IRIS: Wireless Ring for Vision-based Smart Home Interaction","authors":"Maruchi Kim, Antonio Glenn, Bandhav Veluri, Yunseo Lee, Eyoel Gebre,\n  Aditya Bagaria, Shwetak Patel, Shyamnath Gollakota","authorsParsed":[["Kim","Maruchi",""],["Glenn","Antonio",""],["Veluri","Bandhav",""],["Lee","Yunseo",""],["Gebre","Eyoel",""],["Bagaria","Aditya",""],["Patel","Shwetak",""],["Gollakota","Shyamnath",""]],"versions":[{"version":"v1","created":"Thu, 25 Jul 2024 15:45:17 GMT"}],"updateDate":"2024-07-26","timestamp":1721922317000,"abstract":"  Integrating cameras into wireless smart rings has been challenging due to\nsize and power constraints. We introduce IRIS, the first wireless\nvision-enabled smart ring system for smart home interactions. Equipped with a\ncamera, Bluetooth radio, inertial measurement unit (IMU), and an onboard\nbattery, IRIS meets the small size, weight, and power (SWaP) requirements for\nring devices. IRIS is context-aware, adapting its gesture set to the detected\ndevice, and can last for 16-24 hours on a single charge. IRIS leverages the\nscene semantics to achieve instance-level device recognition. In a study\ninvolving 23 participants, IRIS consistently outpaced voice commands, with a\nhigher proportion of participants expressing a preference for IRIS over voice\ncommands regarding toggling a device's state, granular control, and social\nacceptability. Our work pushes the boundary of what is possible with ring\nform-factor devices, addressing system challenges and opening up novel\ninteraction capabilities.\n","subjects":["Computing Research Repository/Human-Computer Interaction","Computing Research Repository/Emerging Technologies","Computing Research Repository/Machine Learning","Electrical Engineering and Systems Science/Image and Video Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}