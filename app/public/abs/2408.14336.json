{"id":"2408.14336","title":"Equivariant Reinforcement Learning under Partial Observability","authors":"Hai Nguyen, Andrea Baisero, David Klee, Dian Wang, Robert Platt,\n  Christopher Amato","authorsParsed":[["Nguyen","Hai",""],["Baisero","Andrea",""],["Klee","David",""],["Wang","Dian",""],["Platt","Robert",""],["Amato","Christopher",""]],"versions":[{"version":"v1","created":"Mon, 26 Aug 2024 15:07:01 GMT"}],"updateDate":"2024-08-27","timestamp":1724684821000,"abstract":"  Incorporating inductive biases is a promising approach for tackling\nchallenging robot learning domains with sample-efficient solutions. This paper\nidentifies partially observable domains where symmetries can be a useful\ninductive bias for efficient learning. Specifically, by encoding the\nequivariance regarding specific group symmetries into the neural networks, our\nactor-critic reinforcement learning agents can reuse solutions in the past for\nrelated scenarios. Consequently, our equivariant agents outperform\nnon-equivariant approaches significantly in terms of sample efficiency and\nfinal performance, demonstrated through experiments on a range of robotic tasks\nin simulation and real hardware.\n","subjects":["Computing Research Repository/Robotics","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}