{"id":"2408.03603","title":"EnJa: Ensemble Jailbreak on Large Language Models","authors":"Jiahao Zhang, Zilong Wang, Ruofan Wang, Xingjun Ma and Yu-Gang Jiang","authorsParsed":[["Zhang","Jiahao",""],["Wang","Zilong",""],["Wang","Ruofan",""],["Ma","Xingjun",""],["Jiang","Yu-Gang",""]],"versions":[{"version":"v1","created":"Wed, 7 Aug 2024 07:46:08 GMT"}],"updateDate":"2024-08-08","timestamp":1723016768000,"abstract":"  As Large Language Models (LLMs) are increasingly being deployed in\nsafety-critical applications, their vulnerability to potential jailbreaks --\nmalicious prompts that can disable the safety mechanism of LLMs -- has\nattracted growing research attention. While alignment methods have been\nproposed to protect LLMs from jailbreaks, many have found that aligned LLMs can\nstill be jailbroken by carefully crafted malicious prompts, producing content\nthat violates policy regulations. Existing jailbreak attacks on LLMs can be\ncategorized into prompt-level methods which make up stories/logic to circumvent\nsafety alignment and token-level attack methods which leverage gradient methods\nto find adversarial tokens. In this work, we introduce the concept of Ensemble\nJailbreak and explore methods that can integrate prompt-level and token-level\njailbreak into a more powerful hybrid jailbreak attack. Specifically, we\npropose a novel EnJa attack to hide harmful instructions using prompt-level\njailbreak, boost the attack success rate using a gradient-based attack, and\nconnect the two types of jailbreak attacks via a template-based connector. We\nevaluate the effectiveness of EnJa on several aligned models and show that it\nachieves a state-of-the-art attack success rate with fewer queries and is much\nstronger than any individual jailbreak.\n","subjects":["Computing Research Repository/Cryptography and Security","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}