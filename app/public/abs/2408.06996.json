{"id":"2408.06996","title":"Blessing of Dimensionality for Approximating Sobolev Classes on\n  Manifolds","authors":"Hong Ye Tan, Subhadip Mukherjee, Junqi Tang, Carola-Bibiane\n  Sch\\\"onlieb","authorsParsed":[["Tan","Hong Ye",""],["Mukherjee","Subhadip",""],["Tang","Junqi",""],["Sch√∂nlieb","Carola-Bibiane",""]],"versions":[{"version":"v1","created":"Tue, 13 Aug 2024 15:56:42 GMT"}],"updateDate":"2024-08-14","timestamp":1723564602000,"abstract":"  The manifold hypothesis says that natural high-dimensional data is actually\nsupported on or around a low-dimensional manifold. Recent success of\nstatistical and learning-based methods empirically supports this hypothesis,\ndue to outperforming classical statistical intuition in very high dimensions. A\nnatural step for analysis is thus to assume the manifold hypothesis and derive\nbounds that are independent of any embedding space. Theoretical implications in\nthis direction have recently been explored in terms of generalization of ReLU\nnetworks and convergence of Langevin methods. We complement existing results by\nproviding theoretical statistical complexity results, which directly relates to\ngeneralization properties. In particular, we demonstrate that the statistical\ncomplexity required to approximate a class of bounded Sobolev functions on a\ncompact manifold is bounded from below, and moreover that this bound is\ndependent only on the intrinsic properties of the manifold. These provide\ncomplementary bounds for existing approximation results for ReLU networks on\nmanifolds, which give upper bounds on generalization capacity.\n","subjects":["Computing Research Repository/Machine Learning","Mathematics/Statistics Theory","Statistics/Statistics Theory"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}