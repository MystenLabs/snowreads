{"id":"2408.04678","title":"CREST: Effectively Compacting a Datastore For Retrieval-Based\n  Speculative Decoding","authors":"Sophia Ho, Jinsol Park, Patrick Wang","authorsParsed":[["Ho","Sophia",""],["Park","Jinsol",""],["Wang","Patrick",""]],"versions":[{"version":"v1","created":"Thu, 8 Aug 2024 03:38:49 GMT"}],"updateDate":"2024-08-12","timestamp":1723088329000,"abstract":"  We present CREST (Compact Retrieval-Based Speculative Decoding), a redesign\nof REST that allows it to be effectively \"compacted\". REST is a drafting\ntechnique for speculative decoding based on retrieving exact n-gram matches of\nthe most recent n tokens generated by the target LLM from a datastore. The key\nidea of CREST is to only store a subset of the smallest and most common n-grams\nin the datastore with the hope of achieving comparable performance with less\nstorage space. We found that storing a subset of n-grams both reduces storage\nspace and improves performance. CREST matches REST's accepted token length with\n10.6-13.5x less storage space and achieves a 16.5-17.1% higher acceptance\nlength than REST using the same storage space on the HumanEval and MT Bench\nbenchmarks.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Databases"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"RRf2LdrtrPRNr2G8FieW6OWUzrxsiz3Rra6_e9-CimA","pdfSize":"905024"}
