{"id":"2407.02747","title":"Curvature Clues: Decoding Deep Learning Privacy with Input Loss\n  Curvature","authors":"Deepak Ravikumar, Efstathia Soufleri, Kaushik Roy","authorsParsed":[["Ravikumar","Deepak",""],["Soufleri","Efstathia",""],["Roy","Kaushik",""]],"versions":[{"version":"v1","created":"Wed, 3 Jul 2024 01:47:46 GMT"}],"updateDate":"2024-07-04","timestamp":1719971266000,"abstract":"  In this paper, we explore the properties of loss curvature with respect to\ninput data in deep neural networks. Curvature of loss with respect to input\n(termed input loss curvature) is the trace of the Hessian of the loss with\nrespect to the input. We investigate how input loss curvature varies between\ntrain and test sets, and its implications for train-test distinguishability. We\ndevelop a theoretical framework that derives an upper bound on the train-test\ndistinguishability based on privacy and the size of the training set. This\nnovel insight fuels the development of a new black box membership inference\nattack utilizing input loss curvature. We validate our theoretical findings\nthrough experiments in computer vision classification tasks, demonstrating that\ninput loss curvature surpasses existing methods in membership inference\neffectiveness. Our analysis highlights how the performance of membership\ninference attack (MIA) methods varies with the size of the training set,\nshowing that curvature-based MIA outperforms other methods on sufficiently\nlarge datasets. This condition is often met by real datasets, as demonstrated\nby our results on CIFAR10, CIFAR100, and ImageNet. These findings not only\nadvance our understanding of deep neural network behavior but also improve the\nability to test privacy-preserving techniques in machine learning.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Cryptography and Security"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/"}