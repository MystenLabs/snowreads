{"id":"2408.10292","title":"Leveraging Superfluous Information in Contrastive Representation\n  Learning","authors":"Xuechu Yu","authorsParsed":[["Yu","Xuechu",""]],"versions":[{"version":"v1","created":"Mon, 19 Aug 2024 16:21:08 GMT"}],"updateDate":"2024-08-21","timestamp":1724084468000,"abstract":"  Contrastive representation learning, which aims to learnthe shared\ninformation between different views of unlabeled data by maximizing the mutual\ninformation between them, has shown its powerful competence in self-supervised\nlearning for downstream tasks. However, recent works have demonstrated that\nmore estimated mutual information does not guarantee better performance in\ndifferent downstream tasks. Such works inspire us to conjecture that the\nlearned representations not only maintain task-relevant information from\nunlabeled data but also carry task-irrelevant information which is superfluous\nfor downstream tasks, thus leading to performance degeneration. In this paper\nwe show that superfluous information does exist during the conventional\ncontrastive learning framework, and further design a new objective, namely\nSuperInfo, to learn robust representations by a linear combination of both\npredictive and superfluous information. Besides, we notice that it is feasible\nto tune the coefficients of introduced losses to discard task-irrelevant\ninformation, while keeping partial non-shared task-relevant information\naccording to our SuperInfo loss.We demonstrate that learning with our loss can\noften outperform the traditional contrastive learning approaches on image\nclassification, object detection and instance segmentation tasks with\nsignificant improvements.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"jzxAvDjclL9IqIA4PszT-2N_EoDByuEGR3lp6rfpvLw","pdfSize":"516874"}
