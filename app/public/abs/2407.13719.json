{"id":"2407.13719","title":"HazeCLIP: Towards Language Guided Real-World Image Dehazing","authors":"Ruiyi Wang, Wenhao Li, Xiaohong Liu, Chunyi Li, Zicheng Zhang,\n  Xiongkuo Min, Guangtao Zhai","authorsParsed":[["Wang","Ruiyi",""],["Li","Wenhao",""],["Liu","Xiaohong",""],["Li","Chunyi",""],["Zhang","Zicheng",""],["Min","Xiongkuo",""],["Zhai","Guangtao",""]],"versions":[{"version":"v1","created":"Thu, 18 Jul 2024 17:18:25 GMT"}],"updateDate":"2024-07-19","timestamp":1721323105000,"abstract":"  Existing methods have achieved remarkable performance in single image\ndehazing, particularly on synthetic datasets. However, they often struggle with\nreal-world hazy images due to domain shift, limiting their practical\napplicability. This paper introduces HazeCLIP, a language-guided adaptation\nframework designed to enhance the real-world performance of pre-trained\ndehazing networks. Inspired by the Contrastive Language-Image Pre-training\n(CLIP) model's ability to distinguish between hazy and clean images, we utilize\nit to evaluate dehazing results. Combined with a region-specific dehazing\ntechnique and tailored prompt sets, CLIP model accurately identifies hazy\nareas, providing a high-quality, human-like prior that guides the fine-tuning\nprocess of pre-trained networks. Extensive experiments demonstrate that\nHazeCLIP achieves the state-of-the-art performance in real-word image dehazing,\nevaluated through both visual quality and no-reference quality assessments. The\ncode is available: https://github.com/Troivyn/HazeCLIP .\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}