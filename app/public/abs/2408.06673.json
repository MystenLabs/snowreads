{"id":"2408.06673","title":"Pragmatic inference of scalar implicature by LLMs","authors":"Ye-eun Cho, Seong mook Kim","authorsParsed":[["Cho","Ye-eun",""],["Kim","Seong mook",""]],"versions":[{"version":"v1","created":"Tue, 13 Aug 2024 06:52:29 GMT"}],"updateDate":"2024-08-14","timestamp":1723531949000,"abstract":"  This study investigates how Large Language Models (LLMs), particularly BERT\n(Devlin et al., 2019) and GPT-2 (Radford et al., 2019), engage in pragmatic\ninference of scalar implicature, such as some. Two sets of experiments were\nconducted using cosine similarity and next sentence/token prediction as\nexperimental methods. The results in experiment 1 showed that, both models\ninterpret some as pragmatic implicature not all in the absence of context,\naligning with human language processing. In experiment 2, in which Question\nUnder Discussion (QUD) was presented as a contextual cue, BERT showed\nconsistent performance regardless of types of QUDs, while GPT-2 encountered\nprocessing difficulties since a certain type of QUD required pragmatic\ninference for implicature. The findings revealed that, in terms of theoretical\napproaches, BERT inherently incorporates pragmatic implicature not all within\nthe term some, adhering to Default model (Levinson, 2000). In contrast, GPT-2\nseems to encounter processing difficulties in inferring pragmatic implicature\nwithin context, consistent with Context-driven model (Sperber and Wilson,\n2002).\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"fZWV3_xDMSSRVKKWozoCF2MnvhO-TEF8XrQyuYTjs58","pdfSize":"1365017"}
