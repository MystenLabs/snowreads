{"id":"2408.13018","title":"Robust Iterative Value Conversion: Deep Reinforcement Learning for\n  Neurochip-driven Edge Robots","authors":"Yuki Kadokawa, Tomohito Kodera, Yoshihisa Tsurumine, Shinya Nishimura,\n  Takamitsu Matsubara","authorsParsed":[["Kadokawa","Yuki",""],["Kodera","Tomohito",""],["Tsurumine","Yoshihisa",""],["Nishimura","Shinya",""],["Matsubara","Takamitsu",""]],"versions":[{"version":"v1","created":"Fri, 23 Aug 2024 12:13:48 GMT"}],"updateDate":"2024-08-26","timestamp":1724415228000,"abstract":"  A neurochip is a device that reproduces the signal processing mechanisms of\nbrain neurons and calculates Spiking Neural Networks (SNNs) with low power\nconsumption and at high speed. Thus, neurochips are attracting attention from\nedge robot applications, which suffer from limited battery capacity. This paper\naims to achieve deep reinforcement learning (DRL) that acquires SNN policies\nsuitable for neurochip implementation. Since DRL requires a complex function\napproximation, we focus on conversion techniques from Floating Point NN (FPNN)\nbecause it is one of the most feasible SNN techniques. However, DRL requires\nconversions to SNNs for every policy update to collect the learning samples for\na DRL-learning cycle, which updates the FPNN policy and collects the SNN policy\nsamples. Accumulative conversion errors can significantly degrade the\nperformance of the SNN policies. We propose Robust Iterative Value Conversion\n(RIVC) as a DRL that incorporates conversion error reduction and robustness to\nconversion errors. To reduce them, FPNN is optimized with the same number of\nquantization bits as an SNN. The FPNN output is not significantly changed by\nquantization. To robustify the conversion error, an FPNN policy that is applied\nwith quantization is updated to increase the gap between the probability of\nselecting the optimal action and other actions. This step prevents unexpected\nreplacements of the policy's optimal actions. We verified RIVC's effectiveness\non a neurochip-driven robot. The results showed that RIVC consumed 1/15 times\nless power and increased the calculation speed by five times more than an edge\nCPU (quad-core ARM Cortex-A72). The previous framework with no countermeasures\nagainst conversion errors failed to train the policies. Videos from our\nexperiments are available: https://youtu.be/Q5Z0-BvK1Tc.\n","subjects":["Computing Research Repository/Robotics"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}