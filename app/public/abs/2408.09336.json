{"id":"2408.09336","title":"Elite360M: Efficient 360 Multi-task Learning via Bi-projection Fusion\n  and Cross-task Collaboration","authors":"Hao Ai, Lin Wang","authorsParsed":[["Ai","Hao",""],["Wang","Lin",""]],"versions":[{"version":"v1","created":"Sun, 18 Aug 2024 02:33:45 GMT"}],"updateDate":"2024-08-20","timestamp":1723948425000,"abstract":"  360 cameras capture the entire surrounding environment with a large FoV,\nexhibiting comprehensive visual information to directly infer the 3D\nstructures, e.g., depth and surface normal, and semantic information\nsimultaneously. Existing works predominantly specialize in a single task,\nleaving multi-task learning of 3D geometry and semantics largely unexplored.\nAchieving such an objective is, however, challenging due to: 1) inherent\nspherical distortion of planar equirectangular projection (ERP) and\ninsufficient global perception induced by 360 image's ultra-wide FoV; 2)\nnon-trivial progress in effectively merging geometry and semantics among\ndifferent tasks to achieve mutual benefits. In this paper, we propose a novel\nend-to-end multi-task learning framework, named Elite360M, capable of inferring\n3D structures via depth and surface normal estimation, and semantics via\nsemantic segmentation simultaneously. Our key idea is to build a representation\nwith strong global perception and less distortion while exploring the inter-\nand cross-task relationships between geometry and semantics. We incorporate the\ndistortion-free and spatially continuous icosahedron projection (ICOSAP) points\nand combine them with ERP to enhance global perception. With a negligible cost,\na Bi-projection Bi-attention Fusion module is thus designed to capture the\nsemantic- and distance-aware dependencies between each pixel of the\nregion-aware ERP feature and the ICOSAP point feature set. Moreover, we propose\na novel Cross-task Collaboration module to explicitly extract task-specific\ngeometric and semantic information from the learned representation to achieve\npreliminary predictions. It then integrates the spatial contextual information\namong tasks to realize cross-task fusion. Extensive experiments demonstrate the\neffectiveness and efficacy of Elite360M.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-sa/4.0/"}