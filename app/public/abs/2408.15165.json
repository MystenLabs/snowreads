{"id":"2408.15165","title":"Latent Ewald summation for machine learning of long-range interactions","authors":"Bingqing Cheng","authorsParsed":[["Cheng","Bingqing",""]],"versions":[{"version":"v1","created":"Tue, 27 Aug 2024 16:03:18 GMT"}],"updateDate":"2024-08-28","timestamp":1724774598000,"abstract":"  Machine learning interatomic potentials (MLIPs) often neglect long-range\ninteractions, such as electrostatic and dispersion forces. In this work, we\nintroduce a straightforward and efficient method to account for long-range\ninteractions by learning a latent variable from local atomic descriptors and\napplying an Ewald summation to this variable. We demonstrate that in systems\nincluding charged, polar, or apolar molecular dimers, bulk water, and\nwater-vapor interface, standard short-ranged MLIPs can lead to unphysical\npredictions even when employing message passing. The long-range models\neffectively eliminate these artifacts, with only about twice the computational\ncost of short-range MLIPs.\n","subjects":["Computing Research Repository/Machine Learning","Condensed Matter/Materials Science","Physics/Chemical Physics","Physics/Computational Physics"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}