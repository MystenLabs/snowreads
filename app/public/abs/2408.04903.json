{"id":"2408.04903","title":"Axiomatic Characterisations of Sample-based Explainers","authors":"Leila Amgoud, Martin C. Cooper and Salim Debbaoui","authorsParsed":[["Amgoud","Leila",""],["Cooper","Martin C.",""],["Debbaoui","Salim",""]],"versions":[{"version":"v1","created":"Fri, 9 Aug 2024 07:10:07 GMT"},{"version":"v2","created":"Mon, 12 Aug 2024 07:04:56 GMT"}],"updateDate":"2024-08-13","timestamp":1723187407000,"abstract":"  Explaining decisions of black-box classifiers is both important and\ncomputationally challenging. In this paper, we scrutinize explainers that\ngenerate feature-based explanations from samples or datasets. We start by\npresenting a set of desirable properties that explainers would ideally satisfy,\ndelve into their relationships, and highlight incompatibilities of some of\nthem. We identify the entire family of explainers that satisfy two key\nproperties which are compatible with all the others. Its instances provide\nsufficient reasons, called weak abductive explanations.We then unravel its\nvarious subfamilies that satisfy subsets of compatible properties. Indeed, we\nfully characterize all the explainers that satisfy any subset of compatible\nproperties. In particular, we introduce the first (broad family of) explainers\nthat guarantee the existence of explanations and their global consistency.We\ndiscuss some of its instances including the irrefutable explainer and the\nsurrogate explainer whose explanations can be found in polynomial time.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}