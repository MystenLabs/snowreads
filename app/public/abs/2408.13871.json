{"id":"2408.13871","title":"Flexible game-playing AI with AlphaViT: adapting to multiple games and\n  board sizes","authors":"Kazuhisa Fujita","authorsParsed":[["Fujita","Kazuhisa",""]],"versions":[{"version":"v1","created":"Sun, 25 Aug 2024 15:40:21 GMT"}],"updateDate":"2024-08-27","timestamp":1724600421000,"abstract":"  This paper presents novel game AI agents based on the AlphaZero framework,\nenhanced with Vision Transformers (ViT): AlphaViT, AlphaViD, and AlphaVDA.\nThese agents are designed to play various board games of different sizes using\na single model, overcoming AlphaZero's limitation of being restricted to a\nfixed board size. AlphaViT uses only a transformer encoder, while AlphaViD and\nAlphaVDA contain both an encoder and a decoder. AlphaViD's decoder receives\ninput from the encoder output, while AlphaVDA uses a learnable matrix as\ndecoder input. Using the AlphaZero framework, the three proposed methods\ndemonstrate their versatility in different game environments, including\nConnect4, Gomoku, and Othello. Experimental results show that these agents,\nwhether trained on a single game or on multiple games simultaneously,\nconsistently outperform traditional algorithms such as Minimax and Monte Carlo\ntree search using a single DNN with shared weights, while approaching the\nperformance of AlphaZero. In particular, AlphaViT and AlphaViD show strong\nperformance across games, with AlphaViD benefiting from an additional decoder\nlayer that enhances its ability to adapt to different action spaces and board\nsizes. These results may suggest the potential of transformer-based\narchitectures to develop more flexible and robust game AI agents capable of\nexcelling in multiple games and dynamic environments.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}