{"id":"2408.01460","title":"LocalValueBench: A Collaboratively Built and Extensible Benchmark for\n  Evaluating Localized Value Alignment and Ethical Safety in Large Language\n  Models","authors":"Gwenyth Isobel Meadows, Nicholas Wai Long Lau, Eva Adelina Susanto,\n  Chi Lok Yu, Aditya Paul","authorsParsed":[["Meadows","Gwenyth Isobel",""],["Lau","Nicholas Wai Long",""],["Susanto","Eva Adelina",""],["Yu","Chi Lok",""],["Paul","Aditya",""]],"versions":[{"version":"v1","created":"Sat, 27 Jul 2024 05:55:42 GMT"}],"updateDate":"2024-08-06","timestamp":1722059742000,"abstract":"  The proliferation of large language models (LLMs) requires robust evaluation\nof their alignment with local values and ethical standards, especially as\nexisting benchmarks often reflect the cultural, legal, and ideological values\nof their creators. \\textsc{LocalValueBench}, introduced in this paper, is an\nextensible benchmark designed to assess LLMs' adherence to Australian values,\nand provides a framework for regulators worldwide to develop their own LLM\nbenchmarks for local value alignment. Employing a novel typology for ethical\nreasoning and an interrogation approach, we curated comprehensive questions and\nutilized prompt engineering strategies to probe LLMs' value alignment. Our\nevaluation criteria quantified deviations from local values, ensuring a\nrigorous assessment process. Comparative analysis of three commercial LLMs by\nUSA vendors revealed significant insights into their effectiveness and\nlimitations, demonstrating the critical importance of value alignment. This\nstudy offers valuable tools and methodologies for regulators to create tailored\nbenchmarks, highlighting avenues for future research to enhance ethical AI\ndevelopment.\n","subjects":["Computing Research Repository/Computers and Society","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/"}