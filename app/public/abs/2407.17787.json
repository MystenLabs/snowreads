{"id":"2407.17787","title":"HC-GST: Heterophily-aware Distribution Consistency based Graph\n  Self-training","authors":"Fali Wang, Tianxiang Zhao, Junjie Xu, Suhang Wang","authorsParsed":[["Wang","Fali",""],["Zhao","Tianxiang",""],["Xu","Junjie",""],["Wang","Suhang",""]],"versions":[{"version":"v1","created":"Thu, 25 Jul 2024 05:38:06 GMT"}],"updateDate":"2024-07-26","timestamp":1721885886000,"abstract":"  Graph self-training (GST), which selects and assigns pseudo-labels to\nunlabeled nodes, is popular for tackling label sparsity in graphs. However,\nrecent study on homophily graphs show that GST methods could introduce and\namplify distribution shift between training and test nodes as they tend to\nassign pseudo-labels to nodes they are good at. As GNNs typically perform\nbetter on homophilic nodes, there could be potential shifts towards homophilic\npseudo-nodes, which is underexplored. Our preliminary experiments on\nheterophilic graphs verify that these methods can cause shifts in homophily\nratio distributions, leading to \\textit{training bias} that improves\nperformance on homophilic nodes while degrading it on heterophilic ones.\nTherefore, we study a novel problem of reducing homophily ratio distribution\nshifts during self-training on heterophilic graphs. A key challenge is the\naccurate calculation of homophily ratios and their distributions without\nextensive labeled data. To tackle them, we propose a novel Heterophily-aware\nDistribution Consistency-based Graph Self-Training (HC-GST) framework, which\nestimates homophily ratios using soft labels and optimizes a selection vector\nto align pseudo-nodes with the global homophily ratio distribution. Extensive\nexperiments on both homophilic and heterophilic graphs show that HC-GST\neffectively reduces training bias and enhances self-training performance.\n","subjects":["Computing Research Repository/Social and Information Networks","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}