{"id":"2408.14176","title":"SwiftBrush v2: Make Your One-step Diffusion Model Better Than Its\n  Teacher","authors":"Trung Dao, Thuan Hoang Nguyen, Thanh Le, Duc Vu, Khoi Nguyen, Cuong\n  Pham, Anh Tran","authorsParsed":[["Dao","Trung",""],["Nguyen","Thuan Hoang",""],["Le","Thanh",""],["Vu","Duc",""],["Nguyen","Khoi",""],["Pham","Cuong",""],["Tran","Anh",""]],"versions":[{"version":"v1","created":"Mon, 26 Aug 2024 10:42:53 GMT"},{"version":"v2","created":"Tue, 27 Aug 2024 04:59:58 GMT"}],"updateDate":"2024-08-28","timestamp":1724668973000,"abstract":"  In this paper, we aim to enhance the performance of SwiftBrush, a prominent\none-step text-to-image diffusion model, to be competitive with its multi-step\nStable Diffusion counterpart. Initially, we explore the quality-diversity\ntrade-off between SwiftBrush and SD Turbo: the former excels in image\ndiversity, while the latter excels in image quality. This observation motivates\nour proposed modifications in the training methodology, including better weight\ninitialization and efficient LoRA training. Moreover, our introduction of a\nnovel clamped CLIP loss enhances image-text alignment and results in improved\nimage quality. Remarkably, by combining the weights of models trained with\nefficient LoRA and full training, we achieve a new state-of-the-art one-step\ndiffusion model, achieving an FID of 8.14 and surpassing all GAN-based and\nmulti-step Stable Diffusion models. The project page is available at\nhttps://swiftbrushv2.github.io.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"kdK6-ltCFecfDuUmPNgfKrXa4dbVwEPLP5tCfcmt-SE","pdfSize":"35353909"}
