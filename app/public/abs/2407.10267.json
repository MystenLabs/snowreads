{"id":"2407.10267","title":"RS-NeRF: Neural Radiance Fields from Rolling Shutter Images","authors":"Muyao Niu, Tong Chen, Yifan Zhan, Zhuoxiao Li, Xiang Ji, Yinqiang\n  Zheng","authorsParsed":[["Niu","Muyao",""],["Chen","Tong",""],["Zhan","Yifan",""],["Li","Zhuoxiao",""],["Ji","Xiang",""],["Zheng","Yinqiang",""]],"versions":[{"version":"v1","created":"Sun, 14 Jul 2024 16:27:11 GMT"}],"updateDate":"2024-07-16","timestamp":1720974431000,"abstract":"  Neural Radiance Fields (NeRFs) have become increasingly popular because of\ntheir impressive ability for novel view synthesis. However, their effectiveness\nis hindered by the Rolling Shutter (RS) effects commonly found in most camera\nsystems. To solve this, we present RS-NeRF, a method designed to synthesize\nnormal images from novel views using input with RS distortions. This involves a\nphysical model that replicates the image formation process under RS conditions\nand jointly optimizes NeRF parameters and camera extrinsic for each image row.\nWe further address the inherent shortcomings of the basic RS-NeRF model by\ndelving into the RS characteristics and developing algorithms to enhance its\nfunctionality. First, we impose a smoothness regularization to better estimate\ntrajectories and improve the synthesis quality, in line with the camera\nmovement prior. We also identify and address a fundamental flaw in the vanilla\nRS model by introducing a multi-sampling algorithm. This new approach improves\nthe model's performance by comprehensively exploiting the RGB data across\ndifferent rows for each intermediate camera pose. Through rigorous\nexperimentation, we demonstrate that RS-NeRF surpasses previous methods in both\nsynthetic and real-world scenarios, proving its ability to correct RS-related\ndistortions effectively. Codes and data available:\nhttps://github.com/MyNiuuu/RS-NeRF\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}