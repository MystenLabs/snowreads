{"id":"2408.02976","title":"Empathy Level Alignment via Reinforcement Learning for Empathetic\n  Response Generation","authors":"Hui Ma, Bo Zhang, Bo Xu, Jian Wang, Hongfei Lin, and Xiao Sun","authorsParsed":[["Ma","Hui",""],["Zhang","Bo",""],["Xu","Bo",""],["Wang","Jian",""],["Lin","Hongfei",""],["Sun","Xiao",""]],"versions":[{"version":"v1","created":"Tue, 6 Aug 2024 06:16:00 GMT"}],"updateDate":"2024-08-07","timestamp":1722924960000,"abstract":"  Empathetic response generation, aiming at understanding the user's situation\nand feelings and respond empathically, is crucial in building human-like\ndialogue systems. Previous methods mainly focus on using maximum likelihood\nestimation as the optimization objective for training response generation\nmodels, without taking into account the empathy level alignment between\ngenerated responses and target responses. To this end, we propose an empathetic\nresponse generation using reinforcement learning (EmpRL) framework. The\nframework designs an effective empathy reward function and generates empathetic\nresponses by maximizing the expected reward through reinforcement learning.\nGiven the powerful text generation capability of pre-trained language models,\nEmpRL utilizes the pre-trained T5 model as the generator and conducts further\ntraining to initialize the policy. To align the empathy level between generated\nresponses and target responses in the context, an empathy reward function\ncontaining three empathy communication mechanisms, i.e., emotional reaction,\ninterpretation, and exploration, is constructed using pre-designed and\npre-trained empathy identifiers. Finally, the proximal policy optimization\nalgorithm is used to further train the policy to produce empathetic responses.\nBoth automatic and manual evaluations demonstrate that the proposed EmpRL\nframework can improve the quality of generated responses, enhance the empathy\nlevel similarity between generated and target responses, and produce empathetic\nresponses covering both affective and cognitive aspects.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}