{"id":"2408.11667","title":"The Problems with Proxies: Making Data Work Visible through Requester\n  Practices","authors":"Annabel Rothschild, Ding Wang, Niveditha Jayakumar Vilvanathan, Lauren\n  Wilcox, Carl DiSalvo, and Betsy DiSalvo","authorsParsed":[["Rothschild","Annabel",""],["Wang","Ding",""],["Vilvanathan","Niveditha Jayakumar",""],["Wilcox","Lauren",""],["DiSalvo","Carl",""],["DiSalvo","Betsy",""]],"versions":[{"version":"v1","created":"Wed, 21 Aug 2024 14:39:34 GMT"}],"updateDate":"2024-08-22","timestamp":1724251174000,"abstract":"  Fairness in AI and ML systems is increasingly linked to the proper treatment\nand recognition of data workers involved in training dataset development. Yet,\nthose who collect and annotate the data, and thus have the most intimate\nknowledge of its development, are often excluded from critical discussions.\nThis exclusion prevents data annotators, who are domain experts, from\ncontributing effectively to dataset contextualization. Our investigation into\nthe hiring and engagement practices of 52 data work requesters on platforms\nlike Amazon Mechanical Turk reveals a gap: requesters frequently hold naive or\nunchallenged notions of worker identities and capabilities and rely on ad-hoc\nqualification tasks that fail to respect the workers' expertise. These\npractices not only undermine the quality of data but also the ethical standards\nof AI development. To rectify these issues, we advocate for policy changes to\nenhance how data annotation tasks are designed and managed and to ensure data\nworkers are treated with the respect they deserve.\n","subjects":["Computing Research Repository/Human-Computer Interaction"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/"}