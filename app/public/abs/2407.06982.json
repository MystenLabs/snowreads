{"id":"2407.06982","title":"Information-theoretic classification of the cutoff phenomenon in Markov\n  processes","authors":"Youjia Wang, Michael C.H.Choi","authorsParsed":[["Wang","Youjia",""],["Choi","Michael C. H.",""]],"versions":[{"version":"v1","created":"Tue, 9 Jul 2024 15:57:12 GMT"}],"updateDate":"2024-07-10","timestamp":1720540632000,"abstract":"  We investigate the cutoff phenomenon for Markov processes under information\ndivergences such as $f$-divergences and R\\'enyi divergences. We classify most\ncommon divergences into four types, namely $L^2$-type, $\\mathrm{TV}$-type,\nseparation-type and $\\mathrm{KL}$ divergence, in which we prove that the cutoff\nphenomenon are equivalent and relate the cutoff time and window among members\nwithin each type. To justify that this classification is natural, we provide\nexamples in which the family of Markov processes exhibit cutoff in one type but\nnot in another. We also establish new product conditions in these settings for\nthe processes to exhibit cutoff, along with new results in non-reversible or\nnon-normal situations. The proofs rely on a functional analytic approach\ntowards cutoff.\n","subjects":["Mathematics/Probability","Computing Research Repository/Information Theory","Mathematics/Information Theory"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}