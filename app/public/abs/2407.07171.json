{"id":"2407.07171","title":"ItTakesTwo: Leveraging Peer Representations for Semi-supervised LiDAR\n  Semantic Segmentation","authors":"Yuyuan Liu, Yuanhong Chen, Hu Wang, Vasileios Belagiannis, Ian Reid\n  and Gustavo Carneiro","authorsParsed":[["Liu","Yuyuan",""],["Chen","Yuanhong",""],["Wang","Hu",""],["Belagiannis","Vasileios",""],["Reid","Ian",""],["Carneiro","Gustavo",""]],"versions":[{"version":"v1","created":"Tue, 9 Jul 2024 18:26:53 GMT"},{"version":"v2","created":"Fri, 19 Jul 2024 07:47:39 GMT"}],"updateDate":"2024-07-22","timestamp":1720549613000,"abstract":"  The costly and time-consuming annotation process to produce large training\nsets for modelling semantic LiDAR segmentation methods has motivated the\ndevelopment of semi-supervised learning (SSL) methods. However, such SSL\napproaches often concentrate on employing consistency learning only for\nindividual LiDAR representations. This narrow focus results in limited\nperturbations that generally fail to enable effective consistency learning.\nAdditionally, these SSL approaches employ contrastive learning based on the\nsampling from a limited set of positive and negative embedding samples. This\npaper introduces a novel semi-supervised LiDAR semantic segmentation framework\ncalled ItTakesTwo (IT2). IT2 is designed to ensure consistent predictions from\npeer LiDAR representations, thereby improving the perturbation effectiveness in\nconsistency learning. Furthermore, our contrastive learning employs informative\nsamples drawn from a distribution of positive and negative embeddings learned\nfrom the entire training set. Results on public benchmarks show that our\napproach achieves remarkable improvements over the previous state-of-the-art\n(SOTA) methods in the field. The code is available at:\nhttps://github.com/yyliu01/IT2.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}