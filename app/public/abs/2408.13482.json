{"id":"2408.13482","title":"MPruner: Optimizing Neural Network Size with CKA-Based Mutual\n  Information Pruning","authors":"Seungbeom Hu, ChanJun Park, Andrew Ferraiuolo, Sang-Ki Ko, Jinwoo Kim,\n  Haein Song, Jieung Kim","authorsParsed":[["Hu","Seungbeom",""],["Park","ChanJun",""],["Ferraiuolo","Andrew",""],["Ko","Sang-Ki",""],["Kim","Jinwoo",""],["Song","Haein",""],["Kim","Jieung",""]],"versions":[{"version":"v1","created":"Sat, 24 Aug 2024 05:54:47 GMT"},{"version":"v2","created":"Tue, 3 Sep 2024 00:48:37 GMT"}],"updateDate":"2024-09-04","timestamp":1724478887000,"abstract":"  Determining the optimal size of a neural network is critical, as it directly\nimpacts runtime performance and memory usage. Pruning is a well-established\nmodel compression technique that reduces the size of neural networks while\nmathematically guaranteeing accuracy preservation. However, many recent pruning\nmethods overlook the global contributions of individual model components,\nmaking it difficult to ensure that a pruned model meets the desired dataset and\nperformance requirements. To address these challenges, we developed a new\npruning algorithm, MPruner, that leverages mutual information through vector\nsimilarity. MPruner utilizes layer clustering with the Centered Kernel\nAlignment (CKA) similarity metric, allowing us to incorporate global\ninformation from the neural network for more precise and efficient layer-wise\npruning. We evaluated MPruner across various architectures and configurations,\ndemonstrating its versatility and providing practical guidelines. MPruner\nachieved up to a 50% reduction in parameters and memory usage for CNN and\ntransformer-based models, with minimal to no loss in accuracy.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by-sa/4.0/"}