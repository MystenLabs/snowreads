{"id":"2407.11422","title":"Reflective Instruction Tuning: Mitigating Hallucinations in Large\n  Vision-Language Models","authors":"Jinrui Zhang, Teng Wang, Haigang Zhang, Ping Lu, Feng Zheng","authorsParsed":[["Zhang","Jinrui",""],["Wang","Teng",""],["Zhang","Haigang",""],["Lu","Ping",""],["Zheng","Feng",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 06:32:45 GMT"}],"updateDate":"2024-07-17","timestamp":1721111565000,"abstract":"  Large vision-language models (LVLMs) have shown promising performance on a\nvariety of vision-language tasks. However, they remain susceptible to\nhallucinations, generating outputs misaligned with visual content or\ninstructions. While various mitigation strategies have been proposed, they\noften neglect a key contributor to hallucinations: lack of fine-grained\nreasoning supervision during training. Without intermediate reasoning steps,\nmodels may establish superficial shortcuts between instructions and responses,\nfailing to internalize the inherent reasoning logic. To address this challenge,\nwe propose reflective instruction tuning, which integrates rationale learning\ninto visual instruction tuning. Unlike previous methods that learning from\nresponses only, our approach entails the model predicting rationales justifying\nwhy responses are correct or incorrect. This fosters a deeper engagement with\nthe fine-grained reasoning underlying each response, thus enhancing the model's\nreasoning proficiency. To facilitate this approach, we propose REVERIE, the\nfirst large-scale instruction-tuning dataset with ReflEctiVE RatIonalE\nannotations. REVERIE comprises 115k machine-generated reasoning instructions,\neach meticulously annotated with a corresponding pair of correct and confusing\nresponses, alongside comprehensive rationales elucidating the justification\nbehind the correctness or erroneousness of each response. Experimental results\non multiple LVLM benchmarks reveal that reflective instruction tuning with the\nREVERIE dataset yields noticeable performance gain over the baseline model,\ndemonstrating the effectiveness of reflecting from the rationales. Project page\nis at https://zjr2000.github.io/projects/reverie.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}