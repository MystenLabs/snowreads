{"id":"2407.14029","title":"PASS++: A Dual Bias Reduction Framework for Non-Exemplar\n  Class-Incremental Learning","authors":"Fei Zhu, Xu-Yao Zhang, Zhen Cheng, Cheng-Lin Liu","authorsParsed":[["Zhu","Fei",""],["Zhang","Xu-Yao",""],["Cheng","Zhen",""],["Liu","Cheng-Lin",""]],"versions":[{"version":"v1","created":"Fri, 19 Jul 2024 05:03:16 GMT"}],"updateDate":"2024-07-22","timestamp":1721365396000,"abstract":"  Class-incremental learning (CIL) aims to recognize new classes incrementally\nwhile maintaining the discriminability of old classes. Most existing CIL\nmethods are exemplar-based, i.e., storing a part of old data for retraining.\nWithout relearning old data, those methods suffer from catastrophic forgetting.\nIn this paper, we figure out two inherent problems in CIL, i.e., representation\nbias and classifier bias, that cause catastrophic forgetting of old knowledge.\nTo address these two biases, we present a simple and novel dual bias reduction\nframework that employs self-supervised transformation (SST) in input space and\nprototype augmentation (protoAug) in deep feature space. On the one hand, SST\nalleviates the representation bias by learning generic and diverse\nrepresentations that can transfer across different tasks. On the other hand,\nprotoAug overcomes the classifier bias by explicitly or implicitly augmenting\nprototypes of old classes in the deep feature space, which poses tighter\nconstraints to maintain previously learned decision boundaries. We further\npropose hardness-aware prototype augmentation and multi-view ensemble\nstrategies, leading to significant improvements. The proposed framework can be\neasily integrated with pre-trained models. Without storing any samples of old\nclasses, our method can perform comparably with state-of-the-art exemplar-based\napproaches which store plenty of old data. We hope to draw the attention of\nresearchers back to non-exemplar CIL by rethinking the necessity of storing old\nsamples in CIL.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}