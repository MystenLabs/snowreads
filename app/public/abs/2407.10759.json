{"id":"2407.10759","title":"Qwen2-Audio Technical Report","authors":"Yunfei Chu, Jin Xu, Qian Yang, Haojie Wei, Xipin Wei, Zhifang Guo,\n  Yichong Leng, Yuanjun Lv, Jinzheng He, Junyang Lin, Chang Zhou, Jingren Zhou","authorsParsed":[["Chu","Yunfei",""],["Xu","Jin",""],["Yang","Qian",""],["Wei","Haojie",""],["Wei","Xipin",""],["Guo","Zhifang",""],["Leng","Yichong",""],["Lv","Yuanjun",""],["He","Jinzheng",""],["Lin","Junyang",""],["Zhou","Chang",""],["Zhou","Jingren",""]],"versions":[{"version":"v1","created":"Mon, 15 Jul 2024 14:38:09 GMT"}],"updateDate":"2024-07-16","timestamp":1721054289000,"abstract":"  We introduce the latest progress of Qwen-Audio, a large-scale audio-language\nmodel called Qwen2-Audio, which is capable of accepting various audio signal\ninputs and performing audio analysis or direct textual responses with regard to\nspeech instructions. In contrast to complex hierarchical tags, we have\nsimplified the pre-training process by utilizing natural language prompts for\ndifferent data and tasks, and have further expanded the data volume. We have\nboosted the instruction-following capability of Qwen2-Audio and implemented two\ndistinct audio interaction modes for voice chat and audio analysis. In the\nvoice chat mode, users can freely engage in voice interactions with Qwen2-Audio\nwithout text input. In the audio analysis mode, users could provide audio and\ntext instructions for analysis during the interaction. Note that we do not use\nany system prompts to switch between voice chat and audio analysis modes.\nQwen2-Audio is capable of intelligently comprehending the content within audio\nand following voice commands to respond appropriately. For instance, in an\naudio segment that simultaneously contains sounds, multi-speaker conversations,\nand a voice command, Qwen2-Audio can directly understand the command and\nprovide an interpretation and response to the audio. Additionally, DPO has\noptimized the model's performance in terms of factuality and adherence to\ndesired behavior. According to the evaluation results from AIR-Bench,\nQwen2-Audio outperformed previous SOTAs, such as Gemini-1.5-pro, in tests\nfocused on audio-centric instruction-following capabilities. Qwen2-Audio is\nopen-sourced with the aim of fostering the advancement of the multi-modal\nlanguage community.\n","subjects":["Electrical Engineering and Systems Science/Audio and Speech Processing","Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}