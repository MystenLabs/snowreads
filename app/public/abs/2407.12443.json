{"id":"2407.12443","title":"Preventing Catastrophic Overfitting in Fast Adversarial Training: A\n  Bi-level Optimization Perspective","authors":"Zhaoxin Wang, Handing Wang, Cong Tian, Yaochu Jin","authorsParsed":[["Wang","Zhaoxin",""],["Wang","Handing",""],["Tian","Cong",""],["Jin","Yaochu",""]],"versions":[{"version":"v1","created":"Wed, 17 Jul 2024 09:53:20 GMT"}],"updateDate":"2024-07-18","timestamp":1721210000000,"abstract":"  Adversarial training (AT) has become an effective defense method against\nadversarial examples (AEs) and it is typically framed as a bi-level\noptimization problem. Among various AT methods, fast AT (FAT), which employs a\nsingle-step attack strategy to guide the training process, can achieve good\nrobustness against adversarial attacks at a low cost. However, FAT methods\nsuffer from the catastrophic overfitting problem, especially on complex tasks\nor with large-parameter models. In this work, we propose a FAT method termed\nFGSM-PCO, which mitigates catastrophic overfitting by averting the collapse of\nthe inner optimization problem in the bi-level optimization process. FGSM-PCO\ngenerates current-stage AEs from the historical AEs and incorporates them into\nthe training process using an adaptive mechanism. This mechanism determines an\nappropriate fusion ratio according to the performance of the AEs on the\ntraining model. Coupled with a loss function tailored to the training\nframework, FGSM-PCO can alleviate catastrophic overfitting and help the\nrecovery of an overfitted model to effective training. We evaluate our\nalgorithm across three models and three datasets to validate its effectiveness.\nComparative empirical studies against other FAT algorithms demonstrate that our\nproposed method effectively addresses unresolved overfitting issues in existing\nalgorithms.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}