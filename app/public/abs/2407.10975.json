{"id":"2407.10975","title":"Stream State-tying for Sign Language Recognition","authors":"Jiyong Ma, Wen Gao, Chunli Wang","authorsParsed":[["Ma","Jiyong",""],["Gao","Wen",""],["Wang","Chunli",""]],"versions":[{"version":"v1","created":"Sun, 21 Apr 2024 23:21:52 GMT"}],"updateDate":"2024-07-17","timestamp":1713741712000,"abstract":"  In this paper, a novel approach to sign language recognition based on state\ntying in each of data streams is presented. In this framework, it is assumed\nthat hand gesture signal is represented in terms of six synchronous data\nstreams, i.e., the left/right hand position, left/right hand orientation and\nleft/right handshape. This approach offers a very accurate representation of\nthe sign space and keeps the number of parameters reasonably small in favor of\na fast decoding. Experiments were carried out for 5177 Chinese signs. The real\ntime isolated recognition rate is 94.8%. For continuous sign recognition, the\nword correct rate is 91.4%. Keywords: Sign language recognition; Automatic sign\nlanguage translation; Hand gesture recognition; Hidden Markov models;\nState-tying; Multimodal user interface; Virtual reality; Man-machine systems.\n","subjects":["Computing Research Repository/Other Computer Science","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/"}