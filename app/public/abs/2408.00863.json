{"id":"2408.00863","title":"UniMoT: Unified Molecule-Text Language Model with Discrete Token\n  Representation","authors":"Juzheng Zhang, Yatao Bian, Yongqiang Chen, Quanming Yao","authorsParsed":[["Zhang","Juzheng",""],["Bian","Yatao",""],["Chen","Yongqiang",""],["Yao","Quanming",""]],"versions":[{"version":"v1","created":"Thu, 1 Aug 2024 18:31:31 GMT"}],"updateDate":"2024-08-05","timestamp":1722537091000,"abstract":"  The remarkable success of Large Language Models (LLMs) across diverse tasks\nhas driven the research community to extend their capabilities to molecular\napplications. However, most molecular LLMs employ adapter-based architectures\nthat do not treat molecule and text modalities equally and lack a supervision\nsignal for the molecule modality. To address these issues, we introduce UniMoT,\na Unified Molecule-Text LLM adopting a tokenizer-based architecture that\nexpands the vocabulary of LLM with molecule tokens. Specifically, we introduce\na Vector Quantization-driven tokenizer that incorporates a Q-Former to bridge\nthe modality gap between molecule and text. This tokenizer transforms molecules\ninto sequences of molecule tokens with causal dependency, encapsulating\nhigh-level molecular and textual information. Equipped with this tokenizer,\nUniMoT can unify molecule and text modalities under a shared token\nrepresentation and an autoregressive training paradigm, enabling it to\ninterpret molecules as a foreign language and generate them as text. Following\na four-stage training scheme, UniMoT emerges as a multi-modal generalist\ncapable of performing both molecule-to-text and text-to-molecule tasks.\nExtensive experiments demonstrate that UniMoT achieves state-of-the-art\nperformance across a wide range of molecule comprehension and generation tasks.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"Nkt1O990yWJQxyKA2bzGDADTs8rxM2Psc1O5xIS8Zn8","pdfSize":"826033"}
