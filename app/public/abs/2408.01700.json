{"id":"2408.01700","title":"Integrating Large Language Models and Knowledge Graphs for Extraction\n  and Validation of Textual Test Data","authors":"Antonio De Santis, Marco Balduini, Federico De Santis, Andrea Proia,\n  Arsenio Leo, Marco Brambilla, Emanuele Della Valle","authorsParsed":[["De Santis","Antonio",""],["Balduini","Marco",""],["De Santis","Federico",""],["Proia","Andrea",""],["Leo","Arsenio",""],["Brambilla","Marco",""],["Della Valle","Emanuele",""]],"versions":[{"version":"v1","created":"Sat, 3 Aug 2024 07:42:53 GMT"}],"updateDate":"2024-08-06","timestamp":1722670973000,"abstract":"  Aerospace manufacturing companies, such as Thales Alenia Space, design,\ndevelop, integrate, verify, and validate products characterized by high\ncomplexity and low volume. They carefully document all phases for each product\nbut analyses across products are challenging due to the heterogeneity and\nunstructured nature of the data in documents. In this paper, we propose a\nhybrid methodology that leverages Knowledge Graphs (KGs) in conjunction with\nLarge Language Models (LLMs) to extract and validate data contained in these\ndocuments. We consider a case study focused on test data related to electronic\nboards for satellites. To do so, we extend the Semantic Sensor Network\nontology. We store the metadata of the reports in a KG, while the actual test\nresults are stored in parquet accessible via a Virtual Knowledge Graph. The\nvalidation process is managed using an LLM-based approach. We also conduct a\nbenchmarking study to evaluate the performance of state-of-the-art LLMs in\nexecuting this task. Finally, we analyze the costs and benefits of automating\npreexisting processes of manual data extraction and validation for subsequent\ncross-report analyses.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"4tvJPDOmW4FC9LGrP2KIU4MdyZ2WCHGKFc6H3xUlvww","pdfSize":"5577495"}
