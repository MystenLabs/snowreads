{"id":"2408.00754","title":"Coarse Correspondence Elicit 3D Spacetime Understanding in Multimodal\n  Language Model","authors":"Benlin Liu, Yuhao Dong, Yiqin Wang, Yongming Rao, Yansong Tang,\n  Wei-Chiu Ma, Ranjay Krishna","authorsParsed":[["Liu","Benlin",""],["Dong","Yuhao",""],["Wang","Yiqin",""],["Rao","Yongming",""],["Tang","Yansong",""],["Ma","Wei-Chiu",""],["Krishna","Ranjay",""]],"versions":[{"version":"v1","created":"Thu, 1 Aug 2024 17:57:12 GMT"}],"updateDate":"2024-08-02","timestamp":1722535032000,"abstract":"  Multimodal language models (MLLMs) are increasingly being implemented in\nreal-world environments, necessitating their ability to interpret 3D spaces and\ncomprehend temporal dynamics. Despite their potential, current top models\nwithin our community still fall short in adequately understanding spatial and\ntemporal dimensions. We introduce Coarse Correspondence, a simple,\ntraining-free, effective, and general-purpose visual prompting method to elicit\n3D and temporal understanding in multimodal LLMs. Our method uses a lightweight\ntracking model to find object correspondences between frames in a video or\nbetween sets of image viewpoints. It selects the most frequent object instances\nand visualizes them with markers with unique IDs in the image. With this simple\napproach, we achieve state-of-the-art results on 3D understanding benchmarks\nincluding ScanQA (+20.5\\%) and a subset of OpenEQA (+9.7\\%), and on long-form\nvideo benchmarks such as EgoSchema (+6.0\\%). We also curate a small diagnostic\ndataset to evaluate whether MLLMs can reason about space from a described\nviewpoint other than the camera viewpoint. Again, Coarse Correspondence\nimproves spatial perspective-taking abilities but we highlight that MLLMs\nstruggle with this task. Together, we demonstrate that our simple prompting\nmethod can significantly aid downstream tasks that require 3D or temporal\nreasoning.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}