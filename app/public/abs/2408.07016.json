{"id":"2408.07016","title":"Defining and Measuring Disentanglement for non-Independent Factors of\n  Variation","authors":"Antonio Almud\\'evar, Alfonso Ortega, Luis Vicente, Antonio Miguel and\n  Eduardo Lleida","authorsParsed":[["Almud√©var","Antonio",""],["Ortega","Alfonso",""],["Vicente","Luis",""],["Miguel","Antonio",""],["Lleida","Eduardo",""]],"versions":[{"version":"v1","created":"Tue, 13 Aug 2024 16:30:36 GMT"}],"updateDate":"2024-08-14","timestamp":1723566636000,"abstract":"  Representation learning is an approach that allows to discover and extract\nthe factors of variation from the data. Intuitively, a representation is said\nto be disentangled if it separates the different factors of variation in a way\nthat is understandable to humans. Definitions of disentanglement and metrics to\nmeasure it usually assume that the factors of variation are independent of each\nother. However, this is generally false in the real world, which limits the use\nof these definitions and metrics to very specific and unrealistic scenarios. In\nthis paper we give a definition of disentanglement based on information theory\nthat is also valid when the factors of variation are not independent.\nFurthermore, we relate this definition to the Information Bottleneck Method.\nFinally, we propose a method to measure the degree of disentanglement from the\ngiven definition that works when the factors of variation are not independent.\nWe show through different experiments that the method proposed in this paper\ncorrectly measures disentanglement with non-independent factors of variation,\nwhile other methods fail in this scenario.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence","Statistics/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"GqpJIeOUpmigcM8xSFmtKEC24G1Kg93doyb57KAkn5k","pdfSize":"527233"}
