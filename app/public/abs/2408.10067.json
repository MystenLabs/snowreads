{"id":"2408.10067","title":"Towards a Benchmark for Colorectal Cancer Segmentation in Endorectal\n  Ultrasound Videos: Dataset and Model Development","authors":"Yuncheng Jiang, Yiwen Hu, Zixun Zhang, Jun Wei, Chun-Mei Feng, Xuemei\n  Tang, Xiang Wan, Yong Liu, Shuguang Cui, Zhen Li","authorsParsed":[["Jiang","Yuncheng",""],["Hu","Yiwen",""],["Zhang","Zixun",""],["Wei","Jun",""],["Feng","Chun-Mei",""],["Tang","Xuemei",""],["Wan","Xiang",""],["Liu","Yong",""],["Cui","Shuguang",""],["Li","Zhen",""]],"versions":[{"version":"v1","created":"Mon, 19 Aug 2024 15:04:42 GMT"}],"updateDate":"2024-08-20","timestamp":1724079882000,"abstract":"  Endorectal ultrasound (ERUS) is an important imaging modality that provides\nhigh reliability for diagnosing the depth and boundary of invasion in\ncolorectal cancer. However, the lack of a large-scale ERUS dataset with\nhigh-quality annotations hinders the development of automatic ultrasound\ndiagnostics. In this paper, we collected and annotated the first benchmark\ndataset that covers diverse ERUS scenarios, i.e. colorectal cancer\nsegmentation, detection, and infiltration depth staging. Our ERUS-10K dataset\ncomprises 77 videos and 10,000 high-resolution annotated frames. Based on this\ndataset, we further introduce a benchmark model for colorectal cancer\nsegmentation, named the Adaptive Sparse-context TRansformer (ASTR). ASTR is\ndesigned based on three considerations: scanning mode discrepancy, temporal\ninformation, and low computational complexity. For generalizing to different\nscanning modes, the adaptive scanning-mode augmentation is proposed to convert\nbetween raw sector images and linear scan ones. For mining temporal\ninformation, the sparse-context transformer is incorporated to integrate\ninter-frame local and global features. For reducing computational complexity,\nthe sparse-context block is introduced to extract contextual features from\nauxiliary frames. Finally, on the benchmark dataset, the proposed ASTR model\nachieves a 77.6% Dice score in rectal cancer segmentation, largely\noutperforming previous state-of-the-art methods.\n","subjects":["Electrical Engineering and Systems Science/Image and Video Processing","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}