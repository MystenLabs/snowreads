{"id":"2407.15569","title":"An Empirical Study of Retrieval Augmented Generation with\n  Chain-of-Thought","authors":"Yuetong Zhao, Hongyu Cao, Xianyu Zhao, Zhijian Ou","authorsParsed":[["Zhao","Yuetong",""],["Cao","Hongyu",""],["Zhao","Xianyu",""],["Ou","Zhijian",""]],"versions":[{"version":"v1","created":"Mon, 22 Jul 2024 11:55:14 GMT"},{"version":"v2","created":"Fri, 30 Aug 2024 14:52:24 GMT"}],"updateDate":"2024-09-02","timestamp":1721649314000,"abstract":"  Since the launch of ChatGPT at the end of 2022, generative dialogue models\nrepresented by ChatGPT have quickly become essential tools in daily life. As\nuser expectations increase, enhancing the capability of generative dialogue\nmodels to solve complex problems has become a focal point of current research.\nThis paper delves into the effectiveness of the RAFT (Retrieval Augmented\nFine-Tuning) method in improving the performance of Generative dialogue models.\nRAFT combines chain-of-thought with model supervised fine-tuning (SFT) and\nretrieval augmented generation (RAG), which significantly enhanced the model's\ninformation extraction and logical reasoning abilities. We evaluated the RAFT\nmethod across multiple datasets and analysed its performance in various\nreasoning tasks, including long-form QA and short-form QA tasks, tasks in both\nChinese and English, and supportive and comparison reasoning tasks. Notably, it\naddresses the gaps in previous research regarding long-form QA tasks and\nChinese datasets. Moreover, we also evaluate the benefit of the\nchain-of-thought (CoT) in the RAFT method. This work offers valuable insights\nfor studies focused on enhancing the performance of generative dialogue models.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}