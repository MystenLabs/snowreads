{"id":"2407.21043","title":"CP-Prompt: Composition-Based Cross-modal Prompting for\n  Domain-Incremental Continual Learning","authors":"Yu Feng, Zhen Tian, Yifan Zhu, Zongfu Han, Haoran Luo, Guangwei Zhang,\n  Meina Song","authorsParsed":[["Feng","Yu",""],["Tian","Zhen",""],["Zhu","Yifan",""],["Han","Zongfu",""],["Luo","Haoran",""],["Zhang","Guangwei",""],["Song","Meina",""]],"versions":[{"version":"v1","created":"Mon, 22 Jul 2024 04:07:12 GMT"},{"version":"v2","created":"Fri, 2 Aug 2024 14:58:54 GMT"}],"updateDate":"2024-08-05","timestamp":1721621232000,"abstract":"  The key challenge of cross-modal domain-incremental learning (DIL) is to\nenable the learning model to continuously learn from novel data with different\nfeature distributions under the same task without forgetting old ones. However,\nexisting top-performing methods still cause high forgetting rates, by lacking\nintra-domain knowledge extraction and inter-domain common prompting strategy.\nIn this paper, we propose a simple yet effective framework, CP-Prompt, by\ntraining limited parameters to instruct a pre-trained model to learn new\ndomains and avoid forgetting existing feature distributions. CP-Prompt captures\nintra-domain knowledge by compositionally inserting personalized prompts on\nmulti-head self-attention layers and then learns the inter-domain knowledge\nwith a common prompting strategy. CP-Prompt shows superiority compared with\nstate-of-the-art baselines among three widely evaluated DIL tasks. The source\ncode is available at https://github.com/dannis97500/CP_Prompt.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}