{"id":"2407.10266","title":"psifx -- Psychological and Social Interactions Feature Extraction\n  Package","authors":"Guillaume Rochette and Matthew J. Vowels","authorsParsed":[["Rochette","Guillaume",""],["Vowels","Matthew J.",""]],"versions":[{"version":"v1","created":"Sun, 14 Jul 2024 16:20:42 GMT"},{"version":"v2","created":"Tue, 16 Jul 2024 09:30:03 GMT"}],"updateDate":"2024-07-17","timestamp":1720974042000,"abstract":"  psifx is a plug-and-play multi-modal feature extraction toolkit, aiming to\nfacilitate and democratize the use of state-of-the-art machine learning\ntechniques for human sciences research. It is motivated by a need (a) to\nautomate and standardize data annotation processes, otherwise involving\nexpensive, lengthy, and inconsistent human labor, such as the transcription or\ncoding of behavior changes from audio and video sources; (b) to develop and\ndistribute open-source community-driven psychology research software; and (c)\nto enable large-scale access and ease of use to non-expert users. The framework\ncontains an array of tools for tasks, such as speaker diarization,\nclosed-caption transcription and translation from audio, as well as body, hand,\nand facial pose estimation and gaze tracking from video. The package has been\ndesigned with a modular and task-oriented approach, enabling the community to\nadd or update new tools easily. We strongly hope that this package will provide\npsychologists a simple and practical solution for efficiently a range of audio,\nlinguistic, and visual features from audio and video, thereby creating new\nopportunities for in-depth study of real-time behavioral phenomena.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}