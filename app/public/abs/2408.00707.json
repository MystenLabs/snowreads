{"id":"2408.00707","title":"Synthetic dual image generation for reduction of labeling efforts in\n  semantic segmentation of micrographs with a customized metric function","authors":"Matias Oscar Volman Stern, Dominic Hohs, Andreas Jansche, Timo\n  Bernthaler and Gerhard Schneider","authorsParsed":[["Stern","Matias Oscar Volman",""],["Hohs","Dominic",""],["Jansche","Andreas",""],["Bernthaler","Timo",""],["Schneider","Gerhard",""]],"versions":[{"version":"v1","created":"Thu, 1 Aug 2024 16:54:11 GMT"}],"updateDate":"2024-08-02","timestamp":1722531251000,"abstract":"  Training of semantic segmentation models for material analysis requires\nmicrographs and their corresponding masks. It is quite unlikely that perfect\nmasks will be drawn, especially at the edges of objects, and sometimes the\namount of data that can be obtained is small, since only a few samples are\navailable. These aspects make it very problematic to train a robust model. We\ndemonstrate a workflow for the improvement of semantic segmentation models of\nmicrographs through the generation of synthetic microstructural images in\nconjunction with masks. The workflow only requires joining a few micrographs\nwith their respective masks to create the input for a Vector\nQuantised-Variational AutoEncoder model that includes an embedding space, which\nis trained such that a generative model (PixelCNN) learns the distribution of\neach input, transformed into discrete codes, and can be used to sample new\ncodes. The latter will eventually be decoded by VQ-VAE to generate images\nalongside corresponding masks for semantic segmentation. To evaluate the\nsynthetic data, we have trained U-Net models with different amounts of these\nsynthetic data in conjunction with real data. These models were then evaluated\nusing non-synthetic images only. Additionally, we introduce a customized metric\nderived from the mean Intersection over Union (mIoU). The proposed metric\nprevents a few falsely predicted pixels from greatly reducing the value of the\nmIoU. We have achieved a reduction in sample preparation and acquisition times,\nas well as the efforts, needed for image processing and labeling tasks, are\nless when it comes to training semantic segmentation model. The approach could\nbe generalized to various types of image data such that it serves as a\nuser-friendly solution for training models with a small number of real images.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Computational Engineering, Finance, and Science","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"skNbVcp4YNibR2pKoOZcSEC0sNPuoEzgnX-HFKzbcIg","pdfSize":"2310301"}
