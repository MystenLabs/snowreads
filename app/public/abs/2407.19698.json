{"id":"2407.19698","title":"Classification Matters: Improving Video Action Detection with\n  Class-Specific Attention","authors":"Jinsung Lee, Taeoh Kim, Inwoong Lee, Minho Shim, Dongyoon Wee, Minsu\n  Cho, Suha Kwak","authorsParsed":[["Lee","Jinsung",""],["Kim","Taeoh",""],["Lee","Inwoong",""],["Shim","Minho",""],["Wee","Dongyoon",""],["Cho","Minsu",""],["Kwak","Suha",""]],"versions":[{"version":"v1","created":"Mon, 29 Jul 2024 04:43:58 GMT"},{"version":"v2","created":"Tue, 27 Aug 2024 08:06:38 GMT"},{"version":"v3","created":"Wed, 28 Aug 2024 04:41:09 GMT"},{"version":"v4","created":"Wed, 11 Sep 2024 06:56:55 GMT"}],"updateDate":"2024-09-12","timestamp":1722228238000,"abstract":"  Video action detection (VAD) aims to detect actors and classify their actions\nin a video. We figure that VAD suffers more from classification rather than\nlocalization of actors. Hence, we analyze how prevailing methods form features\nfor classification and find that they prioritize actor regions, yet often\noverlooking the essential contextual information necessary for accurate\nclassification. Accordingly, we propose to reduce the bias toward actor and\nencourage paying attention to the context that is relevant to each action\nclass. By assigning a class-dedicated query to each action class, our model can\ndynamically determine where to focus for effective classification. The proposed\nmodel demonstrates superior performance on three challenging benchmarks with\nsignificantly fewer parameters and less computation.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"U8Oa12PNvZM6af6Xm1S1diQZqCQ2Tb9P88LllSTtQGs","pdfSize":"5796513","objectId":"0x20ae6c093741dd70a7e256c9e8484301563925f3c2e125d5b410c3e3c2fc417d","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
