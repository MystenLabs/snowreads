{"id":"2408.05497","title":"MABR: A Multilayer Adversarial Bias Removal Approach Without Prior Bias\n  Knowledge","authors":"Maxwell J. Yin, Boyu Wang, and Charles Ling","authorsParsed":[["Yin","Maxwell J.",""],["Wang","Boyu",""],["Ling","Charles",""]],"versions":[{"version":"v1","created":"Sat, 10 Aug 2024 09:11:01 GMT"}],"updateDate":"2024-08-13","timestamp":1723281061000,"abstract":"  Models trained on real-world data often mirror and exacerbate existing social\nbiases. Traditional methods for mitigating these biases typically require prior\nknowledge of the specific biases to be addressed, such as gender or racial\nbiases, and the social groups associated with each instance. In this paper, we\nintroduce a novel adversarial training strategy that operates independently of\nprior bias-type knowledge and protected attribute labels. Our approach\nproactively identifies biases during model training by utilizing auxiliary\nmodels, which are trained concurrently by predicting the performance of the\nmain model without relying on task labels. Additionally, we implement these\nauxiliary models at various levels of the feature maps of the main model,\nenabling the detection of a broader and more nuanced range of bias features.\nThrough experiments on racial and gender biases in sentiment and occupation\nclassification tasks, our method effectively reduces social biases without the\nneed for demographic annotations. Moreover, our approach not only matches but\noften surpasses the efficacy of methods that require detailed demographic\ninsights, marking a significant advancement in bias mitigation techniques.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}