{"id":"2408.10055","title":"Efficient Exploration in Deep Reinforcement Learning: A Novel Bayesian\n  Actor-Critic Algorithm","authors":"Nikolai Rozanov","authorsParsed":[["Rozanov","Nikolai",""]],"versions":[{"version":"v1","created":"Mon, 19 Aug 2024 14:50:48 GMT"}],"updateDate":"2024-08-20","timestamp":1724079048000,"abstract":"  Reinforcement learning (RL) and Deep Reinforcement Learning (DRL), in\nparticular, have the potential to disrupt and are already changing the way we\ninteract with the world. One of the key indicators of their applicability is\ntheir ability to scale and work in real-world scenarios, that is in large-scale\nproblems. This scale can be achieved via a combination of factors, the\nalgorithm's ability to make use of large amounts of data and computational\nresources and the efficient exploration of the environment for viable solutions\n(i.e. policies).\n  In this work, we investigate and motivate some theoretical foundations for\ndeep reinforcement learning. We start with exact dynamic programming and work\nour way up to stochastic approximations and stochastic approximations for a\nmodel-free scenario, which forms the theoretical basis of modern reinforcement\nlearning. We present an overview of this highly varied and rapidly changing\nfield from the perspective of Approximate Dynamic Programming. We then focus\nour study on the short-comings with respect to exploration of the cornerstone\napproaches (i.e. DQN, DDQN, A2C) in deep reinforcement learning. On the theory\nside, our main contribution is the proposal of a novel Bayesian actor-critic\nalgorithm. On the empirical side, we evaluate Bayesian exploration as well as\nactor-critic algorithms on standard benchmarks as well as state-of-the-art\nevaluation suites and show the benefits of both of these approaches over\ncurrent state-of-the-art deep RL methods. We release all the implementations\nand provide a full python library that is easy to install and hopefully will\nserve the reinforcement learning community in a meaningful way, and provide a\nstrong foundation for future work.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"Y72tZXqkJPXfoP5Qer0ENZVBgXJc1ElL-fADcq5quso","pdfSize":"1371846"}
