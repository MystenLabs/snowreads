{"id":"2408.12791","title":"Open-Set Deepfake Detection: A Parameter-Efficient Adaptation Method\n  with Forgery Style Mixture","authors":"Chenqi Kong, Anwei Luo, Peijun Bao, Haoliang Li, Renjie Wan, Zengwei\n  Zheng, Anderson Rocha, Alex C. Kot","authorsParsed":[["Kong","Chenqi",""],["Luo","Anwei",""],["Bao","Peijun",""],["Li","Haoliang",""],["Wan","Renjie",""],["Zheng","Zengwei",""],["Rocha","Anderson",""],["Kot","Alex C.",""]],"versions":[{"version":"v1","created":"Fri, 23 Aug 2024 01:53:36 GMT"}],"updateDate":"2024-08-26","timestamp":1724378016000,"abstract":"  Open-set face forgery detection poses significant security threats and\npresents substantial challenges for existing detection models. These detectors\nprimarily have two limitations: they cannot generalize across unknown forgery\ndomains and inefficiently adapt to new data. To address these issues, we\nintroduce an approach that is both general and parameter-efficient for face\nforgery detection. It builds on the assumption that different forgery source\ndomains exhibit distinct style statistics. Previous methods typically require\nfully fine-tuning pre-trained networks, consuming substantial time and\ncomputational resources. In turn, we design a forgery-style mixture formulation\nthat augments the diversity of forgery source domains, enhancing the model's\ngeneralizability across unseen domains. Drawing on recent advancements in\nvision transformers (ViT) for face forgery detection, we develop a\nparameter-efficient ViT-based detection model that includes lightweight forgery\nfeature extraction modules and enables the model to extract global and local\nforgery clues simultaneously. We only optimize the inserted lightweight modules\nduring training, maintaining the original ViT structure with its pre-trained\nImageNet weights. This training strategy effectively preserves the informative\npre-trained knowledge while flexibly adapting the model to the task of Deepfake\ndetection. Extensive experimental results demonstrate that the designed model\nachieves state-of-the-art generalizability with significantly reduced trainable\nparameters, representing an important step toward open-set Deepfake detection\nin the wild.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}