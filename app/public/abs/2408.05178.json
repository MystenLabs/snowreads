{"id":"2408.05178","title":"ECG-FM: An Open Electrocardiogram Foundation Model","authors":"Kaden McKeen, Laura Oliva, Sameer Masood, Augustin Toma, Barry Rubin,\n  Bo Wang","authorsParsed":[["McKeen","Kaden",""],["Oliva","Laura",""],["Masood","Sameer",""],["Toma","Augustin",""],["Rubin","Barry",""],["Wang","Bo",""]],"versions":[{"version":"v1","created":"Fri, 9 Aug 2024 17:06:49 GMT"}],"updateDate":"2024-08-12","timestamp":1723223209000,"abstract":"  The electrocardiogram (ECG) is a ubiquitous diagnostic test. Conventional\ntask-specific ECG analysis models require large numbers of expensive ECG\nannotations or associated labels to train. Transfer learning techniques have\nbeen shown to improve generalization and reduce reliance on labeled data. We\npresent ECG-FM, an open foundation model for ECG analysis, and conduct a\ncomprehensive study performed on a dataset of 1.66 million ECGs sourced from\nboth publicly available and private institutional sources. ECG-FM adopts a\ntransformer-based architecture and is pretrained on 2.5 million samples using\nECG-specific augmentations and contrastive learning, as well as a continuous\nsignal masking objective. Our transparent evaluation includes a diverse range\nof downstream tasks, where we predict ECG interpretation labels, reduced left\nventricular ejection fraction, and abnormal cardiac troponin. Affirming\nECG-FM's effectiveness as a foundation model, we demonstrate how its command of\ncontextual information results in strong performance, rich pretrained\nembeddings, and reliable interpretability. Due to a lack of open-weight\npractices, we highlight how ECG analysis is lagging behind other medical\nmachine learning subfields in terms of foundation model adoption. Our code is\navailable at https://github.com/bowang-lab/ECG-FM/.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/"}