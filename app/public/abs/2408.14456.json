{"id":"2408.14456","title":"Center Direction Network for Grasping Point Localization on Cloths","authors":"Domen Tabernik, Jon Muhovi\\v{c}, Matej Urbas and Danijel Sko\\v{c}aj","authorsParsed":[["Tabernik","Domen",""],["Muhovič","Jon",""],["Urbas","Matej",""],["Skočaj","Danijel",""]],"versions":[{"version":"v1","created":"Mon, 26 Aug 2024 17:49:05 GMT"}],"updateDate":"2024-09-13","timestamp":1724694545000,"abstract":"  Object grasping is a fundamental challenge in robotics and computer vision,\ncritical for advancing robotic manipulation capabilities. Deformable objects,\nlike fabrics and cloths, pose additional challenges due to their non-rigid\nnature. In this work, we introduce CeDiRNet-3DoF, a deep-learning model for\ngrasp point detection, with a particular focus on cloth objects. CeDiRNet-3DoF\nemploys center direction regression alongside a localization network, attaining\nfirst place in the perception task of ICRA 2023's Cloth Manipulation Challenge.\nRecognizing the lack of standardized benchmarks in the literature that hinder\neffective method comparison, we present the ViCoS Towel Dataset. This extensive\nbenchmark dataset comprises 8,000 real and 12,000 synthetic images, serving as\na robust resource for training and evaluating contemporary data-driven\ndeep-learning approaches. Extensive evaluation revealed CeDiRNet-3DoF's\nrobustness in real-world performance, outperforming state-of-the-art methods,\nincluding the latest transformer-based models. Our work bridges a crucial gap,\noffering a robust solution and benchmark for cloth grasping in computer vision\nand robotics. Code and dataset are available at:\nhttps://github.com/vicoslab/CeDiRNet-3DoF\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}