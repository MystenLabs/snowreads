{"id":"2407.15186","title":"A Survey on Employing Large Language Models for Text-to-SQL Tasks","authors":"Liang Shi, Zhengju Tang, Nan Zhang, Xiaotong Zhang, Zhi Yang","authorsParsed":[["Shi","Liang",""],["Tang","Zhengju",""],["Zhang","Nan",""],["Zhang","Xiaotong",""],["Yang","Zhi",""]],"versions":[{"version":"v1","created":"Sun, 21 Jul 2024 14:48:23 GMT"},{"version":"v2","created":"Sun, 11 Aug 2024 13:54:21 GMT"},{"version":"v3","created":"Mon, 9 Sep 2024 06:17:21 GMT"}],"updateDate":"2024-09-10","timestamp":1721573303000,"abstract":"  The increasing volume of data stored in relational databases has led to the\nneed for efficient querying and utilization of this data in various sectors.\nHowever, writing SQL queries requires specialized knowledge, which poses a\nchallenge for non-professional users trying to access and query databases.\nText-to-SQL parsing solves this issue by converting natural language queries\ninto SQL queries, thus making database access more accessible for non-expert\nusers. To take advantage of the recent developments in Large Language Models\n(LLMs), a range of new methods have emerged, with a primary focus on prompt\nengineering and fine-tuning. This survey provides a comprehensive overview of\nLLMs in text-to-SQL tasks, discussing benchmark datasets, prompt engineering,\nfine-tuning methods, and future research directions. We hope this review will\nenable readers to gain a broader understanding of the recent advances in this\nfield and offer some insights into its future trajectory.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}