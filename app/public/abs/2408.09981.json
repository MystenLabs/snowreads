{"id":"2408.09981","title":"Parseval Convolution Operators and Neural Networks","authors":"Michael Unser, Stanislas Ducotterd","authorsParsed":[["Unser","Michael",""],["Ducotterd","Stanislas",""]],"versions":[{"version":"v1","created":"Mon, 19 Aug 2024 13:31:16 GMT"}],"updateDate":"2024-08-20","timestamp":1724074276000,"abstract":"  We first establish a kernel theorem that characterizes all linear\nshift-invariant (LSI) operators acting on discrete multicomponent signals. This\nresult naturally leads to the identification of the Parseval convolution\noperators as the class of energy-preserving filterbanks. We then present a\nconstructive approach for the design/specification of such filterbanks via the\nchaining of elementary Parseval modules, each of which being parameterized by\nan orthogonal matrix or a 1-tight frame. Our analysis is complemented with\nexplicit formulas for the Lipschitz constant of all the components of a\nconvolutional neural network (CNN), which gives us a handle on their stability.\nFinally, we demonstrate the usage of those tools with the design of a CNN-based\nalgorithm for the iterative reconstruction of biomedical images. Our algorithm\nfalls within the plug-and-play framework for the resolution of inverse\nproblems. It yields better-quality results than the sparsity-based methods used\nin compressed sensing, while offering essentially the same convergence and\nrobustness guarantees.\n","subjects":["Electrical Engineering and Systems Science/Signal Processing","Computing Research Repository/Machine Learning","Mathematics/Functional Analysis","Statistics/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"BGA-x515-a-4FxhkB7buOKS0jg_fqZxpEIxmSr-Z69k","pdfSize":"1093755"}
