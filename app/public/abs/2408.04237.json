{"id":"2408.04237","title":"Learning to Rewrite: Generalized LLM-Generated Text Detection","authors":"Wei Hao, Ran Li, Weiliang Zhao, Junfeng Yang, Chengzhi Mao","authorsParsed":[["Hao","Wei",""],["Li","Ran",""],["Zhao","Weiliang",""],["Yang","Junfeng",""],["Mao","Chengzhi",""]],"versions":[{"version":"v1","created":"Thu, 8 Aug 2024 05:53:39 GMT"}],"updateDate":"2024-08-09","timestamp":1723096419000,"abstract":"  Large language models (LLMs) can be abused at scale to create non-factual\ncontent and spread disinformation. Detecting LLM-generated content is essential\nto mitigate these risks, but current classifiers often fail to generalize in\nopen-world contexts. Prior work shows that LLMs tend to rewrite LLM-generated\ncontent less frequently, which can be used for detection and naturally\ngeneralizes to unforeseen data. However, we find that the rewriting edit\ndistance between human and LLM content can be indistinguishable across domains,\nleading to detection failures. We propose training an LLM to rewrite input\ntext, producing minimal edits for LLM-generated content and more edits for\nhuman-written text, deriving a distinguishable and generalizable edit distance\ndifference across different domains. Experiments on text from 21 independent\ndomains and three popular LLMs (e.g., GPT-4o, Gemini, and Llama-3) show that\nour classifier outperforms the state-of-the-art zero-shot classifier by up to\n20.6% on AUROC score and the rewriting classifier by 9.2% on F1 score. Our work\nsuggests that LLM can effectively detect machine-generated text if they are\ntrained properly.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"fPWbhucFy5J2SCGPo10MIp0QQOsWudOIsq0dMrkXUf8","pdfSize":"604603"}
