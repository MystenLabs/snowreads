{"id":"2407.11017","title":"Direct-Inverse Prompting: Analyzing LLMs' Discriminative Capacity in\n  Self-Improving Generation","authors":"Jihyun Janice Ahn, Ryo Kamoi, Lu Cheng, Rui Zhang, Wenpeng Yin","authorsParsed":[["Ahn","Jihyun Janice",""],["Kamoi","Ryo",""],["Cheng","Lu",""],["Zhang","Rui",""],["Yin","Wenpeng",""]],"versions":[{"version":"v1","created":"Thu, 27 Jun 2024 02:26:47 GMT"}],"updateDate":"2024-07-17","timestamp":1719455207000,"abstract":"  Mainstream LLM research has primarily focused on enhancing their generative\ncapabilities. However, even the most advanced LLMs experience uncertainty in\ntheir outputs, often producing varied results on different runs or when faced\nwith minor changes in input, despite no substantial change in content. Given\nmultiple responses from the same LLM to the same input, we advocate leveraging\nthe LLMs' discriminative capability to reduce this generative uncertainty,\naiding in identifying the correct answers. Specifically, we propose and analyze\nthree discriminative prompts: direct, inverse, and hybrid, to explore the\npotential of both closed-source and open-source LLMs in self-improving their\ngenerative performance on two benchmark datasets. Our insights reveal which\ndiscriminative prompt is most promising and when to use it. To our knowledge,\nthis is the first work to systematically analyze LLMs' discriminative capacity\nto address generative uncertainty.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}