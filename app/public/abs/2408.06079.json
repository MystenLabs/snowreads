{"id":"2408.06079","title":"Towards Adversarial Robustness via Debiased High-Confidence Logit\n  Alignment","authors":"Kejia Zhang, Juanjuan Weng, Zhiming Luo, Shaozi Li","authorsParsed":[["Zhang","Kejia",""],["Weng","Juanjuan",""],["Luo","Zhiming",""],["Li","Shaozi",""]],"versions":[{"version":"v1","created":"Mon, 12 Aug 2024 11:56:06 GMT"}],"updateDate":"2024-08-13","timestamp":1723463766000,"abstract":"  Despite the significant advances that deep neural networks (DNNs) have\nachieved in various visual tasks, they still exhibit vulnerability to\nadversarial examples, leading to serious security concerns. Recent adversarial\ntraining techniques have utilized inverse adversarial attacks to generate\nhigh-confidence examples, aiming to align the distributions of adversarial\nexamples with the high-confidence regions of their corresponding classes.\nHowever, in this paper, our investigation reveals that high-confidence outputs\nunder inverse adversarial attacks are correlated with biased feature\nactivation. Specifically, training with inverse adversarial examples causes the\nmodel's attention to shift towards background features, introducing a spurious\ncorrelation bias. To address this bias, we propose Debiased High-Confidence\nAdversarial Training (DHAT), a novel approach that not only aligns the logits\nof adversarial examples with debiased high-confidence logits obtained from\ninverse adversarial examples, but also restores the model's attention to its\nnormal state by enhancing foreground logit orthogonality. Extensive experiments\ndemonstrate that DHAT achieves state-of-the-art performance and exhibits robust\ngeneralization capabilities across various vision datasets. Additionally, DHAT\ncan seamlessly integrate with existing advanced adversarial training techniques\nfor improving the performance.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}