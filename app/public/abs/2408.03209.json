{"id":"2408.03209","title":"IPAdapter-Instruct: Resolving Ambiguity in Image-based Conditioning\n  using Instruct Prompts","authors":"Ciara Rowles, Shimon Vainer, Dante De Nigris, Slava Elizarov,\n  Konstantin Kutsy, Simon Donn\\'e","authorsParsed":[["Rowles","Ciara",""],["Vainer","Shimon",""],["De Nigris","Dante",""],["Elizarov","Slava",""],["Kutsy","Konstantin",""],["Donn√©","Simon",""]],"versions":[{"version":"v1","created":"Tue, 6 Aug 2024 14:08:22 GMT"},{"version":"v2","created":"Tue, 27 Aug 2024 12:39:18 GMT"}],"updateDate":"2024-08-28","timestamp":1722953302000,"abstract":"  Diffusion models continuously push the boundary of state-of-the-art image\ngeneration, but the process is hard to control with any nuance: practice proves\nthat textual prompts are inadequate for accurately describing image style or\nfine structural details (such as faces). ControlNet and IPAdapter address this\nshortcoming by conditioning the generative process on imagery instead, but each\nindividual instance is limited to modeling a single conditional posterior: for\npractical use-cases, where multiple different posteriors are desired within the\nsame workflow, training and using multiple adapters is cumbersome. We propose\nIPAdapter-Instruct, which combines natural-image conditioning with ``Instruct''\nprompts to swap between interpretations for the same conditioning image: style\ntransfer, object extraction, both, or something else still? IPAdapterInstruct\nefficiently learns multiple tasks with minimal loss in quality compared to\ndedicated per-task models.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"E98x_GsCJ7QqPGN58_0QPSktA_HoO9O7kjszrJm5Kek","pdfSize":"34263989"}
