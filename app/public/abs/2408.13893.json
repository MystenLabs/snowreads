{"id":"2408.13893","title":"SimpleSpeech 2: Towards Simple and Efficient Text-to-Speech with\n  Flow-based Scalar Latent Transformer Diffusion Models","authors":"Dongchao Yang, Rongjie Huang, Yuanyuan Wang, Haohan Guo, Dading Chong,\n  Songxiang Liu, Xixin Wu, Helen Meng","authorsParsed":[["Yang","Dongchao",""],["Huang","Rongjie",""],["Wang","Yuanyuan",""],["Guo","Haohan",""],["Chong","Dading",""],["Liu","Songxiang",""],["Wu","Xixin",""],["Meng","Helen",""]],"versions":[{"version":"v1","created":"Sun, 25 Aug 2024 17:07:39 GMT"},{"version":"v2","created":"Wed, 28 Aug 2024 07:16:37 GMT"}],"updateDate":"2024-08-29","timestamp":1724605659000,"abstract":"  Scaling Text-to-speech (TTS) to large-scale datasets has been demonstrated as\nan effective method for improving the diversity and naturalness of synthesized\nspeech. At the high level, previous large-scale TTS models can be categorized\ninto either Auto-regressive (AR) based (\\textit{e.g.}, VALL-E) or\nNon-auto-regressive (NAR) based models (\\textit{e.g.}, NaturalSpeech 2/3).\nAlthough these works demonstrate good performance, they still have potential\nweaknesses. For instance, AR-based models are plagued by unstable generation\nquality and slow generation speed; meanwhile, some NAR-based models need\nphoneme-level duration alignment information, thereby increasing the complexity\nof data pre-processing, model design, and loss design. In this work, we build\nupon our previous publication by implementing a simple and efficient\nnon-autoregressive (NAR) TTS framework, termed SimpleSpeech 2. SimpleSpeech 2\neffectively combines the strengths of both autoregressive (AR) and\nnon-autoregressive (NAR) methods, offering the following key advantages: (1)\nsimplified data preparation; (2) straightforward model and loss design; and (3)\nstable, high-quality generation performance with fast inference speed. Compared\nto our previous publication, we present ({\\romannumeral1}) a detailed analysis\nof the influence of speech tokenizer and noisy label for TTS performance;\n({\\romannumeral2}) four distinct types of sentence duration predictors;\n({\\romannumeral3}) a novel flow-based scalar latent transformer diffusion\nmodel. With these improvement, we show a significant improvement in generation\nperformance and generation speed compared to our previous work and other\nstate-of-the-art (SOTA) large-scale TTS models. Furthermore, we show that\nSimpleSpeech 2 can be seamlessly extended to multilingual TTS by training it on\nmultilingual speech datasets. Demos are available on:\n{https://dongchaoyang.top/SimpleSpeech2\\_demo/}.\n","subjects":["Computing Research Repository/Sound","Computing Research Repository/Computation and Language","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}