{"id":"2407.12402","title":"TurkishMMLU: Measuring Massive Multitask Language Understanding in\n  Turkish","authors":"Arda Y\\\"uksel, Abdullatif K\\\"oksal, L\\\"utfi Kerem \\c{S}enel, Anna\n  Korhonen, Hinrich Sch\\\"utze","authorsParsed":[["Yüksel","Arda",""],["Köksal","Abdullatif",""],["Şenel","Lütfi Kerem",""],["Korhonen","Anna",""],["Schütze","Hinrich",""]],"versions":[{"version":"v1","created":"Wed, 17 Jul 2024 08:28:55 GMT"}],"updateDate":"2024-07-18","timestamp":1721204935000,"abstract":"  Multiple choice question answering tasks evaluate the reasoning,\ncomprehension, and mathematical abilities of Large Language Models (LLMs).\nWhile existing benchmarks employ automatic translation for multilingual\nevaluation, this approach is error-prone and potentially introduces culturally\nbiased questions, especially in social sciences. We introduce the first\nmultitask, multiple-choice Turkish QA benchmark, TurkishMMLU, to evaluate LLMs'\nunderstanding of the Turkish language. TurkishMMLU includes over 10,000\nquestions, covering 9 different subjects from Turkish high-school education\ncurricula. These questions are written by curriculum experts, suitable for the\nhigh-school curricula in Turkey, covering subjects ranging from natural\nsciences and math questions to more culturally representative topics such as\nTurkish Literature and the history of the Turkish Republic. We evaluate over 20\nLLMs, including multilingual open-source (e.g., Gemma, Llama, MT5),\nclosed-source (GPT 4o, Claude, Gemini), and Turkish-adapted (e.g., Trendyol)\nmodels. We provide an extensive evaluation, including zero-shot and few-shot\nevaluation of LLMs, chain-of-thought reasoning, and question difficulty\nanalysis along with model performance. We provide an in-depth analysis of the\nTurkish capabilities and limitations of current LLMs to provide insights for\nfuture LLMs for the Turkish language. We publicly release our code for the\ndataset and evaluation: https://github.com/ArdaYueksel/TurkishMMLU.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}