{"id":"2407.12332","title":"Why Do You Grok? A Theoretical Analysis of Grokking Modular Addition","authors":"Mohamad Amin Mohamadi, Zhiyuan Li, Lei Wu, Danica J. Sutherland","authorsParsed":[["Mohamadi","Mohamad Amin",""],["Li","Zhiyuan",""],["Wu","Lei",""],["Sutherland","Danica J.",""]],"versions":[{"version":"v1","created":"Wed, 17 Jul 2024 06:15:30 GMT"}],"updateDate":"2024-07-18","timestamp":1721196930000,"abstract":"  We present a theoretical explanation of the ``grokking'' phenomenon, where a\nmodel generalizes long after overfitting,for the originally-studied problem of\nmodular addition. First, we show that early in gradient descent, when the\n``kernel regime'' approximately holds, no permutation-equivariant model can\nachieve small population error on modular addition unless it sees at least a\nconstant fraction of all possible data points. Eventually, however, models\nescape the kernel regime. We show that two-layer quadratic networks that\nachieve zero training loss with bounded $\\ell_{\\infty}$ norm generalize well\nwith substantially fewer training points, and further show such networks exist\nand can be found by gradient descent with small $\\ell_{\\infty}$ regularization.\nWe further provide empirical evidence that these networks as well as simple\nTransformers, leave the kernel regime only after initially overfitting. Taken\ntogether, our results strongly support the case for grokking as a consequence\nof the transition from kernel-like behavior to limiting behavior of gradient\ndescent on deep networks.\n","subjects":["Computing Research Repository/Machine Learning","Statistics/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}