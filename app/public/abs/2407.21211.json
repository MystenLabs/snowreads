{"id":"2407.21211","title":"Self-Supervised Models in Automatic Whispered Speech Recognition","authors":"Aref Farhadipour, Homa Asadi, Volker Dellwo","authorsParsed":[["Farhadipour","Aref",""],["Asadi","Homa",""],["Dellwo","Volker",""]],"versions":[{"version":"v1","created":"Tue, 30 Jul 2024 21:45:37 GMT"}],"updateDate":"2024-08-01","timestamp":1722375937000,"abstract":"  In automatic speech recognition, any factor that alters the acoustic\nproperties of speech can pose a challenge to the system's performance. This\npaper presents a novel approach for automatic whispered speech recognition in\nthe Irish dialect using the self-supervised WavLM model. Conventional automatic\nspeech recognition systems often fail to accurately recognise whispered speech\ndue to its distinct acoustic properties and the scarcity of relevant training\ndata. To address this challenge, we utilized a pre-trained WavLM model,\nfine-tuned with a combination of whispered and normal speech data from the\nwTIMIT and CHAINS datasets, which include the English language in Singaporean\nand Irish dialects, respectively. Our baseline evaluation with the OpenAI\nWhisper model highlighted its limitations, achieving a Word Error Rate (WER) of\n18.8% on whispered speech. In contrast, the proposed WavLM-based system\nsignificantly improved performance, achieving a WER of 9.22%. These results\ndemonstrate the efficacy of our approach in recognising whispered speech and\nunderscore the importance of tailored acoustic modeling for robust automatic\nspeech recognition systems. This study provides valuable insights into\ndeveloping effective automatic speech recognition solutions for challenging\nspeech affected by whisper and dialect. The source codes for this paper are\nfreely available.\n","subjects":["Electrical Engineering and Systems Science/Audio and Speech Processing","Computing Research Repository/Sound"],"license":"http://creativecommons.org/licenses/by/4.0/"}