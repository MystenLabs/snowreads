{"id":"2408.12068","title":"Simplified Mamba with Disentangled Dependency Encoding for Long-Term\n  Time Series Forecasting","authors":"Zixuan Weng, Jindong Han, Wenzhao Jiang, Hao Liu","authorsParsed":[["Weng","Zixuan",""],["Han","Jindong",""],["Jiang","Wenzhao",""],["Liu","Hao",""]],"versions":[{"version":"v1","created":"Thu, 22 Aug 2024 02:14:59 GMT"}],"updateDate":"2024-08-23","timestamp":1724292899000,"abstract":"  Recently many deep learning models have been proposed for Long-term Time\nSeries Forecasting (LTSF). Based on previous literature, we identify three\ncritical patterns that can improve forecasting accuracy: the order and semantic\ndependencies in time dimension as well as cross-variate dependency. However,\nlittle effort has been made to simultaneously consider order and semantic\ndependencies when developing forecasting models. Moreover, existing approaches\nutilize cross-variate dependency by mixing information from different\ntimestamps and variates, which may introduce irrelevant or harmful\ncross-variate information to the time dimension and largely hinder forecasting\nperformance. To overcome these limitations, we investigate the potential of\nMamba for LTSF and discover two key advantages benefiting forecasting: (i) the\nselection mechanism makes Mamba focus on or ignore specific inputs and learn\nsemantic dependency easily, and (ii) Mamba preserves order dependency by\nprocessing sequences recursively. After that, we empirically find that the\nnon-linear activation used in Mamba is unnecessary for semantically sparse time\nseries data. Therefore, we further propose SAMBA, a Simplified Mamba with\ndisentangled dependency encoding. Specifically, we first remove the\nnon-linearities of Mamba to make it more suitable for LTSF. Furthermore, we\npropose a disentangled dependency encoding strategy to endow Mamba with\ncross-variate dependency modeling capabilities while reducing the interference\nbetween time and variate dimensions. Extensive experimental results on seven\nreal-world datasets demonstrate the effectiveness of SAMBA over\nstate-of-the-art forecasting models.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}