{"id":"2408.03619","title":"Making Robust Generalizers Less Rigid with Soft Ascent-Descent","authors":"Matthew J. Holland, Toma Hamada","authorsParsed":[["Holland","Matthew J.",""],["Hamada","Toma",""]],"versions":[{"version":"v1","created":"Wed, 7 Aug 2024 08:23:42 GMT"}],"updateDate":"2024-08-08","timestamp":1723019022000,"abstract":"  While the traditional formulation of machine learning tasks is in terms of\nperformance on average, in practice we are often interested in how well a\ntrained model performs on rare or difficult data points at test time. To\nachieve more robust and balanced generalization, methods applying\nsharpness-aware minimization to a subset of worst-case examples have proven\nsuccessful for image classification tasks, but only using deep neural networks\nin a scenario where the most difficult points are also the least common. In\nthis work, we show how such a strategy can dramatically break down under more\ndiverse models, and as a more robust alternative, instead of typical sharpness\nwe propose and evaluate a training criterion which penalizes poor loss\nconcentration, which can be easily combined with loss transformations such as\nCVaR or DRO that control tail emphasis.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}