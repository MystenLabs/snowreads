{"id":"2407.01015","title":"Bayesian Entropy Neural Networks for Physics-Aware Prediction","authors":"Rahul Rathnakumar, Jiayu Huang, Hao Yan, Yongming Liu","authorsParsed":[["Rathnakumar","Rahul",""],["Huang","Jiayu",""],["Yan","Hao",""],["Liu","Yongming",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 07:00:44 GMT"}],"updateDate":"2024-07-02","timestamp":1719817244000,"abstract":"  This paper addresses the need for deep learning models to integrate\nwell-defined constraints into their outputs, driven by their application in\nsurrogate models, learning with limited data and partial information, and\nscenarios requiring flexible model behavior to incorporate non-data sample\ninformation. We introduce Bayesian Entropy Neural Networks (BENN), a framework\ngrounded in Maximum Entropy (MaxEnt) principles, designed to impose constraints\non Bayesian Neural Network (BNN) predictions. BENN is capable of constraining\nnot only the predicted values but also their derivatives and variances,\nensuring a more robust and reliable model output. To achieve simultaneous\nuncertainty quantification and constraint satisfaction, we employ the method of\nmultipliers approach. This allows for the concurrent estimation of neural\nnetwork parameters and the Lagrangian multipliers associated with the\nconstraints. Our experiments, spanning diverse applications such as beam\ndeflection modeling and microstructure generation, demonstrate the\neffectiveness of BENN. The results highlight significant improvements over\ntraditional BNNs and showcase competitive performance relative to contemporary\nconstrained deep learning methods.\n","subjects":["Statistics/Machine Learning","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"jByVh7JNEV08PeS1Ahx2I4WYuudWZH1mVl1Mbd1yPEE","pdfSize":"1327835"}
