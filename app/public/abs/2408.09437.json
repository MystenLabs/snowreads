{"id":"2408.09437","title":"Hindi-BEIR : A Large Scale Retrieval Benchmark in Hindi","authors":"Arkadeep Acharya, Rudra Murthy, Vishwajeet Kumar, Jaydeep Sen","authorsParsed":[["Acharya","Arkadeep",""],["Murthy","Rudra",""],["Kumar","Vishwajeet",""],["Sen","Jaydeep",""]],"versions":[{"version":"v1","created":"Sun, 18 Aug 2024 10:55:04 GMT"}],"updateDate":"2024-08-20","timestamp":1723978504000,"abstract":"  Given the large number of Hindi speakers worldwide, there is a pressing need\nfor robust and efficient information retrieval systems for Hindi. Despite\nongoing research, there is a lack of comprehensive benchmark for evaluating\nretrieval models in Hindi. To address this gap, we introduce the Hindi version\nof the BEIR benchmark, which includes a subset of English BEIR datasets\ntranslated to Hindi, existing Hindi retrieval datasets, and synthetically\ncreated datasets for retrieval. The benchmark is comprised of $15$ datasets\nspanning across $8$ distinct tasks. We evaluate state-of-the-art multilingual\nretrieval models on this benchmark to identify task and domain-specific\nchallenges and their impact on retrieval performance. By releasing this\nbenchmark and a set of relevant baselines, we enable researchers to understand\nthe limitations and capabilities of current Hindi retrieval models, promoting\nadvancements in this critical area. The datasets from Hindi-BEIR are publicly\navailable.\n","subjects":["Computing Research Repository/Information Retrieval","Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"nAJLdwnk7Zd-cdkQsGBJVhIHoFyrlQZUUH4P7vn5IOw","pdfSize":"3029587"}
