{"id":"2408.04197","title":"Pairwise Judgment Formulation for Semantic Embedding Model in Web Search","authors":"Mengze Hong, Chen Jason Zhang","authorsParsed":[["Hong","Mengze",""],["Zhang","Chen Jason",""]],"versions":[{"version":"v1","created":"Thu, 8 Aug 2024 03:35:35 GMT"}],"updateDate":"2024-08-09","timestamp":1723088135000,"abstract":"  Semantic Embedding Model (SEM), a neural network-based Siamese architecture,\nis gaining momentum in information retrieval and natural language processing.\nIn order to train SEM in a supervised fashion for Web search, the search engine\nquery log is typically utilized to automatically formulate pairwise judgments\nas training data. Despite the growing application of semantic embeddings in the\nsearch engine industry, little work has been done on formulating effective\npairwise judgments for training SEM. In this paper, we make the first in-depth\ninvestigation of a wide range of strategies for generating pairwise judgments\nfor SEM. An interesting (perhaps surprising) discovery reveals that the\nconventional pairwise judgment formulation strategy wildly used in the field of\npairwise Learning-to-Rank (LTR) is not necessarily effective for training SEM.\nThrough a large-scale empirical study based on query logs and click-through\nactivities from a major commercial search engine, we demonstrate the effective\nstrategies for SEM and highlight the advantages of a hybrid heuristic (i.e.,\nClicked > Non-Clicked) in comparison to the atomic heuristics (e.g., Clicked >\nSkipped) in LTR. We conclude with best practices for training SEM and offer\npromising insights for future research.\n","subjects":["Computing Research Repository/Information Retrieval","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Databases"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}