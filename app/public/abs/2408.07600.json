{"id":"2408.07600","title":"Disentangle and denoise: Tackling context misalignment for video moment\n  retrieval","authors":"Kaijing Ma, Han Fang, Xianghao Zang, Chao Ban, Lanxiang Zhou,\n  Zhongjiang He, Yongxiang Li, Hao Sun, Zerun Feng, Xingsong Hou","authorsParsed":[["Ma","Kaijing",""],["Fang","Han",""],["Zang","Xianghao",""],["Ban","Chao",""],["Zhou","Lanxiang",""],["He","Zhongjiang",""],["Li","Yongxiang",""],["Sun","Hao",""],["Feng","Zerun",""],["Hou","Xingsong",""]],"versions":[{"version":"v1","created":"Wed, 14 Aug 2024 15:00:27 GMT"}],"updateDate":"2024-08-15","timestamp":1723647627000,"abstract":"  Video Moment Retrieval, which aims to locate in-context video moments\naccording to a natural language query, is an essential task for cross-modal\ngrounding. Existing methods focus on enhancing the cross-modal interactions\nbetween all moments and the textual description for video understanding.\nHowever, constantly interacting with all locations is unreasonable because of\nuneven semantic distribution across the timeline and noisy visual backgrounds.\nThis paper proposes a cross-modal Context Denoising Network (CDNet) for\naccurate moment retrieval by disentangling complex correlations and denoising\nirrelevant dynamics.Specifically, we propose a query-guided semantic\ndisentanglement (QSD) to decouple video moments by estimating alignment levels\naccording to the global and fine-grained correlation. A Context-aware Dynamic\nDenoisement (CDD) is proposed to enhance understanding of aligned\nspatial-temporal details by learning a group of query-relevant offsets.\nExtensive experiments on public benchmarks demonstrate that the proposed CDNet\nachieves state-of-the-art performances.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"JKHBCA8OUl-F0sMqHCZHWru7S7KBvUVfwU4-TDwN_fU","pdfSize":"7119138"}
