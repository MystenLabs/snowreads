{"id":"2408.08027","title":"Enhancing Large Language Model-based Speech Recognition by\n  Contextualization for Rare and Ambiguous Words","authors":"Kento Nozawa, Takashi Masuko, Toru Taniguchi","authorsParsed":[["Nozawa","Kento",""],["Masuko","Takashi",""],["Taniguchi","Toru",""]],"versions":[{"version":"v1","created":"Thu, 15 Aug 2024 08:50:58 GMT"}],"updateDate":"2024-08-16","timestamp":1723711858000,"abstract":"  We develop a large language model (LLM) based automatic speech recognition\n(ASR) system that can be contextualized by providing keywords as prior\ninformation in text prompts. We adopt decoder-only architecture and use our\nin-house LLM, PLaMo-100B, pre-trained from scratch using datasets dominated by\nJapanese and English texts as the decoder. We adopt a pre-trained Whisper\nencoder as an audio encoder, and the audio embeddings from the audio encoder\nare projected to the text embedding space by an adapter layer and concatenated\nwith text embeddings converted from text prompts to form inputs to the decoder.\nBy providing keywords as prior information in the text prompts, we can\ncontextualize our LLM-based ASR system without modifying the model architecture\nto transcribe ambiguous words in the input audio accurately. Experimental\nresults demonstrate that providing keywords to the decoder can significantly\nimprove the recognition performance of rare and ambiguous words.\n","subjects":["Electrical Engineering and Systems Science/Audio and Speech Processing","Computing Research Repository/Computation and Language","Computing Research Repository/Sound"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"akRUfjjdkEibjcsy1YsgWKgV6mseCqsHJl-p_Aa35WQ","pdfSize":"668384"}
