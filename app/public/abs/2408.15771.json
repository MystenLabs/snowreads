{"id":"2408.15771","title":"wav2pos: Sound Source Localization using Masked Autoencoders","authors":"Axel Berg, Jens Gulin, Mark O'Connor, Chuteng Zhou, Karl {\\AA}str\\\"om,\n  Magnus Oskarsson","authorsParsed":[["Berg","Axel",""],["Gulin","Jens",""],["O'Connor","Mark",""],["Zhou","Chuteng",""],["Åström","Karl",""],["Oskarsson","Magnus",""]],"versions":[{"version":"v1","created":"Wed, 28 Aug 2024 13:09:20 GMT"}],"updateDate":"2024-08-29","timestamp":1724850560000,"abstract":"  We present a novel approach to the 3D sound source localization task for\ndistributed ad-hoc microphone arrays by formulating it as a set-to-set\nregression problem. By training a multi-modal masked autoencoder model that\noperates on audio recordings and microphone coordinates, we show that such a\nformulation allows for accurate localization of the sound source, by\nreconstructing coordinates masked in the input. Our approach is flexible in the\nsense that a single model can be used with an arbitrary number of microphones,\neven when a subset of audio recordings and microphone coordinates are missing.\nWe test our method on simulated and real-world recordings of music and speech\nin indoor environments, and demonstrate competitive performance compared to\nboth classical and other learning based localization methods.\n","subjects":["Electrical Engineering and Systems Science/Audio and Speech Processing","Computing Research Repository/Machine Learning","Computing Research Repository/Sound"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}