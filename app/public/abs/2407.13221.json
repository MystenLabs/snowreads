{"id":"2407.13221","title":"Multimodal Label Relevance Ranking via Reinforcement Learning","authors":"Taian Guo, Taolin Zhang, Haoqian Wu, Hanjun Li, Ruizhi Qiao, Xing Sun","authorsParsed":[["Guo","Taian",""],["Zhang","Taolin",""],["Wu","Haoqian",""],["Li","Hanjun",""],["Qiao","Ruizhi",""],["Sun","Xing",""]],"versions":[{"version":"v1","created":"Thu, 18 Jul 2024 07:06:49 GMT"}],"updateDate":"2024-07-19","timestamp":1721286409000,"abstract":"  Conventional multi-label recognition methods often focus on label confidence,\nfrequently overlooking the pivotal role of partial order relations consistent\nwith human preference. To resolve these issues, we introduce a novel method for\nmultimodal label relevance ranking, named Label Relevance Ranking with Proximal\nPolicy Optimization (LR\\textsuperscript{2}PPO), which effectively discerns\npartial order relations among labels. LR\\textsuperscript{2}PPO first utilizes\npartial order pairs in the target domain to train a reward model, which aims to\ncapture human preference intrinsic to the specific scenario. Furthermore, we\nmeticulously design state representation and a policy loss tailored for ranking\ntasks, enabling LR\\textsuperscript{2}PPO to boost the performance of label\nrelevance ranking model and largely reduce the requirement of partial order\nannotation for transferring to new scenes. To assist in the evaluation of our\napproach and similar methods, we further propose a novel benchmark dataset,\nLRMovieNet, featuring multimodal labels and their corresponding partial order\ndata. Extensive experiments demonstrate that our LR\\textsuperscript{2}PPO\nalgorithm achieves state-of-the-art performance, proving its effectiveness in\naddressing the multimodal label relevance ranking problem. Codes and the\nproposed LRMovieNet dataset are publicly available at\n\\url{https://github.com/ChazzyGordon/LR2PPO}.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}