{"id":"2407.19875","title":"Exploring Robust Face-Voice Matching in Multilingual Environments","authors":"Jiehui Tang, Xiaofei Wang, Zhen Xiao, Jiayi Liu, Xueliang Liu, Richang\n  Hong","authorsParsed":[["Tang","Jiehui",""],["Wang","Xiaofei",""],["Xiao","Zhen",""],["Liu","Jiayi",""],["Liu","Xueliang",""],["Hong","Richang",""]],"versions":[{"version":"v1","created":"Mon, 29 Jul 2024 10:51:31 GMT"}],"updateDate":"2024-07-30","timestamp":1722250291000,"abstract":"  This paper presents Team Xaiofei's innovative approach to exploring\nFace-Voice Association in Multilingual Environments (FAME) at ACM Multimedia\n2024. We focus on the impact of different languages in face-voice matching by\nbuilding upon Fusion and Orthogonal Projection (FOP), introducing four key\ncomponents: a dual-branch structure, dynamic sample pair weighting, robust data\naugmentation, and score polarization strategy. Our dual-branch structure serves\nas an auxiliary mechanism to better integrate and provide more comprehensive\ninformation. We also introduce a dynamic weighting mechanism for various sample\npairs to optimize learning. Data augmentation techniques are employed to\nenhance the model's generalization across diverse conditions. Additionally,\nscore polarization strategy based on age and gender matching confidence\nclarifies and accentuates the final results. Our methods demonstrate\nsignificant effectiveness, achieving an equal error rate (EER) of 20.07 on the\nV2-EH dataset and 21.76 on the V1-EU dataset.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}