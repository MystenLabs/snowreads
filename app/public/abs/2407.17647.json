{"id":"2407.17647","title":"An Energy-Efficient Artefact Detection Accelerator on FPGAs for\n  Hyper-Spectral Satellite Imagery","authors":"Cornell Castelino, Shashwat Khandelwal, Shanker Shreejith,\n  Sharatchandra Varma Bogaraju","authorsParsed":[["Castelino","Cornell",""],["Khandelwal","Shashwat",""],["Shreejith","Shanker",""],["Bogaraju","Sharatchandra Varma",""]],"versions":[{"version":"v1","created":"Wed, 24 Jul 2024 21:24:56 GMT"}],"updateDate":"2024-07-26","timestamp":1721856296000,"abstract":"  Hyper-Spectral Imaging (HSI) is a crucial technique for analysing remote\nsensing data acquired from Earth observation satellites. The rich spatial and\nspectral information obtained through HSI allows for better characterisation\nand exploration of the Earth's surface over traditional techniques like RGB and\nMulti-Spectral imaging on the downlinked image data at ground stations.\nSometimes, these images do not contain meaningful information due to the\npresence of clouds or other artefacts, limiting their usefulness. Transmission\nof such artefact HSI images leads to wasteful use of already scarce energy and\ntime costs required for communication. While detecting such artefacts before\ntransmitting the HSI image is desirable, the computational complexity of these\nalgorithms and the limited power budget on satellites (especially CubeSats) are\nkey constraints. This paper presents an unsupervised learning-based\nconvolutional autoencoder (CAE) model for artefact identification of acquired\nHSI images at the satellite and a deployment architecture on AMD's Zynq\nUltrascale FPGAs. The model is trained and tested on widely used HSI image\ndatasets: Indian Pines, Salinas Valley, the University of Pavia and the Kennedy\nSpace Center. For deployment, the model is quantised to 8-bit precision,\nfine-tuned using the Vitis-AI framework and integrated as a subordinate\naccelerator using AMD's Deep-Learning Processing Units (DPU) instance on the\nZynq device. Our tests show that the model can process each spectral band in an\nHSI image in 4 ms, 2.6x better than INT8 inference on Nvidia's Jetson platform\n& 1.27x better than SOTA artefact detectors. Our model also achieves an\nf1-score of 92.8% and FPR of 0% across the dataset, while consuming 21.52 mJ\nper HSI image, 3.6x better than INT8 Jetson inference & 7.5x better than SOTA\nartefact detectors, making it a viable architecture for deployment in CubeSats.\n","subjects":["Computing Research Repository/Hardware Architecture"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"Yh9XBCBNppfSDY3zOkqIVUEDejEM3DKbfVkSA4H83cI","pdfSize":"3695483","objectId":"0x80d50bdb278b66ef003c640fa4fdbbef9875b49cff6a4762bef2eec828922720","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
