{"id":"2408.09839","title":"Segment-Anything Models Achieve Zero-shot Robustness in Autonomous\n  Driving","authors":"Jun Yan, Pengyu Wang, Danni Wang, Weiquan Huang, Daniel Watzenig,\n  Huilin Yin","authorsParsed":[["Yan","Jun",""],["Wang","Pengyu",""],["Wang","Danni",""],["Huang","Weiquan",""],["Watzenig","Daniel",""],["Yin","Huilin",""]],"versions":[{"version":"v1","created":"Mon, 19 Aug 2024 09:35:51 GMT"}],"updateDate":"2024-08-20","timestamp":1724060151000,"abstract":"  Semantic segmentation is a significant perception task in autonomous driving.\nIt suffers from the risks of adversarial examples. In the past few years, deep\nlearning has gradually transitioned from convolutional neural network (CNN)\nmodels with a relatively small number of parameters to foundation models with a\nhuge number of parameters. The segment-anything model (SAM) is a generalized\nimage segmentation framework that is capable of handling various types of\nimages and is able to recognize and segment arbitrary objects in an image\nwithout the need to train on a specific object. It is a unified model that can\nhandle diverse downstream tasks, including semantic segmentation, object\ndetection, and tracking. In the task of semantic segmentation for autonomous\ndriving, it is significant to study the zero-shot adversarial robustness of\nSAM. Therefore, we deliver a systematic empirical study on the robustness of\nSAM without additional training. Based on the experimental results, the\nzero-shot adversarial robustness of the SAM under the black-box corruptions and\nwhite-box adversarial attacks is acceptable, even without the need for\nadditional training. The finding of this study is insightful in that the\ngigantic model parameters and huge amounts of training data lead to the\nphenomenon of emergence, which builds a guarantee of adversarial robustness.\nSAM is a vision foundation model that can be regarded as an early prototype of\nan artificial general intelligence (AGI) pipeline. In such a pipeline, a\nunified model can handle diverse tasks. Therefore, this research not only\ninspects the impact of vision foundation models on safe autonomous driving but\nalso provides a perspective on developing trustworthy AGI. The code is\navailable at: https://github.com/momo1986/robust_sam_iv.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/"}