{"id":"2407.07667","title":"VEnhancer: Generative Space-Time Enhancement for Video Generation","authors":"Jingwen He, Tianfan Xue, Dongyang Liu, Xinqi Lin, Peng Gao, Dahua Lin,\n  Yu Qiao, Wanli Ouyang, Ziwei Liu","authorsParsed":[["He","Jingwen",""],["Xue","Tianfan",""],["Liu","Dongyang",""],["Lin","Xinqi",""],["Gao","Peng",""],["Lin","Dahua",""],["Qiao","Yu",""],["Ouyang","Wanli",""],["Liu","Ziwei",""]],"versions":[{"version":"v1","created":"Wed, 10 Jul 2024 13:46:08 GMT"}],"updateDate":"2024-07-11","timestamp":1720619168000,"abstract":"  We present VEnhancer, a generative space-time enhancement framework that\nimproves the existing text-to-video results by adding more details in spatial\ndomain and synthetic detailed motion in temporal domain. Given a generated\nlow-quality video, our approach can increase its spatial and temporal\nresolution simultaneously with arbitrary up-sampling space and time scales\nthrough a unified video diffusion model. Furthermore, VEnhancer effectively\nremoves generated spatial artifacts and temporal flickering of generated\nvideos. To achieve this, basing on a pretrained video diffusion model, we train\na video ControlNet and inject it to the diffusion model as a condition on low\nframe-rate and low-resolution videos. To effectively train this video\nControlNet, we design space-time data augmentation as well as video-aware\nconditioning. Benefiting from the above designs, VEnhancer yields to be stable\nduring training and shares an elegant end-to-end training manner. Extensive\nexperiments show that VEnhancer surpasses existing state-of-the-art video\nsuper-resolution and space-time super-resolution methods in enhancing\nAI-generated videos. Moreover, with VEnhancer, exisiting open-source\nstate-of-the-art text-to-video method, VideoCrafter-2, reaches the top one in\nvideo generation benchmark -- VBench.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Electrical Engineering and Systems Science/Image and Video Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}