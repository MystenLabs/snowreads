{"id":"2408.01877","title":"Is Generative Communication between Embodied Agents Good for Zero-Shot\n  ObjectNav?","authors":"Vishnu Sashank Dorbala, Vishnu Dutt Sharma, Pratap Tokekar, Dinesh\n  Manocha","authorsParsed":[["Dorbala","Vishnu Sashank",""],["Sharma","Vishnu Dutt",""],["Tokekar","Pratap",""],["Manocha","Dinesh",""]],"versions":[{"version":"v1","created":"Sat, 3 Aug 2024 22:55:26 GMT"},{"version":"v2","created":"Sun, 11 Aug 2024 21:26:41 GMT"}],"updateDate":"2024-08-13","timestamp":1722725726000,"abstract":"  In Zero-Shot ObjectNav, an embodied ground agent is expected to navigate to a\ntarget object specified by a natural language label without any\nenvironment-specific fine-tuning. This is challenging, given the limited view\nof a ground agent and its independent exploratory behavior. To address these\nissues, we consider an assistive overhead agent with a bounded global view\nalongside the ground agent and present two coordinated navigation schemes for\njudicious exploration. We establish the influence of the Generative\nCommunication (GC) between the embodied agents equipped with Vision-Language\nModels (VLMs) in improving zero-shot ObjectNav, achieving a 10% improvement in\nthe ground agent's ability to find the target object in comparison with an\nunassisted setup in simulation. We further analyze the GC for unique traits\nquantifying the presence of hallucination and cooperation. In particular, we\nidentify a unique trait of \"preemptive hallucination\" specific to our embodied\nsetting, where the overhead agent assumes that the ground agent has executed an\naction in the dialogue when it is yet to move. Finally, we conduct real-world\ninferences with GC and showcase qualitative examples where countering\npre-emptive hallucination via prompt finetuning improves real-world ObjectNav\nperformance.\n","subjects":["Computing Research Repository/Robotics","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}