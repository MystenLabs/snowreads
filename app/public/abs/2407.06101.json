{"id":"2407.06101","title":"Neural Garment Dynamics via Manifold-Aware Transformers","authors":"Peizhuo Li, Tuanfeng Y. Wang, Timur Levent Kesdogan, Duygu Ceylan,\n  Olga Sorkine-Hornung","authorsParsed":[["Li","Peizhuo",""],["Wang","Tuanfeng Y.",""],["Kesdogan","Timur Levent",""],["Ceylan","Duygu",""],["Sorkine-Hornung","Olga",""]],"versions":[{"version":"v1","created":"Mon, 13 May 2024 11:05:52 GMT"}],"updateDate":"2024-07-09","timestamp":1715598352000,"abstract":"  Data driven and learning based solutions for modeling dynamic garments have\nsignificantly advanced, especially in the context of digital humans. However,\nexisting approaches often focus on modeling garments with respect to a fixed\nparametric human body model and are limited to garment geometries that were\nseen during training. In this work, we take a different approach and model the\ndynamics of a garment by exploiting its local interactions with the underlying\nhuman body. Specifically, as the body moves, we detect local garment-body\ncollisions, which drive the deformation of the garment. At the core of our\napproach is a mesh-agnostic garment representation and a manifold-aware\ntransformer network design, which together enable our method to generalize to\nunseen garment and body geometries. We evaluate our approach on a wide variety\nof garment types and motion sequences and provide competitive qualitative and\nquantitative results with respect to the state of the art.\n","subjects":["Computing Research Repository/Graphics","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}