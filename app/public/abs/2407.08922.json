{"id":"2407.08922","title":"Leveraging large language models for nano synthesis mechanism\n  explanation: solid foundations or mere conjectures?","authors":"Yingming Pu, Liping Huang, Tao Lin, Hongyu Chen","authorsParsed":[["Pu","Yingming",""],["Huang","Liping",""],["Lin","Tao",""],["Chen","Hongyu",""]],"versions":[{"version":"v1","created":"Fri, 12 Jul 2024 02:05:59 GMT"}],"updateDate":"2024-07-15","timestamp":1720749959000,"abstract":"  With the rapid development of artificial intelligence (AI), large language\nmodels (LLMs) such as GPT-4 have garnered significant attention in the\nscientific community, demonstrating great potential in advancing scientific\ndiscovery. This progress raises a critical question: are these LLMs\nwell-aligned with real-world physicochemical principles? Current evaluation\nstrategies largely emphasize fact-based knowledge, such as material property\nprediction or name recognition, but they often lack an understanding of\nfundamental physicochemical mechanisms that require logical reasoning. To\nbridge this gap, our study developed a benchmark consisting of 775\nmultiple-choice questions focusing on the mechanisms of gold nanoparticle\nsynthesis. By reflecting on existing evaluation metrics, we question whether a\ndirect true-or-false assessment merely suggests conjecture. Hence, we propose a\nnovel evaluation metric, the confidence-based score (c-score), which probes the\noutput logits to derive the precise probability for the correct answer. Based\non extensive experiments, our results show that in the context of gold\nnanoparticle synthesis, LLMs understand the underlying physicochemical\nmechanisms rather than relying on conjecture. This study underscores the\npotential of LLMs to grasp intrinsic scientific mechanisms and sets the stage\nfor developing more reliable and effective AI tools across various scientific\ndomains.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}