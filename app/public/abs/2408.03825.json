{"id":"2408.03825","title":"Towards Real-Time Gaussian Splatting: Accelerating 3DGS through\n  Photometric SLAM","authors":"Yan Song Hu, Dayou Mao, Yuhao Chen, and John Zelek","authorsParsed":[["Hu","Yan Song",""],["Mao","Dayou",""],["Chen","Yuhao",""],["Zelek","John",""]],"versions":[{"version":"v1","created":"Wed, 7 Aug 2024 15:01:08 GMT"}],"updateDate":"2024-08-08","timestamp":1723042868000,"abstract":"  Initial applications of 3D Gaussian Splatting (3DGS) in Visual Simultaneous\nLocalization and Mapping (VSLAM) demonstrate the generation of high-quality\nvolumetric reconstructions from monocular video streams. However, despite these\npromising advancements, current 3DGS integrations have reduced tracking\nperformance and lower operating speeds compared to traditional VSLAM. To\naddress these issues, we propose integrating 3DGS with Direct Sparse Odometry,\na monocular photometric SLAM system. We have done preliminary experiments\nshowing that using Direct Sparse Odometry point cloud outputs, as opposed to\nstandard structure-from-motion methods, significantly shortens the training\ntime needed to achieve high-quality renders. Reducing 3DGS training time\nenables the development of 3DGS-integrated SLAM systems that operate in\nreal-time on mobile hardware. These promising initial findings suggest further\nexploration is warranted in combining traditional VSLAM systems with 3DGS.\n","subjects":["Computing Research Repository/Robotics","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/"}