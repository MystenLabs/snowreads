{"id":"2408.15649","title":"Hierarchical Blockmodelling for Knowledge Graphs","authors":"Marcin Pietrasik and Marek Reformat and Anna Wilbik","authorsParsed":[["Pietrasik","Marcin",""],["Reformat","Marek",""],["Wilbik","Anna",""]],"versions":[{"version":"v1","created":"Wed, 28 Aug 2024 09:04:15 GMT"}],"updateDate":"2024-08-29","timestamp":1724835855000,"abstract":"  In this paper, we investigate the use of probabilistic graphical models,\nspecifically stochastic blockmodels, for the purpose of hierarchical entity\nclustering on knowledge graphs. These models, seldom used in the Semantic Web\ncommunity, decompose a graph into a set of probability distributions. The\nparameters of these distributions are then inferred allowing for their\nsubsequent sampling to generate a random graph. In a non-parametric setting,\nthis allows for the induction of hierarchical clusterings without prior\nconstraints on the hierarchy's structure. Specifically, this is achieved by the\nintegration of the Nested Chinese Restaurant Process and the Stick Breaking\nProcess into the generative model. In this regard, we propose a model\nleveraging such integration and derive a collapsed Gibbs sampling scheme for\nits inference. To aid in understanding, we describe the steps in this\nderivation and provide an implementation for the sampler. We evaluate our model\non synthetic and real-world datasets and quantitatively compare against\nbenchmark models. We further evaluate our results qualitatively and find that\nour model is capable of inducing coherent cluster hierarchies in small scale\nsettings. The work presented in this paper provides the first step for the\nfurther application of stochastic blockmodels for knowledge graphs on a larger\nscale. We conclude the paper with potential avenues for future work on more\nscalable inference schemes.\n","subjects":["Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"lQfACKis2u2NAtuhZ4IfNRi8NawROE23lvDHzQErL2Y","pdfSize":"643774"}
