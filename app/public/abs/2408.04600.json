{"id":"2408.04600","title":"Improving Network Interpretability via Explanation Consistency\n  Evaluation","authors":"Hefeng Wu, Hao Jiang, Keze Wang, Ziyi Tang, Xianghuan He, Liang Lin","authorsParsed":[["Wu","Hefeng",""],["Jiang","Hao",""],["Wang","Keze",""],["Tang","Ziyi",""],["He","Xianghuan",""],["Lin","Liang",""]],"versions":[{"version":"v1","created":"Thu, 8 Aug 2024 17:20:08 GMT"}],"updateDate":"2024-08-09","timestamp":1723137608000,"abstract":"  While deep neural networks have achieved remarkable performance, they tend to\nlack transparency in prediction. The pursuit of greater interpretability in\nneural networks often results in a degradation of their original performance.\nSome works strive to improve both interpretability and performance, but they\nprimarily depend on meticulously imposed conditions. In this paper, we propose\na simple yet effective framework that acquires more explainable activation\nheatmaps and simultaneously increase the model performance, without the need\nfor any extra supervision. Specifically, our concise framework introduces a new\nmetric, i.e., explanation consistency, to reweight the training samples\nadaptively in model learning. The explanation consistency metric is utilized to\nmeasure the similarity between the model's visual explanations of the original\nsamples and those of semantic-preserved adversarial samples, whose background\nregions are perturbed by using image adversarial attack techniques. Our\nframework then promotes the model learning by paying closer attention to those\ntraining samples with a high difference in explanations (i.e., low explanation\nconsistency), for which the current model cannot provide robust\ninterpretations. Comprehensive experimental results on various benchmarks\ndemonstrate the superiority of our framework in multiple aspects, including\nhigher recognition accuracy, greater data debiasing capability, stronger\nnetwork robustness, and more precise localization ability on both regular\nnetworks and interpretable networks. We also provide extensive ablation studies\nand qualitative analyses to unveil the detailed contribution of each component.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}