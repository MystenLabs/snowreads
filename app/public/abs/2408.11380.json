{"id":"2408.11380","title":"Reflex-Based Open-Vocabulary Navigation without Prior Knowledge Using\n  Omnidirectional Camera and Multiple Vision-Language Models","authors":"Kento Kawaharazuka, Yoshiki Obinata, Naoaki Kanazawa, Naoto Tsukamoto,\n  Kei Okada, Masayuki Inaba","authorsParsed":[["Kawaharazuka","Kento",""],["Obinata","Yoshiki",""],["Kanazawa","Naoaki",""],["Tsukamoto","Naoto",""],["Okada","Kei",""],["Inaba","Masayuki",""]],"versions":[{"version":"v1","created":"Wed, 21 Aug 2024 07:18:58 GMT"}],"updateDate":"2024-08-22","timestamp":1724224738000,"abstract":"  Various robot navigation methods have been developed, but they are mainly\nbased on Simultaneous Localization and Mapping (SLAM), reinforcement learning,\netc., which require prior map construction or learning. In this study, we\nconsider the simplest method that does not require any map construction or\nlearning, and execute open-vocabulary navigation of robots without any prior\nknowledge to do this. We applied an omnidirectional camera and pre-trained\nvision-language models to the robot. The omnidirectional camera provides a\nuniform view of the surroundings, thus eliminating the need for complicated\nexploratory behaviors including trajectory generation. By applying multiple\npre-trained vision-language models to this omnidirectional image and\nincorporating reflective behaviors, we show that navigation becomes simple and\ndoes not require any prior setup. Interesting properties and limitations of our\nmethod are discussed based on experiments with the mobile robot Fetch.\n","subjects":["Computing Research Repository/Robotics","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Systems and Control","Electrical Engineering and Systems Science/Systems and Control"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}