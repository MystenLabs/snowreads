{"id":"2407.20999","title":"MoFO: Momentum-Filtered Optimizer for Mitigating Forgetting in LLM\n  Fine-Tuning","authors":"Yupeng Chen, Senmiao Wang, Zhihang Lin, Zeyu Qin, Yushun Zhang, Tian\n  Ding, Ruoyu Sun","authorsParsed":[["Chen","Yupeng",""],["Wang","Senmiao",""],["Lin","Zhihang",""],["Qin","Zeyu",""],["Zhang","Yushun",""],["Ding","Tian",""],["Sun","Ruoyu",""]],"versions":[{"version":"v1","created":"Tue, 30 Jul 2024 17:38:24 GMT"},{"version":"v2","created":"Wed, 31 Jul 2024 17:56:03 GMT"}],"updateDate":"2024-08-01","timestamp":1722361104000,"abstract":"  Recently, large language models (LLMs) have demonstrated remarkable\ncapabilities in a wide range of tasks. Typically, an LLM is pre-trained on\nlarge corpora and subsequently fine-tuned on task-specific datasets. However,\nduring fine-tuning, LLMs may forget the knowledge acquired in the pre-training\nstage, leading to a decline in general capabilities. To address this issue, we\npropose a new fine-tuning algorithm termed Momentum-Filtered Optimizer (MoFO).\nThe key idea of MoFO is to iteratively select and update the model parameters\nwith the largest momentum magnitudes. Compared to full-parameter training, MoFO\nachieves similar fine-tuning performance while keeping parameters closer to the\npre-trained model, thereby mitigating knowledge forgetting. Unlike most\nexisting methods for forgetting mitigation, MoFO combines the following two\nadvantages. First, MoFO does not require access to pre-training data. This\nmakes MoFO particularly suitable for fine-tuning scenarios where pre-training\ndata is unavailable, such as fine-tuning checkpoint-only open-source LLMs.\nSecond, MoFO does not alter the original loss function. This could avoid\nimpairing the model performance on the fine-tuning tasks. We validate MoFO\nthrough rigorous convergence analysis and extensive experiments, demonstrating\nits superiority over existing methods in mitigating forgetting and enhancing\nfine-tuning performance.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"9sfodyU9jcTOp3UezFotoyv8UFlBfdYPpKjeIzyZVuQ","pdfSize":"969858"}
