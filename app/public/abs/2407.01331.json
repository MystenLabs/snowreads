{"id":"2407.01331","title":"Restyling Unsupervised Concept Based Interpretable Networks with\n  Generative Models","authors":"Jayneel Parekh, Quentin Bouniot, Pavlo Mozharovskyi, Alasdair Newson,\n  Florence d'Alch\\'e-Buc","authorsParsed":[["Parekh","Jayneel",""],["Bouniot","Quentin",""],["Mozharovskyi","Pavlo",""],["Newson","Alasdair",""],["d'Alch√©-Buc","Florence",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 14:39:41 GMT"}],"updateDate":"2024-07-02","timestamp":1719844781000,"abstract":"  Developing inherently interpretable models for prediction has gained\nprominence in recent years. A subclass of these models, wherein the\ninterpretable network relies on learning high-level concepts, are valued\nbecause of closeness of concept representations to human communication.\nHowever, the visualization and understanding of the learnt unsupervised\ndictionary of concepts encounters major limitations, specially for large-scale\nimages. We propose here a novel method that relies on mapping the concept\nfeatures to the latent space of a pretrained generative model. The use of a\ngenerative model enables high quality visualization, and naturally lays out an\nintuitive and interactive procedure for better interpretation of the learnt\nconcepts. Furthermore, leveraging pretrained generative models has the\nadditional advantage of making the training of the system more efficient. We\nquantitatively ascertain the efficacy of our method in terms of accuracy of the\ninterpretable prediction network, fidelity of reconstruction, as well as\nfaithfulness and consistency of learnt concepts. The experiments are conducted\non multiple image recognition benchmarks for large-scale images. Project page\navailable at https://jayneelparekh.github.io/VisCoIN_project_page/\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}