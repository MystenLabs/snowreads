{"id":"2408.11966","title":"Visual Localization in 3D Maps: Comparing Point Cloud, Mesh, and NeRF\n  Representations","authors":"Lintong Zhang, Yifu Tao, Jiarong Lin, Fu Zhang, Maurice Fallon","authorsParsed":[["Zhang","Lintong",""],["Tao","Yifu",""],["Lin","Jiarong",""],["Zhang","Fu",""],["Fallon","Maurice",""]],"versions":[{"version":"v1","created":"Wed, 21 Aug 2024 19:37:17 GMT"}],"updateDate":"2024-08-23","timestamp":1724269037000,"abstract":"  This paper introduces and assesses a cross-modal global visual localization\nsystem that can localize camera images within a color 3D map representation\nbuilt using both visual and lidar sensing. We present three different\nstate-of-the-art methods for creating the color 3D maps: point clouds, meshes,\nand neural radiance fields (NeRF). Our system constructs a database of\nsynthetic RGB and depth image pairs from these representations. This database\nserves as the basis for global localization. We present an automatic approach\nthat builds this database by synthesizing novel images of the scene and\nexploiting the 3D structure encoded in the different representations. Next, we\npresent a global localization system that relies on the synthetic image\ndatabase to accurately estimate the 6 DoF camera poses of monocular query\nimages. Our localization approach relies on different learning-based global\ndescriptors and feature detectors which enable robust image retrieval and\nmatching despite the domain gap between (real) query camera images and the\nsynthetic database images. We assess the system's performance through extensive\nreal-world experiments in both indoor and outdoor settings, in order to\nevaluate the effectiveness of each map representation and the benefits against\ntraditional structure-from-motion localization approaches. Our results show\nthat all three map representations can achieve consistent localization success\nrates of 55% and higher across various environments. NeRF synthesized images\nshow superior performance, localizing query images at an average success rate\nof 72%. Furthermore, we demonstrate that our synthesized database enables\nglobal localization even when the map creation data and the localization\nsequence are captured when travelling in opposite directions. Our system,\noperating in real-time on a mobile laptop equipped with a GPU, achieves a\nprocessing rate of 1Hz.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Robotics"],"license":"http://creativecommons.org/licenses/by/4.0/"}