{"id":"2407.13992","title":"Semantic Communications for 3D Human Face Transmission with Neural\n  Radiance Fields","authors":"Guanlin Wu, Zhonghao Lyu, Juyong Zhang, Jie Xu","authorsParsed":[["Wu","Guanlin",""],["Lyu","Zhonghao",""],["Zhang","Juyong",""],["Xu","Jie",""]],"versions":[{"version":"v1","created":"Fri, 19 Jul 2024 02:48:10 GMT"}],"updateDate":"2024-07-22","timestamp":1721357290000,"abstract":"  This paper investigates the transmission of three-dimensional (3D) human face\ncontent for immersive communication over a rate-constrained\ntransmitter-receiver link. We propose a new framework named NeRF-SeCom, which\nleverages neural radiance fields (NeRF) and semantic communications to improve\nthe quality of 3D visualizations while minimizing the communication overhead.\nIn the NeRF-SeCom framework, we first train a NeRF face model based on the\nNeRFBlendShape method, which is pre-shared between the transmitter and receiver\nas the semantic knowledge base to facilitate the real-time transmission. Next,\nwith knowledge base, the transmitter extracts and sends only the essential\nsemantic features for the receiver to reconstruct 3D face in real time. To\noptimize the transmission efficiency, we classify the expression features into\nstatic and dynamic types. Over each video chunk, static features are\ntransmitted once for all frames, whereas dynamic features are transmitted over\na portion of frames to adhere to rate constraints. Additionally, we propose a\nfeature prediction mechanism, which allows the receiver to predict the dynamic\nfeatures for frames that are not transmitted. Experiments show that our\nproposed NeRF-SeCom framework significantly outperforms benchmark methods in\ndelivering high-quality 3D visualizations of human faces.\n","subjects":["Electrical Engineering and Systems Science/Image and Video Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}