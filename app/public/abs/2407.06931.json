{"id":"2407.06931","title":"A Unified Approach to Multi-task Legged Navigation: Temporal Logic Meets\n  Reinforcement Learning","authors":"Jesse Jiang, Samuel Coogan, Ye Zhao","authorsParsed":[["Jiang","Jesse",""],["Coogan","Samuel",""],["Zhao","Ye",""]],"versions":[{"version":"v1","created":"Tue, 9 Jul 2024 15:06:52 GMT"}],"updateDate":"2024-07-10","timestamp":1720537612000,"abstract":"  This study examines the problem of hopping robot navigation planning to\nachieve simultaneous goal-directed and environment exploration tasks. We\nconsider a scenario in which the robot has mandatory goal-directed tasks\ndefined using Linear Temporal Logic (LTL) specifications as well as optional\nexploration tasks represented using a reward function. Additionally, there\nexists uncertainty in the robot dynamics which results in motion perturbation.\nWe first propose an abstraction of 3D hopping robot dynamics which enables\nhigh-level planning and a neural-network-based optimization for low-level\ncontrol. We then introduce a Multi-task Product IMDP (MT-PIMDP) model of the\nsystem and tasks. We propose a unified control policy synthesis algorithm which\nenables both task-directed goal-reaching behaviors as well as task-agnostic\nexploration to learn perturbations and reward. We provide a formal proof of the\ntrade-off induced by prioritizing either LTL or RL actions. We demonstrate our\nmethods with simulation case studies in a 2D world navigation environment.\n","subjects":["Computing Research Repository/Robotics"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}