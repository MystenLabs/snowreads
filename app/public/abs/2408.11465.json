{"id":"2408.11465","title":"MeTTA: Single-View to 3D Textured Mesh Reconstruction with Test-Time\n  Adaptation","authors":"Kim Yu-Ji, Hyunwoo Ha, Kim Youwang, Jaeheung Surh, Hyowon Ha, Tae-Hyun\n  Oh","authorsParsed":[["Yu-Ji","Kim",""],["Ha","Hyunwoo",""],["Youwang","Kim",""],["Surh","Jaeheung",""],["Ha","Hyowon",""],["Oh","Tae-Hyun",""]],"versions":[{"version":"v1","created":"Wed, 21 Aug 2024 09:35:16 GMT"}],"updateDate":"2024-08-22","timestamp":1724232916000,"abstract":"  Reconstructing 3D from a single view image is a long-standing challenge. One\nof the popular approaches to tackle this problem is learning-based methods, but\ndealing with the test cases unfamiliar with training data (Out-of-distribution;\nOoD) introduces an additional challenge. To adapt for unseen samples in test\ntime, we propose MeTTA, a test-time adaptation (TTA) exploiting generative\nprior. We design joint optimization of 3D geometry, appearance, and pose to\nhandle OoD cases with only a single view image. However, the alignment between\nthe reference image and the 3D shape via the estimated viewpoint could be\nerroneous, which leads to ambiguity. To address this ambiguity, we carefully\ndesign learnable virtual cameras and their self-calibration. In our\nexperiments, we demonstrate that MeTTA effectively deals with OoD scenarios at\nfailure cases of existing learning-based 3D reconstruction models and enables\nobtaining a realistic appearance with physically based rendering (PBR)\ntextures.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}