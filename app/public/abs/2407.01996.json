{"id":"2407.01996","title":"ViG-Bias: Visually Grounded Bias Discovery and Mitigation","authors":"Badr-Eddine Marani, Mohamed Hanini, Nihitha Malayarukil, Stergios\n  Christodoulidis, Maria Vakalopoulou and Enzo Ferrante","authorsParsed":[["Marani","Badr-Eddine",""],["Hanini","Mohamed",""],["Malayarukil","Nihitha",""],["Christodoulidis","Stergios",""],["Vakalopoulou","Maria",""],["Ferrante","Enzo",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 07:10:10 GMT"},{"version":"v2","created":"Wed, 3 Jul 2024 12:42:47 GMT"},{"version":"v3","created":"Sun, 4 Aug 2024 21:56:57 GMT"}],"updateDate":"2024-08-06","timestamp":1719904210000,"abstract":"  The proliferation of machine learning models in critical decision making\nprocesses has underscored the need for bias discovery and mitigation\nstrategies. Identifying the reasons behind a biased system is not\nstraightforward, since in many occasions they are associated with hidden\nspurious correlations which are not easy to spot. Standard approaches rely on\nbias audits performed by analyzing model performance in pre-defined subgroups\nof data samples, usually characterized by common attributes like gender or\nethnicity when it comes to people, or other specific attributes defining\nsemantically coherent groups of images. However, it is not always possible to\nknow a-priori the specific attributes defining the failure modes of visual\nrecognition systems. Recent approaches propose to discover these groups by\nleveraging large vision language models, which enable the extraction of\ncross-modal embeddings and the generation of textual descriptions to\ncharacterize the subgroups where a certain model is underperforming. In this\nwork, we argue that incorporating visual explanations (e.g. heatmaps generated\nvia GradCAM or other approaches) can boost the performance of such bias\ndiscovery and mitigation frameworks. To this end, we introduce Visually\nGrounded Bias Discovery and Mitigation (ViG-Bias), a simple yet effective\ntechnique which can be integrated to a variety of existing frameworks to\nimprove both, discovery and mitigation performance. Our comprehensive\nevaluation shows that incorporating visual explanations enhances existing\ntechniques like DOMINO, FACTS and Bias-to-Text, across several challenging\ndatasets, including CelebA, Waterbirds, and NICO++.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}