{"id":"2408.05350","title":"Enabling Quick, Accurate Crowdsourced Annotation for Elevation-Aware\n  Flood Extent Mapping","authors":"Landon Dyken, Saugat Adhikari, Pravin Poudel, Steve Petruzza, Da Yan,\n  Will Usher, Sidharth Kumar","authorsParsed":[["Dyken","Landon",""],["Adhikari","Saugat",""],["Poudel","Pravin",""],["Petruzza","Steve",""],["Yan","Da",""],["Usher","Will",""],["Kumar","Sidharth",""]],"versions":[{"version":"v1","created":"Wed, 31 Jul 2024 23:42:05 GMT"}],"updateDate":"2024-08-13","timestamp":1722469325000,"abstract":"  In order to assess damage and properly allocate relief efforts, mapping the\nextent of flood events is a necessary and important aspect of disaster\nmanagement. In recent years, deep learning methods have evolved as an effective\ntool to quickly label high-resolution imagery and provide necessary flood\nextent mappings. These methods, though, require large amounts of annotated\ntraining data to create models that are accurate and robust to new flooded\nimagery. In this work, we provide FloodTrace, an application that enables\neffective crowdsourcing for flooded region annotation for machine learning\ntraining data, removing the requirement for annotation to be done solely by\nresearchers. We accomplish this through two orthogonal methods within our\napplication, informed by requirements from domain experts. First, we utilize\nelevation-guided annotation tools and 3D rendering to inform user annotation\ndecisions with digital elevation model data, improving annotation accuracy. For\nthis purpose, we provide a unique annotation method that uses topological data\nanalysis to outperform the state-of-the-art elevation-guided annotation tool in\nefficiency. Second, we provide a framework for researchers to review aggregated\ncrowdsourced annotations and correct inaccuracies using methods inspired by\nuncertainty visualization. We conducted a user study to confirm the application\neffectiveness in which 266 graduate students annotated high-resolution aerial\nimagery from Hurricane Matthew in North Carolina. Experimental results show the\naccuracy and efficiency benefits of our application apply even for untrained\nusers. In addition, using our aggregation and correction framework, flood\ndetection models trained on crowdsourced annotations were able to achieve\nperformance equal to models trained on expert-labeled annotations, while\nrequiring a fraction of the time on the part of the researcher.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}