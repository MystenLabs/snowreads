{"id":"2407.01886","title":"Core Knowledge Learning Framework for Graph Adaptation and Scalability\n  Learning","authors":"Bowen Zhang, Zhichao Huang, Genan Dai, Guangning Xu, Xiaomao Fan, Hu\n  Huang","authorsParsed":[["Zhang","Bowen",""],["Huang","Zhichao",""],["Dai","Genan",""],["Xu","Guangning",""],["Fan","Xiaomao",""],["Huang","Hu",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 02:16:43 GMT"}],"updateDate":"2024-07-03","timestamp":1719886603000,"abstract":"  Graph classification is a pivotal challenge in machine learning, especially\nwithin the realm of graph-based data, given its importance in numerous\nreal-world applications such as social network analysis, recommendation\nsystems, and bioinformatics. Despite its significance, graph classification\nfaces several hurdles, including adapting to diverse prediction tasks, training\nacross multiple target domains, and handling small-sample prediction scenarios.\nCurrent methods often tackle these challenges individually, leading to\nfragmented solutions that lack a holistic approach to the overarching problem.\nIn this paper, we propose an algorithm aimed at addressing the aforementioned\nchallenges. By incorporating insights from various types of tasks, our method\naims to enhance adaptability, scalability, and generalizability in graph\nclassification. Motivated by the recognition that the underlying subgraph plays\na crucial role in GNN prediction, while the remainder is task-irrelevant, we\nintroduce the Core Knowledge Learning (\\method{}) framework for graph\nadaptation and scalability learning. \\method{} comprises several key modules,\nincluding the core subgraph knowledge submodule, graph domain adaptation\nmodule, and few-shot learning module for downstream tasks. Each module is\ntailored to tackle specific challenges in graph classification, such as domain\nshift, label inconsistencies, and data scarcity. By learning the core subgraph\nof the entire graph, we focus on the most pertinent features for task\nrelevance. Consequently, our method offers benefits such as improved model\nperformance, increased domain adaptability, and enhanced robustness to domain\nvariations. Experimental results demonstrate significant performance\nenhancements achieved by our method compared to state-of-the-art approaches.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/publicdomain/zero/1.0/","blobId":"Cn9R-gZ9lUOhmDTpTGkS2P99u6vbWTsO1sY_fyiWN_w","pdfSize":"992310","objectId":"0x1e2f1803de46cf57d81d25858e8595cbc3929e19ad35576c3a32a6fa6a252e9c","registeredEpoch":"3","certifiedEpoch":"3","startEpoch":"3","endEpoch":"203"}
