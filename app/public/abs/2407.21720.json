{"id":"2407.21720","title":"Detecting, Explaining, and Mitigating Memorization in Diffusion Models","authors":"Yuxin Wen, Yuchen Liu, Chen Chen, Lingjuan Lyu","authorsParsed":[["Wen","Yuxin",""],["Liu","Yuchen",""],["Chen","Chen",""],["Lyu","Lingjuan",""]],"versions":[{"version":"v1","created":"Wed, 31 Jul 2024 16:13:29 GMT"}],"updateDate":"2024-08-01","timestamp":1722442409000,"abstract":"  Recent breakthroughs in diffusion models have exhibited exceptional\nimage-generation capabilities. However, studies show that some outputs are\nmerely replications of training data. Such replications present potential legal\nchallenges for model owners, especially when the generated content contains\nproprietary information. In this work, we introduce a straightforward yet\neffective method for detecting memorized prompts by inspecting the magnitude of\ntext-conditional predictions. Our proposed method seamlessly integrates without\ndisrupting sampling algorithms, and delivers high accuracy even at the first\ngeneration step, with a single generation per prompt. Building on our detection\nstrategy, we unveil an explainable approach that shows the contribution of\nindividual words or tokens to memorization. This offers an interactive medium\nfor users to adjust their prompts. Moreover, we propose two strategies i.e., to\nmitigate memorization by leveraging the magnitude of text-conditional\npredictions, either through minimization during inference or filtering during\ntraining. These proposed strategies effectively counteract memorization while\nmaintaining high-generation quality. Code is available at\nhttps://github.com/YuxinWenRick/diffusion_memorization.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"Vd2t4EY3iWPh2QNytvNVcbniMP0n-CwSk4iB91e3geA","pdfSize":"44651948","objectId":"0xa8ab4c387c7213c7e3bf963f535fd4c768d4f53293d5695c6e6a5757f0c5daae","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
