{"id":"2408.13718","title":"GPT-4 Emulates Average-Human Emotional Cognition from a Third-Person\n  Perspective","authors":"Ala N. Tak and Jonathan Gratch","authorsParsed":[["Tak","Ala N.",""],["Gratch","Jonathan",""]],"versions":[{"version":"v1","created":"Sun, 11 Aug 2024 01:22:09 GMT"}],"updateDate":"2024-08-27","timestamp":1723339329000,"abstract":"  This paper extends recent investigations on the emotional reasoning abilities\nof Large Language Models (LLMs). Current research on LLMs has not directly\nevaluated the distinction between how LLMs predict the self-attribution of\nemotions and the perception of others' emotions. We first look at carefully\ncrafted emotion-evoking stimuli, originally designed to find patterns of brain\nneural activity representing fine-grained inferred emotional attributions of\nothers. We show that GPT-4 is especially accurate in reasoning about such\nstimuli. This suggests LLMs agree with humans' attributions of others' emotions\nin stereotypical scenarios remarkably more than self-attributions of emotions\nin idiosyncratic situations. To further explore this, our second study utilizes\na dataset containing annotations from both the author and a third-person\nperspective. We find that GPT-4's interpretations align more closely with human\njudgments about the emotions of others than with self-assessments. Notably,\nconventional computational models of emotion primarily rely on self-reported\nground truth as the gold standard. However, an average observer's standpoint,\nwhich LLMs appear to have adopted, might be more relevant for many downstream\napplications, at least in the absence of individual information and adequate\nsafety considerations.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language","Computing Research Repository/Human-Computer Interaction"],"license":"http://creativecommons.org/licenses/by/4.0/"}