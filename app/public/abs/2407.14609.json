{"id":"2407.14609","title":"Adversarial Databases Improve Success in Retrieval-based Large Language\n  Models","authors":"Sean Wu, Michael Koo, Li Yo Kao, Andy Black, Lesley Blum, Fabien\n  Scalzo, Ira Kurtz","authorsParsed":[["Wu","Sean",""],["Koo","Michael",""],["Kao","Li Yo",""],["Black","Andy",""],["Blum","Lesley",""],["Scalzo","Fabien",""],["Kurtz","Ira",""]],"versions":[{"version":"v1","created":"Fri, 19 Jul 2024 18:08:39 GMT"}],"updateDate":"2024-07-23","timestamp":1721412519000,"abstract":"  Open-source LLMs have shown great potential as fine-tuned chatbots, and\ndemonstrate robust abilities in reasoning and surpass many existing benchmarks.\nRetrieval-Augmented Generation (RAG) is a technique for improving the\nperformance of LLMs on tasks that the models weren't explicitly trained on, by\nleveraging external knowledge databases. Numerous studies have demonstrated the\neffectiveness of RAG to more successfully accomplish downstream tasks when\nusing vector datasets that consist of relevant background information. It has\nbeen implicitly assumed by those in the field that if adversarial background\ninformation is utilized in this context, that the success of using a RAG-based\napproach would be nonexistent or even negatively impact the results. To address\nthis assumption, we tested several open-source LLMs on the ability of RAG to\nimprove their success in answering multiple-choice questions (MCQ) in the\nmedical subspecialty field of Nephrology. Unlike previous studies, we examined\nthe effect of RAG in utilizing both relevant and adversarial background\ndatabases. We set up several open-source LLMs, including Llama 3, Phi-3,\nMixtral 8x7b, Zephyr$\\beta$, and Gemma 7B Instruct, in a zero-shot RAG\npipeline. As adversarial sources of information, text from the Bible and a\nRandom Words generated database were used for comparison. Our data show that\nmost of the open-source LLMs improve their multiple-choice test-taking success\nas expected when incorporating relevant information vector databases.\nSurprisingly however, adversarial Bible text significantly improved the success\nof many LLMs and even random word text improved test taking ability of some of\nthe models. In summary, our results demonstrate for the first time the\ncountertintuitive ability of adversarial information datasets to improve the\nRAG-based LLM success.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}