{"id":"2408.05502","title":"GEM: Context-Aware Gaze EstiMation with Visual Search Behavior Matching\n  for Chest Radiograph","authors":"Shaonan Liu, Wenting Chen, Jie Liu, Xiaoling Luo, Linlin Shen","authorsParsed":[["Liu","Shaonan",""],["Chen","Wenting",""],["Liu","Jie",""],["Luo","Xiaoling",""],["Shen","Linlin",""]],"versions":[{"version":"v1","created":"Sat, 10 Aug 2024 09:46:25 GMT"}],"updateDate":"2024-08-13","timestamp":1723283185000,"abstract":"  Gaze estimation is pivotal in human scene comprehension tasks, particularly\nin medical diagnostic analysis. Eye-tracking technology facilitates the\nrecording of physicians' ocular movements during image interpretation, thereby\nelucidating their visual attention patterns and information-processing\nstrategies. In this paper, we initially define the context-aware gaze\nestimation problem in medical radiology report settings. To understand the\nattention allocation and cognitive behavior of radiologists during the medical\nimage interpretation process, we propose a context-aware Gaze EstiMation (GEM)\nnetwork that utilizes eye gaze data collected from radiologists to simulate\ntheir visual search behavior patterns throughout the image interpretation\nprocess. It consists of a context-awareness module, visual behavior graph\nconstruction, and visual behavior matching. Within the context-awareness\nmodule, we achieve intricate multimodal registration by establishing\nconnections between medical reports and images. Subsequently, for a more\naccurate simulation of genuine visual search behavior patterns, we introduce a\nvisual behavior graph structure, capturing such behavior through high-order\nrelationships (edges) between gaze points (nodes). To maintain the authenticity\nof visual behavior, we devise a visual behavior-matching approach, adjusting\nthe high-order relationships between them by matching the graph constructed\nfrom real and estimated gaze points. Extensive experiments on four publicly\navailable datasets demonstrate the superiority of GEM over existing methods and\nits strong generalizability, which also provides a new direction for the\neffective utilization of diverse modalities in medical image interpretation and\nenhances the interpretability of models in the field of medical imaging.\nhttps://github.com/Tiger-SN/GEM\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}