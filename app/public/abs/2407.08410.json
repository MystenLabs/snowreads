{"id":"2407.08410","title":"Specialist vision-language models for clinical ophthalmology","authors":"Robbie Holland, Thomas R. P. Taylor, Christopher Holmes, Sophie Riedl,\n  Julia Mai, Maria Patsiamanidi, Dimitra Mitsopoulou, Paul Hager, Philip\n  M\\\"uller, Hendrik P. N. Scholl, Hrvoje Bogunovi\\'c, Ursula Schmidt-Erfurth,\n  Daniel Rueckert, Sobha Sivaprasad, Andrew J. Lotery, Martin J. Menten (on\n  behalf of the PINNACLE consortium)","authorsParsed":[["Holland","Robbie","","on\n  behalf of the PINNACLE consortium"],["Taylor","Thomas R. P.","","on\n  behalf of the PINNACLE consortium"],["Holmes","Christopher","","on\n  behalf of the PINNACLE consortium"],["Riedl","Sophie","","on\n  behalf of the PINNACLE consortium"],["Mai","Julia","","on\n  behalf of the PINNACLE consortium"],["Patsiamanidi","Maria","","on\n  behalf of the PINNACLE consortium"],["Mitsopoulou","Dimitra","","on\n  behalf of the PINNACLE consortium"],["Hager","Paul","","on\n  behalf of the PINNACLE consortium"],["Müller","Philip","","on\n  behalf of the PINNACLE consortium"],["Scholl","Hendrik P. N.","","on\n  behalf of the PINNACLE consortium"],["Bogunović","Hrvoje","","on\n  behalf of the PINNACLE consortium"],["Schmidt-Erfurth","Ursula","","on\n  behalf of the PINNACLE consortium"],["Rueckert","Daniel","","on\n  behalf of the PINNACLE consortium"],["Sivaprasad","Sobha","","on\n  behalf of the PINNACLE consortium"],["Lotery","Andrew J.","","on\n  behalf of the PINNACLE consortium"],["Menten","Martin J.","","on\n  behalf of the PINNACLE consortium"]],"versions":[{"version":"v1","created":"Thu, 11 Jul 2024 11:31:48 GMT"}],"updateDate":"2024-07-12","timestamp":1720697508000,"abstract":"  Clinicians spend a significant amount of time reviewing medical images and\ntranscribing their findings regarding patient diagnosis, referral and treatment\nin text form. Vision-language models (VLMs), which automatically interpret\nimages and summarize their findings as text, have enormous potential to\nalleviate clinical workloads and increase patient access to high-quality\nmedical care. While foundational models have stirred considerable interest in\nthe medical community, it is unclear whether their general capabilities\ntranslate to real-world clinical utility. In this work, we show that foundation\nVLMs markedly underperform compared to practicing ophthalmologists on\nspecialist tasks crucial to the care of patients with age-related macular\ndegeneration (AMD). To address this, we initially identified the essential\ncapabilities required for image-based clinical decision-making, and then\ndeveloped a curriculum to selectively train VLMs in these skills. The resulting\nmodel, RetinaVLM, can be instructed to write reports that significantly\noutperform those written by leading foundation medical VLMs in disease staging\n(F1 score of 0.63 vs. 0.11) and patient referral (0.67 vs. 0.39), and\napproaches the diagnostic performance of junior ophthalmologists (who achieve\n0.77 and 0.78 on the respective tasks). Furthermore, in a reader study\ninvolving two senior ophthalmologists with up to 32 years of experience,\nRetinaVLM's reports were found to be similarly correct (78.6% vs. 82.1%) and\ncomplete (both 78.6%) as reports written by junior ophthalmologists with up to\n10 years of experience. These results demonstrate that our curriculum-based\napproach provides a blueprint for specializing generalist foundation medical\nVLMs to handle real-world clinical tasks.\n","subjects":["Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"b9lgpvcFcnpruAjGDjt5Q8YqtOFRI1LlGS-0GyQlKW0","pdfSize":"43308909","objectId":"0x363550d30a8bf3044575f361c538a1067d368c129743dffacf40c86e365017b1","registeredEpoch":"1","certifiedEpoch":"1","startEpoch":"1","endEpoch":"201"}
