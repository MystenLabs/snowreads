{"id":"2408.03433","title":"Hybrid diffusion models: combining supervised and generative pretraining\n  for label-efficient fine-tuning of segmentation models","authors":"Bruno Sauvalle, Mathieu Salzmann","authorsParsed":[["Sauvalle","Bruno",""],["Salzmann","Mathieu",""]],"versions":[{"version":"v1","created":"Tue, 6 Aug 2024 20:19:06 GMT"}],"updateDate":"2024-08-08","timestamp":1722975546000,"abstract":"  We are considering in this paper the task of label-efficient fine-tuning of\nsegmentation models: We assume that a large labeled dataset is available and\nallows to train an accurate segmentation model in one domain, and that we have\nto adapt this model on a related domain where only a few samples are available.\nWe observe that this adaptation can be done using two distinct methods: The\nfirst method, supervised pretraining, is simply to take the model trained on\nthe first domain using classical supervised learning, and fine-tune it on the\nsecond domain with the available labeled samples. The second method is to\nperform self-supervised pretraining on the first domain using a generic pretext\ntask in order to get high-quality representations which can then be used to\ntrain a model on the second domain in a label-efficient way. We propose in this\npaper to fuse these two approaches by introducing a new pretext task, which is\nto perform simultaneously image denoising and mask prediction on the first\ndomain. We motivate this choice by showing that in the same way that an image\ndenoiser conditioned on the noise level can be considered as a generative model\nfor the unlabeled image distribution using the theory of diffusion models, a\nmodel trained using this new pretext task can be considered as a generative\nmodel for the joint distribution of images and segmentation masks under the\nassumption that the mapping from images to segmentation masks is deterministic.\nWe then empirically show on several datasets that fine-tuning a model\npretrained using this approach leads to better results than fine-tuning a\nsimilar model trained using either supervised or unsupervised pretraining only.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}