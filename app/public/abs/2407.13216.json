{"id":"2407.13216","title":"QuIIL at T3 challenge: Towards Automation in Life-Saving Intervention\n  Procedures from First-Person View","authors":"Trinh T. L. Vuong, Doanh C. Bui and Jin Tae Kwak","authorsParsed":[["Vuong","Trinh T. L.",""],["Bui","Doanh C.",""],["Kwak","Jin Tae",""]],"versions":[{"version":"v1","created":"Thu, 18 Jul 2024 06:55:26 GMT"}],"updateDate":"2024-07-19","timestamp":1721285726000,"abstract":"  In this paper, we present our solutions for a spectrum of automation tasks in\nlife-saving intervention procedures within the Trauma THOMPSON (T3) Challenge,\nencompassing action recognition, action anticipation, and Visual Question\nAnswering (VQA). For action recognition and anticipation, we propose a\npre-processing strategy that samples and stitches multiple inputs into a single\nimage and then incorporates momentum- and attention-based knowledge\ndistillation to improve the performance of the two tasks. For training, we\npresent an action dictionary-guided design, which consistently yields the most\nfavorable results across our experiments. In the realm of VQA, we leverage\nobject-level features and deploy co-attention networks to train both object and\nquestion features. Notably, we introduce a novel frame-question cross-attention\nmechanism at the network's core for enhanced performance. Our solutions achieve\nthe $2^{nd}$ rank in action recognition and anticipation tasks and $1^{st}$\nrank in the VQA task.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}