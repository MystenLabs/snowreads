{"id":"2408.01366","title":"Play to the Score: Stage-Guided Dynamic Multi-Sensory Fusion for Robotic\n  Manipulation","authors":"Ruoxuan Feng, Di Hu, Wenke Ma, Xuelong Li","authorsParsed":[["Feng","Ruoxuan",""],["Hu","Di",""],["Ma","Wenke",""],["Li","Xuelong",""]],"versions":[{"version":"v1","created":"Fri, 2 Aug 2024 16:20:56 GMT"}],"updateDate":"2024-08-05","timestamp":1722615656000,"abstract":"  Humans possess a remarkable talent for flexibly alternating to different\nsenses when interacting with the environment. Picture a chef skillfully gauging\nthe timing of ingredient additions and controlling the heat according to the\ncolors, sounds, and aromas, seamlessly navigating through every stage of the\ncomplex cooking process. This ability is founded upon a thorough comprehension\nof task stages, as achieving the sub-goal within each stage can necessitate the\nutilization of different senses. In order to endow robots with similar ability,\nwe incorporate the task stages divided by sub-goals into the imitation learning\nprocess to accordingly guide dynamic multi-sensory fusion. We propose MS-Bot, a\nstage-guided dynamic multi-sensory fusion method with coarse-to-fine stage\nunderstanding, which dynamically adjusts the priority of modalities based on\nthe fine-grained state within the predicted current stage. We train a robot\nsystem equipped with visual, auditory, and tactile sensors to accomplish\nchallenging robotic manipulation tasks: pouring and peg insertion with keyway.\nExperimental results indicate that our approach enables more effective and\nexplainable dynamic fusion, aligning more closely with the human fusion process\nthan existing methods.\n","subjects":["Computing Research Repository/Robotics","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}