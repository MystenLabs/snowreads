{"id":"2408.16400","title":"Outside the Comfort Zone: Analysing LLM Capabilities in Software\n  Vulnerability Detection","authors":"Yuejun Guo, Constantinos Patsakis, Qiang Hu, Qiang Tang, and Fran\n  Casino","authorsParsed":[["Guo","Yuejun",""],["Patsakis","Constantinos",""],["Hu","Qiang",""],["Tang","Qiang",""],["Casino","Fran",""]],"versions":[{"version":"v1","created":"Thu, 29 Aug 2024 10:00:57 GMT"}],"updateDate":"2024-08-30","timestamp":1724925657000,"abstract":"  The significant increase in software production driven by automation and\nfaster development lifecycles has resulted in a corresponding surge in software\nvulnerabilities. In parallel, the evolving landscape of software vulnerability\ndetection, highlighting the shift from traditional methods to machine learning\nand large language models (LLMs), provides massive opportunities at the cost of\nresource-demanding computations. This paper thoroughly analyses LLMs'\ncapabilities in detecting vulnerabilities within source code by testing models\nbeyond their usual applications to study their potential in cybersecurity\ntasks. We evaluate the performance of six open-source models that are\nspecifically trained for vulnerability detection against six general-purpose\nLLMs, three of which were further fine-tuned on a dataset that we compiled. Our\ndataset, alongside five state-of-the-art benchmark datasets, were used to\ncreate a pipeline to leverage a binary classification task, namely classifying\ncode into vulnerable and non-vulnerable. The findings highlight significant\nvariations in classification accuracy across benchmarks, revealing the critical\ninfluence of fine-tuning in enhancing the detection capabilities of small LLMs\nover their larger counterparts, yet only in the specific scenarios in which\nthey were trained. Further experiments and analysis also underscore the issues\nwith current benchmark datasets, particularly around mislabeling and their\nimpact on model training and performance, which raises concerns about the\ncurrent state of practice. We also discuss the road ahead in the field\nsuggesting strategies for improved model training and dataset curation.\n","subjects":["Computing Research Repository/Cryptography and Security"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}