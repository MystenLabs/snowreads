{"id":"2408.05927","title":"A Simple Early Exiting Framework for Accelerated Sampling in Diffusion\n  Models","authors":"Taehong Moon, Moonseok Choi, EungGu Yun, Jongmin Yoon, Gayoung Lee,\n  Jaewoong Cho, Juho Lee","authorsParsed":[["Moon","Taehong",""],["Choi","Moonseok",""],["Yun","EungGu",""],["Yoon","Jongmin",""],["Lee","Gayoung",""],["Cho","Jaewoong",""],["Lee","Juho",""]],"versions":[{"version":"v1","created":"Mon, 12 Aug 2024 05:33:45 GMT"}],"updateDate":"2024-08-13","timestamp":1723440825000,"abstract":"  Diffusion models have shown remarkable performance in generation problems\nover various domains including images, videos, text, and audio. A practical\nbottleneck of diffusion models is their sampling speed, due to the repeated\nevaluation of score estimation networks during the inference. In this work, we\npropose a novel framework capable of adaptively allocating compute required for\nthe score estimation, thereby reducing the overall sampling time of diffusion\nmodels. We observe that the amount of computation required for the score\nestimation may vary along the time step for which the score is estimated. Based\non this observation, we propose an early-exiting scheme, where we skip the\nsubset of parameters in the score estimation network during the inference,\nbased on a time-dependent exit schedule. Using the diffusion models for image\nsynthesis, we show that our method could significantly improve the sampling\nthroughput of the diffusion models without compromising image quality.\nFurthermore, we also demonstrate that our method seamlessly integrates with\nvarious types of solvers for faster sampling, capitalizing on their\ncompatibility to enhance overall efficiency. The source code and our\nexperiments are available at \\url{https://github.com/taehong-moon/ee-diffusion}\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}