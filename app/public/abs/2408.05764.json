{"id":"2408.05764","title":"A robust baro-radar-inertial odometry m-estimator for multicopter\n  navigation in cities and forests","authors":"Rik Girod, Marco Hauswirth, Patrick Pfreundschuh, Mariano Biasio,\n  Roland Siegwart","authorsParsed":[["Girod","Rik",""],["Hauswirth","Marco",""],["Pfreundschuh","Patrick",""],["Biasio","Mariano",""],["Siegwart","Roland",""]],"versions":[{"version":"v1","created":"Sun, 11 Aug 2024 12:57:01 GMT"}],"updateDate":"2024-08-13","timestamp":1723381021000,"abstract":"  Search and rescue operations require mobile robots to navigate unstructured\nindoor and outdoor environments. In particular, actively stabilized multirotor\ndrones need precise movement data to balance and avoid obstacles. Combining\nradial velocities from on-chip radar with MEMS inertial sensing has proven to\nprovide robust, lightweight, and consistent state estimation, even in visually\nor geometrically degraded environments. Statistical tests robustify these\nestimators against radar outliers. However, available work with binary outlier\nfilters lacks adaptability to various hardware setups and environments. Other\nwork has predominantly been tested in handheld static environments or\nautomotive contexts. This work introduces a robust baro-radar-inertial odometry\n(BRIO) m-estimator for quadcopter flights in typical GNSS-denied scenarios.\nExtensive real-world closed-loop flights in cities and forests demonstrate\nrobustness to moving objects and ghost targets, maintaining a consistent\nperformance with 0.5 % to 3.2 % drift per distance traveled. Benchmarks on\npublic datasets validate the system's generalizability. The code, dataset, and\nvideo are available at https://github.com/ethz-asl/rio.\n","subjects":["Computing Research Repository/Robotics","Electrical Engineering and Systems Science/Signal Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}