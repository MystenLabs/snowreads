{"id":"2407.18637","title":"DynamicTrack: Advancing Gigapixel Tracking in Crowded Scenes","authors":"Yunqi Zhao, Yuchen Guo, Zheng Cao, Kai Ni, Ruqi Huang, Lu Fang","authorsParsed":[["Zhao","Yunqi",""],["Guo","Yuchen",""],["Cao","Zheng",""],["Ni","Kai",""],["Huang","Ruqi",""],["Fang","Lu",""]],"versions":[{"version":"v1","created":"Fri, 26 Jul 2024 10:08:01 GMT"}],"updateDate":"2024-07-29","timestamp":1721988481000,"abstract":"  Tracking in gigapixel scenarios holds numerous potential applications in\nvideo surveillance and pedestrian analysis. Existing algorithms attempt to\nperform tracking in crowded scenes by utilizing multiple cameras or group\nrelationships. However, their performance significantly degrades when\nconfronted with complex interaction and occlusion inherent in gigapixel images.\nIn this paper, we introduce DynamicTrack, a dynamic tracking framework designed\nto address gigapixel tracking challenges in crowded scenes. In particular, we\npropose a dynamic detector that utilizes contrastive learning to jointly detect\nthe head and body of pedestrians. Building upon this, we design a dynamic\nassociation algorithm that effectively utilizes head and body information for\nmatching purposes. Extensive experiments show that our tracker achieves\nstate-of-the-art performance on widely used tracking benchmarks specifically\ndesigned for gigapixel crowded scenes.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}