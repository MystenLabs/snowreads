{"id":"2407.12380","title":"PCQ: Emotion Recognition in Speech via Progressive Channel Querying","authors":"Xincheng Wang and Liejun Wang and Yinfeng Yu and Xinxin Jiao","authorsParsed":[["Wang","Xincheng",""],["Wang","Liejun",""],["Yu","Yinfeng",""],["Jiao","Xinxin",""]],"versions":[{"version":"v1","created":"Wed, 17 Jul 2024 07:58:16 GMT"}],"updateDate":"2024-07-18","timestamp":1721203096000,"abstract":"  In human-computer interaction (HCI), Speech Emotion Recognition (SER) is a\nkey technology for understanding human intentions and emotions. Traditional SER\nmethods struggle to effectively capture the long-term temporal correla-tions\nand dynamic variations in complex emotional expressions. To overcome these\nlimitations, we introduce the PCQ method, a pioneering approach for SER via\n\\textbf{P}rogressive \\textbf{C}hannel \\textbf{Q}uerying. This method can drill\ndown layer by layer in the channel dimension through the channel query\ntechnique to achieve dynamic modeling of long-term contextual information of\nemotions. This mul-ti-level analysis gives the PCQ method an edge in capturing\nthe nuances of hu-man emotions. Experimental results show that our model\nimproves the weighted average (WA) accuracy by 3.98\\% and 3.45\\% and the\nunweighted av-erage (UA) accuracy by 5.67\\% and 5.83\\% on the IEMOCAP and EMODB\nemotion recognition datasets, respectively, significantly exceeding the\nbaseline levels.\n","subjects":["Electrical Engineering and Systems Science/Audio and Speech Processing","Computing Research Repository/Sound"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"LnFRUZk8ddDo2jYS8PnIAwDh9TK4zcyoYUWC7tfu_5o","pdfSize":"1888330","objectId":"0x0a59916e2fe4afe9791e7feeae2045fa550fb18cf0eedf645d183036375467bd","registeredEpoch":"3","certifiedEpoch":"3","startEpoch":"3","endEpoch":"203"}
