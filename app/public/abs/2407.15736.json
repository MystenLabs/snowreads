{"id":"2407.15736","title":"OMoS-QA: A Dataset for Cross-Lingual Extractive Question Answering in a\n  German Migration Context","authors":"Steffen Kleinle, Jakob Prange, Annemarie Friedrich","authorsParsed":[["Kleinle","Steffen",""],["Prange","Jakob",""],["Friedrich","Annemarie",""]],"versions":[{"version":"v1","created":"Mon, 22 Jul 2024 15:40:17 GMT"}],"updateDate":"2024-07-23","timestamp":1721662817000,"abstract":"  When immigrating to a new country, it is easy to feel overwhelmed by the need\nto obtain information on financial support, housing, schooling, language\ncourses, and other issues. If relocation is rushed or even forced, the\nnecessity for high-quality answers to such questions is all the more urgent.\nOfficial immigration counselors are usually overbooked, and online systems\ncould guide newcomers to the requested information or a suitable counseling\nservice.\n  To this end, we present OMoS-QA, a dataset of German and English questions\npaired with relevant trustworthy documents and manually annotated answers,\nspecifically tailored to this scenario. Questions are automatically generated\nwith an open-source large language model (LLM) and answer sentences are\nselected by crowd workers with high agreement. With our data, we conduct a\ncomparison of 5 pretrained LLMs on the task of extractive question answering\n(QA) in German and English. Across all models and both languages, we find high\nprecision and low-to-mid recall in selecting answer sentences, which is a\nfavorable trade-off to avoid misleading users. This performance even holds up\nwhen the question language does not match the document language. When it comes\nto identifying unanswerable questions given a context, there are larger\ndifferences between the two languages.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/"}