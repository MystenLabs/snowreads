{"id":"2408.05906","title":"AdTEC: A Unified Benchmark for Evaluating Text Quality in Search Engine\n  Advertising","authors":"Peinan Zhang, Yusuke Sakai, Masato Mita, Hiroki Ouchi, Taro Watanabe","authorsParsed":[["Zhang","Peinan",""],["Sakai","Yusuke",""],["Mita","Masato",""],["Ouchi","Hiroki",""],["Watanabe","Taro",""]],"versions":[{"version":"v1","created":"Mon, 12 Aug 2024 03:32:53 GMT"}],"updateDate":"2024-08-13","timestamp":1723433573000,"abstract":"  With the increase in the more fluent ad texts automatically created by\nnatural language generation technology, it is in the high demand to verify the\nquality of these creatives in a real-world setting. We propose AdTEC, the first\npublic benchmark to evaluate ad texts in multiple aspects from the perspective\nof practical advertising operations. Our contributions are: (i) Defining five\ntasks for evaluating the quality of ad texts and building a dataset based on\nthe actual operational experience of advertising agencies, which is typically\nkept in-house. (ii) Validating the performance of existing pre-trained language\nmodels (PLMs) and human evaluators on the dataset. (iii) Analyzing the\ncharacteristics and providing challenges of the benchmark. The results show\nthat while PLMs have already reached the practical usage level in several\ntasks, human still outperforms in certain domains, implying that there is\nsignificant room for improvement in such area.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/"}