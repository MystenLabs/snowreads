{"id":"2408.09191","title":"GSLAMOT: A Tracklet and Query Graph-based Simultaneous Locating,\n  Mapping, and Multiple Object Tracking System","authors":"Shuo Wang, Yongcai Wang, Zhimin Xu, Yongyu Guo, Wanting Li, Zhe Huang,\n  Xuewei Bai, Deying Li","authorsParsed":[["Wang","Shuo",""],["Wang","Yongcai",""],["Xu","Zhimin",""],["Guo","Yongyu",""],["Li","Wanting",""],["Huang","Zhe",""],["Bai","Xuewei",""],["Li","Deying",""]],"versions":[{"version":"v1","created":"Sat, 17 Aug 2024 13:09:33 GMT"}],"updateDate":"2024-08-20","timestamp":1723900173000,"abstract":"  For interacting with mobile objects in unfamiliar environments,\nsimultaneously locating, mapping, and tracking the 3D poses of multiple objects\nare crucially required. This paper proposes a Tracklet Graph and Query\nGraph-based framework, i.e., GSLAMOT, to address this challenge. GSLAMOT\nutilizes camera and LiDAR multimodal information as inputs and divides the\nrepresentation of the dynamic scene into a semantic map for representing the\nstatic environment, a trajectory of the ego-agent, and an online maintained\nTracklet Graph (TG) for tracking and predicting the 3D poses of the detected\nmobile objects. A Query Graph (QG) is constructed in each frame by object\ndetection to query and update TG. For accurate object association, a\nMulti-criteria Star Graph Association (MSGA) method is proposed to find matched\nobjects between the detections in QG and the predicted tracklets in TG. Then,\nan Object-centric Graph Optimization (OGO) method is proposed to simultaneously\noptimize the TG, the semantic map, and the agent trajectory. It triangulates\nthe detected objects into the map to enrich the map's semantic information. We\naddress the efficiency issues to handle the three tightly coupled tasks in\nparallel. Experiments are conducted on KITTI, Waymo, and an emulated Traffic\nCongestion dataset that highlights challenging scenarios. Experiments show that\nGSLAMOT enables accurate crowded object tracking while conducting SLAM\naccurately in challenging scenarios, demonstrating more excellent performances\nthan the state-of-the-art methods. The code and dataset are at\nhttps://gslamot.github.io.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}