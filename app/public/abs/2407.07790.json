{"id":"2407.07790","title":"Systematic Evaluation of Neural Retrieval Models on the Touch\\'e 2020\n  Argument Retrieval Subset of BEIR","authors":"Nandan Thakur, Luiz Bonifacio, Maik Fr\\\"obe, Alexander Bondarenko,\n  Ehsan Kamalloo, Martin Potthast, Matthias Hagen, Jimmy Lin","authorsParsed":[["Thakur","Nandan",""],["Bonifacio","Luiz",""],["Fr√∂be","Maik",""],["Bondarenko","Alexander",""],["Kamalloo","Ehsan",""],["Potthast","Martin",""],["Hagen","Matthias",""],["Lin","Jimmy",""]],"versions":[{"version":"v1","created":"Wed, 10 Jul 2024 16:07:51 GMT"}],"updateDate":"2024-07-11","timestamp":1720627671000,"abstract":"  The zero-shot effectiveness of neural retrieval models is often evaluated on\nthe BEIR benchmark -- a combination of different IR evaluation datasets.\nInterestingly, previous studies found that particularly on the BEIR subset\nTouch\\'e 2020, an argument retrieval task, neural retrieval models are\nconsiderably less effective than BM25. Still, so far, no further investigation\nhas been conducted on what makes argument retrieval so \"special\". To more\ndeeply analyze the respective potential limits of neural retrieval models, we\nrun a reproducibility study on the Touch\\'e 2020 data. In our study, we focus\non two experiments: (i) a black-box evaluation (i.e., no model retraining),\nincorporating a theoretical exploration using retrieval axioms, and (ii) a data\ndenoising evaluation involving post-hoc relevance judgments. Our black-box\nevaluation reveals an inherent bias of neural models towards retrieving short\npassages from the Touch\\'e 2020 data, and we also find that quite a few of the\nneural models' results are unjudged in the Touch\\'e 2020 data. As many of the\nshort Touch\\'e passages are not argumentative and thus non-relevant per se, and\nas the missing judgments complicate fair comparison, we denoise the Touch\\'e\n2020 data by excluding very short passages (less than 20 words) and by\naugmenting the unjudged data with post-hoc judgments following the Touch\\'e\nguidelines. On the denoised data, the effectiveness of the neural models\nimproves by up to 0.52 in nDCG@10, but BM25 is still more effective. Our code\nand the augmented Touch\\'e 2020 dataset are available at\n\\url{https://github.com/castorini/touche-error-analysis}.\n","subjects":["Computing Research Repository/Information Retrieval"],"license":"http://creativecommons.org/licenses/by-sa/4.0/","blobId":"HPJfAMGLsirqJ4mgAoeI1aaZ0Fr1u-4CwR7otx1r2oA","pdfSize":"727886","objectId":"0x89a142b1a4d2722ed670d05e9b83b62fb1699809e64298aaf7ee43135fcebaae","registeredEpoch":"1","certifiedEpoch":"1","startEpoch":"1","endEpoch":"201"}
