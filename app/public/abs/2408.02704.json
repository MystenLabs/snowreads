{"id":"2408.02704","title":"Spatial-temporal Graph Convolutional Networks with Diversified\n  Transformation for Dynamic Graph Representation Learning","authors":"Ling Wang, Yixiang Huang, and Hao Wu","authorsParsed":[["Wang","Ling",""],["Huang","Yixiang",""],["Wu","Hao",""]],"versions":[{"version":"v1","created":"Mon, 5 Aug 2024 09:40:47 GMT"}],"updateDate":"2024-08-07","timestamp":1722850847000,"abstract":"  Dynamic graphs (DG) are often used to describe evolving interactions between\nnodes in real-world applications. Temporal patterns are a natural feature of\nDGs and are also key to representation learning. However, existing dynamic GCN\nmodels are mostly composed of static GCNs and sequence modules, which results\nin the separation of spatiotemporal information and cannot effectively capture\ncomplex temporal patterns in DGs. To address this problem, this study proposes\na spatial-temporal graph convolutional networks with diversified transformation\n(STGCNDT), which includes three aspects: a) constructing a unified graph tensor\nconvolutional network (GTCN) using tensor M-products without the need to\nrepresent spatiotemporal information separately; b) introducing three\ntransformation schemes in GTCN to model complex temporal patterns to aggregate\ntemporal information; and c) constructing an ensemble of diversified\ntransformation schemes to obtain higher representation capabilities. Empirical\nstudies on four DGs that appear in communication networks show that the\nproposed STGCNDT significantly outperforms state-of-the-art models in solving\nlink weight estimation tasks due to the diversified transformations.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}