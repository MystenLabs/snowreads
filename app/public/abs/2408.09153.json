{"id":"2408.09153","title":"Are CLIP features all you need for Universal Synthetic Image Origin\n  Attribution?","authors":"Dario Cioni, Christos Tzelepis, Lorenzo Seidenari, Ioannis Patras","authorsParsed":[["Cioni","Dario",""],["Tzelepis","Christos",""],["Seidenari","Lorenzo",""],["Patras","Ioannis",""]],"versions":[{"version":"v1","created":"Sat, 17 Aug 2024 09:54:21 GMT"}],"updateDate":"2024-08-20","timestamp":1723888461000,"abstract":"  The steady improvement of Diffusion Models for visual synthesis has given\nrise to many new and interesting use cases of synthetic images but also has\nraised concerns about their potential abuse, which poses significant societal\nthreats. To address this, fake images need to be detected and attributed to\ntheir source model, and given the frequent release of new generators, realistic\napplications need to consider an Open-Set scenario where some models are unseen\nat training time. Existing forensic techniques are either limited to Closed-Set\nsettings or to GAN-generated images, relying on fragile frequency-based\n\"fingerprint\" features. By contrast, we propose a simple yet effective\nframework that incorporates features from large pre-trained foundation models\nto perform Open-Set origin attribution of synthetic images produced by various\ngenerative models, including Diffusion Models. We show that our method leads to\nremarkable attribution performance, even in the low-data regime, exceeding the\nperformance of existing methods and generalizes better on images obtained from\na diverse set of architectures. We make the code publicly available at:\nhttps://github.com/ciodar/UniversalAttribution.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}