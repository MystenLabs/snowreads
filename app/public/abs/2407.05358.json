{"id":"2407.05358","title":"CPM: Class-conditional Prompting Machine for Audio-visual Segmentation","authors":"Yuanhong Chen, Chong Wang, Yuyuan Liu, Hu Wang, Gustavo Carneiro","authorsParsed":[["Chen","Yuanhong",""],["Wang","Chong",""],["Liu","Yuyuan",""],["Wang","Hu",""],["Carneiro","Gustavo",""]],"versions":[{"version":"v1","created":"Sun, 7 Jul 2024 13:20:21 GMT"},{"version":"v2","created":"Tue, 16 Jul 2024 01:35:24 GMT"}],"updateDate":"2024-07-17","timestamp":1720358421000,"abstract":"  Audio-visual segmentation (AVS) is an emerging task that aims to accurately\nsegment sounding objects based on audio-visual cues. The success of AVS\nlearning systems depends on the effectiveness of cross-modal interaction. Such\na requirement can be naturally fulfilled by leveraging transformer-based\nsegmentation architecture due to its inherent ability to capture long-range\ndependencies and flexibility in handling different modalities. However, the\ninherent training issues of transformer-based methods, such as the low efficacy\nof cross-attention and unstable bipartite matching, can be amplified in AVS,\nparticularly when the learned audio query does not provide a clear semantic\nclue. In this paper, we address these two issues with the new Class-conditional\nPrompting Machine (CPM). CPM improves the bipartite matching with a learning\nstrategy combining class-agnostic queries with class-conditional queries. The\nefficacy of cross-modal attention is upgraded with new learning objectives for\nthe audio, visual and joint modalities. We conduct experiments on AVS\nbenchmarks, demonstrating that our method achieves state-of-the-art (SOTA)\nsegmentation accuracy.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"hs3arjmTwJHQByGAo44UKypnEGRiHJ3LoMHgZ_erOJA","pdfSize":"46095753"}
