{"id":"2407.01303","title":"RoDyn-SLAM: Robust Dynamic Dense RGB-D SLAM with Neural Radiance Fields","authors":"Haochen Jiang, Yueming Xu, Kejie Li, Jianfeng Feng, Li Zhang","authorsParsed":[["Jiang","Haochen",""],["Xu","Yueming",""],["Li","Kejie",""],["Feng","Jianfeng",""],["Zhang","Li",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 14:01:45 GMT"}],"updateDate":"2024-07-02","timestamp":1719842505000,"abstract":"  Leveraging neural implicit representation to conduct dense RGB-D SLAM has\nbeen studied in recent years. However, this approach relies on a static\nenvironment assumption and does not work robustly within a dynamic environment\ndue to the inconsistent observation of geometry and photometry. To address the\nchallenges presented in dynamic environments, we propose a novel dynamic SLAM\nframework with neural radiance field. Specifically, we introduce a motion mask\ngeneration method to filter out the invalid sampled rays. This design\neffectively fuses the optical flow mask and semantic mask to enhance the\nprecision of motion mask. To further improve the accuracy of pose estimation,\nwe have designed a divide-and-conquer pose optimization algorithm that\ndistinguishes between keyframes and non-keyframes. The proposed edge warp loss\ncan effectively enhance the geometry constraints between adjacent frames.\nExtensive experiments are conducted on the two challenging datasets, and the\nresults show that RoDyn-SLAM achieves state-of-the-art performance among recent\nneural RGB-D methods in both accuracy and robustness.\n","subjects":["Computing Research Repository/Robotics"],"license":"http://creativecommons.org/licenses/by/4.0/"}