{"id":"2408.06258","title":"Deep Learning System Boundary Testing through Latent Space Style Mixing","authors":"Amr Abdellatif, Xingcheng Chen, Vincenzo Riccio, Andrea Stocco","authorsParsed":[["Abdellatif","Amr",""],["Chen","Xingcheng",""],["Riccio","Vincenzo",""],["Stocco","Andrea",""]],"versions":[{"version":"v1","created":"Mon, 12 Aug 2024 16:14:55 GMT"}],"updateDate":"2024-08-13","timestamp":1723479295000,"abstract":"  Evaluating the behavioral frontier of deep learning (DL) systems is crucial\nfor understanding their generalizability and robustness. However, boundary\ntesting is challenging due to their high-dimensional input space. Generative\nartificial intelligence offers a promising solution by modeling data\ndistribution within compact latent space representations, thereby facilitating\nfiner-grained explorations. In this work, we introduce MIMICRY, a novel\nblack-box system-agnostic test generator that leverages these latent\nrepresentations to generate frontier inputs for the DL systems under test.\nSpecifically, MIMICRY uses style-based generative adversarial networks trained\nto learn the representation of inputs with disentangled features. This\nrepresentation enables embedding style-mixing operations between a source and a\ntarget input, combining their features to explore the boundary between them. We\nevaluated the effectiveness of different MIMICRY configurations in generating\nboundary inputs for four popular DL image classification systems. Our results\nshow that manipulating the latent space allows for effective and efficient\nexploration of behavioral frontiers. As opposed to a model-based baseline,\nMIMICRY generates a higher quality frontier of behaviors which includes more\nand closer inputs. Additionally, we assessed the validity of these inputs,\nrevealing a high validity rate according to human assessors.\n","subjects":["Computing Research Repository/Software Engineering","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}