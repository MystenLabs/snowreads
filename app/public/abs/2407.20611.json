{"id":"2407.20611","title":"The Entrapment Problem in Random Walk Decentralized Learning","authors":"Zonghong Liu, Salim El Rouayheb, Matthew Dwyer","authorsParsed":[["Liu","Zonghong",""],["Rouayheb","Salim El",""],["Dwyer","Matthew",""]],"versions":[{"version":"v1","created":"Tue, 30 Jul 2024 07:36:13 GMT"}],"updateDate":"2024-07-31","timestamp":1722324973000,"abstract":"  This paper explores decentralized learning in a graph-based setting, where\ndata is distributed across nodes. We investigate a decentralized SGD algorithm\nthat utilizes a random walk to update a global model based on local data. Our\nfocus is on designing the transition probability matrix to speed up\nconvergence. While importance sampling can enhance centralized learning, its\ndecentralized counterpart, using the Metropolis-Hastings (MH) algorithm, can\nlead to the entrapment problem, where the random walk becomes stuck at certain\nnodes, slowing convergence. To address this, we propose the Metropolis-Hastings\nwith L\\'evy Jumps (MHLJ) algorithm, which incorporates random perturbations\n(jumps) to overcome entrapment. We theoretically establish the convergence rate\nand error gap of MHLJ and validate our findings through numerical experiments.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Distributed, Parallel, and Cluster Computing","Computing Research Repository/Information Theory","Mathematics/Information Theory"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}