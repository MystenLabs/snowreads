{"id":"2407.08978","title":"Towards Chapter-to-Chapter Context-Aware Literary Translation via Large\n  Language Models","authors":"Linghao Jin, Li An, Xuezhe Ma","authorsParsed":[["Jin","Linghao",""],["An","Li",""],["Ma","Xuezhe",""]],"versions":[{"version":"v1","created":"Fri, 12 Jul 2024 04:18:22 GMT"}],"updateDate":"2024-07-15","timestamp":1720757902000,"abstract":"  Discourse phenomena in existing document-level translation datasets are\nsparse, which has been a fundamental obstacle in the development of\ncontext-aware machine translation models. Moreover, most existing\ndocument-level corpora and context-aware machine translation methods rely on an\nunrealistic assumption on sentence-level alignments. To mitigate these issues,\nwe first curate a novel dataset of Chinese-English literature, which consists\nof 160 books with intricate discourse structures. Then, we propose a more\npragmatic and challenging setting for context-aware translation, termed\nchapter-to-chapter (Ch2Ch) translation, and investigate the performance of\ncommonly-used machine translation models under this setting. Furthermore, we\nintroduce a potential approach of finetuning large language models (LLMs)\nwithin the domain of Ch2Ch literary translation, yielding impressive\nimprovements over baselines. Through our comprehensive analysis, we unveil that\nliterary translation under the Ch2Ch setting is challenging in nature, with\nrespect to both model learning methods and translation decoding algorithms.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}