{"id":"2408.16662","title":"Space3D-Bench: Spatial 3D Question Answering Benchmark","authors":"Emilia Szymanska, Mihai Dusmanu, Jan-Willem Buurlage, Mahdi Rad, Marc\n  Pollefeys","authorsParsed":[["Szymanska","Emilia",""],["Dusmanu","Mihai",""],["Buurlage","Jan-Willem",""],["Rad","Mahdi",""],["Pollefeys","Marc",""]],"versions":[{"version":"v1","created":"Thu, 29 Aug 2024 16:05:22 GMT"},{"version":"v2","created":"Tue, 10 Sep 2024 10:19:16 GMT"},{"version":"v3","created":"Sun, 15 Sep 2024 15:51:00 GMT"}],"updateDate":"2024-09-17","timestamp":1724947522000,"abstract":"  Answering questions about the spatial properties of the environment poses\nchallenges for existing language and vision foundation models due to a lack of\nunderstanding of the 3D world notably in terms of relationships between\nobjects. To push the field forward, multiple 3D Q&A datasets were proposed\nwhich, overall, provide a variety of questions, but they individually focus on\nparticular aspects of 3D reasoning or are limited in terms of data modalities.\nTo address this, we present Space3D-Bench - a collection of 1000 general\nspatial questions and answers related to scenes of the Replica dataset which\noffers a variety of data modalities: point clouds, posed RGB-D images,\nnavigation meshes and 3D object detections. To ensure that the questions cover\na wide range of 3D objectives, we propose an indoor spatial questions taxonomy\ninspired by geographic information systems and use it to balance the dataset\naccordingly. Moreover, we provide an assessment system that grades natural\nlanguage responses based on predefined ground-truth answers by leveraging a\nVision Language Model's comprehension of both text and images to compare the\nresponses with ground-truth textual information or relevant visual data.\nFinally, we introduce a baseline called RAG3D-Chat integrating the world\nunderstanding of foundation models with rich context retrieval, achieving an\naccuracy of 67% on the proposed dataset.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}