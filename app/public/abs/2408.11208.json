{"id":"2408.11208","title":"PooDLe: Pooled and dense self-supervised learning from naturalistic\n  videos","authors":"Alex N. Wang, Christopher Hoang, Yuwen Xiong, Yann LeCun, Mengye Ren","authorsParsed":[["Wang","Alex N.",""],["Hoang","Christopher",""],["Xiong","Yuwen",""],["LeCun","Yann",""],["Ren","Mengye",""]],"versions":[{"version":"v1","created":"Tue, 20 Aug 2024 21:40:48 GMT"}],"updateDate":"2024-08-22","timestamp":1724190048000,"abstract":"  Self-supervised learning has driven significant progress in learning from\nsingle-subject, iconic images. However, there are still unanswered questions\nabout the use of minimally-curated, naturalistic video data, which contain\ndense scenes with many independent objects, imbalanced class distributions, and\nvarying object sizes. In this paper, we propose a novel approach that combines\nan invariance-based SSL objective on pooled representations with a dense SSL\nobjective that enforces equivariance to optical flow warping. Our findings\nindicate that a unified objective applied at multiple feature scales is\nessential for learning effective image representations from high-resolution,\nnaturalistic videos. We validate our approach on the BDD100K driving video\ndataset and the Walking Tours first-person video dataset, demonstrating its\nability to capture spatial understanding from a dense objective and semantic\nunderstanding via a pooled representation objective.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}