{"id":"2408.07981","title":"LLaVA-Surg: Towards Multimodal Surgical Assistant via Structured\n  Surgical Video Learning","authors":"Jiajie Li, Garrett Skinner, Gene Yang, Brian R Quaranto, Steven D\n  Schwaitzberg, Peter C W Kim, Jinjun Xiong","authorsParsed":[["Li","Jiajie",""],["Skinner","Garrett",""],["Yang","Gene",""],["Quaranto","Brian R",""],["Schwaitzberg","Steven D",""],["Kim","Peter C W",""],["Xiong","Jinjun",""]],"versions":[{"version":"v1","created":"Thu, 15 Aug 2024 07:00:20 GMT"}],"updateDate":"2024-08-16","timestamp":1723705220000,"abstract":"  Multimodal large language models (LLMs) have achieved notable success across\nvarious domains, while research in the medical field has largely focused on\nunimodal images. Meanwhile, current general-domain multimodal models for videos\nstill lack the capabilities to understand and engage in conversations about\nsurgical videos. One major contributing factor is the absence of datasets in\nthe surgical field. In this paper, we create a new dataset, Surg-QA, consisting\nof 102,000 surgical video-instruction pairs, the largest of its kind so far. To\nbuild such a dataset, we propose a novel two-stage question-answer generation\npipeline with LLM to learn surgical knowledge in a structured manner from the\npublicly available surgical lecture videos. The pipeline breaks down the\ngeneration process into two stages to significantly reduce the task complexity,\nallowing us to use a more affordable, locally deployed open-source LLM than the\npremium paid LLM services. It also mitigates the risk of LLM hallucinations\nduring question-answer generation, thereby enhancing the overall quality of the\ngenerated data. We further train LLaVA-Surg, a novel vision-language\nconversational assistant capable of answering open-ended questions about\nsurgical videos, on this Surg-QA dataset, and conduct comprehensive evaluations\non zero-shot surgical video question-answering tasks. We show that LLaVA-Surg\nsignificantly outperforms all previous general-domain models, demonstrating\nexceptional multimodal conversational skills in answering open-ended questions\nabout surgical videos. We will release our code, model, and the\ninstruction-tuning dataset.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"Lh5v_CqWJbCS4ElwDblP0HnsbxTAHb9hx_j5vkiv8dU","pdfSize":"4361031"}
