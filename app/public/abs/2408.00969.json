{"id":"2408.00969","title":"Visible-Thermal Multiple Object Tracking: Large-scale Video Dataset and\n  Progressive Fusion Approach","authors":"Yabin Zhu, Qianwu Wang, Chenglong Li, Jin Tang, Zhixiang Huang","authorsParsed":[["Zhu","Yabin",""],["Wang","Qianwu",""],["Li","Chenglong",""],["Tang","Jin",""],["Huang","Zhixiang",""]],"versions":[{"version":"v1","created":"Fri, 2 Aug 2024 01:29:43 GMT"}],"updateDate":"2024-08-05","timestamp":1722562183000,"abstract":"  The complementary benefits from visible and thermal infrared data are widely\nutilized in various computer vision task, such as visual tracking, semantic\nsegmentation and object detection, but rarely explored in Multiple Object\nTracking (MOT). In this work, we contribute a large-scale Visible-Thermal video\nbenchmark for MOT, called VT-MOT. VT-MOT has the following main advantages. 1)\nThe data is large scale and high diversity. VT-MOT includes 582 video sequence\npairs, 401k frame pairs from surveillance, drone, and handheld platforms. 2)\nThe cross-modal alignment is highly accurate. We invite several professionals\nto perform both spatial and temporal alignment frame by frame. 3) The\nannotation is dense and high-quality. VT-MOT has 3.99 million annotation boxes\nannotated and double-checked by professionals, including heavy occlusion and\nobject re-acquisition (object disappear and reappear) challenges. To provide a\nstrong baseline, we design a simple yet effective tracking framework, which\neffectively fuses temporal information and complementary information of two\nmodalities in a progressive manner, for robust visible-thermal MOT. A\ncomprehensive experiment are conducted on VT-MOT and the results prove the\nsuperiority and effectiveness of the proposed method compared with\nstate-of-the-art methods. From the evaluation results and analysis, we specify\nseveral potential future directions for visible-thermal MOT. The project is\nreleased in https://github.com/wqw123wqw/PFTrack.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}