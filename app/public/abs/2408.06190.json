{"id":"2408.06190","title":"FruitNeRF: A Unified Neural Radiance Field based Fruit Counting\n  Framework","authors":"Lukas Meyer and Andreas Gilson and Ute Schmidt and Marc Stamminger","authorsParsed":[["Meyer","Lukas",""],["Gilson","Andreas",""],["Schmidt","Ute",""],["Stamminger","Marc",""]],"versions":[{"version":"v1","created":"Mon, 12 Aug 2024 14:40:38 GMT"}],"updateDate":"2024-08-13","timestamp":1723473638000,"abstract":"  We introduce FruitNeRF, a unified novel fruit counting framework that\nleverages state-of-the-art view synthesis methods to count any fruit type\ndirectly in 3D. Our framework takes an unordered set of posed images captured\nby a monocular camera and segments fruit in each image. To make our system\nindependent of the fruit type, we employ a foundation model that generates\nbinary segmentation masks for any fruit. Utilizing both modalities, RGB and\nsemantic, we train a semantic neural radiance field. Through uniform volume\nsampling of the implicit Fruit Field, we obtain fruit-only point clouds. By\napplying cascaded clustering on the extracted point cloud, our approach\nachieves precise fruit count.The use of neural radiance fields provides\nsignificant advantages over conventional methods such as object tracking or\noptical flow, as the counting itself is lifted into 3D. Our method prevents\ndouble counting fruit and avoids counting irrelevant fruit.We evaluate our\nmethodology using both real-world and synthetic datasets. The real-world\ndataset consists of three apple trees with manually counted ground truths, a\nbenchmark apple dataset with one row and ground truth fruit location, while the\nsynthetic dataset comprises various fruit types including apple, plum, lemon,\npear, peach, and mango.Additionally, we assess the performance of fruit\ncounting using the foundation model compared to a U-Net.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/"}