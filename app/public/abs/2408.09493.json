{"id":"2408.09493","title":"Ancestral Reinforcement Learning: Unifying Zeroth-Order Optimization and\n  Genetic Algorithms for Reinforcement Learning","authors":"So Nakashima and Tetsuya J. Kobayashi","authorsParsed":[["Nakashima","So",""],["Kobayashi","Tetsuya J.",""]],"versions":[{"version":"v1","created":"Sun, 18 Aug 2024 14:16:55 GMT"},{"version":"v2","created":"Mon, 2 Sep 2024 16:19:25 GMT"}],"updateDate":"2024-09-04","timestamp":1723990615000,"abstract":"  Reinforcement Learning (RL) offers a fundamental framework for discovering\noptimal action strategies through interactions within unknown environments.\nRecent advancement have shown that the performance and applicability of RL can\nsignificantly be enhanced by exploiting a population of agents in various ways.\nZeroth-Order Optimization (ZOO) leverages an agent population to estimate the\ngradient of the objective function, enabling robust policy refinement even in\nnon-differentiable scenarios. As another application, Genetic Algorithms (GA)\nboosts the exploration of policy landscapes by mutational generation of policy\ndiversity in an agent population and its refinement by selection. A natural\nquestion is whether we can have the best of two worlds that the agent\npopulation can have. In this work, we propose Ancestral Reinforcement Learning\n(ARL), which synergistically combines the robust gradient estimation of ZOO\nwith the exploratory power of GA. The key idea in ARL is that each agent within\na population infers gradient by exploiting the history of its ancestors, i.e.,\nthe ancestor population in the past, while maintaining the diversity of\npolicies in the current population as in GA. We also theoretically reveal that\nthe populational search in ARL implicitly induces the KL-regularization of the\nobjective function, resulting in the enhanced exploration. Our results extend\nthe applicability of populational algorithms for RL.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}