{"id":"2408.06019","title":"HeadGAP: Few-shot 3D Head Avatar via Generalizable Gaussian Priors","authors":"Xiaozheng Zheng, Chao Wen, Zhaohu Li, Weiyi Zhang, Zhuo Su, Xu Chang,\n  Yang Zhao, Zheng Lv, Xiaoyuan Zhang, Yongjie Zhang, Guidong Wang, Lan Xu","authorsParsed":[["Zheng","Xiaozheng",""],["Wen","Chao",""],["Li","Zhaohu",""],["Zhang","Weiyi",""],["Su","Zhuo",""],["Chang","Xu",""],["Zhao","Yang",""],["Lv","Zheng",""],["Zhang","Xiaoyuan",""],["Zhang","Yongjie",""],["Wang","Guidong",""],["Xu","Lan",""]],"versions":[{"version":"v1","created":"Mon, 12 Aug 2024 09:19:38 GMT"}],"updateDate":"2024-08-13","timestamp":1723454378000,"abstract":"  In this paper, we present a novel 3D head avatar creation approach capable of\ngeneralizing from few-shot in-the-wild data with high-fidelity and animatable\nrobustness. Given the underconstrained nature of this problem, incorporating\nprior knowledge is essential. Therefore, we propose a framework comprising\nprior learning and avatar creation phases. The prior learning phase leverages\n3D head priors derived from a large-scale multi-view dynamic dataset, and the\navatar creation phase applies these priors for few-shot personalization. Our\napproach effectively captures these priors by utilizing a Gaussian\nSplatting-based auto-decoder network with part-based dynamic modeling. Our\nmethod employs identity-shared encoding with personalized latent codes for\nindividual identities to learn the attributes of Gaussian primitives. During\nthe avatar creation phase, we achieve fast head avatar personalization by\nleveraging inversion and fine-tuning strategies. Extensive experiments\ndemonstrate that our model effectively exploits head priors and successfully\ngeneralizes them to few-shot personalization, achieving photo-realistic\nrendering quality, multi-view consistency, and stable animation.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}