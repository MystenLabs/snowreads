{"id":"2408.16879","title":"MSLIQA: Enhancing Learning Representations for Image Quality Assessment\n  through Multi-Scale Learning","authors":"Nasim Jamshidi Avanaki, Abhijay Ghildyal, Nabajeet Barman and Saman\n  Zadtootaghaj","authorsParsed":[["Avanaki","Nasim Jamshidi",""],["Ghildyal","Abhijay",""],["Barman","Nabajeet",""],["Zadtootaghaj","Saman",""]],"versions":[{"version":"v1","created":"Thu, 29 Aug 2024 20:05:02 GMT"},{"version":"v2","created":"Fri, 6 Sep 2024 17:17:16 GMT"}],"updateDate":"2024-09-09","timestamp":1724961902000,"abstract":"  No-Reference Image Quality Assessment (NR-IQA) remains a challenging task due\nto the diversity of distortions and the lack of large annotated datasets. Many\nstudies have attempted to tackle these challenges by developing more accurate\nNR-IQA models, often employing complex and computationally expensive networks,\nor by bridging the domain gap between various distortions to enhance\nperformance on test datasets. In our work, we improve the performance of a\ngeneric lightweight NR-IQA model by introducing a novel augmentation strategy\nthat boosts its performance by almost 28\\%. This augmentation strategy enables\nthe network to better discriminate between different distortions in various\nparts of the image by zooming in and out. Additionally, the inclusion of\ntest-time augmentation further enhances performance, making our lightweight\nnetwork's results comparable to the current state-of-the-art models, simply\nthrough the use of augmentations.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Multimedia"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"LykSomTrr_i5gp5mX8AG_vFhXUwVWgz5GbLsTZn-a60","pdfSize":"357046"}
