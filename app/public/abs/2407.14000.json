{"id":"2407.14000","title":"Clinical Reading Comprehension with Encoder-Decoder Models Enhanced by\n  Direct Preference Optimization","authors":"Md Sultan Al Nahian, Ramakanth Kavuluru","authorsParsed":[["Nahian","Md Sultan Al",""],["Kavuluru","Ramakanth",""]],"versions":[{"version":"v1","created":"Fri, 19 Jul 2024 03:12:10 GMT"}],"updateDate":"2024-07-22","timestamp":1721358730000,"abstract":"  Extractive question answering over clinical text is a crucial need to help\ndeal with the deluge of clinical text generated in hospitals. While encoder\nmodels (e.g., BERT) have been popular for this reading comprehension task,\nrecently encoder-decoder models (e.g., T5) are on the rise. There is also the\nemergence of preference optimization techniques to align decoder-only LLMs with\nhuman preferences. In this paper, we combine encoder-decoder models with the\ndirect preference optimization (DPO) method to improve over prior state of the\nart for the RadQA radiology question answering task by 12-15 F1 points. To the\nbest of our knowledge, this effort is the first to show that DPO method also\nworks for reading comprehension via novel heuristics to generate preference\ndata without human inputs.\n","subjects":["Computing Research Repository/Information Retrieval","Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}