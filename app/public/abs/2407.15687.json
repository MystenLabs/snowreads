{"id":"2407.15687","title":"SoftCVI: Contrastive variational inference with self-generated soft\n  labels","authors":"Daniel Ward, Mark Beaumont and Matteo Fasiolo","authorsParsed":[["Ward","Daniel",""],["Beaumont","Mark",""],["Fasiolo","Matteo",""]],"versions":[{"version":"v1","created":"Mon, 22 Jul 2024 14:54:12 GMT"},{"version":"v2","created":"Tue, 10 Sep 2024 18:46:35 GMT"}],"updateDate":"2024-09-12","timestamp":1721660052000,"abstract":"  Estimating a distribution given access to its unnormalized density is pivotal\nin Bayesian inference, where the posterior is generally known only up to an\nunknown normalizing constant. Variational inference and Markov chain Monte\nCarlo methods are the predominant tools for this task; however, both are often\nchallenging to apply reliably, particularly when the posterior has complex\ngeometry. Here, we introduce Soft Contrastive Variational Inference (SoftCVI),\nwhich allows a family of variational objectives to be derived through a\ncontrastive estimation framework. The approach parameterizes a classifier in\nterms of a variational distribution, reframing the inference task as a\ncontrastive estimation problem aiming to identify a single true posterior\nsample among a set of samples. Despite this framing, we do not require positive\nor negative samples, but rather learn by sampling the variational distribution\nand computing ground truth soft classification labels from the unnormalized\nposterior itself. The objectives have zero variance gradient when the\nvariational approximation is exact, without the need for specialized gradient\nestimators. We empirically investigate the performance on a variety of Bayesian\ninference tasks, using both simple (e.g. normal) and expressive (normalizing\nflow) variational distributions. We find that SoftCVI can be used to form\nobjectives which are stable to train and mass-covering, frequently\noutperforming inference with other variational approaches.\n","subjects":["Statistics/Machine Learning","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}