{"id":"2408.04811","title":"h4rm3l: A Dynamic Benchmark of Composable Jailbreak Attacks for LLM\n  Safety Assessment","authors":"Moussa Koulako Bala Doumbouya, Ananjan Nandi, Gabriel Poesia, Davide\n  Ghilardi, Anna Goldie, Federico Bianchi, Dan Jurafsky, Christopher D. Manning","authorsParsed":[["Doumbouya","Moussa Koulako Bala",""],["Nandi","Ananjan",""],["Poesia","Gabriel",""],["Ghilardi","Davide",""],["Goldie","Anna",""],["Bianchi","Federico",""],["Jurafsky","Dan",""],["Manning","Christopher D.",""]],"versions":[{"version":"v1","created":"Fri, 9 Aug 2024 01:45:39 GMT"},{"version":"v2","created":"Fri, 13 Sep 2024 05:19:32 GMT"}],"updateDate":"2024-09-16","timestamp":1723167939000,"abstract":"  The safety of Large Language Models (LLMs) remains a critical concern due to\na lack of adequate benchmarks for systematically evaluating their ability to\nresist generating harmful content. Previous efforts towards automated red\nteaming involve static or templated sets of illicit requests and adversarial\nprompts which have limited utility given jailbreak attacks' evolving and\ncomposable nature. We propose a novel dynamic benchmark of composable jailbreak\nattacks to move beyond static datasets and taxonomies of attacks and harms. Our\napproach consists of three components collectively called h4rm3l: (1) a\ndomain-specific language that formally expresses jailbreak attacks as\ncompositions of parameterized prompt transformation primitives, (2)\nbandit-based few-shot program synthesis algorithms that generate novel attacks\noptimized to penetrate the safety filters of a target black box LLM, and (3)\nopen-source automated red-teaming software employing the previous two\ncomponents. We use h4rm3l to generate a dataset of 2656 successful novel\njailbreak attacks targeting 6 state-of-the-art (SOTA) open-source and\nproprietary LLMs. Several of our synthesized attacks are more effective than\npreviously reported ones, with Attack Success Rates exceeding 90% on SOTA\nclosed language models such as claude-3-haiku and GPT4-o. By generating\ndatasets of jailbreak attacks in a unified formal representation, h4rm3l\nenables reproducible benchmarking and automated red-teaming, contributes to\nunderstanding LLM safety limitations, and supports the development of robust\ndefenses in an increasingly LLM-integrated world.\n  Warning: This paper and related research artifacts contain offensive and\npotentially disturbing prompts and model-generated content.\n","subjects":["Computing Research Repository/Cryptography and Security","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by-sa/4.0/","blobId":"0s2q-jPpHLjQ6HxyIcB1ulzJyjFIOxm3FAyPABmylSA","pdfSize":"5016558"}
