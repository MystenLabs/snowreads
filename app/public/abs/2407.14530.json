{"id":"2407.14530","title":"FuncEvalGMN: Evaluating Functional Correctness of SQL via Graph Matching\n  Network","authors":"Yi Zhan, Yang Sun, Han Weng, Longjie Cui, Guifeng Wang, Jiajun Xie, Yu\n  Tian, Xiaoming Yin, Boyi Liu, Dongchi Huang","authorsParsed":[["Zhan","Yi",""],["Sun","Yang",""],["Weng","Han",""],["Cui","Longjie",""],["Wang","Guifeng",""],["Xie","Jiajun",""],["Tian","Yu",""],["Yin","Xiaoming",""],["Liu","Boyi",""],["Huang","Dongchi",""]],"versions":[{"version":"v1","created":"Tue, 9 Jul 2024 03:05:27 GMT"}],"updateDate":"2024-07-23","timestamp":1720494327000,"abstract":"  In this paper, we propose a novel graph-based methodology to evaluate the\nfunctional correctness of SQL generation. Conventional metrics for assessing\nSQL code generation, such as matching-based and execution-based methods (e.g.,\nexact set match and execution accuracy), are subject to two primary\nlimitations. Firstly, the former fails to effectively assess functional\ncorrectness, as different SQL queries may possess identical functionalities.\nSecondly, the latter is susceptible to producing false positive samples in\nevaluations. Our proposed evaluation method, \\texttt{FuncEvalGMN}, does not\ndepend on the sufficient preparation of the test data, and it enables precise\ntesting of the functional correctness of the code. Firstly, we parse SQL using\na relational operator tree (ROT) called \\textit{Relnode}, which contains rich\nsemantic information from the perspective of logical execution.Then, we\nintroduce a GNN-based approach for predicting the functional correctness of\ngenerated SQL. This approach incorporates global positional embeddings to\naddress the limitations with the loss of topological information in\nconventional graph matching frameworks. As an auxiliary contribution, we\npropose a rule-based matching algorithm, Relnode Partial Matching\n(\\texttt{RelPM}) as a baseline. Finally, we contribute a dataset,\n\\texttt{Pair-Aug-Spider} with a training set and two testing sets, each\ncomprising pairs of SQL codes to simulate various SQL code evaluation\nscenarios. The training set and one testing dataset focus on code generation\nusing large language models (LLMs), while the other emphasizes SQL equivalence\nrewriting.\n","subjects":["Computing Research Repository/Databases","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"hv6J1TDsqOKbl-hciPbyiVxNyE20I_eHAiUW3YvxlM4","pdfSize":"8167540"}
