{"id":"2407.15415","title":"LLaST: Improved End-to-end Speech Translation System Leveraged by Large\n  Language Models","authors":"Xi Chen, Songyang Zhang, Qibing Bai, Kai Chen, Satoshi Nakamura","authorsParsed":[["Chen","Xi",""],["Zhang","Songyang",""],["Bai","Qibing",""],["Chen","Kai",""],["Nakamura","Satoshi",""]],"versions":[{"version":"v1","created":"Mon, 22 Jul 2024 06:42:00 GMT"}],"updateDate":"2024-07-23","timestamp":1721630520000,"abstract":"  We introduces LLaST, a framework for building high-performance Large Language\nmodel based Speech-to-text Translation systems. We address the limitations of\nend-to-end speech translation(E2E ST) models by exploring model architecture\ndesign and optimization techniques tailored for LLMs. Our approach includes\nLLM-based speech translation architecture design, ASR-augmented training,\nmultilingual data augmentation, and dual-LoRA optimization. Our approach\ndemonstrates superior performance on the CoVoST-2 benchmark and showcases\nexceptional scaling capabilities powered by LLMs. We believe this effective\nmethod will serve as a strong baseline for speech translation and provide\ninsights for future improvements of the LLM-based speech translation framework.\nWe release the data, code and models in https://github.com/openaudiolab/LLaST.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}