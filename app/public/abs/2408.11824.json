{"id":"2408.11824","title":"AppAgent v2: Advanced Agent for Flexible Mobile Interactions","authors":"Yanda Li, Chi Zhang, Wanqi Yang, Bin Fu, Pei Cheng, Xin Chen, Ling\n  Chen, Yunchao Wei","authorsParsed":[["Li","Yanda",""],["Zhang","Chi",""],["Yang","Wanqi",""],["Fu","Bin",""],["Cheng","Pei",""],["Chen","Xin",""],["Chen","Ling",""],["Wei","Yunchao",""]],"versions":[{"version":"v1","created":"Mon, 5 Aug 2024 06:31:39 GMT"},{"version":"v2","created":"Fri, 23 Aug 2024 04:13:48 GMT"}],"updateDate":"2024-08-26","timestamp":1722839499000,"abstract":"  With the advancement of Multimodal Large Language Models (MLLM), LLM-driven\nvisual agents are increasingly impacting software interfaces, particularly\nthose with graphical user interfaces. This work introduces a novel LLM-based\nmultimodal agent framework for mobile devices. This framework, capable of\nnavigating mobile devices, emulates human-like interactions. Our agent\nconstructs a flexible action space that enhances adaptability across various\napplications including parser, text and vision descriptions. The agent operates\nthrough two main phases: exploration and deployment. During the exploration\nphase, functionalities of user interface elements are documented either through\nagent-driven or manual explorations into a customized structured knowledge\nbase. In the deployment phase, RAG technology enables efficient retrieval and\nupdate from this knowledge base, thereby empowering the agent to perform tasks\neffectively and accurately. This includes performing complex, multi-step\noperations across various applications, thereby demonstrating the framework's\nadaptability and precision in handling customized task workflows. Our\nexperimental results across various benchmarks demonstrate the framework's\nsuperior performance, confirming its effectiveness in real-world scenarios. Our\ncode will be open source soon.\n","subjects":["Computing Research Repository/Human-Computer Interaction","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/"}