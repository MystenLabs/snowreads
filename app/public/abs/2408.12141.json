{"id":"2408.12141","title":"TRRG: Towards Truthful Radiology Report Generation With Cross-modal\n  Disease Clue Enhanced Large Language Model","authors":"Yuhao Wang, Chao Hao, Yawen Cui, Xinqi Su, Weicheng Xie, Tao Tan,\n  Zitong Yu","authorsParsed":[["Wang","Yuhao",""],["Hao","Chao",""],["Cui","Yawen",""],["Su","Xinqi",""],["Xie","Weicheng",""],["Tan","Tao",""],["Yu","Zitong",""]],"versions":[{"version":"v1","created":"Thu, 22 Aug 2024 05:52:27 GMT"}],"updateDate":"2024-08-23","timestamp":1724305947000,"abstract":"  The vision-language modeling capability of multi-modal large language models\nhas attracted wide attention from the community. However, in medical domain,\nradiology report generation using vision-language models still faces\nsignificant challenges due to the imbalanced data distribution caused by\nnumerous negated descriptions in radiology reports and issues such as rough\nalignment between radiology reports and radiography. In this paper, we propose\na truthful radiology report generation framework, namely TRRG, based on\nstage-wise training for cross-modal disease clue injection into large language\nmodels. In pre-training stage, During the pre-training phase, contrastive\nlearning is employed to enhance the ability of visual encoder to perceive\nfine-grained disease details. In fine-tuning stage, the clue injection module\nwe proposed significantly enhances the disease-oriented perception capability\nof the large language model by effectively incorporating the robust zero-shot\ndisease perception. Finally, through the cross-modal clue interaction module,\nour model effectively achieves the multi-granular interaction of visual\nembeddings and an arbitrary number of disease clue embeddings. This\nsignificantly enhances the report generation capability and clinical\neffectiveness of multi-modal large language models in the field of radiology\nreportgeneration. Experimental results demonstrate that our proposed\npre-training and fine-tuning framework achieves state-of-the-art performance in\nradiology report generation on datasets such as IU-Xray and MIMIC-CXR. Further\nanalysis indicates that our proposed method can effectively enhance the model\nto perceive diseases and improve its clinical effectiveness.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"9aazlbMKl4z5z8eEjRsGsBc708Ih0YgRIlMcoOBLaN8","pdfSize":"569775"}
