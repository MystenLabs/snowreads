{"id":"2408.00293","title":"Gradient Flow Decoding","authors":"Tadashi Wadayama and Lantian Wei","authorsParsed":[["Wadayama","Tadashi",""],["Wei","Lantian",""]],"versions":[{"version":"v1","created":"Thu, 1 Aug 2024 05:41:28 GMT"}],"updateDate":"2024-08-02","timestamp":1722490888000,"abstract":"  This paper presents the Gradient Flow (GF) decoding for LDPC codes. GF\ndecoding, a continuous-time methodology based on gradient flow, employs a\npotential energy function associated with bipolar codewords of LDPC codes. The\ndecoding process of the GF decoding is concisely defined by an ordinary\ndifferential equation and thus it is well suited to an analog circuit\nimplementation. We experimentally demonstrate that the decoding performance of\nthe GF decoding for AWGN channels is comparable to that of the multi-bit mode\ngradient descent bit flipping algorithm. We further introduce the negative\nlog-likelihood function of the channel for generalizing the GF decoding. The\nproposed method is shown to be tensor-computable, which means that the gradient\nof the objective function can be evaluated with the combination of basic tensor\ncomputations. This characteristic is well-suited to emerging AI accelerators,\npotentially applicable in wireless signal processing. The paper assesses the\ndecoding performance of the generalized GF decoding in LDPC-coded MIMO\nchannels. Our numerical experiments reveal that the decoding performance rivals\nthat of established techniques like MMSE + BP. Furthermore, an exploration of\nscore-based channel learning for capturing statistical properties is also\nprovided.\n","subjects":["Computing Research Repository/Information Theory","Mathematics/Information Theory"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"SXXBym-_TiPzWgF8H9XwbgctFtdYktfzmsm-yuSTr64","pdfSize":"2600189","txDigest":"De9RspA55YNY6SnhuAPL6t8JSG9Y6uRxZpST37ntztyK","endEpoch":"1","status":"CERTIFIED"}
