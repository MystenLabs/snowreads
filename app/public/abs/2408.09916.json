{"id":"2408.09916","title":"Attribution Analysis Meets Model Editing: Advancing Knowledge Correction\n  in Vision Language Models with VisEdit","authors":"Qizhou Chen, Taolin Zhang, Chengyu Wang, Xiaofeng He, Dakan Wang,\n  Tingting Liu","authorsParsed":[["Chen","Qizhou",""],["Zhang","Taolin",""],["Wang","Chengyu",""],["He","Xiaofeng",""],["Wang","Dakan",""],["Liu","Tingting",""]],"versions":[{"version":"v1","created":"Mon, 19 Aug 2024 11:44:40 GMT"}],"updateDate":"2024-08-20","timestamp":1724067880000,"abstract":"  Model editing aims to correct outdated or erroneous knowledge in large models\nwithout costly retraining. Recent research discovered that the mid-layer\nrepresentation of the subject's final token in a prompt has a strong influence\non factual predictions, and developed Large Language Model (LLM) editing\ntechniques based on this observation. However, for Vision-LLMs (VLLMs), how\nvisual representations impact the predictions from a decoder-only language\nmodel remains largely unexplored. To the best of our knowledge, model editing\nfor VLLMs has not been extensively studied in the literature. In this work, we\nemploy the contribution allocation and noise perturbation methods to measure\nthe contributions of visual representations for token predictions. Our\nattribution analysis shows that visual representations in mid-to-later layers\nthat are highly relevant to the prompt contribute significantly to predictions.\nBased on these insights, we propose VisEdit, a novel model editor for VLLMs\nthat effectively corrects knowledge by editing intermediate visual\nrepresentations in regions important to the edit prompt. We evaluated VisEdit\nusing multiple VLLM backbones and public VLLM editing benchmark datasets. The\nresults show the superiority of VisEdit over the strong baselines adapted from\nexisting state-of-the-art editors for LLMs.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"1pIfBemSXIOT1HMiR9HrTo5q5e2uGbBKt9qNqOOePrQ","pdfSize":"4672083"}
