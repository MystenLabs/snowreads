{"id":"2407.04368","title":"Romanization Encoding For Multilingual ASR","authors":"Wen Ding, Fei Jia, Hainan Xu, Yu Xi, Junjie Lai, Boris Ginsburg","authorsParsed":[["Ding","Wen",""],["Jia","Fei",""],["Xu","Hainan",""],["Xi","Yu",""],["Lai","Junjie",""],["Ginsburg","Boris",""]],"versions":[{"version":"v1","created":"Fri, 5 Jul 2024 09:13:24 GMT"}],"updateDate":"2024-07-08","timestamp":1720170804000,"abstract":"  We introduce romanization encoding for script-heavy languages to optimize\nmultilingual and code-switching Automatic Speech Recognition (ASR) systems. By\nadopting romanization encoding alongside a balanced concatenated tokenizer\nwithin a FastConformer-RNNT framework equipped with a Roman2Char module, we\nsignificantly reduce vocabulary and output dimensions, enabling larger training\nbatches and reduced memory consumption. Our method decouples acoustic modeling\nand language modeling, enhancing the flexibility and adaptability of the\nsystem. In our study, applying this method to Mandarin-English ASR resulted in\na remarkable 63.51% vocabulary reduction and notable performance gains of\n13.72% and 15.03% on SEAME code-switching benchmarks. Ablation studies on\nMandarin-Korean and Mandarin-Japanese highlight our method's strong capability\nto address the complexities of other script-heavy languages, paving the way for\nmore versatile and effective multilingual ASR systems.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Sound","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}