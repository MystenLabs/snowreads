{"id":"2408.05566","title":"Document-Level Event Extraction with Definition-Driven ICL","authors":"Zhuoyuan Liu, Yilin Luo","authorsParsed":[["Liu","Zhuoyuan",""],["Luo","Yilin",""]],"versions":[{"version":"v1","created":"Sat, 10 Aug 2024 14:24:09 GMT"}],"updateDate":"2024-08-13","timestamp":1723299849000,"abstract":"  In the field of Natural Language Processing (NLP), Large Language Models\n(LLMs) have shown great potential in document-level event extraction tasks, but\nexisting methods face challenges in the design of prompts. To address this\nissue, we propose an optimization strategy called \"Definition-driven\nDocument-level Event Extraction (DDEE).\" By adjusting the length of the prompt\nand enhancing the clarity of heuristics, we have significantly improved the\nevent extraction performance of LLMs. We used data balancing techniques to\nsolve the long-tail effect problem, enhancing the model's generalization\nability for event types. At the same time, we refined the prompt to ensure it\nis both concise and comprehensive, adapting to the sensitivity of LLMs to the\nstyle of prompts. In addition, the introduction of structured heuristic methods\nand strict limiting conditions has improved the precision of event and argument\nrole extraction. These strategies not only solve the prompt engineering\nproblems of LLMs in document-level event extraction but also promote the\ndevelopment of event extraction technology, providing new research perspectives\nfor other tasks in the NLP field.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computers and Society","Computing Research Repository/Information Retrieval"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}