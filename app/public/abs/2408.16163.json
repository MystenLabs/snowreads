{"id":"2408.16163","title":"FRACTURED-SORRY-Bench: Framework for Revealing Attacks in Conversational\n  Turns Undermining Refusal Efficacy and Defenses over SORRY-Bench","authors":"Aman Priyanshu and Supriti Vijay","authorsParsed":[["Priyanshu","Aman",""],["Vijay","Supriti",""]],"versions":[{"version":"v1","created":"Wed, 28 Aug 2024 22:51:29 GMT"}],"updateDate":"2024-08-30","timestamp":1724885489000,"abstract":"  This paper introduces FRACTURED-SORRY-Bench, a framework for evaluating the\nsafety of Large Language Models (LLMs) against multi-turn conversational\nattacks. Building upon the SORRY-Bench dataset, we propose a simple yet\neffective method for generating adversarial prompts by breaking down harmful\nqueries into seemingly innocuous sub-questions. Our approach achieves a maximum\nincrease of +46.22\\% in Attack Success Rates (ASRs) across GPT-4, GPT-4o,\nGPT-4o-mini, and GPT-3.5-Turbo models compared to baseline methods. We\ndemonstrate that this technique poses a challenge to current LLM safety\nmeasures and highlights the need for more robust defenses against subtle,\nmulti-turn attacks.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"Mk-_GXA6HS1cxPsV2MTvORNHkHZUcFgrNRCKmYoX8_8","pdfSize":"69641"}
