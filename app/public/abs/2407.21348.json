{"id":"2407.21348","title":"SuperVINS: A visual-inertial SLAM framework integrated deep learning\n  features","authors":"Hongkun Luo, Chi Guo, Yang Liu, Zengke Li","authorsParsed":[["Luo","Hongkun",""],["Guo","Chi",""],["Liu","Yang",""],["Li","Zengke",""]],"versions":[{"version":"v1","created":"Wed, 31 Jul 2024 05:38:49 GMT"}],"updateDate":"2024-08-01","timestamp":1722404329000,"abstract":"  In this article, we propose enhancements to VINS-Fusion by incorporating deep\nlearning features and deep learning matching methods. We implemented the\ntraining of deep learning feature bag of words and utilized these features for\nloop closure detection. Additionally, we introduce the RANSAC algorithm in the\ndeep learning feature matching module to optimize matching. SuperVINS, an\nimproved version of VINS-Fusion, outperforms it in terms of positioning\naccuracy, robustness, and more. Particularly in challenging scenarios like low\nillumination and rapid jitter, traditional geometric features fail to fully\nexploit image information, whereas deep learning features excel at capturing\nimage features.To validate our proposed improvement scheme, we conducted\nexperiments using open source datasets. We performed a comprehensive analysis\nof the experimental results from both qualitative and quantitative\nperspectives. The results demonstrate the feasibility and effectiveness of this\ndeep learning-based approach for SLAM systems.To foster knowledge exchange in\nthis field, we have made the code for this article publicly available. You can\nfind the code at this link: https://github.com/luohongk/SuperVINS.\n","subjects":["Computing Research Repository/Robotics"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"EGBNwFzb51XfDM5djUEXHGYaQtt2kPpgw3dTef8_K8U","pdfSize":"21687597","objectId":"0x2b97794afe5125e713af8c92b7508f4b415360c4b0e686e7ae0f68bc56aa92e8","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
