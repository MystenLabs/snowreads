{"id":"2407.20257","title":"Causal Understanding For Video Question Answering","authors":"Bhanu Prakash Reddy Guda, Tanmay Kulkarni, Adithya Sampath,\n  Swarnashree Mysore Sathyendra","authorsParsed":[["Guda","Bhanu Prakash Reddy",""],["Kulkarni","Tanmay",""],["Sampath","Adithya",""],["Sathyendra","Swarnashree Mysore",""]],"versions":[{"version":"v1","created":"Tue, 23 Jul 2024 06:32:46 GMT"}],"updateDate":"2024-07-31","timestamp":1721716366000,"abstract":"  Video Question Answering is a challenging task, which requires the model to\nreason over multiple frames and understand the interaction between different\nobjects to answer questions based on the context provided within the video,\nespecially in datasets like NExT-QA (Xiao et al., 2021a) which emphasize on\ncausal and temporal questions. Previous approaches leverage either sub-sampled\ninformation or causal intervention techniques along with complete video\nfeatures to tackle the NExT-QA task. In this work we elicit the limitations of\nthese approaches and propose solutions along four novel directions of\nimprovements on theNExT-QA dataset. Our approaches attempts to compensate for\nthe shortcomings in the previous works by systematically attacking each of\nthese problems by smartly sampling frames, explicitly encoding actions and\ncreating interventions that challenge the understanding of the model. Overall,\nfor both single-frame (+6.3%) and complete-video (+1.1%) based approaches, we\nobtain the state-of-the-art results on NExT-QA dataset.\n","subjects":["Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"0Fa-G1usJLbk10B3o8Ezsh5fh9IDbCv1deKzvy1d6sQ","pdfSize":"26307570"}
