{"id":"2407.00934","title":"CLEME2.0: Towards More Interpretable Evaluation by Disentangling Edits\n  for Grammatical Error Correction","authors":"Jingheng Ye, Zishan Xu, Yinghui Li, Xuxin Cheng, Linlin Song, Qingyu\n  Zhou, Hai-Tao Zheng, Ying Shen, Xin Su","authorsParsed":[["Ye","Jingheng",""],["Xu","Zishan",""],["Li","Yinghui",""],["Cheng","Xuxin",""],["Song","Linlin",""],["Zhou","Qingyu",""],["Zheng","Hai-Tao",""],["Shen","Ying",""],["Su","Xin",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 03:35:58 GMT"}],"updateDate":"2024-07-02","timestamp":1719804958000,"abstract":"  The paper focuses on improving the interpretability of Grammatical Error\nCorrection (GEC) metrics, which receives little attention in previous studies.\nTo bridge the gap, we propose CLEME2.0, a reference-based evaluation strategy\nthat can describe four elementary dimensions of GEC systems, namely\nhit-correction, error-correction, under-correction, and over-correction. They\ncollectively contribute to revealing the critical characteristics and locating\ndrawbacks of GEC systems. Evaluating systems by Combining these dimensions\nleads to high human consistency over other reference-based and reference-less\nmetrics. Extensive experiments on 2 human judgement datasets and 6 reference\ndatasets demonstrate the effectiveness and robustness of our method. All the\ncodes will be released after the peer review.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}