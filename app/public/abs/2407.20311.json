{"id":"2407.20311","title":"Physics of Language Models: Part 2.1, Grade-School Math and the Hidden\n  Reasoning Process","authors":"Tian Ye, Zicheng Xu, Yuanzhi Li, Zeyuan Allen-Zhu","authorsParsed":[["Ye","Tian",""],["Xu","Zicheng",""],["Li","Yuanzhi",""],["Allen-Zhu","Zeyuan",""]],"versions":[{"version":"v1","created":"Mon, 29 Jul 2024 17:52:40 GMT"}],"updateDate":"2024-07-31","timestamp":1722275560000,"abstract":"  Recent advances in language models have demonstrated their capability to\nsolve mathematical reasoning problems, achieving near-perfect accuracy on\ngrade-school level math benchmarks like GSM8K. In this paper, we formally study\nhow language models solve these problems. We design a series of controlled\nexperiments to address several fundamental questions: (1) Can language models\ntruly develop reasoning skills, or do they simply memorize templates? (2) What\nis the model's hidden (mental) reasoning process? (3) Do models solve math\nquestions using skills similar to or different from humans? (4) Do models\ntrained on GSM8K-like datasets develop reasoning skills beyond those necessary\nfor solving GSM8K problems? (5) What mental process causes models to make\nreasoning mistakes? (6) How large or deep must a model be to effectively solve\nGSM8K-level math questions?\n  Our study uncovers many hidden mechanisms by which language models solve\nmathematical questions, providing insights that extend beyond current\nunderstandings of LLMs.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}