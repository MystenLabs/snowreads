{"id":"2407.03875","title":"RobQuNNs: A Methodology for Robust Quanvolutional Neural Networks\n  against Adversarial Attacks","authors":"Walid El Maouaki, Alberto Marchisio, Taoufik Said, Muhammad Shafique,\n  Mohamed Bennai","authorsParsed":[["Maouaki","Walid El",""],["Marchisio","Alberto",""],["Said","Taoufik",""],["Shafique","Muhammad",""],["Bennai","Mohamed",""]],"versions":[{"version":"v1","created":"Thu, 4 Jul 2024 12:13:52 GMT"}],"updateDate":"2024-07-08","timestamp":1720095232000,"abstract":"  Recent advancements in quantum computing have led to the emergence of hybrid\nquantum neural networks, such as Quanvolutional Neural Networks (QuNNs), which\nintegrate quantum and classical layers. While the susceptibility of classical\nneural networks to adversarial attacks is well-documented, the impact on QuNNs\nremains less understood. This study introduces RobQuNN, a new methodology to\nenhance the robustness of QuNNs against adversarial attacks, utilizing quantum\ncircuit expressibility and entanglement capability alongside different\nadversarial strategies. Additionally, the study investigates the\ntransferability of adversarial examples between classical and quantum models\nusing RobQuNN, enhancing our understanding of cross-model vulnerabilities and\npointing to new directions in quantum cybersecurity. The findings reveal that\nQuNNs exhibit up to 60\\% higher robustness compared to classical networks for\nthe MNIST dataset, particularly at low levels of perturbation. This underscores\nthe potential of quantum approaches in improving security defenses. In\naddition, RobQuNN revealed that QuNN does not exhibit enhanced resistance or\nsusceptibility to cross-model adversarial examples regardless of the quantum\ncircuit architecture.\n","subjects":["Physics/Quantum Physics"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}