{"id":"2408.13167","title":"A density ratio framework for evaluating the utility of synthetic data","authors":"Thom Benjamin Volker, Peter-Paul de Wolf, Erik-Jan van Kesteren","authorsParsed":[["Volker","Thom Benjamin",""],["de Wolf","Peter-Paul",""],["van Kesteren","Erik-Jan",""]],"versions":[{"version":"v1","created":"Fri, 23 Aug 2024 15:39:30 GMT"}],"updateDate":"2024-08-26","timestamp":1724427570000,"abstract":"  Synthetic data generation is a promising technique to facilitate the use of\nsensitive data while mitigating the risk of privacy breaches. However, for\nsynthetic data to be useful in downstream analysis tasks, it needs to be of\nsufficient quality. Various methods have been proposed to measure the utility\nof synthetic data, but their results are often incomplete or even misleading.\nIn this paper, we propose using density ratio estimation to improve quality\nevaluation for synthetic data, and thereby the quality of synthesized datasets.\nWe show how this framework relates to and builds on existing measures, yielding\nglobal and local utility measures that are informative and easy to interpret.\nWe develop an estimator which requires little to no manual tuning due to\nautomatic selection of a nonparametric density ratio model. Through\nsimulations, we find that density ratio estimation yields more accurate\nestimates of global utility than established procedures. A real-world data\napplication demonstrates how the density ratio can guide refinements of\nsynthesis models and can be used to improve downstream analyses. We conclude\nthat density ratio estimation is a valuable tool in synthetic data generation\nworkflows and provide these methods in the accessible open source R-package\ndensityratio.\n","subjects":["Statistics/Machine Learning","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}