{"id":"2407.00889","title":"Non-Prehensile Aerial Manipulation using Model-Based Deep Reinforcement\n  Learning","authors":"Cora A. Dimmig and Marin Kobilarov","authorsParsed":[["Dimmig","Cora A.",""],["Kobilarov","Marin",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 01:24:31 GMT"}],"updateDate":"2024-07-02","timestamp":1719797071000,"abstract":"  With the continual adoption of Uncrewed Aerial Vehicles (UAVs) across a\nwide-variety of application spaces, robust aerial manipulation remains a key\nresearch challenge. Aerial manipulation tasks require interacting with objects\nin the environment, often without knowing their dynamical properties like mass\nand friction a priori. Additionally, interacting with these objects can have a\nsignificant impact on the control and stability of the vehicle. We investigated\nan approach for robust control and non-prehensile aerial manipulation in\nunknown environments. In particular, we use model-based Deep Reinforcement\nLearning (DRL) to learn a world model of the environment while simultaneously\nlearning a policy for interaction with the environment. We evaluated our\napproach on a series of push tasks by moving an object between goal locations\nand demonstrated repeatable behaviors across a range of friction values.\n","subjects":["Computing Research Repository/Robotics"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}