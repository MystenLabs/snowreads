{"id":"2407.01249","title":"Anomaly-aware summary statistic from data batches","authors":"Gaia Grosso","authorsParsed":[["Grosso","Gaia",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 12:56:38 GMT"},{"version":"v2","created":"Sun, 15 Sep 2024 14:09:11 GMT"}],"updateDate":"2024-09-17","timestamp":1719838598000,"abstract":"  Signal-agnostic data exploration based on machine learning could unveil very\nsubtle statistical deviations of collider data from the expected Standard Model\nof particle physics. The beneficial impact of a large training sample on\nmachine learning solutions motivates the exploration of increasingly large and\ninclusive samples of acquired data with resource efficient computational\nmethods. In this work we consider the New Physics Learning Machine (NPLM), a\nmultivariate goodness-of-fit test built on the Neyman-Pearson\nmaximum-likelihood-ratio construction, and we address the problem of testing\nlarge size samples under computational and storage resource constraints. We\npropose to perform parallel NPLM routines over batches of the data, and to\ncombine them by locally aggregating over the data-to-reference density ratios\nlearnt by each batch. The resulting data hypothesis defining the\nlikelihood-ratio test is thus shared over the batches, and complies with the\nassumption that the expected rate of new physical processes is time invariant.\nWe show that this method outperforms the simple sum of the independent tests\nrun over the batches, and can recover, or even surpass, the sensitivity of the\nsingle test run over the full data. Beside the significant advantage for the\noffline application of NPLM to large size samples, the proposed approach offers\nnew prospects toward the use of NPLM to construct anomaly-aware summary\nstatistics in quasi-online data streaming scenarios.\n","subjects":["Physics/High Energy Physics - Experiment","Physics/Data Analysis, Statistics and Probability"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}