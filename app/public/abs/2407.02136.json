{"id":"2407.02136","title":"Black Big Boxes: Do Language Models Hide a Theory of Adjective Order?","authors":"Jaap Jumelet, Lisa Bylinina, Willem Zuidema, Jakub Szymanik","authorsParsed":[["Jumelet","Jaap",""],["Bylinina","Lisa",""],["Zuidema","Willem",""],["Szymanik","Jakub",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 10:29:09 GMT"}],"updateDate":"2024-07-03","timestamp":1719916149000,"abstract":"  In English and other languages, multiple adjectives in a complex noun phrase\nshow intricate ordering patterns that have been a target of much linguistic\ntheory. These patterns offer an opportunity to assess the ability of language\nmodels (LMs) to learn subtle rules of language involving factors that cross the\ntraditional divisions of syntax, semantics, and pragmatics. We review existing\nhypotheses designed to explain Adjective Order Preferences (AOPs) in humans and\ndevelop a setup to study AOPs in LMs: we present a reusable corpus of adjective\npairs and define AOP measures for LMs. With these tools, we study a series of\nLMs across intermediate checkpoints during training. We find that all models'\npredictions are much closer to human AOPs than predictions generated by factors\nidentified in theoretical linguistics. At the same time, we demonstrate that\nthe observed AOPs in LMs are strongly correlated with the frequency of the\nadjective pairs in the training data and report limited generalization to\nunseen combinations. This highlights the difficulty in establishing the link\nbetween LM performance and linguistic theory. We therefore conclude with a road\nmap for future studies our results set the stage for, and a discussion of key\nquestions about the nature of knowledge in LMs and their ability to generalize\nbeyond the training sets.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/"}