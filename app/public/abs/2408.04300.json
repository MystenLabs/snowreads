{"id":"2408.04300","title":"An Explainable Non-local Network for COVID-19 Diagnosis","authors":"Jingfu Yang, Peng Huang, Jing Hu, Shu Hu, Siwei Lyu, Xin Wang, Jun\n  Guo, Xi Wu","authorsParsed":[["Yang","Jingfu",""],["Huang","Peng",""],["Hu","Jing",""],["Hu","Shu",""],["Lyu","Siwei",""],["Wang","Xin",""],["Guo","Jun",""],["Wu","Xi",""]],"versions":[{"version":"v1","created":"Thu, 8 Aug 2024 08:35:21 GMT"}],"updateDate":"2024-08-09","timestamp":1723106121000,"abstract":"  The CNN has achieved excellent results in the automatic classification of\nmedical images. In this study, we propose a novel deep residual 3D attention\nnon-local network (NL-RAN) to classify CT images included COVID-19, common\npneumonia, and normal to perform rapid and explainable COVID-19 diagnosis. We\nbuilt a deep residual 3D attention non-local network that could achieve\nend-to-end training. The network is embedded with a nonlocal module to capture\nglobal information, while a 3D attention module is embedded to focus on the\ndetails of the lesion so that it can directly analyze the 3D lung CT and output\nthe classification results. The output of the attention module can be used as a\nheat map to increase the interpretability of the model. 4079 3D CT scans were\nincluded in this study. Each scan had a unique label (novel coronavirus\npneumonia, common pneumonia, and normal). The CT scans cohort was randomly\nsplit into a training set of 3263 scans, a validation set of 408 scans, and a\ntesting set of 408 scans. And compare with existing mainstream classification\nmethods, such as CovNet, CBAM, ResNet, etc. Simultaneously compare the\nvisualization results with visualization methods such as CAM. Model performance\nwas evaluated using the Area Under the ROC Curve(AUC), precision, and F1-score.\nThe NL-RAN achieved the AUC of 0.9903, the precision of 0.9473, and the\nF1-score of 0.9462, surpass all the classification methods compared. The heat\nmap output by the attention module is also clearer than the heat map output by\nCAM. Our experimental results indicate that our proposed method performs\nsignificantly better than existing methods. In addition, the first attention\nmodule outputs a heat map containing detailed outline information to increase\nthe interpretability of the model. Our experiments indicate that the inference\nof our model is fast. It can provide real-time assistance with diagnosis.\n","subjects":["Electrical Engineering and Systems Science/Image and Video Processing","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}