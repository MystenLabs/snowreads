{"id":"2408.10908","title":"Enhancing End-to-End Autonomous Driving Systems Through Synchronized\n  Human Behavior Data","authors":"Yiqun Duan, Zhuoli Zhuang, Jinzhao Zhou, Yu-Cheng Chang, Yu-Kai Wang,\n  Chin-Teng Lin","authorsParsed":[["Duan","Yiqun",""],["Zhuang","Zhuoli",""],["Zhou","Jinzhao",""],["Chang","Yu-Cheng",""],["Wang","Yu-Kai",""],["Lin","Chin-Teng",""]],"versions":[{"version":"v1","created":"Tue, 20 Aug 2024 14:51:51 GMT"}],"updateDate":"2024-08-21","timestamp":1724165511000,"abstract":"  This paper presents a pioneering exploration into the integration of\nfine-grained human supervision within the autonomous driving domain to enhance\nsystem performance. The current advances in End-to-End autonomous driving\nnormally are data-driven and rely on given expert trials. However, this\nreliance limits the systems' generalizability and their ability to earn human\ntrust. Addressing this gap, our research introduces a novel approach by\nsynchronously collecting data from human and machine drivers under identical\ndriving scenarios, focusing on eye-tracking and brainwave data to guide machine\nperception and decision-making processes. This paper utilizes the Carla\nsimulation to evaluate the impact brought by human behavior guidance.\nExperimental results show that using human attention to guide machine attention\ncould bring a significant improvement in driving performance. However, guidance\nby human intention still remains a challenge. This paper pioneers a promising\ndirection and potential for utilizing human behavior guidance to enhance\nautonomous systems.\n","subjects":["Computing Research Repository/Robotics","Computing Research Repository/Human-Computer Interaction"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}