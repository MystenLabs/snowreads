{"id":"2408.14776","title":"MROVSeg: Breaking the Resolution Curse of Vision-Language Models in\n  Open-Vocabulary Semantic Segmentation","authors":"Yuanbing Zhu, Bingke Zhu, Zhen Chen, Huan Xu, Ming Tang, Jinqiao Wang","authorsParsed":[["Zhu","Yuanbing",""],["Zhu","Bingke",""],["Chen","Zhen",""],["Xu","Huan",""],["Tang","Ming",""],["Wang","Jinqiao",""]],"versions":[{"version":"v1","created":"Tue, 27 Aug 2024 04:45:53 GMT"}],"updateDate":"2024-08-28","timestamp":1724733953000,"abstract":"  Open-vocabulary semantic segmentation aims to segment and recognize\nsemantically meaningful regions based on text-based descriptions during\ninference. A typical solution to address this task is to leverage powerful\nvision-language models (VLMs), such as CLIP, to bridge the gap between open-\nand close-vocabulary recognition. As VLMs are usually pretrained with\nlow-resolution images (e.g. $224\\times224$), most previous methods operate only\non downscaled images. We question this design as low resolution features often\nfail to preserve fine details. Although employing additional image backbones\nfor high-resolution inputs can mitigate this issue, it may also introduce\nsignificant computation overhead. Therefore, we propose MROVSeg, a\nmulti-resolution training framework for open-vocabulary semantic segmentation\nwith a single pretrained CLIP backbone, that uses sliding windows to slice the\nhigh-resolution input into uniform patches, each matching the input size of the\nwell-trained image encoder. Its key components include a Multi-Res Adapter,\nwhich restores the spatial geometry and grasps local-global correspondences\nacross patches by learnable convolutional and scale attention layers. To\nachieve accurate segmentation, we introduce Multi-grained Masked Attention\nscheme to aggregate multi-grained semantics by performing cross-attention\nbetween object queries and multi-resolution CLIP features within the region of\ninterests. Through comprehensive experiments, we demonstrate the superiority of\nMROVSeg on well-established open-vocabulary semantic segmentation benchmarks,\nparticularly for high-resolution inputs, establishing new standards for\nopen-vocabulary semantic segmentation.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"zHJ0ZrJZS5sQy5cVFc4cow0PARZYm-eqlmZ5BkFy_eo","pdfSize":"17463244"}
