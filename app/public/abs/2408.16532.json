{"id":"2408.16532","title":"WavTokenizer: an Efficient Acoustic Discrete Codec Tokenizer for Audio\n  Language Modeling","authors":"Shengpeng Ji, Ziyue Jiang, Xize Cheng, Yifu Chen, Minghui Fang,\n  Jialong Zuo, Qian Yang, Ruiqi Li, Ziang Zhang, Xiaoda Yang, Rongjie Huang,\n  Yidi Jiang, Qian Chen, Siqi Zheng, Wen Wang, Zhou Zhao","authorsParsed":[["Ji","Shengpeng",""],["Jiang","Ziyue",""],["Cheng","Xize",""],["Chen","Yifu",""],["Fang","Minghui",""],["Zuo","Jialong",""],["Yang","Qian",""],["Li","Ruiqi",""],["Zhang","Ziang",""],["Yang","Xiaoda",""],["Huang","Rongjie",""],["Jiang","Yidi",""],["Chen","Qian",""],["Zheng","Siqi",""],["Wang","Wen",""],["Zhao","Zhou",""]],"versions":[{"version":"v1","created":"Thu, 29 Aug 2024 13:43:36 GMT"}],"updateDate":"2024-08-30","timestamp":1724939016000,"abstract":"  Language models have been effectively applied to modeling natural signals,\nsuch as images, video, speech, and audio. A crucial component of these models\nis the codec tokenizer, which compresses high-dimensional natural signals into\nlower-dimensional discrete tokens. In this paper, we introduce WavTokenizer,\nwhich offers several advantages over previous SOTA acoustic codec models in the\naudio domain: 1)extreme compression. By compressing the layers of quantizers\nand the temporal dimension of the discrete codec, one-second audio of 24kHz\nsampling rate requires only a single quantizer with 40 or 75 tokens. 2)improved\nsubjective quality. Despite the reduced number of tokens, WavTokenizer achieves\nstate-of-the-art reconstruction quality with outstanding UTMOS scores and\ninherently contains richer semantic information. Specifically, we achieve these\nresults by designing a broader VQ space, extended contextual windows, and\nimproved attention networks, as well as introducing a powerful multi-scale\ndiscriminator and an inverse Fourier transform structure. We conducted\nextensive reconstruction experiments in the domains of speech, audio, and\nmusic. WavTokenizer exhibited strong performance across various objective and\nsubjective metrics compared to state-of-the-art models. We also tested semantic\ninformation, VQ utilization, and adaptability to generative models.\nComprehensive ablation studies confirm the necessity of each module in\nWavTokenizer. The related code, demos, and pre-trained models are available at\nhttps://github.com/jishengpeng/WavTokenizer.\n","subjects":["Electrical Engineering and Systems Science/Audio and Speech Processing","Computing Research Repository/Machine Learning","Computing Research Repository/Multimedia","Computing Research Repository/Sound","Electrical Engineering and Systems Science/Signal Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}