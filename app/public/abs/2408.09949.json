{"id":"2408.09949","title":"C${^2}$RL: Content and Context Representation Learning for Gloss-free\n  Sign Language Translation and Retrieval","authors":"Zhigang Chen and Benjia Zhou and Yiqing Huang and Jun Wan and Yibo Hu\n  and Hailin Shi and Yanyan Liang and Zhen Lei and Du Zhang","authorsParsed":[["Chen","Zhigang",""],["Zhou","Benjia",""],["Huang","Yiqing",""],["Wan","Jun",""],["Hu","Yibo",""],["Shi","Hailin",""],["Liang","Yanyan",""],["Lei","Zhen",""],["Zhang","Du",""]],"versions":[{"version":"v1","created":"Mon, 19 Aug 2024 12:42:10 GMT"}],"updateDate":"2024-08-20","timestamp":1724071330000,"abstract":"  Sign Language Representation Learning (SLRL) is crucial for a range of sign\nlanguage-related downstream tasks such as Sign Language Translation (SLT) and\nSign Language Retrieval (SLRet). Recently, many gloss-based and gloss-free SLRL\nmethods have been proposed, showing promising performance. Among them, the\ngloss-free approach shows promise for strong scalability without relying on\ngloss annotations. However, it currently faces suboptimal solutions due to\nchallenges in encoding the intricate, context-sensitive characteristics of sign\nlanguage videos, mainly struggling to discern essential sign features using a\nnon-monotonic video-text alignment strategy. Therefore, we introduce an\ninnovative pretraining paradigm for gloss-free SLRL, called C${^2}$RL, in this\npaper. Specifically, rather than merely incorporating a non-monotonic semantic\nalignment of video and text to learn language-oriented sign features, we\nemphasize two pivotal aspects of SLRL: Implicit Content Learning (ICL) and\nExplicit Context Learning (ECL). ICL delves into the content of communication,\ncapturing the nuances, emphasis, timing, and rhythm of the signs. In contrast,\nECL focuses on understanding the contextual meaning of signs and converting\nthem into equivalent sentences. Despite its simplicity, extensive experiments\nconfirm that the joint optimization of ICL and ECL results in robust sign\nlanguage representation and significant performance gains in gloss-free SLT and\nSLRet tasks. Notably, C${^2}$RL improves the BLEU-4 score by +5.3 on P14T,\n+10.6 on CSL-daily, +6.2 on OpenASL, and +1.3 on How2Sign. It also boosts the\nR@1 score by +8.3 on P14T, +14.4 on CSL-daily, and +5.9 on How2Sign.\nAdditionally, we set a new baseline for the OpenASL dataset in the SLRet task.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}