{"id":"2407.19523","title":"Robust Fast Adaptation from Adversarially Explicit Task Distribution\n  Generation","authors":"Cheems Wang, Yiqin Lv, Yixiu Mao, Yun Qu, Yi Xu, Xiangyang Ji","authorsParsed":[["Wang","Cheems",""],["Lv","Yiqin",""],["Mao","Yixiu",""],["Qu","Yun",""],["Xu","Yi",""],["Ji","Xiangyang",""]],"versions":[{"version":"v1","created":"Sun, 28 Jul 2024 16:23:55 GMT"}],"updateDate":"2024-07-30","timestamp":1722183835000,"abstract":"  Meta-learning is a practical learning paradigm to transfer skills across\ntasks from a few examples. Nevertheless, the existence of task distribution\nshifts tends to weaken meta-learners' generalization capability, particularly\nwhen the task distribution is naively hand-crafted or based on simple priors\nthat fail to cover typical scenarios sufficiently. Here, we consider explicitly\ngenerative modeling task distributions placed over task identifiers and propose\nrobustifying fast adaptation from adversarial training. Our approach, which can\nbe interpreted as a model of a Stackelberg game, not only uncovers the task\nstructure during problem-solving from an explicit generative model but also\ntheoretically increases the adaptation robustness in worst cases. This work has\npractical implications, particularly in dealing with task distribution shifts\nin meta-learning, and contributes to theoretical insights in the field. Our\nmethod demonstrates its robustness in the presence of task subpopulation shifts\nand improved performance over SOTA baselines in extensive experiments. The\nproject is available at https://sites.google.com/view/ar-metalearn.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}