{"id":"2407.00263","title":"From Local Concepts to Universals: Evaluating the Multicultural\n  Understanding of Vision-Language Models","authors":"Mehar Bhatia, Sahithya Ravi, Aditya Chinchure, Eunjeong Hwang, Vered\n  Shwartz","authorsParsed":[["Bhatia","Mehar",""],["Ravi","Sahithya",""],["Chinchure","Aditya",""],["Hwang","Eunjeong",""],["Shwartz","Vered",""]],"versions":[{"version":"v1","created":"Fri, 28 Jun 2024 23:28:28 GMT"}],"updateDate":"2024-07-02","timestamp":1719617308000,"abstract":"  Despite recent advancements in vision-language models, their performance\nremains suboptimal on images from non-western cultures due to\nunderrepresentation in training datasets. Various benchmarks have been proposed\nto test models' cultural inclusivity, but they have limited coverage of\ncultures and do not adequately assess cultural diversity across universal as\nwell as culture-specific local concepts. To address these limitations, we\nintroduce the GlobalRG benchmark, comprising two challenging tasks: retrieval\nacross universals and cultural visual grounding. The former task entails\nretrieving culturally diverse images for universal concepts from 50 countries,\nwhile the latter aims at grounding culture-specific concepts within images from\n15 countries. Our evaluation across a wide range of models reveals that the\nperformance varies significantly across cultures -- underscoring the necessity\nfor enhancing multicultural understanding in vision-language models.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}