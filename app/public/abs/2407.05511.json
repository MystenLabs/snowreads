{"id":"2407.05511","title":"Provably Efficient Long-Horizon Exploration in Monte Carlo Tree Search\n  through State Occupancy Regularization","authors":"Liam Schramm, Abdeslam Boularias","authorsParsed":[["Schramm","Liam",""],["Boularias","Abdeslam",""]],"versions":[{"version":"v1","created":"Sun, 7 Jul 2024 22:58:52 GMT"}],"updateDate":"2024-07-09","timestamp":1720393132000,"abstract":"  Monte Carlo tree search (MCTS) has been successful in a variety of domains,\nbut faces challenges with long-horizon exploration when compared to\nsampling-based motion planning algorithms like Rapidly-Exploring Random Trees.\nTo address these limitations of MCTS, we derive a tree search algorithm based\non policy optimization with state occupancy measure regularization, which we\ncall {\\it Volume-MCTS}. We show that count-based exploration and sampling-based\nmotion planning can be derived as approximate solutions to this state occupancy\nmeasure regularized objective. We test our method on several robot navigation\nproblems, and find that Volume-MCTS outperforms AlphaZero and displays\nsignificantly better long-horizon exploration properties.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Robotics"],"license":"http://creativecommons.org/licenses/by/4.0/"}