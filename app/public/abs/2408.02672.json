{"id":"2408.02672","title":"Latent-INR: A Flexible Framework for Implicit Representations of Videos\n  with Discriminative Semantics","authors":"Shishira R Maiya, Anubhav Gupta, Matthew Gwilliam, Max Ehrlich,\n  Abhinav Shrivastava","authorsParsed":[["Maiya","Shishira R",""],["Gupta","Anubhav",""],["Gwilliam","Matthew",""],["Ehrlich","Max",""],["Shrivastava","Abhinav",""]],"versions":[{"version":"v1","created":"Mon, 5 Aug 2024 17:59:51 GMT"}],"updateDate":"2024-08-06","timestamp":1722880791000,"abstract":"  Implicit Neural Networks (INRs) have emerged as powerful representations to\nencode all forms of data, including images, videos, audios, and scenes. With\nvideo, many INRs for video have been proposed for the compression task, and\nrecent methods feature significant improvements with respect to encoding time,\nstorage, and reconstruction quality. However, these encoded representations\nlack semantic meaning, so they cannot be used for any downstream tasks that\nrequire such properties, such as retrieval. This can act as a barrier for\nadoption of video INRs over traditional codecs as they do not offer any\nsignificant edge apart from compression. To alleviate this, we propose a\nflexible framework that decouples the spatial and temporal aspects of the video\nINR. We accomplish this with a dictionary of per-frame latents that are learned\njointly with a set of video specific hypernetworks, such that given a latent,\nthese hypernetworks can predict the INR weights to reconstruct the given frame.\nThis framework not only retains the compression efficiency, but the learned\nlatents can be aligned with features from large vision models, which grants\nthem discriminative properties. We align these latents with CLIP and show good\nperformance for both compression and video retrieval tasks. By aligning with\nVideoLlama, we are able to perform open-ended chat with our learned latents as\nthe visual inputs. Additionally, the learned latents serve as a proxy for the\nunderlying weights, allowing us perform tasks like video interpolation. These\nsemantic properties and applications, existing simultaneously with ability to\nperform compression, interpolation, and superresolution properties, are a first\nin this field of work.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}