{"id":"2408.12787","title":"LLM-PBE: Assessing Data Privacy in Large Language Models","authors":"Qinbin Li, Junyuan Hong, Chulin Xie, Jeffrey Tan, Rachel Xin, Junyi\n  Hou, Xavier Yin, Zhun Wang, Dan Hendrycks, Zhangyang Wang, Bo Li, Bingsheng\n  He, Dawn Song","authorsParsed":[["Li","Qinbin",""],["Hong","Junyuan",""],["Xie","Chulin",""],["Tan","Jeffrey",""],["Xin","Rachel",""],["Hou","Junyi",""],["Yin","Xavier",""],["Wang","Zhun",""],["Hendrycks","Dan",""],["Wang","Zhangyang",""],["Li","Bo",""],["He","Bingsheng",""],["Song","Dawn",""]],"versions":[{"version":"v1","created":"Fri, 23 Aug 2024 01:37:29 GMT"},{"version":"v2","created":"Fri, 6 Sep 2024 04:30:50 GMT"}],"updateDate":"2024-09-09","timestamp":1724377049000,"abstract":"  Large Language Models (LLMs) have become integral to numerous domains,\nsignificantly advancing applications in data management, mining, and analysis.\nTheir profound capabilities in processing and interpreting complex language\ndata, however, bring to light pressing concerns regarding data privacy,\nespecially the risk of unintentional training data leakage. Despite the\ncritical nature of this issue, there has been no existing literature to offer a\ncomprehensive assessment of data privacy risks in LLMs. Addressing this gap,\nour paper introduces LLM-PBE, a toolkit crafted specifically for the systematic\nevaluation of data privacy risks in LLMs. LLM-PBE is designed to analyze\nprivacy across the entire lifecycle of LLMs, incorporating diverse attack and\ndefense strategies, and handling various data types and metrics. Through\ndetailed experimentation with multiple LLMs, LLM-PBE facilitates an in-depth\nexploration of data privacy concerns, shedding light on influential factors\nsuch as model size, data characteristics, and evolving temporal dimensions.\nThis study not only enriches the understanding of privacy issues in LLMs but\nalso serves as a vital resource for future research in the field. Aimed at\nenhancing the breadth of knowledge in this area, the findings, resources, and\nour full technical report are made available at https://llm-pbe.github.io/,\nproviding an open platform for academic and practical advancements in LLM\nprivacy assessment.\n","subjects":["Computing Research Repository/Cryptography and Security","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}