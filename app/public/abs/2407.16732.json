{"id":"2407.16732","title":"PyBench: Evaluating LLM Agent on various real-world coding tasks","authors":"Yaolun Zhang, Yinxu Pan, Yudong Wang, Jie Cai","authorsParsed":[["Zhang","Yaolun",""],["Pan","Yinxu",""],["Wang","Yudong",""],["Cai","Jie",""]],"versions":[{"version":"v1","created":"Tue, 23 Jul 2024 15:23:14 GMT"},{"version":"v2","created":"Sat, 3 Aug 2024 03:00:43 GMT"}],"updateDate":"2024-08-06","timestamp":1721748194000,"abstract":"  The LLM Agent, equipped with a code interpreter, is capable of automatically\nsolving real-world coding tasks, such as data analysis and image editing.\n  However, existing benchmarks primarily focus on either simplistic tasks, such\nas completing a few lines of code, or on extremely complex and specific tasks\nat the repository level, neither of which are representative of various daily\ncoding tasks.\n  To address this gap, we introduce \\textbf{PyBench}, a benchmark encompassing\nfive main categories of real-world tasks, covering more than 10 types of files.\nGiven a high-level user query and related files, the LLM Agent needs to reason\nand execute Python code via a code interpreter for a few turns before making a\nformal response to fulfill the user's requirements. Successfully addressing\ntasks in PyBench demands a robust understanding of various Python packages,\nsuperior reasoning capabilities, and the ability to incorporate feedback from\nexecuted code. Our evaluations indicate that current open-source LLMs are\nstruggling with these tasks. Hence, we conduct analysis and experiments on four\nkinds of datasets proving that comprehensive abilities are needed for PyBench.\nOur fine-tuned 8B size model: \\textbf{PyLlama3} achieves an exciting\nperformance on PyBench which surpasses many 33B and 70B size models. Our\nBenchmark, Training Dataset, and Model are available at:\n{https://github.com/Mercury7353/PyBench}\n","subjects":["Computing Research Repository/Software Engineering","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}