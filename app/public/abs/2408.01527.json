{"id":"2408.01527","title":"Using LLMs to Establish Implicit User Sentiment of Software Desirability","authors":"Sherri Weitl-Harms, John D. Hastings, Jonah Lum","authorsParsed":[["Weitl-Harms","Sherri",""],["Hastings","John D.",""],["Lum","Jonah",""]],"versions":[{"version":"v1","created":"Fri, 2 Aug 2024 18:40:10 GMT"},{"version":"v2","created":"Sun, 8 Sep 2024 19:59:06 GMT"}],"updateDate":"2024-09-10","timestamp":1722624010000,"abstract":"  This study explores the use of LLMs for providing quantitative zero-shot\nsentiment analysis of implicit software desirability, addressing a critical\nchallenge in product evaluation where traditional review scores, though\nconvenient, fail to capture the richness of qualitative user feedback.\nInnovations include establishing a method that 1) works with qualitative user\nexperience data without the need for explicit review scores, 2) focuses on\nimplicit user satisfaction, and 3) provides scaled numerical sentiment\nanalysis, offering a more nuanced understanding of user sentiment, instead of\nsimply classifying sentiment as positive, neutral, or negative.\n  Data is collected using the Microsoft Product Desirability Toolkit (PDT), a\nwell-known qualitative user experience analysis tool. For initial exploration,\nthe PDT metric was given to users of two software systems. PDT data was fed\nthrough several LLMs (Claude Sonnet 3 and 3.5, GPT4, and GPT4o) and through a\nleading transfer learning technique, Twitter-Roberta-Base-Sentiment, and Vader,\na leading sentiment analysis tool. Each system was asked to evaluate the data\nin two ways, by looking at the sentiment expressed in the PDT word/explanation\npairs; and by looking at the sentiment expressed by the users in their grouped\nselection of five words and explanations, as a whole. Each LLM provided a\nsentiment score, its confidence (low, medium, high) in the score, and an\nexplanation of the score.\n  All LLMs tested were able to statistically detect user sentiment from the\nusers' grouped data, whereas TRBS and Vader were not. The confidence and\nexplanation of confidence provided by the LLMs assisted in understanding user\nsentiment. This study adds deeper understanding of evaluating user experiences,\ntoward the goal of creating a universal tool that quantifies implicit\nsentiment.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Human-Computer Interaction","Computing Research Repository/Machine Learning","Computing Research Repository/Software Engineering"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}