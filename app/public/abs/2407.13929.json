{"id":"2407.13929","title":"Unmasking Social Bots: How Confident Are We?","authors":"James Giroux, Ariyarathne Gangani, Alexander C. Nwala, Cristiano\n  Fanelli","authorsParsed":[["Giroux","James",""],["Gangani","Ariyarathne",""],["Nwala","Alexander C.",""],["Fanelli","Cristiano",""]],"versions":[{"version":"v1","created":"Thu, 18 Jul 2024 22:33:52 GMT"}],"updateDate":"2024-07-22","timestamp":1721342032000,"abstract":"  Social bots remain a major vector for spreading disinformation on social\nmedia and a menace to the public. Despite the progress made in developing\nmultiple sophisticated social bot detection algorithms and tools, bot detection\nremains a challenging, unsolved problem that is fraught with uncertainty due to\nthe heterogeneity of bot behaviors, training data, and detection algorithms.\nDetection models often disagree on whether to label the same account as bot or\nhuman-controlled. However, they do not provide any measure of uncertainty to\nindicate how much we should trust their results. We propose to address both bot\ndetection and the quantification of uncertainty at the account level - a novel\nfeature of this research. This dual focus is crucial as it allows us to\nleverage additional information related to the quantified uncertainty of each\nprediction, thereby enhancing decision-making and improving the reliability of\nbot classifications. Specifically, our approach facilitates targeted\ninterventions for bots when predictions are made with high confidence and\nsuggests caution (e.g., gathering more data) when predictions are uncertain.\n","subjects":["Computing Research Repository/Social and Information Networks","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}