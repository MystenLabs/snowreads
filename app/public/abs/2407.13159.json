{"id":"2407.13159","title":"Attenuation-Aware Weighted Optical Flow with Medium Transmission Map for\n  Learning-based Visual Odometry in Underwater terrain","authors":"Bach Nguyen Gia, Chanh Minh Tran, Kamioka Eiji, Tan Phan Xuan","authorsParsed":[["Gia","Bach Nguyen",""],["Tran","Chanh Minh",""],["Eiji","Kamioka",""],["Xuan","Tan Phan",""]],"versions":[{"version":"v1","created":"Thu, 18 Jul 2024 05:00:15 GMT"}],"updateDate":"2024-07-19","timestamp":1721278815000,"abstract":"  This paper addresses the challenge of improving learning-based monocular\nvisual odometry (VO) in underwater environments by integrating principles of\nunderwater optical imaging to manipulate optical flow estimation. Leveraging\nthe inherent properties of underwater imaging, the novel wflow-TartanVO is\nintroduced, enhancing the accuracy of VO systems for autonomous underwater\nvehicles (AUVs). The proposed method utilizes a normalized medium transmission\nmap as a weight map to adjust the estimated optical flow for emphasizing\nregions with lower degradation and suppressing uncertain regions affected by\nunderwater light scattering and absorption. wflow-TartanVO does not require\nfine-tuning of pre-trained VO models, thus promoting its adaptability to\ndifferent environments and camera models. Evaluation of different real-world\nunderwater datasets demonstrates the outperformance of wflow-TartanVO over\nbaseline VO methods, as evidenced by the considerably reduced Absolute\nTrajectory Error (ATE). The implementation code is available at:\nhttps://github.com/bachzz/wflow-TartanVO\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"BnW573b3inG_uJRXlUocon2qGnW6dfQtNJTbmsTnBJM","pdfSize":"1537643"}
