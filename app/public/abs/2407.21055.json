{"id":"2407.21055","title":"Bailicai: A Domain-Optimized Retrieval-Augmented Generation Framework\n  for Medical Applications","authors":"Cui Long, Yongbin Liu, Chunping Ouyang, Ying Yu","authorsParsed":[["Long","Cui",""],["Liu","Yongbin",""],["Ouyang","Chunping",""],["Yu","Ying",""]],"versions":[{"version":"v1","created":"Wed, 24 Jul 2024 12:27:33 GMT"}],"updateDate":"2024-08-01","timestamp":1721824053000,"abstract":"  Large Language Models (LLMs) have exhibited remarkable proficiency in natural\nlanguage understanding, prompting extensive exploration of their potential\napplications across diverse domains. In the medical domain, open-source LLMs\nhave demonstrated moderate efficacy following domain-specific fine-tuning;\nhowever, they remain substantially inferior to proprietary models such as GPT-4\nand GPT-3.5. These open-source models encounter limitations in the\ncomprehensiveness of domain-specific knowledge and exhibit a propensity for\n'hallucinations' during text generation. To mitigate these issues, researchers\nhave implemented the Retrieval-Augmented Generation (RAG) approach, which\naugments LLMs with background information from external knowledge bases while\npreserving the model's internal parameters. However, document noise can\nadversely affect performance, and the application of RAG in the medical field\nremains in its nascent stages. This study presents the Bailicai framework: a\nnovel integration of retrieval-augmented generation with large language models\noptimized for the medical domain. The Bailicai framework augments the\nperformance of LLMs in medicine through the implementation of four sub-modules.\nExperimental results demonstrate that the Bailicai approach surpasses existing\nmedical domain LLMs across multiple medical benchmarks and exceeds the\nperformance of GPT-3.5. Furthermore, the Bailicai method effectively attenuates\nthe prevalent issue of hallucinations in medical applications of LLMs and\nameliorates the noise-related challenges associated with traditional RAG\ntechniques when processing irrelevant or pseudo-relevant documents.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}