{"id":"2408.02053","title":"PanicleNeRF: low-cost, high-precision in-field phenotypingof rice\n  panicles with smartphone","authors":"Xin Yang (1 and 2), Xuqi Lu (1 and 2), Pengyao Xie (1 and 2), Ziyue\n  Guo (1 and 2), Hui Fang (1), Haowei Fu (3), Xiaochun Hu (4), Zhenbiao Sun\n  (4), Haiyan Cen (1 and 2) ((1) College of Biosystems Engineering and Food\n  Science, Zhejiang University, (2) Key Laboratory of Spectroscopy Sensing,\n  Ministry of Agriculture and Rural Affairs, (3) Jiaxing Academy of\n  Agricultural Science, (4) Yuan Longping High-Tech Agriculture Co., Ltd)","authorsParsed":[["Yang","Xin","","1 and 2"],["Lu","Xuqi","","1 and 2"],["Xie","Pengyao","","1 and 2"],["Guo","Ziyue","","1 and 2"],["Fang","Hui","","1 and 2"],["Fu","Haowei","","1 and 2"],["Hu","Xiaochun","","1 and 2"],["Sun","Zhenbiao","","1 and 2"],["Cen","Haiyan","","1 and 2"]],"versions":[{"version":"v1","created":"Sun, 4 Aug 2024 15:01:16 GMT"}],"updateDate":"2024-08-06","timestamp":1722783676000,"abstract":"  The rice panicle traits significantly influence grain yield, making them a\nprimary target for rice phenotyping studies. However, most existing techniques\nare limited to controlled indoor environments and difficult to capture the rice\npanicle traits under natural growth conditions. Here, we developed PanicleNeRF,\na novel method that enables high-precision and low-cost reconstruction of rice\npanicle three-dimensional (3D) models in the field using smartphone. The\nproposed method combined the large model Segment Anything Model (SAM) and the\nsmall model You Only Look Once version 8 (YOLOv8) to achieve high-precision\nsegmentation of rice panicle images. The NeRF technique was then employed for\n3D reconstruction using the images with 2D segmentation. Finally, the resulting\npoint clouds are processed to successfully extract panicle traits. The results\nshow that PanicleNeRF effectively addressed the 2D image segmentation task,\nachieving a mean F1 Score of 86.9% and a mean Intersection over Union (IoU) of\n79.8%, with nearly double the boundary overlap (BO) performance compared to\nYOLOv8. As for point cloud quality, PanicleNeRF significantly outperformed\ntraditional SfM-MVS (structure-from-motion and multi-view stereo) methods, such\nas COLMAP and Metashape. The panicle length was then accurately extracted with\nthe rRMSE of 2.94% for indica and 1.75% for japonica rice. The panicle volume\nestimated from 3D point clouds strongly correlated with the grain number (R2 =\n0.85 for indica and 0.82 for japonica) and grain mass (0.80 for indica and 0.76\nfor japonica). This method provides a low-cost solution for high-throughput\nin-field phenotyping of rice panicles, accelerating the efficiency of rice\nbreeding.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}