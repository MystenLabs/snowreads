{"id":"2408.10527","title":"EdgeNAT: Transformer for Efficient Edge Detection","authors":"Jinghuai Jie, Yan Guo, Guixing Wu, Junmin Wu, Baojian Hua","authorsParsed":[["Jie","Jinghuai",""],["Guo","Yan",""],["Wu","Guixing",""],["Wu","Junmin",""],["Hua","Baojian",""]],"versions":[{"version":"v1","created":"Tue, 20 Aug 2024 04:04:22 GMT"}],"updateDate":"2024-08-21","timestamp":1724126662000,"abstract":"  Transformers, renowned for their powerful feature extraction capabilities,\nhave played an increasingly prominent role in various vision tasks. Especially,\nrecent advancements present transformer with hierarchical structures such as\nDilated Neighborhood Attention Transformer (DiNAT), demonstrating outstanding\nability to efficiently capture both global and local features. However,\ntransformers' application in edge detection has not been fully exploited. In\nthis paper, we propose EdgeNAT, a one-stage transformer-based edge detector\nwith DiNAT as the encoder, capable of extracting object boundaries and\nmeaningful edges both accurately and efficiently. On the one hand, EdgeNAT\ncaptures global contextual information and detailed local cues with DiNAT, on\nthe other hand, it enhances feature representation with a novel SCAF-MLA\ndecoder by utilizing both inter-spatial and inter-channel relationships of\nfeature maps. Extensive experiments on multiple datasets show that our method\nachieves state-of-the-art performance on both RGB and depth images. Notably, on\nthe widely used BSDS500 dataset, our L model achieves impressive performances,\nwith ODS F-measure and OIS F-measure of 86.0%, 87.6% for multi-scale input,and\n84.9%, and 86.3% for single-scale input, surpassing the current\nstate-of-the-art EDTER by 1.2%, 1.1%, 1.7%, and 1.6%, respectively. Moreover,\nas for throughput, our approach runs at 20.87 FPS on RTX 4090 GPU with\nsingle-scale input. The code for our method will be released soon.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}