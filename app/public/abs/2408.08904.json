{"id":"2408.08904","title":"Privacy in Federated Learning","authors":"Jaydip Sen, Hetvi Waghela, Sneha Rakshit","authorsParsed":[["Sen","Jaydip",""],["Waghela","Hetvi",""],["Rakshit","Sneha",""]],"versions":[{"version":"v1","created":"Mon, 12 Aug 2024 18:41:58 GMT"}],"updateDate":"2024-08-20","timestamp":1723488118000,"abstract":"  Federated Learning (FL) represents a significant advancement in distributed\nmachine learning, enabling multiple participants to collaboratively train\nmodels without sharing raw data. This decentralized approach enhances privacy\nby keeping data on local devices. However, FL introduces new privacy\nchallenges, as model updates shared during training can inadvertently leak\nsensitive information. This chapter delves into the core privacy concerns\nwithin FL, including the risks of data reconstruction, model inversion attacks,\nand membership inference. It explores various privacy-preserving techniques,\nsuch as Differential Privacy (DP) and Secure Multi-Party Computation (SMPC),\nwhich are designed to mitigate these risks. The chapter also examines the\ntrade-offs between model accuracy and privacy, emphasizing the importance of\nbalancing these factors in practical implementations. Furthermore, it discusses\nthe role of regulatory frameworks, such as GDPR, in shaping the privacy\nstandards for FL. By providing a comprehensive overview of the current state of\nprivacy in FL, this chapter aims to equip researchers and practitioners with\nthe knowledge necessary to navigate the complexities of secure federated\nlearning environments. The discussion highlights both the potential and\nlimitations of existing privacy-enhancing techniques, offering insights into\nfuture research directions and the development of more robust solutions.\n","subjects":["Computing Research Repository/Cryptography and Security"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}