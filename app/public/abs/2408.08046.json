{"id":"2408.08046","title":"Optimal control problems with generalized mean-field dynamics and\n  viscosity solution to Master Bellman equation","authors":"Rainer Buckdahn, Juan Li and Zhanxin Li","authorsParsed":[["Buckdahn","Rainer",""],["Li","Juan",""],["Li","Zhanxin",""]],"versions":[{"version":"v1","created":"Thu, 15 Aug 2024 09:25:32 GMT"}],"updateDate":"2024-08-16","timestamp":1723713932000,"abstract":"  We study an optimal control problem of generalized mean-field dynamics with\nopen-loop controls, where the coefficients depend not only on the state\nprocesses and controls, but also on the joint law of them. The value function\n$V$ defined in a conventional way, but it does not satisfy the Dynamic\nProgramming Principle (DPP for short). For this reason we introduce subtly a\nnovel value function $\\vartheta$, which is closely related to the original\nvalue function $V$, such that, a description of $\\vartheta$, as a solution of a\npartial differential equation (PDE), also characterizes $V$. We establish the\nDPP for $\\vartheta$. By using an intrinsic notion of viscosity solutions,\ninitially introduced in Burzoni, Ignazio, Reppen and Soner [8] and specifically\ntailored to our framework, we show that the value function $\\vartheta$ is a\nviscosity solution to a Master Bellman equation on a subset of Wasserstein\nspace of probability measures. The uniqueness of viscosity solution is proved\nfor coefficients which depend on the time and the joint law of the control\nprocess and the controlled process. Our approach is inspired by Buckdahn, Li,\nPeng and Rainer [7], and leads to a generalization of the mean-field PDE in [7]\nto a Master Bellman equation in the case of controls.\n","subjects":["Mathematics/Optimization and Control","Mathematics/Probability"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"rMqg2bkqBk2eFygHI1nvteoiGvBMfM_fDZ32n37HUSI","pdfSize":"398890"}
