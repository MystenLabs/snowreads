{"id":"2407.12861","title":"CiteME: Can Language Models Accurately Cite Scientific Claims?","authors":"Ori Press, Andreas Hochlehnert, Ameya Prabhu, Vishaal Udandarao, Ofir\n  Press, Matthias Bethge","authorsParsed":[["Press","Ori",""],["Hochlehnert","Andreas",""],["Prabhu","Ameya",""],["Udandarao","Vishaal",""],["Press","Ofir",""],["Bethge","Matthias",""]],"versions":[{"version":"v1","created":"Wed, 10 Jul 2024 11:31:20 GMT"}],"updateDate":"2024-07-19","timestamp":1720611080000,"abstract":"  Thousands of new scientific papers are published each month. Such information\noverload complicates researcher efforts to stay current with the\nstate-of-the-art as well as to verify and correctly attribute claims. We pose\nthe following research question: Given a text excerpt referencing a paper,\ncould an LM act as a research assistant to correctly identify the referenced\npaper? We advance efforts to answer this question by building a benchmark that\nevaluates the abilities of LMs in citation attribution. Our benchmark, CiteME,\nconsists of text excerpts from recent machine learning papers, each referencing\na single other paper. CiteME use reveals a large gap between frontier LMs and\nhuman performance, with LMs achieving only 4.2-18.5% accuracy and humans 69.7%.\nWe close this gap by introducing CiteAgent, an autonomous system built on the\nGPT-4o LM that can also search and read papers, which achieves an accuracy of\n35.3\\% on CiteME. Overall, CiteME serves as a challenging testbed for\nopen-ended claim attribution, driving the research community towards a future\nwhere any claim made by an LM can be automatically verified and discarded if\nfound to be incorrect.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Human-Computer Interaction"],"license":"http://creativecommons.org/licenses/by/4.0/"}