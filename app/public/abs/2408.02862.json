{"id":"2408.02862","title":"On The Stability of Moral Preferences: A Problem with Computational\n  Elicitation Methods","authors":"Kyle Boerstler, Vijay Keswani, Lok Chan, Jana Schaich Borg, Vincent\n  Conitzer, Hoda Heidari, and Walter Sinnott-Armstrong","authorsParsed":[["Boerstler","Kyle",""],["Keswani","Vijay",""],["Chan","Lok",""],["Borg","Jana Schaich",""],["Conitzer","Vincent",""],["Heidari","Hoda",""],["Sinnott-Armstrong","Walter",""]],"versions":[{"version":"v1","created":"Mon, 5 Aug 2024 23:20:47 GMT"}],"updateDate":"2024-08-07","timestamp":1722900047000,"abstract":"  Preference elicitation frameworks feature heavily in the research on\nparticipatory ethical AI tools and provide a viable mechanism to enquire and\nincorporate the moral values of various stakeholders. As part of the\nelicitation process, surveys about moral preferences, opinions, and judgments\nare typically administered only once to each participant. This methodological\npractice is reasonable if participants' responses are stable over time such\nthat, all other relevant factors being held constant, their responses today\nwill be the same as their responses to the same questions at a later time.\nHowever, we do not know how often that is the case. It is possible that\nparticipants' true moral preferences change, are subject to temporary moods or\nwhims, or are influenced by environmental factors we don't track. If\nparticipants' moral responses are unstable in such ways, it would raise\nimportant methodological and theoretical issues for how participants' true\nmoral preferences, opinions, and judgments can be ascertained. We address this\npossibility here by asking the same survey participants the same moral\nquestions about which patient should receive a kidney when only one is\navailable ten times in ten different sessions over two weeks, varying only\npresentation order across sessions. We measured how often participants gave\ndifferent responses to simple (Study One) and more complicated (Study Two)\nrepeated scenarios. On average, the fraction of times participants changed\ntheir responses to controversial scenarios was around 10-18% across studies,\nand this instability is observed to have positive associations with response\ntime and decision-making difficulty. We discuss the implications of these\nresults for the efficacy of moral preference elicitation, highlighting the role\nof response instability in causing value misalignment between stakeholders and\nAI tools trained on their moral judgments.\n","subjects":["Computing Research Repository/Computers and Society","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Human-Computer Interaction"],"license":"http://creativecommons.org/licenses/by/4.0/"}