{"id":"2407.15219","title":"Efficient Visual Transformer by Learnable Token Merging","authors":"Yancheng Wang, Yingzhen Yang","authorsParsed":[["Wang","Yancheng",""],["Yang","Yingzhen",""]],"versions":[{"version":"v1","created":"Sun, 21 Jul 2024 17:09:19 GMT"}],"updateDate":"2024-07-23","timestamp":1721581759000,"abstract":"  Self-attention and transformers have been widely used in deep learning.\nRecent efforts have been devoted to incorporating transformer blocks into\ndifferent neural architectures, including those with convolutions, leading to\nvarious visual transformers for computer vision tasks. In this paper, we\npropose a novel and compact transformer block, Transformer with Learnable Token\nMerging (LTM), or LTM-Transformer. LTM-Transformer performs token merging in a\nlearnable scheme. LTM-Transformer is compatible with many popular and compact\ntransformer networks, and it reduces the FLOPs and the inference time of the\nvisual transformers while maintaining or even improving the prediction\naccuracy. In the experiments, we replace all the transformer blocks in popular\nvisual transformers, including MobileViT, EfficientViT, ViT-S/16, and Swin-T,\nwith LTM-Transformer blocks, leading to LTM-Transformer networks with different\nbackbones. The LTM-Transformer is motivated by reduction of Information\nBottleneck, and a novel and separable variational upper bound for the IB loss\nis derived. The architecture of mask module in our LTM blocks which generate\nthe token merging mask is designed to reduce the derived upper bound for the IB\nloss. Extensive results on computer vision tasks evidence that LTM-Transformer\nrenders compact and efficient visual transformers with comparable or much\nbetter prediction accuracy than the original visual transformers. The code of\nthe LTM-Transformer is available at\n\\url{https://github.com/Statistical-Deep-Learning/LTM}.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}