{"id":"2408.09539","title":"Byzantine-resilient Federated Learning Employing Normalized Gradients on\n  Non-IID Datasets","authors":"Shiyuan Zuo, Xingrun Yan, Rongfei Fan, Li Shen, Puning Zhao, Jie Xu,\n  Han Hu","authorsParsed":[["Zuo","Shiyuan",""],["Yan","Xingrun",""],["Fan","Rongfei",""],["Shen","Li",""],["Zhao","Puning",""],["Xu","Jie",""],["Hu","Han",""]],"versions":[{"version":"v1","created":"Sun, 18 Aug 2024 16:50:39 GMT"}],"updateDate":"2024-08-20","timestamp":1723999839000,"abstract":"  In practical federated learning (FL) systems, the presence of malicious\nByzantine attacks and data heterogeneity often introduces biases into the\nlearning process. However, existing Byzantine-robust methods typically only\nachieve a compromise between adaptability to different loss function types\n(including both strongly convex and non-convex) and robustness to heterogeneous\ndatasets, but with non-zero optimality gap. Moreover, this compromise often\ncomes at the cost of high computational complexity for aggregation, which\nsignificantly slows down the training speed. To address this challenge, we\npropose a federated learning approach called Federated Normalized Gradients\nAlgorithm (Fed-NGA). Fed-NGA simply normalizes the uploaded local gradients to\nbe unit vectors before aggregation, achieving a time complexity of\n$\\mathcal{O}(pM)$, where $p$ represents the dimension of model parameters and\n$M$ is the number of participating clients. This complexity scale achieves the\nbest level among all the existing Byzantine-robust methods. Furthermore,\nthrough rigorous proof, we demonstrate that Fed-NGA transcends the trade-off\nbetween adaptability to loss function type and data heterogeneity and the\nlimitation of non-zero optimality gap in existing literature. Specifically,\nFed-NGA can adapt to both non-convex loss functions and non-IID datasets\nsimultaneously, with zero optimality gap at a rate of $\\mathcal{O}\n(1/T^{\\frac{1}{2} - \\delta})$, where T is the iteration number and $\\delta \\in\n(0,\\frac{1}{2})$. In cases where the loss function is strongly convex, the zero\noptimality gap achieving rate can be improved to be linear. Experimental\nresults provide evidence of the superiority of our proposed Fed-NGA on time\ncomplexity and convergence performance over baseline methods.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Distributed, Parallel, and Cluster Computing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}