{"id":"2407.01475","title":"Exploring FPGA designs for MX and beyond","authors":"Ebby Samson, Naveen Mellempudi, Wayne Luk, George A. Constantinides","authorsParsed":[["Samson","Ebby",""],["Mellempudi","Naveen",""],["Luk","Wayne",""],["Constantinides","George A.",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 17:07:33 GMT"}],"updateDate":"2024-07-02","timestamp":1719853653000,"abstract":"  A number of companies recently worked together to release the new Open\nCompute Project MX standard for low-precision computation, aimed at efficient\nneural network implementation. In this paper, we describe and evaluate the\nfirst open-source FPGA implementation of the arithmetic defined in the\nstandard. Our designs fully support all the standard's concrete formats for\nconversion into and out of MX formats and for the standard-defined arithmetic\noperations, as well as arbitrary fixed-point and floating-point formats.\nCertain elements of the standard are left as implementation-defined, and we\npresent the first concrete FPGA-inspired choices for these elements, which we\noutline in the paper. Our library of optimized hardware components is available\nopen source, and can be used to build larger systems. For this purpose, we also\ndescribe and release an open-source Pytorch library for quantization into the\nnew standard, integrated with the Brevitas library so that the community can\ndevelop novel neural network designs quantized with MX formats in mind. We\ndemonstrate the usability and efficacy of our libraries via the implementation\nof example neural networks such as ResNet-18 on the ImageNet ILSVRC12 dataset.\nOur testing shows that MX is very effective for formats such as INT5 or FP6\nwhich are not natively supported on GPUs. This gives FPGAs an advantage as they\nhave the flexibility to implement a custom datapath and take advantage of the\nsmaller area footprints offered by these formats.\n","subjects":["Computing Research Repository/Hardware Architecture","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"85gUHzopWiUpff3NI9aF2hWybUzj14V4RyKJrMQWJGQ","pdfSize":"543599"}
