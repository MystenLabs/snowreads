{"id":"2408.15602","title":"On the Benefits of Visual Stabilization for Frame- and Event-based\n  Perception","authors":"Juan Pablo Rodriguez-Gomez and Jose Ramiro Martinez-de Dios and Anibal\n  Ollero and Guillermo Gallego","authorsParsed":[["Rodriguez-Gomez","Juan Pablo",""],["Dios","Jose Ramiro Martinez-de",""],["Ollero","Anibal",""],["Gallego","Guillermo",""]],"versions":[{"version":"v1","created":"Wed, 28 Aug 2024 07:49:30 GMT"}],"updateDate":"2024-08-29","timestamp":1724831370000,"abstract":"  Vision-based perception systems are typically exposed to large orientation\nchanges in different robot applications. In such conditions, their performance\nmight be compromised due to the inherent complexity of processing data captured\nunder challenging motion. Integration of mechanical stabilizers to compensate\nfor the camera rotation is not always possible due to the robot payload\nconstraints. This paper presents a processing-based stabilization approach to\ncompensate the camera's rotational motion both on events and on frames (i.e.,\nimages). Assuming that the camera's attitude is available, we evaluate the\nbenefits of stabilization in two perception applications: feature tracking and\nestimating the translation component of the camera's ego-motion. The validation\nis performed using synthetic data and sequences from well-known event-based\nvision datasets. The experiments unveil that stabilization can improve feature\ntracking and camera ego-motion estimation accuracy in 27.37% and 34.82%,\nrespectively. Concurrently, stabilization can reduce the processing time of\ncomputing the camera's linear velocity by at least 25%. Code is available at\nhttps://github.com/tub-rip/visual_stabilization\n","subjects":["Computing Research Repository/Robotics","Computing Research Repository/Computer Vision and Pattern Recognition","Electrical Engineering and Systems Science/Image and Video Processing"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/"}