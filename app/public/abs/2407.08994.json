{"id":"2407.08994","title":"Global Attention-Guided Dual-Domain Point Cloud Feature Learning for\n  Classification and Segmentation","authors":"Zihao Li, Pan Gao, Kang You, Chuan Yan, Manoranjan Paul","authorsParsed":[["Li","Zihao",""],["Gao","Pan",""],["You","Kang",""],["Yan","Chuan",""],["Paul","Manoranjan",""]],"versions":[{"version":"v1","created":"Fri, 12 Jul 2024 05:19:19 GMT"}],"updateDate":"2024-07-15","timestamp":1720761559000,"abstract":"  Previous studies have demonstrated the effectiveness of point-based neural\nmodels on the point cloud analysis task. However, there remains a crucial issue\non producing the efficient input embedding for raw point coordinates. Moreover,\nanother issue lies in the limited efficiency of neighboring aggregations, which\nis a critical component in the network stem. In this paper, we propose a Global\nAttention-guided Dual-domain Feature Learning network (GAD) to address the\nabove-mentioned issues. We first devise the Contextual Position-enhanced\nTransformer (CPT) module, which is armed with an improved global attention\nmechanism, to produce a global-aware input embedding that serves as the\nguidance to subsequent aggregations. Then, the Dual-domain K-nearest neighbor\nFeature Fusion (DKFF) is cascaded to conduct effective feature aggregation\nthrough novel dual-domain feature learning which appreciates both local\ngeometric relations and long-distance semantic connections. Extensive\nexperiments on multiple point cloud analysis tasks (e.g., classification, part\nsegmentation, and scene semantic segmentation) demonstrate the superior\nperformance of the proposed method and the efficacy of the devised modules.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}