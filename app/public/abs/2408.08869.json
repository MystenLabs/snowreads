{"id":"2408.08869","title":"PEDAL: Enhancing Greedy Decoding with Large Language Models using\n  Diverse Exemplars","authors":"Sumanth Prabhu","authorsParsed":[["Prabhu","Sumanth",""]],"versions":[{"version":"v1","created":"Fri, 16 Aug 2024 17:54:09 GMT"},{"version":"v2","created":"Mon, 19 Aug 2024 04:29:34 GMT"}],"updateDate":"2024-08-20","timestamp":1723830849000,"abstract":"  Self-ensembling techniques with diverse reasoning paths such as\nSelf-Consistency have demonstrated remarkable performance gains in text\ngeneration with Large Language Models (LLMs). However, such techniques depend\non the availability of an accurate answer extraction process to aggregate\nacross multiple outputs. Moreover, they acquire higher inference cost, in\ncomparison to Greedy Decoding, due to generation of relatively higher number of\noutput tokens. Research has shown that the free form text outputs from\nSelf-Consistency can be aggregated reliably using LLMs to produce the final\noutput. Additionally, recent advancements in LLM inference have demonstrated\nthat usage of diverse exemplars in prompts have the ability to induce diversity\nin the LLM outputs. Such proven techniques can be easily extended to\nself-ensembling based approaches to achieve enhanced results in text\ngeneration. In this paper, we introduce PEDAL (Prompts based on Exemplar\nDiversity Aggregated using LLMs), a hybrid self-ensembling approach, that\ncombines the strengths of diverse exemplar based prompts and LLM based\naggregation to achieve improvement in overall performance. On the publicly\navailable SVAMP and ARC datasets, our experiments reveal that PEDAL can achieve\nbetter accuracy than Greedy Decoding based strategies with lower inference cost\ncompared to Self Consistency based approaches.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}