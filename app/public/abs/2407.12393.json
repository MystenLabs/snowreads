{"id":"2407.12393","title":"PersLLM: A Personified Training Approach for Large Language Models","authors":"Zheni Zeng, Jiayi Chen, Huimin Chen, Yukun Yan, Yuxuan Chen, Zhenghao\n  Liu, Zhiyuan Liu, Maosong Sun","authorsParsed":[["Zeng","Zheni",""],["Chen","Jiayi",""],["Chen","Huimin",""],["Yan","Yukun",""],["Chen","Yuxuan",""],["Liu","Zhenghao",""],["Liu","Zhiyuan",""],["Sun","Maosong",""]],"versions":[{"version":"v1","created":"Wed, 17 Jul 2024 08:13:22 GMT"},{"version":"v2","created":"Thu, 18 Jul 2024 04:18:43 GMT"},{"version":"v3","created":"Fri, 26 Jul 2024 02:34:14 GMT"},{"version":"v4","created":"Thu, 8 Aug 2024 06:08:54 GMT"}],"updateDate":"2024-08-09","timestamp":1721204002000,"abstract":"  Large language models exhibit aspects of human-level intelligence that\ncatalyze their application as human-like agents in domains such as social\nsimulations, human-machine interactions, and collaborative multi-agent systems.\nHowever, the absence of distinct personalities, such as displaying ingratiating\nbehaviors, inconsistent opinions, and uniform response patterns, diminish LLMs\nutility in practical applications. Addressing this, the development of\npersonality traits in LLMs emerges as a crucial area of research to unlock\ntheir latent potential. Existing methods to personify LLMs generally involve\nstrategies like employing stylized training data for instruction tuning or\nusing prompt engineering to simulate different personalities. These methods\nonly capture superficial linguistic styles instead of the core of personalities\nand are therefore not stable. In this study, we propose PersLLM, integrating\npsychology-grounded principles of personality: social practice, consistency,\nand dynamic development, into a comprehensive training methodology. We\nincorporate personality traits directly into the model parameters, enhancing\nthe model's resistance to induction, promoting consistency, and supporting the\ndynamic evolution of personality. Single-agent evaluation validates our\nmethod's superiority, as it produces responses more aligned with reference\npersonalities compared to other approaches. Case studies for multi-agent\ncommunication highlight its benefits in enhancing opinion consistency within\nindividual agents and fostering collaborative creativity among multiple agents\nin dialogue contexts, potentially benefiting human simulation and multi-agent\ncooperation. Additionally, human-agent interaction evaluations indicate that\nour personified models significantly enhance interactive experiences,\nunderscoring the practical implications of our research.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computers and Society"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/"}