{"id":"2408.09209","title":"H2PIPE: High throughput CNN Inference on FPGAs with High-Bandwidth\n  Memory","authors":"Mario Doumet, Marius Stan, Mathew Hall, Vaughn Betz","authorsParsed":[["Doumet","Mario",""],["Stan","Marius",""],["Hall","Mathew",""],["Betz","Vaughn",""]],"versions":[{"version":"v1","created":"Sat, 17 Aug 2024 14:25:32 GMT"}],"updateDate":"2024-08-20","timestamp":1723904732000,"abstract":"  Convolutional Neural Networks (CNNs) combine large amounts of parallelizable\ncomputation with frequent memory access. Field Programmable Gate Arrays (FPGAs)\ncan achieve low latency and high throughput CNN inference by implementing\ndataflow accelerators that pipeline layer-specific hardware to implement an\nentire network. By implementing a different processing element for each CNN\nlayer, these layer-pipelined accelerators can achieve high compute density, but\nhaving all layers processing in parallel requires high memory bandwidth.\nTraditionally this has been satisfied by storing all weights on chip, but this\nis infeasible for the largest CNNs, which are often those most in need of\nacceleration. In this work we augment a state-of-the-art dataflow accelerator\n(HPIPE) to leverage both High-Bandwidth Memory (HBM) and on-chip storage,\nenabling high performance layer-pipelined dataflow acceleration of large CNNs.\nBased on profiling results of HBM's latency and throughput against expected\naddress patterns, we develop an algorithm to choose which weight buffers should\nbe moved off chip and how deep the on-chip FIFOs to HBM should be to minimize\ncompute unit stalling. We integrate the new hardware generation within the\nHPIPE domain-specific CNN compiler and demonstrate good bandwidth efficiency\nagainst theoretical limits. Compared to the best prior work we obtain speed-ups\nof at least 19.4x, 5.1x and 10.5x on ResNet-18, ResNet-50 and VGG-16\nrespectively.\n","subjects":["Computing Research Repository/Hardware Architecture","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}