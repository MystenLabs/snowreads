{"id":"2408.13741","title":"CAMH: Advancing Model Hijacking Attack in Machine Learning","authors":"Xing He, Jiahao Chen, Yuwen Pu, Qingming Li, Chunyi Zhou, Yingcai Wu,\n  Jinbao Li, Shouling Ji","authorsParsed":[["He","Xing",""],["Chen","Jiahao",""],["Pu","Yuwen",""],["Li","Qingming",""],["Zhou","Chunyi",""],["Wu","Yingcai",""],["Li","Jinbao",""],["Ji","Shouling",""]],"versions":[{"version":"v1","created":"Sun, 25 Aug 2024 07:03:01 GMT"}],"updateDate":"2024-08-27","timestamp":1724569381000,"abstract":"  In the burgeoning domain of machine learning, the reliance on third-party\nservices for model training and the adoption of pre-trained models have surged.\nHowever, this reliance introduces vulnerabilities to model hijacking attacks,\nwhere adversaries manipulate models to perform unintended tasks, leading to\nsignificant security and ethical concerns, like turning an ordinary image\nclassifier into a tool for detecting faces in pornographic content, all without\nthe model owner's knowledge. This paper introduces Category-Agnostic Model\nHijacking (CAMH), a novel model hijacking attack method capable of addressing\nthe challenges of class number mismatch, data distribution divergence, and\nperformance balance between the original and hijacking tasks. CAMH incorporates\nsynchronized training layers, random noise optimization, and a dual-loop\noptimization approach to ensure minimal impact on the original task's\nperformance while effectively executing the hijacking task. We evaluate CAMH\nacross multiple benchmark datasets and network architectures, demonstrating its\npotent attack effectiveness while ensuring minimal degradation in the\nperformance of the original task.\n","subjects":["Computing Research Repository/Cryptography and Security"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}