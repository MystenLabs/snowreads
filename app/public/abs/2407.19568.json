{"id":"2407.19568","title":"Are LLMs Good Annotators for Discourse-level Event Relation Extraction?","authors":"Kangda Wei, Aayush Gautam, Ruihong Huang","authorsParsed":[["Wei","Kangda",""],["Gautam","Aayush",""],["Huang","Ruihong",""]],"versions":[{"version":"v1","created":"Sun, 28 Jul 2024 19:27:06 GMT"}],"updateDate":"2024-07-30","timestamp":1722194826000,"abstract":"  Large Language Models (LLMs) have demonstrated proficiency in a wide array of\nnatural language processing tasks. However, its effectiveness over\ndiscourse-level event relation extraction (ERE) tasks remains unexplored. In\nthis paper, we assess the effectiveness of LLMs in addressing discourse-level\nERE tasks characterized by lengthy documents and intricate relations\nencompassing coreference, temporal, causal, and subevent types. Evaluation is\nconducted using an commercial model, GPT-3.5, and an open-source model,\nLLaMA-2. Our study reveals a notable underperformance of LLMs compared to the\nbaseline established through supervised learning. Although Supervised\nFine-Tuning (SFT) can improve LLMs performance, it does not scale well compared\nto the smaller supervised baseline model. Our quantitative and qualitative\nanalysis shows that LLMs have several weaknesses when applied for extracting\nevent relations, including a tendency to fabricate event mentions, and failures\nto capture transitivity rules among relations, detect long distance relations,\nor comprehend contexts with dense event mentions.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"bLHE_-VCErk9vnAXNSlFcQzbWmvq_FFb1MU2tUFGco0","pdfSize":"1252436"}
