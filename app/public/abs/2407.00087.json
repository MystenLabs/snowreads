{"id":"2407.00087","title":"ARES: Alternating Reinforcement Learning and Supervised Fine-Tuning for\n  Enhanced Multi-Modal Chain-of-Thought Reasoning Through Diverse AI Feedback","authors":"Ju-Seung Byun, Jiyun Chun, Jihyung Kil, Andrew Perrault","authorsParsed":[["Byun","Ju-Seung",""],["Chun","Jiyun",""],["Kil","Jihyung",""],["Perrault","Andrew",""]],"versions":[{"version":"v1","created":"Tue, 25 Jun 2024 07:20:11 GMT"}],"updateDate":"2024-07-02","timestamp":1719300011000,"abstract":"  Large Multimodal Models (LMMs) excel at comprehending human instructions and\ndemonstrate remarkable results across a broad spectrum of tasks. Reinforcement\nLearning from Human Feedback (RLHF) and AI Feedback (RLAIF) further refine LLMs\nby aligning them with specific preferences. These methods primarily use\nranking-based feedback for entire generations. With advanced AI models\n(Teacher), such as GPT-4 and Claude 3 Opus, we can request various types of\ndetailed feedback that are expensive for humans to provide. We propose a\ntwo-stage algorithm ARES that Alternates REinforcement Learning (RL) and\nSupervised Fine-Tuning (SFT). First, we request the Teacher to score how much\neach sentence contributes to solving the problem in a Chain-of-Thought (CoT).\nThis sentence-level feedback allows us to consider individual valuable\nsegments, providing more granular rewards for the RL procedure. Second, we ask\nthe Teacher to correct the wrong reasoning after the RL stage. The RL procedure\nrequires massive efforts for hyperparameter tuning and often generates errors\nlike repetitive words and incomplete sentences. With the correction feedback,\nwe stabilize the RL fine-tuned model through SFT. We conduct experiments on\nmulti-model dataset ScienceQA and A-OKVQA to demonstrate the effectiveness of\nour proposal. ARES rationale reasoning achieves around 70% win rate against\nbaseline models judged by GPT-4o. Additionally, we observe that the improved\nrationale reasoning leads to a 2.5% increase in inference answer accuracy on\naverage for the multi-modal datasets.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}