{"id":"2408.07452","title":"CMU's IWSLT 2024 Simultaneous Speech Translation System","authors":"Xi Xu and Siqi Ouyang and Brian Yan and Patrick Fernandes and William\n  Chen and Lei Li and Graham Neubig and Shinji Watanabe","authorsParsed":[["Xu","Xi",""],["Ouyang","Siqi",""],["Yan","Brian",""],["Fernandes","Patrick",""],["Chen","William",""],["Li","Lei",""],["Neubig","Graham",""],["Watanabe","Shinji",""]],"versions":[{"version":"v1","created":"Wed, 14 Aug 2024 10:44:51 GMT"}],"updateDate":"2024-08-15","timestamp":1723632291000,"abstract":"  This paper describes CMU's submission to the IWSLT 2024 Simultaneous Speech\nTranslation (SST) task for translating English speech to German text in a\nstreaming manner. Our end-to-end speech-to-text (ST) system integrates the\nWavLM speech encoder, a modality adapter, and the Llama2-7B-Base model as the\ndecoder. We employ a two-stage training approach: initially, we align the\nrepresentations of speech and text, followed by full fine-tuning. Both stages\nare trained on MuST-c v2 data with cross-entropy loss. We adapt our offline ST\nmodel for SST using a simple fixed hold-n policy. Experiments show that our\nmodel obtains an offline BLEU score of 31.1 and a BLEU score of 29.5 under 2\nseconds latency on the MuST-C-v2 tst-COMMON.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/"}