{"id":"2407.14367","title":"Thinking Racial Bias in Fair Forgery Detection: Models, Datasets and\n  Evaluations","authors":"Decheng Liu, Zongqi Wang, Chunlei Peng, Nannan Wang, Ruimin Hu, Xinbo\n  Gao","authorsParsed":[["Liu","Decheng",""],["Wang","Zongqi",""],["Peng","Chunlei",""],["Wang","Nannan",""],["Hu","Ruimin",""],["Gao","Xinbo",""]],"versions":[{"version":"v1","created":"Fri, 19 Jul 2024 14:53:18 GMT"},{"version":"v2","created":"Sat, 31 Aug 2024 15:28:20 GMT"}],"updateDate":"2024-09-04","timestamp":1721400798000,"abstract":"  Due to the successful development of deep image generation technology,\nforgery detection plays a more important role in social and economic security.\nRacial bias has not been explored thoroughly in the deep forgery detection\nfield. In the paper, we first contribute a dedicated dataset called the Fair\nForgery Detection (FairFD) dataset, where we prove the racial bias of public\nstate-of-the-art (SOTA) methods. Different from existing forgery detection\ndatasets, the self-constructed FairFD dataset contains a balanced racial ratio\nand diverse forgery generation images with the largest-scale subjects.\nAdditionally, we identify the problems with naive fairness metrics when\nbenchmarking forgery detection models. To comprehensively evaluate fairness, we\ndesign novel metrics including Approach Averaged Metric and Utility Regularized\nMetric, which can avoid deceptive results. We also present an effective and\nrobust post-processing technique, Bias Pruning with Fair Activations (BPFA),\nwhich improves fairness without requiring retraining or weight updates.\nExtensive experiments conducted with 12 representative forgery detection models\ndemonstrate the value of the proposed dataset and the reasonability of the\ndesigned fairness metrics. By applying the BPFA to the existing fairest\ndetector, we achieve a new SOTA. Furthermore, we conduct more in-depth analyses\nto offer more insights to inspire researchers in the community.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}