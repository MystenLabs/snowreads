{"id":"2408.10627","title":"Rethinking Video Segmentation with Masked Video Consistency: Did the\n  Model Learn as Intended?","authors":"Chen Liang, Qiang Guo, Xiaochao Qu, Luoqi Liu, Ting Liu","authorsParsed":[["Liang","Chen",""],["Guo","Qiang",""],["Qu","Xiaochao",""],["Liu","Luoqi",""],["Liu","Ting",""]],"versions":[{"version":"v1","created":"Tue, 20 Aug 2024 08:08:32 GMT"}],"updateDate":"2024-08-21","timestamp":1724141312000,"abstract":"  Video segmentation aims at partitioning video sequences into meaningful\nsegments based on objects or regions of interest within frames. Current video\nsegmentation models are often derived from image segmentation techniques, which\nstruggle to cope with small-scale or class-imbalanced video datasets. This\nleads to inconsistent segmentation results across frames. To address these\nissues, we propose a training strategy Masked Video Consistency, which enhances\nspatial and temporal feature aggregation. MVC introduces a training strategy\nthat randomly masks image patches, compelling the network to predict the entire\nsemantic segmentation, thus improving contextual information integration.\nAdditionally, we introduce Object Masked Attention (OMA) to optimize the\ncross-attention mechanism by reducing the impact of irrelevant queries, thereby\nenhancing temporal modeling capabilities. Our approach, integrated into the\nlatest decoupled universal video segmentation framework, achieves\nstate-of-the-art performance across five datasets for three video segmentation\ntasks, demonstrating significant improvements over previous methods without\nincreasing model parameters.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"l3WV-1IneVyJ4Ox-Z87_d5tfNEf7FT8f2IVBNYs1vRs","pdfSize":"23690118"}
