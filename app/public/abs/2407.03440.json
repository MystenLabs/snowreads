{"id":"2407.03440","title":"Advanced Framework for Animal Sound Classification With Features\n  Optimization","authors":"Qiang Yang, Xiuying Chen, Changsheng Ma, Carlos M. Duarte, and\n  Xiangliang Zhang","authorsParsed":[["Yang","Qiang",""],["Chen","Xiuying",""],["Ma","Changsheng",""],["Duarte","Carlos M.",""],["Zhang","Xiangliang",""]],"versions":[{"version":"v1","created":"Wed, 3 Jul 2024 18:33:47 GMT"}],"updateDate":"2024-07-08","timestamp":1720031627000,"abstract":"  The automatic classification of animal sounds presents an enduring challenge\nin bioacoustics, owing to the diverse statistical properties of sound signals,\nvariations in recording equipment, and prevalent low Signal-to-Noise Ratio\n(SNR) conditions. Deep learning models like Convolutional Neural Networks (CNN)\nand Long Short-Term Memory (LSTM) have excelled in human speech recognition but\nhave not been effectively tailored to the intricate nature of animal sounds,\nwhich exhibit substantial diversity even within the same domain. We propose an\nautomated classification framework applicable to general animal sound\nclassification. Our approach first optimizes audio features from Mel-frequency\ncepstral coefficients (MFCC) including feature rearrangement and feature\nreduction. It then uses the optimized features for the deep learning model,\ni.e., an attention-based Bidirectional LSTM (Bi-LSTM), to extract deep semantic\nfeatures for sound classification. We also contribute an animal sound benchmark\ndataset encompassing oceanic animals and birds1. Extensive experimentation with\nreal-world datasets demonstrates that our approach consistently outperforms\nbaseline methods by over 25% in precision, recall, and accuracy, promising\nadvancements in animal sound classification.\n","subjects":["Computing Research Repository/Sound","Computing Research Repository/Machine Learning","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by/4.0/"}