{"id":"2407.10743","title":"Scaling 3D Reasoning with LMMs to Large Robot Mission Environments Using\n  Datagraphs","authors":"W. J. Meijer, A.C. Kemmeren, E.H.J. Riemens, J.E. Fransman, M. van\n  Bekkum, G.J. Burghouts, J.D. van Mil","authorsParsed":[["Meijer","W. J.",""],["Kemmeren","A. C.",""],["Riemens","E. H. J.",""],["Fransman","J. E.",""],["van Bekkum","M.",""],["Burghouts","G. J.",""],["van Mil","J. D.",""]],"versions":[{"version":"v1","created":"Mon, 15 Jul 2024 14:16:13 GMT"}],"updateDate":"2024-07-16","timestamp":1721052973000,"abstract":"  This paper addresses the challenge of scaling Large Multimodal Models (LMMs)\nto expansive 3D environments. Solving this open problem is especially relevant\nfor robot deployment in many first-responder scenarios, such as\nsearch-and-rescue missions that cover vast spaces. The use of LMMs in these\nsettings is currently hampered by the strict context windows that limit the\nLMM's input size. We therefore introduce a novel approach that utilizes a\ndatagraph structure, which allows the LMM to iteratively query smaller sections\nof a large environment. Using the datagraph in conjunction with graph traversal\nalgorithms, we can prioritize the most relevant locations to the query, thereby\nimproving the scalability of 3D scene language tasks. We illustrate the\ndatagraph using 3D scenes, but these can be easily substituted by other dense\nmodalities that represent the environment, such as pointclouds or Gaussian\nsplats. We demonstrate the potential to use the datagraph for two 3D scene\nlanguage task use cases, in a search-and-rescue mission example.\n","subjects":["Computing Research Repository/Robotics","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}