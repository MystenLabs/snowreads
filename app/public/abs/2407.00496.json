{"id":"2407.00496","title":"A Two-stage Reinforcement Learning-based Approach for Multi-entity Task\n  Allocation","authors":"Aicheng Gong, Kai Yang, Jiafei Lyu, Xiu Li","authorsParsed":[["Gong","Aicheng",""],["Yang","Kai",""],["Lyu","Jiafei",""],["Li","Xiu",""]],"versions":[{"version":"v1","created":"Sat, 29 Jun 2024 17:13:44 GMT"}],"updateDate":"2024-07-02","timestamp":1719681224000,"abstract":"  Task allocation is a key combinatorial optimization problem, crucial for\nmodern applications such as multi-robot cooperation and resource scheduling.\nDecision makers must allocate entities to tasks reasonably across different\nscenarios. However, traditional methods assume static attributes and numbers of\ntasks and entities, often relying on dynamic programming and heuristic\nalgorithms for solutions. In reality, task allocation resembles Markov decision\nprocesses, with dynamically changing task and entity attributes. Thus,\nalgorithms must dynamically allocate tasks based on their states. To address\nthis issue, we propose a two-stage task allocation algorithm based on\nsimilarity, utilizing reinforcement learning to learn allocation strategies.\nThe proposed pre-assign strategy allows entities to preselect appropriate\ntasks, effectively avoiding local optima and thereby better finding the optimal\nallocation. We also introduce an attention mechanism and a hyperparameter\nnetwork structure to adapt to the changing number and attributes of entities\nand tasks, enabling our network structure to generalize to new tasks.\nExperimental results across multiple environments demonstrate that our\nalgorithm effectively addresses the challenges of dynamic task allocation in\npractical applications. Compared to heuristic algorithms like genetic\nalgorithms, our reinforcement learning approach better solves dynamic\nallocation problems and achieves zero-shot generalization to new tasks with\ngood performance. The code is available at\nhttps://github.com/yk7333/TaskAllocation.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}