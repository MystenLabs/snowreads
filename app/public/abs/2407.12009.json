{"id":"2407.12009","title":"Using Multimodal Foundation Models and Clustering for Improved Style\n  Ambiguity Loss","authors":"James Baker","authorsParsed":[["Baker","James",""]],"versions":[{"version":"v1","created":"Thu, 20 Jun 2024 15:43:13 GMT"}],"updateDate":"2024-07-18","timestamp":1718898193000,"abstract":"  Teaching text-to-image models to be creative involves using style ambiguity\nloss, which requires a pretrained classifier. In this work, we explore a new\nform of the style ambiguity training objective, used to approximate creativity,\nthat does not require training a classifier or even a labeled dataset. We then\ntrain a diffusion model to maximize style ambiguity to imbue the diffusion\nmodel with creativity and find our new methods improve upon the traditional\nmethod, based on automated metrics for human judgment, while still maintaining\ncreativity and novelty.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/"}