{"id":"2408.16799","title":"Replica Analysis for Ensemble Techniques in Variable Selection","authors":"Takashi Takahashi","authorsParsed":[["Takahashi","Takashi",""]],"versions":[{"version":"v1","created":"Thu, 29 Aug 2024 11:06:26 GMT"}],"updateDate":"2024-09-02","timestamp":1724929586000,"abstract":"  Variable selection is a problem of statistics that aims to find the subset of\nthe $N$-dimensional possible explanatory variables that are truly related to\nthe generation process of the response variable. In high-dimensional setups,\nwhere the input dimension $N$ is comparable to the data size $M$, it is\ndifficult to use classic methods based on $p$-values. Therefore, methods based\non the ensemble learning are often used. In this review article, we introduce\nhow the performance of these ensemble-based methods can be systematically\nanalyzed using the replica method from statistical mechanics when $N$ and $M$\ndiverge at the same rate as $N,M\\to\\infty, M/N\\to\\alpha\\in(0,\\infty)$. As a\nconcrete application, we analyze the power of stability selection (SS) and the\nderandomized knockoff (dKO) with the $\\ell_1$-regularized statistics in the\nhigh-dimensional linear model. The result indicates that dKO provably\noutperforms the vanilla knockoff and the standard SS, while increasing the\nbootstrap resampling rate in SS might further improve the detection power.\n","subjects":["Mathematics/Statistics Theory","Condensed Matter/Disordered Systems and Neural Networks","Condensed Matter/Statistical Mechanics","Computing Research Repository/Information Theory","Mathematics/Information Theory","Statistics/Statistics Theory"],"license":"http://creativecommons.org/licenses/by/4.0/"}