{"id":"2408.12979","title":"Internal and External Knowledge Interactive Refinement Framework for\n  Knowledge-Intensive Question Answering","authors":"Haowei Du, Dongyan Zhao","authorsParsed":[["Du","Haowei",""],["Zhao","Dongyan",""]],"versions":[{"version":"v1","created":"Fri, 23 Aug 2024 10:52:57 GMT"}],"updateDate":"2024-08-26","timestamp":1724410377000,"abstract":"  Recent works have attempted to integrate external knowledge into LLMs to\naddress the limitations and potential factual errors in LLM-generated content.\nHowever, how to retrieve the correct knowledge from the large amount of\nexternal knowledge imposes a challenge. To this end, we empirically observe\nthat LLMs have already encoded rich knowledge in their pretrained parameters\nand utilizing these internal knowledge improves the retrieval of external\nknowledge when applying them to knowledge-intensive tasks. In this paper, we\npropose a new internal and external knowledge interactive refinement paradigm\ndubbed IEKR to utilize internal knowledge in LLM to help retrieve relevant\nknowledge from the external knowledge base, as well as exploit the external\nknowledge to refine the hallucination of generated internal knowledge. By\nsimply adding a prompt like 'Tell me something about' to the LLMs, we try to\nreview related explicit knowledge and insert them with the query into the\nretriever for external retrieval. The external knowledge is utilized to\ncomplement the internal knowledge into input of LLM for answers. We conduct\nexperiments on 3 benchmark datasets in knowledge-intensive question answering\ntask with different LLMs and domains, achieving the new state-of-the-art.\nFurther analysis shows the effectiveness of different modules in our approach.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"xRZzpzlRuem9psUKWYfglLvMgeLCyww69rHPstjAwM0","pdfSize":"490938"}
