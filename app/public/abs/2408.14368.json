{"id":"2408.14368","title":"GR-MG: Leveraging Partially Annotated Data via Multi-Modal Goal\n  Conditioned Policy","authors":"Peiyan Li, Hongtao Wu, Yan Huang, Chilam Cheang, Liang Wang, Tao Kong","authorsParsed":[["Li","Peiyan",""],["Wu","Hongtao",""],["Huang","Yan",""],["Cheang","Chilam",""],["Wang","Liang",""],["Kong","Tao",""]],"versions":[{"version":"v1","created":"Mon, 26 Aug 2024 15:46:41 GMT"}],"updateDate":"2024-08-27","timestamp":1724687201000,"abstract":"  The robotics community has consistently aimed to achieve generalizable robot\nmanipulation with flexible natural language instructions. One of the primary\nchallenges is that obtaining robot data fully annotated with both actions and\ntexts is time-consuming and labor-intensive. However, partially annotated data,\nsuch as human activity videos without action labels and robot play data without\nlanguage labels, is much easier to collect. Can we leverage these data to\nenhance the generalization capability of robots? In this paper, we propose\nGR-MG, a novel method which supports conditioning on both a language\ninstruction and a goal image. During training, GR-MG samples goal images from\ntrajectories and conditions on both the text and the goal image or solely on\nthe image when text is unavailable. During inference, where only the text is\nprovided, GR-MG generates the goal image via a diffusion-based image-editing\nmodel and condition on both the text and the generated image. This approach\nenables GR-MG to leverage large amounts of partially annotated data while still\nusing language to flexibly specify tasks. To generate accurate goal images, we\npropose a novel progress-guided goal image generation model which injects task\nprogress information into the generation process, significantly improving the\nfidelity and the performance. In simulation experiments, GR-MG improves the\naverage number of tasks completed in a row of 5 from 3.35 to 4.04. In\nreal-robot experiments, GR-MG is able to perform 47 different tasks and\nimproves the success rate from 62.5% to 75.0% and 42.4% to 57.6% in simple and\ngeneralization settings, respectively. Code and checkpoints will be available\nat the project page: https://gr-mg.github.io/.\n","subjects":["Computing Research Repository/Robotics","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}