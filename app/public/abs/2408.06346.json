{"id":"2408.06346","title":"Closing the Affective Loop via Experience-Driven Reinforcement Learning\n  Designers","authors":"Matthew Barthet, Diogo Branco, Roberto Gallotta, Ahmed Khalifa,\n  Georgios N. Yannakakis","authorsParsed":[["Barthet","Matthew",""],["Branco","Diogo",""],["Gallotta","Roberto",""],["Khalifa","Ahmed",""],["Yannakakis","Georgios N.",""]],"versions":[{"version":"v1","created":"Tue, 23 Jul 2024 13:56:43 GMT"}],"updateDate":"2024-08-14","timestamp":1721743003000,"abstract":"  Autonomously tailoring content to a set of predetermined affective patterns\nhas long been considered the holy grail of affect-aware human-computer\ninteraction at large. The experience-driven procedural content generation\nframework realises this vision by searching for content that elicits a certain\nexperience pattern to a user. In this paper, we propose a novel reinforcement\nlearning (RL) framework for generating affect-tailored content, and we test it\nin the domain of racing games. Specifically, the experience-driven RL (EDRL)\nframework is given a target arousal trace, and it then generates a racetrack\nthat elicits the desired affective responses for a particular type of player.\nEDRL leverages a reward function that assesses the affective pattern of any\ngenerated racetrack from a corpus of arousal traces. Our findings suggest that\nEDRL can accurately generate affect-driven racing game levels according to a\ndesigner's style and outperforms search-based methods for personalised content\ngeneration. The method is not only directly applicable to game content\ngeneration tasks but also employable broadly to any domain that uses content\nfor affective adaptation.\n","subjects":["Computing Research Repository/Human-Computer Interaction","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}