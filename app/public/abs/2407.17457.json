{"id":"2407.17457","title":"CSCPR: Cross-Source-Context Indoor RGB-D Place Recognition","authors":"Jing Liang, Zhuo Deng, Zheming Zhou, Min Sun, Omid Ghasemalizadeh,\n  Cheng-Hao Kuo, Arnie Sen, Dinesh Manocha","authorsParsed":[["Liang","Jing",""],["Deng","Zhuo",""],["Zhou","Zheming",""],["Sun","Min",""],["Ghasemalizadeh","Omid",""],["Kuo","Cheng-Hao",""],["Sen","Arnie",""],["Manocha","Dinesh",""]],"versions":[{"version":"v1","created":"Wed, 24 Jul 2024 17:50:00 GMT"}],"updateDate":"2024-07-25","timestamp":1721843400000,"abstract":"  We present a new algorithm, Cross-Source-Context Place Recognition (CSCPR),\nfor RGB-D indoor place recognition that integrates global retrieval and\nreranking into a single end-to-end model. Unlike prior approaches that\nprimarily focus on the RGB domain, CSCPR is designed to handle the RGB-D data.\nWe extend the Context-of-Clusters (CoCs) for handling noisy colorized point\nclouds and introduce two novel modules for reranking: the Self-Context Cluster\n(SCC) and Cross Source Context Cluster (CSCC), which enhance feature\nrepresentation and match query-database pairs based on local features,\nrespectively. We also present two new datasets, ScanNetIPR and ARKitIPR. Our\nexperiments demonstrate that CSCPR significantly outperforms state-of-the-art\nmodels on these datasets by at least 36.5% in Recall@1 at ScanNet-PR dataset\nand 44% in new datasets. Code and datasets will be released.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Robotics"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}