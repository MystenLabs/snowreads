{"id":"2408.15409","title":"Awes, Laws, and Flaws From Today's LLM Research","authors":"Adrian de Wynter","authorsParsed":[["de Wynter","Adrian",""]],"versions":[{"version":"v1","created":"Tue, 27 Aug 2024 21:19:37 GMT"},{"version":"v2","created":"Thu, 29 Aug 2024 17:00:24 GMT"}],"updateDate":"2024-08-30","timestamp":1724793577000,"abstract":"  We perform a critical examination of the scientific methodology behind\ncontemporary large language model (LLM) research. For this we assess over 2,000\nresearch works based on criteria typical of what is considered good research\n(e.g. presence of statistical tests and reproducibility) and cross-validate it\nwith arguments that are at the centre of controversy (e.g., claims of emergent\nbehaviour, the use of LLMs as evaluators). We find multiple trends, such as\ndeclines in claims of emergent behaviour and ethics disclaimers; the rise of\nLLMs as evaluators in spite of a lack of consensus from the community about\ntheir useability; and an increase of claims of LLM reasoning abilities,\ntypically without leveraging human evaluation. This paper underscores the need\nfor more scrutiny and rigour by and from this field to live up to the\nfundamentals of a responsible scientific method that is ethical, reproducible,\nsystematic, and open to criticism.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"KbOtRdPspSlrZxkUFxEJW6_MuorTEpTa1AdwOExme0g","pdfSize":"435083"}
