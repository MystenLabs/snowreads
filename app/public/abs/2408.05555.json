{"id":"2408.05555","title":"Large Language Model-based Role-Playing for Personalized Medical Jargon\n  Extraction","authors":"Jung Hoon Lim, Sunjae Kwon, Zonghai Yao, John P.Lalor, Hong Yu","authorsParsed":[["Lim","Jung Hoon",""],["Kwon","Sunjae",""],["Yao","Zonghai",""],["Lalor","John P.",""],["Yu","Hong",""]],"versions":[{"version":"v1","created":"Sat, 10 Aug 2024 13:40:44 GMT"}],"updateDate":"2024-08-13","timestamp":1723297244000,"abstract":"  Previous studies reveal that Electronic Health Records (EHR), which have been\nwidely adopted in the U.S. to allow patients to access their personal medical\ninformation, do not have high readability to patients due to the prevalence of\nmedical jargon. Tailoring medical notes to individual comprehension by\nidentifying jargon that is difficult for each person will enhance the utility\nof generative models. We present the first quantitative analysis to measure the\nimpact of role-playing in LLM in medical term extraction. By comparing the\nresults of Mechanical Turk workers over 20 sentences, our study demonstrates\nthat LLM role-playing improves F1 scores in 95% of cases across 14 different\nsocio-demographic backgrounds. Furthermore, applying role-playing with\nin-context learning outperformed the previous state-of-the-art models. Our\nresearch showed that ChatGPT can improve traditional medical term extraction\nsystems by utilizing role-play to deliver personalized patient education, a\npotential that previous models had not achieved.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/"}