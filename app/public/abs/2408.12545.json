{"id":"2408.12545","title":"Dynamics of Meta-learning Representation in the Teacher-student Scenario","authors":"Hui Wang, Cho Tung Yip and Bo Li","authorsParsed":[["Wang","Hui",""],["Yip","Cho Tung",""],["Li","Bo",""]],"versions":[{"version":"v1","created":"Thu, 22 Aug 2024 16:59:32 GMT"}],"updateDate":"2024-08-23","timestamp":1724345972000,"abstract":"  Gradient-based meta-learning algorithms have gained popularity for their\nability to train models on new tasks using limited data. Empirical observations\nindicate that such algorithms are able to learn a shared representation across\ntasks, which is regarded as a key factor in their success. However, the\nin-depth theoretical understanding of the learning dynamics and the origin of\nthe shared representation remains underdeveloped. In this work, we investigate\nthe meta-learning dynamics of the non-linear two-layer neural networks trained\non streaming tasks in the teach-student scenario. Through the lens of\nstatistical physics analysis, we characterize the macroscopic behavior of the\nmeta-training processes, the formation of the shared representation, and the\ngeneralization ability of the model on new tasks. The analysis also points to\nthe importance of the choice of certain hyper-parameters of the learning\nalgorithms.\n","subjects":["Computing Research Repository/Machine Learning","Condensed Matter/Disordered Systems and Neural Networks"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}