{"id":"2407.02389","title":"SafaRi:Adaptive Sequence Transformer for Weakly Supervised Referring\n  Expression Segmentation","authors":"Sayan Nag, Koustava Goswami and Srikrishna Karanam","authorsParsed":[["Nag","Sayan",""],["Goswami","Koustava",""],["Karanam","Srikrishna",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 16:02:25 GMT"}],"updateDate":"2024-07-03","timestamp":1719936145000,"abstract":"  Referring Expression Segmentation (RES) aims to provide a segmentation mask\nof the target object in an image referred to by the text (i.e., referring\nexpression). Existing methods require large-scale mask annotations. Moreover,\nsuch approaches do not generalize well to unseen/zero-shot scenarios. To\naddress the aforementioned issues, we propose a weakly-supervised bootstrapping\narchitecture for RES with several new algorithmic innovations. To the best of\nour knowledge, ours is the first approach that considers only a fraction of\nboth mask and box annotations (shown in Figure 1 and Table 1) for training. To\nenable principled training of models in such low-annotation settings, improve\nimage-text region-level alignment, and further enhance spatial localization of\nthe target object in the image, we propose Cross-modal Fusion with Attention\nConsistency module. For automatic pseudo-labeling of unlabeled samples, we\nintroduce a novel Mask Validity Filtering routine based on a spatially aware\nzero-shot proposal scoring approach. Extensive experiments show that with just\n30% annotations, our model SafaRi achieves 59.31 and 48.26 mIoUs as compared to\n58.93 and 48.19 mIoUs obtained by the fully-supervised SOTA method SeqTR\nrespectively on RefCOCO+@testA and RefCOCO+testB datasets. SafaRi also\noutperforms SeqTR by 11.7% (on RefCOCO+testA) and 19.6% (on RefCOCO+testB) in a\nfully-supervised setting and demonstrates strong generalization capabilities in\nunseen/zero-shot tasks.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning","Computing Research Repository/Multimedia"],"license":"http://creativecommons.org/licenses/by/4.0/"}