{"id":"2408.17363","title":"Look, Learn and Leverage (L$^3$): Mitigating Visual-Domain Shift and\n  Discovering Intrinsic Relations via Symbolic Alignment","authors":"Hanchen Xie, Jiageng Zhu, Mahyar Khayatkhoei, Jiazhi Li, Wael\n  AbdAlmageed","authorsParsed":[["Xie","Hanchen",""],["Zhu","Jiageng",""],["Khayatkhoei","Mahyar",""],["Li","Jiazhi",""],["AbdAlmageed","Wael",""]],"versions":[{"version":"v1","created":"Fri, 30 Aug 2024 15:53:48 GMT"}],"updateDate":"2024-09-02","timestamp":1725033228000,"abstract":"  Modern deep learning models have demonstrated outstanding performance on\ndiscovering the underlying mechanisms when both visual appearance and intrinsic\nrelations (e.g., causal structure) data are sufficient, such as Disentangled\nRepresentation Learning (DRL), Causal Representation Learning (CRL) and Visual\nQuestion Answering (VQA) methods. However, generalization ability of these\nmodels is challenged when the visual domain shifts and the relations data is\nabsent during finetuning. To address this challenge, we propose a novel\nlearning framework, Look, Learn and Leverage (L$^3$), which decomposes the\nlearning process into three distinct phases and systematically utilize the\nclass-agnostic segmentation masks as the common symbolic space to align visual\ndomains. Thus, a relations discovery model can be trained on the source domain,\nand when the visual domain shifts and the intrinsic relations are absent, the\npretrained relations discovery model can be directly reused and maintain a\nsatisfactory performance. Extensive performance evaluations are conducted on\nthree different tasks: DRL, CRL and VQA, and show outstanding results on all\nthree tasks, which reveals the advantages of L$^3$.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}