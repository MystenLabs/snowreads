{"id":"2408.11280","title":"Exploring Scene Coherence for Semi-Supervised 3D Semantic Segmentation","authors":"Chuandong Liu, Shuguo Jiang, Xingxing Weng, Lei Yu, Pengcheng Li,\n  Gui-Song Xia","authorsParsed":[["Liu","Chuandong",""],["Jiang","Shuguo",""],["Weng","Xingxing",""],["Yu","Lei",""],["Li","Pengcheng",""],["Xia","Gui-Song",""]],"versions":[{"version":"v1","created":"Wed, 21 Aug 2024 02:03:03 GMT"}],"updateDate":"2024-08-22","timestamp":1724205783000,"abstract":"  Semi-supervised semantic segmentation, which efficiently addresses the\nlimitation of acquiring dense annotations, is essential for 3D scene\nunderstanding. Most methods leverage the teacher model to generate pseudo\nlabels, and then guide the learning of the student model on unlabeled scenes.\nHowever, they focus only on points with pseudo labels while directly\noverlooking points without pseudo labels, namely intra-scene inconsistency,\nleading to semantic ambiguity. Moreover, inter-scene correlation between\nlabeled and unlabeled scenes contribute to transferring rich annotation\ninformation, yet this has not been explored for the semi-supervised tasks. To\naddress these two problems, we propose to explore scene coherence for\nsemi-supervised 3D semantic segmentation, dubbed CoScene. Inspired by the\nunstructured and unordered nature of the point clouds, our CoScene adopts the\nstraightforward point erasure strategy to ensure the intra-scene consistency.\nMoreover, patch-based data augmentation is proposed to enhance the inter-scene\ninformation transfer between labeled and unlabeled scenes at both scene and\ninstance levels. Extensive experimental results on SemanticKITTI and nuScenes\nshow that our approach outperforms existing methods.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}