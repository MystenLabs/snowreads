{"id":"2408.09253","title":"Reinforcement Learning Compensated Model Predictive Control for Off-road\n  Driving on Unknown Deformable Terrain","authors":"Prakhar Gupta, Jonathon M. Smereka, Yunyi Jia","authorsParsed":[["Gupta","Prakhar",""],["Smereka","Jonathon M.",""],["Jia","Yunyi",""]],"versions":[{"version":"v1","created":"Sat, 17 Aug 2024 16:53:51 GMT"}],"updateDate":"2024-08-20","timestamp":1723913631000,"abstract":"  This study presents an Actor-Critic reinforcement learning Compensated Model\nPredictive Controller (AC2MPC) designed for high-speed, off-road autonomous\ndriving on deformable terrains. Addressing the difficulty of modeling unknown\ntire-terrain interaction and ensuring real-time control feasibility and\nperformance, this framework integrates deep reinforcement learning with a model\npredictive controller to manage unmodeled nonlinear dynamics. We evaluate the\ncontroller framework over constant and varying velocity profiles using\nhigh-fidelity simulator Project Chrono. Our findings demonstrate that our\ncontroller statistically outperforms standalone model-based and learning-based\ncontrollers over three unknown terrains that represent sandy deformable track,\nsandy and rocky track and cohesive clay-like deformable soil track. Despite\nvaried and previously unseen terrain characteristics, this framework\ngeneralized well enough to track longitudinal reference speeds with the least\nerror. Furthermore, this framework required significantly less training data\ncompared to purely learning based controller, converging in fewer steps while\ndelivering better performance. Even when under-trained, this controller\noutperformed the standalone controllers, highlighting its potential for safer\nand more efficient real-world deployment.\n","subjects":["Computing Research Repository/Robotics","Computing Research Repository/Systems and Control","Electrical Engineering and Systems Science/Systems and Control"],"license":"http://creativecommons.org/licenses/by-sa/4.0/"}