{"id":"2408.02140","title":"VidModEx: Interpretable and Efficient Black Box Model Extraction for\n  High-Dimensional Spaces","authors":"Somnath Sendhil Kumar, Yuvaraj Govindarajulu, Pavan Kulkarni,\n  Manojkumar Parmar","authorsParsed":[["Kumar","Somnath Sendhil",""],["Govindarajulu","Yuvaraj",""],["Kulkarni","Pavan",""],["Parmar","Manojkumar",""]],"versions":[{"version":"v1","created":"Sun, 4 Aug 2024 20:38:45 GMT"}],"updateDate":"2024-08-06","timestamp":1722803925000,"abstract":"  In the domain of black-box model extraction, conventional methods reliant on\nsoft labels or surrogate datasets struggle with scaling to high-dimensional\ninput spaces and managing the complexity of an extensive array of interrelated\nclasses. In this work, we present a novel approach that utilizes SHAP (SHapley\nAdditive exPlanations) to enhance synthetic data generation. SHAP quantifies\nthe individual contributions of each input feature towards the victim model's\noutput, facilitating the optimization of an energy-based GAN towards a\ndesirable output. This method significantly boosts performance, achieving a\n16.45% increase in the accuracy of image classification models and extending to\nvideo classification models with an average improvement of 26.11% and a maximum\nof 33.36% on challenging datasets such as UCF11, UCF101, Kinetics 400, Kinetics\n600, and Something-Something V2. We further demonstrate the effectiveness and\npractical utility of our method under various scenarios, including the\navailability of top-k prediction probabilities, top-k prediction labels, and\ntop-1 labels.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"rlBUQzjV06rnW-UwNYxkwhFyKTPa7GqU147gdJoLM6k","pdfSize":"15533626","txDigest":"2o8VUYhRrWTRjQeEvLTR5BeV7Y9EscsVhUo7gBdT8pWE","endEpoch":"1","status":"CERTIFIED"}
