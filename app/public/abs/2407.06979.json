{"id":"2407.06979","title":"Can virtual staining for high-throughput screening generalize?","authors":"Samuel Tonks, Cuong Nguyen, Steve Hood, Ryan Musso, Ceridwen Hopely,\n  Steve Titus, Minh Doan, Iain Styles and Alexander Krull","authorsParsed":[["Tonks","Samuel",""],["Nguyen","Cuong",""],["Hood","Steve",""],["Musso","Ryan",""],["Hopely","Ceridwen",""],["Titus","Steve",""],["Doan","Minh",""],["Styles","Iain",""],["Krull","Alexander",""]],"versions":[{"version":"v1","created":"Tue, 9 Jul 2024 15:54:06 GMT"},{"version":"v2","created":"Tue, 13 Aug 2024 08:31:42 GMT"}],"updateDate":"2024-08-14","timestamp":1720540446000,"abstract":"  The large volume and variety of imaging data from high-throughput screening\n(HTS) in the pharmaceutical industry present an excellent resource for training\nvirtual staining models. However, the potential of models trained under one set\nof experimental conditions to generalize to other conditions remains\nunderexplored. This study systematically investigates whether data from three\ncell types (lung, ovarian, and breast) and two phenotypes (toxic and non-toxic\nconditions) commonly found in HTS can effectively train virtual staining models\nto generalize across three typical HTS distribution shifts: unseen phenotypes,\nunseen cell types, and the combination of both. Utilizing a dataset of 772,416\npaired bright-field, cytoplasm, nuclei, and DNA-damage stain images, we\nevaluate the generalization capabilities of models across pixel-based,\ninstance-wise, and biological-feature-based levels. Our findings indicate that\ntraining virtual nuclei and cytoplasm models on non-toxic condition samples not\nonly generalizes to toxic condition samples but leads to improved performance\nacross all evaluation levels compared to training on toxic condition samples.\nGeneralization to unseen cell types shows variability depending on the cell\ntype; models trained on ovarian or lung cell samples often perform well under\nother conditions, while those trained on breast cell samples consistently show\npoor generalization. Generalization to unseen cell types and phenotypes shows\ngood generalization across all levels of evaluation compared to addressing\nunseen cell types alone. This study represents the first large-scale,\ndata-centric analysis of the generalization capability of virtual staining\nmodels trained on diverse HTS datasets, providing valuable strategies for\nexperimental training data generation.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computer Vision and Pattern Recognition","Quantitative Biology/Quantitative Methods"],"license":"http://creativecommons.org/licenses/by-sa/4.0/"}