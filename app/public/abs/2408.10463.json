{"id":"2408.10463","title":"Adversarial training of Keyword Spotting to Minimize TTS Data\n  Overfitting","authors":"Hyun Jin Park, Dhruuv Agarwal, Neng Chen, Rentao Sun, Kurt Partridge,\n  Justin Chen, Harry Zhang, Pai Zhu, Jacob Bartel, Kyle Kastner, Gary Wang,\n  Andrew Rosenberg, Quan Wang","authorsParsed":[["Park","Hyun Jin",""],["Agarwal","Dhruuv",""],["Chen","Neng",""],["Sun","Rentao",""],["Partridge","Kurt",""],["Chen","Justin",""],["Zhang","Harry",""],["Zhu","Pai",""],["Bartel","Jacob",""],["Kastner","Kyle",""],["Wang","Gary",""],["Rosenberg","Andrew",""],["Wang","Quan",""]],"versions":[{"version":"v1","created":"Tue, 20 Aug 2024 00:16:12 GMT"}],"updateDate":"2024-08-21","timestamp":1724112972000,"abstract":"  The keyword spotting (KWS) problem requires large amounts of real speech\ntraining data to achieve high accuracy across diverse populations. Utilizing\nlarge amounts of text-to-speech (TTS) synthesized data can reduce the cost and\ntime associated with KWS development. However, TTS data may contain artifacts\nnot present in real speech, which the KWS model can exploit (overfit), leading\nto degraded accuracy on real speech. To address this issue, we propose applying\nan adversarial training method to prevent the KWS model from learning\nTTS-specific features when trained on large amounts of TTS data. Experimental\nresults demonstrate that KWS model accuracy on real speech data can be improved\nby up to 12% when adversarial loss is used in addition to the original KWS\nloss. Surprisingly, we also observed that the adversarial setup improves\naccuracy by up to 8%, even when trained solely on TTS and real negative speech\ndata, without any real positive examples.\n","subjects":["Computing Research Repository/Sound","Computing Research Repository/Machine Learning","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"B4eriF8XAnq_CT5xFch2JE-mElb4G2bYN1ExrkONJfk","pdfSize":"542537"}
