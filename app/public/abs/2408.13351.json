{"id":"2408.13351","title":"SeA: Semantic Adversarial Augmentation for Last Layer Features from\n  Unsupervised Representation Learning","authors":"Qi Qian, Yuanhong Xu, Juhua Hu","authorsParsed":[["Qian","Qi",""],["Xu","Yuanhong",""],["Hu","Juhua",""]],"versions":[{"version":"v1","created":"Fri, 23 Aug 2024 19:55:13 GMT"}],"updateDate":"2024-08-27","timestamp":1724442913000,"abstract":"  Deep features extracted from certain layers of a pre-trained deep model show\nsuperior performance over the conventional hand-crafted features. Compared with\nfine-tuning or linear probing that can explore diverse augmentations, \\eg,\nrandom crop/flipping, in the original input space, the appropriate\naugmentations for learning with fixed deep features are more challenging and\nhave been less investigated, which degenerates the performance. To unleash the\npotential of fixed deep features, we propose a novel semantic adversarial\naugmentation (SeA) in the feature space for optimization. Concretely, the\nadversarial direction implied by the gradient will be projected to a subspace\nspanned by other examples to preserve the semantic information. Then, deep\nfeatures will be perturbed with the semantic direction, and augmented features\nwill be applied to learn the classifier. Experiments are conducted on $11$\nbenchmark downstream classification tasks with $4$ popular pre-trained models.\nOur method is $2\\%$ better than the deep features without SeA on average.\nMoreover, compared to the expensive fine-tuning that is expected to give good\nperformance, SeA shows a comparable performance on $6$ out of $11$ tasks,\ndemonstrating the effectiveness of our proposal in addition to its efficiency.\nCode is available at \\url{https://github.com/idstcv/SeA}.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}