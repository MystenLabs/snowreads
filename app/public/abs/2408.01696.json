{"id":"2408.01696","title":"Generating High-quality Symbolic Music Using Fine-grained Discriminators","authors":"Zhedong Zhang, Liang Li, Jiehua Zhang, Zhenghui Hu, Hongkui Wang,\n  Chenggang Yan, Jian Yang, Yuankai Qi","authorsParsed":[["Zhang","Zhedong",""],["Li","Liang",""],["Zhang","Jiehua",""],["Hu","Zhenghui",""],["Wang","Hongkui",""],["Yan","Chenggang",""],["Yang","Jian",""],["Qi","Yuankai",""]],"versions":[{"version":"v1","created":"Sat, 3 Aug 2024 07:32:21 GMT"}],"updateDate":"2024-08-06","timestamp":1722670341000,"abstract":"  Existing symbolic music generation methods usually utilize discriminator to\nimprove the quality of generated music via global perception of music. However,\nconsidering the complexity of information in music, such as rhythm and melody,\na single discriminator cannot fully reflect the differences in these two\nprimary dimensions of music. In this work, we propose to decouple the melody\nand rhythm from music, and design corresponding fine-grained discriminators to\ntackle the aforementioned issues. Specifically, equipped with a pitch\naugmentation strategy, the melody discriminator discerns the melody variations\npresented by the generated samples. By contrast, the rhythm discriminator,\nenhanced with bar-level relative positional encoding, focuses on the velocity\nof generated notes. Such a design allows the generator to be more explicitly\naware of which aspects should be adjusted in the generated music, making it\neasier to mimic human-composed music. Experimental results on the POP909\nbenchmark demonstrate the favorable performance of the proposed method compared\nto several state-of-the-art methods in terms of both objective and subjective\nmetrics.\n","subjects":["Computing Research Repository/Sound","Computing Research Repository/Artificial Intelligence","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"lG801RIBF_q2RYK0T0f2CkO9Tfs_32GD9ShmkoWwXEw","pdfSize":"1462827"}
