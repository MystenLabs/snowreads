{"id":"2408.06743","title":"Class-aware and Augmentation-free Contrastive Learning from Label\n  Proportion","authors":"Jialiang Wang, Ning Zhang, Shimin Di, Ruidong Wang, Lei Chen","authorsParsed":[["Wang","Jialiang",""],["Zhang","Ning",""],["Di","Shimin",""],["Wang","Ruidong",""],["Chen","Lei",""]],"versions":[{"version":"v1","created":"Tue, 13 Aug 2024 09:04:47 GMT"}],"updateDate":"2024-08-14","timestamp":1723539887000,"abstract":"  Learning from Label Proportion (LLP) is a weakly supervised learning scenario\nin which training data is organized into predefined bags of instances,\ndisclosing only the class label proportions per bag. This paradigm is essential\nfor user modeling and personalization, where user privacy is paramount,\noffering insights into user preferences without revealing individual data. LLP\nfaces a unique difficulty: the misalignment between bag-level supervision and\nthe objective of instance-level prediction, primarily due to the inherent\nambiguity in label proportion matching. Previous studies have demonstrated deep\nrepresentation learning can generate auxiliary signals to promote the\nsupervision level in the image domain. However, applying these techniques to\ntabular data presents significant challenges: 1) they rely heavily on\nlabel-invariant augmentation to establish multi-view, which is not feasible\nwith the heterogeneous nature of tabular datasets, and 2) tabular datasets\noften lack sufficient semantics for perfect class distinction, making them\nprone to suboptimality caused by the inherent ambiguity of label proportion\nmatching.\n  To address these challenges, we propose an augmentation-free contrastive\nframework TabLLP-BDC that introduces class-aware supervision (explicitly aware\nof class differences) at the instance level. Our solution features a two-stage\nBag Difference Contrastive (BDC) learning mechanism that establishes robust\nclass-aware instance-level supervision by disassembling the nuance between bag\nlabel proportions, without relying on augmentations. Concurrently, our model\npresents a pioneering multi-task pretraining pipeline tailored for\ntabular-based LLP, capturing intrinsic tabular feature correlations in\nalignment with label proportion distribution. Extensive experiments demonstrate\nthat TabLLP-BDC achieves state-of-the-art performance for LLP in the tabular\ndomain.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"HJGDaPvvyA4eWsDXvdNA0iDfW6xWC1qhrXCwWkqtSoU","pdfSize":"1440646"}
