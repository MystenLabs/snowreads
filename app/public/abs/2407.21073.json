{"id":"2407.21073","title":"Enhancing Adversarial Text Attacks on BERT Models with Projected\n  Gradient Descent","authors":"Hetvi Waghela, Jaydip Sen, Sneha Rakshit","authorsParsed":[["Waghela","Hetvi",""],["Sen","Jaydip",""],["Rakshit","Sneha",""]],"versions":[{"version":"v1","created":"Mon, 29 Jul 2024 09:07:29 GMT"}],"updateDate":"2024-08-01","timestamp":1722244049000,"abstract":"  Adversarial attacks against deep learning models represent a major threat to\nthe security and reliability of natural language processing (NLP) systems. In\nthis paper, we propose a modification to the BERT-Attack framework, integrating\nProjected Gradient Descent (PGD) to enhance its effectiveness and robustness.\nThe original BERT-Attack, designed for generating adversarial examples against\nBERT-based models, suffers from limitations such as a fixed perturbation budget\nand a lack of consideration for semantic similarity. The proposed approach in\nthis work, PGD-BERT-Attack, addresses these limitations by leveraging PGD to\niteratively generate adversarial examples while ensuring both imperceptibility\nand semantic similarity to the original input. Extensive experiments are\nconducted to evaluate the performance of PGD-BERT-Attack compared to the\noriginal BERT-Attack and other baseline methods. The results demonstrate that\nPGD-BERT-Attack achieves higher success rates in causing misclassification\nwhile maintaining low perceptual changes. Furthermore, PGD-BERT-Attack produces\nadversarial instances that exhibit greater semantic resemblance to the initial\ninput, enhancing their applicability in real-world scenarios. Overall, the\nproposed modification offers a more effective and robust approach to\nadversarial attacks on BERT-based models, thus contributing to the advancement\nof defense against attacks on NLP systems.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Computation and Language","Computing Research Repository/Cryptography and Security"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}