{"id":"2408.01688","title":"SiamMo: Siamese Motion-Centric 3D Object Tracking","authors":"Yuxiang Yang, Yingqi Deng, Jing Zhang, Hongjie Gu, Zhekang Dong","authorsParsed":[["Yang","Yuxiang",""],["Deng","Yingqi",""],["Zhang","Jing",""],["Gu","Hongjie",""],["Dong","Zhekang",""]],"versions":[{"version":"v1","created":"Sat, 3 Aug 2024 07:02:01 GMT"},{"version":"v2","created":"Mon, 9 Sep 2024 05:24:27 GMT"}],"updateDate":"2024-09-10","timestamp":1722668521000,"abstract":"  Current 3D single object tracking methods primarily rely on the Siamese\nmatching-based paradigm, which struggles with textureless and incomplete LiDAR\npoint clouds. Conversely, the motion-centric paradigm avoids appearance\nmatching, thus overcoming these issues. However, its complex multi-stage\npipeline and the limited temporal modeling capability of a single-stream\narchitecture constrain its potential. In this paper, we introduce SiamMo, a\nnovel and simple Siamese motion-centric tracking approach. Unlike the\ntraditional single-stream architecture, we employ Siamese feature extraction\nfor motion-centric tracking. This decouples feature extraction from temporal\nfusion, significantly enhancing tracking performance. Additionally, we design a\nSpatio-Temporal Feature Aggregation module to integrate Siamese features at\nmultiple scales, capturing motion information effectively. We also introduce a\nBox-aware Feature Encoding module to encode object size priors into motion\nestimation. SiamMo is a purely motion-centric tracker that eliminates the need\nfor additional processes like segmentation and box refinement. Without whistles\nand bells, SiamMo not only surpasses state-of-the-art methods across multiple\nbenchmarks but also demonstrates exceptional robustness in challenging\nscenarios. SiamMo sets a new record on the KITTI tracking benchmark with 90.1\\%\nprecision while maintaining a high inference speed of 108 FPS. The code will be\nreleased at https://github.com/HDU-VRLab/SiamMo.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}