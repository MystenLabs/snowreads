{"id":"2407.16058","title":"Revisiting Score Function Estimators for $k$-Subset Sampling","authors":"Klas Wijk and Ricardo Vinuesa and Hossein Azizpour","authorsParsed":[["Wijk","Klas",""],["Vinuesa","Ricardo",""],["Azizpour","Hossein",""]],"versions":[{"version":"v1","created":"Mon, 22 Jul 2024 21:26:39 GMT"},{"version":"v2","created":"Fri, 16 Aug 2024 10:29:46 GMT"}],"updateDate":"2024-08-19","timestamp":1721683599000,"abstract":"  Are score function estimators an underestimated approach to learning with\n$k$-subset sampling? Sampling $k$-subsets is a fundamental operation in many\nmachine learning tasks that is not amenable to differentiable parametrization,\nimpeding gradient-based optimization. Prior work has focused on relaxed\nsampling or pathwise gradient estimators. Inspired by the success of score\nfunction estimators in variational inference and reinforcement learning, we\nrevisit them within the context of $k$-subset sampling. Specifically, we\ndemonstrate how to efficiently compute the $k$-subset distribution's score\nfunction using a discrete Fourier transform, and reduce the estimator's\nvariance with control variates. The resulting estimator provides both exact\nsamples and unbiased gradient estimates while also applying to\nnon-differentiable downstream models, unlike existing methods. Experiments in\nfeature selection show results competitive with current methods, despite weaker\nassumptions.\n","subjects":["Computing Research Repository/Machine Learning","Statistics/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}