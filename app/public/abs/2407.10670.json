{"id":"2407.10670","title":"Enhancing Retrieval and Managing Retrieval: A Four-Module Synergy for\n  Improved Quality and Efficiency in RAG Systems","authors":"Yunxiao Shi, Xing Zi, Zijing Shi, Haimin Zhang, Qiang Wu, Min Xu","authorsParsed":[["Shi","Yunxiao",""],["Zi","Xing",""],["Shi","Zijing",""],["Zhang","Haimin",""],["Wu","Qiang",""],["Xu","Min",""]],"versions":[{"version":"v1","created":"Mon, 15 Jul 2024 12:35:00 GMT"}],"updateDate":"2024-07-16","timestamp":1721046900000,"abstract":"  Retrieval-augmented generation (RAG) techniques leverage the in-context\nlearning capabilities of large language models (LLMs) to produce more accurate\nand relevant responses. Originating from the simple 'retrieve-then-read'\napproach, the RAG framework has evolved into a highly flexible and modular\nparadigm. A critical component, the Query Rewriter module, enhances knowledge\nretrieval by generating a search-friendly query. This method aligns input\nquestions more closely with the knowledge base. Our research identifies\nopportunities to enhance the Query Rewriter module to Query Rewriter+ by\ngenerating multiple queries to overcome the Information Plateaus associated\nwith a single query and by rewriting questions to eliminate Ambiguity, thereby\nclarifying the underlying intent. We also find that current RAG systems exhibit\nissues with Irrelevant Knowledge; to overcome this, we propose the Knowledge\nFilter. These two modules are both based on the instruction-tuned Gemma-2B\nmodel, which together enhance response quality. The final identified issue is\nRedundant Retrieval; we introduce the Memory Knowledge Reservoir and the\nRetriever Trigger to solve this. The former supports the dynamic expansion of\nthe RAG system's knowledge base in a parameter-free manner, while the latter\noptimizes the cost for accessing external knowledge, thereby improving resource\nutilization and response efficiency. These four RAG modules synergistically\nimprove the response quality and efficiency of the RAG system. The\neffectiveness of these modules has been validated through experiments and\nablation studies across six common QA datasets. The source code can be accessed\nat https://github.com/Ancientshi/ERM4.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"h1ubePHEeoK8U54jLQKFMi4r-kPd-EI6xSvNx1hmyzI","pdfSize":"1305096","objectId":"0x87474b62c37437372c6077452668ed9172f245b5fcc51b460406d93f21316e69","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
