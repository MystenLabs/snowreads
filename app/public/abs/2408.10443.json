{"id":"2408.10443","title":"Federated Learning of Large ASR Models in the Real World","authors":"Yonghui Xiao, Yuxin Ding, Changwan Ryu, Petr Zadrazil, Francoise\n  Beaufays","authorsParsed":[["Xiao","Yonghui",""],["Ding","Yuxin",""],["Ryu","Changwan",""],["Zadrazil","Petr",""],["Beaufays","Francoise",""]],"versions":[{"version":"v1","created":"Mon, 19 Aug 2024 22:44:10 GMT"}],"updateDate":"2024-08-21","timestamp":1724107450000,"abstract":"  Federated learning (FL) has shown promising results on training machine\nlearning models with privacy preservation. However, for large models with over\n100 million parameters, the training resource requirement becomes an obstacle\nfor FL because common devices do not have enough memory and computation power\nto finish the FL tasks. Although efficient training methods have been proposed,\nit is still a challenge to train the large models like Conformer based ASR.\nThis paper presents a systematic solution to train the full-size ASR models of\n130M parameters with FL. To our knowledge, this is the first real-world FL\napplication of the Conformer model, which is also the largest model ever\ntrained with FL so far. And this is the first paper showing FL can improve the\nASR model quality with a set of proposed methods to refine the quality of data\nand labels of clients. We demonstrate both the training efficiency and the\nmodel quality improvement in real-world experiments.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Computation and Language","Computing Research Repository/Sound","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}