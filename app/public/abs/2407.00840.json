{"id":"2407.00840","title":"MUSE-Net: Missingness-aware mUlti-branching Self-attention Encoder for\n  Irregular Longitudinal Electronic Health Records","authors":"Zekai Wang, Tieming Liu, Bing Yao","authorsParsed":[["Wang","Zekai",""],["Liu","Tieming",""],["Yao","Bing",""]],"versions":[{"version":"v1","created":"Sun, 30 Jun 2024 21:54:41 GMT"}],"updateDate":"2024-07-02","timestamp":1719784481000,"abstract":"  The era of big data has made vast amounts of clinical data readily available,\nparticularly in the form of electronic health records (EHRs), which provides\nunprecedented opportunities for developing data-driven diagnostic tools to\nenhance clinical decision making. However, the application of EHRs in\ndata-driven modeling faces challenges such as irregularly spaced multi-variate\ntime series, issues of incompleteness, and data imbalance. Realizing the full\ndata potential of EHRs hinges on the development of advanced analytical models.\nIn this paper, we propose a novel Missingness-aware mUlti-branching\nSelf-attention Encoder (MUSE-Net) to cope with the challenges in modeling\nlongitudinal EHRs for data-driven disease prediction. The MUSE-Net leverages a\nmulti-task Gaussian process (MGP) with missing value masks for data imputation,\na multi-branching architecture to address the data imbalance problem, and a\ntime-aware self-attention encoder to account for the irregularly spaced time\ninterval in longitudinal EHRs. We evaluate the proposed MUSE-Net using both\nsynthetic and real-world datasets. Experimental results show that our MUSE-Net\noutperforms existing methods that are widely used to investigate longitudinal\nsignals.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}