{"id":"2408.02980","title":"Sample-agnostic Adversarial Perturbation for Vision-Language\n  Pre-training Models","authors":"Haonan Zheng and Wen Jiang and Xinyang Deng and Wenrui Li","authorsParsed":[["Zheng","Haonan",""],["Jiang","Wen",""],["Deng","Xinyang",""],["Li","Wenrui",""]],"versions":[{"version":"v1","created":"Tue, 6 Aug 2024 06:25:39 GMT"}],"updateDate":"2024-08-07","timestamp":1722925539000,"abstract":"  Recent studies on AI security have highlighted the vulnerability of\nVision-Language Pre-training (VLP) models to subtle yet intentionally designed\nperturbations in images and texts. Investigating multimodal systems' robustness\nvia adversarial attacks is crucial in this field. Most multimodal attacks are\nsample-specific, generating a unique perturbation for each sample to construct\nadversarial samples. To the best of our knowledge, it is the first work through\nmultimodal decision boundaries to explore the creation of a universal,\nsample-agnostic perturbation that applies to any image. Initially, we explore\nstrategies to move sample points beyond the decision boundaries of linear\nclassifiers, refining the algorithm to ensure successful attacks under the top\n$k$ accuracy metric. Based on this foundation, in visual-language tasks, we\ntreat visual and textual modalities as reciprocal sample points and decision\nhyperplanes, guiding image embeddings to traverse text-constructed decision\nboundaries, and vice versa. This iterative process consistently refines a\nuniversal perturbation, ultimately identifying a singular direction within the\ninput space which is exploitable to impair the retrieval performance of VLP\nmodels. The proposed algorithms support the creation of global perturbations or\nadversarial patches. Comprehensive experiments validate the effectiveness of\nour method, showcasing its data, task, and model transferability across various\nVLP models and datasets. Code: https://github.com/LibertazZ/MUAP\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}