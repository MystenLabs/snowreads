{"id":"2407.18074","title":"Principal-Agent Reinforcement Learning","authors":"Dima Ivanov, Paul D\\\"utting, Inbal Talgam-Cohen, Tonghan Wang, David\n  C. Parkes","authorsParsed":[["Ivanov","Dima",""],["DÃ¼tting","Paul",""],["Talgam-Cohen","Inbal",""],["Wang","Tonghan",""],["Parkes","David C.",""]],"versions":[{"version":"v1","created":"Thu, 25 Jul 2024 14:28:58 GMT"}],"updateDate":"2024-07-26","timestamp":1721917738000,"abstract":"  Contracts are the economic framework which allows a principal to delegate a\ntask to an agent -- despite misaligned interests, and even without directly\nobserving the agent's actions. In many modern reinforcement learning settings,\nself-interested agents learn to perform a multi-stage task delegated to them by\na principal. We explore the significant potential of utilizing contracts to\nincentivize the agents. We model the delegated task as an MDP, and study a\nstochastic game between the principal and agent where the principal learns what\ncontracts to use, and the agent learns an MDP policy in response. We present a\nlearning-based algorithm for optimizing the principal's contracts, which\nprovably converges to the subgame-perfect equilibrium of the principal-agent\ngame. A deep RL implementation allows us to apply our method to very large MDPs\nwith unknown transition dynamics. We extend our approach to multiple agents,\nand demonstrate its relevance to resolving a canonical sequential social\ndilemma with minimal intervention to agent rewards.\n","subjects":["Computing Research Repository/Computer Science and Game Theory","Computing Research Repository/Machine Learning","Computing Research Repository/Multiagent Systems"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}