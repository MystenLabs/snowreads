{"id":"2407.09221","title":"Evaluating AI Evaluation: Perils and Prospects","authors":"John Burden","authorsParsed":[["Burden","John",""]],"versions":[{"version":"v1","created":"Fri, 12 Jul 2024 12:37:13 GMT"}],"updateDate":"2024-07-15","timestamp":1720787833000,"abstract":"  As AI systems appear to exhibit ever-increasing capability and generality,\nassessing their true potential and safety becomes paramount. This paper\ncontends that the prevalent evaluation methods for these systems are\nfundamentally inadequate, heightening the risks and potential hazards\nassociated with AI. I argue that a reformation is required in the way we\nevaluate AI systems and that we should look towards cognitive sciences for\ninspiration in our approaches, which have a longstanding tradition of assessing\ngeneral intelligence across diverse species. We will identify some of the\ndifficulties that need to be overcome when applying cognitively-inspired\napproaches to general-purpose AI systems and also analyse the emerging area of\n\"Evals\". The paper concludes by identifying promising research pathways that\ncould refine AI evaluation, advancing it towards a rigorous scientific domain\nthat contributes to the development of safe AI systems.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computers and Society"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}