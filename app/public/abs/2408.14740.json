{"id":"2408.14740","title":"Properties of Effective Information Anonymity Regulations","authors":"Aloni Cohen, Micah Altman, Francesca Falzon, Evangelina Anna Markatou,\n  Kobbi Nissim","authorsParsed":[["Cohen","Aloni",""],["Altman","Micah",""],["Falzon","Francesca",""],["Markatou","Evangelina Anna",""],["Nissim","Kobbi",""]],"versions":[{"version":"v1","created":"Tue, 27 Aug 2024 02:34:41 GMT"}],"updateDate":"2024-08-28","timestamp":1724726081000,"abstract":"  A firm seeks to analyze a dataset and to release the results. The dataset\ncontains information about individual people, and the firm is subject to some\nregulation that forbids the release of the dataset itself. The regulation also\nimposes conditions on the release of the results. What properties should the\nregulation satisfy? We restrict our attention to regulations tailored to\ncontrolling the downstream effects of the release specifically on the\nindividuals to whom the data relate. A particular example of interest is an\nanonymization rule, where a data protection regulation limiting the disclosure\nof personally identifiable information does not restrict the distribution of\ndata that has been sufficiently anonymized.\n  In this paper, we develop a set of technical requirements for anonymization\nrules and related regulations. The requirements are derived by situating within\na simple abstract model of data processing a set of guiding general principles\nput forth in prior work. We describe an approach to evaluating such regulations\nusing these requirements -- thus enabling the application of the general\nprinciples for the design of mechanisms. As an exemplar, we evaluate competing\ninterpretations of regulatory requirements from the EU's General Data\nProtection Regulation.\n","subjects":["Computing Research Repository/Computers and Society"],"license":"http://creativecommons.org/licenses/by/4.0/"}