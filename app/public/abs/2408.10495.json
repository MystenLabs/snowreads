{"id":"2408.10495","title":"How Well Do Large Language Models Serve as End-to-End Secure Code\n  Producers?","authors":"Jianian Gong, Nachuan Duan, Ziheng Tao, Zhaohui Gong, Yuan Yuan,\n  Minlie Huang","authorsParsed":[["Gong","Jianian",""],["Duan","Nachuan",""],["Tao","Ziheng",""],["Gong","Zhaohui",""],["Yuan","Yuan",""],["Huang","Minlie",""]],"versions":[{"version":"v1","created":"Tue, 20 Aug 2024 02:42:29 GMT"}],"updateDate":"2024-08-21","timestamp":1724121749000,"abstract":"  The rapid advancement of large language models (LLMs) such as GPT-4 has\nrevolutionized the landscape of software engineering, positioning these models\nat the core of modern development practices. As we anticipate these models to\nevolve into the primary and trustworthy tools used in software development,\nensuring the security of the code they produce becomes paramount. How well can\nLLMs serve as end-to-end secure code producers? This paper presents a\nsystematic investigation into LLMs' inherent potential to generate code with\nfewer vulnerabilities. Specifically, We studied GPT-3.5 and GPT-4's capability\nto identify and repair vulnerabilities in the code generated by four popular\nLLMs including themselves (GPT-3.5, GPT-4, Code Llama, and CodeGeeX2). By\nmanually or automatically reviewing 4,900 pieces of code, our study reveals\nthat: (1) large language models lack awareness of scenario-relevant security\nrisks, which leads to the generation of over 75% vulnerable code on the\nSecurityEval benchmark; (2) LLMs such as GPT-3.5 and GPT-4 are unable to\nprecisely identify vulnerabilities in the code they generated; (3) GPT-3.5 and\nGPT-4 can achieve 33.2%~59.6% success rates in repairing the insecure code\nproduced by the 4 LLMs, but they both perform poorly when repairing\nself-produced code, indicating self-repair \"blind spots\". To address the\nlimitation of a single round of repair, we developed a lightweight tool that\nprompts LLMs to construct safer source code through an iterative repair\nprocedure based on the insights gained from our study. Experiments show that\nassisted by semantic analysis engines, our tool significantly improves the\nsuccess rates of repair to 65.9%~85.5%.\n","subjects":["Computing Research Repository/Software Engineering","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}