{"id":"2407.14790","title":"Step-by-Step Reasoning to Solve Grid Puzzles: Where do LLMs Falter?","authors":"Nemika Tyagi, Mihir Parmar, Mohith Kulkarni, Aswin RRV, Nisarg Patel,\n  Mutsumi Nakamura, Arindam Mitra, Chitta Baral","authorsParsed":[["Tyagi","Nemika",""],["Parmar","Mihir",""],["Kulkarni","Mohith",""],["RRV","Aswin",""],["Patel","Nisarg",""],["Nakamura","Mutsumi",""],["Mitra","Arindam",""],["Baral","Chitta",""]],"versions":[{"version":"v1","created":"Sat, 20 Jul 2024 07:43:07 GMT"}],"updateDate":"2024-07-23","timestamp":1721461387000,"abstract":"  Solving grid puzzles involves a significant amount of logical reasoning.\nHence, it is a good domain to evaluate the reasoning capability of a model\nwhich can then guide us to improve the reasoning ability of models. However,\nmost existing works evaluate only the final predicted answer of a puzzle,\nwithout delving into an in-depth analysis of the LLMs' reasoning chains (such\nas where they falter) or providing any finer metrics to evaluate them. Since\nLLMs may rely on simple heuristics or artifacts to predict the final answer, it\nis crucial to evaluate the generated reasoning chain beyond overall correctness\nmeasures, for accurately evaluating the reasoning abilities of LLMs. To this\nend, we first develop GridPuzzle, an evaluation dataset comprising 274\ngrid-based puzzles with different complexities. Second, we propose a new error\ntaxonomy derived from manual analysis of reasoning chains from LLMs including\nGPT-4, Claude-3, Gemini, Mistral, and Llama-2. Then, we develop an LLM-based\nframework for large-scale subjective evaluation (i.e., identifying errors) and\nan objective metric, PuzzleEval, to evaluate the correctness of reasoning\nchains. Evaluating reasoning chains from LLMs leads to several interesting\nfindings. We further show that existing prompting methods used for enhancing\nmodels' reasoning abilities do not improve performance on GridPuzzle. This\nhighlights the importance of understanding fine-grained errors and presents a\nchallenge for future research to enhance LLMs' puzzle-solving abilities by\ndeveloping methods that address these errors. Data and source code are\navailable at https://github.com/Mihir3009/GridPuzzle.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"Mc7IPNdWgML38qna0CSHNaHpnFWBb9NQWKFObl-wqoU","pdfSize":"5480956"}
