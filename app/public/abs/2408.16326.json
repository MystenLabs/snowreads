{"id":"2408.16326","title":"Critic-CoT: Boosting the reasoning abilities of large language model via\n  Chain-of-thoughts Critic","authors":"Xin Zheng, Jie Lou, Boxi Cao, Xueru Wen, Yuqiu Ji, Hongyu Lin, Yaojie\n  Lu, Xianpei Han, Debing Zhang, Le Sun","authorsParsed":[["Zheng","Xin",""],["Lou","Jie",""],["Cao","Boxi",""],["Wen","Xueru",""],["Ji","Yuqiu",""],["Lin","Hongyu",""],["Lu","Yaojie",""],["Han","Xianpei",""],["Zhang","Debing",""],["Sun","Le",""]],"versions":[{"version":"v1","created":"Thu, 29 Aug 2024 08:02:09 GMT"}],"updateDate":"2024-08-30","timestamp":1724918529000,"abstract":"  Self-critic has become an important mechanism for enhancing the reasoning\nperformance of LLMs. However, current approaches mainly involve basic prompts\nwithout further training, which tend to be over-simplified, leading to limited\naccuracy.Moreover, there is a lack of in-depth investigation of the\nrelationship between LLM's ability to criticism and its task-solving\nperformance.To address these issues, we propose Critic-CoT, a novel framework\nthat pushes LLMs toward System-2-like critic capability, via step-wise CoT\nreasoning format and distant-supervision data construction, without the need\nfor human annotation. Experiments on GSM8K and MATH show that via filtering out\ninvalid solutions or iterative refinement, our enhanced model boosts\ntask-solving performance, which demonstrates the effectiveness of our method.\nFurther, we find that training on critique and refinement alone improves the\ngeneration. We hope our work could shed light on future research on improving\nthe reasoning and critic ability of LLMs.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"vJaCzPDzNLLKIVD5ZTzgt0HhHUDqgD3UpYkCzx9I4z4","pdfSize":"457193"}
