{"id":"2407.08257","title":"Knowledge distillation to effectively attain both region-of-interest and\n  global semantics from an image where multiple objects appear","authors":"Seonwhee Jin","authorsParsed":[["Jin","Seonwhee",""]],"versions":[{"version":"v1","created":"Thu, 11 Jul 2024 07:57:33 GMT"}],"updateDate":"2024-07-12","timestamp":1720684653000,"abstract":"  Models based on convolutional neural networks (CNN) and transformers have\nsteadily been improved. They also have been applied in various computer vision\ndownstream tasks. However, in object detection tasks, accurately localizing and\nclassifying almost infinite categories of foods in images remains challenging.\nTo address these problems, we first segmented the food as the\nregion-of-interest (ROI) by using the segment-anything model (SAM) and masked\nthe rest of the region except ROI as black pixels. This process simplified the\nproblems into a single classification for which annotation and training were\nmuch simpler than object detection. The images in which only the ROI was\npreserved were fed as inputs to fine-tune various off-the-shelf models that\nencoded their own inductive biases. Among them, Data-efficient image\nTransformers (DeiTs) had the best classification performance. Nonetheless, when\nfoods' shapes and textures were similar, the contextual features of the\nROI-only images were not enough for accurate classification. Therefore, we\nintroduced a novel type of combined architecture, RveRNet, which consisted of\nROI, extra-ROI, and integration modules that allowed it to account for both the\nROI's and global contexts. The RveRNet's F1 score was 10% better than other\nindividual models when classifying ambiguous food images. If the RveRNet's\nmodules were DeiT with the knowledge distillation from the CNN, performed the\nbest. We investigated how architectures can be made robust against input noise\ncaused by permutation and translocation. The results indicated that there was a\ntrade-off between how much the CNN teacher's knowledge could be distilled to\nDeiT and DeiT's innate strength. Code is publicly available at:\nhttps://github.com/Seonwhee-Genome/RveRNet.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}