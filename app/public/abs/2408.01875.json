{"id":"2408.01875","title":"Re-Invoke: Tool Invocation Rewriting for Zero-Shot Tool Retrieval","authors":"Yanfei Chen, Jinsung Yoon, Devendra Singh Sachan, Qingze Wang, Vincent\n  Cohen-Addad, Mohammadhossein Bateni, Chen-Yu Lee, Tomas Pfister","authorsParsed":[["Chen","Yanfei",""],["Yoon","Jinsung",""],["Sachan","Devendra Singh",""],["Wang","Qingze",""],["Cohen-Addad","Vincent",""],["Bateni","Mohammadhossein",""],["Lee","Chen-Yu",""],["Pfister","Tomas",""]],"versions":[{"version":"v1","created":"Sat, 3 Aug 2024 22:49:27 GMT"}],"updateDate":"2024-08-06","timestamp":1722725367000,"abstract":"  Recent advances in large language models (LLMs) have enabled autonomous\nagents with complex reasoning and task-fulfillment capabilities using a wide\nrange of tools. However, effectively identifying the most relevant tools for a\ngiven task becomes a key bottleneck as the toolset size grows, hindering\nreliable tool utilization. To address this, we introduce Re-Invoke, an\nunsupervised tool retrieval method designed to scale effectively to large\ntoolsets without training. Specifically, we first generate a diverse set of\nsynthetic queries that comprehensively cover different aspects of the query\nspace associated with each tool document during the tool indexing phase.\nSecond, we leverage LLM's query understanding capabilities to extract key\ntool-related context and underlying intents from user queries during the\ninference phase. Finally, we employ a novel multi-view similarity ranking\nstrategy based on intents to pinpoint the most relevant tools for each query.\nOur evaluation demonstrates that Re-Invoke significantly outperforms\nstate-of-the-art alternatives in both single-tool and multi-tool scenarios, all\nwithin a fully unsupervised setting. Notably, on the ToolE datasets, we achieve\na 20% relative improvement in nDCG@5 for single-tool retrieval and a 39%\nimprovement for multi-tool retrieval.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}