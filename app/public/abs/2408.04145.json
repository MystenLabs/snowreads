{"id":"2408.04145","title":"ComKD-CLIP: Comprehensive Knowledge Distillation for Contrastive\n  Language-Image Pre-traning Model","authors":"Yifan Chen, Xiaozhen Qiao, Zhe Sun, and Xuelong Li","authorsParsed":[["Chen","Yifan",""],["Qiao","Xiaozhen",""],["Sun","Zhe",""],["Li","Xuelong",""]],"versions":[{"version":"v1","created":"Thu, 8 Aug 2024 01:12:21 GMT"},{"version":"v2","created":"Wed, 14 Aug 2024 07:43:06 GMT"},{"version":"v3","created":"Wed, 21 Aug 2024 01:36:27 GMT"}],"updateDate":"2024-08-22","timestamp":1723079541000,"abstract":"  Contrastive Language-Image Pre-training (CLIP) models excel in integrating\nsemantic information between images and text through contrastive learning\ntechniques. It has achieved remarkable performance in various multimodal tasks.\nHowever, the deployment of large CLIP models is hindered in resource-limited\nenvironments, while smaller models frequently fail to meet the performance\nbenchmarks required for practical applications. In this paper, we propose a\nnovel approach, ComKD-CLIP: Comprehensive Knowledge Distillation for\nContrastive Language-Image Pre-traning Model, which aims to comprehensively\ndistill the knowledge from a large teacher CLIP model into a smaller student\nmodel, ensuring comparable performance with significantly reduced parameters.\nComKD-CLIP is composed of two key mechanisms: Image Feature Alignment (IFAlign)\nand Educational Attention (EduAttention). IFAlign makes the image features\nextracted by the student model closely match those extracted by the teacher\nmodel, enabling the student to learn teacher's knowledge of extracting image\nfeatures. EduAttention explores the cross-relationships between text features\nextracted by the teacher model and image features extracted by the student\nmodel, enabling the student model to learn how the teacher model integrates\ntext-image features. In addition, ComKD-CLIP can refine the knowledge distilled\nfrom IFAlign and EduAttention by leveraging the text-image feature fusion\nresults of the teacher model, ensuring the student model accurately absorbs the\nteacher's knowledge. Extensive experiments conducted on 11 datasets have\ndemonstrated the superiority of the proposed method.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}