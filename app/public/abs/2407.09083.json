{"id":"2407.09083","title":"BKDSNN: Enhancing the Performance of Learning-based Spiking Neural\n  Networks Training with Blurred Knowledge Distillation","authors":"Zekai Xu, Kang You, Qinghai Guo, Xiang Wang and Zhezhi He","authorsParsed":[["Xu","Zekai",""],["You","Kang",""],["Guo","Qinghai",""],["Wang","Xiang",""],["He","Zhezhi",""]],"versions":[{"version":"v1","created":"Fri, 12 Jul 2024 08:17:24 GMT"},{"version":"v2","created":"Mon, 15 Jul 2024 02:19:34 GMT"}],"updateDate":"2024-08-21","timestamp":1720772244000,"abstract":"  Spiking neural networks (SNNs), which mimic biological neural system to\nconvey information via discrete spikes, are well known as brain-inspired models\nwith excellent computing efficiency. By utilizing the surrogate gradient\nestimation for discrete spikes, learning-based SNN training methods that can\nachieve ultra-low inference latency (number of time-step) emerge recently.\nNevertheless, due to the difficulty in deriving precise gradient estimation for\ndiscrete spikes using learning-based method, a distinct accuracy gap persists\nbetween SNN and its artificial neural networks (ANNs) counterpart. To address\nthe aforementioned issue, we propose a blurred knowledge distillation (BKD)\ntechnique, which leverages random blurred SNN feature to restore and imitate\nthe ANN feature. Note that, our BKD is applied upon the feature map right\nbefore the last layer of SNN, which can also mix with prior logits-based\nknowledge distillation for maximized accuracy boost. To our best knowledge, in\nthe category of learning-based methods, our work achieves state-of-the-art\nperformance for training SNNs on both static and neuromorphic datasets. On\nImageNet dataset, BKDSNN outperforms prior best results by 4.51% and 0.93% with\nthe network topology of CNN and Transformer respectively.\n","subjects":["Computing Research Repository/Neural and Evolutionary Computing"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"QWSRuyPDKlJkmHrBCThMD-JHjlgq4p0PjuOTitJZ_n4","pdfSize":"2794585","objectId":"0xe4c5628913b9150c19d3998054346a8f8c7d17a546227cd10e3690528d77c864","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
