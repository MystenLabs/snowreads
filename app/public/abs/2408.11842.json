{"id":"2408.11842","title":"Non-Causal to Causal SSL-Supported Transfer Learning: Towards a\n  High-Performance Low-Latency Speech Vocoder","authors":"Renzheng Shi and Andreas B\\\"ar and Marvin Sach and Wouter Tirry and\n  Tim Fingscheidt","authorsParsed":[["Shi","Renzheng",""],["BÃ¤r","Andreas",""],["Sach","Marvin",""],["Tirry","Wouter",""],["Fingscheidt","Tim",""]],"versions":[{"version":"v1","created":"Wed, 7 Aug 2024 12:49:40 GMT"},{"version":"v2","created":"Mon, 26 Aug 2024 12:01:07 GMT"}],"updateDate":"2024-08-27","timestamp":1723034980000,"abstract":"  Recently, BigVGAN has emerged as high-performance speech vocoder. Its\nsequence-to-sequence-based synthesis, however, prohibits usage in low-latency\nconversational applications. Our work addresses this shortcoming in three\nsteps. First, we introduce low latency into BigVGAN via implementing causal\nconvolutions, yielding decreased performance. Second, to regain performance, we\npropose a teacher-student transfer learning scheme to distill the high-delay\nnon-causal BigVGAN into our low-latency causal vocoder. Third, taking advantage\nof a self-supervised learning (SSL) model, in our case wav2vec 2.0, we align\nits encoder speech representations extracted from our low-latency causal\nvocoder to the ground truth ones. In speaker-independent settings, both\nproposed training schemes notably elevate the performance of our low-latency\nvocoder, closing up to the original high-delay BigVGAN. At only 21% higher\ncomplexity, our best small causal vocoder achieves 3.96 PESQ and 1.25 MCD,\nexcelling even the original small non-causal BigVGAN (3.64 PESQ) by 0.32 PESQ\nand 0.1 MCD points, respectively.\n","subjects":["Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}