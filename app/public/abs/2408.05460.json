{"id":"2408.05460","title":"Trajectory Planning for Teleoperated Space Manipulators Using Deep\n  Reinforcement Learning","authors":"Bo Xia, Xianru Tian, Bo Yuan, Zhiheng Li, Bin Liang, Xueqian Wang","authorsParsed":[["Xia","Bo",""],["Tian","Xianru",""],["Yuan","Bo",""],["Li","Zhiheng",""],["Liang","Bin",""],["Wang","Xueqian",""]],"versions":[{"version":"v1","created":"Sat, 10 Aug 2024 07:08:09 GMT"}],"updateDate":"2024-08-13","timestamp":1723273689000,"abstract":"  Trajectory planning for teleoperated space manipulators involves challenges\nsuch as accurately modeling system dynamics, particularly in free-floating\nmodes with non-holonomic constraints, and managing time delays that increase\nmodel uncertainty and affect control precision. Traditional teleoperation\nmethods rely on precise dynamic models requiring complex parameter\nidentification and calibration, while data-driven methods do not require prior\nknowledge but struggle with time delays. A novel framework utilizing deep\nreinforcement learning (DRL) is introduced to address these challenges. The\nframework incorporates three methods: Mapping, Prediction, and State\nAugmentation, to handle delays when delayed state information is received at\nthe master end. The Soft Actor Critic (SAC) algorithm processes the state\ninformation to compute the next action, which is then sent to the remote\nmanipulator for environmental interaction. Four environments are constructed\nusing the MuJoCo simulation platform to account for variations in base and\ntarget fixation: fixed base and target, fixed base with rotated target,\nfree-floating base with fixed target, and free-floating base with rotated\ntarget. Extensive experiments with both constant and random delays are\nconducted to evaluate the proposed methods. Results demonstrate that all three\nmethods effectively address trajectory planning challenges, with State\nAugmentation showing superior efficiency and robustness.\n","subjects":["Computing Research Repository/Robotics"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}