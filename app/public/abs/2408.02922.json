{"id":"2408.02922","title":"Pose Magic: Efficient and Temporally Consistent Human Pose Estimation\n  with a Hybrid Mamba-GCN Network","authors":"Xinyi Zhang, Qiqi Bao, Qinpeng Cui, Wenming Yang, Qingmin Liao","authorsParsed":[["Zhang","Xinyi",""],["Bao","Qiqi",""],["Cui","Qinpeng",""],["Yang","Wenming",""],["Liao","Qingmin",""]],"versions":[{"version":"v1","created":"Tue, 6 Aug 2024 03:15:18 GMT"},{"version":"v2","created":"Wed, 7 Aug 2024 06:44:24 GMT"}],"updateDate":"2024-08-08","timestamp":1722914118000,"abstract":"  Current state-of-the-art (SOTA) methods in 3D Human Pose Estimation (HPE) are\nprimarily based on Transformers. However, existing Transformer-based 3D HPE\nbackbones often encounter a trade-off between accuracy and computational\nefficiency. To resolve the above dilemma, in this work, we leverage recent\nadvances in state space models and utilize Mamba for high-quality and efficient\nlong-range modeling. Nonetheless, Mamba still faces challenges in precisely\nexploiting local dependencies between joints. To address these issues, we\npropose a new attention-free hybrid spatiotemporal architecture named Hybrid\nMamba-GCN (Pose Magic). This architecture introduces local enhancement with GCN\nby capturing relationships between neighboring joints, thus producing new\nrepresentations to complement Mamba's outputs. By adaptively fusing\nrepresentations from Mamba and GCN, Pose Magic demonstrates superior capability\nin learning the underlying 3D structure. To meet the requirements of real-time\ninference, we also provide a fully causal version. Extensive experiments show\nthat Pose Magic achieves new SOTA results ($\\downarrow 0.9 mm$) while saving\n$74.1\\%$ FLOPs. In addition, Pose Magic exhibits optimal motion consistency and\nthe ability to generalize to unseen sequence lengths.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}