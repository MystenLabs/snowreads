{"id":"2407.06964","title":"Parameter-Efficient and Memory-Efficient Tuning for Vision Transformer:\n  A Disentangled Approach","authors":"Taolin Zhang, Jiawang Bai, Zhihe Lu, Dongze Lian, Genping Wang,\n  Xinchao Wang, Shu-Tao Xia","authorsParsed":[["Zhang","Taolin",""],["Bai","Jiawang",""],["Lu","Zhihe",""],["Lian","Dongze",""],["Wang","Genping",""],["Wang","Xinchao",""],["Xia","Shu-Tao",""]],"versions":[{"version":"v1","created":"Tue, 9 Jul 2024 15:45:04 GMT"},{"version":"v2","created":"Sun, 14 Jul 2024 05:50:32 GMT"}],"updateDate":"2024-07-16","timestamp":1720539904000,"abstract":"  Recent works on parameter-efficient transfer learning (PETL) show the\npotential to adapt a pre-trained Vision Transformer to downstream recognition\ntasks with only a few learnable parameters. However, since they usually insert\nnew structures into the pre-trained model, entire intermediate features of that\nmodel are changed and thus need to be stored to be involved in\nback-propagation, resulting in memory-heavy training. We solve this problem\nfrom a novel disentangled perspective, i.e., dividing PETL into two aspects:\ntask-specific learning and pre-trained knowledge utilization. Specifically, we\nsynthesize the task-specific query with a learnable and lightweight module,\nwhich is independent of the pre-trained model. The synthesized query equipped\nwith task-specific knowledge serves to extract the useful features for\ndownstream tasks from the intermediate representations of the pre-trained model\nin a query-only manner. Built upon these features, a customized classification\nhead is proposed to make the prediction for the input sample. lightweight\narchitecture and avoids the use of heavy intermediate features for running\ngradient descent, it demonstrates limited memory usage in training. Extensive\nexperiments manifest that our method achieves state-of-the-art performance\nunder memory constraints, showcasing its applicability in real-world\nsituations.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}