{"id":"2407.05411","title":"Assessing Code Generation with Intermediate Languages","authors":"Xun Deng, Sicheng Zhong, Honghua Dong, Jingyu Hu, Sidi Mohamed\n  Beillahi, Xujie Si, Fan Long","authorsParsed":[["Deng","Xun",""],["Zhong","Sicheng",""],["Dong","Honghua",""],["Hu","Jingyu",""],["Beillahi","Sidi Mohamed",""],["Si","Xujie",""],["Long","Fan",""]],"versions":[{"version":"v1","created":"Sun, 7 Jul 2024 15:35:41 GMT"}],"updateDate":"2024-07-09","timestamp":1720366541000,"abstract":"  Intermediate step methodologies like chain of thoughts (COT) have\ndemonstrated effectiveness in enhancing the performance of Large Language\nModels (LLMs) on code generation. This study explores the utilization of\nintermediate languages, including various programming languages, natural\nlanguage solutions, and pseudo-code, and systematically evaluates their impact\non the performance of LLMs in code generation tasks. Our experiments encompass\neleven models across the CodeLlama, GPT, and Mistral families, as well as newly\nreleased smaller models. Our findings reveal that intermediate languages\ngenerally exhibit greater efficacy in larger models that have not yet achieved\nstate-of-the-art performance. Natural language consistently emerges as the most\neffective intermediate representation across all target languages. However, we\nobserve no universally effective intermediate formal language across different\nmodels and target languages. Furthermore, we uncover a weak correlation between\nthe correctness of intermediate solutions and final generation, suggesting that\nimprovements may stem from the chain-of-thought effect rather than\nlanguage-specific transfer. Interestingly, we discover that for GPT family\nmodels, prompting multiple times without explicit self-correction instructions\nyields performance gains across the studied languages.\n","subjects":["Computing Research Repository/Software Engineering"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}