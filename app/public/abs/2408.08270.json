{"id":"2408.08270","title":"HeightLane: BEV Heightmap guided 3D Lane Detection","authors":"Chaesong Park, Eunbin Seo, Jongwoo Lim","authorsParsed":[["Park","Chaesong",""],["Seo","Eunbin",""],["Lim","Jongwoo",""]],"versions":[{"version":"v1","created":"Thu, 15 Aug 2024 17:14:57 GMT"}],"updateDate":"2024-08-16","timestamp":1723742097000,"abstract":"  Accurate 3D lane detection from monocular images presents significant\nchallenges due to depth ambiguity and imperfect ground modeling. Previous\nattempts to model the ground have often used a planar ground assumption with\nlimited degrees of freedom, making them unsuitable for complex road\nenvironments with varying slopes. Our study introduces HeightLane, an\ninnovative method that predicts a height map from monocular images by creating\nanchors based on a multi-slope assumption. This approach provides a detailed\nand accurate representation of the ground. HeightLane employs the predicted\nheightmap along with a deformable attention-based spatial feature transform\nframework to efficiently convert 2D image features into 3D bird's eye view\n(BEV) features, enhancing spatial understanding and lane structure recognition.\nAdditionally, the heightmap is used for the positional encoding of BEV\nfeatures, further improving their spatial accuracy. This explicit view\ntransformation bridges the gap between front-view perceptions and spatially\naccurate BEV representations, significantly improving detection performance. To\naddress the lack of the necessary ground truth (GT) height map in the original\nOpenLane dataset, we leverage the Waymo dataset and accumulate its LiDAR data\nto generate a height map for the drivable area of each scene. The GT heightmaps\nare used to train the heightmap extraction module from monocular images.\nExtensive experiments on the OpenLane validation set show that HeightLane\nachieves state-of-the-art performance in terms of F-score, highlighting its\npotential in real-world applications.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}