{"id":"2408.08471","title":"Fairness Issues and Mitigations in (Differentially Private)\n  Socio-demographic Data Processes","authors":"Joonhyuk Ko, Juba Ziani, Saswat Das, Matt Williams, Ferdinando\n  Fioretto","authorsParsed":[["Ko","Joonhyuk",""],["Ziani","Juba",""],["Das","Saswat",""],["Williams","Matt",""],["Fioretto","Ferdinando",""]],"versions":[{"version":"v1","created":"Fri, 16 Aug 2024 01:13:36 GMT"}],"updateDate":"2024-08-19","timestamp":1723770816000,"abstract":"  Statistical agencies rely on sampling techniques to collect socio-demographic\ndata crucial for policy-making and resource allocation. This paper shows that\nsurveys of important societal relevance introduce sampling errors that unevenly\nimpact group-level estimates, thereby compromising fairness in downstream\ndecisions. To address these issues, this paper introduces an optimization\napproach modeled on real-world survey design processes, ensuring sampling costs\nare optimized while maintaining error margins within prescribed tolerances.\nAdditionally, privacy-preserving methods used to determine sampling rates can\nfurther impact these fairness issues. The paper explores the impact of\ndifferential privacy on the statistics informing the sampling process,\nrevealing a surprising effect: not only the expected negative effect from the\naddition of noise for differential privacy is negligible, but also this privacy\nnoise can in fact reduce unfairness as it positively biases smaller counts.\nThese findings are validated over an extensive analysis using datasets commonly\napplied in census statistics.\n","subjects":["Computing Research Repository/Cryptography and Security","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computers and Society"],"license":"http://creativecommons.org/licenses/by/4.0/"}