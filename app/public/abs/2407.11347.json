{"id":"2407.11347","title":"I$^2$-SLAM: Inverting Imaging Process for Robust Photorealistic Dense\n  SLAM","authors":"Gwangtak Bae, Changwoon Choi, Hyeongjun Heo, Sang Min Kim, Young Min\n  Kim","authorsParsed":[["Bae","Gwangtak",""],["Choi","Changwoon",""],["Heo","Hyeongjun",""],["Kim","Sang Min",""],["Kim","Young Min",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 03:31:33 GMT"}],"updateDate":"2024-07-17","timestamp":1721100693000,"abstract":"  We present an inverse image-formation module that can enhance the robustness\nof existing visual SLAM pipelines for casually captured scenarios. Casual video\ncaptures often suffer from motion blur and varying appearances, which degrade\nthe final quality of coherent 3D visual representation. We propose integrating\nthe physical imaging into the SLAM system, which employs linear HDR radiance\nmaps to collect measurements. Specifically, individual frames aggregate images\nof multiple poses along the camera trajectory to explain prevalent motion blur\nin hand-held videos. Additionally, we accommodate per-frame appearance\nvariation by dedicating explicit variables for image formation steps, namely\nwhite balance, exposure time, and camera response function. Through joint\noptimization of additional variables, the SLAM pipeline produces high-quality\nimages with more accurate trajectories. Extensive experiments demonstrate that\nour approach can be incorporated into recent visual SLAM pipelines using\nvarious scene representations, such as neural radiance fields or Gaussian\nsplatting.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}