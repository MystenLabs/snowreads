{"id":"2407.11260","title":"Quality Scalable Quantization Methodology for Deep Learning on Edge","authors":"Salman Abdul Khaliq and Rehan Hafiz","authorsParsed":[["Khaliq","Salman Abdul",""],["Hafiz","Rehan",""]],"versions":[{"version":"v1","created":"Mon, 15 Jul 2024 22:00:29 GMT"}],"updateDate":"2024-07-17","timestamp":1721080829000,"abstract":"  Deep Learning Architectures employ heavy computations and bulk of the\ncomputational energy is taken up by the convolution operations in the\nConvolutional Neural Networks. The objective of our proposed work is to reduce\nthe energy consumption and size of CNN for using machine learning techniques in\nedge computing on ubiquitous computing devices. We propose Systematic Quality\nScalable Design Methodology consisting of Quality Scalable Quantization on a\nhigher abstraction level and Quality Scalable Multipliers at lower abstraction\nlevel. The first component consists of parameter compression where we\napproximate representation of values in filters of deep learning models by\nencoding in 3 bits. A shift and scale based on-chip decoding hardware is\nproposed which can decode these 3-bit representations to recover approximate\nfilter values. The size of the DNN model is reduced this way and can be sent\nover a communication channel to be decoded on the edge computing devices. This\nway power is reduced by limiting data bits by approximation. In the second\ncomponent we propose a quality scalable multiplier which reduces the number of\npartial products by converting numbers in canonic sign digit representations\nand further approximating the number by reducing least significant bits. These\nquantized CNNs provide almost same ac-curacy as network with original weights\nwith little or no fine-tuning. The hardware for the adaptive multipliers\nutilize gate clocking for reducing energy consumption during multiplications.\nThe proposed methodology greatly reduces the memory and power requirements of\nDNN models making it a feasible approach to deploy Deep Learning on edge\ncomputing. The experiments done on LeNet and ConvNets show an increase upto 6%\nof zeros and memory savings upto 82.4919% while keeping the accuracy near the\nstate of the art.\n","subjects":["Computing Research Repository/Distributed, Parallel, and Cluster Computing","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"268NJb4vKXaBm4WAn_Qr_xlq7h1aBb73a7OW0jaOgI0","pdfSize":"1193785","objectId":"0xd2cb025f9dd9af6ba8de2c67dc8474e4012f44fe3fc093edf954335abc525820","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
