{"id":"2408.07514","title":"CNN-JEPA: Self-Supervised Pretraining Convolutional Neural Networks\n  Using Joint Embedding Predictive Architecture","authors":"Andr\\'as Kalapos, B\\'alint Gyires-T\\'oth","authorsParsed":[["Kalapos","András",""],["Gyires-Tóth","Bálint",""]],"versions":[{"version":"v1","created":"Wed, 14 Aug 2024 12:48:37 GMT"}],"updateDate":"2024-08-15","timestamp":1723639717000,"abstract":"  Self-supervised learning (SSL) has become an important approach in\npretraining large neural networks, enabling unprecedented scaling of model and\ndataset sizes. While recent advances like I-JEPA have shown promising results\nfor Vision Transformers, adapting such methods to Convolutional Neural Networks\n(CNNs) presents unique challenges. In this paper, we introduce CNN-JEPA, a\nnovel SSL method that successfully applies the joint embedding predictive\narchitecture approach to CNNs. Our method incorporates a sparse CNN encoder to\nhandle masked inputs, a fully convolutional predictor using depthwise separable\nconvolutions, and an improved masking strategy. We demonstrate that CNN-JEPA\noutperforms I-JEPA with ViT architectures on ImageNet-100, achieving 73.3%\nlinear top-1 accuracy with a standard ResNet-50 encoder. Compared to other\nCNN-based SSL methods, CNN-JEPA requires 17-35% less training time for the same\nnumber of epochs and approaches the linear and k-NN top-1 accuracies of BYOL,\nSimCLR, and VICReg. Our approach offers a simpler, more efficient alternative\nto existing SSL methods for CNNs, requiring minimal augmentations and no\nseparate projector network.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}