{"id":"2408.14991","title":"Speech Recognition Transformers: Topological-lingualism Perspective","authors":"Shruti Singh, Muskaan Singh, Virender Kadyan","authorsParsed":[["Singh","Shruti",""],["Singh","Muskaan",""],["Kadyan","Virender",""]],"versions":[{"version":"v1","created":"Tue, 27 Aug 2024 12:15:43 GMT"}],"updateDate":"2024-08-28","timestamp":1724760943000,"abstract":"  Transformers have evolved with great success in various artificial\nintelligence tasks. Thanks to our recent prevalence of self-attention\nmechanisms, which capture long-term dependency, phenomenal outcomes in speech\nprocessing and recognition tasks have been produced. The paper presents a\ncomprehensive survey of transformer techniques oriented in speech modality. The\nmain contents of this survey include (1) background of traditional ASR,\nend-to-end transformer ecosystem, and speech transformers (2) foundational\nmodels in a speech via lingualism paradigm, i.e., monolingual, bilingual,\nmultilingual, and cross-lingual (3) dataset and languages, acoustic features,\narchitecture, decoding, and evaluation metric from a specific topological\nlingualism perspective (4) popular speech transformer toolkit for building\nend-to-end ASR systems. Finally, highlight the discussion of open challenges\nand potential research directions for the community to conduct further research\nin this domain.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Sound","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"-A1WbjmkgtkmfEnTZKikYWaD1UQLeVcSxek4oTM3ow0","pdfSize":"865379"}
