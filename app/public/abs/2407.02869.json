{"id":"2407.02869","title":"PicoAudio: Enabling Precise Timestamp and Frequency Controllability of\n  Audio Events in Text-to-audio Generation","authors":"Zeyu Xie, Xuenan Xu, Zhizheng Wu, and Mengyue Wu","authorsParsed":[["Xie","Zeyu",""],["Xu","Xuenan",""],["Wu","Zhizheng",""],["Wu","Mengyue",""]],"versions":[{"version":"v1","created":"Wed, 3 Jul 2024 07:33:14 GMT"},{"version":"v2","created":"Wed, 17 Jul 2024 09:50:57 GMT"}],"updateDate":"2024-07-18","timestamp":1719991994000,"abstract":"  Recently, audio generation tasks have attracted considerable research\ninterests. Precise temporal controllability is essential to integrate audio\ngeneration with real applications. In this work, we propose a temporal\ncontrolled audio generation framework, PicoAudio. PicoAudio integrates temporal\ninformation to guide audio generation through tailored model design. It\nleverages data crawling, segmentation, filtering, and simulation of\nfine-grained temporally-aligned audio-text data. Both subjective and objective\nevaluations demonstrate that PicoAudio dramantically surpasses current\nstate-of-the-art generation models in terms of timestamp and occurrence\nfrequency controllability. The generated samples are available on the demo\nwebsite https://zeyuxie29.github.io/PicoAudio.github.io.\n","subjects":["Computing Research Repository/Sound","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}