{"id":"2407.11266","title":"Towards High-Quality 3D Motion Transfer with Realistic Apparel Animation","authors":"Rong Wang, Wei Mao, Changsheng Lu, Hongdong Li","authorsParsed":[["Wang","Rong",""],["Mao","Wei",""],["Lu","Changsheng",""],["Li","Hongdong",""]],"versions":[{"version":"v1","created":"Mon, 15 Jul 2024 22:17:35 GMT"}],"updateDate":"2024-07-17","timestamp":1721081855000,"abstract":"  Animating stylized characters to match a reference motion sequence is a\nhighly demanded task in film and gaming industries. Existing methods mostly\nfocus on rigid deformations of characters' body, neglecting local deformations\non the apparel driven by physical dynamics. They deform apparel the same way as\nthe body, leading to results with limited details and unrealistic artifacts,\ne.g. body-apparel penetration. In contrast, we present a novel method aiming\nfor high-quality motion transfer with realistic apparel animation. As existing\ndatasets lack annotations necessary for generating realistic apparel\nanimations, we build a new dataset named MMDMC, which combines stylized\ncharacters from the MikuMikuDance community with real-world Motion Capture\ndata. We then propose a data-driven pipeline that learns to disentangle body\nand apparel deformations via two neural deformation modules. For body parts, we\npropose a geodesic attention block to effectively incorporate semantic priors\ninto skeletal body deformation to tackle complex body shapes for stylized\ncharacters. Since apparel motion can significantly deviate from respective body\njoints, we propose to model apparel deformation in a non-linear vertex\ndisplacement field conditioned on its historic states. Extensive experiments\nshow that our method produces results with superior quality for various types\nof apparel. Our dataset is released in https://github.com/rongakowang/MMDMC.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}