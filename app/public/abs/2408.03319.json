{"id":"2408.03319","title":"Training LLMs to Recognize Hedges in Spontaneous Narratives","authors":"Amie J. Paige, Adil Soubki, John Murzaku, Owen Rambow, Susan E.\n  Brennan","authorsParsed":[["Paige","Amie J.",""],["Soubki","Adil",""],["Murzaku","John",""],["Rambow","Owen",""],["Brennan","Susan E.",""]],"versions":[{"version":"v1","created":"Tue, 6 Aug 2024 17:51:42 GMT"}],"updateDate":"2024-08-07","timestamp":1722966702000,"abstract":"  Hedges allow speakers to mark utterances as provisional, whether to signal\nnon-prototypicality or \"fuzziness\", to indicate a lack of commitment to an\nutterance, to attribute responsibility for a statement to someone else, to\ninvite input from a partner, or to soften critical feedback in the service of\nface-management needs. Here we focus on hedges in an experimentally\nparameterized corpus of 63 Roadrunner cartoon narratives spontaneously produced\nfrom memory by 21 speakers for co-present addressees, transcribed to text\n(Galati and Brennan, 2010). We created a gold standard of hedges annotated by\nhuman coders (the Roadrunner-Hedge corpus) and compared three LLM-based\napproaches for hedge detection: fine-tuning BERT, and zero and few-shot\nprompting with GPT-4o and LLaMA-3. The best-performing approach was a\nfine-tuned BERT model, followed by few-shot GPT-4o. After an error analysis on\nthe top performing approaches, we used an LLM-in-the-Loop approach to improve\nthe gold standard coding, as well as to highlight cases in which hedges are\nambiguous in linguistically interesting ways that will guide future research.\nThis is the first step in our research program to train LLMs to interpret and\ngenerate collateral signals appropriately and meaningfully in conversation.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}