{"id":"2408.07395","title":"Improving Global Parameter-sharing in Physically Heterogeneous\n  Multi-agent Reinforcement Learning with Unified Action Space","authors":"Xiaoyang Yu, Youfang Lin, Shuo Wang, Kai Lv, Sheng Han","authorsParsed":[["Yu","Xiaoyang",""],["Lin","Youfang",""],["Wang","Shuo",""],["Lv","Kai",""],["Han","Sheng",""]],"versions":[{"version":"v1","created":"Wed, 14 Aug 2024 09:15:11 GMT"}],"updateDate":"2024-08-15","timestamp":1723626911000,"abstract":"  In a multi-agent system (MAS), action semantics indicates the different\ninfluences of agents' actions toward other entities, and can be used to divide\nagents into groups in a physically heterogeneous MAS. Previous multi-agent\nreinforcement learning (MARL) algorithms apply global parameter-sharing across\ndifferent types of heterogeneous agents without careful discrimination of\ndifferent action semantics. This common implementation decreases the\ncooperation and coordination between agents in complex situations. However,\nfully independent agent parameters dramatically increase the computational cost\nand training difficulty. In order to benefit from the usage of different action\nsemantics while also maintaining a proper parameter-sharing structure, we\nintroduce the Unified Action Space (UAS) to fulfill the requirement. The UAS is\nthe union set of all agent actions with different semantics. All agents first\ncalculate their unified representation in the UAS, and then generate their\nheterogeneous action policies using different available-action-masks. To\nfurther improve the training of extra UAS parameters, we introduce a\nCross-Group Inverse (CGI) loss to predict other groups' agent policies with the\ntrajectory information. As a universal method for solving the physically\nheterogeneous MARL problem, we implement the UAS adding to both value-based and\npolicy-based MARL algorithms, and propose two practical algorithms: U-QMIX and\nU-MAPPO. Experimental results in the SMAC environment prove the effectiveness\nof both U-QMIX and U-MAPPO compared with several state-of-the-art MARL methods.\n","subjects":["Computing Research Repository/Multiagent Systems","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}