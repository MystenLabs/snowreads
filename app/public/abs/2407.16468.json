{"id":"2407.16468","title":"Enhancing GNNs Performance on Combinatorial Optimization by Recurrent\n  Feature Update","authors":"Daria Pugacheva, Andrei Ermakov, Igor Lyskov, Ilya Makarov and Yuriy\n  Zotov","authorsParsed":[["Pugacheva","Daria",""],["Ermakov","Andrei",""],["Lyskov","Igor",""],["Makarov","Ilya",""],["Zotov","Yuriy",""]],"versions":[{"version":"v1","created":"Tue, 23 Jul 2024 13:34:35 GMT"}],"updateDate":"2024-07-24","timestamp":1721741675000,"abstract":"  Combinatorial optimization (CO) problems are crucial in various scientific\nand industrial applications. Recently, researchers have proposed using\nunsupervised Graph Neural Networks (GNNs) to address NP-hard combinatorial\noptimization problems, which can be reformulated as Quadratic Unconstrained\nBinary Optimization (QUBO) problems. GNNs have demonstrated high performance\nwith nearly linear scalability and significantly outperformed classic\nheuristic-based algorithms in terms of computational efficiency on large-scale\nproblems. However, when utilizing standard node features, GNNs tend to get\ntrapped to suboptimal local minima of the energy landscape, resulting in low\nquality solutions. We introduce a novel algorithm, denoted hereafter as\nQRF-GNN, leveraging the power of GNNs to efficiently solve CO problems with\nQUBO formulation. It relies on unsupervised learning by minimizing the loss\nfunction derived from QUBO relaxation. The proposed key components of the\narchitecture include the recurrent use of intermediate GNN predictions,\nparallel convolutional layers and combination of static node features as input.\nAltogether, it helps to adapt the intermediate solution candidate to minimize\nQUBO-based loss function, taking into account not only static graph features,\nbut also intermediate predictions treated as dynamic, i.e. iteratively changing\nrecurrent features. The performance of the proposed algorithm has been\nevaluated on the canonical benchmark datasets for maximum cut, graph coloring\nand maximum independent set problems. Results of experiments show that QRF-GNN\ndrastically surpasses existing learning-based approaches and is comparable to\nthe state-of-the-art conventional heuristics, improving their scalability on\nlarge instances.\n","subjects":["Computing Research Repository/Machine Learning","Mathematics/Optimization and Control"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"0EI8Zk1GwtTUcZKrk49EtAUS_BGdApvSeZKKDdUUT-k","pdfSize":"1353227"}
