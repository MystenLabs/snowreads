{"id":"2408.11287","title":"Taming Generative Diffusion for Universal Blind Image Restoration","authors":"Siwei Tu, Weidong Yang, Ben Fei","authorsParsed":[["Tu","Siwei",""],["Yang","Weidong",""],["Fei","Ben",""]],"versions":[{"version":"v1","created":"Wed, 21 Aug 2024 02:19:54 GMT"}],"updateDate":"2024-08-22","timestamp":1724206794000,"abstract":"  Diffusion models have been widely utilized for image restoration. However,\nprevious blind image restoration methods still need to assume the type of\ndegradation model while leaving the parameters to be optimized, limiting their\nreal-world applications. Therefore, we aim to tame generative diffusion prior\nfor universal blind image restoration dubbed BIR-D, which utilizes an\noptimizable convolutional kernel to simulate the degradation model and\ndynamically update the parameters of the kernel in the diffusion steps,\nenabling it to achieve blind image restoration results even in various complex\nsituations. Besides, based on mathematical reasoning, we have provided an\nempirical formula for the chosen of adaptive guidance scale, eliminating the\nneed for a grid search for the optimal parameter. Experimentally, Our BIR-D has\ndemonstrated superior practicality and versatility than off-the-shelf\nunsupervised methods across various tasks both on real-world and synthetic\ndatasets, qualitatively and quantitatively. BIR-D is able to fulfill\nmulti-guidance blind image restoration. Moreover, BIR-D can also restore images\nthat undergo multiple and complicated degradations, demonstrating the practical\napplications.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}