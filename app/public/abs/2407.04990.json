{"id":"2407.04990","title":"Conditional Semi-Supervised Data Augmentation for Spam Message Detection\n  with Low Resource Data","authors":"Ulin Nuha, Chih-Hsueh Lin","authorsParsed":[["Nuha","Ulin",""],["Lin","Chih-Hsueh",""]],"versions":[{"version":"v1","created":"Sat, 6 Jul 2024 07:51:24 GMT"}],"updateDate":"2024-07-09","timestamp":1720252284000,"abstract":"  Several machine learning schemes have attempted to perform the detection of\nspam messages. However, those schemes mostly require a huge amount of labeled\ndata. The existing techniques addressing the lack of data availability have\nissues with effectiveness and robustness. Therefore, this paper proposes a\nconditional semi-supervised data augmentation (CSSDA) for a spam detection\nmodel lacking the availability of data. The main architecture of CSSDA\ncomprises feature extraction and enhanced generative network. Here, we exploit\nunlabeled data for data augmentation to extend training data. The enhanced\ngenerative in our proposed scheme produces latent variables as fake samples\nfrom unlabeled data through a conditional scheme. Latent variables can come\nfrom labeled and unlabeled data as the input for the final classifier in our\nspam detection model. The experimental results indicate that our proposed CSSDA\nachieves excellent results compared to several related methods both exploiting\nunlabeled data and not. In the experiment stage with various amounts of\nunlabeled data, CSSDA is the only robust model that obtains a balanced accuracy\nof about 85% when the availability of labeled data is large. We also conduct\nseveral ablation studies to investigate our proposed scheme in detail. The\nresult also shows that several ablation studies strengthen our proposed\ninnovations. These experiments indicate that unlabeled data has a significant\ncontribution to data augmentation using the conditional semi-supervised scheme\nfor spam detection.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}