{"id":"2407.10780","title":"Correlations Are Ruining Your Gradient Descent","authors":"Nasir Ahmad","authorsParsed":[["Ahmad","Nasir",""]],"versions":[{"version":"v1","created":"Mon, 15 Jul 2024 14:59:43 GMT"}],"updateDate":"2024-07-16","timestamp":1721055583000,"abstract":"  Herein the topics of (natural) gradient descent, data decorrelation, and\napproximate methods for backpropagation are brought into a dialogue. Natural\ngradient descent illuminates how gradient vectors, pointing at directions of\nsteepest descent, can be improved by considering the local curvature of loss\nlandscapes. We extend this perspective and show that to fully solve the problem\nilluminated by natural gradients in neural networks, one must recognise that\ncorrelations in the data at any linear transformation, including node responses\nat every layer of a neural network, cause a non-orthonormal relationship\nbetween the model's parameters. To solve this requires a solution to\ndecorrelate inputs at each individual layer of a neural network. We describe a\nrange of methods which have been proposed for decorrelation and whitening of\nnode output, while providing a novel method specifically useful for distributed\ncomputing and computational neuroscience. Implementing decorrelation within\nmulti-layer neural networks, we can show that not only is training via\nbackpropagation sped up significantly but also existing approximations of\nbackpropagation, which have failed catastrophically in the past, are made\nperformant once more. This has the potential to provide a route forward for\napproximate gradient descent methods which have previously been discarded,\ntraining approaches for analogue and neuromorphic hardware, and potentially\ninsights as to the efficacy and utility of decorrelation processes in the\nbrain.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Neural and Evolutionary Computing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}