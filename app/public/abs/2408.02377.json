{"id":"2408.02377","title":"A Few-Shot Approach for Relation Extraction Domain Adaptation using\n  Large Language Models","authors":"Vanni Zavarella and Juan Carlos Gamero-Salinas and Sergio Consoli","authorsParsed":[["Zavarella","Vanni",""],["Gamero-Salinas","Juan Carlos",""],["Consoli","Sergio",""]],"versions":[{"version":"v1","created":"Mon, 5 Aug 2024 11:06:36 GMT"}],"updateDate":"2024-08-06","timestamp":1722855996000,"abstract":"  Knowledge graphs (KGs) have been successfully applied to the analysis of\ncomplex scientific and technological domains, with automatic KG generation\nmethods typically building upon relation extraction models capturing\nfine-grained relations between domain entities in text. While these relations\nare fully applicable across scientific areas, existing models are trained on\nfew domain-specific datasets such as SciERC and do not perform well on new\ntarget domains. In this paper, we experiment with leveraging in-context\nlearning capabilities of Large Language Models to perform schema-constrained\ndata annotation, collecting in-domain training instances for a\nTransformer-based relation extraction model deployed on titles and abstracts of\nresearch papers in the Architecture, Construction, Engineering and Operations\n(AECO) domain. By assessing the performance gain with respect to a baseline\nDeep Learning architecture trained on off-domain data, we show that by using a\nfew-shot learning strategy with structured prompts and only minimal expert\nannotation the presented approach can potentially support domain adaptation of\na science KG generation model.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"XX1SKhtZ3CC56t9uPu42zzBt3I4i4tVLgX0kmNrq4J0","pdfSize":"925213"}
