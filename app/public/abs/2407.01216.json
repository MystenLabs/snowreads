{"id":"2407.01216","title":"Let Hybrid A* Path Planner Obey Traffic Rules: A Deep Reinforcement\n  Learning-Based Planning Framework","authors":"Xibo Li, Shruti Patel and Christof B\\\"uskens","authorsParsed":[["Li","Xibo",""],["Patel","Shruti",""],["BÃ¼skens","Christof",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 12:00:10 GMT"}],"updateDate":"2024-07-02","timestamp":1719835210000,"abstract":"  Deep reinforcement learning (DRL) allows a system to interact with its\nenvironment and take actions by training an efficient policy that maximizes\nself-defined rewards. In autonomous driving, it can be used as a strategy for\nhigh-level decision making, whereas low-level algorithms such as the hybrid A*\npath planning have proven their ability to solve the local trajectory planning\nproblem. In this work, we combine these two methods where the DRL makes\nhigh-level decisions such as lane change commands. After obtaining the lane\nchange command, the hybrid A* planner is able to generate a collision-free\ntrajectory to be executed by a model predictive controller (MPC). In addition,\nthe DRL algorithm is able to keep the lane change command consistent within a\nchosen time-period. Traffic rules are implemented using linear temporal logic\n(LTL), which is then utilized as a reward function in DRL. Furthermore, we\nvalidate the proposed method on a real system to demonstrate its feasibility\nfrom simulation to implementation on real hardware.\n","subjects":["Computing Research Repository/Robotics","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"LoO9lcPewO3BCC4HYoqHdp7fIO0nEr4Imkb-8nkJ5zQ","pdfSize":"1313768","objectId":"0x45577c02e0b828eb20d333938e48cfeed18755c18d6f5b9e6386b0d3c045113a","registeredEpoch":"3","certifiedEpoch":"3","startEpoch":"3","endEpoch":"203"}
