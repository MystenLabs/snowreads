{"id":"2407.14110","title":"MC-PanDA: Mask Confidence for Panoptic Domain Adaptation","authors":"Ivan Martinovi\\'c, Josip \\v{S}ari\\'c, Sini\\v{s}a \\v{S}egvi\\'c","authorsParsed":[["Martinović","Ivan",""],["Šarić","Josip",""],["Šegvić","Siniša",""]],"versions":[{"version":"v1","created":"Fri, 19 Jul 2024 08:28:35 GMT"}],"updateDate":"2024-07-22","timestamp":1721377715000,"abstract":"  Domain adaptive panoptic segmentation promises to resolve the long tail of\ncorner cases in natural scene understanding. Previous state of the art\naddresses this problem with cross-task consistency, careful system-level\noptimization and heuristic improvement of teacher predictions. In contrast, we\npropose to build upon remarkable capability of mask transformers to estimate\ntheir own prediction uncertainty. Our method avoids noise amplification by\nleveraging fine-grained confidence of panoptic teacher predictions. In\nparticular, we modulate the loss with mask-wide confidence and discourage\nback-propagation in pixels with uncertain teacher or confident student.\nExperimental evaluation on standard benchmarks reveals a substantial\ncontribution of the proposed selection techniques. We report 47.4 PQ on Synthia\nto Cityscapes, which corresponds to an improvement of 6.2 percentage points\nover the state of the art. The source code is available at\nhttps://github.com/helen1c/MC-PanDA.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/"}