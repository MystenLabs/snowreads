{"id":"2408.16167","title":"Free Lunch in the Forest: Functionally-Identical Pruning of Boosted Tree\n  Ensembles","authors":"Youssouf Emine, Alexandre Forel, Idriss Malek and Thibaut Vidal","authorsParsed":[["Emine","Youssouf",""],["Forel","Alexandre",""],["Malek","Idriss",""],["Vidal","Thibaut",""]],"versions":[{"version":"v1","created":"Wed, 28 Aug 2024 23:15:46 GMT"}],"updateDate":"2024-08-30","timestamp":1724886946000,"abstract":"  Tree ensembles, including boosting methods, are highly effective and widely\nused for tabular data. However, large ensembles lack interpretability and\nrequire longer inference times. We introduce a method to prune a tree ensemble\ninto a reduced version that is \"functionally identical\" to the original model.\nIn other words, our method guarantees that the prediction function stays\nunchanged for any possible input. As a consequence, this pruning algorithm is\nlossless for any aggregated metric. We formalize the problem of functionally\nidentical pruning on ensembles, introduce an exact optimization model, and\nprovide a fast yet highly effective method to prune large ensembles. Our\nalgorithm iteratively prunes considering a finite set of points, which is\nincrementally augmented using an adversarial model. In multiple computational\nexperiments, we show that our approach is a \"free lunch\", significantly\nreducing the ensemble size without altering the model's behavior. Thus, we can\npreserve state-of-the-art performance at a fraction of the original model's\nsize.\n","subjects":["Computing Research Repository/Machine Learning","Mathematics/Optimization and Control"],"license":"http://creativecommons.org/licenses/by/4.0/"}