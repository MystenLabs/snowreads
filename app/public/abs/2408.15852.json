{"id":"2408.15852","title":"chemtrain: Learning Deep Potential Models via Automatic Differentiation\n  and Statistical Physics","authors":"Paul Fuchs, Stephan Thaler, Sebastien R\\\"ocken and Julija Zavadlav","authorsParsed":[["Fuchs","Paul",""],["Thaler","Stephan",""],["RÃ¶cken","Sebastien",""],["Zavadlav","Julija",""]],"versions":[{"version":"v1","created":"Wed, 28 Aug 2024 15:14:58 GMT"}],"updateDate":"2024-08-29","timestamp":1724858098000,"abstract":"  Neural Networks (NNs) are promising models for refining the accuracy of\nmolecular dynamics, potentially opening up new fields of application. Typically\ntrained bottom-up, atomistic NN potential models can reach first-principle\naccuracy, while coarse-grained implicit solvent NN potentials surpass classical\ncontinuum solvent models. However, overcoming the limitations of costly\ngeneration of accurate reference data and data inefficiency of common bottom-up\ntraining demands efficient incorporation of data from many sources. This paper\nintroduces the framework chemtrain to learn sophisticated NN potential models\nthrough customizable training routines and advanced training algorithms. These\nroutines can combine multiple top-down and bottom-up algorithms, e.g., to\nincorporate both experimental and simulation data or pre-train potentials with\nless costly algorithms. chemtrain provides an object-oriented high-level\ninterface to simplify the creation of custom routines. On the lower level,\nchemtrain relies on JAX to compute gradients and scale the computations to use\navailable resources. We demonstrate the simplicity and importance of combining\nmultiple algorithms in the examples of parametrizing an all-atomistic model of\ntitanium and a coarse-grained implicit solvent model of alanine dipeptide.\n","subjects":["Physics/Chemical Physics","Computing Research Repository/Machine Learning","Physics/Computational Physics"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}