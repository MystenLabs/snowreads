{"id":"2407.16034","title":"Efficient Replay Memory Architectures in Multi-Agent Reinforcement\n  Learning for Traffic Congestion Control","authors":"Mukul Chodhary, Kevin Octavian, SooJean Han","authorsParsed":[["Chodhary","Mukul",""],["Octavian","Kevin",""],["Han","SooJean",""]],"versions":[{"version":"v1","created":"Mon, 22 Jul 2024 20:20:04 GMT"}],"updateDate":"2024-07-24","timestamp":1721679604000,"abstract":"  Episodic control, inspired by the role of episodic memory in the human brain,\nhas been shown to improve the sample inefficiency of model-free reinforcement\nlearning by reusing high-return past experiences. However, the memory growth of\nepisodic control is undesirable in large-scale multi-agent problems such as\nvehicle traffic management. This paper proposes a novel replay memory\narchitecture called Dual-Memory Integrated Learning, to augment to multi-agent\nreinforcement learning methods for congestion control via adaptive light signal\nscheduling. Our dual-memory architecture mimics two core capabilities of human\ndecision-making. First, it relies on diverse types of memory--semantic and\nepisodic, short-term and long-term--in order to remember high-return states\nthat occur often in the network and filter out states that don't. Second, it\nemploys equivalence classes to group together similar state-action pairs and\nthat can be controlled using the same action (i.e., light signal sequence).\nTheoretical analyses establish memory growth bounds, and simulation experiments\non several intersection networks showcase improved congestion performance\n(e.g., vehicle throughput) from our method.\n","subjects":["Electrical Engineering and Systems Science/Systems and Control","Computing Research Repository/Systems and Control"],"license":"http://creativecommons.org/licenses/by/4.0/"}