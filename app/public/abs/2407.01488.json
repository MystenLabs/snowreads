{"id":"2407.01488","title":"LEXI: Large Language Models Experimentation Interface","authors":"Guy Laban, Tomer Laban, Hatice Gunes","authorsParsed":[["Laban","Guy",""],["Laban","Tomer",""],["Gunes","Hatice",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 17:24:30 GMT"},{"version":"v2","created":"Tue, 2 Jul 2024 15:31:41 GMT"}],"updateDate":"2024-07-03","timestamp":1719854670000,"abstract":"  The recent developments in Large Language Models (LLM), mark a significant\nmoment in the research and development of social interactions with artificial\nagents. These agents are widely deployed in a variety of settings, with\npotential impact on users. However, the study of social interactions with\nagents powered by LLM is still emerging, limited by access to the technology\nand to data, the absence of standardised interfaces, and challenges to\nestablishing controlled experimental setups using the currently available\nbusiness-oriented platforms. To answer these gaps, we developed LEXI, LLMs\nExperimentation Interface, an open-source tool enabling the deployment of\nartificial agents powered by LLM in social interaction behavioural experiments.\nUsing a graphical interface, LEXI allows researchers to build agents, and\ndeploy them in experimental setups along with forms and questionnaires while\ncollecting interaction logs and self-reported data. The outcomes of usability\ntesting indicate LEXI's broad utility, high usability and minimum mental\nworkload requirement, with distinctive benefits observed across disciplines. A\nproof-of-concept study exploring the tool's efficacy in evaluating social HAIs\nwas conducted, resulting in high-quality data. A comparison of empathetic\nversus neutral agents indicated that people perceive empathetic agents as more\nsocial, and write longer and more positive messages towards them.\n","subjects":["Computing Research Repository/Human-Computer Interaction"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/"}