{"id":"2407.04411","title":"Waterfall: Framework for Robust and Scalable Text Watermarking","authors":"Gregory Kang Ruey Lau, Xinyuan Niu, Hieu Dao, Jiangwei Chen,\n  Chuan-Sheng Foo, Bryan Kian Hsiang Low","authorsParsed":[["Lau","Gregory Kang Ruey",""],["Niu","Xinyuan",""],["Dao","Hieu",""],["Chen","Jiangwei",""],["Foo","Chuan-Sheng",""],["Low","Bryan Kian Hsiang",""]],"versions":[{"version":"v1","created":"Fri, 5 Jul 2024 10:51:33 GMT"}],"updateDate":"2024-07-08","timestamp":1720176693000,"abstract":"  Protecting intellectual property (IP) of text such as articles and code is\nincreasingly important, especially as sophisticated attacks become possible,\nsuch as paraphrasing by large language models (LLMs) or even unauthorized\ntraining of LLMs on copyrighted text to infringe such IP. However, existing\ntext watermarking methods are not robust enough against such attacks nor\nscalable to millions of users for practical implementation. In this paper, we\npropose Waterfall, the first training-free framework for robust and scalable\ntext watermarking applicable across multiple text types (e.g., articles, code)\nand languages supportable by LLMs, for general text and LLM data provenance.\nWaterfall comprises several key innovations, such as being the first to use LLM\nas paraphrasers for watermarking along with a novel combination of techniques\nthat are surprisingly effective in achieving robust verifiability and\nscalability. We empirically demonstrate that Waterfall achieves significantly\nbetter scalability, robust verifiability, and computational efficiency compared\nto SOTA article-text watermarking methods, and also showed how it could be\ndirectly applied to the watermarking of code.\n","subjects":["Computing Research Repository/Cryptography and Security","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}