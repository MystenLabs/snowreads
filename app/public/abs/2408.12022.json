{"id":"2408.12022","title":"Understanding Epistemic Language with a Bayesian Theory of Mind","authors":"Lance Ying, Tan Zhi-Xuan, Lionel Wong, Vikash Mansinghka, Joshua B.\n  Tenenbaum","authorsParsed":[["Ying","Lance",""],["Zhi-Xuan","Tan",""],["Wong","Lionel",""],["Mansinghka","Vikash",""],["Tenenbaum","Joshua B.",""]],"versions":[{"version":"v1","created":"Wed, 21 Aug 2024 22:29:56 GMT"}],"updateDate":"2024-08-23","timestamp":1724279396000,"abstract":"  How do people understand and evaluate claims about others' beliefs, even\nthough these beliefs cannot be directly observed? In this paper, we introduce a\ncognitive model of epistemic language interpretation, grounded in Bayesian\ninferences about other agents' goals, beliefs, and intentions: a\nlanguage-augmented Bayesian theory-of-mind (LaBToM). By translating natural\nlanguage into an epistemic ``language-of-thought'', then evaluating these\ntranslations against the inferences produced by inverting a probabilistic\ngenerative model of rational action and perception, LaBToM captures graded\nplausibility judgments about epistemic claims. We validate our model in an\nexperiment where participants watch an agent navigate a maze to find keys\nhidden in boxes needed to reach their goal, then rate sentences about the\nagent's beliefs. In contrast with multimodal LLMs (GPT-4o, Gemini Pro) and\nablated models, our model correlates highly with human judgments for a wide\nrange of expressions, including modal language, uncertainty expressions,\nknowledge claims, likelihood comparisons, and attributions of false belief.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"bDJ1NFqc1Vw40VorNCmPndwcnDRMREyoeJOVQWcUsL0","pdfSize":"2549525"}
