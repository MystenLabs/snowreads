{"id":"2408.03816","title":"Early Prediction of Causes (not Effects) in Healthcare by Long-Term\n  Clinical Time Series Forecasting","authors":"Michael Staniek, Marius Fracarolli, Michael Hagmann, Stefan Riezler","authorsParsed":[["Staniek","Michael",""],["Fracarolli","Marius",""],["Hagmann","Michael",""],["Riezler","Stefan",""]],"versions":[{"version":"v1","created":"Wed, 7 Aug 2024 14:52:06 GMT"},{"version":"v2","created":"Mon, 26 Aug 2024 13:12:45 GMT"}],"updateDate":"2024-08-27","timestamp":1723042326000,"abstract":"  Machine learning for early syndrome diagnosis aims to solve the intricate\ntask of predicting a ground truth label that most often is the outcome (effect)\nof a medical consensus definition applied to observed clinical measurements\n(causes), given clinical measurements observed several hours before. Instead of\nfocusing on the prediction of the future effect, we propose to directly predict\nthe causes via time series forecasting (TSF) of clinical variables and\ndetermine the effect by applying the gold standard consensus definition to the\nforecasted values. This method has the invaluable advantage of being\nstraightforwardly interpretable to clinical practitioners, and because model\ntraining does not rely on a particular label anymore, the forecasted data can\nbe used to predict any consensus-based label. We exemplify our method by means\nof long-term TSF with Transformer models, with a focus on accurate prediction\nof sparse clinical variables involved in the SOFA-based Sepsis-3 definition and\nthe new Simplified Acute Physiology Score (SAPS-II) definition. Our experiments\nare conducted on two datasets and show that contrary to recent proposals which\nadvocate set function encoders for time series and direct multi-step decoders,\nbest results are achieved by a combination of standard dense encoders with\niterative multi-step decoders. The key for success of iterative multi-step\ndecoding can be attributed to its ability to capture cross-variate dependencies\nand to a student forcing training strategy that teaches the model to rely on\nits own previous time step predictions for the next time step prediction.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by-sa/4.0/","blobId":"g5xaUhFCYJniq11cpZN0HUsRU77V8z4EEfE0u3VcsJQ","pdfSize":"1401082"}
