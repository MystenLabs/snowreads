{"id":"2407.20446","title":"MEVDT: Multi-Modal Event-Based Vehicle Detection and Tracking Dataset","authors":"Zaid A. El Shair and Samir A. Rawashdeh","authorsParsed":[["Shair","Zaid A. El",""],["Rawashdeh","Samir A.",""]],"versions":[{"version":"v1","created":"Mon, 29 Jul 2024 22:57:20 GMT"}],"updateDate":"2024-07-31","timestamp":1722293840000,"abstract":"  In this data article, we introduce the Multi-Modal Event-based Vehicle\nDetection and Tracking (MEVDT) dataset. This dataset provides a synchronized\nstream of event data and grayscale images of traffic scenes, captured using the\nDynamic and Active-Pixel Vision Sensor (DAVIS) 240c hybrid event-based camera.\nMEVDT comprises 63 multi-modal sequences with approximately 13k images, 5M\nevents, 10k object labels, and 85 unique object tracking trajectories.\nAdditionally, MEVDT includes manually annotated ground truth labels\n$\\unicode{x2014}$ consisting of object classifications, pixel-precise bounding\nboxes, and unique object IDs $\\unicode{x2014}$ which are provided at a labeling\nfrequency of 24 Hz. Designed to advance the research in the domain of\nevent-based vision, MEVDT aims to address the critical need for high-quality,\nreal-world annotated datasets that enable the development and evaluation of\nobject detection and tracking algorithms in automotive environments.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Databases"],"license":"http://creativecommons.org/licenses/by/4.0/"}