{"id":"2408.03612","title":"JARViS: Detecting Actions in Video Using Unified Actor-Scene Context\n  Relation Modeling","authors":"Seok Hwan Lee, Taein Son, Soo Won Seo, Jisong Kim, Jun Won Choi","authorsParsed":[["Lee","Seok Hwan",""],["Son","Taein",""],["Seo","Soo Won",""],["Kim","Jisong",""],["Choi","Jun Won",""]],"versions":[{"version":"v1","created":"Wed, 7 Aug 2024 08:08:08 GMT"},{"version":"v2","created":"Tue, 17 Sep 2024 06:25:38 GMT"}],"updateDate":"2024-09-18","timestamp":1723018088000,"abstract":"  Video action detection (VAD) is a formidable vision task that involves the\nlocalization and classification of actions within the spatial and temporal\ndimensions of a video clip. Among the myriad VAD architectures, two-stage VAD\nmethods utilize a pre-trained person detector to extract the region of interest\nfeatures, subsequently employing these features for action detection. However,\nthe performance of two-stage VAD methods has been limited as they depend solely\non localized actor features to infer action semantics. In this study, we\npropose a new two-stage VAD framework called Joint Actor-scene context Relation\nmodeling based on Visual Semantics (JARViS), which effectively consolidates\ncross-modal action semantics distributed globally across spatial and temporal\ndimensions using Transformer attention. JARViS employs a person detector to\nproduce densely sampled actor features from a keyframe. Concurrently, it uses a\nvideo backbone to create spatio-temporal scene features from a video clip.\nFinally, the fine-grained interactions between actors and scenes are modeled\nthrough a Unified Action-Scene Context Transformer to directly output the final\nset of actions in parallel. Our experimental results demonstrate that JARViS\noutperforms existing methods by significant margins and achieves\nstate-of-the-art performance on three popular VAD datasets, including AVA,\nUCF101-24, and JHMDB51-21.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}