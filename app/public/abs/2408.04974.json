{"id":"2408.04974","title":"XNN: Paradigm Shift in Mitigating Identity Leakage within Cloud-Enabled\n  Deep Learning","authors":"Kaixin Liu, Huixin Xiong, Bingyu Duan, Zexuan Cheng, Xinyu Zhou,\n  Wanqian Zhang, Xiangyu Zhang","authorsParsed":[["Liu","Kaixin",""],["Xiong","Huixin",""],["Duan","Bingyu",""],["Cheng","Zexuan",""],["Zhou","Xinyu",""],["Zhang","Wanqian",""],["Zhang","Xiangyu",""]],"versions":[{"version":"v1","created":"Fri, 9 Aug 2024 09:54:11 GMT"}],"updateDate":"2024-08-12","timestamp":1723197251000,"abstract":"  In the domain of cloud-based deep learning, the imperative for external\ncomputational resources coexists with acute privacy concerns, particularly\nidentity leakage. To address this challenge, we introduce XNN and XNN-d,\npioneering methodologies that infuse neural network features with randomized\nperturbations, striking a harmonious balance between utility and privacy. XNN,\ndesigned for the training phase, ingeniously blends random permutation with\nmatrix multiplication techniques to obfuscate feature maps, effectively\nshielding private data from potential breaches without compromising training\nintegrity. Concurrently, XNN-d, devised for the inference phase, employs\nadversarial training to integrate generative adversarial noise. This technique\neffectively counters black-box access attacks aimed at identity extraction,\nwhile a distilled face recognition network adeptly processes the perturbed\nfeatures, ensuring accurate identification. Our evaluation demonstrates XNN's\neffectiveness, significantly outperforming existing methods in reducing\nidentity leakage while maintaining a high model accuracy.\n","subjects":["Computing Research Repository/Cryptography and Security","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}