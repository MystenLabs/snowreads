{"id":"2407.16293","title":"A new Linear Time Bi-level $\\ell_{1,\\infty}$ projection ; Application to\n  the sparsification of auto-encoders neural networks","authors":"Michel Barlaud, Guillaume Perez and Jean-Paul Marmorat","authorsParsed":[["Barlaud","Michel",""],["Perez","Guillaume",""],["Marmorat","Jean-Paul",""]],"versions":[{"version":"v1","created":"Tue, 23 Jul 2024 08:51:29 GMT"}],"updateDate":"2024-07-24","timestamp":1721724689000,"abstract":"  The $\\ell_{1,\\infty}$ norm is an efficient-structured projection, but the\ncomplexity of the best algorithm is, unfortunately, $\\mathcal{O}\\big(n m \\log(n\nm)\\big)$ for a matrix $n\\times m$.\\\\ In this paper, we propose a new bi-level\nprojection method, for which we show that the time complexity for the\n$\\ell_{1,\\infty}$ norm is only $\\mathcal{O}\\big(n m \\big)$ for a matrix\n$n\\times m$. Moreover, we provide a new $\\ell_{1,\\infty}$ identity with\nmathematical proof and experimental validation. Experiments show that our\nbi-level $\\ell_{1,\\infty}$ projection is $2.5$ times faster than the actual\nfastest algorithm and provides the best sparsity while keeping the same\naccuracy in classification applications.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}