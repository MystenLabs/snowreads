{"id":"2407.17907","title":"Amortized Posterior Sampling with Diffusion Prior Distillation","authors":"Abbas Mammadov, Hyungjin Chung, Jong Chul Ye","authorsParsed":[["Mammadov","Abbas",""],["Chung","Hyungjin",""],["Ye","Jong Chul",""]],"versions":[{"version":"v1","created":"Thu, 25 Jul 2024 09:53:12 GMT"}],"updateDate":"2024-07-26","timestamp":1721901192000,"abstract":"  We propose a variational inference approach to sample from the posterior\ndistribution for solving inverse problems. From a pre-trained diffusion model,\nour approach trains a conditional flow model to minimize the divergence between\nthe proposal variational distribution and the posterior distribution implicitly\ndefined through the diffusion model. Once trained, the flow model is capable of\nsampling from the posterior distribution with a single NFE, amortized with\nrespect to the measurement. The proposed method paves a new path for distilling\na diffusion prior for efficient posterior sampling. We show that our method is\napplicable to standard signals in Euclidean space, as well as signals on\nmanifold.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"kg4O0X06gudOXmNq6fsUd3CpjoLcew8FB6lUk5kWcr4","pdfSize":"21794920","objectId":"0xa29e62e6c12d68ce6191937d14f440254bb25524a99780f3d3f0911506133c67","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
