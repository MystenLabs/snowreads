{"id":"2408.07897","title":"The Nah Bandit: Modeling User Non-compliance in Recommendation Systems","authors":"Tianyue Zhou, Jung-Hoon Cho, Cathy Wu","authorsParsed":[["Zhou","Tianyue",""],["Cho","Jung-Hoon",""],["Wu","Cathy",""]],"versions":[{"version":"v1","created":"Thu, 15 Aug 2024 03:01:02 GMT"}],"updateDate":"2024-08-16","timestamp":1723690862000,"abstract":"  Recommendation systems now pervade the digital world, ranging from\nadvertising to entertainment. However, it remains challenging to implement\neffective recommendation systems in the physical world, such as in mobility or\nhealth. This work focuses on a key challenge: in the physical world, it is\noften easy for the user to opt out of taking any recommendation if they are not\nto her liking, and to fall back to her baseline behavior. It is thus crucial in\ncyber-physical recommendation systems to operate with an interaction model that\nis aware of such user behavior, lest the user abandon the recommendations\naltogether. This paper thus introduces the Nah Bandit, a tongue-in-cheek\nreference to describe a Bandit problem where users can say `nah' to the\nrecommendation and opt for their preferred option instead. As such, this\nproblem lies in between a typical bandit setup and supervised learning. We\nmodel the user non-compliance by parameterizing an anchoring effect of\nrecommendations on users. We then propose the Expert with Clustering (EWC)\nalgorithm, a hierarchical approach that incorporates feedback from both\nrecommended and non-recommended options to accelerate user preference learning.\nIn a recommendation scenario with $N$ users, $T$ rounds per user, and $K$\nclusters, EWC achieves a regret bound of $O(N\\sqrt{T\\log K} + NT)$, achieving\nsuperior theoretical performance in the short term compared to LinUCB\nalgorithm. Experimental results also highlight that EWC outperforms both\nsupervised learning and traditional contextual bandit approaches. This\nadvancement reveals that effective use of non-compliance feedback can\naccelerate preference learning and improve recommendation accuracy. This work\nlays the foundation for future research in Nah Bandit, providing a robust\nframework for more effective recommendation systems.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Information Retrieval","Computing Research Repository/Multiagent Systems","Computing Research Repository/Systems and Control","Electrical Engineering and Systems Science/Systems and Control"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}