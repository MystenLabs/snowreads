{"id":"2408.10901","title":"A Grey-box Attack against Latent Diffusion Model-based Image Editing by\n  Posterior Collapse","authors":"Zhongliang Guo, Lei Fang, Jingyu Lin, Yifei Qian, Shuai Zhao, Zeyu\n  Wang, Junhao Dong, Cunjian Chen, Ognjen Arandjelovi\\'c, Chun Pong Lau","authorsParsed":[["Guo","Zhongliang",""],["Fang","Lei",""],["Lin","Jingyu",""],["Qian","Yifei",""],["Zhao","Shuai",""],["Wang","Zeyu",""],["Dong","Junhao",""],["Chen","Cunjian",""],["ArandjeloviÄ‡","Ognjen",""],["Lau","Chun Pong",""]],"versions":[{"version":"v1","created":"Tue, 20 Aug 2024 14:43:53 GMT"},{"version":"v2","created":"Mon, 2 Sep 2024 05:25:06 GMT"}],"updateDate":"2024-09-04","timestamp":1724165033000,"abstract":"  Recent advancements in generative AI, particularly Latent Diffusion Models\n(LDMs), have revolutionized image synthesis and manipulation. However, these\ngenerative techniques raises concerns about data misappropriation and\nintellectual property infringement. Adversarial attacks on machine learning\nmodels have been extensively studied, and a well-established body of research\nhas extended these techniques as a benign metric to prevent the underlying\nmisuse of generative AI. Current approaches to safeguarding images from\nmanipulation by LDMs are limited by their reliance on model-specific knowledge\nand their inability to significantly degrade semantic quality of generated\nimages. In response to these shortcomings, we propose the Posterior Collapse\nAttack (PCA) based on the observation that VAEs suffer from posterior collapse\nduring training. Our method minimizes dependence on the white-box information\nof target models to get rid of the implicit reliance on model-specific\nknowledge. By accessing merely a small amount of LDM parameters, in specific\nmerely the VAE encoder of LDMs, our method causes a substantial semantic\ncollapse in generation quality, particularly in perceptual consistency, and\ndemonstrates strong transferability across various model architectures.\nExperimental results show that PCA achieves superior perturbation effects on\nimage generation of LDMs with lower runtime and VRAM. Our method outperforms\nexisting techniques, offering a more robust and generalizable solution that is\nhelpful in alleviating the socio-technical challenges posed by the rapidly\nevolving landscape of generative AI.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}