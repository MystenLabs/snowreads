{"id":"2408.03762","title":"'Finance Wizard' at the FinLLM Challenge Task: Financial Text\n  Summarization","authors":"Meisin Lee, Soon Lay-Ki","authorsParsed":[["Lee","Meisin",""],["Lay-Ki","Soon",""]],"versions":[{"version":"v1","created":"Wed, 7 Aug 2024 13:31:44 GMT"}],"updateDate":"2024-08-08","timestamp":1723037504000,"abstract":"  This paper presents our participation under the team name `Finance Wizard' in\nthe FinNLP-AgentScen 2024 shared task #2: Financial Text Summarization. It\ndocuments our pipeline approach of fine-tuning a foundation model into a\ntask-specific model for Financial Text Summarization. It involves (1) adapting\nLlama3 8B, a foundation model, to the Finance domain via continued\npre-training, (2) multi-task instruction-tuning to further equip the model with\nmore finance-related capabilities, (3) finally fine-tuning the model into a\ntask-specific `expert'. Our model, FinLlama3\\_sum, yielded commendable results,\nsecuring the third position in its category with a ROUGE-1 score of 0.521.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"RQeTDnP120vBfA1sf1hryYl5DCw4atZHTiiXTSuGAls","pdfSize":"344568"}
