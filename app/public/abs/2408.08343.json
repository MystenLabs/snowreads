{"id":"2408.08343","title":"API-guided Dataset Synthesis to Finetune Large Code Models","authors":"Zongjie Li, Daoyuan Wu, Shuai Wang, Zhendong Su","authorsParsed":[["Li","Zongjie",""],["Wu","Daoyuan",""],["Wang","Shuai",""],["Su","Zhendong",""]],"versions":[{"version":"v1","created":"Thu, 15 Aug 2024 14:48:42 GMT"},{"version":"v2","created":"Thu, 22 Aug 2024 11:29:51 GMT"}],"updateDate":"2024-08-23","timestamp":1723733322000,"abstract":"  Large code models (LCMs), pre-trained on vast code corpora, have demonstrated\nremarkable performance across a wide array of code-related tasks. Supervised\nfine-tuning (SFT) plays a vital role in aligning these models with specific\nrequirements and enhancing their performance in particular domains. However,\nsynthesizing high-quality SFT datasets poses a significant challenge due to the\nuneven quality of datasets and the scarcity of domain-specific datasets.\n  Inspired by APIs as high-level abstractions of code that encapsulate rich\nsemantic information in a concise structure, we propose DataScope, an\nAPI-guided dataset synthesis framework designed to enhance the SFT process for\nLCMs in both general and domain-specific scenarios. DataScope comprises two\nmain components: Dsel and Dgen. On one hand, Dsel employs API coverage as a\ncore metric, enabling efficient dataset synthesis in general scenarios by\nselecting subsets of existing (uneven-quality) datasets with higher API\ncoverage. On the other hand, Dgen recasts domain dataset synthesis as a process\nof using API-specified high-level functionality and deliberately-constituted\ncode skeletons to synthesize concrete code.\n  Extensive experiments demonstrate DataScope's effectiveness, with models\nfine-tuned on its synthesized datasets outperforming those tuned on unoptimized\ndatasets five times larger. Furthermore, a series of analyses on model\ninternals, relevant hyperparameters, and case studies provide additional\nevidence for the efficacy of our proposed methods. These findings underscore\nthe significance of dataset quality in SFT and advance the field of LCMs by\nproviding an efficient, cost-effective framework for constructing high-quality\ndatasets. This contribution enhances performance across both general and\ndomain-specific scenarios, paving the way for more powerful and tailored LCMs.\n","subjects":["Computing Research Repository/Software Engineering","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}