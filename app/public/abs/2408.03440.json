{"id":"2408.03440","title":"TF-Locoformer: Transformer with Local Modeling by Convolution for Speech\n  Separation and Enhancement","authors":"Kohei Saijo, Gordon Wichern, Fran\\c{c}ois G. Germain, Zexu Pan,\n  Jonathan Le Roux","authorsParsed":[["Saijo","Kohei",""],["Wichern","Gordon",""],["Germain","Fran√ßois G.",""],["Pan","Zexu",""],["Roux","Jonathan Le",""]],"versions":[{"version":"v1","created":"Tue, 6 Aug 2024 20:30:14 GMT"}],"updateDate":"2024-08-08","timestamp":1722976214000,"abstract":"  Time-frequency (TF) domain dual-path models achieve high-fidelity speech\nseparation. While some previous state-of-the-art (SoTA) models rely on RNNs,\nthis reliance means they lack the parallelizability, scalability, and\nversatility of Transformer blocks. Given the wide-ranging success of pure\nTransformer-based architectures in other fields, in this work we focus on\nremoving the RNN from TF-domain dual-path models, while maintaining SoTA\nperformance. This work presents TF-Locoformer, a Transformer-based model with\nLOcal-modeling by COnvolution. The model uses feed-forward networks (FFNs) with\nconvolution layers, instead of linear layers, to capture local information,\nletting the self-attention focus on capturing global patterns. We place two\nsuch FFNs before and after self-attention to enhance the local-modeling\ncapability. We also introduce a novel normalization for TF-domain dual-path\nmodels. Experiments on separation and enhancement datasets show that the\nproposed model meets or exceeds SoTA in multiple benchmarks with an RNN-free\narchitecture.\n","subjects":["Electrical Engineering and Systems Science/Audio and Speech Processing","Computing Research Repository/Sound"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}