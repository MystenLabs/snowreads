{"id":"2408.12084","title":"Vision-Based Detection of Uncooperative Targets and Components on Small\n  Satellites","authors":"Hannah Grauer, Elena-Sorina Lupu, Connor Lee, Soon-Jo Chung, Darren\n  Rowen, Benjamen Bycroft, Phaedrus Leeds, John Brader","authorsParsed":[["Grauer","Hannah",""],["Lupu","Elena-Sorina",""],["Lee","Connor",""],["Chung","Soon-Jo",""],["Rowen","Darren",""],["Bycroft","Benjamen",""],["Leeds","Phaedrus",""],["Brader","John",""]],"versions":[{"version":"v1","created":"Thu, 22 Aug 2024 02:48:13 GMT"}],"updateDate":"2024-08-23","timestamp":1724294893000,"abstract":"  Space debris and inactive satellites pose a threat to the safety and\nintegrity of operational spacecraft and motivate the need for space situational\nawareness techniques. These uncooperative targets create a challenging tracking\nand detection problem due to a lack of prior knowledge of their features,\ntrajectories, or even existence. Recent advancements in computer vision models\ncan be used to improve upon existing methods for tracking such uncooperative\ntargets to make them more robust and reliable to the wide-ranging nature of the\ntarget. This paper introduces an autonomous detection model designed to\nidentify and monitor these objects using learning and computer vision. The\nautonomous detection method aims to identify and accurately track the\nuncooperative targets in varied circumstances, including different camera\nspectral sensitivities, lighting, and backgrounds. Our method adapts to the\nrelative distance between the observing spacecraft and the target, and\ndifferent detection strategies are adjusted based on distance. At larger\ndistances, we utilize You Only Look Once (YOLOv8), a multitask Convolutional\nNeural Network (CNN), for zero-shot and domain-specific single-shot real time\ndetection of the target. At shorter distances, we use knowledge distillation to\ncombine visual foundation models with a lightweight fast segmentation CNN\n(Fast-SCNN) to segment the spacecraft components with low storage requirements\nand fast inference times, and to enable weight updates from earth and possible\nonboard training. Lastly, we test our method on a custom dataset simulating the\nunique conditions encountered in space, as well as a publicly-available\ndataset.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"GJZ7GfleXCp6icp6Zc4MOhgYE77ryjMPL-IU5MBQV-8","pdfSize":"3517648"}
