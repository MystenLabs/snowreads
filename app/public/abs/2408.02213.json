{"id":"2408.02213","title":"Is Large Language Model Good at Database Knob Tuning? A Comprehensive\n  Experimental Evaluation","authors":"Yiyan Li, Haoyang Li, Zhao Pu, Jing Zhang, Xinyi Zhang, Tao Ji, Luming\n  Sun, Cuiping Li, Hong Chen","authorsParsed":[["Li","Yiyan",""],["Li","Haoyang",""],["Pu","Zhao",""],["Zhang","Jing",""],["Zhang","Xinyi",""],["Ji","Tao",""],["Sun","Luming",""],["Li","Cuiping",""],["Chen","Hong",""]],"versions":[{"version":"v1","created":"Mon, 5 Aug 2024 03:26:01 GMT"}],"updateDate":"2024-08-06","timestamp":1722828361000,"abstract":"  Knob tuning plays a crucial role in optimizing databases by adjusting knobs\nto enhance database performance. However, traditional tuning methods often\nfollow a Try-Collect-Adjust approach, proving inefficient and\ndatabase-specific. Moreover, these methods are often opaque, making it\nchallenging for DBAs to grasp the underlying decision-making process.\n  The emergence of large language models (LLMs) like GPT-4 and Claude-3 has\nexcelled in complex natural language tasks, yet their potential in database\nknob tuning remains largely unexplored. This study harnesses LLMs as\nexperienced DBAs for knob-tuning tasks with carefully designed prompts. We\nidentify three key subtasks in the tuning system: knob pruning, model\ninitialization, and knob recommendation, proposing LLM-driven solutions to\nreplace conventional methods for each subtask.\n  We conduct extensive experiments to compare LLM-driven approaches against\ntraditional methods across the subtasks to evaluate LLMs' efficacy in the knob\ntuning domain. Furthermore, we explore the adaptability of LLM-based solutions\nin diverse evaluation settings, encompassing new benchmarks, database engines,\nand hardware environments. Our findings reveal that LLMs not only match or\nsurpass traditional methods but also exhibit notable interpretability by\ngenerating responses in a coherent ``chain-of-thought'' manner. We further\nobserve that LLMs exhibit remarkable generalizability through simple\nadjustments in prompts, eliminating the necessity for additional training or\nextensive code modifications.\n  Drawing insights from our experimental findings, we identify several\nopportunities for future research aimed at advancing the utilization of LLMs in\nthe realm of database management.\n","subjects":["Computing Research Repository/Databases","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}