{"id":"2408.00762","title":"UniTalker: Scaling up Audio-Driven 3D Facial Animation through A Unified\n  Model","authors":"Xiangyu Fan, Jiaqi Li, Zhiqian Lin, Weiye Xiao, Lei Yang","authorsParsed":[["Fan","Xiangyu",""],["Li","Jiaqi",""],["Lin","Zhiqian",""],["Xiao","Weiye",""],["Yang","Lei",""]],"versions":[{"version":"v1","created":"Thu, 1 Aug 2024 17:59:27 GMT"}],"updateDate":"2024-08-02","timestamp":1722535167000,"abstract":"  Audio-driven 3D facial animation aims to map input audio to realistic facial\nmotion. Despite significant progress, limitations arise from inconsistent 3D\nannotations, restricting previous models to training on specific annotations\nand thereby constraining the training scale. In this work, we present\nUniTalker, a unified model featuring a multi-head architecture designed to\neffectively leverage datasets with varied annotations. To enhance training\nstability and ensure consistency among multi-head outputs, we employ three\ntraining strategies, namely, PCA, model warm-up, and pivot identity embedding.\nTo expand the training scale and diversity, we assemble A2F-Bench, comprising\nfive publicly available datasets and three newly curated datasets. These\ndatasets contain a wide range of audio domains, covering multilingual speech\nvoices and songs, thereby scaling the training data from commonly employed\ndatasets, typically less than 1 hour, to 18.5 hours. With a single trained\nUniTalker model, we achieve substantial lip vertex error reductions of 9.2% for\nBIWI dataset and 13.7% for Vocaset. Additionally, the pre-trained UniTalker\nexhibits promise as the foundation model for audio-driven facial animation\ntasks. Fine-tuning the pre-trained UniTalker on seen datasets further enhances\nperformance on each dataset, with an average error reduction of 6.3% on\nA2F-Bench. Moreover, fine-tuning UniTalker on an unseen dataset with only half\nthe data surpasses prior state-of-the-art models trained on the full dataset.\nThe code and dataset are available at the project page\nhttps://github.com/X-niper/UniTalker.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}