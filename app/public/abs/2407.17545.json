{"id":"2407.17545","title":"Large Language Models for Anomaly Detection in Computational Workflows:\n  from Supervised Fine-Tuning to In-Context Learning","authors":"Hongwei Jin, George Papadimitriou, Krishnan Raghavan, Pawel Zuk,\n  Prasanna Balaprakash, Cong Wang, Anirban Mandal, Ewa Deelman","authorsParsed":[["Jin","Hongwei",""],["Papadimitriou","George",""],["Raghavan","Krishnan",""],["Zuk","Pawel",""],["Balaprakash","Prasanna",""],["Wang","Cong",""],["Mandal","Anirban",""],["Deelman","Ewa",""]],"versions":[{"version":"v1","created":"Wed, 24 Jul 2024 16:33:04 GMT"}],"updateDate":"2024-07-26","timestamp":1721838784000,"abstract":"  Anomaly detection in computational workflows is critical for ensuring system\nreliability and security. However, traditional rule-based methods struggle to\ndetect novel anomalies. This paper leverages large language models (LLMs) for\nworkflow anomaly detection by exploiting their ability to learn complex data\npatterns. Two approaches are investigated: 1) supervised fine-tuning (SFT),\nwhere pre-trained LLMs are fine-tuned on labeled data for sentence\nclassification to identify anomalies, and 2) in-context learning (ICL) where\nprompts containing task descriptions and examples guide LLMs in few-shot\nanomaly detection without fine-tuning. The paper evaluates the performance,\nefficiency, generalization of SFT models, and explores zero-shot and few-shot\nICL prompts and interpretability enhancement via chain-of-thought prompting.\nExperiments across multiple workflow datasets demonstrate the promising\npotential of LLMs for effective anomaly detection in complex executions.\n","subjects":["Computing Research Repository/Software Engineering","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}