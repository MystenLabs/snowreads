{"id":"2407.08706","title":"HiRes-LLaVA: Restoring Fragmentation Input in High-Resolution Large\n  Vision-Language Models","authors":"Runhui Huang, Xinpeng Ding, Chunwei Wang, Jianhua Han, Yulong Liu,\n  Hengshuang Zhao, Hang Xu, Lu Hou, Wei Zhang, Xiaodan Liang","authorsParsed":[["Huang","Runhui",""],["Ding","Xinpeng",""],["Wang","Chunwei",""],["Han","Jianhua",""],["Liu","Yulong",""],["Zhao","Hengshuang",""],["Xu","Hang",""],["Hou","Lu",""],["Zhang","Wei",""],["Liang","Xiaodan",""]],"versions":[{"version":"v1","created":"Thu, 11 Jul 2024 17:42:17 GMT"}],"updateDate":"2024-07-12","timestamp":1720719737000,"abstract":"  High-resolution inputs enable Large Vision-Language Models (LVLMs) to discern\nfiner visual details, enhancing their comprehension capabilities. To reduce the\ntraining and computation costs caused by high-resolution input, one promising\ndirection is to use sliding windows to slice the input into uniform patches,\neach matching the input size of the well-trained vision encoder. Although\nefficient, this slicing strategy leads to the fragmentation of original input,\ni.e., the continuity of contextual information and spatial geometry is lost\nacross patches, adversely affecting performance in cross-patch context\nperception and position-specific tasks. To overcome these shortcomings, we\nintroduce HiRes-LLaVA, a novel framework designed to efficiently process any\nsize of high-resolution input without altering the original contextual and\ngeometric information. HiRes-LLaVA comprises two innovative components: (i) a\nSliceRestore adapter that reconstructs sliced patches into their original form,\nefficiently extracting both global and local features via down-up-sampling and\nconvolution layers, and (ii) a Self-Mining Sampler to compresses the vision\ntokens based on themselves, preserving the original context and positional\ninformation while reducing training overhead. To assess the ability of handling\ncontext fragmentation, we construct a new benchmark, EntityGrid-QA, consisting\nof edge-related and position-related tasks. Our comprehensive experiments\ndemonstrate the superiority of HiRes-LLaVA on both existing public benchmarks\nand on EntityGrid-QA, particularly on document-oriented tasks, establishing new\nstandards for handling high-resolution inputs.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}