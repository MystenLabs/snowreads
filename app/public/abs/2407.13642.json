{"id":"2407.13642","title":"Open-Vocabulary 3D Semantic Segmentation with Text-to-Image Diffusion\n  Models","authors":"Xiaoyu Zhu, Hao Zhou, Pengfei Xing, Long Zhao, Hao Xu, Junwei Liang,\n  Alexander Hauptmann, Ting Liu, Andrew Gallagher","authorsParsed":[["Zhu","Xiaoyu",""],["Zhou","Hao",""],["Xing","Pengfei",""],["Zhao","Long",""],["Xu","Hao",""],["Liang","Junwei",""],["Hauptmann","Alexander",""],["Liu","Ting",""],["Gallagher","Andrew",""]],"versions":[{"version":"v1","created":"Thu, 18 Jul 2024 16:20:56 GMT"}],"updateDate":"2024-07-19","timestamp":1721319656000,"abstract":"  In this paper, we investigate the use of diffusion models which are\npre-trained on large-scale image-caption pairs for open-vocabulary 3D semantic\nunderstanding. We propose a novel method, namely Diff2Scene, which leverages\nfrozen representations from text-image generative models, along with\nsalient-aware and geometric-aware masks, for open-vocabulary 3D semantic\nsegmentation and visual grounding tasks. Diff2Scene gets rid of any labeled 3D\ndata and effectively identifies objects, appearances, materials, locations and\ntheir compositions in 3D scenes. We show that it outperforms competitive\nbaselines and achieves significant improvements over state-of-the-art methods.\nIn particular, Diff2Scene improves the state-of-the-art method on ScanNet200 by\n12%.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/"}