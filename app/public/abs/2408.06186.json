{"id":"2408.06186","title":"Improving Structural Diversity of Blackbox LLMs via\n  Chain-of-Specification Prompting","authors":"Halley Young, Yimeng Zeng, Jacob Gardner, Osbert Bastani","authorsParsed":[["Young","Halley",""],["Zeng","Yimeng",""],["Gardner","Jacob",""],["Bastani","Osbert",""]],"versions":[{"version":"v1","created":"Mon, 12 Aug 2024 14:34:06 GMT"}],"updateDate":"2024-08-13","timestamp":1723473246000,"abstract":"  The capability to generate diverse text is a key challenge facing large\nlanguage models (LLMs). Thus far, diversity has been studied via metrics such\nas $n$-gram diversity or diversity of BERT embeddings. However, for these kinds\nof diversity, the user has little control over the dimensions along which\ndiversity is considered. For example, in the poetry domain, one might desire\ndiversity in terms of rhyme and meter, whereas in the code domain, one might\ndesire diversity in terms of the kinds of expressions used to solve a problem.\nWe propose a diversity metric called structural diversity, where the user\nprovides a mapping from generated text to features capturing the kinds of\ndiversity that they care about. In addition, we propose a novel strategy called\nchain-of-specification (CoS) prompting for improving diversity by first having\nthe LLM generate a specification encoding one instance of structural features,\nand then prompting the LLM to generate text that satisfies these features;\nnotably, our strategy works with blackbox LLMs. In our experiments, we show\nthat for structural diversity in the poetry and code domains, CoS significantly\nimproves diversity compared to several baselines.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}