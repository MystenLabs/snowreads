{"id":"2407.01613","title":"Self-adaptive weights based on balanced residual decay rate for\n  physics-informed neural networks and deep operator networks","authors":"Wenqian Chen, Amanda A. Howard, Panos Stinis","authorsParsed":[["Chen","Wenqian",""],["Howard","Amanda A.",""],["Stinis","Panos",""]],"versions":[{"version":"v1","created":"Fri, 28 Jun 2024 00:53:48 GMT"}],"updateDate":"2024-07-03","timestamp":1719536028000,"abstract":"  Physics-informed deep learning has emerged as a promising alternative for\nsolving partial differential equations. However, for complex problems, training\nthese networks can still be challenging, often resulting in unsatisfactory\naccuracy and efficiency. In this work, we demonstrate that the failure of plain\nphysics-informed neural networks arises from the significant discrepancy in the\nconvergence speed of residuals at different training points, where the slowest\nconvergence speed dominates the overall solution convergence. Based on these\nobservations, we propose a point-wise adaptive weighting method that balances\nthe residual decay rate across different training points. The performance of\nour proposed adaptive weighting method is compared with current\nstate-of-the-art adaptive weighting methods on benchmark problems for both\nphysics-informed neural networks and physics-informed deep operator networks.\nThrough extensive numerical results we demonstrate that our proposed approach\nof balanced residual decay rates offers several advantages, including bounded\nweights, high prediction accuracy, fast convergence speed, low training\nuncertainty, low computational cost and ease of hyperparameter tuning.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence","Statistics/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}