{"id":"2407.03197","title":"DyFADet: Dynamic Feature Aggregation for Temporal Action Detection","authors":"Le Yang, Ziwei Zheng, Yizeng Han, Hao Cheng, Shiji Song, Gao Huang and\n  Fan Li","authorsParsed":[["Yang","Le",""],["Zheng","Ziwei",""],["Han","Yizeng",""],["Cheng","Hao",""],["Song","Shiji",""],["Huang","Gao",""],["Li","Fan",""]],"versions":[{"version":"v1","created":"Wed, 3 Jul 2024 15:29:10 GMT"}],"updateDate":"2024-07-04","timestamp":1720020550000,"abstract":"  Recent proposed neural network-based Temporal Action Detection (TAD) models\nare inherently limited to extracting the discriminative representations and\nmodeling action instances with various lengths from complex scenes by\nshared-weights detection heads. Inspired by the successes in dynamic neural\nnetworks, in this paper, we build a novel dynamic feature aggregation (DFA)\nmodule that can simultaneously adapt kernel weights and receptive fields at\ndifferent timestamps. Based on DFA, the proposed dynamic encoder layer\naggregates the temporal features within the action time ranges and guarantees\nthe discriminability of the extracted representations. Moreover, using DFA\nhelps to develop a Dynamic TAD head (DyHead), which adaptively aggregates the\nmulti-scale features with adjusted parameters and learned receptive fields\nbetter to detect the action instances with diverse ranges from videos. With the\nproposed encoder layer and DyHead, a new dynamic TAD model, DyFADet, achieves\npromising performance on a series of challenging TAD benchmarks, including\nHACS-Segment, THUMOS14, ActivityNet-1.3, Epic-Kitchen 100, Ego4D-Moment\nQueriesV1.0, and FineAction. Code is released to\nhttps://github.com/yangle15/DyFADet-pytorch.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}