{"id":"2408.11775","title":"Leveraging Fine-Tuned Retrieval-Augmented Generation with Long-Context\n  Support: For 3GPP Standards","authors":"Omar Erak, Nouf Alabbasi, Omar Alhussein, Ismail Lotfi, Amr Hussein,\n  Sami Muhaidat, Merouane Debbah","authorsParsed":[["Erak","Omar",""],["Alabbasi","Nouf",""],["Alhussein","Omar",""],["Lotfi","Ismail",""],["Hussein","Amr",""],["Muhaidat","Sami",""],["Debbah","Merouane",""]],"versions":[{"version":"v1","created":"Wed, 21 Aug 2024 17:00:05 GMT"}],"updateDate":"2024-08-22","timestamp":1724259605000,"abstract":"  Recent studies show that large language models (LLMs) struggle with technical\nstandards in telecommunications. We propose a fine-tuned retrieval-augmented\ngeneration (RAG) system based on the Phi-2 small language model (SLM) to serve\nas an oracle for communication networks. Our developed system leverages\nforward-looking semantic chunking to adaptively determine parsing breakpoints\nbased on embedding similarity, enabling effective processing of diverse\ndocument formats. To handle the challenge of multiple similar contexts in\ntechnical standards, we employ a re-ranking algorithm to prioritize the most\nrelevant retrieved chunks. Recognizing the limitations of Phi-2's small context\nwindow, we implement a recent technique, namely SelfExtend, to expand the\ncontext window during inference, which not only boosts the performance but also\ncan accommodate a wider range of user queries and design requirements from\ncustomers to specialized technicians. For fine-tuning, we utilize the low-rank\nadaptation (LoRA) technique to enhance computational efficiency during training\nand enable effective fine-tuning on small datasets. Our comprehensive\nexperiments demonstrate substantial improvements over existing\nquestion-answering approaches in the telecom domain, achieving performance that\nexceeds larger language models such as GPT-4 (which is about 880 times larger\nin size). This work presents a novel approach to leveraging SLMs for\ncommunication networks, offering a balance of efficiency and performance. This\nwork can serve as a foundation towards agentic language models for networks.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Networking and Internet Architecture"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}