{"id":"2407.07660","title":"Boosting Medical Image Synthesis via Registration-guided Consistency and\n  Disentanglement Learning","authors":"Chuanpu Li, Zeli Chen, Yiwen Zhang, Liming Zhong and Wei Yang","authorsParsed":[["Li","Chuanpu",""],["Chen","Zeli",""],["Zhang","Yiwen",""],["Zhong","Liming",""],["Yang","Wei",""]],"versions":[{"version":"v1","created":"Wed, 10 Jul 2024 13:41:26 GMT"}],"updateDate":"2024-07-11","timestamp":1720618886000,"abstract":"  Medical image synthesis remains challenging due to misalignment noise during\ntraining. Existing methods have attempted to address this challenge by\nincorporating a registration-guided module. However, these methods tend to\noverlook the task-specific constraints on the synthetic and registration\nmodules, which may cause the synthetic module to still generate spatially\naligned images with misaligned target images during training, regardless of the\nregistration module's function. Therefore, this paper proposes\nregistration-guided consistency and incorporates disentanglement learning for\nmedical image synthesis. The proposed registration-guided consistency\narchitecture fosters task-specificity within the synthetic and registration\nmodules by applying identical deformation fields before and after synthesis,\nwhile enforcing output consistency through an alignment loss. Moreover, the\nsynthetic module is designed to possess the capability of disentangling\nanatomical structures and specific styles across various modalities. An anatomy\nconsistency loss is introduced to further compel the synthetic module to\npreserve geometrical integrity within latent spaces. Experiments conducted on\nboth an in-house abdominal CECT-CT dataset and a publicly available pelvic\nMR-CT dataset have demonstrated the superiority of the proposed method.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}