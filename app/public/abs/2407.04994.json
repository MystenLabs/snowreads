{"id":"2407.04994","title":"The Solution for Language-Enhanced Image New Category Discovery","authors":"Haonan Xu, Dian Chao, Xiangyu Wu, Zhonghua Wan, Yang Yang","authorsParsed":[["Xu","Haonan",""],["Chao","Dian",""],["Wu","Xiangyu",""],["Wan","Zhonghua",""],["Yang","Yang",""]],"versions":[{"version":"v1","created":"Sat, 6 Jul 2024 08:09:29 GMT"}],"updateDate":"2024-07-09","timestamp":1720253369000,"abstract":"  Treating texts as images, combining prompts with textual labels for prompt\ntuning, and leveraging the alignment properties of CLIP have been successfully\napplied in zero-shot multi-label image recognition. Nonetheless, relying solely\non textual labels to store visual information is insufficient for representing\nthe diversity of visual objects. In this paper, we propose reversing the\ntraining process of CLIP and introducing the concept of Pseudo Visual Prompts.\nThese prompts are initialized for each object category and pre-trained on\nlarge-scale, low-cost sentence data generated by large language models. This\nprocess mines the aligned visual information in CLIP and stores it in\nclass-specific visual prompts. We then employ contrastive learning to transfer\nthe stored visual information to the textual labels, enhancing their visual\nrepresentation capacity. Additionally, we introduce a dual-adapter module that\nsimultaneously leverages knowledge from the original CLIP and new learning\nknowledge derived from downstream datasets. Benefiting from the pseudo visual\nprompts, our method surpasses the state-of-the-art not only on clean annotated\ntext data but also on pseudo text data generated by large language models.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}