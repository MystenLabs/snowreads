{"id":"2407.03007","title":"What Affects the Stability of Tool Learning? An Empirical Study on the\n  Robustness of Tool Learning Frameworks","authors":"Chengrui Huang, Zhengliang Shi, Yuntao Wen, Xiuying Chen, Peng Han,\n  Shen Gao, Shuo Shang","authorsParsed":[["Huang","Chengrui",""],["Shi","Zhengliang",""],["Wen","Yuntao",""],["Chen","Xiuying",""],["Han","Peng",""],["Gao","Shen",""],["Shang","Shuo",""]],"versions":[{"version":"v1","created":"Wed, 3 Jul 2024 11:06:05 GMT"}],"updateDate":"2024-07-04","timestamp":1720004765000,"abstract":"  Tool learning methods have enhanced the ability of large language models\n(LLMs) to interact with real-world applications. Many existing works fine-tune\nLLMs or design prompts to enable LLMs to select appropriate tools and correctly\ninvoke them to meet user requirements. However, it is observed in previous\nworks that the performance of tool learning varies from tasks, datasets,\ntraining settings, and algorithms. Without understanding the impact of these\nfactors, it can lead to inconsistent results, inefficient model deployment, and\nsuboptimal tool utilization, ultimately hindering the practical integration and\nscalability of LLMs in real-world scenarios. Therefore, in this paper, we\nexplore the impact of both internal and external factors on the performance of\ntool learning frameworks. Through extensive experiments on two benchmark\ndatasets, we find several insightful conclusions for future work, including the\nobservation that LLMs can benefit significantly from increased trial and\nexploration. We believe our empirical study provides a new perspective for\nfuture tool learning research.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}