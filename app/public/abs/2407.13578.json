{"id":"2407.13578","title":"Large Language Models as Reliable Knowledge Bases?","authors":"Danna Zheng, Mirella Lapata, Jeff Z. Pan","authorsParsed":[["Zheng","Danna",""],["Lapata","Mirella",""],["Pan","Jeff Z.",""]],"versions":[{"version":"v1","created":"Thu, 18 Jul 2024 15:20:18 GMT"}],"updateDate":"2024-07-19","timestamp":1721316018000,"abstract":"  The NLP community has recently shown a growing interest in leveraging Large\nLanguage Models (LLMs) for knowledge-intensive tasks, viewing LLMs as potential\nknowledge bases (KBs). However, the reliability and extent to which LLMs can\nfunction as KBs remain underexplored. While previous studies suggest LLMs can\nencode knowledge within their parameters, the amount of parametric knowledge\nalone is not sufficient to evaluate their effectiveness as KBs. This study\ndefines criteria that a reliable LLM-as-KB should meet, focusing on factuality\nand consistency, and covering both seen and unseen knowledge. We develop\nseveral metrics based on these criteria and use them to evaluate 26 popular\nLLMs, while providing a comprehensive analysis of the effects of model size,\ninstruction tuning, and in-context learning (ICL). Our results paint a worrying\npicture. Even a high-performant model like GPT-3.5-turbo is not factual or\nconsistent, and strategies like ICL and fine-tuning are unsuccessful at making\nLLMs better KBs.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"IPyuwBHz7HNjd0nY75gAI3YFjWTC3_xpHJLkcU79jtE","pdfSize":"17725185"}
