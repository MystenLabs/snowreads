{"id":"2408.02152","title":"Generative Retrieval with Few-shot Indexing","authors":"Arian Askari, Chuan Meng, Mohammad Aliannejadi, Zhaochun Ren,\n  Evangelos Kanoulas, Suzan Verberne","authorsParsed":[["Askari","Arian",""],["Meng","Chuan",""],["Aliannejadi","Mohammad",""],["Ren","Zhaochun",""],["Kanoulas","Evangelos",""],["Verberne","Suzan",""]],"versions":[{"version":"v1","created":"Sun, 4 Aug 2024 22:00:34 GMT"}],"updateDate":"2024-08-06","timestamp":1722808834000,"abstract":"  Existing generative retrieval (GR) approaches rely on training-based\nindexing, i.e., fine-tuning a model to memorise the associations between a\nquery and the document identifier (docid) of a relevant document.\nTraining-based indexing has three limitations: high training overhead,\nunder-utilization of the pre-trained knowledge of large language models (LLMs),\nand challenges in adapting to a dynamic document corpus. To address the above\nissues, we propose a novel few-shot indexing-based GR framework (Few-Shot GR).\nIt has a novel few-shot indexing process, where we prompt an LLM to generate\ndocids for all documents in a corpus, ultimately creating a docid bank for the\nentire corpus. During retrieval, we feed a query to the same LLM and constrain\nit to generate a docid within the docid bank created during indexing, and then\nmap the generated docid back to its corresponding document. Few-Shot GR relies\nsolely on prompting an LLM without requiring any training, making it more\nefficient. Moreover, we devise few-shot indexing with one-to-many mapping to\nfurther enhance Few-Shot GR. Experiments show that Few-Shot GR achieves\nsuperior performance to state-of-the-art GR methods that require heavy\ntraining.\n","subjects":["Computing Research Repository/Information Retrieval","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"e1uH5emqy4zs8GOCPbTdC4fjtNMgMvYSu0_3AWsCX4Q","pdfSize":"270761","txDigest":"AtjSfkgPexZ1xD9htemwVxNgLA3NsHp9wE3Zfjarps2Y","endEpoch":"1","status":"CERTIFIED"}
