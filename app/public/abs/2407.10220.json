{"id":"2407.10220","title":"PAFUSE: Part-based Diffusion for 3D Whole-Body Pose Estimation","authors":"Nermin Samet, C\\'edric Rommel, David Picard, Eduardo Valle","authorsParsed":[["Samet","Nermin",""],["Rommel","CÃ©dric",""],["Picard","David",""],["Valle","Eduardo",""]],"versions":[{"version":"v1","created":"Sun, 14 Jul 2024 14:24:05 GMT"}],"updateDate":"2024-07-16","timestamp":1720967045000,"abstract":"  We introduce a novel approach for 3D whole-body pose estimation, addressing\nthe challenge of scale- and deformability- variance across body parts brought\nby the challenge of extending the 17 major joints on the human body to\nfine-grained keypoints on the face and hands. In addition to addressing the\nchallenge of exploiting motion in unevenly sampled data, we combine stable\ndiffusion to a hierarchical part representation which predicts the relative\nlocations of fine-grained keypoints within each part (e.g., face) with respect\nto the part's local reference frame. On the H3WB dataset, our method greatly\noutperforms the current state of the art, which fails to exploit the temporal\ninformation. We also show considerable improvements compared to other\nspatiotemporal 3D human-pose estimation approaches that fail to account for the\nbody part specificities. Code is available at\nhttps://github.com/valeoai/PAFUSE.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}