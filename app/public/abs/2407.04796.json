{"id":"2407.04796","title":"Toucan: Many-to-Many Translation for 150 African Language Pairs","authors":"AbdelRahim Elmadany, Ife Adebara, Muhammad Abdul-Mageed","authorsParsed":[["Elmadany","AbdelRahim",""],["Adebara","Ife",""],["Abdul-Mageed","Muhammad",""]],"versions":[{"version":"v1","created":"Fri, 5 Jul 2024 18:12:19 GMT"},{"version":"v2","created":"Fri, 12 Jul 2024 17:13:47 GMT"}],"updateDate":"2024-07-15","timestamp":1720203139000,"abstract":"  We address a notable gap in Natural Language Processing (NLP) by introducing\na collection of resources designed to improve Machine Translation (MT) for\nlow-resource languages, with a specific focus on African languages. First, we\nintroduce two language models (LMs), Cheetah-1.2B and Cheetah-3.7B, with 1.2\nbillion and 3.7 billion parameters respectively. Next, we finetune the\naforementioned models to create toucan, an Afrocentric machine translation\nmodel designed to support 156 African language pairs. To evaluate Toucan, we\ncarefully develop an extensive machine translation benchmark, dubbed\nAfroLingu-MT, tailored for evaluating machine translation. Toucan significantly\noutperforms other models, showcasing its remarkable performance on MT for\nAfrican languages. Finally, we train a new model, spBLEU-1K, to enhance\ntranslation evaluation metrics, covering 1K languages, including 614 African\nlanguages. This work aims to advance the field of NLP, fostering cross-cultural\nunderstanding and knowledge exchange, particularly in regions with limited\nlanguage resources such as Africa. The GitHub repository for the Toucan project\nis available at https://github.com/UBC-NLP/Toucan.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}