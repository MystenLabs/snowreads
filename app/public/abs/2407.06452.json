{"id":"2407.06452","title":"Exploiting Heterogeneity in Timescales for Sparse Recurrent Spiking\n  Neural Networks for Energy-Efficient Edge Computing","authors":"Biswadeep Chakraborty, Saibal Mukhopadhyay","authorsParsed":[["Chakraborty","Biswadeep",""],["Mukhopadhyay","Saibal",""]],"versions":[{"version":"v1","created":"Mon, 8 Jul 2024 23:33:12 GMT"}],"updateDate":"2024-07-10","timestamp":1720481592000,"abstract":"  Spiking Neural Networks (SNNs) represent the forefront of neuromorphic\ncomputing, promising energy-efficient and biologically plausible models for\ncomplex tasks. This paper weaves together three groundbreaking studies that\nrevolutionize SNN performance through the introduction of heterogeneity in\nneuron and synapse dynamics. We explore the transformative impact of\nHeterogeneous Recurrent Spiking Neural Networks (HRSNNs), supported by rigorous\nanalytical frameworks and novel pruning methods like Lyapunov Noise Pruning\n(LNP). Our findings reveal how heterogeneity not only enhances classification\nperformance but also reduces spiking activity, leading to more efficient and\nrobust networks. By bridging theoretical insights with practical applications,\nthis comprehensive summary highlights the potential of SNNs to outperform\ntraditional neural networks while maintaining lower computational costs. Join\nus on a journey through the cutting-edge advancements that pave the way for the\nfuture of intelligent, energy-efficient neural computing.\n","subjects":["Computing Research Repository/Neural and Evolutionary Computing","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/"}