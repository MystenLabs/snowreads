{"id":"2407.13957","title":"The Group Robustness is in the Details: Revisiting Finetuning under\n  Spurious Correlations","authors":"Tyler LaBonte and John C. Hill and Xinchen Zhang and Vidya Muthukumar\n  and Abhishek Kumar","authorsParsed":[["LaBonte","Tyler",""],["Hill","John C.",""],["Zhang","Xinchen",""],["Muthukumar","Vidya",""],["Kumar","Abhishek",""]],"versions":[{"version":"v1","created":"Fri, 19 Jul 2024 00:34:03 GMT"}],"updateDate":"2024-07-22","timestamp":1721349243000,"abstract":"  Modern machine learning models are prone to over-reliance on spurious\ncorrelations, which can often lead to poor performance on minority groups. In\nthis paper, we identify surprising and nuanced behavior of finetuned models on\nworst-group accuracy via comprehensive experiments on four well-established\nbenchmarks across vision and language tasks. We first show that the commonly\nused class-balancing techniques of mini-batch upsampling and loss upweighting\ncan induce a decrease in worst-group accuracy (WGA) with training epochs,\nleading to performance no better than without class-balancing. While in some\nscenarios, removing data to create a class-balanced subset is more effective,\nwe show this depends on group structure and propose a mixture method which can\noutperform both techniques. Next, we show that scaling pretrained models is\ngenerally beneficial for worst-group accuracy, but only in conjuction with\nappropriate class-balancing. Finally, we identify spectral imbalance in\nfinetuning features as a potential source of group disparities -- minority\ngroup covariance matrices incur a larger spectral norm than majority groups\nonce conditioned on the classes. Our results show more nuanced interactions of\nmodern finetuned models with group robustness than was previously known. Our\ncode is available at https://github.com/tmlabonte/revisiting-finetuning.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}