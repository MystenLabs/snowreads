{"id":"2408.11055","title":"Prompt-Guided Image-Adaptive Neural Implicit Lookup Tables for\n  Interpretable Image Enhancement","authors":"Satoshi Kosugi","authorsParsed":[["Kosugi","Satoshi",""]],"versions":[{"version":"v1","created":"Tue, 20 Aug 2024 17:59:01 GMT"}],"updateDate":"2024-08-21","timestamp":1724176741000,"abstract":"  In this paper, we delve into the concept of interpretable image enhancement,\na technique that enhances image quality by adjusting filter parameters with\neasily understandable names such as \"Exposure\" and \"Contrast\". Unlike using\npredefined image editing filters, our framework utilizes learnable filters that\nacquire interpretable names through training. Our contribution is two-fold.\nFirstly, we introduce a novel filter architecture called an image-adaptive\nneural implicit lookup table, which uses a multilayer perceptron to implicitly\ndefine the transformation from input feature space to output color space. By\nincorporating image-adaptive parameters directly into the input features, we\nachieve highly expressive filters. Secondly, we introduce a prompt guidance\nloss to assign interpretable names to each filter. We evaluate visual\nimpressions of enhancement results, such as exposure and contrast, using a\nvision and language model along with guiding prompts. We define a constraint to\nensure that each filter affects only the targeted visual impression without\ninfluencing other attributes, which allows us to obtain the desired filter\neffects. Experimental results show that our method outperforms existing\npredefined filter-based methods, thanks to the filters optimized to predict\ntarget results. Our source code is available at\nhttps://github.com/satoshi-kosugi/PG-IA-NILUT.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}