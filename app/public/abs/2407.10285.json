{"id":"2407.10285","title":"Noise Calibration: Plug-and-play Content-Preserving Video Enhancement\n  using Pre-trained Video Diffusion Models","authors":"Qinyu Yang, Haoxin Chen, Yong Zhang, Menghan Xia, Xiaodong Cun, Zhixun\n  Su and Ying Shan","authorsParsed":[["Yang","Qinyu",""],["Chen","Haoxin",""],["Zhang","Yong",""],["Xia","Menghan",""],["Cun","Xiaodong",""],["Su","Zhixun",""],["Shan","Ying",""]],"versions":[{"version":"v1","created":"Sun, 14 Jul 2024 17:59:56 GMT"}],"updateDate":"2024-07-16","timestamp":1720979996000,"abstract":"  In order to improve the quality of synthesized videos, currently, one\npredominant method involves retraining an expert diffusion model and then\nimplementing a noising-denoising process for refinement. Despite the\nsignificant training costs, maintaining consistency of content between the\noriginal and enhanced videos remains a major challenge. To tackle this\nchallenge, we propose a novel formulation that considers both visual quality\nand consistency of content. Consistency of content is ensured by a proposed\nloss function that maintains the structure of the input, while visual quality\nis improved by utilizing the denoising process of pretrained diffusion models.\nTo address the formulated optimization problem, we have developed a\nplug-and-play noise optimization strategy, referred to as Noise Calibration. By\nrefining the initial random noise through a few iterations, the content of\noriginal video can be largely preserved, and the enhancement effect\ndemonstrates a notable improvement. Extensive experiments have demonstrated the\neffectiveness of the proposed method.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}