{"id":"2408.12119","title":"Understanding Data Reconstruction Leakage in Federated Learning from a\n  Theoretical Perspective","authors":"Zifan Wang, Binghui Zhang, Meng Pang, Yuan Hong, and Binghui Wang","authorsParsed":[["Wang","Zifan",""],["Zhang","Binghui",""],["Pang","Meng",""],["Hong","Yuan",""],["Wang","Binghui",""]],"versions":[{"version":"v1","created":"Thu, 22 Aug 2024 04:20:48 GMT"}],"updateDate":"2024-08-23","timestamp":1724300448000,"abstract":"  Federated learning (FL) is an emerging collaborative learning paradigm that\naims to protect data privacy. Unfortunately, recent works show FL algorithms\nare vulnerable to the serious data reconstruction attacks. However, existing\nworks lack a theoretical foundation on to what extent the devices' data can be\nreconstructed and the effectiveness of these attacks cannot be compared fairly\ndue to their unstable performance. To address this deficiency, we propose a\ntheoretical framework to understand data reconstruction attacks to FL. Our\nframework involves bounding the data reconstruction error and an attack's error\nbound reflects its inherent attack effectiveness. Under the framework, we can\ntheoretically compare the effectiveness of existing attacks. For instance, our\nresults on multiple datasets validate that the iDLG attack inherently\noutperforms the DLG attack.\n","subjects":["Computing Research Repository/Cryptography and Security","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/"}