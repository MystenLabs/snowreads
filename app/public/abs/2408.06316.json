{"id":"2408.06316","title":"Body Transformer: Leveraging Robot Embodiment for Policy Learning","authors":"Carmelo Sferrazza, Dun-Ming Huang, Fangchen Liu, Jongmin Lee, Pieter\n  Abbeel","authorsParsed":[["Sferrazza","Carmelo",""],["Huang","Dun-Ming",""],["Liu","Fangchen",""],["Lee","Jongmin",""],["Abbeel","Pieter",""]],"versions":[{"version":"v1","created":"Mon, 12 Aug 2024 17:31:28 GMT"}],"updateDate":"2024-08-13","timestamp":1723483888000,"abstract":"  In recent years, the transformer architecture has become the de facto\nstandard for machine learning algorithms applied to natural language processing\nand computer vision. Despite notable evidence of successful deployment of this\narchitecture in the context of robot learning, we claim that vanilla\ntransformers do not fully exploit the structure of the robot learning problem.\nTherefore, we propose Body Transformer (BoT), an architecture that leverages\nthe robot embodiment by providing an inductive bias that guides the learning\nprocess. We represent the robot body as a graph of sensors and actuators, and\nrely on masked attention to pool information throughout the architecture. The\nresulting architecture outperforms the vanilla transformer, as well as the\nclassical multilayer perceptron, in terms of task completion, scaling\nproperties, and computational efficiency when representing either imitation or\nreinforcement learning policies. Additional material including the open-source\ncode is available at https://sferrazza.cc/bot_site.\n","subjects":["Computing Research Repository/Robotics","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}