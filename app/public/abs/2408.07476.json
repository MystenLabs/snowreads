{"id":"2408.07476","title":"One Step Diffusion-based Super-Resolution with Time-Aware Distillation","authors":"Xiao He, Huaao Tang, Zhijun Tu, Junchao Zhang, Kun Cheng, Hanting\n  Chen, Yong Guo, Mingrui Zhu, Nannan Wang, Xinbo Gao, Jie Hu","authorsParsed":[["He","Xiao",""],["Tang","Huaao",""],["Tu","Zhijun",""],["Zhang","Junchao",""],["Cheng","Kun",""],["Chen","Hanting",""],["Guo","Yong",""],["Zhu","Mingrui",""],["Wang","Nannan",""],["Gao","Xinbo",""],["Hu","Jie",""]],"versions":[{"version":"v1","created":"Wed, 14 Aug 2024 11:47:22 GMT"}],"updateDate":"2024-08-15","timestamp":1723636042000,"abstract":"  Diffusion-based image super-resolution (SR) methods have shown promise in\nreconstructing high-resolution images with fine details from low-resolution\ncounterparts. However, these approaches typically require tens or even hundreds\nof iterative samplings, resulting in significant latency. Recently, techniques\nhave been devised to enhance the sampling efficiency of diffusion-based SR\nmodels via knowledge distillation. Nonetheless, when aligning the knowledge of\nstudent and teacher models, these solutions either solely rely on pixel-level\nloss constraints or neglect the fact that diffusion models prioritize varying\nlevels of information at different time steps. To accomplish effective and\nefficient image super-resolution, we propose a time-aware diffusion\ndistillation method, named TAD-SR. Specifically, we introduce a novel score\ndistillation strategy to align the data distribution between the outputs of the\nstudent and teacher models after minor noise perturbation. This distillation\nstrategy enables the student network to concentrate more on the high-frequency\ndetails. Furthermore, to mitigate performance limitations stemming from\ndistillation, we integrate a latent adversarial loss and devise a time-aware\ndiscriminator that leverages diffusion priors to effectively distinguish\nbetween real images and generated images. Extensive experiments conducted on\nsynthetic and real-world datasets demonstrate that the proposed method achieves\ncomparable or even superior performance compared to both previous\nstate-of-the-art (SOTA) methods and the teacher model in just one sampling\nstep. Codes are available at https://github.com/LearningHx/TAD-SR.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}