{"id":"2407.21338","title":"Image-Based Deep Reinforcement Learning with Intrinsically Motivated\n  Stimuli: On the Execution of Complex Robotic Tasks","authors":"David Valencia, Henry Williams, Yuning Xing, Trevor Gee, Minas\n  Liarokapis, Bruce A. MacDonald","authorsParsed":[["Valencia","David",""],["Williams","Henry",""],["Xing","Yuning",""],["Gee","Trevor",""],["Liarokapis","Minas",""],["MacDonald","Bruce A.",""]],"versions":[{"version":"v1","created":"Wed, 31 Jul 2024 05:11:06 GMT"}],"updateDate":"2024-08-01","timestamp":1722402666000,"abstract":"  Reinforcement Learning (RL) has been widely used to solve tasks where the\nenvironment consistently provides a dense reward value. However, in real-world\nscenarios, rewards can often be poorly defined or sparse. Auxiliary signals are\nindispensable for discovering efficient exploration strategies and aiding the\nlearning process. In this work, inspired by intrinsic motivation theory, we\npostulate that the intrinsic stimuli of novelty and surprise can assist in\nimproving exploration in complex, sparsely rewarded environments. We introduce\na novel sample-efficient method able to learn directly from pixels, an\nimage-based extension of TD3 with an autoencoder called \\textit{NaSA-TD3}. The\nexperiments demonstrate that NaSA-TD3 is easy to train and an efficient method\nfor tackling complex continuous-control robotic tasks, both in simulated\nenvironments and real-world settings. NaSA-TD3 outperforms existing\nstate-of-the-art RL image-based methods in terms of final performance without\nrequiring pre-trained models or human demonstrations.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"a5Jj0d9exPAGTlpOoEX3DzRxLdAP1FEcgvShQ0dXTik","pdfSize":"2109665"}
