{"id":"2407.12982","title":"Retrieval-Enhanced Machine Learning: Synthesis and Opportunities","authors":"To Eun Kim, Alireza Salemi, Andrew Drozdov, Fernando Diaz, Hamed\n  Zamani","authorsParsed":[["Kim","To Eun",""],["Salemi","Alireza",""],["Drozdov","Andrew",""],["Diaz","Fernando",""],["Zamani","Hamed",""]],"versions":[{"version":"v1","created":"Wed, 17 Jul 2024 20:01:21 GMT"}],"updateDate":"2024-07-19","timestamp":1721246481000,"abstract":"  In the field of language modeling, models augmented with retrieval components\nhave emerged as a promising solution to address several challenges faced in the\nnatural language processing (NLP) field, including knowledge grounding,\ninterpretability, and scalability. Despite the primary focus on NLP, we posit\nthat the paradigm of retrieval-enhancement can be extended to a broader\nspectrum of machine learning (ML) such as computer vision, time series\nprediction, and computational biology. Therefore, this work introduces a formal\nframework of this paradigm, Retrieval-Enhanced Machine Learning (REML), by\nsynthesizing the literature in various domains in ML with consistent notations\nwhich is missing from the current literature. Also, we found that while a\nnumber of studies employ retrieval components to augment their models, there is\na lack of integration with foundational Information Retrieval (IR) research. We\nbridge this gap between the seminal IR research and contemporary REML studies\nby investigating each component that comprises the REML framework. Ultimately,\nthe goal of this work is to equip researchers across various disciplines with a\ncomprehensive, formally structured framework of retrieval-enhanced models,\nthereby fostering interdisciplinary future research.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Computation and Language","Computing Research Repository/Information Retrieval"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}