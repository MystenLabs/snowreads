{"id":"2407.09165","title":"Robust Yet Efficient Conformal Prediction Sets","authors":"Soroush H. Zargarbashi, Mohammad Sadegh Akhondzadeh, Aleksandar\n  Bojchevski","authorsParsed":[["Zargarbashi","Soroush H.",""],["Akhondzadeh","Mohammad Sadegh",""],["Bojchevski","Aleksandar",""]],"versions":[{"version":"v1","created":"Fri, 12 Jul 2024 10:59:44 GMT"}],"updateDate":"2024-07-15","timestamp":1720781984000,"abstract":"  Conformal prediction (CP) can convert any model's output into prediction sets\nguaranteed to include the true label with any user-specified probability.\nHowever, same as the model itself, CP is vulnerable to adversarial test\nexamples (evasion) and perturbed calibration data (poisoning). We derive\nprovably robust sets by bounding the worst-case change in conformity scores.\nOur tighter bounds lead to more efficient sets. We cover both continuous and\ndiscrete (sparse) data and our guarantees work both for evasion and poisoning\nattacks (on both features and labels).\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}