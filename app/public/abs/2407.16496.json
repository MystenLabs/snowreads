{"id":"2407.16496","title":"Articulation Work and Tinkering for Fairness in Machine Learning","authors":"Miriam Fahimi, Mayra Russo, Kristen M. Scott, Maria-Esther Vidal,\n  Bettina Berendt, Katharina Kinder-Kurlanda","authorsParsed":[["Fahimi","Miriam",""],["Russo","Mayra",""],["Scott","Kristen M.",""],["Vidal","Maria-Esther",""],["Berendt","Bettina",""],["Kinder-Kurlanda","Katharina",""]],"versions":[{"version":"v1","created":"Tue, 23 Jul 2024 14:11:12 GMT"},{"version":"v2","created":"Wed, 28 Aug 2024 12:20:42 GMT"}],"updateDate":"2024-08-29","timestamp":1721743872000,"abstract":"  The field of fair AI aims to counter biased algorithms through computational\nmodelling. However, it faces increasing criticism for perpetuating the use of\noverly technical and reductionist methods. As a result, novel approaches appear\nin the field to address more socially-oriented and interdisciplinary (SOI)\nperspectives on fair AI. In this paper, we take this dynamic as the starting\npoint to study the tension between computer science (CS) and SOI research. By\ndrawing on STS and CSCW theory, we position fair AI research as a matter of\n'organizational alignment': what makes research 'doable' is the successful\nalignment of three levels of work organization (the social world, the\nlaboratory, and the experiment). Based on qualitative interviews with CS\nresearchers, we analyze the tasks, resources, and actors required for doable\nresearch in the case of fair AI. We find that CS researchers engage with SOI\nresearch to some extent, but organizational conditions, articulation work, and\nambiguities of the social world constrain the doability of SOI research for\nthem. Based on our findings, we identify and discuss problems for aligning CS\nand SOI as fair AI continues to evolve.\n","subjects":["Computing Research Repository/Computers and Society","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}