{"id":"2407.00993","title":"Mobile-Bench: An Evaluation Benchmark for LLM-based Mobile Agents","authors":"Shihan Deng, Weikai Xu, Hongda Sun, Wei Liu, Tao Tan, Jianfeng Liu,\n  Ang Li, Jian Luan, Bin Wang, Rui Yan, Shuo Shang","authorsParsed":[["Deng","Shihan",""],["Xu","Weikai",""],["Sun","Hongda",""],["Liu","Wei",""],["Tan","Tao",""],["Liu","Jianfeng",""],["Li","Ang",""],["Luan","Jian",""],["Wang","Bin",""],["Yan","Rui",""],["Shang","Shuo",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 06:10:01 GMT"}],"updateDate":"2024-07-02","timestamp":1719814201000,"abstract":"  With the remarkable advancements of large language models (LLMs), LLM-based\nagents have become a research hotspot in human-computer interaction. However,\nthere is a scarcity of benchmarks available for LLM-based mobile agents.\nBenchmarking these agents generally faces three main challenges: (1) The\ninefficiency of UI-only operations imposes limitations to task evaluation. (2)\nSpecific instructions within a singular application lack adequacy for assessing\nthe multi-dimensional reasoning and decision-making capacities of LLM mobile\nagents. (3) Current evaluation metrics are insufficient to accurately assess\nthe process of sequential actions. To this end, we propose Mobile-Bench, a\nnovel benchmark for evaluating the capabilities of LLM-based mobile agents.\nFirst, we expand conventional UI operations by incorporating 103 collected APIs\nto accelerate the efficiency of task completion. Subsequently, we collect\nevaluation data by combining real user queries with augmentation from LLMs. To\nbetter evaluate different levels of planning capabilities for mobile agents,\nour data is categorized into three distinct groups: SAST, SAMT, and MAMT,\nreflecting varying levels of task complexity. Mobile-Bench comprises 832 data\nentries, with more than 200 tasks specifically designed to evaluate multi-APP\ncollaboration scenarios. Furthermore, we introduce a more accurate evaluation\nmetric, named CheckPoint, to assess whether LLM-based mobile agents reach\nessential points during their planning and reasoning steps.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}