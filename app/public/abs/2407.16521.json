{"id":"2407.16521","title":"AMONGAGENTS: Evaluating Large Language Models in the Interactive\n  Text-Based Social Deduction Game","authors":"Yizhou Chi, Lingjun Mao, Zineng Tang","authorsParsed":[["Chi","Yizhou",""],["Mao","Lingjun",""],["Tang","Zineng",""]],"versions":[{"version":"v1","created":"Tue, 23 Jul 2024 14:34:38 GMT"},{"version":"v2","created":"Wed, 24 Jul 2024 15:12:09 GMT"}],"updateDate":"2024-07-25","timestamp":1721745278000,"abstract":"  Strategic social deduction games serve as valuable testbeds for evaluating\nthe understanding and inference skills of language models, offering crucial\ninsights into social science, artificial intelligence, and strategic gaming.\nThis paper focuses on creating proxies of human behavior in simulated\nenvironments, with Among Us utilized as a tool for studying simulated human\nbehavior. The study introduces a text-based game environment, named\nAmongAgents, that mirrors the dynamics of Among Us. Players act as crew members\naboard a spaceship, tasked with identifying impostors who are sabotaging the\nship and eliminating the crew. Within this environment, the behavior of\nsimulated language agents is analyzed. The experiments involve diverse game\nsequences featuring different configurations of Crewmates and Impostor\npersonality archetypes. Our work demonstrates that state-of-the-art large\nlanguage models (LLMs) can effectively grasp the game rules and make decisions\nbased on the current context. This work aims to promote further exploration of\nLLMs in goal-oriented games with incomplete information and complex action\nspaces, as these settings offer valuable opportunities to assess language model\nperformance in socially driven scenarios.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/"}