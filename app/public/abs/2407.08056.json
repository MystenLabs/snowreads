{"id":"2407.08056","title":"Pareto Low-Rank Adapters: Efficient Multi-Task Learning with Preferences","authors":"Nikolaos Dimitriadis, Pascal Frossard, Francois Fleuret","authorsParsed":[["Dimitriadis","Nikolaos",""],["Frossard","Pascal",""],["Fleuret","Francois",""]],"versions":[{"version":"v1","created":"Wed, 10 Jul 2024 21:25:51 GMT"}],"updateDate":"2024-07-12","timestamp":1720646751000,"abstract":"  Dealing with multi-task trade-offs during inference can be addressed via\nPareto Front Learning (PFL) methods that parameterize the Pareto Front with a\nsingle model, contrary to traditional Multi-Task Learning (MTL) approaches that\noptimize for a single trade-off which has to be decided prior to training.\nHowever, recent PFL methodologies suffer from limited scalability, slow\nconvergence and excessive memory requirements compared to MTL approaches while\nexhibiting inconsistent mappings from preference space to objective space. In\nthis paper, we introduce PaLoRA, a novel parameter-efficient method that\naugments the original model with task-specific low-rank adapters and\ncontinuously parameterizes the Pareto Front in their convex hull. Our approach\ndedicates the original model and the adapters towards learning general and\ntask-specific features, respectively. Additionally, we propose a deterministic\nsampling schedule of preference vectors that reinforces this division of labor,\nenabling faster convergence and scalability to real world networks. Our\nexperimental results show that PaLoRA outperforms MTL and PFL baselines across\nvarious datasets, scales to large networks and provides a continuous\nparameterization of the Pareto Front, reducing the memory overhead $23.8-31.7$\ntimes compared with competing PFL baselines in scene understanding benchmarks.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}