{"id":"2408.04646","title":"Efficacy of Large Language Models in Systematic Reviews","authors":"Aaditya Shah and Shridhar Mehendale and Siddha Kanthi","authorsParsed":[["Shah","Aaditya",""],["Mehendale","Shridhar",""],["Kanthi","Siddha",""]],"versions":[{"version":"v1","created":"Sat, 3 Aug 2024 00:01:13 GMT"}],"updateDate":"2024-08-12","timestamp":1722643273000,"abstract":"  This study investigates the effectiveness of Large Language Models (LLMs) in\ninterpreting existing literature through a systematic review of the\nrelationship between Environmental, Social, and Governance (ESG) factors and\nfinancial performance. The primary objective is to assess how LLMs can\nreplicate a systematic review on a corpus of ESG-focused papers. We compiled\nand hand-coded a database of 88 relevant papers published from March 2020 to\nMay 2024. Additionally, we used a set of 238 papers from a previous systematic\nreview of ESG literature from January 2015 to February 2020. We evaluated two\ncurrent state-of-the-art LLMs, Meta AI's Llama 3 8B and OpenAI's GPT-4o, on the\naccuracy of their interpretations relative to human-made classifications on\nboth sets of papers. We then compared these results to a \"Custom GPT\" and a\nfine-tuned GPT-4o Mini model using the corpus of 238 papers as training data.\nThe fine-tuned GPT-4o Mini model outperformed the base LLMs by 28.3% on average\nin overall accuracy on prompt 1. At the same time, the \"Custom GPT\" showed a\n3.0% and 15.7% improvement on average in overall accuracy on prompts 2 and 3,\nrespectively. Our findings reveal promising results for investors and agencies\nto leverage LLMs to summarize complex evidence related to ESG investing,\nthereby enabling quicker decision-making and a more efficient market.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"GQxZNN44B9yE-_ATRq-1rySMKQWYZ_xL5IwiYPEfM8Y","pdfSize":"624870"}
