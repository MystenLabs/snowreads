{"id":"2407.13900","title":"Exploring the Evidence-Based Beliefs and Behaviors of LLM-Based\n  Programming Assistants","authors":"Chris Brown and Jason Cusati","authorsParsed":[["Brown","Chris",""],["Cusati","Jason",""]],"versions":[{"version":"v1","created":"Thu, 18 Jul 2024 21:06:39 GMT"}],"updateDate":"2024-07-22","timestamp":1721336799000,"abstract":"  Recent innovations in artificial intelligence (AI), primarily powered by\nlarge language models (LLMs), have transformed how programmers develop and\nmaintain software -- leading to new frontiers in software engineering (SE). The\nadvanced capabilities of LLM-based programming assistants to support software\ndevelopment tasks have led to a rise in the adoption of LLMs in SE. However,\nlittle is known about the evidenced-based practices, tools and processes\nverified by research findings, supported and adopted by AI programming\nassistants. To this end, our work conducts a preliminary evaluation exploring\nthe beliefs and behaviors of LLM used to support software development tasks. We\ninvestigate 17 evidence-based claims posited by empirical SE research across\nfive LLM-based programming assistants. Our findings show that LLM-based\nprogramming assistants have ambiguous beliefs regarding research claims, lack\ncredible evidence to support responses, and are incapable of adopting practices\ndemonstrated by empirical SE research to support development tasks. Based on\nour results, we provide implications for practitioners adopting LLM-based\nprogramming assistants in development contexts and shed light on future\nresearch directions to enhance the reliability and trustworthiness of LLMs --\naiming to increase awareness and adoption of evidence-based SE research\nfindings in practice.\n","subjects":["Computing Research Repository/Software Engineering"],"license":"http://creativecommons.org/licenses/by/4.0/"}