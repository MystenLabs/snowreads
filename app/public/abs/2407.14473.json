{"id":"2407.14473","title":"MLMT-CNN for Object Detection and Segmentation in Multi-layer and\n  Multi-spectral Images","authors":"Majedaldein Almahasneh, Adeline Paiement, Xianghua Xie, Jean\n  Aboudarham","authorsParsed":[["Almahasneh","Majedaldein",""],["Paiement","Adeline",""],["Xie","Xianghua",""],["Aboudarham","Jean",""]],"versions":[{"version":"v1","created":"Fri, 19 Jul 2024 17:21:53 GMT"}],"updateDate":"2024-07-22","timestamp":1721409713000,"abstract":"  Precisely localising solar Active Regions (AR) from multi-spectral images is\na challenging but important task in understanding solar activity and its\ninfluence on space weather. A main challenge comes from each modality capturing\na different location of the 3D objects, as opposed to typical multi-spectral\nimaging scenarios where all image bands observe the same scene. Thus, we refer\nto this special multi-spectral scenario as multi-layer. We present a multi-task\ndeep learning framework that exploits the dependencies between image bands to\nproduce 3D AR localisation (segmentation and detection) where different image\nbands (and physical locations) have their own set of results. Furthermore, to\naddress the difficulty of producing dense AR annotations for training\nsupervised machine learning (ML) algorithms, we adapt a training strategy based\non weak labels (i.e. bounding boxes) in a recursive manner. We compare our\ndetection and segmentation stages against baseline approaches for solar image\nanalysis (multi-channel coronal hole detection, SPOCA for ARs) and\nstate-of-the-art deep learning methods (Faster RCNN, U-Net). Additionally, both\ndetection a nd segmentation stages are quantitatively validated on artificially\ncreated data of similar spatial configurations made from annotated multi-modal\nmagnetic resonance images. Our framework achieves an average of 0.72 IoU\n(segmentation) and 0.90 F1 score (detection) across all modalities, comparing\nto the best performing baseline methods with scores of 0.53 and 0.58,\nrespectively, on the artificial dataset, and 0.84 F1 score in the AR detection\ntask comparing to baseline of 0.82 F1 score. Our segmentation results are\nqualitatively validated by an expert on real ARs.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Physics/Space Physics"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}