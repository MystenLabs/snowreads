{"id":"2407.09919","title":"Arbitrary-Scale Video Super-Resolution with Structural and Textural\n  Priors","authors":"Wei Shang, Dongwei Ren, Wanying Zhang, Yuming Fang, Wangmeng Zuo, Kede\n  Ma","authorsParsed":[["Shang","Wei",""],["Ren","Dongwei",""],["Zhang","Wanying",""],["Fang","Yuming",""],["Zuo","Wangmeng",""],["Ma","Kede",""]],"versions":[{"version":"v1","created":"Sat, 13 Jul 2024 15:27:39 GMT"}],"updateDate":"2024-07-16","timestamp":1720884459000,"abstract":"  Arbitrary-scale video super-resolution (AVSR) aims to enhance the resolution\nof video frames, potentially at various scaling factors, which presents several\nchallenges regarding spatial detail reproduction, temporal consistency, and\ncomputational complexity. In this paper, we first describe a strong baseline\nfor AVSR by putting together three variants of elementary building blocks: 1) a\nflow-guided recurrent unit that aggregates spatiotemporal information from\nprevious frames, 2) a flow-refined cross-attention unit that selects\nspatiotemporal information from future frames, and 3) a hyper-upsampling unit\nthat generates scaleaware and content-independent upsampling kernels. We then\nintroduce ST-AVSR by equipping our baseline with a multi-scale structural and\ntextural prior computed from the pre-trained VGG network. This prior has proven\neffective in discriminating structure and texture across different locations\nand scales, which is beneficial for AVSR. Comprehensive experiments show that\nST-AVSR significantly improves super-resolution quality, generalization\nability, and inference speed over the state-of-theart. The code is available at\nhttps://github.com/shangwei5/ST-AVSR.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}