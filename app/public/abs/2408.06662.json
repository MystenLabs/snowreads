{"id":"2408.06662","title":"Bi-directional Contextual Attention for 3D Dense Captioning","authors":"Minjung Kim, Hyung Suk Lim, Soonyoung Lee, Bumsoo Kim, Gunhee Kim","authorsParsed":[["Kim","Minjung",""],["Lim","Hyung Suk",""],["Lee","Soonyoung",""],["Kim","Bumsoo",""],["Kim","Gunhee",""]],"versions":[{"version":"v1","created":"Tue, 13 Aug 2024 06:25:54 GMT"}],"updateDate":"2024-08-14","timestamp":1723530354000,"abstract":"  3D dense captioning is a task involving the localization of objects and the\ngeneration of descriptions for each object in a 3D scene. Recent approaches\nhave attempted to incorporate contextual information by modeling relationships\nwith object pairs or aggregating the nearest neighbor features of an object.\nHowever, the contextual information constructed in these scenarios is limited\nin two aspects: first, objects have multiple positional relationships that\nexist across the entire global scene, not only near the object itself. Second,\nit faces with contradicting objectives--where localization and attribute\ndescriptions are generated better with tight localization, while descriptions\ninvolving global positional relations are generated better with contextualized\nfeatures of the global scene. To overcome this challenge, we introduce BiCA, a\ntransformer encoder-decoder pipeline that engages in 3D dense captioning for\neach object with Bi-directional Contextual Attention. Leveraging parallelly\ndecoded instance queries for objects and context queries for non-object\ncontexts, BiCA generates object-aware contexts, where the contexts relevant to\neach object is summarized, and context-aware objects, where the objects\nrelevant to the summarized object-aware contexts are aggregated. This extension\nrelieves previous methods from the contradicting objectives, enhancing both\nlocalization performance and enabling the aggregation of contextual features\nthroughout the global scene; thus improving caption generation performance\nsimultaneously. Extensive experiments on two of the most widely-used 3D dense\ncaptioning datasets demonstrate that our proposed method achieves a significant\nimprovement over prior methods.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}