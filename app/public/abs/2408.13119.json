{"id":"2408.13119","title":"Coarse-to-fine Alignment Makes Better Speech-image Retrieval","authors":"Lifeng Zhou and Yuke Li","authorsParsed":[["Zhou","Lifeng",""],["Li","Yuke",""]],"versions":[{"version":"v1","created":"Thu, 15 Aug 2024 02:21:49 GMT"},{"version":"v2","created":"Wed, 11 Sep 2024 10:00:50 GMT"}],"updateDate":"2024-09-12","timestamp":1723688509000,"abstract":"  In this paper, we propose a novel framework for speech-image retrieval. We\nutilize speech-image contrastive (SIC) learning tasks to align speech and image\nrepresentations at a coarse level and speech-image matching (SIM) learning\ntasks to further refine the fine-grained cross-modal alignment. SIC and SIM\nlearning tasks are jointly trained in a unified manner. To optimize the\nlearning process, we utilize an embedding queue that facilitates efficient\nsampling of high-quality and diverse negative representations during SIC\nlearning. Additionally, it enhances the learning of SIM tasks by effectively\nmining hard negatives based on contrastive similarities calculated in SIC\ntasks. To further optimize learning under noisy supervision, we incorporate\nmomentum distillation into the training process. Experimental results show that\nour framework outperforms the state-of-the-art method by more than 4% in R@1 on\ntwo benchmark datasets for the speech-image retrieval tasks. Moreover, as\nobserved in zero-shot experiments, our framework demonstrates excellent\ngeneralization capabilities.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Sound","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}