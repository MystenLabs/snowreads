{"id":"2408.00728","title":"CERT-ED: Certifiably Robust Text Classification for Edit Distance","authors":"Zhuoqun Huang, Neil G Marchant, Olga Ohrimenko, Benjamin I. P.\n  Rubinstein","authorsParsed":[["Huang","Zhuoqun",""],["Marchant","Neil G",""],["Ohrimenko","Olga",""],["Rubinstein","Benjamin I. P.",""]],"versions":[{"version":"v1","created":"Thu, 1 Aug 2024 17:20:24 GMT"}],"updateDate":"2024-08-02","timestamp":1722532824000,"abstract":"  With the growing integration of AI in daily life, ensuring the robustness of\nsystems to inference-time attacks is crucial. Among the approaches for\ncertifying robustness to such adversarial examples, randomized smoothing has\nemerged as highly promising due to its nature as a wrapper around arbitrary\nblack-box models. Previous work on randomized smoothing in natural language\nprocessing has primarily focused on specific subsets of edit distance\noperations, such as synonym substitution or word insertion, without exploring\nthe certification of all edit operations. In this paper, we adapt Randomized\nDeletion (Huang et al., 2023) and propose, CERTified Edit Distance defense\n(CERT-ED) for natural language classification. Through comprehensive\nexperiments, we demonstrate that CERT-ED outperforms the existing Hamming\ndistance method RanMASK (Zeng et al., 2023) in 4 out of 5 datasets in terms of\nboth accuracy and the cardinality of the certificate. By covering various\nthreat models, including 5 direct and 5 transfer attacks, our method improves\nempirical robustness in 38 out of 50 settings.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Cryptography and Security","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}