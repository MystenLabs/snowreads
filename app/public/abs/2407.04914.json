{"id":"2407.04914","title":"Analytic analysis of the worst-case complexity of the gradient method\n  with exact line search and the Polyak stepsize","authors":"Ya-Kui Huang, Hou-Duo Qi","authorsParsed":[["Huang","Ya-Kui",""],["Qi","Hou-Duo",""]],"versions":[{"version":"v1","created":"Sat, 6 Jul 2024 01:48:54 GMT"}],"updateDate":"2024-07-09","timestamp":1720230534000,"abstract":"  We give a novel analytic analysis of the worst-case complexity of the\ngradient method with exact line search and the Polyak stepsize, respectively,\nwhich previously could only be established by computer-assisted proof. Our\nanalysis is based on studying the linear convergence of a family of gradient\nmethods, whose stepsizes include the one determined by exact line search and\nthe Polyak stepsize as special instances. The asymptotic behavior of the\nconsidered family is also investigated which shows that the gradient method\nwith the Polyak stepsize will zigzag in a two-dimensional subspace spanned by\nthe two eigenvectors corresponding to the largest and smallest eigenvalues of\nthe Hessian.\n","subjects":["Mathematics/Optimization and Control"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/"}