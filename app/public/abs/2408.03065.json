{"id":"2408.03065","title":"SCOPE: A Synthetic Multi-Modal Dataset for Collective Perception\n  Including Physical-Correct Weather Conditions","authors":"J\\\"org Gamerdinger, Sven Teufel, Patrick Schulz, Stephan Amann,\n  Jan-Patrick Kirchner, Oliver Bringmann","authorsParsed":[["Gamerdinger","JÃ¶rg",""],["Teufel","Sven",""],["Schulz","Patrick",""],["Amann","Stephan",""],["Kirchner","Jan-Patrick",""],["Bringmann","Oliver",""]],"versions":[{"version":"v1","created":"Tue, 6 Aug 2024 09:35:50 GMT"}],"updateDate":"2024-08-07","timestamp":1722936950000,"abstract":"  Collective perception has received considerable attention as a promising\napproach to overcome occlusions and limited sensing ranges of vehicle-local\nperception in autonomous driving. In order to develop and test novel collective\nperception technologies, appropriate datasets are required. These datasets must\ninclude not only different environmental conditions, as they strongly influence\nthe perception capabilities, but also a wide range of scenarios with different\nroad users as well as realistic sensor models. Therefore, we propose the\nSynthetic COllective PErception (SCOPE) dataset. SCOPE is the first synthetic\nmulti-modal dataset that incorporates realistic camera and LiDAR models as well\nas parameterized and physically accurate weather simulations for both sensor\ntypes. The dataset contains 17,600 frames from over 40 diverse scenarios with\nup to 24 collaborative agents, infrastructure sensors, and passive traffic,\nincluding cyclists and pedestrians. In addition, recordings from two novel\ndigital-twin maps from Karlsruhe and T\\\"ubingen are included. The dataset is\navailable at https://ekut-es.github.io/scope\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}