{"id":"2408.13597","title":"Automated Software Vulnerability Patching using Large Language Models","authors":"Yu Nong, Haoran Yang, Long Cheng, Hongxin Hu, and Haipeng Cai","authorsParsed":[["Nong","Yu",""],["Yang","Haoran",""],["Cheng","Long",""],["Hu","Hongxin",""],["Cai","Haipeng",""]],"versions":[{"version":"v1","created":"Sat, 24 Aug 2024 14:51:50 GMT"}],"updateDate":"2024-08-27","timestamp":1724511110000,"abstract":"  Timely and effective vulnerability patching is essential for cybersecurity\ndefense, for which various approaches have been proposed yet still struggle to\ngenerate valid and correct patches for real-world vulnerabilities. In this\npaper, we leverage the power and merits of pre-trained large language models\n(LLMs) to enable automated vulnerability patching using no test input/exploit\nevidence and without model training/fine-tuning. To elicit LLMs to effectively\nreason about vulnerable code behaviors, which is essential for quality patch\ngeneration, we introduce adaptive prompting on LLMs and instantiate the\nmethodology as LLMPATCH, an automated LLM-based patching system. Our evaluation\nof LLMPATCH on real-world vulnerable code including zeroday vulnerabilities\ndemonstrates its superior performance to both existing prompting methods and\nstate-of-the-art non-LLM-based techniques (by 98.9% and 65.4% in F1 over the\nbest baseline performance). LLMPATCH has also successfully patched 7 out of 11\nzero-day vulnerabilities, including 2 that none of the four baselines compared\nwere able to.\n","subjects":["Computing Research Repository/Cryptography and Security","Computing Research Repository/Software Engineering"],"license":"http://creativecommons.org/licenses/by/4.0/"}