{"id":"2407.13469","title":"Fixed and Adaptive Simultaneous Machine Translation Strategies Using\n  Adapters","authors":"Abderrahmane Issam and Yusuf Can Semerci and Jan Scholtes and\n  Gerasimos Spanakis","authorsParsed":[["Issam","Abderrahmane",""],["Semerci","Yusuf Can",""],["Scholtes","Jan",""],["Spanakis","Gerasimos",""]],"versions":[{"version":"v1","created":"Thu, 18 Jul 2024 12:42:45 GMT"}],"updateDate":"2024-07-19","timestamp":1721306565000,"abstract":"  Simultaneous machine translation aims at solving the task of real-time\ntranslation by starting to translate before consuming the full input, which\nposes challenges in terms of balancing quality and latency of the translation.\nThe wait-$k$ policy offers a solution by starting to translate after consuming\n$k$ words, where the choice of the number $k$ directly affects the latency and\nquality. In applications where we seek to keep the choice over latency and\nquality at inference, the wait-$k$ policy obliges us to train more than one\nmodel. In this paper, we address the challenge of building one model that can\nfulfil multiple latency levels and we achieve this by introducing lightweight\nadapter modules into the decoder. The adapters are trained to be specialized\nfor different wait-$k$ values and compared to other techniques they offer more\nflexibility to allow for reaping the benefits of parameter sharing and\nminimizing interference. Additionally, we show that by combining with an\nadaptive strategy, we can further improve the results. Experiments on two\nlanguage directions show that our method outperforms or competes with other\nstrong baselines on most latency values.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"2hukKvvpSMuHwoqcA5vA9t_-NKFanFvmG-AVpHLlCnQ","pdfSize":"1732888","objectId":"0x7734b1d00492b6a7c6ad5955159bb7183c6076566c29a39c680463285e56d135","registeredEpoch":"3","certifiedEpoch":"3","startEpoch":"3","endEpoch":"203"}
