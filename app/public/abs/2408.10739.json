{"id":"2408.10739","title":"TrackNeRF: Bundle Adjusting NeRF from Sparse and Noisy Views via Feature\n  Tracks","authors":"Jinjie Mai, Wenxuan Zhu, Sara Rojas, Jesus Zarzar, Abdullah Hamdi,\n  Guocheng Qian, Bing Li, Silvio Giancola, Bernard Ghanem","authorsParsed":[["Mai","Jinjie",""],["Zhu","Wenxuan",""],["Rojas","Sara",""],["Zarzar","Jesus",""],["Hamdi","Abdullah",""],["Qian","Guocheng",""],["Li","Bing",""],["Giancola","Silvio",""],["Ghanem","Bernard",""]],"versions":[{"version":"v1","created":"Tue, 20 Aug 2024 11:14:23 GMT"}],"updateDate":"2024-08-21","timestamp":1724152463000,"abstract":"  Neural radiance fields (NeRFs) generally require many images with accurate\nposes for accurate novel view synthesis, which does not reflect realistic\nsetups where views can be sparse and poses can be noisy. Previous solutions for\nlearning NeRFs with sparse views and noisy poses only consider local geometry\nconsistency with pairs of views. Closely following \\textit{bundle adjustment}\nin Structure-from-Motion (SfM), we introduce TrackNeRF for more globally\nconsistent geometry reconstruction and more accurate pose optimization.\nTrackNeRF introduces \\textit{feature tracks}, \\ie connected pixel trajectories\nacross \\textit{all} visible views that correspond to the \\textit{same} 3D\npoints. By enforcing reprojection consistency among feature tracks, TrackNeRF\nencourages holistic 3D consistency explicitly. Through extensive experiments,\nTrackNeRF sets a new benchmark in noisy and sparse view reconstruction. In\nparticular, TrackNeRF shows significant improvements over the state-of-the-art\nBARF and SPARF by $\\sim8$ and $\\sim1$ in terms of PSNR on DTU under various\nsparse and noisy view setups. The code is available at\n\\href{https://tracknerf.github.io/}.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}