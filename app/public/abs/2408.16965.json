{"id":"2408.16965","title":"Contrastive Learning with Synthetic Positives","authors":"Dewen Zeng, Yawen Wu, Xinrong Hu, Xiaowei Xu, Yiyu Shi","authorsParsed":[["Zeng","Dewen",""],["Wu","Yawen",""],["Hu","Xinrong",""],["Xu","Xiaowei",""],["Shi","Yiyu",""]],"versions":[{"version":"v1","created":"Fri, 30 Aug 2024 01:47:43 GMT"}],"updateDate":"2024-09-02","timestamp":1724982463000,"abstract":"  Contrastive learning with the nearest neighbor has proved to be one of the\nmost efficient self-supervised learning (SSL) techniques by utilizing the\nsimilarity of multiple instances within the same class. However, its efficacy\nis constrained as the nearest neighbor algorithm primarily identifies ``easy''\npositive pairs, where the representations are already closely located in the\nembedding space. In this paper, we introduce a novel approach called\nContrastive Learning with Synthetic Positives (CLSP) that utilizes synthetic\nimages, generated by an unconditional diffusion model, as the additional\npositives to help the model learn from diverse positives. Through feature\ninterpolation in the diffusion model sampling process, we generate images with\ndistinct backgrounds yet similar semantic content to the anchor image. These\nimages are considered ``hard'' positives for the anchor image, and when\nincluded as supplementary positives in the contrastive loss, they contribute to\na performance improvement of over 2\\% and 1\\% in linear evaluation compared to\nthe previous NNCLR and All4One methods across multiple benchmark datasets such\nas CIFAR10, achieving state-of-the-art methods. On transfer learning\nbenchmarks, CLSP outperforms existing SSL frameworks on 6 out of 8 downstream\ndatasets. We believe CLSP establishes a valuable baseline for future SSL\nstudies incorporating synthetic data in the training process.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}