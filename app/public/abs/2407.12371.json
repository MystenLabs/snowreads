{"id":"2407.12371","title":"HIMO: A New Benchmark for Full-Body Human Interacting with Multiple\n  Objects","authors":"Xintao Lv, Liang Xu, Yichao Yan, Xin Jin, Congsheng Xu, Shuwen Wu,\n  Yifan Liu, Lincheng Li, Mengxiao Bi, Wenjun Zeng, Xiaokang Yang","authorsParsed":[["Lv","Xintao",""],["Xu","Liang",""],["Yan","Yichao",""],["Jin","Xin",""],["Xu","Congsheng",""],["Wu","Shuwen",""],["Liu","Yifan",""],["Li","Lincheng",""],["Bi","Mengxiao",""],["Zeng","Wenjun",""],["Yang","Xiaokang",""]],"versions":[{"version":"v1","created":"Wed, 17 Jul 2024 07:47:34 GMT"},{"version":"v2","created":"Wed, 11 Sep 2024 09:53:18 GMT"}],"updateDate":"2024-09-12","timestamp":1721202454000,"abstract":"  Generating human-object interactions (HOIs) is critical with the tremendous\nadvances of digital avatars. Existing datasets are typically limited to humans\ninteracting with a single object while neglecting the ubiquitous manipulation\nof multiple objects. Thus, we propose HIMO, a large-scale MoCap dataset of\nfull-body human interacting with multiple objects, containing 3.3K 4D HOI\nsequences and 4.08M 3D HOI frames. We also annotate HIMO with detailed textual\ndescriptions and temporal segments, benchmarking two novel tasks of HOI\nsynthesis conditioned on either the whole text prompt or the segmented text\nprompts as fine-grained timeline control. To address these novel tasks, we\npropose a dual-branch conditional diffusion model with a mutual interaction\nmodule for HOI synthesis. Besides, an auto-regressive generation pipeline is\nalso designed to obtain smooth transitions between HOI segments. Experimental\nresults demonstrate the generalization ability to unseen object geometries and\ntemporal compositions.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}