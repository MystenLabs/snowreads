{"id":"2407.05765","title":"Enlarging Feature Support Overlap for Domain Generalization","authors":"Yaoyao Zhu, Xiuding Cai, Dong Miao, Yu Yao and Zhongliang Fu","authorsParsed":[["Zhu","Yaoyao",""],["Cai","Xiuding",""],["Miao","Dong",""],["Yao","Yu",""],["Fu","Zhongliang",""]],"versions":[{"version":"v1","created":"Mon, 8 Jul 2024 09:16:42 GMT"}],"updateDate":"2024-07-09","timestamp":1720430202000,"abstract":"  Deep models often struggle with out-of-distribution (OOD) generalization,\nlimiting their real-world applicability beyond controlled laboratory settings.\nInvariant risk minimization (IRM) addresses this issue by learning invariant\nfeatures and minimizing the risk across different domains. Thus, it avoids the\npitfalls of pseudo-invariant features and spurious causality associated with\nempirical risk minimization (ERM). However, according to the support overlap\ntheorem, ERM and IRM may fail to address the OOD problem when pseudo-invariant\nfeatures have insufficient support overlap. To this end, we propose a novel\nmethod to enlarge feature support overlap for domain generalization.\nSpecifically, we introduce Bayesian random semantic data augmentation to\nincrease sample diversity and overcome the deficiency of IRM. Experiments on\nseveral challenging OOD generalization benchmarks demonstrate that our approach\nsurpasses existing models, delivering superior performance and robustness. The\ncode is available at \\url{https://github.com/YaoyaoZhu19/BSDG}.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}