{"id":"2407.01490","title":"LLM See, LLM Do: Guiding Data Generation to Target Non-Differentiable\n  Objectives","authors":"Lu\\'isa Shimabucoro, Sebastian Ruder, Julia Kreutzer, Marzieh Fadaee\n  and Sara Hooker","authorsParsed":[["Shimabucoro","Lu√≠sa",""],["Ruder","Sebastian",""],["Kreutzer","Julia",""],["Fadaee","Marzieh",""],["Hooker","Sara",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 17:26:21 GMT"},{"version":"v2","created":"Fri, 19 Jul 2024 10:45:21 GMT"}],"updateDate":"2024-07-22","timestamp":1719854781000,"abstract":"  The widespread adoption of synthetic data raises new questions about how\nmodels generating the data can influence other large language models (LLMs) via\ndistilled data. To start, our work exhaustively characterizes the impact of\npassive inheritance of model properties by systematically studying the\nconsequences of synthetic data integration. We provide one of the most\ncomprehensive studies to-date of how the source of synthetic data shapes\nmodels' internal biases, calibration and generations' textual attributes and\npreferences. We find that models are surprisingly sensitive towards certain\nattributes even when the synthetic data prompts appear \"neutral\". which invites\nthe question whether this sensitivity can be exploited for good.\n  Our findings invite the question can we explicitly steer the models towards\nthe properties we want at test time by exploiting the data generation process?\nThis would have historically been considered infeasible due to the cost of\ncollecting data with a specific characteristic or objective in mind. However,\nimprovement in the quality of synthetic data, as well as a shift towards\ngeneral-purpose models designed to follow a diverse way of instructions, means\nthis question is timely. We propose active inheritance as a term to describe\nintentionally constraining synthetic data according to a non-differentiable\nobjective. We demonstrate how active inheritance can steer the generation\nprofiles of models towards desirable non-differentiable attributes, e.g. high\nlexical diversity or low toxicity.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"xJP_oAPjpK3cAbpYQzbXWW2RNj3Ek0Xa7snp2725zQw","pdfSize":"909337"}
