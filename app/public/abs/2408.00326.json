{"id":"2408.00326","title":"Exploiting Preferences in Loss Functions for Sequential Recommendation\n  via Weak Transitivity","authors":"Hyunsoo Chung, Jungtaek Kim, Hyungeun Jo, Hyungwon Choi","authorsParsed":[["Chung","Hyunsoo",""],["Kim","Jungtaek",""],["Jo","Hyungeun",""],["Choi","Hyungwon",""]],"versions":[{"version":"v1","created":"Thu, 1 Aug 2024 06:55:19 GMT"}],"updateDate":"2024-08-02","timestamp":1722495319000,"abstract":"  A choice of optimization objective is immensely pivotal in the design of a\nrecommender system as it affects the general modeling process of a user's\nintent from previous interactions. Existing approaches mainly adhere to three\ncategories of loss functions: pairwise, pointwise, and setwise loss functions.\nDespite their effectiveness, a critical and common drawback of such objectives\nis viewing the next observed item as a unique positive while considering all\nremaining items equally negative. Such a binary label assignment is generally\nlimited to assuring a higher recommendation score of the positive item,\nneglecting potential structures induced by varying preferences between other\nunobserved items. To alleviate this issue, we propose a novel method that\nextends original objectives to explicitly leverage the different levels of\npreferences as relative orders between their scores. Finally, we demonstrate\nthe superior performance of our method compared to baseline objectives.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Information Retrieval"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}