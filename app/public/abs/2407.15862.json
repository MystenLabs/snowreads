{"id":"2407.15862","title":"Performance Evaluation of Lightweight Open-source Large Language Models\n  in Pediatric Consultations: A Comparative Analysis","authors":"Qiuhong Wei, Ying Cui, Mengwei Ding, Yanqin Wang, Lingling Xiang,\n  Zhengxiong Yao, Ceran Chen, Ying Long, Zhezhen Jin and Ximing Xu","authorsParsed":[["Wei","Qiuhong",""],["Cui","Ying",""],["Ding","Mengwei",""],["Wang","Yanqin",""],["Xiang","Lingling",""],["Yao","Zhengxiong",""],["Chen","Ceran",""],["Long","Ying",""],["Jin","Zhezhen",""],["Xu","Ximing",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 03:35:09 GMT"}],"updateDate":"2024-07-24","timestamp":1721100909000,"abstract":"  Large language models (LLMs) have demonstrated potential applications in\nmedicine, yet data privacy and computational burden limit their deployment in\nhealthcare institutions. Open-source and lightweight versions of LLMs emerge as\npotential solutions, but their performance, particularly in pediatric settings\nremains underexplored. In this cross-sectional study, 250 patient consultation\nquestions were randomly selected from a public online medical forum, with 10\nquestions from each of 25 pediatric departments, spanning from December 1,\n2022, to October 30, 2023. Two lightweight open-source LLMs, ChatGLM3-6B and\nVicuna-7B, along with a larger-scale model, Vicuna-13B, and the widely-used\nproprietary ChatGPT-3.5, independently answered these questions in Chinese\nbetween November 1, 2023, and November 7, 2023. To assess reproducibility, each\ninquiry was replicated once. We found that ChatGLM3-6B demonstrated higher\naccuracy and completeness than Vicuna-13B and Vicuna-7B (P < .001), but all\nwere outperformed by ChatGPT-3.5. ChatGPT-3.5 received the highest ratings in\naccuracy (65.2%) compared to ChatGLM3-6B (41.2%), Vicuna-13B (11.2%), and\nVicuna-7B (4.4%). Similarly, in completeness, ChatGPT-3.5 led (78.4%), followed\nby ChatGLM3-6B (76.0%), Vicuna-13B (34.8%), and Vicuna-7B (22.0%) in highest\nratings. ChatGLM3-6B matched ChatGPT-3.5 in readability, both outperforming\nVicuna models (P < .001). In terms of empathy, ChatGPT-3.5 outperformed the\nlightweight LLMs (P < .001). In safety, all models performed comparably well (P\n> .05), with over 98.4% of responses being rated as safe. Repetition of\ninquiries confirmed these findings. In conclusion, Lightweight LLMs demonstrate\npromising application in pediatric healthcare. However, the observed gap\nbetween lightweight and large-scale proprietary LLMs underscores the need for\ncontinued development efforts.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language","Computing Research Repository/Computers and Society"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"x_bWjm_kP4Pv4PJ23yvLoKKhNRB_k7XcvsBFAIh2BbM","pdfSize":"2332927"}
