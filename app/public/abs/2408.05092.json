{"id":"2408.05092","title":"PriPHiT: Privacy-Preserving Hierarchical Training of Deep Neural\n  Networks","authors":"Yamin Sepehri, Pedram Pad, Pascal Frossard, L. Andrea Dunbar","authorsParsed":[["Sepehri","Yamin",""],["Pad","Pedram",""],["Frossard","Pascal",""],["Dunbar","L. Andrea",""]],"versions":[{"version":"v1","created":"Fri, 9 Aug 2024 14:33:34 GMT"}],"updateDate":"2024-08-12","timestamp":1723214014000,"abstract":"  The training phase of deep neural networks requires substantial resources and\nas such is often performed on cloud servers. However, this raises privacy\nconcerns when the training dataset contains sensitive content, e.g., face\nimages. In this work, we propose a method to perform the training phase of a\ndeep learning model on both an edge device and a cloud server that prevents\nsensitive content being transmitted to the cloud while retaining the desired\ninformation. The proposed privacy-preserving method uses adversarial early\nexits to suppress the sensitive content at the edge and transmits the\ntask-relevant information to the cloud. This approach incorporates noise\naddition during the training phase to provide a differential privacy guarantee.\nWe extensively test our method on different facial datasets with diverse face\nattributes using various deep learning architectures, showcasing its\noutstanding performance. We also demonstrate the effectiveness of privacy\npreservation through successful defenses against different white-box and deep\nreconstruction attacks.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Cryptography and Security","Computing Research Repository/Distributed, Parallel, and Cluster Computing","Computing Research Repository/Machine Learning","Electrical Engineering and Systems Science/Image and Video Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}