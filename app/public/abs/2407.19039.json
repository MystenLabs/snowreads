{"id":"2407.19039","title":"GraphBPE: Molecular Graphs Meet Byte-Pair Encoding","authors":"Yuchen Shen and Barnab\\'as P\\'oczos","authorsParsed":[["Shen","Yuchen",""],["Póczos","Barnabás",""]],"versions":[{"version":"v1","created":"Fri, 26 Jul 2024 18:45:09 GMT"}],"updateDate":"2024-07-30","timestamp":1722019509000,"abstract":"  With the increasing attention to molecular machine learning, various\ninnovations have been made in designing better models or proposing more\ncomprehensive benchmarks. However, less is studied on the data preprocessing\nschedule for molecular graphs, where a different view of the molecular graph\ncould potentially boost the model's performance. Inspired by the Byte-Pair\nEncoding (BPE) algorithm, a subword tokenization method popularly adopted in\nNatural Language Processing, we propose GraphBPE, which tokenizes a molecular\ngraph into different substructures and acts as a preprocessing schedule\nindependent of the model architectures. Our experiments on 3 graph-level\nclassification and 3 graph-level regression datasets show that data\npreprocessing could boost the performance of models for molecular graphs, and\nGraphBPE is effective for small classification datasets and it performs on par\nwith other tokenization methods across different model architectures.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence","Physics/Chemical Physics","Quantitative Biology/Biomolecules"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}