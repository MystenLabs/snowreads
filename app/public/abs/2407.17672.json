{"id":"2407.17672","title":"Spiking Neural Networks in Vertical Federated Learning: Performance\n  Trade-offs","authors":"Maryam Abbasihafshejani, Anindya Maiti, Murtuza Jadliwala","authorsParsed":[["Abbasihafshejani","Maryam",""],["Maiti","Anindya",""],["Jadliwala","Murtuza",""]],"versions":[{"version":"v1","created":"Wed, 24 Jul 2024 23:31:02 GMT"},{"version":"v2","created":"Tue, 13 Aug 2024 22:46:55 GMT"}],"updateDate":"2024-08-15","timestamp":1721863862000,"abstract":"  Federated machine learning enables model training across multiple clients\nwhile maintaining data privacy. Vertical Federated Learning (VFL) specifically\ndeals with instances where the clients have different feature sets of the same\nsamples. As federated learning models aim to improve efficiency and\nadaptability, innovative neural network architectures like Spiking Neural\nNetworks (SNNs) are being leveraged to enable fast and accurate processing at\nthe edge. SNNs, known for their efficiency over Artificial Neural Networks\n(ANNs), have not been analyzed for their applicability in VFL, thus far. In\nthis paper, we investigate the benefits and trade-offs of using SNN models in a\nvertical federated learning setting. We implement two different federated\nlearning architectures -- with model splitting and without model splitting --\nthat have different privacy and performance implications. We evaluate the setup\nusing CIFAR-10 and CIFAR-100 benchmark datasets along with SNN implementations\nof VGG9 and ResNET classification models. Comparative evaluations demonstrate\nthat the accuracy of SNN models is comparable to that of traditional ANNs for\nVFL applications, albeit significantly more energy efficient.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"2ljTDATC6lqblbdSST6MgFoyiZCjPSw2nufDnim4onM","pdfSize":"1076725"}
