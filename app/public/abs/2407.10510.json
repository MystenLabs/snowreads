{"id":"2407.10510","title":"TCM-FTP: Fine-Tuning Large Language Models for Herbal Prescription\n  Prediction","authors":"Xingzhi Zhou, Xin Dong, Chunhao Li, Yuning Bai, Yulong Xu, Ka Chun\n  Cheung, Simon See, Xinpeng Song, Runshun Zhang, Xuezhong Zhou, and Nevin L.\n  Zhang","authorsParsed":[["Zhou","Xingzhi",""],["Dong","Xin",""],["Li","Chunhao",""],["Bai","Yuning",""],["Xu","Yulong",""],["Cheung","Ka Chun",""],["See","Simon",""],["Song","Xinpeng",""],["Zhang","Runshun",""],["Zhou","Xuezhong",""],["Zhang","Nevin L.",""]],"versions":[{"version":"v1","created":"Mon, 15 Jul 2024 08:06:37 GMT"}],"updateDate":"2024-07-16","timestamp":1721030797000,"abstract":"  Traditional Chinese medicine (TCM) relies on specific combinations of herbs\nin prescriptions to treat symptoms and signs, a practice that spans thousands\nof years. Predicting TCM prescriptions presents a fascinating technical\nchallenge with practical implications. However, this task faces limitations due\nto the scarcity of high-quality clinical datasets and the intricate\nrelationship between symptoms and herbs. To address these issues, we introduce\nDigestDS, a new dataset containing practical medical records from experienced\nexperts in digestive system diseases. We also propose a method, TCM-FTP (TCM\nFine-Tuning Pre-trained), to leverage pre-trained large language models (LLMs)\nthrough supervised fine-tuning on DigestDS. Additionally, we enhance\ncomputational efficiency using a low-rank adaptation technique. TCM-FTP also\nincorporates data augmentation by permuting herbs within prescriptions,\ncapitalizing on their order-agnostic properties. Impressively, TCM-FTP achieves\nan F1-score of 0.8031, surpassing previous methods significantly. Furthermore,\nit demonstrates remarkable accuracy in dosage prediction, achieving a\nnormalized mean square error of 0.0604. In contrast, LLMs without fine-tuning\nperform poorly. Although LLMs have shown capabilities on a wide range of tasks,\nthis work illustrates the importance of fine-tuning for TCM prescription\nprediction, and we have proposed an effective way to do that.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computational Engineering, Finance, and Science"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}