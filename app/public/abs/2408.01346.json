{"id":"2408.01346","title":"Prompt Refinement or Fine-tuning? Best Practices for using LLMs in\n  Computational Social Science Tasks","authors":"Anders Giovanni M{\\o}ller, Luca Maria Aiello","authorsParsed":[["MÃ¸ller","Anders Giovanni",""],["Aiello","Luca Maria",""]],"versions":[{"version":"v1","created":"Fri, 2 Aug 2024 15:46:36 GMT"}],"updateDate":"2024-08-05","timestamp":1722613596000,"abstract":"  Large Language Models are expressive tools that enable complex tasks of text\nunderstanding within Computational Social Science. Their versatility, while\nbeneficial, poses a barrier for establishing standardized best practices within\nthe field. To bring clarity on the values of different strategies, we present\nan overview of the performance of modern LLM-based classification methods on a\nbenchmark of 23 social knowledge tasks. Our results point to three best\npractices: select models with larger vocabulary and pre-training corpora; avoid\nsimple zero-shot in favor of AI-enhanced prompting; fine-tune on task-specific\ndata, and consider more complex forms instruction-tuning on multiple datasets\nonly when only training data is more abundant.\n","subjects":["Computing Research Repository/Computers and Society","Computing Research Repository/Computation and Language","Physics/Physics and Society"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}