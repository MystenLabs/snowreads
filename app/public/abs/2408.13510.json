{"id":"2408.13510","title":"Intelligent Router for LLM Workloads: Improving Performance Through\n  Workload-Aware Scheduling","authors":"Kunal Jain, Anjaly Parayil, Ankur Mallick, Esha Choukse, Xiaoting Qin,\n  Jue Zhang, \\'I\\~nigo Goiri, Rujia Wang, Chetan Bansal, Victor R\\\"uhle, Anoop\n  Kulkarni, Steve Kofsky, Saravan Rajmohan","authorsParsed":[["Jain","Kunal",""],["Parayil","Anjaly",""],["Mallick","Ankur",""],["Choukse","Esha",""],["Qin","Xiaoting",""],["Zhang","Jue",""],["Goiri","Íñigo",""],["Wang","Rujia",""],["Bansal","Chetan",""],["Rühle","Victor",""],["Kulkarni","Anoop",""],["Kofsky","Steve",""],["Rajmohan","Saravan",""]],"versions":[{"version":"v1","created":"Sat, 24 Aug 2024 08:12:22 GMT"}],"updateDate":"2024-08-27","timestamp":1724487142000,"abstract":"  Large Language Model (LLM) workloads have distinct prefill and decode phases\nwith different compute and memory requirements which should ideally be\naccounted for when scheduling input queries across different LLM instances in a\ncluster. However existing scheduling algorithms treat LLM workloads as\nmonolithic jobs without considering the distinct characteristics of the two\nphases in each workload. This leads to sub-optimal scheduling and increased\nresponse latency. In this work, we propose a heuristic-guided reinforcement\nlearning-based intelligent router for data-driven and workload-aware\nscheduling. Our router leverages a trainable response-length predictor, and a\nnovel formulation for estimating the impact of mixing different workloads to\nschedule queries across LLM instances and achieve over 11\\% lower end-to-end\nlatency than existing approaches.\n","subjects":["Computing Research Repository/Distributed, Parallel, and Cluster Computing","Computing Research Repository/Systems and Control","Electrical Engineering and Systems Science/Systems and Control"],"license":"http://creativecommons.org/licenses/by-sa/4.0/"}