{"id":"2407.13608","title":"dzNLP at NADI 2024 Shared Task: Multi-Classifier Ensemble with Weighted\n  Voting and TF-IDF Features","authors":"Mohamed Lichouri, Khaled Lounnas, Boualem Nadjib Zahaf, Mehdi Ayoub\n  Rabiai","authorsParsed":[["Lichouri","Mohamed",""],["Lounnas","Khaled",""],["Zahaf","Boualem Nadjib",""],["Rabiai","Mehdi Ayoub",""]],"versions":[{"version":"v1","created":"Thu, 18 Jul 2024 15:47:42 GMT"}],"updateDate":"2024-07-19","timestamp":1721317662000,"abstract":"  This paper presents the contribution of our dzNLP team to the NADI 2024\nshared task, specifically in Subtask 1 - Multi-label Country-level Dialect\nIdentification (MLDID) (Closed Track). We explored various configurations to\naddress the challenge: in Experiment 1, we utilized a union of n-gram analyzers\n(word, character, character with word boundaries) with different n-gram values;\nin Experiment 2, we combined a weighted union of Term Frequency-Inverse\nDocument Frequency (TF-IDF) features with various weights; and in Experiment 3,\nwe implemented a weighted major voting scheme using three classifiers: Linear\nSupport Vector Classifier (LSVC), Random Forest (RF), and K-Nearest Neighbors\n(KNN).\n  Our approach, despite its simplicity and reliance on traditional machine\nlearning techniques, demonstrated competitive performance in terms of F1-score\nand precision. Notably, we achieved the highest precision score of 63.22% among\nthe participating teams. However, our overall F1 score was approximately 21%,\nsignificantly impacted by a low recall rate of 12.87%. This indicates that\nwhile our models were highly precise, they struggled to recall a broad range of\ndialect labels, highlighting a critical area for improvement in handling\ndiverse dialectal variations.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"Ky3n5PF5V4hlM9qt0ub2aXFcm4v88VWTMAIeSldbKMQ","pdfSize":"133109"}
