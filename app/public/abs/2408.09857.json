{"id":"2408.09857","title":"TaSL: Continual Dialog State Tracking via Task Skill Localization and\n  Consolidation","authors":"Yujie Feng, Xu Chu, Yongxin Xu, Guangyuan Shi, Bo Liu, Xiao-Ming Wu","authorsParsed":[["Feng","Yujie",""],["Chu","Xu",""],["Xu","Yongxin",""],["Shi","Guangyuan",""],["Liu","Bo",""],["Wu","Xiao-Ming",""]],"versions":[{"version":"v1","created":"Mon, 19 Aug 2024 10:01:28 GMT"}],"updateDate":"2024-09-01","timestamp":1724061688000,"abstract":"  A practical dialogue system requires the capacity for ongoing skill\nacquisition and adaptability to new tasks while preserving prior knowledge.\nHowever, current methods for Continual Dialogue State Tracking (DST), a crucial\nfunction of dialogue systems, struggle with the catastrophic forgetting issue\nand knowledge transfer between tasks. We present TaSL, a novel framework for\ntask skill localization and consolidation that enables effective knowledge\ntransfer without relying on memory replay. TaSL uses a novel group-wise\ntechnique to pinpoint task-specific and task-shared areas. Additionally, a\nfine-grained skill consolidation strategy protects task-specific knowledge from\nbeing forgotten while updating shared knowledge for bi-directional knowledge\ntransfer. As a result, TaSL strikes a balance between preserving previous\nknowledge and excelling at new tasks. Comprehensive experiments on various\nbackbones highlight the significant performance improvements of TaSL over\nexisting state-of-the-art methods. The source code is provided for\nreproducibility.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}