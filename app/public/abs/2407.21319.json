{"id":"2407.21319","title":"Big Cooperative Learning","authors":"Yulai Cong","authorsParsed":[["Cong","Yulai",""]],"versions":[{"version":"v1","created":"Wed, 31 Jul 2024 03:59:14 GMT"}],"updateDate":"2024-08-01","timestamp":1722398354000,"abstract":"  Cooperation plays a pivotal role in the evolution of human intelligence;\nmoreover, it also underlies the recent revolutionary advancement of artificial\nintelligence (AI) that is driven by foundation models. Specifically, we reveal\nthat the training of foundation models can be interpreted as a form of big\ncooperative learning (\\textit{abbr.} big learning), where massive learning\nindividuals/tasks \\emph{cooperate} to approach the unique essence of data from\ndiverse perspectives of data prediction, leveraging a universal model. The\npresented big learning therefore unifies most training objectives of foundation\nmodels within a consistent framework, where their underlying assumptions are\nexposed simultaneously. We design tailored simulations to demonstrate the\nprinciple of big learning, based on which we provide learning-perspective\njustifications for the successes of foundation models, with interesting\nside-products. Furthermore, we reveal that big learning is a new dimension for\nupgrading conventional machine learning paradigms, valuable for endowing\nreinvigorations to associated applications; as an illustrative example, we\npropose the BigLearn-GAN, which is a novel adversarially-trained foundation\nmodel with versatile data sampling capabilities. Code is available at\n\\texttt{https://github.com/YulaiCong/BigCooperativeLearning}.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}