{"id":"2407.05996","title":"Multimodal Diffusion Transformer: Learning Versatile Behavior from\n  Multimodal Goals","authors":"Moritz Reuss, \\\"Omer Erdin\\c{c} Ya\\u{g}murlu, Fabian Wenzel, Rudolf\n  Lioutikov","authorsParsed":[["Reuss","Moritz",""],["Yağmurlu","Ömer Erdinç",""],["Wenzel","Fabian",""],["Lioutikov","Rudolf",""]],"versions":[{"version":"v1","created":"Mon, 8 Jul 2024 14:46:44 GMT"}],"updateDate":"2024-07-09","timestamp":1720450004000,"abstract":"  This work introduces the Multimodal Diffusion Transformer (MDT), a novel\ndiffusion policy framework, that excels at learning versatile behavior from\nmultimodal goal specifications with few language annotations. MDT leverages a\ndiffusion-based multimodal transformer backbone and two self-supervised\nauxiliary objectives to master long-horizon manipulation tasks based on\nmultimodal goals. The vast majority of imitation learning methods only learn\nfrom individual goal modalities, e.g. either language or goal images. However,\nexisting large-scale imitation learning datasets are only partially labeled\nwith language annotations, which prohibits current methods from learning\nlanguage conditioned behavior from these datasets. MDT addresses this challenge\nby introducing a latent goal-conditioned state representation that is\nsimultaneously trained on multimodal goal instructions. This state\nrepresentation aligns image and language based goal embeddings and encodes\nsufficient information to predict future states. The representation is trained\nvia two self-supervised auxiliary objectives, enhancing the performance of the\npresented transformer backbone. MDT shows exceptional performance on 164 tasks\nprovided by the challenging CALVIN and LIBERO benchmarks, including a LIBERO\nversion that contains less than $2\\%$ language annotations. Furthermore, MDT\nestablishes a new record on the CALVIN manipulation challenge, demonstrating an\nabsolute performance improvement of $15\\%$ over prior state-of-the-art methods\nthat require large-scale pretraining and contain $10\\times$ more learnable\nparameters. MDT shows its ability to solve long-horizon manipulation from\nsparsely annotated data in both simulated and real-world environments.\nDemonstrations and Code are available at\nhttps://intuitive-robots.github.io/mdt_policy/.\n","subjects":["Computing Research Repository/Robotics"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"rmyE1ss79nOyw8gHUhh5MivugJ61VjK62lN1hFBGa2w","pdfSize":"33332084"}
