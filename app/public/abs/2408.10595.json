{"id":"2408.10595","title":"Synchronization behind Learning in Periodic Zero-Sum Games Triggers\n  Divergence from Nash equilibrium","authors":"Yuma Fujimoto, Kaito Ariu, Kenshi Abe","authorsParsed":[["Fujimoto","Yuma",""],["Ariu","Kaito",""],["Abe","Kenshi",""]],"versions":[{"version":"v1","created":"Tue, 20 Aug 2024 07:11:48 GMT"}],"updateDate":"2024-08-21","timestamp":1724137908000,"abstract":"  Learning in zero-sum games studies a situation where multiple agents\ncompetitively learn their strategy. In such multi-agent learning, we often see\nthat the strategies cycle around their optimum, i.e., Nash equilibrium. When a\ngame periodically varies (called a ``periodic'' game), however, the Nash\nequilibrium moves generically. How learning dynamics behave in such periodic\ngames is of interest but still unclear. Interestingly, we discover that the\nbehavior is highly dependent on the relationship between the two speeds at\nwhich the game changes and at which players learn. We observe that when these\ntwo speeds synchronize, the learning dynamics diverge, and their time-average\ndoes not converge. Otherwise, the learning dynamics draw complicated cycles,\nbut their time-average converges. Under some assumptions introduced for the\ndynamical systems analysis, we prove that this behavior occurs. Furthermore,\nour experiments observe this behavior even if removing these assumptions. This\nstudy discovers a novel phenomenon, i.e., synchronization, and gains insight\nwidely applicable to learning in periodic games.\n","subjects":["Computing Research Repository/Computer Science and Game Theory","Computing Research Repository/Multiagent Systems","Mathematics/Optimization and Control","Nonlinear Sciences/Chaotic Dynamics"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}