{"id":"2408.05160","title":"Federated Hypergraph Learning with Hyperedge Completion","authors":"Linfeng Luo, Fengxiao Tang, Xiyu Liu, Zhiqi Guo, Zihao Qiu, Ming Zhao","authorsParsed":[["Luo","Linfeng",""],["Tang","Fengxiao",""],["Liu","Xiyu",""],["Guo","Zhiqi",""],["Qiu","Zihao",""],["Zhao","Ming",""]],"versions":[{"version":"v1","created":"Fri, 9 Aug 2024 16:31:41 GMT"}],"updateDate":"2024-08-12","timestamp":1723221101000,"abstract":"  Hypergraph neural networks enhance conventional graph neural networks by\ncapturing high-order relationships among nodes, which proves vital in data-rich\nenvironments where interactions are not merely pairwise. As data complexity and\ninterconnectivity grow, it is common for graph-structured data to be split and\nstored in a distributed manner, underscoring the necessity of federated\nlearning on subgraphs. In this work, we propose FedHGN, a novel algorithm for\nfederated hypergraph learning. Our algorithm utilizes subgraphs of a hypergraph\nstored on distributed devices to train local HGNN models in a federated\nmanner:by collaboratively developing an effective global HGNN model through\nsharing model parameters while preserving client privacy. Additionally,\nconsidering that hyperedges may span multiple clients, a pre-training step is\nemployed before the training process in which cross-client hyperedge feature\ngathering is performed at the central server. In this way, the missing\ncross-client information can be supplemented from the central server during the\nnode feature aggregation phase. Experimental results on seven real-world\ndatasets confirm the effectiveness of our approach and demonstrate its\nperformance advantages over traditional federated graph learning methods.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}