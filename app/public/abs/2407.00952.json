{"id":"2407.00952","title":"SplitLoRA: A Split Parameter-Efficient Fine-Tuning Framework for Large\n  Language Models","authors":"Zheng Lin, Xuanjie Hu, Yuxin Zhang, Zhe Chen, Zihan Fang, Xianhao\n  Chen, Ang Li, Praneeth Vepakomma, Yue Gao","authorsParsed":[["Lin","Zheng",""],["Hu","Xuanjie",""],["Zhang","Yuxin",""],["Chen","Zhe",""],["Fang","Zihan",""],["Chen","Xianhao",""],["Li","Ang",""],["Vepakomma","Praneeth",""],["Gao","Yue",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 04:13:25 GMT"}],"updateDate":"2024-07-02","timestamp":1719807205000,"abstract":"  The scalability of large language models (LLMs) in handling high-complexity\nmodels and large-scale datasets has led to tremendous successes in pivotal\ndomains. While there is an urgent need to acquire more training data for LLMs,\na concerning reality is the depletion of high-quality public datasets within a\nfew years. In view of this, the federated learning (FL) LLM fine-tuning\nparadigm recently has been proposed to facilitate collaborative LLM fine-tuning\non distributed private data, where multiple data owners collaboratively\nfine-tune a shared LLM without sharing raw data. However, the staggering model\nsize of LLMs imposes heavy computing and communication burdens on clients,\nposing significant barriers to the democratization of the FL LLM fine-tuning\nparadigm. To address this issue, split learning (SL) has emerged as a promising\nsolution by offloading the primary training workload to a server via model\npartitioning while exchanging activation/activation's gradients with smaller\ndata sizes rather than the entire LLM. Unfortunately, research on the SL LLM\nfine-tuning paradigm is still in its nascent stage. To fill this gap, in this\npaper, we propose the first SL LLM fine-tuning framework, named SplitLoRA.\nSplitLoRA is built on the split federated learning (SFL) framework,\namalgamating the advantages of parallel training from FL and model splitting\nfrom SL and thus greatly enhancing the training efficiency. It is worth noting\nthat SplitLoRA is the inaugural open-source benchmark for SL LLM fine-tuning,\nproviding a foundation for research efforts dedicated to advancing SL LLM\nfine-tuning. Extensive simulations validate that SplitLoRA achieves target\naccuracy in significantly less time than state-of-the-art LLM fine-tuning\nframeworks, demonstrating the superior training performance of SplitLoRA. The\nproject page is available at https://fduinc.github.io/splitlora/.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Computation and Language","Computing Research Repository/Distributed, Parallel, and Cluster Computing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}