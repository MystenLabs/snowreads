{"id":"2408.10280","title":"NoRA: Nested Low-Rank Adaptation for Efficient Fine-Tuning Large Models","authors":"Cheng Lin, Lujun Li, Dezhi Li, Jie Zou, Wei Xue and Yike Guo","authorsParsed":[["Lin","Cheng",""],["Li","Lujun",""],["Li","Dezhi",""],["Zou","Jie",""],["Xue","Wei",""],["Guo","Yike",""]],"versions":[{"version":"v1","created":"Sun, 18 Aug 2024 12:18:56 GMT"},{"version":"v2","created":"Tue, 27 Aug 2024 15:34:49 GMT"}],"updateDate":"2024-08-28","timestamp":1723983536000,"abstract":"  In this paper, we introduce Nested Low-Rank Adaptation (NoRA), a novel\napproach to parameter-efficient fine-tuning that extends the capabilities of\nLow-Rank Adaptation (LoRA) techniques. Vanilla LoRA overlooks pre-trained\nweight inheritance and still requires fine-tuning numerous parameters. To\naddresses these issues, our NoRA adopts a dual-layer nested structure with\nSingular Value Decomposition (SVD), effectively leveraging original matrix\nknowledge while reducing tunable parameters. Specifically, NoRA freezes the\nouter LoRA weights and utilizes an inner LoRA design, providing enhanced\ncontrol over model optimization. This approach allows the model to more\nprecisely adapt to specific tasks while maintaining a compact parameter space.\nBy freezing outer LoRA weights and using an inner LoRA design, NoRA enables\nprecise task adaptation with a compact parameter space. Evaluations on tasks\nincluding commonsense reasoning with large language models, fine-tuning\nvision-language models, and subject-driven generation demonstrate NoRA's\nsuperiority over LoRA and its variants. Code will be released upon acceptance.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by-sa/4.0/","blobId":"DrfD7oT6zFwlGooEQV-iOwYvuwIcRVhbDJx4JL86J8A","pdfSize":"6957294"}
