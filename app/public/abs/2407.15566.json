{"id":"2407.15566","title":"Not All Pairs are Equal: Hierarchical Learning for\n  Average-Precision-Oriented Video Retrieval","authors":"Yang Liu, Qianqian Xu, Peisong Wen, Siran Dai, Qingming Huang","authorsParsed":[["Liu","Yang",""],["Xu","Qianqian",""],["Wen","Peisong",""],["Dai","Siran",""],["Huang","Qingming",""]],"versions":[{"version":"v1","created":"Mon, 22 Jul 2024 11:52:04 GMT"}],"updateDate":"2024-07-23","timestamp":1721649124000,"abstract":"  The rapid growth of online video resources has significantly promoted the\ndevelopment of video retrieval methods. As a standard evaluation metric for\nvideo retrieval, Average Precision (AP) assesses the overall rankings of\nrelevant videos at the top list, making the predicted scores a reliable\nreference for users. However, recent video retrieval methods utilize pair-wise\nlosses that treat all sample pairs equally, leading to an evident gap between\nthe training objective and evaluation metric. To effectively bridge this gap,\nin this work, we aim to address two primary challenges: a) The current\nsimilarity measure and AP-based loss are suboptimal for video retrieval; b) The\nnoticeable noise from frame-to-frame matching introduces ambiguity in\nestimating the AP loss. In response to these challenges, we propose the\nHierarchical learning framework for Average-Precision-oriented Video Retrieval\n(HAP-VR). For the former challenge, we develop the TopK-Chamfer Similarity and\nQuadLinear-AP loss to measure and optimize video-level similarities in terms of\nAP. For the latter challenge, we suggest constraining the frame-level\nsimilarities to achieve an accurate AP loss estimation. Experimental results\npresent that HAP-VR outperforms existing methods on several benchmark datasets,\nproviding a feasible solution for video retrieval tasks and thus offering\npotential benefits for the multi-media application.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}