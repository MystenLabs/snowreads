{"id":"2407.10264","title":"What Makes and Breaks Safety Fine-tuning? A Mechanistic Study","authors":"Samyak Jain, Ekdeep Singh Lubana, Kemal Oksuz, Tom Joy, Philip H.S.\n  Torr, Amartya Sanyal, Puneet K. Dokania","authorsParsed":[["Jain","Samyak",""],["Lubana","Ekdeep Singh",""],["Oksuz","Kemal",""],["Joy","Tom",""],["Torr","Philip H. S.",""],["Sanyal","Amartya",""],["Dokania","Puneet K.",""]],"versions":[{"version":"v1","created":"Sun, 14 Jul 2024 16:12:57 GMT"},{"version":"v2","created":"Tue, 16 Jul 2024 19:19:15 GMT"},{"version":"v3","created":"Wed, 21 Aug 2024 15:12:37 GMT"}],"updateDate":"2024-08-22","timestamp":1720973577000,"abstract":"  Safety fine-tuning helps align Large Language Models (LLMs) with human\npreferences for their safe deployment. To better understand the underlying\nfactors that make models safe via safety fine-tuning, we design a synthetic\ndata generation framework that captures salient aspects of an unsafe input by\nmodeling the interaction between the task the model is asked to perform (e.g.,\n\"design\") versus the specific concepts the task is asked to be performed upon\n(e.g., a \"cycle\" vs. a \"bomb\"). Using this, we investigate three well-known\nsafety fine-tuning methods -- supervised safety fine-tuning, direct preference\noptimization, and unlearning -- and provide significant evidence demonstrating\nthat these methods minimally transform MLP weights to specifically align unsafe\ninputs into its weights' null space. This yields a clustering of inputs based\non whether the model deems them safe or not. Correspondingly, when an\nadversarial input (e.g., a jailbreak) is provided, its activations are closer\nto safer samples, leading to the model processing such an input as if it were\nsafe. We validate our findings, wherever possible, on real-world models --\nspecifically, Llama-2 7B and Llama-3 8B.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}