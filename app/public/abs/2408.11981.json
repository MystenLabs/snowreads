{"id":"2408.11981","title":"Large Language Models for Page Stream Segmentation","authors":"Hunter Heidenreich, Ratish Dalvi, Rohith Mukku, Nikhil Verma, Neven\n  Pi\\v{c}uljan","authorsParsed":[["Heidenreich","Hunter",""],["Dalvi","Ratish",""],["Mukku","Rohith",""],["Verma","Nikhil",""],["Piƒçuljan","Neven",""]],"versions":[{"version":"v1","created":"Wed, 21 Aug 2024 20:28:42 GMT"}],"updateDate":"2024-08-23","timestamp":1724272122000,"abstract":"  Page Stream Segmentation (PSS) is an essential prerequisite for automated\ndocument processing at scale. However, research progress has been limited by\nthe absence of realistic public benchmarks. This paper works towards addressing\nthis gap by introducing TABME++, an enhanced benchmark featuring commercial\nOptical Character Recognition (OCR) annotations. We evaluate the performance of\nlarge language models (LLMs) on PSS, focusing on decoder-based models\nfine-tuned with parameter-efficient methods. Our results show that\ndecoder-based LLMs outperform smaller multimodal encoders. Through a review of\nexisting PSS research and datasets, we identify key challenges and advancements\nin the field. Our findings highlight the key importance of robust OCR,\nproviding valuable insights for the development of more effective document\nprocessing systems.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}