{"id":"2407.19055","title":"Effective Large Language Model Debugging with Best-first Tree Search","authors":"Jialin Song, Jonathan Raiman, Bryan Catanzaro","authorsParsed":[["Song","Jialin",""],["Raiman","Jonathan",""],["Catanzaro","Bryan",""]],"versions":[{"version":"v1","created":"Fri, 26 Jul 2024 19:26:00 GMT"}],"updateDate":"2024-07-30","timestamp":1722021960000,"abstract":"  Large Language Models (LLMs) show promise in code generation tasks. However,\ntheir code-writing abilities are often limited in scope: while they can\nsuccessfully implement simple functions, they struggle with more complex tasks.\nA fundamental difference with how an LLM writes code, compared to a human\nprogrammer, is that it cannot consistently spot and fix bugs. Debugging is a\ncrucial skill for programmers and it enables iterative code refinement towards\na correct implementation. In this work, we propose a novel algorithm to enable\nLLMs to debug their code via self-reflection and search where a model attempts\nto identify its previous mistakes. Our key contributions are 1) a best-first\ntree search algorithm with self-reflections (BESTER) that achieves\nstate-of-the-art Pass@1 in three code generation benchmarks. BESTER maintains\nits superiority when we measure pass rates taking into account additional\ninference costs incurred by tree search. 2) A novel interpretability study on\nwhat self-reflections attend to in buggy programs and how they impact bug\nfixes, which provides a deeper understanding of the debugging process. 3) An\nextensive study on when self-reflections are effective in finding bugs.\n","subjects":["Computing Research Repository/Software Engineering","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}