{"id":"2407.04694","title":"Me, Myself, and AI: The Situational Awareness Dataset (SAD) for LLMs","authors":"Rudolf Laine, Bilal Chughtai, Jan Betley, Kaivalya Hariharan, Jeremy\n  Scheurer, Mikita Balesni, Marius Hobbhahn, Alexander Meinke, Owain Evans","authorsParsed":[["Laine","Rudolf",""],["Chughtai","Bilal",""],["Betley","Jan",""],["Hariharan","Kaivalya",""],["Scheurer","Jeremy",""],["Balesni","Mikita",""],["Hobbhahn","Marius",""],["Meinke","Alexander",""],["Evans","Owain",""]],"versions":[{"version":"v1","created":"Fri, 5 Jul 2024 17:57:02 GMT"}],"updateDate":"2024-07-08","timestamp":1720202222000,"abstract":"  AI assistants such as ChatGPT are trained to respond to users by saying, \"I\nam a large language model\". This raises questions. Do such models know that\nthey are LLMs and reliably act on this knowledge? Are they aware of their\ncurrent circumstances, such as being deployed to the public? We refer to a\nmodel's knowledge of itself and its circumstances as situational awareness. To\nquantify situational awareness in LLMs, we introduce a range of behavioral\ntests, based on question answering and instruction following. These tests form\nthe $\\textbf{Situational Awareness Dataset (SAD)}$, a benchmark comprising 7\ntask categories and over 13,000 questions. The benchmark tests numerous\nabilities, including the capacity of LLMs to (i) recognize their own generated\ntext, (ii) predict their own behavior, (iii) determine whether a prompt is from\ninternal evaluation or real-world deployment, and (iv) follow instructions that\ndepend on self-knowledge.\n  We evaluate 16 LLMs on SAD, including both base (pretrained) and chat models.\nWhile all models perform better than chance, even the highest-scoring model\n(Claude 3 Opus) is far from a human baseline on certain tasks. We also observe\nthat performance on SAD is only partially predicted by metrics of general\nknowledge (e.g. MMLU). Chat models, which are finetuned to serve as AI\nassistants, outperform their corresponding base models on SAD but not on\ngeneral knowledge tasks. The purpose of SAD is to facilitate scientific\nunderstanding of situational awareness in LLMs by breaking it down into\nquantitative abilities. Situational awareness is important because it enhances\na model's capacity for autonomous planning and action. While this has potential\nbenefits for automation, it also introduces novel risks related to AI safety\nand control. Code and latest results available at\nhttps://situational-awareness-dataset.org .\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}