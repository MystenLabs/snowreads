{"id":"2408.09027","title":"Efficient Autoregressive Audio Modeling via Next-Scale Prediction","authors":"Kai Qiu, Xiang Li, Hao Chen, Jie Sun, Jinglu Wang, Zhe Lin, Marios\n  Savvides, Bhiksha Raj","authorsParsed":[["Qiu","Kai",""],["Li","Xiang",""],["Chen","Hao",""],["Sun","Jie",""],["Wang","Jinglu",""],["Lin","Zhe",""],["Savvides","Marios",""],["Raj","Bhiksha",""]],"versions":[{"version":"v1","created":"Fri, 16 Aug 2024 21:48:53 GMT"}],"updateDate":"2024-08-20","timestamp":1723844933000,"abstract":"  Audio generation has achieved remarkable progress with the advance of\nsophisticated generative models, such as diffusion models (DMs) and\nautoregressive (AR) models. However, due to the naturally significant sequence\nlength of audio, the efficiency of audio generation remains an essential issue\nto be addressed, especially for AR models that are incorporated in large\nlanguage models (LLMs). In this paper, we analyze the token length of audio\ntokenization and propose a novel \\textbf{S}cale-level \\textbf{A}udio\n\\textbf{T}okenizer (SAT), with improved residual quantization. Based on SAT, a\nscale-level \\textbf{A}coustic \\textbf{A}uto\\textbf{R}egressive (AAR) modeling\nframework is further proposed, which shifts the next-token AR prediction to\nnext-scale AR prediction, significantly reducing the training cost and\ninference time. To validate the effectiveness of the proposed approach, we\ncomprehensively analyze design choices and demonstrate the proposed AAR\nframework achieves a remarkable \\textbf{35}$\\times$ faster inference speed and\n+\\textbf{1.33} Fr\\'echet Audio Distance (FAD) against baselines on the AudioSet\nbenchmark. Code: \\url{https://github.com/qiuk2/AAR}.\n","subjects":["Computing Research Repository/Sound","Computing Research Repository/Artificial Intelligence","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}