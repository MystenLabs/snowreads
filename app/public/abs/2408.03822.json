{"id":"2408.03822","title":"Compact 3D Gaussian Splatting for Static and Dynamic Radiance Fields","authors":"Joo Chan Lee, Daniel Rho, Xiangyu Sun, Jong Hwan Ko, Eunbyung Park","authorsParsed":[["Lee","Joo Chan",""],["Rho","Daniel",""],["Sun","Xiangyu",""],["Ko","Jong Hwan",""],["Park","Eunbyung",""]],"versions":[{"version":"v1","created":"Wed, 7 Aug 2024 14:56:34 GMT"}],"updateDate":"2024-08-08","timestamp":1723042594000,"abstract":"  3D Gaussian splatting (3DGS) has recently emerged as an alternative\nrepresentation that leverages a 3D Gaussian-based representation and introduces\nan approximated volumetric rendering, achieving very fast rendering speed and\npromising image quality. Furthermore, subsequent studies have successfully\nextended 3DGS to dynamic 3D scenes, demonstrating its wide range of\napplications. However, a significant drawback arises as 3DGS and its following\nmethods entail a substantial number of Gaussians to maintain the high fidelity\nof the rendered images, which requires a large amount of memory and storage. To\naddress this critical issue, we place a specific emphasis on two key\nobjectives: reducing the number of Gaussian points without sacrificing\nperformance and compressing the Gaussian attributes, such as view-dependent\ncolor and covariance. To this end, we propose a learnable mask strategy that\nsignificantly reduces the number of Gaussians while preserving high\nperformance. In addition, we propose a compact but effective representation of\nview-dependent color by employing a grid-based neural field rather than relying\non spherical harmonics. Finally, we learn codebooks to compactly represent the\ngeometric and temporal attributes by residual vector quantization. With model\ncompression techniques such as quantization and entropy coding, we consistently\nshow over 25x reduced storage and enhanced rendering speed compared to 3DGS for\nstatic scenes, while maintaining the quality of the scene representation. For\ndynamic scenes, our approach achieves more than 12x storage efficiency and\nretains a high-quality reconstruction compared to the existing state-of-the-art\nmethods. Our work provides a comprehensive framework for 3D scene\nrepresentation, achieving high performance, fast training, compactness, and\nreal-time rendering. Our project page is available at\nhttps://maincold2.github.io/c3dgs/.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}