{"id":"2408.09822","title":"SurgicaL-CD: Generating Surgical Images via Unpaired Image Translation\n  with Latent Consistency Diffusion Models","authors":"Danush Kumar Venkatesh, Dominik Rivoir, Micha Pfeiffer, Stefanie\n  Speidel","authorsParsed":[["Venkatesh","Danush Kumar",""],["Rivoir","Dominik",""],["Pfeiffer","Micha",""],["Speidel","Stefanie",""]],"versions":[{"version":"v1","created":"Mon, 19 Aug 2024 09:19:25 GMT"},{"version":"v2","created":"Fri, 23 Aug 2024 13:01:11 GMT"}],"updateDate":"2024-08-26","timestamp":1724059165000,"abstract":"  Computer-assisted surgery (CAS) systems are designed to assist surgeons\nduring procedures, thereby reducing complications and enhancing patient care.\nTraining machine learning models for these systems requires a large corpus of\nannotated datasets, which is challenging to obtain in the surgical domain due\nto patient privacy concerns and the significant labeling effort required from\ndoctors. Previous methods have explored unpaired image translation using\ngenerative models to create realistic surgical images from simulations.\nHowever, these approaches have struggled to produce high-quality, diverse\nsurgical images. In this work, we introduce \\emph{SurgicaL-CD}, a\nconsistency-distilled diffusion method to generate realistic surgical images\nwith only a few sampling steps without paired data. We evaluate our approach on\nthree datasets, assessing the generated images in terms of quality and utility\nas downstream training datasets. Our results demonstrate that our method\noutperforms GANs and diffusion-based approaches. Our code is available at\nhttps://gitlab.com/nct_tso_public/gan2diffusion.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/"}