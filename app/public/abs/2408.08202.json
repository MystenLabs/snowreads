{"id":"2408.08202","title":"Towards Practical Human Motion Prediction with LiDAR Point Clouds","authors":"Xiao Han, Yiming Ren, Yichen Yao, Yujing Sun, Yuexin Ma","authorsParsed":[["Han","Xiao",""],["Ren","Yiming",""],["Yao","Yichen",""],["Sun","Yujing",""],["Ma","Yuexin",""]],"versions":[{"version":"v1","created":"Thu, 15 Aug 2024 15:10:01 GMT"}],"updateDate":"2024-08-16","timestamp":1723734601000,"abstract":"  Human motion prediction is crucial for human-centric multimedia understanding\nand interacting. Current methods typically rely on ground truth human poses as\nobserved input, which is not practical for real-world scenarios where only raw\nvisual sensor data is available. To implement these methods in practice, a\npre-phrase of pose estimation is essential. However, such two-stage approaches\noften lead to performance degradation due to the accumulation of errors.\nMoreover, reducing raw visual data to sparse keypoint representations\nsignificantly diminishes the density of information, resulting in the loss of\nfine-grained features. In this paper, we propose \\textit{LiDAR-HMP}, the first\nsingle-LiDAR-based 3D human motion prediction approach, which receives the raw\nLiDAR point cloud as input and forecasts future 3D human poses directly.\nBuilding upon our novel structure-aware body feature descriptor, LiDAR-HMP\nadaptively maps the observed motion manifold to future poses and effectively\nmodels the spatial-temporal correlations of human motions for further\nrefinement of prediction results. Extensive experiments show that our method\nachieves state-of-the-art performance on two public benchmarks and demonstrates\nremarkable robustness and efficacy in real-world deployments.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}