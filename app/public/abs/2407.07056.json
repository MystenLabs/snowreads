{"id":"2407.07056","title":"CAPformer: Compression-Aware Pre-trained Transformer for Low-Light Image\n  Enhancement","authors":"Wei Wang and Zhi Jin","authorsParsed":[["Wang","Wei",""],["Jin","Zhi",""]],"versions":[{"version":"v1","created":"Tue, 9 Jul 2024 17:25:04 GMT"},{"version":"v2","created":"Wed, 10 Jul 2024 11:25:26 GMT"}],"updateDate":"2024-07-11","timestamp":1720545904000,"abstract":"  Low-Light Image Enhancement (LLIE) has advanced with the surge in phone\nphotography demand, yet many existing methods neglect compression, a crucial\nconcern for resource-constrained phone photography. Most LLIE methods overlook\nthis, hindering their effectiveness. In this study, we investigate the effects\nof JPEG compression on low-light images and reveal substantial information loss\ncaused by JPEG due to widespread low pixel values in dark areas. Hence, we\npropose the Compression-Aware Pre-trained Transformer (CAPformer), employing a\nnovel pre-training strategy to learn lossless information from uncompressed\nlow-light images. Additionally, the proposed Brightness-Guided Self-Attention\n(BGSA) mechanism enhances rational information gathering. Experiments\ndemonstrate the superiority of our approach in mitigating compression effects\non LLIE, showcasing its potential for improving LLIE in resource-constrained\nscenarios.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Electrical Engineering and Systems Science/Image and Video Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}