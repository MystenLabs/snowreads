{"id":"2408.15679","title":"DEAR: Depth-Enhanced Action Recognition","authors":"Sadegh Rahmaniboldaji, Filip Rybansky, Quoc Vuong, Frank Guerin,\n  Andrew Gilbert","authorsParsed":[["Rahmaniboldaji","Sadegh",""],["Rybansky","Filip",""],["Vuong","Quoc",""],["Guerin","Frank",""],["Gilbert","Andrew",""]],"versions":[{"version":"v1","created":"Wed, 28 Aug 2024 10:08:38 GMT"},{"version":"v2","created":"Thu, 12 Sep 2024 13:31:48 GMT"}],"updateDate":"2024-09-13","timestamp":1724839718000,"abstract":"  Detecting actions in videos, particularly within cluttered scenes, poses\nsignificant challenges due to the limitations of 2D frame analysis from a\ncamera perspective. Unlike human vision, which benefits from 3D understanding,\nrecognizing actions in such environments can be difficult. This research\nintroduces a novel approach integrating 3D features and depth maps alongside\nRGB features to enhance action recognition accuracy. Our method involves\nprocessing estimated depth maps through a separate branch from the RGB feature\nencoder and fusing the features to understand the scene and actions\ncomprehensively. Using the Side4Video framework and VideoMamba, which employ\nCLIP and VisionMamba for spatial feature extraction, our approach outperformed\nour implementation of the Side4Video network on the Something-Something V2\ndataset. Our code is available at: https://github.com/SadeghRahmaniB/DEAR\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}