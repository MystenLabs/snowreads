{"id":"2407.21139","title":"Enhancing Semantic Similarity Understanding in Arabic NLP with Nested\n  Embedding Learning","authors":"Omer Nacar and Anis Koubaa","authorsParsed":[["Nacar","Omer",""],["Koubaa","Anis",""]],"versions":[{"version":"v1","created":"Tue, 30 Jul 2024 19:03:03 GMT"},{"version":"v2","created":"Thu, 1 Aug 2024 12:24:01 GMT"}],"updateDate":"2024-08-02","timestamp":1722366183000,"abstract":"  This work presents a novel framework for training Arabic nested embedding\nmodels through Matryoshka Embedding Learning, leveraging multilingual,\nArabic-specific, and English-based models, to highlight the power of nested\nembeddings models in various Arabic NLP downstream tasks. Our innovative\ncontribution includes the translation of various sentence similarity datasets\ninto Arabic, enabling a comprehensive evaluation framework to compare these\nmodels across different dimensions. We trained several nested embedding models\non the Arabic Natural Language Inference triplet dataset and assessed their\nperformance using multiple evaluation metrics, including Pearson and Spearman\ncorrelations for cosine similarity, Manhattan distance, Euclidean distance, and\ndot product similarity. The results demonstrate the superior performance of the\nMatryoshka embedding models, particularly in capturing semantic nuances unique\nto the Arabic language. Results demonstrated that Arabic Matryoshka embedding\nmodels have superior performance in capturing semantic nuances unique to the\nArabic language, significantly outperforming traditional models by up to\n20-25\\% across various similarity metrics. These results underscore the\neffectiveness of language-specific training and highlight the potential of\nMatryoshka models in enhancing semantic textual similarity tasks for Arabic\nNLP.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}