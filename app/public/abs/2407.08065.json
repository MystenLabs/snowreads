{"id":"2407.08065","title":"Towards Interpretable Foundation Models of Robot Behavior: A Task\n  Specific Policy Generation Approach","authors":"Isaac Sheidlower, Reuben Aronson, Elaine Schaertl Short","authorsParsed":[["Sheidlower","Isaac",""],["Aronson","Reuben",""],["Short","Elaine Schaertl",""]],"versions":[{"version":"v1","created":"Wed, 10 Jul 2024 21:55:44 GMT"}],"updateDate":"2024-07-12","timestamp":1720648544000,"abstract":"  Foundation models are a promising path toward general-purpose and\nuser-friendly robots. The prevalent approach involves training a generalist\npolicy that, like a reinforcement learning policy, uses observations to output\nactions. Although this approach has seen much success, several concerns arise\nwhen considering deployment and end-user interaction with these systems. In\nparticular, the lack of modularity between tasks means that when model weights\nare updated (e.g., when a user provides feedback), the behavior in other,\nunrelated tasks may be affected. This can negatively impact the system's\ninterpretability and usability. We present an alternative approach to the\ndesign of robot foundation models, Diffusion for Policy Parameters (DPP), which\ngenerates stand-alone, task-specific policies. Since these policies are\ndetached from the foundation model, they are updated only when a user wants,\neither through feedback or personalization, allowing them to gain a high degree\nof familiarity with that policy. We demonstrate a proof-of-concept of DPP in\nsimulation then discuss its limitations and the future of interpretable\nfoundation models.\n","subjects":["Computing Research Repository/Robotics","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"A7aBi2du7NvtDTzZi32FItX0JMjriXS5H5bCYX-zrhs","pdfSize":"512181"}
