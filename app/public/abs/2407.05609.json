{"id":"2407.05609","title":"Open-world Multi-label Text Classification with Extremely Weak\n  Supervision","authors":"Xintong Li, Jinya Jiang, Ria Dharmani, Jayanth Srinivasa, Gaowen Liu,\n  Jingbo Shang","authorsParsed":[["Li","Xintong",""],["Jiang","Jinya",""],["Dharmani","Ria",""],["Srinivasa","Jayanth",""],["Liu","Gaowen",""],["Shang","Jingbo",""]],"versions":[{"version":"v1","created":"Mon, 8 Jul 2024 04:52:49 GMT"}],"updateDate":"2024-07-09","timestamp":1720414369000,"abstract":"  We study open-world multi-label text classification under extremely weak\nsupervision (XWS), where the user only provides a brief description for\nclassification objectives without any labels or ground-truth label space.\nSimilar single-label XWS settings have been explored recently, however, these\nmethods cannot be easily adapted for multi-label. We observe that (1) most\ndocuments have a dominant class covering the majority of content and (2)\nlong-tail labels would appear in some documents as a dominant class. Therefore,\nwe first utilize the user description to prompt a large language model (LLM)\nfor dominant keyphrases of a subset of raw documents, and then construct a\n(initial) label space via clustering. We further apply a zero-shot multi-label\nclassifier to locate the documents with small top predicted scores, so we can\nrevisit their dominant keyphrases for more long-tail labels. We iterate this\nprocess to discover a comprehensive label space and construct a multi-label\nclassifier as a novel method, X-MLClass. X-MLClass exhibits a remarkable\nincrease in ground-truth label space coverage on various datasets, for example,\na 40% improvement on the AAPD dataset over topic modeling and keyword\nextraction methods. Moreover, X-MLClass achieves the best end-to-end\nmulti-label classification accuracy.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/"}