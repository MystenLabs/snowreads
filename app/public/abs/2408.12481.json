{"id":"2408.12481","title":"Self-Learning for Personalized Keyword Spotting on Ultra-Low-Power Audio\n  Sensors","authors":"Manuele Rusci, Francesco Paci, Marco Fariselli, Eric Flamand, Tinne\n  Tuytelaars","authorsParsed":[["Rusci","Manuele",""],["Paci","Francesco",""],["Fariselli","Marco",""],["Flamand","Eric",""],["Tuytelaars","Tinne",""]],"versions":[{"version":"v1","created":"Thu, 22 Aug 2024 15:17:02 GMT"}],"updateDate":"2024-08-23","timestamp":1724339822000,"abstract":"  This paper proposes a self-learning framework to incrementally train\n(fine-tune) a personalized Keyword Spotting (KWS) model after the deployment on\nultra-low power smart audio sensors. We address the fundamental problem of the\nabsence of labeled training data by assigning pseudo-labels to the new recorded\naudio frames based on a similarity score with respect to few user recordings.\nBy experimenting with multiple KWS models with a number of parameters up to\n0.5M on two public datasets, we show an accuracy improvement of up to +19.2%\nand +16.0% vs. the initial models pretrained on a large set of generic\nkeywords. The labeling task is demonstrated on a sensor system composed of a\nlow-power microphone and an energy-efficient Microcontroller (MCU). By\nefficiently exploiting the heterogeneous processing engines of the MCU, the\nalways-on labeling task runs in real-time with an average power cost of up to\n8.2 mW. On the same platform, we estimate an energy cost for on-device training\n10x lower than the labeling energy if sampling a new utterance every 5 s or\n16.4 s with a DS-CNN-S or a DS-CNN-M model. Our empirical result paves the way\nto self-adaptive personalized KWS sensors at the extreme edge.\n","subjects":["Computing Research Repository/Sound","Computing Research Repository/Machine Learning","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}