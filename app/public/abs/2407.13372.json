{"id":"2407.13372","title":"Any Image Restoration with Efficient Automatic Degradation Adaptation","authors":"Bin Ren, Eduard Zamfir, Yawei Li, Zongwei Wu, Danda Pani Paudel, Radu\n  Timofte, Nicu Sebe, Luc Van Gool","authorsParsed":[["Ren","Bin",""],["Zamfir","Eduard",""],["Li","Yawei",""],["Wu","Zongwei",""],["Paudel","Danda Pani",""],["Timofte","Radu",""],["Sebe","Nicu",""],["Van Gool","Luc",""]],"versions":[{"version":"v1","created":"Thu, 18 Jul 2024 10:26:53 GMT"}],"updateDate":"2024-07-19","timestamp":1721298413000,"abstract":"  With the emergence of mobile devices, there is a growing demand for an\nefficient model to restore any degraded image for better perceptual quality.\nHowever, existing models often require specific learning modules tailored for\neach degradation, resulting in complex architectures and high computation\ncosts. Different from previous work, in this paper, we propose a unified manner\nto achieve joint embedding by leveraging the inherent similarities across\nvarious degradations for efficient and comprehensive restoration. Specifically,\nwe first dig into the sub-latent space of each input to analyze the key\ncomponents and reweight their contributions in a gated manner. The intrinsic\nawareness is further integrated with contextualized attention in an X-shaped\nscheme, maximizing local-global intertwining. Extensive comparison on\nbenchmarking all-in-one restoration setting validates our efficiency and\neffectiveness, i.e., our network sets new SOTA records while reducing model\ncomplexity by approximately -82% in trainable parameters and -85\\% in FLOPs.\nOur code will be made publicly available\nat:https://github.com/Amazingren/AnyIR.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}