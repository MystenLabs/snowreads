{"id":"2408.14771","title":"Impact of Noisy Labels on Sound Event Detection: Deletion Errors Are\n  More Detrimental Than Insertion Errors","authors":"Yuliang Zhang, Roberto Togneri, Defeng (David) Huang","authorsParsed":[["Zhang","Yuliang","","David"],["Togneri","Roberto","","David"],["Defeng","","","David"],["Huang","",""]],"versions":[{"version":"v1","created":"Tue, 27 Aug 2024 04:18:39 GMT"},{"version":"v2","created":"Sun, 15 Sep 2024 00:02:13 GMT"}],"updateDate":"2024-09-17","timestamp":1724732319000,"abstract":"  This study explores the critical but underexamined impact of label noise on\nSound Event Detection (SED), which requires both sound identification and\nprecise temporal localization. We categorize label noise into deletion,\ninsertion, substitution, and subjective types and systematically evaluate their\neffects on SED using synthetic and real-life datasets. Our analysis shows that\ndeletion noise significantly degrades performance, while insertion noise is\nrelatively benign. Moreover, loss functions effective against classification\nnoise do not perform well for SED due to intra-class imbalance between\nforeground sound events and background sounds. We demonstrate that loss\nfunctions designed to address data imbalance in SED can effectively reduce the\nimpact of noisy labels on system performance. For instance, halving the weight\nof background sounds in a synthetic dataset improved macro-F1 and micro-F1\nscores by approximately $9\\%$ with minimal Error Rate increase, with consistent\nresults in real-life datasets. This research highlights the nuanced effects of\nnoisy labels on SED systems and provides practical strategies to enhance model\nrobustness, which are pivotal for both constructing new SED datasets and\nimproving model performance, including efficient utilization of soft and\ncrowdsourced labels.\n","subjects":["Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/"}