{"id":"2407.03061","title":"ALTER: Augmentation for Large-Table-Based Reasoning","authors":"Han Zhang, Yuheng Ma, Hanfang Yang","authorsParsed":[["Zhang","Han",""],["Ma","Yuheng",""],["Yang","Hanfang",""]],"versions":[{"version":"v1","created":"Wed, 3 Jul 2024 12:34:45 GMT"}],"updateDate":"2024-07-04","timestamp":1720010085000,"abstract":"  While extensive research has explored the use of large language models (LLMs)\nfor table-based reasoning, most approaches struggle with scalability when\napplied to large tables. To maintain the superior comprehension abilities of\nLLMs in these scenarios, we introduce ALTER(Augmentation for Large-Table-Based\nReasoning)-a framework designed to harness the latent augmentation potential in\nboth free-form natural language (NL) questions, via the query augmentor, and\nsemi-structured tabular data, through the table augmentor. By utilizing only a\nsmall subset of relevant data from the table and supplementing it with\npre-augmented schema, semantic, and literal information, ALTER achieves\noutstanding performance on table-based reasoning benchmarks. We also provide a\ndetailed analysis of large-table scenarios, comparing different methods and\nvarious partitioning principles. In these scenarios, our method outperforms all\nother approaches and exhibits robustness and efficiency against perturbations.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}