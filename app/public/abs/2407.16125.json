{"id":"2407.16125","title":"Diffusion Prior-Based Amortized Variational Inference for Noisy Inverse\n  Problems","authors":"Sojin Lee, Dogyun Park, Inho Kong, and Hyunwoo J. Kim","authorsParsed":[["Lee","Sojin",""],["Park","Dogyun",""],["Kong","Inho",""],["Kim","Hyunwoo J.",""]],"versions":[{"version":"v1","created":"Tue, 23 Jul 2024 02:14:18 GMT"}],"updateDate":"2024-07-24","timestamp":1721700858000,"abstract":"  Recent studies on inverse problems have proposed posterior samplers that\nleverage the pre-trained diffusion models as powerful priors. These attempts\nhave paved the way for using diffusion models in a wide range of inverse\nproblems. However, the existing methods entail computationally demanding\niterative sampling procedures and optimize a separate solution for each\nmeasurement, which leads to limited scalability and lack of generalization\ncapability across unseen samples. To address these limitations, we propose a\nnovel approach, Diffusion prior-based Amortized Variational Inference (DAVI)\nthat solves inverse problems with a diffusion prior from an amortized\nvariational inference perspective. Specifically, instead of separate\nmeasurement-wise optimization, our amortized inference learns a function that\ndirectly maps measurements to the implicit posterior distributions of\ncorresponding clean data, enabling a single-step posterior sampling even for\nunseen measurements. Extensive experiments on image restoration tasks, e.g.,\nGaussian deblur, 4$\\times$ super-resolution, and box inpainting with two\nbenchmark datasets, demonstrate our approach's superior performance over strong\nbaselines. Code is available at https://github.com/mlvlab/DAVI.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}