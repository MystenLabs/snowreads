{"id":"2407.10254","title":"The Elephant in the Room -- Why AI Safety Demands Diverse Teams","authors":"David Rostcheck, Lara Scheibling","authorsParsed":[["Rostcheck","David",""],["Scheibling","Lara",""]],"versions":[{"version":"v1","created":"Tue, 7 May 2024 02:05:23 GMT"}],"updateDate":"2024-07-16","timestamp":1715047523000,"abstract":"  We consider that existing approaches to AI \"safety\" and \"alignment\" may not\nbe using the most effective tools, teams, or approaches. We suggest that an\nalternative and better approach to the problem may be to treat alignment as a\nsocial science problem, since the social sciences enjoy a rich toolkit of\nmodels for understanding and aligning motivation and behavior, much of which\ncould be repurposed to problems involving AI models, and enumerate reasons why\nthis is so. We introduce an alternate alignment approach informed by social\nscience tools and characterized by three steps: 1. defining a positive desired\nsocial outcome for human/AI collaboration as the goal or \"North Star,\" 2.\nproperly framing knowns and unknowns, and 3. forming diverse teams to\ninvestigate, observe, and navigate emerging challenges in alignment.\n","subjects":["Computing Research Repository/Computers and Society","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"EQXi8kOQnnVN-cwEiq0A1pTMDLlu5XDVQztNdGATHZ0","pdfSize":"135038"}
