{"id":"2408.16964","title":"Causal Representation-Based Domain Generalization on Gaze Estimation","authors":"Younghan Kim, Kangryun Moon, Yongjun Park, Yonggyu Kim","authorsParsed":[["Kim","Younghan",""],["Moon","Kangryun",""],["Park","Yongjun",""],["Kim","Yonggyu",""]],"versions":[{"version":"v1","created":"Fri, 30 Aug 2024 01:45:22 GMT"}],"updateDate":"2024-09-02","timestamp":1724982322000,"abstract":"  The availability of extensive datasets containing gaze information for each\nsubject has significantly enhanced gaze estimation accuracy. However, the\ndiscrepancy between domains severely affects a model's performance explicitly\ntrained for a particular domain. In this paper, we propose the Causal\nRepresentation-Based Domain Generalization on Gaze Estimation (CauGE) framework\ndesigned based on the general principle of causal mechanisms, which is\nconsistent with the domain difference. We employ an adversarial training manner\nand an additional penalizing term to extract domain-invariant features. After\nextracting features, we position the attention layer to make features\nsufficient for inferring the actual gaze. By leveraging these modules, CauGE\nensures that the neural networks learn from representations that meet the\ncausal mechanisms' general principles. By this, CauGE generalizes across\ndomains by extracting domain-invariant features, and spurious correlations\ncannot influence the model. Our method achieves state-of-the-art performance in\nthe domain generalization on gaze estimation benchmark.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"rUz_duG-YGD1M7B7QEh59QcrLjJNt9voC2p6dpAgScA","pdfSize":"10497133"}
