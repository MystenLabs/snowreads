{"id":"2408.13972","title":"DynaSurfGS: Dynamic Surface Reconstruction with Planar-based Gaussian\n  Splatting","authors":"Weiwei Cai, Weicai Ye, Peng Ye, Tong He, Tao Chen","authorsParsed":[["Cai","Weiwei",""],["Ye","Weicai",""],["Ye","Peng",""],["He","Tong",""],["Chen","Tao",""]],"versions":[{"version":"v1","created":"Mon, 26 Aug 2024 01:36:46 GMT"}],"updateDate":"2024-08-27","timestamp":1724636206000,"abstract":"  Dynamic scene reconstruction has garnered significant attention in recent\nyears due to its capabilities in high-quality and real-time rendering. Among\nvarious methodologies, constructing a 4D spatial-temporal representation, such\nas 4D-GS, has gained popularity for its high-quality rendered images. However,\nthese methods often produce suboptimal surfaces, as the discrete 3D Gaussian\npoint clouds fail to align with the object's surface precisely. To address this\nproblem, we propose DynaSurfGS to achieve both photorealistic rendering and\nhigh-fidelity surface reconstruction of dynamic scenarios. Specifically, the\nDynaSurfGS framework first incorporates Gaussian features from 4D neural voxels\nwith the planar-based Gaussian Splatting to facilitate precise surface\nreconstruction. It leverages normal regularization to enforce the smoothness of\nthe surface of dynamic objects. It also incorporates the as-rigid-as-possible\n(ARAP) constraint to maintain the approximate rigidity of local neighborhoods\nof 3D Gaussians between timesteps and ensure that adjacent 3D Gaussians remain\nclosely aligned throughout. Extensive experiments demonstrate that DynaSurfGS\nsurpasses state-of-the-art methods in both high-fidelity surface reconstruction\nand photorealistic rendering.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Graphics"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"TXcUpU0ZTQTMek11DfcRXhoP1436ASJ2durs_o18tn4","pdfSize":"5963687"}
