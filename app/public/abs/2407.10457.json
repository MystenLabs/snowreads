{"id":"2407.10457","title":"The Good, The Bad, and The Greedy: Evaluation of LLMs Should Not Ignore\n  Non-Determinism","authors":"Yifan Song, Guoyin Wang, Sujian Li, Bill Yuchen Lin","authorsParsed":[["Song","Yifan",""],["Wang","Guoyin",""],["Li","Sujian",""],["Lin","Bill Yuchen",""]],"versions":[{"version":"v1","created":"Mon, 15 Jul 2024 06:12:17 GMT"}],"updateDate":"2024-07-16","timestamp":1721023937000,"abstract":"  Current evaluations of large language models (LLMs) often overlook\nnon-determinism, typically focusing on a single output per example. This limits\nour understanding of LLM performance variability in real-world applications.\nOur study addresses this issue by exploring key questions about the performance\ndifferences between greedy decoding and sampling, identifying benchmarks'\nconsistency regarding non-determinism, and examining unique model behaviors.\nThrough extensive experiments, we observe that greedy decoding generally\noutperforms sampling methods for most evaluated tasks. We also observe\nconsistent performance across different LLM sizes and alignment methods, noting\nthat alignment can reduce sampling variance. Moreover, our best-of-N sampling\napproach demonstrates that smaller LLMs can match or surpass larger models such\nas GPT-4-Turbo, highlighting the untapped potential of smaller LLMs. This\nresearch shows the importance of considering non-determinism in LLM evaluations\nand provides insights for future LLM development and evaluation.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/"}