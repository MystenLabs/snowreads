{"id":"2408.12666","title":"Benchmarking Counterfactual Interpretability in Deep Learning Models for\n  Time Series Classification","authors":"Ziwen Kan, Shahbaz Rezaei, Xin liu","authorsParsed":[["Kan","Ziwen",""],["Rezaei","Shahbaz",""],["liu","Xin",""]],"versions":[{"version":"v1","created":"Thu, 22 Aug 2024 18:17:26 GMT"}],"updateDate":"2024-08-26","timestamp":1724350646000,"abstract":"  The popularity of deep learning methods in the time series domain boosts\ninterest in interpretability studies, including counterfactual (CF) methods. CF\nmethods identify minimal changes in instances to alter the model predictions.\nDespite extensive research, no existing work benchmarks CF methods in the time\nseries domain. Additionally, the results reported in the literature are\ninconclusive due to the limited number of datasets and inadequate metrics. In\nthis work, we redesign quantitative metrics to accurately capture desirable\ncharacteristics in CFs. We specifically redesign the metrics for sparsity and\nplausibility and introduce a new metric for consistency. Combined with\nvalidity, generation time, and proximity, we form a comprehensive metric set.\nWe systematically benchmark 6 different CF methods on 20 univariate datasets\nand 10 multivariate datasets with 3 different classifiers. Results indicate\nthat the performance of CF methods varies across metrics and among different\nmodels. Finally, we provide case studies and a guideline for practical usage.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence","Statistics/Machine Learning"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/"}