{"id":"2407.18327","title":"The Structure of Financial Equity Research Reports -- Identification of\n  the Most Frequently Asked Questions in Financial Analyst Reports to Automate\n  Equity Research Using Llama 3 and GPT-4","authors":"Adria Pop, Jan Sp\\\"orer, Siegfried Handschuh","authorsParsed":[["Pop","Adria",""],["Sp√∂rer","Jan",""],["Handschuh","Siegfried",""]],"versions":[{"version":"v1","created":"Thu, 4 Jul 2024 15:58:02 GMT"}],"updateDate":"2024-07-29","timestamp":1720108682000,"abstract":"  This research dissects financial equity research reports (ERRs) by mapping\ntheir content into categories. There is insufficient empirical analysis of the\nquestions answered in ERRs. In particular, it is not understood how frequently\ncertain information appears, what information is considered essential, and what\ninformation requires human judgment to distill into an ERR. The study analyzes\n72 ERRs sentence-by-sentence, classifying their 4940 sentences into 169 unique\nquestion archetypes. We did not predefine the questions but derived them solely\nfrom the statements in the ERRs. This approach provides an unbiased view of the\ncontent of the observed ERRs. Subsequently, we used public corporate reports to\nclassify the questions' potential for automation. Answers were labeled\n\"text-extractable\" if the answers to the question were accessible in corporate\nreports. 78.7% of the questions in ERRs can be automated. Those automatable\nquestion consist of 48.2% text-extractable (suited to processing by large\nlanguage models, LLMs) and 30.5% database-extractable questions. Only 21.3% of\nquestions require human judgment to answer. We empirically validate using\nLlama-3-70B and GPT-4-turbo-2024-04-09 that recent advances in language\ngeneration and information extraction enable the automation of approximately\n80% of the statements in ERRs. Surprisingly, the models complement each other's\nstrengths and weaknesses well. The research confirms that the current writing\nprocess of ERRs can likely benefit from additional automation, improving\nquality and efficiency. The research thus allows us to quantify the potential\nimpacts of introducing large language models in the ERR writing process. The\nfull question list, including the archetypes and their frequency, will be made\navailable online after peer review.\n","subjects":["Computing Research Repository/Computers and Society","Computing Research Repository/Computational Engineering, Finance, and Science","Computing Research Repository/Information Retrieval","Quantitative Finance/Computational Finance"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"EtYzGz5e9Fqu_Cc-S_yTJRo6QIj7zlAdHr3zhfiAtf0","pdfSize":"2385523"}
