{"id":"2407.16500","title":"Economic Model Predictive Control as a Solution to Markov Decision\n  Processes","authors":"Dirk Reinhardt, Akhil S. Anand, Shambhuraj Sawant, Sebastien Gros","authorsParsed":[["Reinhardt","Dirk",""],["Anand","Akhil S.",""],["Sawant","Shambhuraj",""],["Gros","Sebastien",""]],"versions":[{"version":"v1","created":"Tue, 23 Jul 2024 14:14:18 GMT"}],"updateDate":"2024-07-24","timestamp":1721744058000,"abstract":"  Markov Decision Processes (MDPs) offer a fairly generic and powerful\nframework to discuss the notion of optimal policies for dynamic systems, in\nparticular when the dynamics are stochastic. However, computing the optimal\npolicy of an MDP can be very difficult due to the curse of dimensionality\npresent in solving the underlying Bellman equations. Model Predictive Control\n(MPC) is a very popular technique for building control policies for complex\ndynamic systems. Historically, MPC has focused on constraint satisfaction and\nsteering dynamic systems towards a user-defined reference. More recently,\nEconomic MPC was proposed as a computationally tractable way of building\noptimal policies for dynamic systems. When stochsaticity is present, economic\nMPC is close to the MDP framework. In that context, Economic MPC can be\nconstrued as attractable heuristic to provide approximate solutions to MDPs.\nHowever, there is arguably a knowledge gap in the literature regarding these\napproximate solutions and the conditions for an MPC scheme to achieve\nclosed-loop optimality. This chapter aims to clarify this approximation\npedagogically, to provide the conditions for MPC to deliver optimal policies,\nand to explore some of their consequences.\n","subjects":["Electrical Engineering and Systems Science/Systems and Control","Computing Research Repository/Systems and Control"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}