{"id":"2407.01306","title":"Unveiling the Unseen: Exploring Whitebox Membership Inference through\n  the Lens of Explainability","authors":"Chenxi Li, Abhinav Kumar, Zhen Guo, Jie Hou, and Reza Tourani","authorsParsed":[["Li","Chenxi",""],["Kumar","Abhinav",""],["Guo","Zhen",""],["Hou","Jie",""],["Tourani","Reza",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 14:07:46 GMT"}],"updateDate":"2024-07-02","timestamp":1719842866000,"abstract":"  The increasing prominence of deep learning applications and reliance on\npersonalized data underscore the urgent need to address privacy\nvulnerabilities, particularly Membership Inference Attacks (MIAs). Despite\nnumerous MIA studies, significant knowledge gaps persist, particularly\nregarding the impact of hidden features (in isolation) on attack efficacy and\ninsufficient justification for the root causes of attacks based on raw data\nfeatures. In this paper, we aim to address these knowledge gaps by first\nexploring statistical approaches to identify the most informative neurons and\nquantifying the significance of the hidden activations from the selected\nneurons on attack accuracy, in isolation and combination. Additionally, we\npropose an attack-driven explainable framework by integrating the target and\nattack models to identify the most influential features of raw data that lead\nto successful membership inference attacks. Our proposed MIA shows an\nimprovement of up to 26% on state-of-the-art MIA.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Cryptography and Security"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}