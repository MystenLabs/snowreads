{"id":"2407.00731","title":"Large Language Models Struggle in Token-Level Clinical Named Entity\n  Recognition","authors":"Qiuhao Lu, Rui Li, Andrew Wen, Jinlian Wang, Liwei Wang, Hongfang Liu","authorsParsed":[["Lu","Qiuhao",""],["Li","Rui",""],["Wen","Andrew",""],["Wang","Jinlian",""],["Wang","Liwei",""],["Liu","Hongfang",""]],"versions":[{"version":"v1","created":"Sun, 30 Jun 2024 15:38:48 GMT"},{"version":"v2","created":"Sat, 17 Aug 2024 00:59:55 GMT"}],"updateDate":"2024-08-20","timestamp":1719761928000,"abstract":"  Large Language Models (LLMs) have revolutionized various sectors, including\nhealthcare where they are employed in diverse applications. Their utility is\nparticularly significant in the context of rare diseases, where data scarcity,\ncomplexity, and specificity pose considerable challenges. In the clinical\ndomain, Named Entity Recognition (NER) stands out as an essential task and it\nplays a crucial role in extracting relevant information from clinical texts.\nDespite the promise of LLMs, current research mostly concentrates on\ndocument-level NER, identifying entities in a more general context across\nentire documents, without extracting their precise location. Additionally,\nefforts have been directed towards adapting ChatGPT for token-level NER.\nHowever, there is a significant research gap when it comes to employing\ntoken-level NER for clinical texts, especially with the use of local\nopen-source LLMs. This study aims to bridge this gap by investigating the\neffectiveness of both proprietary and local LLMs in token-level clinical NER.\nEssentially, we delve into the capabilities of these models through a series of\nexperiments involving zero-shot prompting, few-shot prompting,\nretrieval-augmented generation (RAG), and instruction-fine-tuning. Our\nexploration reveals the inherent challenges LLMs face in token-level NER,\nparticularly in the context of rare diseases, and suggests possible\nimprovements for their application in healthcare. This research contributes to\nnarrowing a significant gap in healthcare informatics and offers insights that\ncould lead to a more refined application of LLMs in the healthcare sector.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}