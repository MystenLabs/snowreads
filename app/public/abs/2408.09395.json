{"id":"2408.09395","title":"OU-CoViT: Copula-Enhanced Bi-Channel Multi-Task Vision Transformers with\n  Dual Adaptation for OU-UWF Images","authors":"Yang Li, Jianing Deng, Chong Zhong, Danjuan Yang, Meiyan Li, A.H.\n  Welsh, Aiyi Liu, Xingtao Zhou, Catherine C. Liu, Bo Fu","authorsParsed":[["Li","Yang",""],["Deng","Jianing",""],["Zhong","Chong",""],["Yang","Danjuan",""],["Li","Meiyan",""],["Welsh","A. H.",""],["Liu","Aiyi",""],["Zhou","Xingtao",""],["Liu","Catherine C.",""],["Fu","Bo",""]],"versions":[{"version":"v1","created":"Sun, 18 Aug 2024 07:42:11 GMT"}],"updateDate":"2024-08-20","timestamp":1723966931000,"abstract":"  Myopia screening using cutting-edge ultra-widefield (UWF) fundus imaging and\njoint modeling of multiple discrete and continuous clinical scores presents a\npromising new paradigm for multi-task problems in Ophthalmology. The bi-channel\nframework that arises from the Ophthalmic phenomenon of ``interocular\nasymmetries'' of both eyes (OU) calls for new employment on the SOTA\ntransformer-based models. However, the application of copula models for\nmultiple mixed discrete-continuous labels on deep learning (DL) is challenging.\nMoreover, the application of advanced large transformer-based models to small\nmedical datasets is challenging due to overfitting and computational resource\nconstraints. To resolve these challenges, we propose OU-CoViT: a novel\nCopula-Enhanced Bi-Channel Multi-Task Vision Transformers with Dual Adaptation\nfor OU-UWF images, which can i) incorporate conditional correlation information\nacross multiple discrete and continuous labels within a deep learning framework\n(by deriving the closed form of a novel Copula Loss); ii) take OU inputs\nsubject to both high correlation and interocular asymmetries using a bi-channel\nmodel with dual adaptation; and iii) enable the adaptation of large vision\ntransformer (ViT) models to small medical datasets. Solid experiments\ndemonstrate that OU-CoViT significantly improves prediction performance\ncompared to single-channel baseline models with empirical loss. Furthermore,\nthe novel architecture of OU-CoViT allows generalizability and extensions of\nour dual adaptation and Copula Loss to various ViT variants and large DL models\non small medical datasets. Our approach opens up new possibilities for joint\nmodeling of heterogeneous multi-channel input and mixed discrete-continuous\nclinical scores in medical practices and has the potential to advance\nAI-assisted clinical decision-making in various medical domains beyond\nOphthalmology.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}