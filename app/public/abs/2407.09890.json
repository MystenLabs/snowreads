{"id":"2407.09890","title":"Speech-Guided Sequential Planning for Autonomous Navigation using Large\n  Language Model Meta AI 3 (Llama3)","authors":"Alkesh K. Srivastava and Philip Dames","authorsParsed":[["Srivastava","Alkesh K.",""],["Dames","Philip",""]],"versions":[{"version":"v1","created":"Sat, 13 Jul 2024 13:43:39 GMT"}],"updateDate":"2024-07-16","timestamp":1720878219000,"abstract":"  In social robotics, a pivotal focus is enabling robots to engage with humans\nin a more natural and seamless manner. The emergence of advanced large language\nmodels (LLMs) such as Generative Pre-trained Transformers (GPTs) and\nautoregressive models like Large Language Model Meta AI (Llamas) has driven\nsignificant advancements in integrating natural language understanding\ncapabilities into social robots. This paper presents a system for speech-guided\nsequential planning in autonomous navigation, utilizing Llama3 and the Robot\nOperating System~(ROS). The proposed system involves using Llama3 to interpret\nvoice commands, extracting essential details through parsing, and decoding\nthese commands into sequential actions for tasks. Such sequential planning is\nessential in various domains, particularly in the pickup and delivery of an\nobject. Once a sequential navigation task is evaluated, we employ DRL-VO, a\nlearning-based control policy that allows a robot to autonomously navigate\nthrough social spaces with static infrastructure and (crowds of) people. We\ndemonstrate the effectiveness of the system in simulation experiment using\nTurtlebot 2 in ROS1 and Turtlebot 3 in ROS2. We conduct hardware trials using a\nClearpath Robotics Jackal UGV, highlighting its potential for real-world\ndeployment in scenarios requiring flexible and interactive robotic behaviors.\n","subjects":["Computing Research Repository/Robotics"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}