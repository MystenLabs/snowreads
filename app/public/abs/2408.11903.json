{"id":"2408.11903","title":"Ancient Wisdom, Modern Tools: Exploring Retrieval-Augmented LLMs for\n  Ancient Indian Philosophy","authors":"Priyanka Mandikal","authorsParsed":[["Mandikal","Priyanka",""]],"versions":[{"version":"v1","created":"Wed, 21 Aug 2024 18:00:21 GMT"},{"version":"v2","created":"Fri, 23 Aug 2024 17:15:39 GMT"}],"updateDate":"2024-08-26","timestamp":1724263221000,"abstract":"  LLMs have revolutionized the landscape of information retrieval and knowledge\ndissemination. However, their application in specialized areas is often\nhindered by factual inaccuracies and hallucinations, especially in long-tail\nknowledge distributions. We explore the potential of retrieval-augmented\ngeneration (RAG) models for long-form question answering (LFQA) in a\nspecialized knowledge domain. We present VedantaNY-10M, a dataset curated from\nextensive public discourses on the ancient Indian philosophy of Advaita\nVedanta. We develop and benchmark a RAG model against a standard, non-RAG LLM,\nfocusing on transcription, retrieval, and generation performance. Human\nevaluations by computational linguists and domain experts show that the RAG\nmodel significantly outperforms the standard model in producing factual and\ncomprehensive responses having fewer hallucinations. In addition, a\nkeyword-based hybrid retriever that emphasizes unique low-frequency terms\nfurther improves results. Our study provides insights into effectively\nintegrating modern large language models with ancient knowledge systems.\nProject page with dataset and code: https://sites.google.com/view/vedantany-10m\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Computers and Society","Computing Research Repository/Information Retrieval"],"license":"http://creativecommons.org/licenses/by/4.0/"}