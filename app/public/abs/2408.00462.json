{"id":"2408.00462","title":"Designing Efficient LLM Accelerators for Edge Devices","authors":"Jude Haris, Rappy Saha, Wenhao Hu, Jos\\'e Cano","authorsParsed":[["Haris","Jude",""],["Saha","Rappy",""],["Hu","Wenhao",""],["Cano","Jos√©",""]],"versions":[{"version":"v1","created":"Thu, 1 Aug 2024 11:06:05 GMT"}],"updateDate":"2024-08-02","timestamp":1722510365000,"abstract":"  The increase in open-source availability of Large Language Models (LLMs) has\nenabled users to deploy them on more and more resource-constrained edge devices\nto reduce reliance on network connections and provide more privacy. However,\nthe high computation and memory demands of LLMs make their execution on\nresource-constrained edge devices challenging and inefficient. To address this\nissue, designing new and efficient edge accelerators for LLM inference is\ncrucial. FPGA-based accelerators are ideal for LLM acceleration due to their\nreconfigurability, as they enable model-specific optimizations and higher\nperformance per watt. However, creating and integrating FPGA-based accelerators\nfor LLMs (particularly on edge devices) has proven challenging, mainly due to\nthe limited hardware design flows for LLMs in existing FPGA platforms.\n  To tackle this issue, in this paper we first propose a new design platform,\nnamed SECDA-LLM, that utilizes the SECDA methodology to streamline the process\nof designing, integrating, and deploying efficient FPGA-based LLM accelerators\nfor the llama.cpp inference framework. We then demonstrate, through a case\nstudy, the potential benefits of SECDA-LLM by creating a new MatMul accelerator\nthat supports block floating point quantized operations for LLMs. Our initial\naccelerator design, deployed on the PYNQ-Z1 board, reduces latency 1.7 seconds\nper token or ~2 seconds per word) by 11x over the dual-core Arm NEON-based CPU\nexecution for the TinyLlama model.\n","subjects":["Computing Research Repository/Hardware Architecture","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}