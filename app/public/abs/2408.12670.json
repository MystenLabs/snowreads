{"id":"2408.12670","title":"Leveraging Information Consistency in Frequency and Spatial Domain for\n  Adversarial Attacks","authors":"Zhibo Jin, Jiayu Zhang, Zhiyu Zhu, Xinyi Wang, Yiyun Huang, Huaming\n  Chen","authorsParsed":[["Jin","Zhibo",""],["Zhang","Jiayu",""],["Zhu","Zhiyu",""],["Wang","Xinyi",""],["Huang","Yiyun",""],["Chen","Huaming",""]],"versions":[{"version":"v1","created":"Thu, 22 Aug 2024 18:24:08 GMT"}],"updateDate":"2024-08-26","timestamp":1724351048000,"abstract":"  Adversarial examples are a key method to exploit deep neural networks. Using\ngradient information, such examples can be generated in an efficient way\nwithout altering the victim model. Recent frequency domain transformation has\nfurther enhanced the transferability of such adversarial examples, such as\nspectrum simulation attack. In this work, we investigate the effectiveness of\nfrequency domain-based attacks, aligning with similar findings in the spatial\ndomain. Furthermore, such consistency between the frequency and spatial domains\nprovides insights into how gradient-based adversarial attacks induce\nperturbations across different domains, which is yet to be explored. Hence, we\npropose a simple, effective, and scalable gradient-based adversarial attack\nalgorithm leveraging the information consistency in both frequency and spatial\ndomains. We evaluate the algorithm for its effectiveness against different\nmodels. Extensive experiments demonstrate that our algorithm achieves\nstate-of-the-art results compared to other gradient-based algorithms. Our code\nis available at: https://github.com/LMBTough/FSA.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}