{"id":"2408.15300","title":"GIFT-SW: Gaussian noise Injected Fine-Tuning of Salient Weights for LLMs","authors":"Maxim Zhelnin, Viktor Moskvoretskii, Egor Shvetsov, Egor Venediktov,\n  Mariya Krylova, Aleksandr Zuev, Evgeny Burnaev","authorsParsed":[["Zhelnin","Maxim",""],["Moskvoretskii","Viktor",""],["Shvetsov","Egor",""],["Venediktov","Egor",""],["Krylova","Mariya",""],["Zuev","Aleksandr",""],["Burnaev","Evgeny",""]],"versions":[{"version":"v1","created":"Tue, 27 Aug 2024 14:41:14 GMT"}],"updateDate":"2024-08-29","timestamp":1724769674000,"abstract":"  Parameter Efficient Fine-Tuning (PEFT) methods have gained popularity and\ndemocratized the usage of Large Language Models (LLMs). Recent studies have\nshown that a small subset of weights significantly impacts performance. Based\non this observation, we introduce a novel PEFT method, called Gaussian noise\nInjected Fine Tuning of Salient Weights (GIFT-SW). Our method updates only\nsalient columns, while injecting Gaussian noise into non-salient ones. To\nidentify these columns, we developeda generalized sensitivity metric that\nextends and unifies metrics from previous studies. Experiments with LLaMA\nmodels demonstrate that GIFT-SW outperforms full fine-tuning and modern PEFT\nmethods under the same computational budget. Moreover, GIFT-SW offers practical\nadvantages to recover performance of models subjected to mixed-precision\nquantization with keeping salient weights in full precision.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/"}