{"id":"2407.06245","title":"ORAN-Bench-13K: An Open Source Benchmark for Assessing LLMs in Open\n  Radio Access Networks","authors":"Pranshav Gajjar and Vijay K. Shah","authorsParsed":[["Gajjar","Pranshav",""],["Shah","Vijay K.",""]],"versions":[{"version":"v1","created":"Mon, 8 Jul 2024 13:07:50 GMT"},{"version":"v2","created":"Sat, 13 Jul 2024 22:48:44 GMT"}],"updateDate":"2024-07-16","timestamp":1720444070000,"abstract":"  Large Language Models (LLMs) can revolutionize how we deploy and operate Open\nRadio Access Networks (O-RAN) by enhancing network analytics, anomaly\ndetection, and code generation and significantly increasing the efficiency and\nreliability of a plethora of O-RAN tasks. In this paper, we present\nORAN-Bench-13K, the first comprehensive benchmark designed to evaluate the\nperformance of Large Language Models (LLMs) within the context of O-RAN. Our\nbenchmark consists of 13,952 meticulously curated multiple-choice questions\ngenerated from 116 O-RAN specification documents. We leverage a novel\nthree-stage LLM framework, and the questions are categorized into three\ndistinct difficulties to cover a wide spectrum of ORAN-related knowledge. We\nthoroughly evaluate the performance of several state-of-the-art LLMs, including\nGemini, Chat-GPT, and Mistral. Additionally, we propose ORANSight, a\nRetrieval-Augmented Generation (RAG)-based pipeline that demonstrates superior\nperformance on ORAN-Bench-13K compared to other tested closed-source models.\nOur findings indicate that current popular LLM models are not proficient in\nO-RAN, highlighting the need for specialized models. We observed a noticeable\nperformance improvement when incorporating the RAG-based ORANSight pipeline,\nwith a Macro Accuracy of 0.784 and a Weighted Accuracy of 0.776, which was on\naverage 21.55% and 22.59% better than the other tested LLMs.\n","subjects":["Computing Research Repository/Networking and Internet Architecture","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}