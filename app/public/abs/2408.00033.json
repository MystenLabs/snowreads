{"id":"2408.00033","title":"Enhanced Fault Detection and Cause Identification Using Integrated\n  Attention Mechanism","authors":"Mohammad Ali Labbaf Khaniki, Alireza Golkarieh, Houman Nouri, Mohammad\n  Manthouri","authorsParsed":[["Khaniki","Mohammad Ali Labbaf",""],["Golkarieh","Alireza",""],["Nouri","Houman",""],["Manthouri","Mohammad",""]],"versions":[{"version":"v1","created":"Wed, 31 Jul 2024 12:01:57 GMT"}],"updateDate":"2024-08-02","timestamp":1722427317000,"abstract":"  This study introduces a novel methodology for fault detection and cause\nidentification within the Tennessee Eastman Process (TEP) by integrating a\nBidirectional Long Short-Term Memory (BiLSTM) neural network with an Integrated\nAttention Mechanism (IAM). The IAM combines the strengths of scaled dot product\nattention, residual attention, and dynamic attention to capture intricate\npatterns and dependencies crucial for TEP fault detection. Initially, the\nattention mechanism extracts important features from the input data, enhancing\nthe model's interpretability and relevance. The BiLSTM network processes these\nfeatures bidirectionally to capture long-range dependencies, and the IAM\nfurther refines the output, leading to improved fault detection results.\nSimulation results demonstrate the efficacy of this approach, showcasing\nsuperior performance in accuracy, false alarm rate, and misclassification rate\ncompared to existing methods. This methodology provides a robust and\ninterpretable solution for fault detection and diagnosis in the TEP,\nhighlighting its potential for industrial applications.\n","subjects":["Computing Research Repository/Artificial Intelligence","Electrical Engineering and Systems Science/Signal Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}