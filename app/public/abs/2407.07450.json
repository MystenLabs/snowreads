{"id":"2407.07450","title":"Using Low-Discrepancy Points for Data Compression in Machine Learning:\n  An Experimental Comparison","authors":"Simone G\\\"ottlich, Jacob Heieck, Andreas Neuenkirch","authorsParsed":[["GÃ¶ttlich","Simone",""],["Heieck","Jacob",""],["Neuenkirch","Andreas",""]],"versions":[{"version":"v1","created":"Wed, 10 Jul 2024 08:07:55 GMT"}],"updateDate":"2024-07-11","timestamp":1720598875000,"abstract":"  Low-discrepancy points (also called Quasi-Monte Carlo points) are\ndeterministically and cleverly chosen point sets in the unit cube, which\nprovide an approximation of the uniform distribution. We explore two methods\nbased on such low-discrepancy points to reduce large data sets in order to\ntrain neural networks. The first one is the method of Dick and Feischl [4],\nwhich relies on digital nets and an averaging procedure. Motivated by our\nexperimental findings, we construct a second method, which again uses digital\nnets, but Voronoi clustering instead of averaging. Both methods are compared to\nthe supercompress approach of [14], which is a variant of the K-means\nclustering algorithm. The comparison is done in terms of the compression error\nfor different objective functions and the accuracy of the training of a neural\nnetwork.\n","subjects":["Statistics/Machine Learning","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}