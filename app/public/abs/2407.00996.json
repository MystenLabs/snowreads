{"id":"2407.00996","title":"Can Small Language Models Learn, Unlearn, and Retain Noise Patterns?","authors":"Nicy Scaria, Silvester John Joseph Kennedy, Deepak Subramani","authorsParsed":[["Scaria","Nicy",""],["Kennedy","Silvester John Joseph",""],["Subramani","Deepak",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 06:22:38 GMT"}],"updateDate":"2024-07-02","timestamp":1719814958000,"abstract":"  Small Language Models (SLMs) are generally considered to be more compact\nversions of large language models (LLMs), typically having fewer than 7 billion\nparameters. This study investigates the ability of small language models to\nlearn, retain, and subsequently eliminate noise that is typically not found on\nthe internet, where most pretraining datasets are sourced. For this, four\npre-trained SLMs were utilized: Olmo 1B, Qwen1.5 1.8B, Gemma 2B, and Phi2 2.7B.\nThe models were instruction-tuned without noise and tested for task execution\nwith in-context learning. Afterward, noise patterns were introduced to evaluate\nthe models' learning and unlearning capabilities. We evaluated the models'\nperformance at various training levels. Phi consistently excelled with\nword-level noise but performed the worst with character-level noise. Despite\nbeing the smallest with approximately 1 billion parameters, Olmo performed\nconsistently well on tasks.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by-sa/4.0/","blobId":"tN4h7dRZ2RvyHyZTLmn1BKar4TmJvSv52SsDIOY1zJQ","pdfSize":"871487"}
