{"id":"2408.02036","title":"LEGO: Self-Supervised Representation Learning for Scene Text Images","authors":"Yujin Ren, Jiaxin Zhang, Lianwen Jin","authorsParsed":[["Ren","Yujin",""],["Zhang","Jiaxin",""],["Jin","Lianwen",""]],"versions":[{"version":"v1","created":"Sun, 4 Aug 2024 14:07:14 GMT"}],"updateDate":"2024-08-06","timestamp":1722780434000,"abstract":"  In recent years, significant progress has been made in scene text recognition\nby data-driven methods. However, due to the scarcity of annotated real-world\ndata, the training of these methods predominantly relies on synthetic data. The\ndistribution gap between synthetic and real data constrains the further\nperformance improvement of these methods in real-world applications. To tackle\nthis problem, a highly promising approach is to utilize massive amounts of\nunlabeled real data for self-supervised training, which has been widely proven\neffective in many NLP and CV tasks. Nevertheless, generic self-supervised\nmethods are unsuitable for scene text images due to their sequential nature. To\naddress this issue, we propose a Local Explicit and Global Order-aware\nself-supervised representation learning method (LEGO) that accounts for the\ncharacteristics of scene text images. Inspired by the human cognitive process\nof learning words, which involves spelling, reading, and writing, we propose\nthree novel pre-text tasks for LEGO to model sequential, semantic, and\nstructural features, respectively. The entire pre-training process is optimized\nby using a consistent Text Knowledge Codebook. Extensive experiments validate\nthat LEGO outperforms previous scene text self-supervised methods. The\nrecognizer incorporated with our pre-trained model achieves superior or\ncomparable performance compared to state-of-the-art scene text recognition\nmethods on six benchmarks. Furthermore, we demonstrate that LEGO can achieve\nsuperior performance in other text-related tasks.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}