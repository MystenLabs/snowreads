{"id":"2407.15780","title":"Explaining Decisions in ML Models: a Parameterized Complexity Analysis","authors":"Sebastian Ordyniak, Giacomo Paesani, Mateusz Rychlicki, Stefan Szeider","authorsParsed":[["Ordyniak","Sebastian",""],["Paesani","Giacomo",""],["Rychlicki","Mateusz",""],["Szeider","Stefan",""]],"versions":[{"version":"v1","created":"Mon, 22 Jul 2024 16:37:48 GMT"}],"updateDate":"2024-07-23","timestamp":1721666268000,"abstract":"  This paper presents a comprehensive theoretical investigation into the\nparameterized complexity of explanation problems in various machine learning\n(ML) models. Contrary to the prevalent black-box perception, our study focuses\non models with transparent internal mechanisms. We address two principal types\nof explanation problems: abductive and contrastive, both in their local and\nglobal variants. Our analysis encompasses diverse ML models, including Decision\nTrees, Decision Sets, Decision Lists, Ordered Binary Decision Diagrams, Random\nForests, and Boolean Circuits, and ensembles thereof, each offering unique\nexplanatory challenges. This research fills a significant gap in explainable AI\n(XAI) by providing a foundational understanding of the complexities of\ngenerating explanations for these models. This work provides insights vital for\nfurther research in the domain of XAI, contributing to the broader discourse on\nthe necessity of transparency and accountability in AI systems.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computational Complexity"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}