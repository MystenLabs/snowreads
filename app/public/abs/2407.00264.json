{"id":"2407.00264","title":"External Model Motivated Agents: Reinforcement Learning for Enhanced\n  Environment Sampling","authors":"Rishav Bhagat, Jonathan Balloch, Zhiyu Lin, Julia Kim, Mark Riedl","authorsParsed":[["Bhagat","Rishav",""],["Balloch","Jonathan",""],["Lin","Zhiyu",""],["Kim","Julia",""],["Riedl","Mark",""]],"versions":[{"version":"v1","created":"Fri, 28 Jun 2024 23:31:22 GMT"}],"updateDate":"2024-07-02","timestamp":1719617482000,"abstract":"  Unlike reinforcement learning (RL) agents, humans remain capable multitaskers\nin changing environments. In spite of only experiencing the world through their\nown observations and interactions, people know how to balance focusing on tasks\nwith learning about how changes may affect their understanding of the world.\nThis is possible by choosing to solve tasks in ways that are interesting and\ngenerally informative beyond just the current task. Motivated by this, we\npropose an agent influence framework for RL agents to improve the adaptation\nefficiency of external models in changing environments without any changes to\nthe agent's rewards. Our formulation is composed of two self-contained modules:\ninterest fields and behavior shaping via interest fields. We implement an\nuncertainty-based interest field algorithm as well as a skill-sampling-based\nbehavior-shaping algorithm to use in testing this framework. Our results show\nthat our method outperforms the baselines in terms of external model adaptation\non metrics that measure both efficiency and performance.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"bajP6WdPJ0A3LRpfLefOlHXQwPV62so0I2xf3zwdNws","pdfSize":"787809","objectId":"0x0b894167628af51a5e6f54a04204c8d5022811da377fd91d4c2b20689958b448","registeredEpoch":"1","certifiedEpoch":"1","startEpoch":"1","endEpoch":"201"}
