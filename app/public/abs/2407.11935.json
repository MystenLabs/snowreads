{"id":"2407.11935","title":"Learning Multi-view Anomaly Detection","authors":"Haoyang He, Jiangning Zhang, Guanzhong Tian, Chengjie Wang, Lei Xie","authorsParsed":[["He","Haoyang",""],["Zhang","Jiangning",""],["Tian","Guanzhong",""],["Wang","Chengjie",""],["Xie","Lei",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 17:26:34 GMT"}],"updateDate":"2024-07-17","timestamp":1721150794000,"abstract":"  This study explores the recently proposed challenging multi-view Anomaly\nDetection (AD) task. Single-view tasks would encounter blind spots from other\nperspectives, resulting in inaccuracies in sample-level prediction. Therefore,\nwe introduce the \\textbf{M}ulti-\\textbf{V}iew \\textbf{A}nomaly\n\\textbf{D}etection (\\textbf{MVAD}) framework, which learns and integrates\nfeatures from multi-views. Specifically, we proposed a\n\\textbf{M}ulti-\\textbf{V}iew \\textbf{A}daptive \\textbf{S}election\n(\\textbf{MVAS}) algorithm for feature learning and fusion across multiple\nviews. The feature maps are divided into neighbourhood attention windows to\ncalculate a semantic correlation matrix between single-view windows and all\nother views, which is a conducted attention mechanism for each single-view\nwindow and the top-K most correlated multi-view windows. Adjusting the window\nsizes and top-K can minimise the computational complexity to linear. Extensive\nexperiments on the Real-IAD dataset for cross-setting (multi/single-class)\nvalidate the effectiveness of our approach, achieving state-of-the-art\nperformance among sample \\textbf{4.1\\%}$\\uparrow$/ image\n\\textbf{5.6\\%}$\\uparrow$/pixel \\textbf{6.7\\%}$\\uparrow$ levels with a total of\nten metrics with only \\textbf{18M} parameters and fewer GPU memory and training\ntime.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}