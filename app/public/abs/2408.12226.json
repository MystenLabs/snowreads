{"id":"2408.12226","title":"EvalYaks: Instruction Tuning Datasets and LoRA Fine-tuned Models for\n  Automated Scoring of CEFR B2 Speaking Assessment Transcripts","authors":"Nicy Scaria, Silvester John Joseph Kennedy, Thomas Latinovich, Deepak\n  Subramani","authorsParsed":[["Scaria","Nicy",""],["Kennedy","Silvester John Joseph",""],["Latinovich","Thomas",""],["Subramani","Deepak",""]],"versions":[{"version":"v1","created":"Thu, 22 Aug 2024 08:57:31 GMT"}],"updateDate":"2024-08-23","timestamp":1724317051000,"abstract":"  Relying on human experts to evaluate CEFR speaking assessments in an\ne-learning environment creates scalability challenges, as it limits how quickly\nand widely assessments can be conducted. We aim to automate the evaluation of\nCEFR B2 English speaking assessments in e-learning environments from\nconversation transcripts. First, we evaluate the capability of leading open\nsource and commercial Large Language Models (LLMs) to score a candidate's\nperformance across various criteria in the CEFR B2 speaking exam in both global\nand India-specific contexts. Next, we create a new expert-validated,\nCEFR-aligned synthetic conversational dataset with transcripts that are rated\nat different assessment scores. In addition, new instruction-tuned datasets are\ndeveloped from the English Vocabulary Profile (up to CEFR B2 level) and the\nCEFR-SP WikiAuto datasets. Finally, using these new datasets, we perform\nparameter efficient instruction tuning of Mistral Instruct 7B v0.2 to develop a\nfamily of models called EvalYaks. Four models in this family are for assessing\nthe four sections of the CEFR B2 speaking exam, one for identifying the CEFR\nlevel of vocabulary and generating level-specific vocabulary, and another for\ndetecting the CEFR level of text and generating level-specific text. EvalYaks\nachieved an average acceptable accuracy of 96%, a degree of variation of 0.35\nlevels, and performed 3 times better than the next best model. This\ndemonstrates that a 7B parameter LLM instruction tuned with high-quality\nCEFR-aligned assessment data can effectively evaluate and score CEFR B2 English\nspeaking assessments, offering a promising solution for scalable, automated\nlanguage proficiency evaluation.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"xu5tjw2CEKvWG-JMn8schjob4vfA_H7D4A54FTzRMUY","pdfSize":"3524415"}
