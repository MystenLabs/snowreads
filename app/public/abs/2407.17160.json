{"id":"2407.17160","title":"A Comparative Analysis of Bilingual and Trilingual Wav2Vec Models for\n  Automatic Speech Recognition in Multilingual Oral History Archives","authors":"Jan Lehe\\v{c}ka, Josef V. Psutka, Lubo\\v{s} \\v{S}m\\'idl, Pavel Ircing,\n  Josef Psutka","authorsParsed":[["Lehečka","Jan",""],["Psutka","Josef V.",""],["Šmídl","Luboš",""],["Ircing","Pavel",""],["Psutka","Josef",""]],"versions":[{"version":"v1","created":"Wed, 24 Jul 2024 11:03:47 GMT"}],"updateDate":"2024-07-25","timestamp":1721819027000,"abstract":"  In this paper, we are comparing monolingual Wav2Vec 2.0 models with various\nmultilingual models to see whether we could improve speech recognition\nperformance on a unique oral history archive containing a lot of mixed-language\nsentences. Our main goal is to push forward research on this unique dataset,\nwhich is an extremely valuable part of our cultural heritage. Our results\nsuggest that monolingual speech recognition models are, in most cases, superior\nto multilingual models, even when processing the oral history archive full of\nmixed-language sentences from non-native speakers. We also performed the same\nexperiments on the public CommonVoice dataset to verify our results. We are\ncontributing to the research community by releasing our pre-trained models to\nthe public.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/"}