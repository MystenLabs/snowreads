{"id":"2408.13457","title":"Make Every Penny Count: Difficulty-Adaptive Self-Consistency for\n  Cost-Efficient Reasoning","authors":"Xinglin Wang, Shaoxiong Feng, Yiwei Li, Peiwen Yuan, Yueqi Zhang,\n  Boyuan Pan, Heda Wang, Yao Hu, Kan Li","authorsParsed":[["Wang","Xinglin",""],["Feng","Shaoxiong",""],["Li","Yiwei",""],["Yuan","Peiwen",""],["Zhang","Yueqi",""],["Pan","Boyuan",""],["Wang","Heda",""],["Hu","Yao",""],["Li","Kan",""]],"versions":[{"version":"v1","created":"Sat, 24 Aug 2024 04:03:35 GMT"}],"updateDate":"2024-08-27","timestamp":1724472215000,"abstract":"  Self-consistency (SC), a widely used decoding strategy for chain-of-thought\nreasoning, shows significant gains across various multi-step reasoning tasks\nbut comes with a high cost due to multiple sampling with the preset size. Its\nvariants, Adaptive self-consistency (ASC) and Early-stopping self-consistency\n(ESC), dynamically adjust the number of samples based on the posterior\ndistribution of a set of pre-samples, reducing the cost of SC with minimal\nimpact on performance. Both methods, however, do not exploit the prior\ninformation about question difficulty. It often results in unnecessary repeated\nsampling for easy questions that could be accurately answered with just one\nattempt, wasting resources. To tackle this problem, we propose\nDifficulty-Adaptive Self-Consistency (DSC), which leverages the difficulty\ninformation from both prior and posterior perspectives to adaptively allocate\ninference resources, further reducing the cost of SC. To demonstrate the\neffectiveness of DSC, we conduct extensive experiments on three popular\ncategories of reasoning tasks: arithmetic, commonsense and symbolic reasoning\non six benchmarks. The empirical results show that DSC consistently surpasses\nthe strong baseline ASC and ESC in terms of costs by a significant margin,\nwhile attaining comparable performances.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}