{"id":"2407.21315","title":"Beyond Silent Letters: Amplifying LLMs in Emotion Recognition with Vocal\n  Nuances","authors":"Zehui Wu, Ziwei Gong, Lin Ai, Pengyuan Shi, Kaan Donbekci and Julia\n  Hirschberg","authorsParsed":[["Wu","Zehui",""],["Gong","Ziwei",""],["Ai","Lin",""],["Shi","Pengyuan",""],["Donbekci","Kaan",""],["Hirschberg","Julia",""]],"versions":[{"version":"v1","created":"Wed, 31 Jul 2024 03:53:14 GMT"},{"version":"v2","created":"Thu, 1 Aug 2024 01:17:34 GMT"}],"updateDate":"2024-08-02","timestamp":1722397994000,"abstract":"  This paper introduces a novel approach to emotion detection in speech using\nLarge Language Models (LLMs). We address the limitation of LLMs in processing\naudio inputs by translating speech characteristics into natural language\ndescriptions. Our method integrates these descriptions into text prompts,\nenabling LLMs to perform multimodal emotion analysis without architectural\nmodifications. We evaluate our approach on two datasets: IEMOCAP and MELD,\ndemonstrating significant improvements in emotion recognition accuracy,\nparticularly for high-quality audio data. Our experiments show that\nincorporating speech descriptions yields a 2 percentage point increase in\nweighted F1 score on IEMOCAP (from 70.111\\% to 72.596\\%). We also compare\nvarious LLM architectures and explore the effectiveness of different feature\nrepresentations. Our findings highlight the potential of this approach in\nenhancing emotion detection capabilities of LLMs and underscore the importance\nof audio quality in speech-based emotion recognition tasks. We'll release the\nsource code on Github.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/"}