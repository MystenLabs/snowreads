{"id":"2407.02345","title":"MORPHEUS: Modeling Role from Personalized Dialogue History by Exploring\n  and Utilizing Latent Space","authors":"Yihong Tang, Bo Wang, Dongming Zhao, Xiaojia Jin, Jijun Zhang, Ruifang\n  He, Yuexian Hou","authorsParsed":[["Tang","Yihong",""],["Wang","Bo",""],["Zhao","Dongming",""],["Jin","Xiaojia",""],["Zhang","Jijun",""],["He","Ruifang",""],["Hou","Yuexian",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 15:12:34 GMT"}],"updateDate":"2024-07-03","timestamp":1719933154000,"abstract":"  Personalized Dialogue Generation (PDG) aims to create coherent responses\naccording to roles or personas. Traditional PDG relies on external role data,\nwhich can be scarce and raise privacy concerns. Approaches address these issues\nby extracting role information from dialogue history, which often fail to\ngenerically model roles in continuous space. To overcome these limitations, we\nintroduce a novel framework \\textbf{MO}dels \\textbf{R}oles from\n\\textbf{P}ersonalized Dialogue \\textbf{H}istory by \\textbf{E}xploring and\n\\textbf{U}tilizing Latent \\textbf{S}pace (MORPHEUS) through a three-stage\ntraining process. Specifically, we create a persona codebook to represent roles\nin latent space compactly, and this codebook is used to construct a posterior\ndistribution of role information. This method enables the model to generalize\nacross roles, allowing the generation of personalized dialogues even for unseen\nroles. Experiments on both Chinese and English datasets demonstrate that\nMORPHEUS enhances the extraction of role information, and improves response\ngeneration without external role data. Additionally, MORPHEUS can be considered\nan efficient fine-tuning for large language models.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}