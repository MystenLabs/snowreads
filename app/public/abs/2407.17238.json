{"id":"2407.17238","title":"Pretrained Visual Representations in Reinforcement Learning","authors":"Emlyn Williams, Athanasios Polydoros","authorsParsed":[["Williams","Emlyn",""],["Polydoros","Athanasios",""]],"versions":[{"version":"v1","created":"Wed, 24 Jul 2024 12:53:26 GMT"}],"updateDate":"2024-07-25","timestamp":1721825606000,"abstract":"  Visual reinforcement learning (RL) has made significant progress in recent\nyears, but the choice of visual feature extractor remains a crucial design\ndecision. This paper compares the performance of RL algorithms that train a\nconvolutional neural network (CNN) from scratch with those that utilize\npre-trained visual representations (PVRs). We evaluate the Dormant Ratio\nMinimization (DRM) algorithm, a state-of-the-art visual RL method, against\nthree PVRs: ResNet18, DINOv2, and Visual Cortex (VC). We use the Metaworld\nPush-v2 and Drawer-Open-v2 tasks for our comparison. Our results show that the\nchoice of training from scratch compared to using PVRs for maximising\nperformance is task-dependent, but PVRs offer advantages in terms of reduced\nreplay buffer size and faster training times. We also identify a strong\ncorrelation between the dormant ratio and model performance, highlighting the\nimportance of exploration in visual RL. Our study provides insights into the\ntrade-offs between training from scratch and using PVRs, informing the design\nof future visual RL algorithms.\n","subjects":["Computing Research Repository/Robotics","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}