{"id":"2407.00079","title":"Mooncake: A KVCache-centric Disaggregated Architecture for LLM Serving","authors":"Ruoyu Qin, Zheming Li, Weiran He, Mingxing Zhang, Yongwei Wu, Weimin\n  Zheng, Xinran Xu","authorsParsed":[["Qin","Ruoyu",""],["Li","Zheming",""],["He","Weiran",""],["Zhang","Mingxing",""],["Wu","Yongwei",""],["Zheng","Weimin",""],["Xu","Xinran",""]],"versions":[{"version":"v1","created":"Mon, 24 Jun 2024 02:05:32 GMT"},{"version":"v2","created":"Tue, 2 Jul 2024 02:49:35 GMT"},{"version":"v3","created":"Tue, 9 Jul 2024 04:03:10 GMT"}],"updateDate":"2024-07-10","timestamp":1719194732000,"abstract":"  Mooncake is the serving platform for Kimi, a leading LLM service provided by\nMoonshot AI. It features a KVCache-centric disaggregated architecture that\nseparates the prefill and decoding clusters. It also leverages the\nunderutilized CPU, DRAM, and SSD resources of the GPU cluster to implement a\ndisaggregated cache of KVCache. The core of Mooncake is its KVCache-centric\nscheduler, which balances maximizing overall effective throughput while meeting\nlatency-related Service Level Objectives (SLOs). Unlike traditional studies\nthat assume all requests will be processed, Mooncake faces challenges due to\nhighly overloaded scenarios. To mitigate these, we developed a prediction-based\nearly rejection policy. Experiments show that Mooncake excels in long-context\nscenarios. Compared to the baseline method, Mooncake can achieve up to a 525%\nincrease in throughput in certain simulated scenarios while adhering to SLOs.\nUnder real workloads, Mooncake's innovative architecture enables Kimi to handle\n75% more requests.\n","subjects":["Computing Research Repository/Distributed, Parallel, and Cluster Computing","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Hardware Architecture"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}