{"id":"2407.00341","title":"Iterative Data Augmentation with Large Language Models for Aspect-based\n  Sentiment Analysis","authors":"Haiyun Li, Qihuang Zhong, Ke Zhu, Juhua Liu, Bo Du, Dacheng Tao","authorsParsed":[["Li","Haiyun",""],["Zhong","Qihuang",""],["Zhu","Ke",""],["Liu","Juhua",""],["Du","Bo",""],["Tao","Dacheng",""]],"versions":[{"version":"v1","created":"Sat, 29 Jun 2024 07:00:37 GMT"}],"updateDate":"2024-07-02","timestamp":1719644437000,"abstract":"  Aspect-based Sentiment Analysis (ABSA) is an important sentiment analysis\ntask, which aims to determine the sentiment polarity towards an aspect in a\nsentence. Due to the expensive and limited labeled data, data augmentation (DA)\nhas become the standard for improving the performance of ABSA. However, current\nDA methods usually have some shortcomings: 1) poor fluency and coherence, 2)\nlack of diversity of generated data, and 3) reliance on some existing labeled\ndata, hindering its applications in real-world scenarios. In response to these\nproblems, we propose a systematic Iterative Data augmentation framework, namely\nIterD, to boost the performance of ABSA. The core of IterD is to leverage the\npowerful ability of large language models (LLMs) to iteratively generate more\nfluent and diverse synthetic labeled data, starting from an unsupervised\nsentence corpus. Extensive experiments on 4 widely-used ABSA benchmarks show\nthat IterD brings consistent and significant performance gains among 5 baseline\nABSA models. More encouragingly, the synthetic data generated by IterD can\nachieve comparable or even better performance against the manually annotated\ndata.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}