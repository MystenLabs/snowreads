{"id":"2407.12512","title":"$\\textit{GeoHard}$: Towards Measuring Class-wise Hardness through\n  Modelling Class Semantics","authors":"Fengyu Cai, Xinran Zhao, Hongming Zhang, Iryna Gurevych, Heinz Koeppl","authorsParsed":[["Cai","Fengyu",""],["Zhao","Xinran",""],["Zhang","Hongming",""],["Gurevych","Iryna",""],["Koeppl","Heinz",""]],"versions":[{"version":"v1","created":"Wed, 17 Jul 2024 11:53:39 GMT"}],"updateDate":"2024-07-18","timestamp":1721217219000,"abstract":"  Recent advances in measuring hardness-wise properties of data guide language\nmodels in sample selection within low-resource scenarios. However,\nclass-specific properties are overlooked for task setup and learning. How will\nthese properties influence model learning and is it generalizable across\ndatasets? To answer this question, this work formally initiates the concept of\n$\\textit{class-wise hardness}$. Experiments across eight natural language\nunderstanding (NLU) datasets demonstrate a consistent hardness distribution\nacross learning paradigms, models, and human judgment. Subsequent experiments\nunveil a notable challenge in measuring such class-wise hardness with\ninstance-level metrics in previous works. To address this, we propose\n$\\textit{GeoHard}$ for class-wise hardness measurement by modeling class\ngeometry in the semantic embedding space. $\\textit{GeoHard}$ surpasses\ninstance-level metrics by over 59 percent on $\\textit{Pearson}$'s correlation\non measuring class-wise hardness. Our analysis theoretically and empirically\nunderscores the generality of $\\textit{GeoHard}$ as a fresh perspective on data\ndiagnosis. Additionally, we showcase how understanding class-wise hardness can\npractically aid in improving task learning.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/"}