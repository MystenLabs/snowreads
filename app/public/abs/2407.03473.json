{"id":"2407.03473","title":"Exploring LGBTQ+ Bias in Generative AI Answers across Different Country\n  and Religious Contexts","authors":"Lilla Vicsek, Anna Vancs\\'o, Mike Zajko, Judit Takacs","authorsParsed":[["Vicsek","Lilla",""],["Vancs√≥","Anna",""],["Zajko","Mike",""],["Takacs","Judit",""]],"versions":[{"version":"v1","created":"Wed, 3 Jul 2024 19:38:19 GMT"}],"updateDate":"2024-07-08","timestamp":1720035499000,"abstract":"  Previous discussions have highlighted the need for generative AI tools to\nbecome more culturally sensitive, yet often neglect the complexities of\nhandling content about minorities, who are perceived differently across\ncultures and religions. Our study examined how two generative AI systems\nrespond to homophobic statements with varying cultural and religious context\ninformation. Findings showed ChatGPT 3.5's replies exhibited cultural\nrelativism, in contrast to Bard's, which stressed human rights and provided\nmore support for LGBTQ+ issues. Both demonstrated significant change in\nresponses based on contextual information provided in the prompts, suggesting\nthat AI systems may adjust in their responses the degree and forms of support\nfor LGBTQ+ people according to information they receive about the user's\nbackground. The study contributes to understanding the social and ethical\nimplications of AI responses and argues that any work to make generative AI\noutputs more culturally diverse requires a grounding in fundamental human\nrights.\n","subjects":["Computing Research Repository/Computers and Society","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/"}