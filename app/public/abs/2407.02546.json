{"id":"2407.02546","title":"Adaptive Autopilot: Constrained DRL for Diverse Driving Behaviors","authors":"Dinesh Cyril Selvaraj, Christian Vitale, Tania Panayiotou, Panayiotis\n  Kolios, Carla Fabiana Chiasserini, and Georgios Ellinas","authorsParsed":[["Selvaraj","Dinesh Cyril",""],["Vitale","Christian",""],["Panayiotou","Tania",""],["Kolios","Panayiotis",""],["Chiasserini","Carla Fabiana",""],["Ellinas","Georgios",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 13:08:01 GMT"}],"updateDate":"2024-07-04","timestamp":1719925681000,"abstract":"  In pursuit of autonomous vehicles, achieving human-like driving behavior is\nvital. This study introduces adaptive autopilot (AA), a unique framework\nutilizing constrained-deep reinforcement learning (C-DRL). AA aims to safely\nemulate human driving to reduce the necessity for driver intervention. Focusing\non the car-following scenario, the process involves (i) extracting data from\nthe highD natural driving study and categorizing it into three driving styles\nusing a rule-based classifier; (ii) employing deep neural network (DNN)\nregressors to predict human-like acceleration across styles; and (iii) using\nC-DRL, specifically the soft actor-critic Lagrangian technique, to learn\nhuman-like safe driving policies. Results indicate effectiveness in each step,\nwith the rule-based classifier distinguishing driving styles, the regressor\nmodel accurately predicting acceleration, outperforming traditional\ncar-following models, and C-DRL agents learning optimal policies for humanlike\ndriving across styles.\n","subjects":["Computing Research Repository/Robotics","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}