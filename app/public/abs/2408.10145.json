{"id":"2408.10145","title":"Multi-Scale Representation Learning for Image Restoration with\n  State-Space Model","authors":"Yuhong He, Long Peng, Qiaosi Yi, Chen Wu, Lu Wang","authorsParsed":[["He","Yuhong",""],["Peng","Long",""],["Yi","Qiaosi",""],["Wu","Chen",""],["Wang","Lu",""]],"versions":[{"version":"v1","created":"Mon, 19 Aug 2024 16:42:58 GMT"}],"updateDate":"2024-08-20","timestamp":1724085778000,"abstract":"  Image restoration endeavors to reconstruct a high-quality, detail-rich image\nfrom a degraded counterpart, which is a pivotal process in photography and\nvarious computer vision systems. In real-world scenarios, different types of\ndegradation can cause the loss of image details at various scales and degrade\nimage contrast. Existing methods predominantly rely on CNN and Transformer to\ncapture multi-scale representations. However, these methods are often limited\nby the high computational complexity of Transformers and the constrained\nreceptive field of CNN, which hinder them from achieving superior performance\nand efficiency in image restoration. To address these challenges, we propose a\nnovel Multi-Scale State-Space Model-based (MS-Mamba) for efficient image\nrestoration that enhances the capacity for multi-scale representation learning\nthrough our proposed global and regional SSM modules. Additionally, an Adaptive\nGradient Block (AGB) and a Residual Fourier Block (RFB) are proposed to improve\nthe network's detail extraction capabilities by capturing gradients in various\ndirections and facilitating learning details in the frequency domain. Extensive\nexperiments on nine public benchmarks across four classic image restoration\ntasks, image deraining, dehazing, denoising, and low-light enhancement,\ndemonstrate that our proposed method achieves new state-of-the-art performance\nwhile maintaining low computational complexity. The source code will be\npublicly available.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}