{"id":"2407.05578","title":"FALIP: Visual Prompt as Foveal Attention Boosts CLIP Zero-Shot\n  Performance","authors":"Jiedong Zhuang, Jiaqi Hu, Lianrui Mu, Rui Hu, Xiaoyu Liang, Jiangnan\n  Ye, Haoji Hu","authorsParsed":[["Zhuang","Jiedong",""],["Hu","Jiaqi",""],["Mu","Lianrui",""],["Hu","Rui",""],["Liang","Xiaoyu",""],["Ye","Jiangnan",""],["Hu","Haoji",""]],"versions":[{"version":"v1","created":"Mon, 8 Jul 2024 03:23:13 GMT"},{"version":"v2","created":"Wed, 21 Aug 2024 13:40:48 GMT"}],"updateDate":"2024-08-22","timestamp":1720408993000,"abstract":"  CLIP has achieved impressive zero-shot performance after pre-training on a\nlarge-scale dataset consisting of paired image-text data. Previous works have\nutilized CLIP by incorporating manually designed visual prompts like colored\ncircles and blur masks into the images to guide the model's attention, showing\nenhanced zero-shot performance in downstream tasks. Although these methods have\nachieved promising results, they inevitably alter the original information of\nthe images, which can lead to failure in specific tasks. We propose a\ntrain-free method Foveal-Attention CLIP (FALIP), which adjusts the CLIP's\nattention by inserting foveal attention masks into the multi-head\nself-attention module. We demonstrate FALIP effectively boosts CLIP zero-shot\nperformance in tasks such as referring expressions comprehension, image\nclassification, and 3D point cloud recognition. Experimental results further\nshow that FALIP outperforms existing methods on most metrics and can augment\ncurrent methods to enhance their performance.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}