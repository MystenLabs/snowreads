{"id":"2407.00805","title":"Towards shutdownable agents via stochastic choice","authors":"Elliott Thornley, Alexander Roman, Christos Ziakas, Leyton Ho, Louis\n  Thomson","authorsParsed":[["Thornley","Elliott",""],["Roman","Alexander",""],["Ziakas","Christos",""],["Ho","Leyton",""],["Thomson","Louis",""]],"versions":[{"version":"v1","created":"Sun, 30 Jun 2024 19:16:02 GMT"}],"updateDate":"2024-07-02","timestamp":1719774962000,"abstract":"  Some worry that advanced artificial agents may resist being shut down. The\nIncomplete Preferences Proposal (IPP) is an idea for ensuring that doesn't\nhappen. A key part of the IPP is using a novel 'Discounted REward for\nSame-Length Trajectories (DREST)' reward function to train agents to (1) pursue\ngoals effectively conditional on each trajectory-length (be 'USEFUL'), and (2)\nchoose stochastically between different trajectory-lengths (be 'NEUTRAL' about\ntrajectory-lengths). In this paper, we propose evaluation metrics for\nUSEFULNESS and NEUTRALITY. We use a DREST reward function to train simple\nagents to navigate gridworlds, and we find that these agents learn to be USEFUL\nand NEUTRAL. Our results thus suggest that DREST reward functions could also\ntrain advanced agents to be USEFUL and NEUTRAL, and thereby make these advanced\nagents useful and shutdownable.\n","subjects":["Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}