{"id":"2408.11278","title":"The Key of Parameter Skew in Federated Learning","authors":"Sifan Wang, Junfeng Liao, Ye Yuan, Riquan Zhang","authorsParsed":[["Wang","Sifan",""],["Liao","Junfeng",""],["Yuan","Ye",""],["Zhang","Riquan",""]],"versions":[{"version":"v1","created":"Wed, 21 Aug 2024 02:01:15 GMT"}],"updateDate":"2024-08-22","timestamp":1724205675000,"abstract":"  Federated Learning (FL) has emerged as an excellent solution for performing\ndeep learning on different data owners without exchanging raw data. However,\nstatistical heterogeneity in FL presents a key challenge, leading to a\nphenomenon of skewness in local model parameter distributions that researchers\nhave largely overlooked. In this work, we propose the concept of parameter skew\nto describe the phenomenon that can substantially affect the accuracy of global\nmodel parameter estimation. Additionally, we introduce FedSA, an aggregation\nstrategy to obtain a high-quality global model, to address the implication from\nparameter skew. Specifically, we categorize parameters into high-dispersion and\nlow-dispersion groups based on the coefficient of variation. For\nhigh-dispersion parameters, Micro-Classes (MIC) and Macro-Classes (MAC)\nrepresent the dispersion at the micro and macro levels, respectively, forming\nthe foundation of FedSA. To evaluate the effectiveness of FedSA, we conduct\nextensive experiments with different FL algorithms on three computer vision\ndatasets. FedSA outperforms eight state-of-the-art baselines by about 4.7% in\ntest accuracy.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}