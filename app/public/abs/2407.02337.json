{"id":"2407.02337","title":"Open foundation models for Azerbaijani language","authors":"Jafar Isbarov, Kavsar Huseynova, Elvin Mammadov, Mammad Hajili, Duygu\n  Ataman","authorsParsed":[["Isbarov","Jafar",""],["Huseynova","Kavsar",""],["Mammadov","Elvin",""],["Hajili","Mammad",""],["Ataman","Duygu",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 15:05:47 GMT"},{"version":"v2","created":"Mon, 19 Aug 2024 23:40:29 GMT"}],"updateDate":"2024-08-21","timestamp":1719932747000,"abstract":"  The emergence of multilingual large language models has enabled the\ndevelopment of language understanding and generation systems in Azerbaijani.\nHowever, most of the production-grade systems rely on cloud solutions, such as\nGPT-4. While there have been several attempts to develop open foundation models\nfor Azerbaijani, these works have not found their way into common use due to a\nlack of systemic benchmarking. This paper encompasses several lines of work\nthat promote open-source foundation models for Azerbaijani. We introduce (1) a\nlarge text corpus for Azerbaijani, (2) a family of encoder-only language models\ntrained on this dataset, (3) labeled datasets for evaluating these models, and\n(4) extensive evaluation that covers all major open-source models with\nAzerbaijani support.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"6O5qAM2iiGKGzDeAYzUir9EQvnHIayRS4ZAe_xghlJE","pdfSize":"1554986"}
