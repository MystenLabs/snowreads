{"id":"2408.11788","title":"DreamFactory: Pioneering Multi-Scene Long Video Generation with a\n  Multi-Agent Framework","authors":"Zhifei Xie, Daniel Tang, Dingwei Tan, Jacques Klein, Tegawend F.\n  Bissyand, Saad Ezzini","authorsParsed":[["Xie","Zhifei",""],["Tang","Daniel",""],["Tan","Dingwei",""],["Klein","Jacques",""],["Bissyand","Tegawend F.",""],["Ezzini","Saad",""]],"versions":[{"version":"v1","created":"Wed, 21 Aug 2024 17:21:13 GMT"}],"updateDate":"2024-08-22","timestamp":1724260873000,"abstract":"  Current video generation models excel at creating short, realistic clips, but\nstruggle with longer, multi-scene videos. We introduce \\texttt{DreamFactory},\nan LLM-based framework that tackles this challenge. \\texttt{DreamFactory}\nleverages multi-agent collaboration principles and a Key Frames Iteration\nDesign Method to ensure consistency and style across long videos. It utilizes\nChain of Thought (COT) to address uncertainties inherent in large language\nmodels. \\texttt{DreamFactory} generates long, stylistically coherent, and\ncomplex videos. Evaluating these long-form videos presents a challenge. We\npropose novel metrics such as Cross-Scene Face Distance Score and Cross-Scene\nStyle Consistency Score. To further research in this area, we contribute the\nMulti-Scene Videos Dataset containing over 150 human-rated videos.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language","Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Software Engineering"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}