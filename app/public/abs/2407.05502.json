{"id":"2407.05502","title":"Faux Polyglot: A Study on Information Disparity in Multilingual Large\n  Language Models","authors":"Nikhil Sharma, Kenton Murray and Ziang Xiao","authorsParsed":[["Sharma","Nikhil",""],["Murray","Kenton",""],["Xiao","Ziang",""]],"versions":[{"version":"v1","created":"Sun, 7 Jul 2024 21:26:36 GMT"},{"version":"v2","created":"Mon, 5 Aug 2024 07:22:58 GMT"}],"updateDate":"2024-08-06","timestamp":1720387596000,"abstract":"  With Retrieval Augmented Generation (RAG), Large Language Models (LLMs) are\nplaying a pivotal role in information search and are being adopted globally.\nAlthough the multilingual capability of LLMs offers new opportunities to bridge\nthe language barrier, do these capabilities translate into real-life scenarios\nwhere linguistic divide and knowledge conflicts between multilingual sources\nare known occurrences? In this paper, we studied LLM's linguistic preference in\na RAG-based information search setting. We found that LLMs displayed systemic\nbias towards information in the same language as the query language in both\ninformation retrieval and answer generation. Furthermore, in scenarios where\nthere is little information in the language of the query, LLMs prefer documents\nin high-resource languages, reinforcing the dominant views. Such bias exists\nfor both factual and opinion-based queries. Our results highlight the\nlinguistic divide within multilingual LLMs in information search systems. The\nseemingly beneficial multilingual capability of LLMs may backfire on\ninformation parity by reinforcing language-specific information cocoons or\nfilter bubbles further marginalizing low-resource views.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Information Retrieval"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}