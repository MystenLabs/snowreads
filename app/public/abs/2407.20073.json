{"id":"2407.20073","title":"Transfer Learning Targeting Mixed Population: A Distributional Robust\n  Perspective","authors":"Keyao Zhan, Xin Xiong, Zijian Guo, Tianxi Cai and Molei Liu","authorsParsed":[["Zhan","Keyao",""],["Xiong","Xin",""],["Guo","Zijian",""],["Cai","Tianxi",""],["Liu","Molei",""]],"versions":[{"version":"v1","created":"Mon, 29 Jul 2024 14:59:09 GMT"}],"updateDate":"2024-07-30","timestamp":1722265149000,"abstract":"  Despite recent advances in transfer learning with multiple source data sets,\nthere still lacks developments for mixture target populations that could be\napproximated through a composite of the sources due to certain key factors like\nethnicity in practice. To address this open problem under distributional shifts\nof covariates and outcome models as well as the absence of accurate labels on\ntarget, we propose a novel approach for distributionally robust transfer\nlearning targeting mixture population. It learns a set of covariate-specific\nweights to infer the target outcome model with multiple sources, relying on a\njoint source mixture assumption for the target population. Then our method\nincorporates a group adversarial learning step to enhance the robustness\nagainst moderate violation of the joint mixture assumption. In addition, our\nframework allows the use of side information like small labeled sample as a\nguidance to avoid over-conservative results. Statistical convergence and\npredictive accuracy of our method are quantified through asymptotic studies.\nSimulation and real-world studies demonstrate the out-performance of our method\nover existing multi-source and transfer learning approaches.\n","subjects":["Statistics/Methodology"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}