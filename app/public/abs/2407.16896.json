{"id":"2407.16896","title":"Free to play: UN Trade and Development's experience with developing its\n  own open-source Retrieval Augmented Generation Large Language Model\n  application","authors":"Daniel Hopp","authorsParsed":[["Hopp","Daniel",""]],"versions":[{"version":"v1","created":"Tue, 18 Jun 2024 14:23:54 GMT"}],"updateDate":"2024-07-25","timestamp":1718720634000,"abstract":"  Generative artificial intelligence (AI), and in particular Large Language\nModels (LLMs), have exploded in popularity and attention since the release to\nthe public of ChatGPT's Generative Pre-trained Transformer (GPT)-3.5 model in\nNovember of 2022. Due to the power of these general purpose models and their\nability to communicate in natural language, they can be useful in a range of\ndomains, including the work of official statistics and international\norganizations. However, with such a novel and seemingly complex technology, it\ncan feel as if generative AI is something that happens to an organization,\nsomething that can be talked about but not understood, that can be commented on\nbut not contributed to. Additionally, the costs of adoption and operation of\nproprietary solutions can be both uncertain and high, a barrier for often\ncost-constrained international organizations. In the face of these challenges,\nUnited Nations Trade and Development (UNCTAD), through its Global Crisis\nResponse Group (GCRG), has explored and developed its own open-source Retrieval\nAugmented Generation (RAG) LLM application. RAG makes LLMs aware of and more\nuseful for the organization's domain and work. Developing in-house solutions\ncomes with pros and cons, with pros including cost, flexibility, and fostering\ninstitutional knowledge. Cons include time and skill investments and gaps and\napplication polish and power. The three libraries developed to produce the app,\nnlp_pipeline for document processing and statistical analysis, local_rag_llm\nfor running a local RAG LLM, and streamlit_rag for the user interface, are\npublicly available on PyPI and GitHub with Dockerfiles. A fourth library,\nlocal_llm_finetune, is also available for fine-tuning existing LLMs which can\nthen be used in the application.\n","subjects":["Computing Research Repository/Computers and Society","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"YCH5Y6fcRn0hbl9ytor7_EAJy92ucItNiIW05gmp09U","pdfSize":"396134"}
