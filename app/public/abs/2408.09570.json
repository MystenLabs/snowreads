{"id":"2408.09570","title":"Say My Name: a Model's Bias Discovery Framework","authors":"Massimiliano Ciranni, Luca Molinaro, Carlo Alberto Barbano, Attilio\n  Fiandrotti, Vittorio Murino, Vito Paolo Pastore, Enzo Tartaglione","authorsParsed":[["Ciranni","Massimiliano",""],["Molinaro","Luca",""],["Barbano","Carlo Alberto",""],["Fiandrotti","Attilio",""],["Murino","Vittorio",""],["Pastore","Vito Paolo",""],["Tartaglione","Enzo",""]],"versions":[{"version":"v1","created":"Sun, 18 Aug 2024 18:50:59 GMT"}],"updateDate":"2024-08-20","timestamp":1724007059000,"abstract":"  In the last few years, due to the broad applicability of deep learning to\ndownstream tasks and end-to-end training capabilities, increasingly more\nconcerns about potential biases to specific, non-representative patterns have\nbeen raised. Many works focusing on unsupervised debiasing usually leverage the\ntendency of deep models to learn ``easier'' samples, for example by clustering\nthe latent space to obtain bias pseudo-labels. However, the interpretation of\nsuch pseudo-labels is not trivial, especially for a non-expert end user, as it\ndoes not provide semantic information about the bias features. To address this\nissue, we introduce ``Say My Name'' (SaMyNa), the first tool to identify biases\nwithin deep models semantically. Unlike existing methods, our approach focuses\non biases learned by the model. Our text-based pipeline enhances explainability\nand supports debiasing efforts: applicable during either training or post-hoc\nvalidation, our method can disentangle task-related information and proposes\nitself as a tool to analyze biases. Evaluation on traditional benchmarks\ndemonstrates its effectiveness in detecting biases and even disclaiming them,\nshowcasing its broad applicability for model diagnosis.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computers and Society"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}