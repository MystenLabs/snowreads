{"id":"2407.04245","title":"Every Pixel Has its Moments: Ultra-High-Resolution Unpaired\n  Image-to-Image Translation via Dense Normalization","authors":"Ming-Yang Ho, Che-Ming Wu, Min-Sheng Wu, and Yufeng Jane Tseng","authorsParsed":[["Ho","Ming-Yang",""],["Wu","Che-Ming",""],["Wu","Min-Sheng",""],["Tseng","Yufeng Jane",""]],"versions":[{"version":"v1","created":"Fri, 5 Jul 2024 04:14:50 GMT"}],"updateDate":"2024-07-08","timestamp":1720152890000,"abstract":"  Recent advancements in ultra-high-resolution unpaired image-to-image\ntranslation have aimed to mitigate the constraints imposed by limited GPU\nmemory through patch-wise inference. Nonetheless, existing methods often\ncompromise between the reduction of noticeable tiling artifacts and the\npreservation of color and hue contrast, attributed to the reliance on global\nimage- or patch-level statistics in the instance normalization layers. In this\nstudy, we introduce a Dense Normalization (DN) layer designed to estimate\npixel-level statistical moments. This approach effectively diminishes tiling\nartifacts while concurrently preserving local color and hue contrasts. To\naddress the computational demands of pixel-level estimation, we further propose\nan efficient interpolation algorithm. Moreover, we invent a parallelism\nstrategy that enables the DN layer to operate in a single pass. Through\nextensive experiments, we demonstrate that our method surpasses all existing\napproaches in performance. Notably, our DN layer is hyperparameter-free and can\nbe seamlessly integrated into most unpaired image-to-image translation\nframeworks without necessitating retraining. Overall, our work paves the way\nfor future exploration in handling images of arbitrary resolutions within the\nrealm of unpaired image-to-image translation. Code is available at:\nhttps://github.com/Kaminyou/Dense-Normalization.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}