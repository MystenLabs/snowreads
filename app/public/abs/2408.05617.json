{"id":"2408.05617","title":"Residual-INR: Communication Efficient On-Device Learning Using Implicit\n  Neural Representation","authors":"Hanqiu Chen, Xuebin Yao, Pradeep Subedi and Cong Hao","authorsParsed":[["Chen","Hanqiu",""],["Yao","Xuebin",""],["Subedi","Pradeep",""],["Hao","Cong",""]],"versions":[{"version":"v1","created":"Sat, 10 Aug 2024 19:31:21 GMT"}],"updateDate":"2024-08-13","timestamp":1723318281000,"abstract":"  Edge computing is a distributed computing paradigm that collects and\nprocesses data at or near the source of data generation. The on-device learning\nat edge relies on device-to-device wireless communication to facilitate\nreal-time data sharing and collaborative decision-making among multiple\ndevices. This significantly improves the adaptability of the edge computing\nsystem to the changing environments. However, as the scale of the edge\ncomputing system is getting larger, communication among devices is becoming the\nbottleneck because of the limited bandwidth of wireless communication leads to\nlarge data transfer latency. To reduce the amount of device-to-device data\ntransmission and accelerate on-device learning, in this paper, we propose\nResidual-INR, a fog computing-based communication-efficient on-device learning\nframework by utilizing implicit neural representation (INR) to compress\nimages/videos into neural network weights. Residual-INR enhances data transfer\nefficiency by collecting JPEG images from edge devices, compressing them into\nINR format at the fog node, and redistributing them for on-device learning. By\nusing a smaller INR for full image encoding and a separate object INR for\nhigh-quality object region reconstruction through residual encoding, our\ntechnique can reduce the encoding redundancy while maintaining the object\nquality. Residual-INR is a promising solution for edge on-device learning\nbecause it reduces data transmission by up to 5.16 x across a network of 10\nedge devices. It also facilitates CPU-free accelerated on-device learning,\nachieving up to 2.9 x speedup without sacrificing accuracy. Our code is\navailable at: https://github.com/sharclab/Residual-INR.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Distributed, Parallel, and Cluster Computing","Computing Research Repository/Information Theory","Mathematics/Information Theory"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}