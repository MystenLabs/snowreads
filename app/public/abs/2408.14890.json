{"id":"2408.14890","title":"Development of Large Annotated Music Datasets using HMM-based Forced\n  Viterbi Alignment","authors":"S. Johanan Joysingh, P. Vijayalakshmi, T. Nagarajan","authorsParsed":[["Joysingh","S. Johanan",""],["Vijayalakshmi","P.",""],["Nagarajan","T.",""]],"versions":[{"version":"v1","created":"Tue, 27 Aug 2024 09:06:29 GMT"}],"updateDate":"2024-08-28","timestamp":1724749589000,"abstract":"  Datasets are essential for any machine learning task. Automatic Music\nTranscription (AMT) is one such task, where considerable amount of data is\nrequired depending on the way the solution is achieved. Considering the fact\nthat a music dataset, complete with audio and its time-aligned transcriptions\nwould require the effort of people with musical experience, it could be stated\nthat the task becomes even more challenging. Musical experience is required in\nplaying the musical instrument(s), and in annotating and verifying the\ntranscriptions. We propose a method that would help in streamlining this\nprocess, making the task of obtaining a dataset from a particular instrument\neasy and efficient. We use predefined guitar exercises and hidden Markov\nmodel(HMM) based forced viterbi alignment to accomplish this. The guitar\nexercises are designed to be simple. Since the note sequence are already\ndefined, HMM based forced viterbi alignment provides time-aligned\ntranscriptions of these audio files. The onsets of the transcriptions are\nmanually verified and the labels are accurate up to 10ms, averaging at 5ms. The\ncontributions of the proposed work is two fold, i) a well streamlined and\nefficient method for generating datasets for any instrument, especially\nmonophonic and, ii) an acoustic plectrum guitar dataset containing wave files\nand transcriptions in the form of label files. This method will aid as a\npreliminary step towards building concrete datasets for building AMT systems\nfor different instruments.\n","subjects":["Electrical Engineering and Systems Science/Audio and Speech Processing","Computing Research Repository/Machine Learning","Computing Research Repository/Sound"],"license":"http://creativecommons.org/licenses/by/4.0/"}