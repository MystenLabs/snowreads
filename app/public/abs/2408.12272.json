{"id":"2408.12272","title":"Decorrelated forward regression for high dimensional data analysis","authors":"Xuejun Jiang, Yue Ma and Haofeng Wang","authorsParsed":[["Jiang","Xuejun",""],["Ma","Yue",""],["Wang","Haofeng",""]],"versions":[{"version":"v1","created":"Thu, 22 Aug 2024 10:12:24 GMT"}],"updateDate":"2024-08-23","timestamp":1724321544000,"abstract":"  Forward regression is a crucial methodology for automatically identifying\nimportant predictors from a large pool of potential covariates. In contexts\nwith moderate predictor correlation, forward selection techniques can achieve\nscreening consistency. However, this property gradually becomes invalid in the\npresence of substantially correlated variables, especially in high-dimensional\ndatasets where strong correlations exist among predictors. This dilemma is\nencountered by other model selection methods in literature as well. To address\nthese challenges, we introduce a novel decorrelated forward (DF) selection\nframework for generalized mean regression models, including prevalent models,\nsuch as linear, logistic, Poisson, and quasi likelihood. The DF selection\nframework stands out because of its ability to convert generalized mean\nregression models into linear ones, thus providing a clear interpretation of\nthe forward selection process. It also offers a closed-form expression for\nforward iteration, to improve practical applicability and efficiency.\nTheoretically, we establish the screening consistency of DF selection and\ndetermine the upper bound of the selected submodel's size. To reduce\ncomputational burden, we develop a thresholding DF algorithm that provides a\nstopping rule for the forward-searching process. Simulations and two real data\napplications show the outstanding performance of our method compared with some\nexisting model selection methods.\n","subjects":["Statistics/Methodology"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}