{"id":"2408.09484","title":"Fredholm Neural Networks","authors":"Kyriakos Georgiou, Constantinos Siettos, Athanasios N. Yannacopoulos","authorsParsed":[["Georgiou","Kyriakos",""],["Siettos","Constantinos",""],["Yannacopoulos","Athanasios N.",""]],"versions":[{"version":"v1","created":"Sun, 18 Aug 2024 13:59:22 GMT"},{"version":"v2","created":"Tue, 20 Aug 2024 07:06:16 GMT"}],"updateDate":"2024-08-21","timestamp":1723989562000,"abstract":"  Within the family of explainable machine-learning, we present Fredholm neural\nnetworks (Fredholm NNs), deep neural networks (DNNs) which replicate fixed\npoint iterations for the solution of linear and nonlinear Fredholm Integral\nEquations (FIE) of the second kind. Applications of FIEs include the solution\nof ordinary, as well as partial differential equations (ODEs, PDEs) and many\nmore. We first prove that Fredholm NNs provide accurate solutions. We then\nprovide insight into the values of the hyperparameters and\ntrainable/explainable weights and biases of the DNN, by directly connecting\ntheir values to the underlying mathematical theory. For our illustrations, we\nuse Fredholm NNs to solve both linear and nonlinear problems, including\nelliptic PDEs and boundary value problems. We show that the proposed scheme\nachieves significant numerical approximation accuracy across both the domain\nand boundary. The proposed methodology provides insight into the connection\nbetween neural networks and classical numerical methods, and we posit that it\ncan have applications in fields such as Uncertainty Quantification (UQ) and\nexplainable artificial intelligence (XAI). Thus, we believe that it will\ntrigger further advances in the intersection between scientific machine\nlearning and numerical analysis.\n","subjects":["Mathematics/Numerical Analysis","Computing Research Repository/Numerical Analysis","Mathematics/Dynamical Systems"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}