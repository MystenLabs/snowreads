{"id":"2408.09594","title":"Moonshine: Distilling Game Content Generators into Steerable Generative\n  Models","authors":"Yuhe Nie, Michael Middleton, Tim Merino, Nidhushan Kanagaraja,\n  Ashutosh Kumar, Zhan Zhuang, Julian Togelius","authorsParsed":[["Nie","Yuhe",""],["Middleton","Michael",""],["Merino","Tim",""],["Kanagaraja","Nidhushan",""],["Kumar","Ashutosh",""],["Zhuang","Zhan",""],["Togelius","Julian",""]],"versions":[{"version":"v1","created":"Sun, 18 Aug 2024 20:59:59 GMT"}],"updateDate":"2024-08-20","timestamp":1724014799000,"abstract":"  Procedural Content Generation via Machine Learning (PCGML) has enhanced game\ncontent creation, yet challenges in controllability and limited training data\npersist. This study addresses these issues by distilling a constructive PCG\nalgorithm into a controllable PCGML model. We first generate a large amount of\ncontent with a constructive algorithm and label it using a Large Language Model\n(LLM). We use these synthetic labels to condition two PCGML models for\ncontent-specific generation, a diffusion model and the five-dollar model. This\nneural network distillation process ensures that the generation aligns with the\noriginal algorithm while introducing controllability through plain text. We\ndefine this text-conditioned PCGML as a Text-to-game-Map (T2M) task, offering\nan alternative to prevalent text-to-image multi-modal tasks. We compare our\ndistilled models with the baseline constructive algorithm. Our analysis of the\nvariety, accuracy, and quality of our generation demonstrates the efficacy of\ndistilling constructive methods into controllable text-conditioned PCGML\nmodels.\n","subjects":["Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/"}