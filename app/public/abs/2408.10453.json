{"id":"2408.10453","title":"Kubrick: Multimodal Agent Collaborations for Synthetic Video Generation","authors":"Liu He, Yizhi Song, Hejun Huang, Daniel Aliaga, Xin Zhou","authorsParsed":[["He","Liu",""],["Song","Yizhi",""],["Huang","Hejun",""],["Aliaga","Daniel",""],["Zhou","Xin",""]],"versions":[{"version":"v1","created":"Mon, 19 Aug 2024 23:31:02 GMT"}],"updateDate":"2024-08-21","timestamp":1724110262000,"abstract":"  Text-to-video generation has been dominated by end-to-end diffusion-based or\nautoregressive models. On one hand, those novel models provide plausible\nversatility, but they are criticized for physical correctness, shading and\nillumination, camera motion, and temporal consistency. On the other hand, film\nindustry relies on manually-edited Computer-Generated Imagery (CGI) using 3D\nmodeling software. Human-directed 3D synthetic videos and animations address\nthe aforementioned shortcomings, but it is extremely tedious and requires tight\ncollaboration between movie makers and 3D rendering experts. In this paper, we\nintroduce an automatic synthetic video generation pipeline based on Vision\nLarge Language Model (VLM) agent collaborations. Given a natural language\ndescription of a video, multiple VLM agents auto-direct various processes of\nthe generation pipeline. They cooperate to create Blender scripts which render\na video that best aligns with the given description. Based on film making\ninspiration and augmented with Blender-based movie making knowledge, the\nDirector agent decomposes the input text-based video description into\nsub-processes. For each sub-process, the Programmer agent produces Python-based\nBlender scripts based on customized function composing and API calling. Then,\nthe Reviewer agent, augmented with knowledge of video reviewing, character\nmotion coordinates, and intermediate screenshots uses its compositional\nreasoning ability to provide feedback to the Programmer agent. The Programmer\nagent iteratively improves the scripts to yield the best overall video outcome.\nOur generated videos show better quality than commercial video generation\nmodels in 5 metrics on video quality and instruction-following performance.\nMoreover, our framework outperforms other approaches in a comprehensive user\nstudy on quality, consistency, and rationality.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Graphics","Computing Research Repository/Multimedia"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}