{"id":"2407.09360","title":"Novel clustered federated learning based on local loss","authors":"Endong Gu, Yongxin Chen, Hao Wen, Xingju Cai, Deren Han","authorsParsed":[["Gu","Endong",""],["Chen","Yongxin",""],["Wen","Hao",""],["Cai","Xingju",""],["Han","Deren",""]],"versions":[{"version":"v1","created":"Fri, 12 Jul 2024 15:37:05 GMT"}],"updateDate":"2024-07-15","timestamp":1720798625000,"abstract":"  This paper proposes LCFL, a novel clustering metric for evaluating clients'\ndata distributions in federated learning. LCFL aligns with federated learning\nrequirements, accurately assessing client-to-client variations in data\ndistribution. It offers advantages over existing clustered federated learning\nmethods, addressing privacy concerns, improving applicability to non-convex\nmodels, and providing more accurate classification results. LCFL does not\nrequire prior knowledge of clients' data distributions. We provide a rigorous\nmathematical analysis, demonstrating the correctness and feasibility of our\nframework. Numerical experiments with neural network instances highlight the\nsuperior performance of LCFL over baselines on several clustered federated\nlearning benchmarks.\n","subjects":["Computing Research Repository/Machine Learning","Mathematics/Optimization and Control"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}