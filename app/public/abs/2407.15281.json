{"id":"2407.15281","title":"SynCPKL: Harnessing LLMs to Generate Synthetic Data for Commonsense\n  Persona Knowledge Linking","authors":"Kuan-Yen Lin","authorsParsed":[["Lin","Kuan-Yen",""]],"versions":[{"version":"v1","created":"Sun, 21 Jul 2024 22:07:14 GMT"}],"updateDate":"2024-07-23","timestamp":1721599634000,"abstract":"  Understanding rich dialogues often requires NLP systems to access relevant\ncommonsense persona knowledge, but retrieving this knowledge is challenging due\nto complex contexts and the implicit nature of commonsense. This paper presents\nour approach to the Commonsense Persona Knowledge Linking (CPKL) challenge,\naddressing the critical need for integrating persona and commonsense knowledge\nin open-domain dialogue systems. We introduce SynCPKL Pipeline, a pipeline that\nleverages Large Language Models to generate high-quality synthetic datasets for\ntraining commonsense persona knowledge linkers. To demonstrate the efficacy of\nour approach, we present SynCPKL, a new dataset specifically designed for this\ntask. Our experiments validate the effectiveness of SynCPKL for training\ncommonsense persona knowledge linkers. Additionally, our top-performing model,\nDerberta-SynCPKL, secured first place in the CPKL challenge by a 16%\nimprovement in F1 score. We released both SynCPKL and Derberta-SynCPKL at\nhttps://github.com/irislin1006/CPKL.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"oo7H-TngPuwXd0SZFmjn981Q0Aaz0cdLSxwTMCI_tZQ","pdfSize":"223005"}
