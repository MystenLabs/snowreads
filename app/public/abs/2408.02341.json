{"id":"2408.02341","title":"An approach to optimize inference of the DIART speaker diarization\n  pipeline","authors":"Roman Aperdannier, Sigurd Schacht, Alexander Piazza","authorsParsed":[["Aperdannier","Roman",""],["Schacht","Sigurd",""],["Piazza","Alexander",""]],"versions":[{"version":"v1","created":"Mon, 5 Aug 2024 09:38:07 GMT"}],"updateDate":"2024-08-06","timestamp":1722850687000,"abstract":"  Speaker diarization answers the question \"who spoke when\" for an audio file.\nIn some diarization scenarios, low latency is required for transcription.\nSpeaker diarization with low latency is referred to as online speaker\ndiarization. The DIART pipeline is an online speaker diarization system. It\nconsists of a segmentation and an embedding model. The embedding model has the\nlargest share of the overall latency. The aim of this paper is to optimize the\ninference latency of the DIART pipeline. Different inference optimization\nmethods such as knowledge distilation, pruning, quantization and layer fusion\nare applied to the embedding model of the pipeline. It turns out that knowledge\ndistillation optimizes the latency, but has a negative effect on the accuracy.\nQuantization and layer fusion also have a positive influence on the latency\nwithout worsening the accuracy. Pruning, on the other hand, does not improve\nlatency.\n","subjects":["Computing Research Repository/Sound","Computing Research Repository/Computation and Language","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by-sa/4.0/","blobId":"UZEyJNn0g8VNh3liiDSnnLtqayAtkR21AXyBn4joErc","pdfSize":"299740"}
