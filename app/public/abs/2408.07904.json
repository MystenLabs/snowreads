{"id":"2408.07904","title":"Assessing Language Models' Worldview for Fiction Generation","authors":"Aisha Khatun and Daniel G. Brown","authorsParsed":[["Khatun","Aisha",""],["Brown","Daniel G.",""]],"versions":[{"version":"v1","created":"Thu, 15 Aug 2024 03:19:41 GMT"}],"updateDate":"2024-08-16","timestamp":1723691981000,"abstract":"  The use of Large Language Models (LLMs) has become ubiquitous, with abundant\napplications in computational creativity. One such application is fictional\nstory generation. Fiction is a narrative that occurs in a story world that is\nslightly different than ours. With LLMs becoming writing partners, we question\nhow suitable they are to generate fiction. This study investigates the ability\nof LLMs to maintain a state of world essential to generate fiction. Through a\nseries of questions to nine LLMs, we find that only two models exhibit\nconsistent worldview, while the rest are self-conflicting. Subsequent analysis\nof stories generated by four models revealed a strikingly uniform narrative\npattern. This uniformity across models further suggests a lack of `state'\nnecessary for fiction. We highlight the limitations of current LLMs in fiction\nwriting and advocate for future research to test and create story worlds for\nLLMs to reside in. All code, dataset, and the generated responses can be found\nin https://github.com/tanny411/llm-reliability-and-consistency-evaluation.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"VbmdgRU0EnY7lC_kwab2hg_5wNSNPfRaat68DQCH8ls","pdfSize":"143205"}
