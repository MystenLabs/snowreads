{"id":"2407.00051","title":"SAGIPS: A Scalable Asynchronous Generative Inverse Problem Solver","authors":"Daniel Lersch, Malachi Schram, Zhenyu Dai, Kishansingh Rajput, Xingfu\n  Wu, N. Sato, J. Taylor Childers","authorsParsed":[["Lersch","Daniel",""],["Schram","Malachi",""],["Dai","Zhenyu",""],["Rajput","Kishansingh",""],["Wu","Xingfu",""],["Sato","N.",""],["Childers","J. Taylor",""]],"versions":[{"version":"v1","created":"Tue, 11 Jun 2024 17:57:49 GMT"}],"updateDate":"2024-07-02","timestamp":1718128669000,"abstract":"  Large scale, inverse problem solving deep learning algorithms have become an\nessential part of modern research and industrial applications. The complexity\nof the underlying inverse problem often poses challenges to the algorithm and\nrequires the proper utilization of high-performance computing systems. Most\ndeep learning algorithms require, due to their design, custom parallelization\ntechniques in order to be resource efficient while showing a reasonable\nconvergence. In this paper we introduces a \\underline{S}calable\n\\underline{A}synchronous \\underline{G}enerative workflow for solving\n\\underline{I}nverse \\underline{P}roblems \\underline{S}olver (SAGIPS) on\nhigh-performance computing systems. We present a workflow that utilizes a\nparallelization approach where the gradients of the generator network are\nupdated in an asynchronous ring-all-reduce fashion. Experiments with a\nscientific proxy application demonstrate that SAGIPS shows near linear weak\nscaling, together with a convergence quality that is comparable to traditional\nmethods. The approach presented here allows leveraging GANs across multiple\nGPUs, promising advancements in solving complex inverse problems at scale.\n","subjects":["Computing Research Repository/Distributed, Parallel, and Cluster Computing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}