{"id":"2407.17847","title":"Move and Act: Enhanced Object Manipulation and Background Integrity for\n  Image Editing","authors":"Pengfei Jiang, Mingbao Lin, Fei Chao, Rongrong Ji","authorsParsed":[["Jiang","Pengfei",""],["Lin","Mingbao",""],["Chao","Fei",""],["Ji","Rongrong",""]],"versions":[{"version":"v1","created":"Thu, 25 Jul 2024 08:00:49 GMT"}],"updateDate":"2024-07-26","timestamp":1721894449000,"abstract":"  Current methods commonly utilize three-branch structures of inversion,\nreconstruction, and editing, to tackle consistent image editing task. However,\nthese methods lack control over the generation position of the edited object\nand have issues with background preservation. To overcome these limitations, we\npropose a tuning-free method with only two branches: inversion and editing.\nThis approach allows users to simultaneously edit the object's action and\ncontrol the generation position of the edited object. Additionally, it achieves\nimproved background preservation. Specifically, we transfer the edited object\ninformation to the target area and repair or preserve the background of other\nareas during the inversion process at a specific time step. In the editing\nstage, we use the image features in self-attention to query the key and value\nof the corresponding time step in the inversion to achieve consistent image\nediting. Impressive image editing results and quantitative evaluation\ndemonstrate the effectiveness of our method. The code is available at\nhttps://github.com/mobiushy/move-act.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}