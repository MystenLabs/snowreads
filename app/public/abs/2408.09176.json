{"id":"2408.09176","title":"Cognitive LLMs: Towards Integrating Cognitive Architectures and Large\n  Language Models for Manufacturing Decision-making","authors":"Siyu Wu, Alessandro Oltramari, Jonathan Francis, C. Lee Giles, Frank\n  E. Ritter","authorsParsed":[["Wu","Siyu",""],["Oltramari","Alessandro",""],["Francis","Jonathan",""],["Giles","C. Lee",""],["Ritter","Frank E.",""]],"versions":[{"version":"v1","created":"Sat, 17 Aug 2024 11:49:53 GMT"}],"updateDate":"2024-08-20","timestamp":1723895393000,"abstract":"  Resolving the dichotomy between the human-like yet constrained reasoning\nprocesses of Cognitive Architectures and the broad but often noisy inference\nbehavior of Large Language Models (LLMs) remains a challenging but exciting\npursuit, for enabling reliable machine reasoning capabilities in production\nsystems. Because Cognitive Architectures are famously developed for the purpose\nof modeling the internal mechanisms of human cognitive decision-making at a\ncomputational level, new investigations consider the goal of informing LLMs\nwith the knowledge necessary for replicating such processes, e.g., guided\nperception, memory, goal-setting, and action. Previous approaches that use LLMs\nfor grounded decision-making struggle with complex reasoning tasks that require\nslower, deliberate cognition over fast and intuitive inference -- reporting\nissues related to the lack of sufficient grounding, as in hallucination. To\nresolve these challenges, we introduce LLM-ACTR, a novel neuro-symbolic\narchitecture that provides human-aligned and versatile decision-making by\nintegrating the ACT-R Cognitive Architecture with LLMs. Our framework extracts\nand embeds knowledge of ACT-R's internal decision-making process as latent\nneural representations, injects this information into trainable LLM adapter\nlayers, and fine-tunes the LLMs for downstream prediction. Our experiments on\nnovel Design for Manufacturing tasks show both improved task performance as\nwell as improved grounded decision-making capability of our approach, compared\nto LLM-only baselines that leverage chain-of-thought reasoning strategies.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language","Computing Research Repository/Symbolic Computation"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}