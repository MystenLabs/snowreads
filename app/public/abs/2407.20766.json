{"id":"2407.20766","title":"Highly Efficient No-reference 4K Video Quality Assessment with\n  Full-Pixel Covering Sampling and Training Strategy","authors":"Xiaoheng Tan, Jiabin Zhang, Yuhui Quan, Jing Li, Yajing Wu, Zilin Bian","authorsParsed":[["Tan","Xiaoheng",""],["Zhang","Jiabin",""],["Quan","Yuhui",""],["Li","Jing",""],["Wu","Yajing",""],["Bian","Zilin",""]],"versions":[{"version":"v1","created":"Tue, 30 Jul 2024 12:10:33 GMT"}],"updateDate":"2024-07-31","timestamp":1722341433000,"abstract":"  Deep Video Quality Assessment (VQA) methods have shown impressive\nhigh-performance capabilities. Notably, no-reference (NR) VQA methods play a\nvital role in situations where obtaining reference videos is restricted or not\nfeasible. Nevertheless, as more streaming videos are being created in\nultra-high definition (e.g., 4K) to enrich viewers' experiences, the current\ndeep VQA methods face unacceptable computational costs. Furthermore, the\nresizing, cropping, and local sampling techniques employed in these methods can\ncompromise the details and content of original 4K videos, thereby negatively\nimpacting quality assessment. In this paper, we propose a highly efficient and\nnovel NR 4K VQA technology. Specifically, first, a novel data sampling and\ntraining strategy is proposed to tackle the problem of excessive resolution.\nThis strategy allows the VQA Swin Transformer-based model to effectively train\nand make inferences using the full data of 4K videos on standard consumer-grade\nGPUs without compromising content or details. Second, a weighting and scoring\nscheme is developed to mimic the human subjective perception mode, which is\nachieved by considering the distinct impact of each sub-region within a 4K\nframe on the overall perception. Third, we incorporate the frequency domain\ninformation of video frames to better capture the details that affect video\nquality, consequently further improving the model's generalizability. To our\nknowledge, this is the first technology for the NR 4K VQA task. Thorough\nempirical studies demonstrate it not only significantly outperforms existing\nmethods on a specialized 4K VQA dataset but also achieves state-of-the-art\nperformance across multiple open-source NR video quality datasets.\n","subjects":["Electrical Engineering and Systems Science/Image and Video Processing","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-sa/4.0/","blobId":"Dm9QKermeanB81YrQm8iK3fGEoVdB2Jmdi0UQoS-cfI","pdfSize":"40958597","objectId":"0xc4f3e538ecfaf02f9f07d15348248096212acdfad4e1cf76a8c3ffc35e06294d","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
