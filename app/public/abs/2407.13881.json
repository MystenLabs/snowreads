{"id":"2407.13881","title":"Privacy-preserving gradient-based fair federated learning","authors":"Janis Adamek, and Moritz Schulze Darup","authorsParsed":[["Adamek","Janis",""],["Darup","Moritz Schulze",""]],"versions":[{"version":"v1","created":"Thu, 18 Jul 2024 19:56:39 GMT"}],"updateDate":"2024-07-22","timestamp":1721332599000,"abstract":"  Federated learning (FL) schemes allow multiple participants to\ncollaboratively train neural networks without the need to directly share the\nunderlying data.However, in early schemes, all participants eventually obtain\nthe same model. Moreover, the aggregation is typically carried out by a third\nparty, who obtains combined gradients or weights, which may reveal the model.\nThese downsides underscore the demand for fair and privacy-preserving FL\nschemes. Here, collaborative fairness asks for individual model quality\ndepending on the individual data contribution. Privacy is demanded with respect\nto any kind of data outsourced to the third party. Now, there already exist\nsome approaches aiming for either fair or privacy-preserving FL and a few works\neven address both features. In our paper, we build upon these seminal works and\npresent a novel, fair and privacy-preserving FL scheme. Our approach, which\nmainly relies on homomorphic encryption, stands out for exclusively using local\ngradients. This increases the usability in comparison to state-of-the-art\napproaches and thereby opens the door to applications in control.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Cryptography and Security","Computing Research Repository/Systems and Control","Electrical Engineering and Systems Science/Systems and Control"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"yjVlb4vdb7fvFV9Zmy5uCfq5fMgvoYIX_Tb_vAQwoc4","pdfSize":"462525"}
