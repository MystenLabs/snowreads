{"id":"2408.11858","title":"Convexity-based Pruning of Speech Representation Models","authors":"Teresa Dorszewski, Lenka T\\v{e}tkov\\'a, Lars Kai Hansen","authorsParsed":[["Dorszewski","Teresa",""],["Tětková","Lenka",""],["Hansen","Lars Kai",""]],"versions":[{"version":"v1","created":"Fri, 16 Aug 2024 09:04:54 GMT"}],"updateDate":"2024-08-23","timestamp":1723799094000,"abstract":"  Speech representation models based on the transformer architecture and\ntrained by self-supervised learning have shown great promise for solving tasks\nsuch as speech and speaker recognition, keyword spotting, emotion detection,\nand more. Typically, it is found that larger models lead to better performance.\nHowever, the significant computational effort involved in such large\ntransformer systems is a challenge for embedded and real-world applications.\nRecent work has shown that there is significant redundancy in the transformer\nmodels for NLP and massive layer pruning is feasible (Sajjad et al., 2023).\nHere, we investigate layer pruning in audio models. We base the pruning\ndecision on a convexity criterion. Convexity of classification regions has\nrecently been proposed as an indicator of subsequent fine-tuning performance in\na range of application domains, including NLP and audio. In empirical\ninvestigations, we find a massive reduction in the computational effort with no\nloss of performance or even improvements in certain cases.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Sound","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"Q5cqZE_fe0ucSi6EcMsm6h4AhjDDRdh82w8DLNwcUts","pdfSize":"1072489"}
