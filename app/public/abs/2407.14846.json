{"id":"2407.14846","title":"Realistic Surgical Image Dataset Generation Based On 3D Gaussian\n  Splatting","authors":"Tianle Zeng, Gerardo Loza Galindo, Junlei Hu, Pietro Valdastri,\n  Dominic Jones","authorsParsed":[["Zeng","Tianle",""],["Galindo","Gerardo Loza",""],["Hu","Junlei",""],["Valdastri","Pietro",""],["Jones","Dominic",""]],"versions":[{"version":"v1","created":"Sat, 20 Jul 2024 11:20:07 GMT"}],"updateDate":"2024-07-29","timestamp":1721474407000,"abstract":"  Computer vision technologies markedly enhance the automation capabilities of\nrobotic-assisted minimally invasive surgery (RAMIS) through advanced tool\ntracking, detection, and localization. However, the limited availability of\ncomprehensive surgical datasets for training represents a significant challenge\nin this field. This research introduces a novel method that employs 3D Gaussian\nSplatting to generate synthetic surgical datasets. We propose a method for\nextracting and combining 3D Gaussian representations of surgical instruments\nand background operating environments, transforming and combining them to\ngenerate high-fidelity synthetic surgical scenarios. We developed a data\nrecording system capable of acquiring images alongside tool and camera poses in\na surgical scene. Using this pose data, we synthetically replicate the scene,\nthereby enabling direct comparisons of the synthetic image quality (29.592\nPSNR). As a further validation, we compared two YOLOv5 models trained on the\nsynthetic and real data, respectively, and assessed their performance in an\nunseen real-world test dataset. Comparing the performances, we observe an\nimprovement in neural network performance, with the synthetic-trained model\noutperforming the real-world trained model by 12%, testing both on real-world\ndata.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}