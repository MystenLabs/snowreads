{"id":"2407.12773","title":"OMG-Net: A Deep Learning Framework Deploying Segment Anything to Detect\n  Pan-Cancer Mitotic Figures from Haematoxylin and Eosin-Stained Slides","authors":"Zhuoyan Shen, Mikael Simard, Douglas Brand, Vanghelita Andrei, Ali\n  Al-Khader, Fatine Oumlil, Katherine Trevers, Thomas Butters, Simon Haefliger,\n  Eleanna Kara, Fernanda Amary, Roberto Tirabosco, Paul Cool, Gary Royle, Maria\n  A. Hawkins, Adrienne M. Flanagan, Charles-Antoine Collins Fekete","authorsParsed":[["Shen","Zhuoyan",""],["Simard","Mikael",""],["Brand","Douglas",""],["Andrei","Vanghelita",""],["Al-Khader","Ali",""],["Oumlil","Fatine",""],["Trevers","Katherine",""],["Butters","Thomas",""],["Haefliger","Simon",""],["Kara","Eleanna",""],["Amary","Fernanda",""],["Tirabosco","Roberto",""],["Cool","Paul",""],["Royle","Gary",""],["Hawkins","Maria A.",""],["Flanagan","Adrienne M.",""],["Fekete","Charles-Antoine Collins",""]],"versions":[{"version":"v1","created":"Wed, 17 Jul 2024 17:53:37 GMT"}],"updateDate":"2024-07-18","timestamp":1721238817000,"abstract":"  Mitotic activity is an important feature for grading several cancer types.\nCounting mitotic figures (MFs) is a time-consuming, laborious task prone to\ninter-observer variation. Inaccurate recognition of MFs can lead to incorrect\ngrading and hence potential suboptimal treatment. In this study, we propose an\nartificial intelligence (AI)-aided approach to detect MFs in digitised\nhaematoxylin and eosin-stained whole slide images (WSIs). Advances in this area\nare hampered by the limited number and types of cancer datasets of MFs. Here we\nestablish the largest pan-cancer dataset of mitotic figures by combining an\nin-house dataset of soft tissue tumours (STMF) with five open-source mitotic\ndatasets comprising multiple human cancers and canine specimens (ICPR, TUPAC,\nCCMCT, CMC and MIDOG++). This new dataset identifies 74,620 MFs and 105,538\nmitotic-like figures. We then employed a two-stage framework (the Optimised\nMitoses Generator Network (OMG-Net) to classify MFs. The framework first\ndeploys the Segment Anything Model (SAM) to automate the contouring of MFs and\nsurrounding objects. An adapted ResNet18 is subsequently trained to classify\nMFs. OMG-Net reaches an F1-score of 0.84 on pan-cancer MF detection (breast\ncarcinoma, neuroendocrine tumour and melanoma), largely outperforming the\nprevious state-of-the-art MIDOG++ benchmark model on its hold-out testing set\n(e.g. +16% F1-score on breast cancer detection, p<0.001) thereby providing\nsuperior accuracy in detecting MFs on various types of tumours obtained with\ndifferent scanners.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"SAYZ6XfH_S4R2MopltKEzFfczdc9Lyg4uiLX4vXtLuM","pdfSize":"16172902","objectId":"0x6dc8378b3ee37a248c27137da0f894695935d799ddd146252e56ec4049c2adf9","registeredEpoch":"3","certifiedEpoch":"3","startEpoch":"3","endEpoch":"203"}
