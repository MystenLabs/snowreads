{"id":"2407.04384","title":"Unsupervised Learning of Category-Level 3D Pose from Object-Centric\n  Videos","authors":"Leonhard Sommer, Artur Jesslen, Eddy Ilg, Adam Kortylewski","authorsParsed":[["Sommer","Leonhard",""],["Jesslen","Artur",""],["Ilg","Eddy",""],["Kortylewski","Adam",""]],"versions":[{"version":"v1","created":"Fri, 5 Jul 2024 09:43:05 GMT"}],"updateDate":"2024-07-08","timestamp":1720172585000,"abstract":"  Category-level 3D pose estimation is a fundamentally important problem in\ncomputer vision and robotics, e.g. for embodied agents or to train 3D\ngenerative models. However, so far methods that estimate the category-level\nobject pose require either large amounts of human annotations, CAD models or\ninput from RGB-D sensors. In contrast, we tackle the problem of learning to\nestimate the category-level 3D pose only from casually taken object-centric\nvideos without human supervision. We propose a two-step pipeline: First, we\nintroduce a multi-view alignment procedure that determines canonical camera\nposes across videos with a novel and robust cyclic distance formulation for\ngeometric and appearance matching using reconstructed coarse meshes and DINOv2\nfeatures. In a second step, the canonical poses and reconstructed meshes enable\nus to train a model for 3D pose estimation from a single image. In particular,\nour model learns to estimate dense correspondences between images and a\nprototypical 3D template by predicting, for each pixel in a 2D image, a feature\nvector of the corresponding vertex in the template mesh. We demonstrate that\nour method outperforms all baselines at the unsupervised alignment of\nobject-centric videos by a large margin and provides faithful and robust\npredictions in-the-wild. Our code and data is available at\nhttps://github.com/GenIntel/uns-obj-pose3d.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}