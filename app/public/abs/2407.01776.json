{"id":"2407.01776","title":"Federated Binary Matrix Factorization using Proximal Optimization","authors":"Sebastian Dalleiger, Jilles Vreeken, Michael Kamp","authorsParsed":[["Dalleiger","Sebastian",""],["Vreeken","Jilles",""],["Kamp","Michael",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 20:10:24 GMT"}],"updateDate":"2024-07-03","timestamp":1719864624000,"abstract":"  Identifying informative components in binary data is an essential task in\nmany research areas, including life sciences, social sciences, and\nrecommendation systems. Boolean matrix factorization (BMF) is a family of\nmethods that performs this task by efficiently factorizing the data. In\nreal-world settings, the data is often distributed across stakeholders and\nrequired to stay private, prohibiting the straightforward application of BMF.\nTo adapt BMF to this context, we approach the problem from a federated-learning\nperspective, while building on a state-of-the-art continuous binary matrix\nfactorization relaxation to BMF that enables efficient gradient-based\noptimization. We propose to only share the relaxed component matrices, which\nare aggregated centrally using a proximal operator that regularizes for binary\noutcomes. We show the convergence of our federated proximal gradient descent\nalgorithm and provide differential privacy guarantees. Our extensive empirical\nevaluation demonstrates that our algorithm outperforms, in terms of quality and\nefficacy, federation schemes of state-of-the-art BMF methods on a diverse set\nof real-world and synthetic data.\n","subjects":["Computing Research Repository/Machine Learning","Statistics/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}