{"id":"2407.21459","title":"KemenkeuGPT: Leveraging a Large Language Model on Indonesia's Government\n  Financial Data and Regulations to Enhance Decision Making","authors":"Gilang Fajar Febrian, Grazziela Figueredo","authorsParsed":[["Febrian","Gilang Fajar",""],["Figueredo","Grazziela",""]],"versions":[{"version":"v1","created":"Wed, 31 Jul 2024 09:16:33 GMT"}],"updateDate":"2024-08-01","timestamp":1722417393000,"abstract":"  Data is crucial for evidence-based policymaking and enhancing public\nservices, including those at the Ministry of Finance of the Republic of\nIndonesia. However, the complexity and dynamic nature of governmental financial\ndata and regulations can hinder decision-making. This study investigates the\npotential of Large Language Models (LLMs) to address these challenges, focusing\non Indonesia's financial data and regulations. While LLMs are effective in the\nfinancial sector, their use in the public sector in Indonesia is unexplored.\nThis study undertakes an iterative process to develop KemenkeuGPT using the\nLangChain with Retrieval-Augmented Generation (RAG), prompt engineering and\nfine-tuning. The dataset from 2003 to 2023 was collected from the Ministry of\nFinance, Statistics Indonesia and the International Monetary Fund (IMF).\nSurveys and interviews with Ministry officials informed, enhanced and\nfine-tuned the model. We evaluated the model using human feedback, LLM-based\nevaluation and benchmarking. The model's accuracy improved from 35% to 61%,\nwith correctness increasing from 48% to 64%. The Retrieval-Augmented Generation\nAssessment (RAGAS) framework showed that KemenkeuGPT achieved 44% correctness\nwith 73% faithfulness, 40% precision and 60% recall, outperforming several\nother base models. An interview with an expert from the Ministry of Finance\nindicated that KemenkeuGPT has the potential to become an essential tool for\ndecision-making. These results are expected to improve with continuous human\nfeedback.\n","subjects":["Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}