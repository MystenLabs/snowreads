{"id":"2408.01565","title":"Embodiment: Self-Supervised Depth Estimation Based on Camera Models","authors":"Jinchang Zhang, Praveen Kumar Reddy, Xue-Iuan Wong, Yiannis Aloimonos,\n  Guoyu Lu","authorsParsed":[["Zhang","Jinchang",""],["Reddy","Praveen Kumar",""],["Wong","Xue-Iuan",""],["Aloimonos","Yiannis",""],["Lu","Guoyu",""]],"versions":[{"version":"v1","created":"Fri, 2 Aug 2024 20:40:19 GMT"},{"version":"v2","created":"Thu, 29 Aug 2024 01:32:17 GMT"}],"updateDate":"2024-08-30","timestamp":1722631219000,"abstract":"  Depth estimation is a critical topic for robotics and vision-related tasks.\nIn monocular depth estimation, in comparison with supervised learning that\nrequires expensive ground truth labeling, self-supervised methods possess great\npotential due to no labeling cost. However, self-supervised learning still has\na large gap with supervised learning in 3D reconstruction and depth estimation\nperformance. Meanwhile, scaling is also a major issue for monocular\nunsupervised depth estimation, which commonly still needs ground truth scale\nfrom GPS, LiDAR, or existing maps to correct. In the era of deep learning,\nexisting methods primarily rely on exploring image relationships to train\nunsupervised neural networks, while the physical properties of the camera\nitself such as intrinsics and extrinsics are often overlooked. These physical\nproperties are not just mathematical parameters; they are embodiments of the\ncamera's interaction with the physical world. By embedding these physical\nproperties into the deep learning model, we can calculate depth priors for\nground regions and regions connected to the ground based on physical\nprinciples, providing free supervision signals without the need for additional\nsensors. This approach is not only easy to implement but also enhances the\neffects of all unsupervised methods by embedding the camera's physical\nproperties into the model, thereby achieving an embodied understanding of the\nreal world.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}