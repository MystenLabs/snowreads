{"id":"2408.10905","title":"The impact of labeling automotive AI as \"trustworthy\" or \"reliable\" on\n  user evaluation and technology acceptance","authors":"John Dorsch and Ophelia Deroy","authorsParsed":[["Dorsch","John",""],["Deroy","Ophelia",""]],"versions":[{"version":"v1","created":"Tue, 20 Aug 2024 14:48:24 GMT"}],"updateDate":"2024-08-21","timestamp":1724165304000,"abstract":"  This study explores whether labeling AI as \"trustworthy\" or \"reliable\"\ninfluences user perceptions and acceptance of automotive AI technologies. Using\na one-way between-subjects design, the research involved 478 online\nparticipants who were presented with guidelines for either trustworthy or\nreliable AI. Participants then evaluated three vignette scenarios and completed\na modified version of the Technology Acceptance Model, which included variables\nsuch as perceived ease of use, human-like trust, and overall attitude. Although\nlabeling AI as \"trustworthy\" did not significantly influence judgments on\nspecific scenarios, it increased perceived ease of use and human-like trust,\nparticularly benevolence. This suggests a positive impact on usability and an\nanthropomorphic effect on user perceptions. The study provides insights into\nhow specific labels can influence attitudes toward AI technology.\n","subjects":["Computing Research Repository/Human-Computer Interaction","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Emerging Technologies"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"SwrRCSwWRg_hwD_DnkUbvYCYpT_3miWHXlnCxPlUhV0","pdfSize":"4222398"}
