{"id":"2407.09672","title":"Mixed-View Panorama Synthesis using Geospatially Guided Diffusion","authors":"Zhexiao Xiong, Xin Xing, Scott Workman, Subash Khanal, Nathan Jacobs","authorsParsed":[["Xiong","Zhexiao",""],["Xing","Xin",""],["Workman","Scott",""],["Khanal","Subash",""],["Jacobs","Nathan",""]],"versions":[{"version":"v1","created":"Fri, 12 Jul 2024 20:12:07 GMT"}],"updateDate":"2024-07-16","timestamp":1720815127000,"abstract":"  We introduce the task of mixed-view panorama synthesis, where the goal is to\nsynthesize a novel panorama given a small set of input panoramas and a\nsatellite image of the area. This contrasts with previous work which only uses\ninput panoramas (same-view synthesis), or an input satellite image (cross-view\nsynthesis). We argue that the mixed-view setting is the most natural to support\npanorama synthesis for arbitrary locations worldwide. A critical challenge is\nthat the spatial coverage of panoramas is uneven, with few panoramas available\nin many regions of the world. We introduce an approach that utilizes\ndiffusion-based modeling and an attention-based architecture for extracting\ninformation from all available input imagery. Experimental results demonstrate\nthe effectiveness of our proposed method. In particular, our model can handle\nscenarios when the available panoramas are sparse or far from the location of\nthe panorama we are attempting to synthesize.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}