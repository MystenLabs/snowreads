{"id":"2408.13154","title":"Interpretable breast cancer classification using CNNs on mammographic\n  images","authors":"Ann-Kristin Balve, Peter Hendrix","authorsParsed":[["Balve","Ann-Kristin",""],["Hendrix","Peter",""]],"versions":[{"version":"v1","created":"Fri, 23 Aug 2024 15:25:42 GMT"}],"updateDate":"2024-08-26","timestamp":1724426742000,"abstract":"  Deep learning models have achieved promising results in breast cancer\nclassification, yet their 'black-box' nature raises interpretability concerns.\nThis research addresses the crucial need to gain insights into the\ndecision-making process of convolutional neural networks (CNNs) for mammogram\nclassification, specifically focusing on the underlying reasons for the CNN's\npredictions of breast cancer. For CNNs trained on the Mammographic Image\nAnalysis Society (MIAS) dataset, we compared the post-hoc interpretability\ntechniques LIME, Grad-CAM, and Kernel SHAP in terms of explanatory depth and\ncomputational efficiency. The results of this analysis indicate that Grad-CAM,\nin particular, provides comprehensive insights into the behavior of the CNN,\nrevealing distinctive patterns in normal, benign, and malignant breast tissue.\nWe discuss the implications of the current findings for the use of machine\nlearning models and interpretation techniques in clinical practice.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"9X1_D3FKGfceWltHUIyibRhtXSHMzTYsMtVc7JEwVT0","pdfSize":"5897502"}
