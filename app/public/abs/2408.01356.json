{"id":"2408.01356","title":"Balanced Residual Distillation Learning for 3D Point Cloud\n  Class-Incremental Semantic Segmentation","authors":"Yuanzhi Su, Siyuan Chen, Yuan-Gen Wang","authorsParsed":[["Su","Yuanzhi",""],["Chen","Siyuan",""],["Wang","Yuan-Gen",""]],"versions":[{"version":"v1","created":"Fri, 2 Aug 2024 16:09:06 GMT"}],"updateDate":"2024-08-05","timestamp":1722614946000,"abstract":"  Class-incremental learning (CIL) thrives due to its success in processing the\ninflux of information by learning from continuously added new classes while\npreventing catastrophic forgetting about the old ones. It is essential for the\nperformance breakthrough of CIL to effectively refine past knowledge from the\nbase model and balance it with new learning. However, such an issue has not yet\nbeen considered in current research. In this work, we explore the potential of\nCIL from these perspectives and propose a novel balanced residual distillation\nframework (BRD-CIL) to push the performance bar of CIL to a new higher level.\nSpecifically, BRD-CIL designs a residual distillation learning strategy, which\ncan dynamically expand the network structure to capture the residuals between\nthe base and target models, effectively refining the past knowledge.\nFurthermore, BRD-CIL designs a balanced pseudo-label learning strategy by\ngenerating a guidance mask to reduce the preference for old classes, ensuring\nbalanced learning from new and old classes. We apply the proposed BRD-CIL to a\nchallenging 3D point cloud semantic segmentation task where the data are\nunordered and unstructured. Extensive experimental results demonstrate that\nBRD-CIL sets a new benchmark with an outstanding balance capability in\nclass-biased scenarios.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}