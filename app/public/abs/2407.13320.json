{"id":"2407.13320","title":"Deep Reinforcement Learning for Multi-Objective Optimization: Enhancing\n  Wind Turbine Energy Generation while Mitigating Noise Emissions","authors":"Mart\\'in de Frutos (1), Oscar A. Marino (1), David Huergo (1), Esteban\n  Ferrer (1 and 2) ((1) ETSIAE-UPM-School of Aeronautics, (2) Center for\n  Computational Simulation, Universidad Polit\\'ecnica de Madrid)","authorsParsed":[["de Frutos","Mart√≠n","","1 and 2"],["Marino","Oscar A.","","1 and 2"],["Huergo","David","","1 and 2"],["Ferrer","Esteban","","1 and 2"]],"versions":[{"version":"v1","created":"Thu, 18 Jul 2024 09:21:51 GMT"}],"updateDate":"2024-07-19","timestamp":1721294511000,"abstract":"  We develop a torque-pitch control framework using deep reinforcement learning\nfor wind turbines to optimize the generation of wind turbine energy while\nminimizing operational noise. We employ a double deep Q-learning, coupled to a\nblade element momentum solver, to enable precise control over wind turbine\nparameters. In addition to the blade element momentum, we use the wind turbine\nacoustic model of Brooks Pope and Marcolini. Through training with simple\nwinds, the agent learns optimal control policies that allow efficient control\nfor complex turbulent winds. Our experiments demonstrate that the reinforcement\nlearning is able to find optima at the Pareto front, when maximizing energy\nwhile minimizing noise. In addition, the adaptability of the reinforcement\nlearning agent to changing turbulent wind conditions, underscores its efficacy\nfor real-world applications. We validate the methodology using a SWT2.3-93 wind\nturbine with a rated power of 2.3 MW. We compare the reinforcement learning\ncontrol to classic controls to show that they are comparable when not taking\ninto account noise emissions. When including a maximum limit of 45 dB to the\nnoise produced (100 meters downwind of the turbine), the extracted yearly\nenergy decreases by 22%. The methodology is flexible and allows for easy tuning\nof the objectives and constraints through the reward definitions, resulting in\na flexible multi-objective optimization framework for wind turbine control.\nOverall, our findings highlight the potential of RL-based control strategies to\nimprove wind turbine efficiency while mitigating noise pollution, thus\nadvancing sustainable energy generation technologies\n","subjects":["Electrical Engineering and Systems Science/Systems and Control","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Systems and Control","Mathematics/Optimization and Control"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"p4vrjcb3B4Q-kW157162OlRI5rBvr5FQBXlwfmoe6XM","pdfSize":"1151570"}
