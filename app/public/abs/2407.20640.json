{"id":"2407.20640","title":"Improved Bounds for Pure Private Agnostic Learning: Item-Level and\n  User-Level Privacy","authors":"Bo Li, Wei Wang, Peng Ye","authorsParsed":[["Li","Bo",""],["Wang","Wei",""],["Ye","Peng",""]],"versions":[{"version":"v1","created":"Tue, 30 Jul 2024 08:35:26 GMT"}],"updateDate":"2024-07-31","timestamp":1722328526000,"abstract":"  Machine Learning has made remarkable progress in a wide range of fields. In\nmany scenarios, learning is performed on datasets involving sensitive\ninformation, in which privacy protection is essential for learning algorithms.\nIn this work, we study pure private learning in the agnostic model -- a\nframework reflecting the learning process in practice. We examine the number of\nusers required under item-level (where each user contributes one example) and\nuser-level (where each user contributes multiple examples) privacy and derive\nseveral improved upper bounds. For item-level privacy, our algorithm achieves a\nnear optimal bound for general concept classes. We extend this to the\nuser-level setting, rendering a tighter upper bound than the one proved by\nGhazi et al. (2023). Lastly, we consider the problem of learning thresholds\nunder user-level privacy and present an algorithm with a nearly tight user\ncomplexity.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}