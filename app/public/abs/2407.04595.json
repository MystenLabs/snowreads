{"id":"2407.04595","title":"Differentially Private Inductive Miner","authors":"Max Schulze, Yorck Zisgen, Moritz Kirschte, Esfandiar Mohammadi, Agnes\n  Koschmider","authorsParsed":[["Schulze","Max",""],["Zisgen","Yorck",""],["Kirschte","Moritz",""],["Mohammadi","Esfandiar",""],["Koschmider","Agnes",""]],"versions":[{"version":"v1","created":"Fri, 5 Jul 2024 15:42:46 GMT"}],"updateDate":"2024-07-08","timestamp":1720194166000,"abstract":"  Protecting personal data about individuals, such as event traces in process\nmining, is an inherently difficult task: an event trace leaks information about\nthe path in a process model that an individual has triggered. Yet, prior\nanonymization methods of event traces like k-anonymity or event log\nsanitization struggled to protect against such leakage, in particular against\nadversaries with sufficient background knowledge. In this work, we provide a\nmethod that tackles the challenge of summarizing sensitive event traces by\nlearning the underlying process tree in a privacy-preserving manner. We prove\nvia the so-called Differential Privacy (DP) property that from the resulting\nsummaries no useful inference can be drawn about any personal data in an event\ntrace. On the technical side, we introduce a differentially private\napproximation (DPIM) of the Inductive Miner. Experimentally, we compare our\nDPIM with the Inductive Miner on 8 real-world event traces by evaluating\nwell-known metrics: fitness, precision, simplicity, and generalization. The\nexperiments show that our DPIM not only protects personal data but also\ngenerates faithful process trees that exhibit little utility loss above the\nInductive Miner.\n","subjects":["Computing Research Repository/Cryptography and Security","Computing Research Repository/Databases"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}