{"id":"2408.04867","title":"An Evaluation of Standard Statistical Models and LLMs on Time Series\n  Forecasting","authors":"Rui Cao and Qiao Wang","authorsParsed":[["Cao","Rui",""],["Wang","Qiao",""]],"versions":[{"version":"v1","created":"Fri, 9 Aug 2024 05:13:03 GMT"}],"updateDate":"2024-08-12","timestamp":1723180383000,"abstract":"  This research examines the use of Large Language Models (LLMs) in predicting\ntime series, with a specific focus on the LLMTIME model. Despite the\nestablished effectiveness of LLMs in tasks such as text generation, language\ntranslation, and sentiment analysis, this study highlights the key challenges\nthat large language models encounter in the context of time series prediction.\nWe assess the performance of LLMTIME across multiple datasets and introduce\nclassical almost periodic functions as time series to gauge its effectiveness.\nThe empirical results indicate that while large language models can perform\nwell in zero-shot forecasting for certain datasets, their predictive accuracy\ndiminishes notably when confronted with diverse time series data and\ntraditional signals. The primary finding of this study is that the predictive\ncapacity of LLMTIME, similar to other LLMs, significantly deteriorates when\ndealing with time series data that contain both periodic and trend components,\nas well as when the signal comprises complex frequency components.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}