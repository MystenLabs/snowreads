{"id":"2407.19604","title":"SCART: Predicting STT-RAM Cache Retention Times Using Machine Learning","authors":"Dhruv Gajaria, Kyle Kuan, Tosiron Adegbija","authorsParsed":[["Gajaria","Dhruv",""],["Kuan","Kyle",""],["Adegbija","Tosiron",""]],"versions":[{"version":"v1","created":"Sun, 28 Jul 2024 22:34:20 GMT"}],"updateDate":"2024-07-30","timestamp":1722206060000,"abstract":"  Prior studies have shown that the retention time of the non-volatile\nspin-transfer torque RAM (STT-RAM) can be relaxed in order to reduce STT-RAM's\nwrite energy and latency. However, since different applications may require\ndifferent retention times, STT-RAM retention times must be critically explored\nto satisfy various applications' needs. This process can be challenging due to\nexploration overhead, and exacerbated by the fact that STT-RAM caches are\nemerging and are not readily available for design time exploration. This paper\nexplores using known and easily obtainable statistics (e.g., SRAM statistics)\nto predict the appropriate STT-RAM retention times, in order to minimize\nexploration overhead. We propose an STT-RAM Cache Retention Time (SCART) model,\nwhich utilizes machine learning to enable design time or runtime prediction of\nright-provisioned STT-RAM retention times for latency or energy optimization.\nExperimental results show that, on average, SCART can reduce the latency and\nenergy by 20.34% and 29.12%, respectively, compared to a homogeneous retention\ntime while reducing the exploration overheads by 52.58% compared to prior work.\n","subjects":["Computing Research Repository/Computers and Society","Computing Research Repository/Hardware Architecture"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}