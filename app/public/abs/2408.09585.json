{"id":"2408.09585","title":"On the Necessity of World Knowledge for Mitigating Missing Labels in\n  Extreme Classification","authors":"Jatin Prakash, Anirudh Buvanesh, Bishal Santra, Deepak Saini, Sachin\n  Yadav, Jian Jiao, Yashoteja Prabhu, Amit Sharma, Manik Varma","authorsParsed":[["Prakash","Jatin",""],["Buvanesh","Anirudh",""],["Santra","Bishal",""],["Saini","Deepak",""],["Yadav","Sachin",""],["Jiao","Jian",""],["Prabhu","Yashoteja",""],["Sharma","Amit",""],["Varma","Manik",""]],"versions":[{"version":"v1","created":"Sun, 18 Aug 2024 20:08:42 GMT"}],"updateDate":"2024-08-20","timestamp":1724011722000,"abstract":"  Extreme Classification (XC) aims to map a query to the most relevant\ndocuments from a very large document set. XC algorithms used in real-world\napplications learn this mapping from datasets curated from implicit feedback,\nsuch as user clicks. However, these datasets inevitably suffer from missing\nlabels. In this work, we observe that systematic missing labels lead to missing\nknowledge, which is critical for accurately modelling relevance between queries\nand documents. We formally show that this absence of knowledge cannot be\nrecovered using existing methods such as propensity weighting and data\nimputation strategies that solely rely on the training dataset. While LLMs\nprovide an attractive solution to augment the missing knowledge, leveraging\nthem in applications with low latency requirements and large document sets is\nchallenging. To incorporate missing knowledge at scale, we propose SKIM\n(Scalable Knowledge Infusion for Missing Labels), an algorithm that leverages a\ncombination of small LM and abundant unstructured meta-data to effectively\nmitigate the missing label problem. We show the efficacy of our method on\nlarge-scale public datasets through exhaustive unbiased evaluation ranging from\nhuman annotations to simulations inspired from industrial settings. SKIM\noutperforms existing methods on Recall@100 by more than 10 absolute points.\nAdditionally, SKIM scales to proprietary query-ad retrieval datasets containing\n10 million documents, outperforming contemporary methods by 12% in offline\nevaluation and increased ad click-yield by 1.23% in an online A/B test\nconducted on a popular search engine. We release our code, prompts, trained XC\nmodels and finetuned SLMs at: https://github.com/bicycleman15/skim\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Information Retrieval"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"-PshBm55aorfY9lqs4wZBV2znzZ4yx5cBtNebwELYxo","pdfSize":"1713999"}
