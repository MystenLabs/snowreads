{"id":"2408.06966","title":"DyG-Mamba: Continuous State Space Modeling on Dynamic Graphs","authors":"Dongyuan Li and Shiyin Tan and Ying Zhang and Ming Jin and Shirui Pan\n  and Manabu Okumura and Renhe Jiang","authorsParsed":[["Li","Dongyuan",""],["Tan","Shiyin",""],["Zhang","Ying",""],["Jin","Ming",""],["Pan","Shirui",""],["Okumura","Manabu",""],["Jiang","Renhe",""]],"versions":[{"version":"v1","created":"Tue, 13 Aug 2024 15:21:46 GMT"}],"updateDate":"2024-08-14","timestamp":1723562506000,"abstract":"  Dynamic graph learning aims to uncover evolutionary laws in real-world\nsystems, enabling accurate social recommendation (link prediction) or early\ndetection of cancer cells (classification). Inspired by the success of state\nspace models, e.g., Mamba, for efficiently capturing long-term dependencies in\nlanguage modeling, we propose DyG-Mamba, a new continuous state space model\n(SSM) for dynamic graph learning. Specifically, we first found that using\ninputs as control signals for SSM is not suitable for continuous-time dynamic\nnetwork data with irregular sampling intervals, resulting in models being\ninsensitive to time information and lacking generalization properties. Drawing\ninspiration from the Ebbinghaus forgetting curve, which suggests that memory of\npast events is strongly correlated with time intervals rather than specific\ndetails of the events themselves, we directly utilize irregular time spans as\ncontrol signals for SSM to achieve significant robustness and generalization.\nThrough exhaustive experiments on 12 datasets for dynamic link prediction and\ndynamic node classification tasks, we found that DyG-Mamba achieves\nstate-of-the-art performance on most of the datasets, while also demonstrating\nsignificantly improved computation and memory efficiency.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}