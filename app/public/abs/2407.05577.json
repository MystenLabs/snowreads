{"id":"2407.05577","title":"Audio-driven High-resolution Seamless Talking Head Video Editing via\n  StyleGAN","authors":"Jiacheng Su, Kunhong Liu, Liyan Chen, Junfeng Yao, Qingsong Liu,\n  Dongdong Lv","authorsParsed":[["Su","Jiacheng",""],["Liu","Kunhong",""],["Chen","Liyan",""],["Yao","Junfeng",""],["Liu","Qingsong",""],["Lv","Dongdong",""]],"versions":[{"version":"v1","created":"Mon, 8 Jul 2024 03:17:10 GMT"}],"updateDate":"2024-07-09","timestamp":1720408630000,"abstract":"  The existing methods for audio-driven talking head video editing have the\nlimitations of poor visual effects. This paper tries to tackle this problem\nthrough editing talking face images seamless with different emotions based on\ntwo modules: (1) an audio-to-landmark module, consisting of the\nCrossReconstructed Emotion Disentanglement and an alignment network module. It\nbridges the gap between speech and facial motions by predicting corresponding\nemotional landmarks from speech; (2) a landmark-based editing module edits face\nvideos via StyleGAN. It aims to generate the seamless edited video consisting\nof the emotion and content components from the input audio. Extensive\nexperiments confirm that compared with state-of-the-arts methods, our method\nprovides high-resolution videos with high visual quality.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}