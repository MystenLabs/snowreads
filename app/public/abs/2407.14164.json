{"id":"2407.14164","title":"Experiences of Censorship on TikTok Across Marginalised Identities","authors":"Eddie L. Ungless, Nina Markl and Bj\\\"orn Ross","authorsParsed":[["Ungless","Eddie L.",""],["Markl","Nina",""],["Ross","Bj√∂rn",""]],"versions":[{"version":"v1","created":"Fri, 19 Jul 2024 09:50:13 GMT"}],"updateDate":"2024-07-22","timestamp":1721382613000,"abstract":"  TikTok has seen exponential growth as a platform, fuelled by the success of\nits proprietary recommender algorithm which serves tailored content to every\nuser - though not without controversy. Users complain of their content being\nunfairly suppressed by ''the algorithm'', particularly users with marginalised\nidentities such as LGBTQ+ users. Together with content removal, this\nsuppression acts to censor what is shared on the platform. Journalists have\nrevealed biases in automatic censorship, as well as human moderation. We\ninvestigate experiences of censorship on TikTok, across users marginalised by\ntheir gender, LGBTQ+ identity, disability or ethnicity. We survey 627 UK-based\nTikTok users and find that marginalised users often feel they are subject to\ncensorship for content that does not violate community guidelines. We highlight\nmany avenues for future research into censorship on TikTok, with a focus on\nusers' folk theories, which greatly shape their experiences of the platform.\n","subjects":["Computing Research Repository/Human-Computer Interaction"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"NPP9l0r9F3MrKFXrzQYc5cGdGGHoe2-DkiNapVLKbd0","pdfSize":"2106154"}
