{"id":"2407.07664","title":"A Coding-Theoretic Analysis of Hyperspherical Prototypical Learning\n  Geometry","authors":"Martin Lindstr\\\"om, Borja Rodr\\'iguez-G\\'alvez, Ragnar Thobaben,\n  Mikael Skoglund","authorsParsed":[["Lindström","Martin",""],["Rodríguez-Gálvez","Borja",""],["Thobaben","Ragnar",""],["Skoglund","Mikael",""]],"versions":[{"version":"v1","created":"Wed, 10 Jul 2024 13:44:19 GMT"}],"updateDate":"2024-07-11","timestamp":1720619059000,"abstract":"  Hyperspherical Prototypical Learning (HPL) is a supervised approach to\nrepresentation learning that designs class prototypes on the unit hypersphere.\nThe prototypes bias the representations to class separation in a scale\ninvariant and known geometry. Previous approaches to HPL have either of the\nfollowing shortcomings: (i) they follow an unprincipled optimisation procedure;\nor (ii) they are theoretically sound, but are constrained to only one possible\nlatent dimension. In this paper, we address both shortcomings. To address (i),\nwe present a principled optimisation procedure whose solution we show is\noptimal. To address (ii), we construct well-separated prototypes in a wide\nrange of dimensions using linear block codes. Additionally, we give a full\ncharacterisation of the optimal prototype placement in terms of achievable and\nconverse bounds, showing that our proposed methods are near-optimal.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computer Vision and Pattern Recognition","Electrical Engineering and Systems Science/Signal Processing","Statistics/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}