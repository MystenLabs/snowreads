{"id":"2408.11185","title":"CRACKS: Crowdsourcing Resources for Analysis and Categorization of Key\n  Subsurface faults","authors":"Mohit Prabhushankar, Kiran Kokilepersaud, Jorge Quesada, Yavuz Yarici,\n  Chen Zhou, Mohammad Alotaibi, Ghassan AlRegib, Ahmad Mustafa, and Yusufjon\n  Kumakov","authorsParsed":[["Prabhushankar","Mohit",""],["Kokilepersaud","Kiran",""],["Quesada","Jorge",""],["Yarici","Yavuz",""],["Zhou","Chen",""],["Alotaibi","Mohammad",""],["AlRegib","Ghassan",""],["Mustafa","Ahmad",""],["Kumakov","Yusufjon",""]],"versions":[{"version":"v1","created":"Tue, 20 Aug 2024 20:40:11 GMT"}],"updateDate":"2024-08-22","timestamp":1724186411000,"abstract":"  Crowdsourcing annotations has created a paradigm shift in the availability of\nlabeled data for machine learning. Availability of large datasets has\naccelerated progress in common knowledge applications involving visual and\nlanguage data. However, specialized applications that require expert labels lag\nin data availability. One such application is fault segmentation in subsurface\nimaging. Detecting, tracking, and analyzing faults has broad societal\nimplications in predicting fluid flows, earthquakes, and storing excess\natmospheric CO$_2$. However, delineating faults with current practices is a\nlabor-intensive activity that requires precise analysis of subsurface imaging\ndata by geophysicists. In this paper, we propose the $\\texttt{CRACKS}$ dataset\nto detect and segment faults in subsurface images by utilizing crowdsourced\nresources. We leverage Amazon Mechanical Turk to obtain fault delineations from\nsections of the Netherlands North Sea subsurface images from (i) $26$ novices\nwho have no exposure to subsurface data and were shown a video describing and\nlabeling faults, (ii) $8$ practitioners who have previously interacted and\nworked on subsurface data, (iii) one geophysicist to label $7636$ faults in the\nregion. Note that all novices, practitioners, and the expert segment faults on\nthe same subsurface volume with disagreements between and among the novices and\npractitioners. Additionally, each fault annotation is equipped with the\nconfidence level of the annotator. The paper provides benchmarks on detecting\nand segmenting the expert labels, given the novice and practitioner labels.\nAdditional details along with the dataset links and codes are available at\n$\\href{https://alregib.ece.gatech.edu/cracks-crowdsourcing-resources-for-analysis-and-categorization-of-key-subsurface-faults/}{link}$.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}