{"id":"2408.01914","title":"Partial-differential-algebraic equations of nonlinear dynamics by\n  Physics-Informed Neural-Network: (I) Operator splitting and framework\n  assessment","authors":"Loc Vu-Quoc and Alexander Humer","authorsParsed":[["Vu-Quoc","Loc",""],["Humer","Alexander",""]],"versions":[{"version":"v1","created":"Sat, 13 Jul 2024 22:48:17 GMT"},{"version":"v2","created":"Wed, 7 Aug 2024 21:09:54 GMT"}],"updateDate":"2024-08-09","timestamp":1720910897000,"abstract":"  Several forms for constructing novel physics-informed neural-networks (PINN)\nfor the solution of partial-differential-algebraic equations based on\nderivative operator splitting are proposed, using the nonlinear Kirchhoff rod\nas a prototype for demonstration. The open-source DeepXDE is likely the most\nwell documented framework with many examples. Yet, we encountered some\npathological problems and proposed novel methods to resolve them. Among these\nnovel methods are the PDE forms, which evolve from the lower-level form with\nfewer unknown dependent variables to higher-level form with more dependent\nvariables, in addition to those from lower-level forms. Traditionally, the\nhighest-level form, the balance-of-momenta form, is the starting point for\n(hand) deriving the lowest-level form through a tedious (and error prone)\nprocess of successive substitutions. The next step in a finite element method\nis to discretize the lowest-level form upon forming a weak form and\nlinearization with appropriate interpolation functions, followed by their\nimplementation in a code and testing. The time-consuming tedium in all of these\nsteps could be bypassed by applying the proposed novel PINN directly to the\nhighest-level form. We developed a script based on JAX. While our JAX script\ndid not show the pathological problems of DDE-T (DDE with TensorFlow backend),\nit is slower than DDE-T. That DDE-T itself being more efficient in higher-level\nform than in lower-level form makes working directly with higher-level form\neven more attractive in addition to the advantages mentioned further above.\nSince coming up with an appropriate learning-rate schedule for a good solution\nis more art than science, we systematically codified in detail our experience\nrunning optimization through a normalization/standardization of the\nnetwork-training process so readers can reproduce our results.\n","subjects":["Mathematics/Numerical Analysis","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Numerical Analysis"],"license":"http://creativecommons.org/licenses/by-sa/4.0/"}