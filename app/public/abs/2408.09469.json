{"id":"2408.09469","title":"Enhancing Adversarial Transferability with Adversarial Weight Tuning","authors":"Jiahao Chen, Zhou Feng, Rui Zeng, Yuwen Pu, Chunyi Zhou, Yi Jiang,\n  Yuyou Gan, Jinbao Li and Shouling Ji","authorsParsed":[["Chen","Jiahao",""],["Feng","Zhou",""],["Zeng","Rui",""],["Pu","Yuwen",""],["Zhou","Chunyi",""],["Jiang","Yi",""],["Gan","Yuyou",""],["Li","Jinbao",""],["Ji","Shouling",""]],"versions":[{"version":"v1","created":"Sun, 18 Aug 2024 13:31:26 GMT"},{"version":"v2","created":"Tue, 20 Aug 2024 05:28:55 GMT"}],"updateDate":"2024-08-21","timestamp":1723987886000,"abstract":"  Deep neural networks (DNNs) are vulnerable to adversarial examples (AEs) that\nmislead the model while appearing benign to human observers. A critical concern\nis the transferability of AEs, which enables black-box attacks without direct\naccess to the target model. However, many previous attacks have failed to\nexplain the intrinsic mechanism of adversarial transferability. In this paper,\nwe rethink the property of transferable AEs and reformalize the formulation of\ntransferability. Building on insights from this mechanism, we analyze the\ngeneralization of AEs across models with different architectures and prove that\nwe can find a local perturbation to mitigate the gap between surrogate and\ntarget models. We further establish the inner connections between model\nsmoothness and flat local maxima, both of which contribute to the\ntransferability of AEs. Further, we propose a new adversarial attack algorithm,\n\\textbf{A}dversarial \\textbf{W}eight \\textbf{T}uning (AWT), which adaptively\nadjusts the parameters of the surrogate model using generated AEs to optimize\nthe flat local maxima and model smoothness simultaneously, without the need for\nextra data. AWT is a data-free tuning method that combines gradient-based and\nmodel-based attack methods to enhance the transferability of AEs. Extensive\nexperiments on a variety of models with different architectures on ImageNet\ndemonstrate that AWT yields superior performance over other attacks, with an\naverage increase of nearly 5\\% and 10\\% attack success rates on CNN-based and\nTransformer-based models, respectively, compared to state-of-the-art attacks.\n","subjects":["Computing Research Repository/Cryptography and Security"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}