{"id":"2407.01516","title":"E.T. the Exceptional Trajectories: Text-to-camera-trajectory generation\n  with character awareness","authors":"Robin Courant, Nicolas Dufour, Xi Wang, Marc Christie and Vicky\n  Kalogeiton","authorsParsed":[["Courant","Robin",""],["Dufour","Nicolas",""],["Wang","Xi",""],["Christie","Marc",""],["Kalogeiton","Vicky",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 17:58:02 GMT"}],"updateDate":"2024-07-02","timestamp":1719856682000,"abstract":"  Stories and emotions in movies emerge through the effect of well-thought-out\ndirecting decisions, in particular camera placement and movement over time.\nCrafting compelling camera trajectories remains a complex iterative process,\neven for skilful artists. To tackle this, in this paper, we propose a dataset\ncalled the Exceptional Trajectories (E.T.) with camera trajectories along with\ncharacter information and textual captions encompassing descriptions of both\ncamera and character. To our knowledge, this is the first dataset of its kind.\nTo show the potential applications of the E.T. dataset, we propose a\ndiffusion-based approach, named DIRECTOR, which generates complex camera\ntrajectories from textual captions that describe the relation and\nsynchronisation between the camera and characters. To ensure robust and\naccurate evaluations, we train on the E.T. dataset CLaTr, a Contrastive\nLanguage-Trajectory embedding for evaluation metrics. We posit that our\nproposed dataset and method significantly advance the democratization of\ncinematography, making it more accessible to common users.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}