{"id":"2407.08414","title":"MeshAvatar: Learning High-quality Triangular Human Avatars from\n  Multi-view Videos","authors":"Yushuo Chen, Zerong Zheng, Zhe Li, Chao Xu, Yebin Liu","authorsParsed":[["Chen","Yushuo",""],["Zheng","Zerong",""],["Li","Zhe",""],["Xu","Chao",""],["Liu","Yebin",""]],"versions":[{"version":"v1","created":"Thu, 11 Jul 2024 11:37:51 GMT"}],"updateDate":"2024-07-12","timestamp":1720697871000,"abstract":"  We present a novel pipeline for learning high-quality triangular human\navatars from multi-view videos. Recent methods for avatar learning are\ntypically based on neural radiance fields (NeRF), which is not compatible with\ntraditional graphics pipeline and poses great challenges for operations like\nediting or synthesizing under different environments. To overcome these\nlimitations, our method represents the avatar with an explicit triangular mesh\nextracted from an implicit SDF field, complemented by an implicit material\nfield conditioned on given poses. Leveraging this triangular avatar\nrepresentation, we incorporate physics-based rendering to accurately decompose\ngeometry and texture. To enhance both the geometric and appearance details, we\nfurther employ a 2D UNet as the network backbone and introduce pseudo normal\nground-truth as additional supervision. Experiments show that our method can\nlearn triangular avatars with high-quality geometry reconstruction and\nplausible material decomposition, inherently supporting editing, manipulation\nor relighting operations.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Graphics"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}