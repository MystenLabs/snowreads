{"id":"2407.18110","title":"MapTune: Advancing ASIC Technology Mapping via Reinforcement Learning\n  Guided Library Tuning","authors":"Mingju Liu, Daniel Robinson, Yingjie Li, Cunxi Yu","authorsParsed":[["Liu","Mingju",""],["Robinson","Daniel",""],["Li","Yingjie",""],["Yu","Cunxi",""]],"versions":[{"version":"v1","created":"Thu, 25 Jul 2024 15:18:47 GMT"}],"updateDate":"2024-07-26","timestamp":1721920727000,"abstract":"  Technology mapping involves mapping logical circuits to a library of cells.\nTraditionally, the full technology library is used, leading to a large search\nspace and potential overhead. Motivated by randomly sampled technology mapping\ncase studies, we propose MapTune framework that addresses this challenge by\nutilizing reinforcement learning to make design-specific choices during cell\nselection. By learning from the environment, MapTune refines the cell selection\nprocess, resulting in a reduced search space and potentially improved mapping\nquality.\n  The effectiveness of MapTune is evaluated on a wide range of benchmarks,\ndifferent technology libraries and technology mappers. The experimental results\ndemonstrate that MapTune achieves higher mapping accuracy and reducing\ndelay/area across diverse circuit designs, technology libraries and mappers.\nThe paper also discusses the Pareto-Optimal exploration and confirms the\nperpetual delay-area trade-off. Conducted on benchmark suites ISCAS 85/89,\nITC/ISCAS 99, VTR8.0 and EPFL benchmarks, the post-technology mapping and\npost-sizing quality-of-results (QoR) have been significantly improved, with\naverage Area-Delay Product (ADP) improvement of 22.54\\% among all different\nexploration settings in MapTune. The improvements are consistently remained for\nfour different technologies (7nm, 45nm, 130nm, and 180 nm) and two different\nmappers.\n","subjects":["Computing Research Repository/Hardware Architecture","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}