{"id":"2407.17344","title":"Label Alignment and Reassignment with Generalist Large Language Model\n  for Enhanced Cross-Domain Named Entity Recognition","authors":"Ke Bao, Chonghuan Yang","authorsParsed":[["Bao","Ke",""],["Yang","Chonghuan",""]],"versions":[{"version":"v1","created":"Wed, 24 Jul 2024 15:13:12 GMT"}],"updateDate":"2024-07-25","timestamp":1721833992000,"abstract":"  Named entity recognition on the in-domain supervised and few-shot settings\nhave been extensively discussed in the NLP community and made significant\nprogress. However, cross-domain NER, a more common task in practical scenarios,\nstill poses a challenge for most NER methods. Previous research efforts in that\narea primarily focus on knowledge transfer such as correlate label information\nfrom source to target domains but few works pay attention to the problem of\nlabel conflict. In this study, we introduce a label alignment and reassignment\napproach, namely LAR, to address this issue for enhanced cross-domain named\nentity recognition, which includes two core procedures: label alignment between\nsource and target domains and label reassignment for type inference. The\nprocess of label reassignment can significantly be enhanced by integrating with\nan advanced large-scale language model such as ChatGPT. We conduct an extensive\nrange of experiments on NER datasets involving both supervised and zero-shot\nscenarios. Empirical experimental results demonstrate the validation of our\nmethod with remarkable performance under the supervised and zero-shot\nout-of-domain settings compared to SOTA methods.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}