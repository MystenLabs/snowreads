{"id":"2408.17097","title":"Reasoning AI Performance Degradation in 6G Networks with Large Language\n  Models","authors":"Liming Huang, Yulei Wu, Dimitra Simeonidou","authorsParsed":[["Huang","Liming",""],["Wu","Yulei",""],["Simeonidou","Dimitra",""]],"versions":[{"version":"v1","created":"Fri, 30 Aug 2024 08:32:50 GMT"}],"updateDate":"2024-09-02","timestamp":1725006770000,"abstract":"  The integration of Artificial Intelligence (AI) within 6G networks is poised\nto revolutionize connectivity, reliability, and intelligent decision-making.\nHowever, the performance of AI models in these networks is crucial, as any\ndecline can significantly impact network efficiency and the services it\nsupports. Understanding the root causes of performance degradation is essential\nfor maintaining optimal network functionality. In this paper, we propose a\nnovel approach to reason about AI model performance degradation in 6G networks\nusing the Large Language Models (LLMs) empowered Chain-of-Thought (CoT) method.\nOur approach employs an LLM as a ''teacher'' model through zero-shot prompting\nto generate teaching CoT rationales, followed by a CoT ''student'' model that\nis fine-tuned by the generated teaching data for learning to reason about\nperformance declines. The efficacy of this model is evaluated in a real-world\nscenario involving a real-time 3D rendering task with multi-Access Technologies\n(mATs) including WiFi, 5G, and LiFi for data transmission. Experimental results\nshow that our approach achieves over 97% reasoning accuracy on the built test\nquestions, confirming the validity of our collected dataset and the\neffectiveness of the LLM-CoT method. Our findings highlight the potential of\nLLMs in enhancing the reliability and efficiency of 6G networks, representing a\nsignificant advancement in the evolution of AI-native network infrastructures.\n","subjects":["Computing Research Repository/Networking and Internet Architecture"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}