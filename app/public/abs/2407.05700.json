{"id":"2407.05700","title":"InverseCoder: Unleashing the Power of Instruction-Tuned Code LLMs with\n  Inverse-Instruct","authors":"Yutong Wu, Di Huang, Wenxuan Shi, Wei Wang, Lingzhe Gao, Shihao Liu,\n  Ziyuan Nan, Kaizhao Yuan, Rui Zhang, Xishan Zhang, Zidong Du, Qi Guo, Yewen\n  Pu, Dawei Yin, Xing Hu, Yunji Chen","authorsParsed":[["Wu","Yutong",""],["Huang","Di",""],["Shi","Wenxuan",""],["Wang","Wei",""],["Gao","Lingzhe",""],["Liu","Shihao",""],["Nan","Ziyuan",""],["Yuan","Kaizhao",""],["Zhang","Rui",""],["Zhang","Xishan",""],["Du","Zidong",""],["Guo","Qi",""],["Pu","Yewen",""],["Yin","Dawei",""],["Hu","Xing",""],["Chen","Yunji",""]],"versions":[{"version":"v1","created":"Mon, 8 Jul 2024 08:00:05 GMT"}],"updateDate":"2024-07-09","timestamp":1720425605000,"abstract":"  Recent advancements in open-source code large language models (LLMs) have\ndemonstrated remarkable coding abilities by fine-tuning on the data generated\nfrom powerful closed-source LLMs such as GPT-3.5 and GPT-4 for instruction\ntuning. This paper explores how to further improve an instruction-tuned code\nLLM by generating data from itself rather than querying closed-source LLMs. Our\nkey observation is the misalignment between the translation of formal and\ninformal languages: translating formal language (i.e., code) to informal\nlanguage (i.e., natural language) is more straightforward than the reverse.\nBased on this observation, we propose INVERSE-INSTRUCT, which summarizes\ninstructions from code snippets instead of the reverse. Specifically, given an\ninstruction tuning corpus for code and the resulting instruction-tuned code\nLLM, we ask the code LLM to generate additional high-quality instructions for\nthe original corpus through code summarization and self-evaluation. Then, we\nfine-tune the base LLM on the combination of the original corpus and the\nself-generated one, which yields a stronger instruction-tuned LLM. We present a\nseries of code LLMs named InverseCoder, which surpasses the performance of the\noriginal code LLMs on a wide range of benchmarks, including Python text-to-code\ngeneration, multilingual coding, and data-science code generation.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Software Engineering"],"license":"http://creativecommons.org/licenses/by/4.0/"}