{"id":"2407.17095","title":"MemBench: Memorized Image Trigger Prompt Dataset for Diffusion Models","authors":"Chunsan Hong and Tae-Hyun Oh and Minhyuk Sung","authorsParsed":[["Hong","Chunsan",""],["Oh","Tae-Hyun",""],["Sung","Minhyuk",""]],"versions":[{"version":"v1","created":"Wed, 24 Jul 2024 08:46:58 GMT"}],"updateDate":"2024-07-25","timestamp":1721810818000,"abstract":"  Diffusion models have achieved remarkable success in Text-to-Image generation\ntasks, leading to the development of many commercial models. However, recent\nstudies have reported that diffusion models often generate replicated images in\ntrain data when triggered by specific prompts, potentially raising social\nissues ranging from copyright to privacy concerns. To sidestep the\nmemorization, there have been recent studies for developing memorization\nmitigation methods for diffusion models. Nevertheless, the lack of benchmarks\nimpedes the assessment of the true effectiveness of these methods. In this\nwork, we present MemBench, the first benchmark for evaluating image\nmemorization mitigation methods. Our benchmark includes a large number of\nmemorized image trigger prompts in Stable Diffusion, the most popularly used\nmodel nowadays. Furthermore, in contrast to the prior work evaluating\nmitigation performance only on trigger prompts, we present metrics evaluating\non both trigger prompts and general prompts, so that we can see whether\nmitigation methods address the memorization issue while maintaining performance\nfor general prompts. This is an important development considering the practical\napplications which previous works have overlooked. Through evaluation on\nMemBench, we verify that the performance of existing image memorization\nmitigation methods is still insufficient for application to diffusion models.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}