{"id":"2407.09453","title":"Weight Block Sparsity: Training, Compilation, and AI Engine Accelerators","authors":"Paolo D'Alberto, Taehee Jeong, Akshai Jain, Shreyas Manjunath, Mrinal\n  Sarmah, Samuel Hsu, Yaswanth Raparti and Nitesh Pipralia","authorsParsed":[["D'Alberto","Paolo",""],["Jeong","Taehee",""],["Jain","Akshai",""],["Manjunath","Shreyas",""],["Sarmah","Mrinal",""],["Hsu","Samuel",""],["Raparti","Yaswanth",""],["Pipralia","Nitesh",""]],"versions":[{"version":"v1","created":"Fri, 12 Jul 2024 17:37:49 GMT"}],"updateDate":"2024-07-16","timestamp":1720805869000,"abstract":"  Nowadays, increasingly larger Deep Neural Networks (DNNs) are being\ndeveloped, trained, and utilized. These networks require significant\ncomputational resources, putting a strain on both advanced and limited devices.\nOur solution is to implement {\\em weight block sparsity}, which is a structured\nsparsity that is friendly to hardware. By zeroing certain sections of the\nconvolution and fully connected layers parameters of pre-trained DNN models, we\ncan efficiently speed up the DNN's inference process. This results in a smaller\nmemory footprint, faster communication, and fewer operations.\n  Our work presents a vertical system that allows for the training of\nconvolution and matrix multiplication weights to exploit 8x8 block sparsity on\na single GPU within a reasonable amount of time. Compilers recognize this\nsparsity and use it for both data compaction and computation splitting into\nthreads. Blocks like these take full advantage of both spatial and temporal\nlocality, paving the way for fast vector operations and memory reuse. By using\nthis system on a Resnet50 model, we were able to reduce the weight by half with\nminimal accuracy loss, resulting in a two-times faster inference speed. We will\npresent performance estimates using accurate and complete code generation for\nAIE2 configuration sets (AMD Versal FPGAs) with Resnet50, Inception V3, and\nVGG16 to demonstrate the necessary synergy between hardware overlay designs and\nsoftware stacks for compiling and executing machine learning applications.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Hardware Architecture","Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/"}