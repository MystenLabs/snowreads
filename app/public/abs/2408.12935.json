{"id":"2408.12935","title":"Trustworthy, Responsible, and Safe AI: A Comprehensive Architectural\n  Framework for AI Safety with Challenges and Mitigations","authors":"Chen Chen, Ziyao Liu, Weifeng Jiang, Si Qi Goh, and Kwok-Yan Lam","authorsParsed":[["Chen","Chen",""],["Liu","Ziyao",""],["Jiang","Weifeng",""],["Goh","Si Qi",""],["Lam","Kwok-Yan",""]],"versions":[{"version":"v1","created":"Fri, 23 Aug 2024 09:33:48 GMT"},{"version":"v2","created":"Thu, 12 Sep 2024 07:45:50 GMT"}],"updateDate":"2024-09-13","timestamp":1724405628000,"abstract":"  AI Safety is an emerging area of critical importance to the safe adoption and\ndeployment of AI systems. With the rapid proliferation of AI and especially\nwith the recent advancement of Generative AI (or GAI), the technology ecosystem\nbehind the design, development, adoption, and deployment of AI systems has\ndrastically changed, broadening the scope of AI Safety to address impacts on\npublic safety and national security. In this paper, we propose a novel\narchitectural framework for understanding and analyzing AI Safety; defining its\ncharacteristics from three perspectives: Trustworthy AI, Responsible AI, and\nSafe AI. We provide an extensive review of current research and advancements in\nAI safety from these perspectives, highlighting their key challenges and\nmitigation approaches. Through examples from state-of-the-art technologies,\nparticularly Large Language Models (LLMs), we present innovative mechanism,\nmethodologies, and techniques for designing and testing AI safety. Our goal is\nto promote advancement in AI safety research, and ultimately enhance people's\ntrust in digital transformation.\n","subjects":["Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/"}