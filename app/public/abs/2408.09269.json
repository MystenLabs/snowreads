{"id":"2408.09269","title":"Enhancing Audio-Language Models through Self-Supervised Post-Training\n  with Text-Audio Pairs","authors":"Anshuman Sinha, Camille Migozzi, Aubin Rey and Chao Zhang","authorsParsed":[["Sinha","Anshuman",""],["Migozzi","Camille",""],["Rey","Aubin",""],["Zhang","Chao",""]],"versions":[{"version":"v1","created":"Sat, 17 Aug 2024 18:53:17 GMT"}],"updateDate":"2024-08-20","timestamp":1723920797000,"abstract":"  Research on multi-modal contrastive learning strategies for audio and text\nhas rapidly gained interest. Contrastively trained Audio-Language Models\n(ALMs), such as CLAP, which establish a unified representation across audio and\nlanguage modalities, have enhanced the efficacy in various subsequent tasks by\nproviding good text aligned audio encoders and vice versa. These improvements\nare evident in areas like zero-shot audio classification and audio retrieval,\namong others. However, the ability of these models to understand natural\nlanguage and temporal relations is still a largely unexplored and open field\nfor research. In this paper, we propose to equip the multi-modal ALMs with\ntemporal understanding without loosing their inherent prior capabilities of\naudio-language tasks with a temporal instillation method TeminAL. We implement\na two-stage training scheme TeminAL A $\\&$ B, where the model first learns to\ndifferentiate between multiple sounds in TeminAL A, followed by a phase that\ninstills a sense of time, thereby enhancing its temporal understanding in\nTeminAL B. This approach results in an average performance gain of $5.28\\%$ in\ntemporal understanding on the ESC-50 dataset, while the model remains\ncompetitive in zero-shot retrieval and classification tasks on the\nAudioCap/Clotho datasets. We also note the lack of proper evaluation techniques\nfor contrastive ALMs and propose a strategy for evaluating ALMs in zero-shot\nsettings. The general-purpose zero-shot model evaluation strategy ZSTE, is used\nto evaluate various prior models. ZSTE demonstrates a general strategy to\nevaluate all ZS contrastive models. The model trained with TeminAL successfully\noutperforms current models on most downstream tasks.\n","subjects":["Computing Research Repository/Sound","Computing Research Repository/Machine Learning","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"XbPoiDaWPonxFHTxHl_AMT2NUQ81amBGj1sba0b_67k","pdfSize":"9306318"}
