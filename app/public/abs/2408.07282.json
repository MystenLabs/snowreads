{"id":"2408.07282","title":"Consistency Based Weakly Self-Supervised Learning for Human Activity\n  Recognition with Wearables","authors":"Taoran Sheng and Manfred Huber","authorsParsed":[["Sheng","Taoran",""],["Huber","Manfred",""]],"versions":[{"version":"v1","created":"Mon, 29 Jul 2024 06:29:21 GMT"}],"updateDate":"2024-08-15","timestamp":1722234561000,"abstract":"  While the widely available embedded sensors in smartphones and other wearable\ndevices make it easier to obtain data of human activities, recognizing\ndifferent types of human activities from sensor-based data remains a difficult\nresearch topic in ubiquitous computing. One reason for this is that most of the\ncollected data is unlabeled. However, many current human activity recognition\n(HAR) systems are based on supervised methods, which heavily rely on the labels\nof the data. We describe a weakly self-supervised approach in this paper that\nconsists of two stages: (1) In stage one, the model learns from the nature of\nhuman activities by projecting the data into an embedding space where similar\nactivities are grouped together; (2) In stage two, the model is fine-tuned\nusing similarity information in a few-shot learning fashion using the\nsimilarity information of the data. This allows downstream classification or\nclustering tasks to benefit from the embeddings. Experiments on three benchmark\ndatasets demonstrate the framework's effectiveness and show that our approach\ncan help the clustering algorithm achieve comparable performance in identifying\nand categorizing the underlying human activities as pure supervised techniques\napplied directly to a corresponding fully labeled data set.\n","subjects":["Electrical Engineering and Systems Science/Signal Processing","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Human-Computer Interaction","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}