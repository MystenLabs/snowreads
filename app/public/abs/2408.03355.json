{"id":"2408.03355","title":"FastEdit: Fast Text-Guided Single-Image Editing via Semantic-Aware\n  Diffusion Fine-Tuning","authors":"Zhi Chen, Zecheng Zhao, Yadan Luo, Zi Huang","authorsParsed":[["Chen","Zhi",""],["Zhao","Zecheng",""],["Luo","Yadan",""],["Huang","Zi",""]],"versions":[{"version":"v1","created":"Tue, 6 Aug 2024 09:16:13 GMT"}],"updateDate":"2024-08-08","timestamp":1722935773000,"abstract":"  Conventional Text-guided single-image editing approaches require a two-step\nprocess, including fine-tuning the target text embedding for over 1K iterations\nand the generative model for another 1.5K iterations. Although it ensures that\nthe resulting image closely aligns with both the input image and the target\ntext, this process often requires 7 minutes per image, posing a challenge for\npractical application due to its time-intensive nature. To address this\nbottleneck, we introduce FastEdit, a fast text-guided single-image editing\nmethod with semantic-aware diffusion fine-tuning, dramatically accelerating the\nediting process to only 17 seconds. FastEdit streamlines the generative model's\nfine-tuning phase, reducing it from 1.5K to a mere 50 iterations. For diffusion\nfine-tuning, we adopt certain time step values based on the semantic\ndiscrepancy between the input image and target text. Furthermore, FastEdit\ncircumvents the initial fine-tuning step by utilizing an image-to-image model\nthat conditions on the feature space, rather than the text embedding space. It\ncan effectively align the target text prompt and input image within the same\nfeature space and save substantial processing time. Additionally, we apply the\nparameter-efficient fine-tuning technique LoRA to U-net. With LoRA, FastEdit\nminimizes the model's trainable parameters to only 0.37\\% of the original size.\nAt the same time, we can achieve comparable editing outcomes with significantly\nreduced computational overhead. We conduct extensive experiments to validate\nthe editing performance of our approach and show promising editing\ncapabilities, including content addition, style transfer, background\nreplacement, and posture manipulation, etc.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"AlNFb-Ngqw2_uqfkaDosmG0CGj60zwDDx-BS0352fiI","pdfSize":"4870453"}
