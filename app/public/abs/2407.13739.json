{"id":"2407.13739","title":"Scaling Granite Code Models to 128K Context","authors":"Matt Stallone, Vaibhav Saxena, Leonid Karlinsky, Bridget McGinn, Tim\n  Bula, Mayank Mishra, Adriana Meza Soria, Gaoyuan Zhang, Aditya Prasad, Yikang\n  Shen, Saptha Surendran, Shanmukha Guttula, Hima Patel, Parameswaran Selvam,\n  Xuan-Hong Dang, Yan Koyfman, Atin Sood, Rogerio Feris, Nirmit Desai, David D.\n  Cox, Ruchir Puri, Rameswar Panda","authorsParsed":[["Stallone","Matt",""],["Saxena","Vaibhav",""],["Karlinsky","Leonid",""],["McGinn","Bridget",""],["Bula","Tim",""],["Mishra","Mayank",""],["Soria","Adriana Meza",""],["Zhang","Gaoyuan",""],["Prasad","Aditya",""],["Shen","Yikang",""],["Surendran","Saptha",""],["Guttula","Shanmukha",""],["Patel","Hima",""],["Selvam","Parameswaran",""],["Dang","Xuan-Hong",""],["Koyfman","Yan",""],["Sood","Atin",""],["Feris","Rogerio",""],["Desai","Nirmit",""],["Cox","David D.",""],["Puri","Ruchir",""],["Panda","Rameswar",""]],"versions":[{"version":"v1","created":"Thu, 18 Jul 2024 17:46:02 GMT"}],"updateDate":"2024-07-19","timestamp":1721324762000,"abstract":"  This paper introduces long-context Granite code models that support effective\ncontext windows of up to 128K tokens. Our solution for scaling context length\nof Granite 3B/8B code models from 2K/4K to 128K consists of a light-weight\ncontinual pretraining by gradually increasing its RoPE base frequency with\nrepository-level file packing and length-upsampled long-context data.\nAdditionally, we also release instruction-tuned models with long-context\nsupport which are derived by further finetuning the long context base models on\na mix of permissively licensed short and long-context instruction-response\npairs. While comparing to the original short-context Granite code models, our\nlong-context models achieve significant improvements on long-context tasks\nwithout any noticeable performance degradation on regular code completion\nbenchmarks (e.g., HumanEval). We release all our long-context Granite code\nmodels under an Apache 2.0 license for both research and commercial use.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language","Computing Research Repository/Software Engineering"],"license":"http://creativecommons.org/licenses/by/4.0/"}