{"id":"2407.02422","title":"Close, But Not There: Boosting Geographic Distance Sensitivity in Visual\n  Place Recognition","authors":"Sergio Izquierdo, Javier Civera","authorsParsed":[["Izquierdo","Sergio",""],["Civera","Javier",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 16:49:01 GMT"}],"updateDate":"2024-07-03","timestamp":1719938941000,"abstract":"  Visual Place Recognition (VPR) plays a critical role in many localization and\nmapping pipelines. It consists of retrieving the closest sample to a query\nimage, in a certain embedding space, from a database of geotagged references.\nThe image embedding is learned to effectively describe a place despite\nvariations in visual appearance, viewpoint, and geometric changes. In this\nwork, we formulate how limitations in the Geographic Distance Sensitivity of\ncurrent VPR embeddings result in a high probability of incorrectly sorting the\ntop-k retrievals, negatively impacting the recall. In order to address this\nissue in single-stage VPR, we propose a novel mining strategy, CliqueMining,\nthat selects positive and negative examples by sampling cliques from a graph of\nvisually similar images. Our approach boosts the sensitivity of VPR embeddings\nat small distance ranges, significantly improving the state of the art on\nrelevant benchmarks. In particular, we raise recall@1 from 75% to 82% in MSLS\nChallenge, and from 76% to 90% in Nordland. Models and code are available at\nhttps://github.com/serizba/cliquemining.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}