{"id":"2407.12216","title":"Mindful-RAG: A Study of Points of Failure in Retrieval Augmented\n  Generation","authors":"Garima Agrawal, Tharindu Kumarage, Zeyad Alghamdi, Huan Liu","authorsParsed":[["Agrawal","Garima",""],["Kumarage","Tharindu",""],["Alghamdi","Zeyad",""],["Liu","Huan",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 23:50:07 GMT"}],"updateDate":"2024-07-18","timestamp":1721173807000,"abstract":"  Large Language Models (LLMs) are proficient at generating coherent and\ncontextually relevant text but face challenges when addressing\nknowledge-intensive queries in domain-specific and factual question-answering\ntasks. Retrieval-augmented generation (RAG) systems mitigate this by\nincorporating external knowledge sources, such as structured knowledge graphs\n(KGs). However, LLMs often struggle to produce accurate answers despite access\nto KG-extracted information containing necessary facts. Our study investigates\nthis dilemma by analyzing error patterns in existing KG-based RAG methods and\nidentifying eight critical failure points. We observed that these errors\npredominantly occur due to insufficient focus on discerning the question's\nintent and adequately gathering relevant context from the knowledge graph\nfacts. Drawing on this analysis, we propose the Mindful-RAG approach, a\nframework designed for intent-based and contextually aligned knowledge\nretrieval. This method explicitly targets the identified failures and offers\nimprovements in the correctness and relevance of responses provided by LLMs,\nrepresenting a significant step forward from existing methods.\n","subjects":["Computing Research Repository/Information Retrieval"],"license":"http://creativecommons.org/licenses/by/4.0/"}