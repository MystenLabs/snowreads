{"id":"2407.02601","title":"Linear Submodular Maximization with Bandit Feedback","authors":"Wenjing Chen, Victoria G. Crawford","authorsParsed":[["Chen","Wenjing",""],["Crawford","Victoria G.",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 18:40:52 GMT"}],"updateDate":"2024-07-04","timestamp":1719945652000,"abstract":"  Submodular optimization with bandit feedback has recently been studied in a\nvariety of contexts. In a number of real-world applications such as diversified\nrecommender systems and data summarization, the submodular function exhibits\nadditional linear structure. We consider developing approximation algorithms\nfor the maximization of a submodular objective function\n$f:2^U\\to\\mathbb{R}_{\\geq 0}$, where $f=\\sum_{i=1}^dw_iF_{i}$. It is assumed\nthat we have value oracle access to the functions $F_i$, but the coefficients\n$w_i$ are unknown, and $f$ can only be accessed via noisy queries. We develop\nalgorithms for this setting inspired by adaptive allocation algorithms in the\nbest-arm identification for linear bandit, with approximation guarantees\narbitrarily close to the setting where we have value oracle access to $f$.\nFinally, we empirically demonstrate that our algorithms make vast improvements\nin terms of sample efficiency compared to algorithms that do not exploit the\nlinear structure of $f$ on instances of move recommendation.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Data Structures and Algorithms"],"license":"http://creativecommons.org/licenses/by/4.0/"}