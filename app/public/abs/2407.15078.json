{"id":"2407.15078","title":"Learning to Compile Programs to Neural Networks","authors":"Logan Weber, Jesse Michel, Alex Renda, Michael Carbin","authorsParsed":[["Weber","Logan",""],["Michel","Jesse",""],["Renda","Alex",""],["Carbin","Michael",""]],"versions":[{"version":"v1","created":"Sun, 21 Jul 2024 07:04:52 GMT"}],"updateDate":"2024-07-23","timestamp":1721545492000,"abstract":"  A $\\textit{neural surrogate of a program}$ is a neural network that mimics\nthe behavior of a program. Researchers have used these neural surrogates to\nautomatically tune program inputs, adapt programs to new settings, and\naccelerate computations. Researchers traditionally develop neural surrogates by\ntraining on input-output examples from a single program. Alternatively,\nlanguage models trained on a large dataset including many programs can consume\nprogram text, to act as a neural surrogate. Using a language model to both\ngenerate a surrogate and act as a surrogate, however, leading to a trade-off\nbetween resource consumption and accuracy. We present $\\textit{neural surrogate\ncompilation}$, a technique for producing neural surrogates directly from\nprogram text without coupling neural surrogate generation and execution. We\nimplement neural surrogate compilers using hypernetworks trained on a dataset\nof C programs and find that they produce neural surrogates that are\n$1.9$-$9.5\\times$ as data-efficient, produce visual results that are\n$1.0$-$1.3\\times$ more similar to ground truth, and train in $4.3$-$7.3\\times$\nfewer epochs than neural surrogates trained from scratch.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"gB1rsPAkxTOpd8KycL6LD1QUKXRO3NKfiO4JBj6KpMY","pdfSize":"19090834"}
