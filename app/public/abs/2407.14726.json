{"id":"2407.14726","title":"MetaAug: Meta-Data Augmentation for Post-Training Quantization","authors":"Cuong Pham, Hoang Anh Dung, Cuong C. Nguyen, Trung Le, Dinh Phung,\n  Gustavo Carneiro, Thanh-Toan Do","authorsParsed":[["Pham","Cuong",""],["Dung","Hoang Anh",""],["Nguyen","Cuong C.",""],["Le","Trung",""],["Phung","Dinh",""],["Carneiro","Gustavo",""],["Do","Thanh-Toan",""]],"versions":[{"version":"v1","created":"Sat, 20 Jul 2024 02:18:51 GMT"},{"version":"v2","created":"Sat, 27 Jul 2024 04:18:22 GMT"}],"updateDate":"2024-07-30","timestamp":1721441931000,"abstract":"  Post-Training Quantization (PTQ) has received significant attention because\nit requires only a small set of calibration data to quantize a full-precision\nmodel, which is more practical in real-world applications in which full access\nto a large training set is not available. However, it often leads to\noverfitting on the small calibration dataset. Several methods have been\nproposed to address this issue, yet they still rely on only the calibration set\nfor the quantization and they do not validate the quantized model due to the\nlack of a validation set. In this work, we propose a novel meta-learning based\napproach to enhance the performance of post-training quantization.\nSpecifically, to mitigate the overfitting problem, instead of only training the\nquantized model using the original calibration set without any validation\nduring the learning process as in previous PTQ works, in our approach, we both\ntrain and validate the quantized model using two different sets of images. In\nparticular, we propose a meta-learning based approach to jointly optimize a\ntransformation network and a quantized model through bi-level optimization. The\ntransformation network modifies the original calibration data and the modified\ndata will be used as the training set to learn the quantized model with the\nobjective that the quantized model achieves a good performance on the original\ncalibration data. Extensive experiments on the widely used ImageNet dataset\nwith different neural network architectures demonstrate that our approach\noutperforms the state-of-the-art PTQ methods.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"rhoTClNm1eCswEoBs-Oj7DMabj74sKSm6ZRm34dOMYI","pdfSize":"4285798"}
