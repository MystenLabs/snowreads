{"id":"2408.07144","title":"Language Models as Models of Language","authors":"Rapha\\\"el Milli\\`ere","authorsParsed":[["Millière","Raphaël",""]],"versions":[{"version":"v1","created":"Tue, 13 Aug 2024 18:26:04 GMT"}],"updateDate":"2024-08-15","timestamp":1723573564000,"abstract":"  This chapter critically examines the potential contributions of modern\nlanguage models to theoretical linguistics. Despite their focus on engineering\ngoals, these models' ability to acquire sophisticated linguistic knowledge from\nmere exposure to data warrants a careful reassessment of their relevance to\nlinguistic theory. I review a growing body of empirical evidence suggesting\nthat language models can learn hierarchical syntactic structure and exhibit\nsensitivity to various linguistic phenomena, even when trained on\ndevelopmentally plausible amounts of data. While the competence/performance\ndistinction has been invoked to dismiss the relevance of such models to\nlinguistic theory, I argue that this assessment may be premature. By carefully\ncontrolling learning conditions and making use of causal intervention methods,\nexperiments with language models can potentially constrain hypotheses about\nlanguage acquisition and competence. I conclude that closer collaboration\nbetween theoretical linguists and computational researchers could yield\nvaluable insights, particularly in advancing debates about linguistic nativism.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"HhhSUpqEtaBus9PbH5HIzp9KeiQyJVJhW38R_iraGL8","pdfSize":"949737"}
