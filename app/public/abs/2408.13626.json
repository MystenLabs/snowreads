{"id":"2408.13626","title":"Towards Case-based Interpretability for Medical Federated Learning","authors":"Laura Latorre, Liliana Petrychenko, Regina Beets-Tan, Taisiya\n  Kopytova, and Wilson Silva","authorsParsed":[["Latorre","Laura",""],["Petrychenko","Liliana",""],["Beets-Tan","Regina",""],["Kopytova","Taisiya",""],["Silva","Wilson",""]],"versions":[{"version":"v1","created":"Sat, 24 Aug 2024 16:42:12 GMT"}],"updateDate":"2024-08-27","timestamp":1724517732000,"abstract":"  We explore deep generative models to generate case-based explanations in a\nmedical federated learning setting. Explaining AI model decisions through\ncase-based interpretability is paramount to increasing trust and allowing\nwidespread adoption of AI in clinical practice. However, medical AI training\nparadigms are shifting towards federated learning settings in order to comply\nwith data protection regulations. In a federated scenario, past data is\ninaccessible to the current user. Thus, we use a deep generative model to\ngenerate synthetic examples that protect privacy and explain decisions. Our\nproof-of-concept focuses on pleural effusion diagnosis and uses publicly\navailable Chest X-ray data.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}