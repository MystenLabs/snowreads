{"id":"2408.11539","title":"Research on the Application of Large Language Models in Automatic\n  Question Generation: A Case Study of ChatGLM in the Context of High School\n  Information Technology Curriculum","authors":"Yanxin Chen, Ling He","authorsParsed":[["Chen","Yanxin",""],["He","Ling",""]],"versions":[{"version":"v1","created":"Wed, 21 Aug 2024 11:38:32 GMT"}],"updateDate":"2024-08-22","timestamp":1724240312000,"abstract":"  This study investigates the application effectiveness of the Large Language\nModel (LLMs) ChatGLM in the automated generation of high school information\ntechnology exam questions. Through meticulously designed prompt engineering\nstrategies, the model is guided to generate diverse questions, which are then\ncomprehensively evaluated by domain experts. The evaluation dimensions include\nthe Hitting(the degree of alignment with teaching content), Fitting (the degree\nof embodiment of core competencies), Clarity (the explicitness of question\ndescriptions), and Willing to use (the teacher's willingness to use the\nquestion in teaching). The results indicate that ChatGLM outperforms\nhuman-generated questions in terms of clarity and teachers' willingness to use,\nalthough there is no significant difference in hit rate and fit. This finding\nsuggests that ChatGLM has the potential to enhance the efficiency of question\ngeneration and alleviate the burden on teachers, providing a new perspective\nfor the future development of educational assessment systems. Future research\ncould explore further optimizations to the ChatGLM model to maintain high fit\nand hit rates while improving the clarity of questions and teachers'\nwillingness to use them.\n","subjects":["Computing Research Repository/Computers and Society"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}