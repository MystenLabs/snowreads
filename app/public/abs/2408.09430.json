{"id":"2408.09430","title":"FASST: Fast LLM-based Simultaneous Speech Translation","authors":"Siqi Ouyang and Xi Xu and Chinmay Dandekar and Lei Li","authorsParsed":[["Ouyang","Siqi",""],["Xu","Xi",""],["Dandekar","Chinmay",""],["Li","Lei",""]],"versions":[{"version":"v1","created":"Sun, 18 Aug 2024 10:12:39 GMT"}],"updateDate":"2024-08-20","timestamp":1723975959000,"abstract":"  Simultaneous speech translation (SST) takes streaming speech input and\ngenerates text translation on the fly. Existing methods either have high\nlatency due to recomputation of input representations, or fall behind of\noffline ST in translation quality. In this paper, we propose FASST, a fast\nlarge language model based method for streaming speech translation. We propose\nblockwise-causal speech encoding and consistency mask, so that streaming speech\ninput can be encoded incrementally without recomputation. Furthermore, we\ndevelop a two-stage training strategy to optimize FASST for simultaneous\ninference. We evaluate FASST and multiple strong prior models on MuST-C\ndataset. Experiment results show that FASST achieves the best quality-latency\ntrade-off. It outperforms the previous best model by an average of 1.5 BLEU\nunder the same latency for English to Spanish translation.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/"}