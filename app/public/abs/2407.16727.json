{"id":"2407.16727","title":"A study of animal action segmentation algorithms across supervised,\n  unsupervised, and semi-supervised learning paradigms","authors":"Ari Blau, Evan S Schaffer, Neeli Mishra, Nathaniel J Miska, The\n  International Brain Laboratory, Liam Paninski, and Matthew R Whiteway","authorsParsed":[["Blau","Ari",""],["Schaffer","Evan S",""],["Mishra","Neeli",""],["Miska","Nathaniel J",""],["Laboratory","The International Brain",""],["Paninski","Liam",""],["Whiteway","Matthew R",""]],"versions":[{"version":"v1","created":"Tue, 23 Jul 2024 14:22:16 GMT"}],"updateDate":"2024-07-25","timestamp":1721744536000,"abstract":"  Action segmentation of behavioral videos is the process of labeling each\nframe as belonging to one or more discrete classes, and is a crucial component\nof many studies that investigate animal behavior. A wide range of algorithms\nexist to automatically parse discrete animal behavior, encompassing supervised,\nunsupervised, and semi-supervised learning paradigms. These algorithms -- which\ninclude tree-based models, deep neural networks, and graphical models -- differ\nwidely in their structure and assumptions on the data. Using four datasets\nspanning multiple species -- fly, mouse, and human -- we systematically study\nhow the outputs of these various algorithms align with manually annotated\nbehaviors of interest. Along the way, we introduce a semi-supervised action\nsegmentation model that bridges the gap between supervised deep neural networks\nand unsupervised graphical models. We find that fully supervised temporal\nconvolutional networks with the addition of temporal information in the\nobservations perform the best on our supervised metrics across all datasets.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Quantitative Biology/Quantitative Methods"],"license":"http://creativecommons.org/licenses/by/4.0/"}