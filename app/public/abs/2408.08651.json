{"id":"2408.08651","title":"Reasoning Beyond Bias: A Study on Counterfactual Prompting and Chain of\n  Thought Reasoning","authors":"Kyle Moore, Jesse Roberts, Thao Pham, Douglas Fisher","authorsParsed":[["Moore","Kyle",""],["Roberts","Jesse",""],["Pham","Thao",""],["Fisher","Douglas",""]],"versions":[{"version":"v1","created":"Fri, 16 Aug 2024 10:34:50 GMT"},{"version":"v2","created":"Fri, 6 Sep 2024 01:52:02 GMT"}],"updateDate":"2024-09-09","timestamp":1723804490000,"abstract":"  Language models are known to absorb biases from their training data, leading\nto predictions driven by statistical regularities rather than semantic\nrelevance. We investigate the impact of these biases on answer choice\npreferences in the Massive Multi-Task Language Understanding (MMLU) task. Our\nfindings reveal that differences in learned regularities across answer options\nare predictive of model preferences and mirror human test-taking strategies. To\naddress this issue, we introduce two novel methods: Counterfactual Prompting\nwith Chain of Thought (CoT) and Counterfactual Prompting with Agnostically\nPrimed CoT (APriCoT). We demonstrate that while Counterfactual Prompting with\nCoT alone is insufficient to mitigate bias, our novel Primed Counterfactual\nPrompting with CoT approach effectively reduces the influence of base-rate\nprobabilities while improving overall accuracy. Our results suggest that\nmitigating bias requires a \"System-2\" like process and that CoT reasoning is\nsusceptible to confirmation bias under some prompting methodologies. Our\ncontributions offer practical solutions for developing more robust and fair\nlanguage models.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/"}