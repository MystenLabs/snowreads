{"id":"2408.04477","title":"What You Need is What You Get: Theory of Mind for an LLM-Based Code\n  Understanding Assistant","authors":"Jonan Richards, Mairieli Wessel","authorsParsed":[["Richards","Jonan",""],["Wessel","Mairieli",""]],"versions":[{"version":"v1","created":"Thu, 8 Aug 2024 14:08:15 GMT"}],"updateDate":"2024-08-09","timestamp":1723126095000,"abstract":"  A growing number of tools have used Large Language Models (LLMs) to support\ndevelopers' code understanding. However, developers still face several barriers\nto using such tools, including challenges in describing their intent in natural\nlanguage, interpreting the tool outcome, and refining an effective prompt to\nobtain useful information. In this study, we designed an LLM-based\nconversational assistant that provides a personalized interaction based on\ninferred user mental state (e.g., background knowledge and experience). We\nevaluate the approach in a within-subject study with fourteen novices to\ncapture their perceptions and preferences. Our results provide insights for\nresearchers and tool builders who want to create or improve LLM-based\nconversational assistants to support novices in code understanding.\n","subjects":["Computing Research Repository/Software Engineering"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"2OcutFGEsahkwpIr3HyPJ_peZAJxbBsJJKm2kGlumwU","pdfSize":"651486"}
