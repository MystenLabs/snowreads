{"id":"2407.07237","title":"The Quantum Imitation Game: Reverse Engineering of Quantum Machine\n  Learning Models","authors":"Archisman Ghosh, Swaroop Ghosh","authorsParsed":[["Ghosh","Archisman",""],["Ghosh","Swaroop",""]],"versions":[{"version":"v1","created":"Tue, 9 Jul 2024 21:35:19 GMT"},{"version":"v2","created":"Mon, 15 Jul 2024 14:27:14 GMT"}],"updateDate":"2024-07-16","timestamp":1720560919000,"abstract":"  Quantum Machine Learning (QML) amalgamates quantum computing paradigms with\nmachine learning models, providing significant prospects for solving complex\nproblems. However, with the expansion of numerous third-party vendors in the\nNoisy Intermediate-Scale Quantum (NISQ) era of quantum computing, the security\nof QML models is of prime importance, particularly against reverse engineering,\nwhich could expose trained parameters and algorithms of the models. We assume\nthe untrusted quantum cloud provider is an adversary having white-box access to\nthe transpiled user-designed trained QML model during inference. Reverse\nengineering (RE) to extract the pre-transpiled QML circuit will enable\nre-transpilation and usage of the model for various hardware with completely\ndifferent native gate sets and even different qubit technology. Such\nflexibility may not be obtained from the transpiled circuit which is tied to a\nparticular hardware and qubit technology. The information about the number of\nparameters, and optimized values can allow further training of the QML model to\nalter the QML model, tamper with the watermark, and/or embed their own\nwatermark or refine the model for other purposes. In this first effort to\ninvestigate the RE of QML circuits, we perform RE and compare the training\naccuracy of original and reverse-engineered Quantum Neural Networks (QNNs) of\nvarious sizes. We note that multi-qubit classifiers can be reverse-engineered\nunder specific conditions with a mean error of order 1e-2 in a reasonable time.\nWe also propose adding dummy fixed parametric gates in the QML models to\nincrease the RE overhead for defense. For instance, adding 2 dummy qubits and 2\nlayers increases the overhead by ~1.76 times for a classifier with 2 qubits and\n3 layers with a performance overhead of less than 9%. We note that RE is a very\npowerful attack model which warrants further efforts on defenses.\n","subjects":["Physics/Quantum Physics","Computing Research Repository/Cryptography and Security","Computing Research Repository/Emerging Technologies","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"Mgki_2JTWNwR5lcPsj4I6lu9Isn4gb1Ca6wc61zbcek","pdfSize":"1150863"}
