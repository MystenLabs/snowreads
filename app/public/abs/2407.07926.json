{"id":"2407.07926","title":"Synthetic Data: Revisiting the Privacy-Utility Trade-off","authors":"Fatima Jahan Sarmin, Atiquer Rahman Sarkar, Yang Wang, Noman Mohammed","authorsParsed":[["Sarmin","Fatima Jahan",""],["Sarkar","Atiquer Rahman",""],["Wang","Yang",""],["Mohammed","Noman",""]],"versions":[{"version":"v1","created":"Tue, 9 Jul 2024 14:48:43 GMT"}],"updateDate":"2024-07-12","timestamp":1720536523000,"abstract":"  Synthetic data has been considered a better privacy-preserving alternative to\ntraditionally sanitized data across various applications. However, a recent\narticle challenges this notion, stating that synthetic data does not provide a\nbetter trade-off between privacy and utility than traditional anonymization\ntechniques, and that it leads to unpredictable utility loss and highly\nunpredictable privacy gain. The article also claims to have identified a breach\nin the differential privacy guarantees provided by PATEGAN and PrivBayes. When\na study claims to refute or invalidate prior findings, it is crucial to verify\nand validate the study. In our work, we analyzed the implementation of the\nprivacy game described in the article and found that it operated in a highly\nspecialized and constrained environment, which limits the applicability of its\nfindings to general cases. Our exploration also revealed that the game did not\nsatisfy a crucial precondition concerning data distributions, which contributed\nto the perceived violation of the differential privacy guarantees offered by\nPATEGAN and PrivBayes. We also conducted a privacy-utility trade-off analysis\nin a more general and unconstrained environment. Our experimentation\ndemonstrated that synthetic data achieves a more favorable privacy-utility\ntrade-off compared to the provided implementation of k-anonymization, thereby\nreaffirming earlier conclusions.\n","subjects":["Computing Research Repository/Cryptography and Security","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}