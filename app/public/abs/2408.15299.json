{"id":"2408.15299","title":"TourSynbio: A Multi-Modal Large Model and Agent Framework to Bridge Text\n  and Protein Sequences for Protein Engineering","authors":"Yiqing Shen, Zan Chen, Michail Mamalakis, Yungeng Liu, Tianbin Li,\n  Yanzhou Su, Junjun He, Pietro Li\\`o, Yu Guang Wang","authorsParsed":[["Shen","Yiqing",""],["Chen","Zan",""],["Mamalakis","Michail",""],["Liu","Yungeng",""],["Li","Tianbin",""],["Su","Yanzhou",""],["He","Junjun",""],["Li√≤","Pietro",""],["Wang","Yu Guang",""]],"versions":[{"version":"v1","created":"Tue, 27 Aug 2024 13:36:00 GMT"}],"updateDate":"2024-08-29","timestamp":1724765760000,"abstract":"  The structural similarities between protein sequences and natural languages\nhave led to parallel advancements in deep learning across both domains. While\nlarge language models (LLMs) have achieved much progress in the domain of\nnatural language processing, their potential in protein engineering remains\nlargely unexplored. Previous approaches have equipped LLMs with protein\nunderstanding capabilities by incorporating external protein encoders, but this\nfails to fully leverage the inherent similarities between protein sequences and\nnatural languages, resulting in sub-optimal performance and increased model\ncomplexity. To address this gap, we present TourSynbio-7B, the first\nmulti-modal large model specifically designed for protein engineering tasks\nwithout external protein encoders. TourSynbio-7B demonstrates that LLMs can\ninherently learn to understand proteins as language. The model is post-trained\nand instruction fine-tuned on InternLM2-7B using ProteinLMDataset, a dataset\ncomprising 17.46 billion tokens of text and protein sequence for\nself-supervised pretraining and 893K instructions for supervised fine-tuning.\nTourSynbio-7B outperforms GPT-4 on the ProteinLMBench, a benchmark of 944\nmanually verified multiple-choice questions, with 62.18% accuracy. Leveraging\nTourSynbio-7B's enhanced protein sequence understanding capability, we\nintroduce TourSynbio-Agent, an innovative framework capable of performing\nvarious protein engineering tasks, including mutation analysis, inverse\nfolding, protein folding, and visualization. TourSynbio-Agent integrates\npreviously disconnected deep learning models in the protein engineering domain,\noffering a unified conversational user interface for improved usability.\nFinally, we demonstrate the efficacy of TourSynbio-7B and TourSynbio-Agent\nthrough two wet lab case studies on vanilla key enzyme modification and steroid\ncompound catalysis.\n","subjects":["Quantitative Biology/Biomolecules","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"FSOIoqf05PjFj-YLselen2MmSiYnwnoYrE7DgXki7lc","pdfSize":"2146447"}
