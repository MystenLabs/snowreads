{"id":"2408.02565","title":"Reasons to Doubt the Impact of AI Risk Evaluations","authors":"Gabriel Mukobi","authorsParsed":[["Mukobi","Gabriel",""]],"versions":[{"version":"v1","created":"Mon, 5 Aug 2024 15:42:51 GMT"}],"updateDate":"2024-08-06","timestamp":1722872571000,"abstract":"  AI safety practitioners invest considerable resources in AI system\nevaluations, but these investments may be wasted if evaluations fail to realize\ntheir impact. This paper questions the core value proposition of evaluations:\nthat they significantly improve our understanding of AI risks and,\nconsequently, our ability to mitigate those risks. Evaluations may fail to\nimprove understanding in six ways, such as risks manifesting beyond the AI\nsystem or insignificant returns from evaluations compared to real-world\nobservations. Improved understanding may also not lead to better risk\nmitigation in four ways, including challenges in upholding and enforcing\ncommitments. Evaluations could even be harmful, for example, by triggering the\nweaponization of dual-use capabilities or invoking high opportunity costs for\nAI safety. This paper concludes with considerations for improving evaluation\npractices and 12 recommendations for AI labs, external evaluators, regulators,\nand academic researchers to encourage a more strategic and impactful approach\nto AI risk assessment and mitigation.\n","subjects":["Computing Research Repository/Computers and Society"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"FPmBtfJARjaXIvVekO_auq5ei9maziW5ncyksJW8UOk","pdfSize":"655399"}
