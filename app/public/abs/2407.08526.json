{"id":"2407.08526","title":"BLOS-BEV: Navigation Map Enhanced Lane Segmentation Network, Beyond Line\n  of Sight","authors":"Hang Wu, Zhenghao Zhang, Siyuan Lin, Tong Qin, Jin Pan, Qiang Zhao,\n  Chunjing Xu, Ming Yang","authorsParsed":[["Wu","Hang",""],["Zhang","Zhenghao",""],["Lin","Siyuan",""],["Qin","Tong",""],["Pan","Jin",""],["Zhao","Qiang",""],["Xu","Chunjing",""],["Yang","Ming",""]],"versions":[{"version":"v1","created":"Thu, 11 Jul 2024 14:15:48 GMT"}],"updateDate":"2024-07-12","timestamp":1720707348000,"abstract":"  Bird's-eye-view (BEV) representation is crucial for the perception function\nin autonomous driving tasks. It is difficult to balance the accuracy,\nefficiency and range of BEV representation. The existing works are restricted\nto a limited perception range within 50 meters. Extending the BEV\nrepresentation range can greatly benefit downstream tasks such as topology\nreasoning, scene understanding, and planning by offering more comprehensive\ninformation and reaction time. The Standard-Definition (SD) navigation maps can\nprovide a lightweight representation of road structure topology, characterized\nby ease of acquisition and low maintenance costs. An intuitive idea is to\ncombine the close-range visual information from onboard cameras with the beyond\nline-of-sight (BLOS) environmental priors from SD maps to realize expanded\nperceptual capabilities. In this paper, we propose BLOS-BEV, a novel BEV\nsegmentation model that incorporates SD maps for accurate beyond line-of-sight\nperception, up to 200m. Our approach is applicable to common BEV architectures\nand can achieve excellent results by incorporating information derived from SD\nmaps. We explore various feature fusion schemes to effectively integrate the\nvisual BEV representations and semantic features from the SD map, aiming to\nleverage the complementary information from both sources optimally. Extensive\nexperiments demonstrate that our approach achieves state-of-the-art performance\nin BEV segmentation on nuScenes and Argoverse benchmark. Through multi-modal\ninputs, BEV segmentation is significantly enhanced at close ranges below 50m,\nwhile also demonstrating superior performance in long-range scenarios,\nsurpassing other methods by over 20% mIoU at distances ranging from 50-200m.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}