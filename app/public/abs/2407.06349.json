{"id":"2407.06349","title":"Large Language Model Recall Uncertainty is Modulated by the Fan Effect","authors":"Jesse Roberts, Kyle Moore, Thao Pham, Oseremhen Ewaleifoh, Doug Fisher","authorsParsed":[["Roberts","Jesse",""],["Moore","Kyle",""],["Pham","Thao",""],["Ewaleifoh","Oseremhen",""],["Fisher","Doug",""]],"versions":[{"version":"v1","created":"Mon, 8 Jul 2024 19:40:50 GMT"}],"updateDate":"2024-07-10","timestamp":1720467650000,"abstract":"  This paper evaluates whether large language models (LLMs) exhibit cognitive\nfan effects, similar to those discovered by Anderson in humans, after being\npre-trained on human textual data. We conduct two sets of in-context recall\nexperiments designed to elicit fan effects. Consistent with human results, we\nfind that LLM recall uncertainty, measured via token probability, is influenced\nby the fan effect. Our results show that removing uncertainty disrupts the\nobserved effect. The experiments suggest the fan effect is consistent whether\nthe fan value is induced in-context or in the pre-training data. Finally, these\nfindings provide in-silico evidence that fan effects and typicality are\nexpressions of the same phenomena.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by-sa/4.0/","blobId":"ct7Cz0FPtkKolA0dZjMQt37JQc837KJAV29v8qu4Xm4","pdfSize":"552299"}
