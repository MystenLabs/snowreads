{"id":"2407.16312","title":"MOMAland: A Set of Benchmarks for Multi-Objective Multi-Agent\n  Reinforcement Learning","authors":"Florian Felten, Umut Ucak, Hicham Azmani, Gao Peng, Willem R\\\"opke,\n  Hendrik Baier, Patrick Mannion, Diederik M. Roijers, Jordan K. Terry,\n  El-Ghazali Talbi, Gr\\'egoire Danoy, Ann Now\\'e, Roxana R\\u{a}dulescu","authorsParsed":[["Felten","Florian",""],["Ucak","Umut",""],["Azmani","Hicham",""],["Peng","Gao",""],["Röpke","Willem",""],["Baier","Hendrik",""],["Mannion","Patrick",""],["Roijers","Diederik M.",""],["Terry","Jordan K.",""],["Talbi","El-Ghazali",""],["Danoy","Grégoire",""],["Nowé","Ann",""],["Rădulescu","Roxana",""]],"versions":[{"version":"v1","created":"Tue, 23 Jul 2024 09:05:06 GMT"}],"updateDate":"2024-07-24","timestamp":1721725506000,"abstract":"  Many challenging tasks such as managing traffic systems, electricity grids,\nor supply chains involve complex decision-making processes that must balance\nmultiple conflicting objectives and coordinate the actions of various\nindependent decision-makers (DMs). One perspective for formalising and\naddressing such tasks is multi-objective multi-agent reinforcement learning\n(MOMARL). MOMARL broadens reinforcement learning (RL) to problems with multiple\nagents each needing to consider multiple objectives in their learning process.\nIn reinforcement learning research, benchmarks are crucial in facilitating\nprogress, evaluation, and reproducibility. The significance of benchmarks is\nunderscored by the existence of numerous benchmark frameworks developed for\nvarious RL paradigms, including single-agent RL (e.g., Gymnasium), multi-agent\nRL (e.g., PettingZoo), and single-agent multi-objective RL (e.g.,\nMO-Gymnasium). To support the advancement of the MOMARL field, we introduce\nMOMAland, the first collection of standardised environments for multi-objective\nmulti-agent reinforcement learning. MOMAland addresses the need for\ncomprehensive benchmarking in this emerging field, offering over 10 diverse\nenvironments that vary in the number of agents, state representations, reward\nstructures, and utility considerations. To provide strong baselines for future\nresearch, MOMAland also includes algorithms capable of learning policies in\nsuch settings.\n","subjects":["Computing Research Repository/Multiagent Systems","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computer Science and Game Theory"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}