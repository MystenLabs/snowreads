{"id":"2407.14643","title":"Double-Layer Soft Data Fusion for Indoor Robot WiFi-Visual Localization","authors":"Yuehua Ding, Jean-Francois Dollinger, Vincent Vauchey, Mourad Zghal","authorsParsed":[["Ding","Yuehua",""],["Dollinger","Jean-Francois",""],["Vauchey","Vincent",""],["Zghal","Mourad",""]],"versions":[{"version":"v1","created":"Fri, 19 Jul 2024 19:40:15 GMT"}],"updateDate":"2024-07-23","timestamp":1721418015000,"abstract":"  This paper presents a novel WiFi-Visual data fusion method for indoor robot\n(TIAGO++) localization. This method can use 10 WiFi samples and 4\nlow-resolution images ($58 \\times 58$ in pixels) to localize a indoor robot\nwith an average error distance about 1.32 meters. The experiment test is 3\nmonths after the data collection in a general teaching building, whose WiFi and\nvisual environments are partially changed. This indirectly shows the robustness\nof the proposed method.\n  Instead of neural network design, this paper focuses on the soft data fusion\nto prevent unbounded errors in visual localization. A double-layer soft data\nfusion is proposed. The proposed soft data fusion includes the first-layer\nWiFi-Visual feature fusion and the second-layer decision vector fusion.\nFirstly, motivated by the excellent capability of neural network in image\nprocessing and recognition, the temporal-spatial features are extracted from\nWiFi data, these features are represented in image form. Secondly, the WiFi\ntemporal-spatial features in image form and the visual features taken by the\nrobot camera are combined together, and are jointly exploited by a\nclassification neural network to produce a likelihood vector for WiFi-Visual\nlocalization. This is called first-layer WiFi-Visual fusion. Similarly, these\ntwo types of features can exploited separately by neural networks to produce\nanother two independent likelihood vectors. Thirdly, the three likelihood\nvectors are fused by Hadamard product and median filtering to produce the final\nlikelihood vector for localization. This called the second-layer decision\nvector fusion. The proposed soft data fusion does not apply any threshold or\nprioritize any data source over the other in the fusion process. It never\nexcludes the positions of low probabilities, which can avoid the information\nloss due to a hard decision. The demo video is provided. The code will be open.\n","subjects":["Computing Research Repository/Robotics"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}