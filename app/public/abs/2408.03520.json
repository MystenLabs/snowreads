{"id":"2408.03520","title":"AirSLAM: An Efficient and Illumination-Robust Point-Line Visual SLAM\n  System","authors":"Kuan Xu, Yuefan Hao, Shenghai Yuan, Chen Wang, Lihua Xie","authorsParsed":[["Xu","Kuan",""],["Hao","Yuefan",""],["Yuan","Shenghai",""],["Wang","Chen",""],["Xie","Lihua",""]],"versions":[{"version":"v1","created":"Wed, 7 Aug 2024 03:08:57 GMT"},{"version":"v2","created":"Wed, 18 Sep 2024 07:23:41 GMT"}],"updateDate":"2024-09-19","timestamp":1723000137000,"abstract":"  In this paper, we present an efficient visual SLAM system designed to tackle\nboth short-term and long-term illumination challenges. Our system adopts a\nhybrid approach that combines deep learning techniques for feature detection\nand matching with traditional backend optimization methods. Specifically, we\npropose a unified convolutional neural network (CNN) that simultaneously\nextracts keypoints and structural lines. These features are then associated,\nmatched, triangulated, and optimized in a coupled manner. Additionally, we\nintroduce a lightweight relocalization pipeline that reuses the built map,\nwhere keypoints, lines, and a structure graph are used to match the query frame\nwith the map. To enhance the applicability of the proposed system to real-world\nrobots, we deploy and accelerate the feature detection and matching networks\nusing C++ and NVIDIA TensorRT. Extensive experiments conducted on various\ndatasets demonstrate that our system outperforms other state-of-the-art visual\nSLAM systems in illumination-challenging environments. Efficiency evaluations\nshow that our system can run at a rate of 73Hz on a PC and 40Hz on an embedded\nplatform.\n","subjects":["Computing Research Repository/Robotics"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}