{"id":"2408.09140","title":"Learning to Explore for Stochastic Gradient MCMC","authors":"SeungHyun Kim, Seohyeon Jung, Seonghyeon Kim, Juho Lee","authorsParsed":[["Kim","SeungHyun",""],["Jung","Seohyeon",""],["Kim","Seonghyeon",""],["Lee","Juho",""]],"versions":[{"version":"v1","created":"Sat, 17 Aug 2024 08:36:42 GMT"}],"updateDate":"2024-08-20","timestamp":1723883802000,"abstract":"  Bayesian Neural Networks(BNNs) with high-dimensional parameters pose a\nchallenge for posterior inference due to the multi-modality of the posterior\ndistributions. Stochastic Gradient MCMC(SGMCMC) with cyclical learning rate\nscheduling is a promising solution, but it requires a large number of sampling\nsteps to explore high-dimensional multi-modal posteriors, making it\ncomputationally expensive. In this paper, we propose a meta-learning strategy\nto build \\gls{sgmcmc} which can efficiently explore the multi-modal target\ndistributions. Our algorithm allows the learned SGMCMC to quickly explore the\nhigh-density region of the posterior landscape. Also, we show that this\nexploration property is transferrable to various tasks, even for the ones\nunseen during a meta-training stage. Using popular image classification\nbenchmarks and a variety of downstream tasks, we demonstrate that our method\nsignificantly improves the sampling efficiency, achieving better performance\nthan vanilla \\gls{sgmcmc} without incurring significant computational overhead.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"8LTuYmByuuOD9kW0u4creEDI4aSHXR0AEW2K0i4qQrw","pdfSize":"4150772"}
