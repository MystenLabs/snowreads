{"id":"2407.12113","title":"A Graph-based Adversarial Imitation Learning Framework for Reliable &\n  Realtime Fleet Scheduling in Urban Air Mobility","authors":"Prithvi Poddar, Steve Paul, Souma Chowdhury","authorsParsed":[["Poddar","Prithvi",""],["Paul","Steve",""],["Chowdhury","Souma",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 18:51:24 GMT"},{"version":"v2","created":"Thu, 5 Sep 2024 17:01:33 GMT"}],"updateDate":"2024-09-06","timestamp":1721155884000,"abstract":"  The advent of Urban Air Mobility (UAM) presents the scope for a\ntransformative shift in the domain of urban transportation. However, its\nwidespread adoption and economic viability depends in part on the ability to\noptimally schedule the fleet of aircraft across vertiports in a UAM network,\nunder uncertainties attributed to airspace congestion, changing weather\nconditions, and varying demands. This paper presents a comprehensive\noptimization formulation of the fleet scheduling problem, while also\nidentifying the need for alternate solution approaches, since directly solving\nthe resulting integer nonlinear programming problem is computationally\nprohibitive for daily fleet scheduling. Previous work has shown the\neffectiveness of using (graph) reinforcement learning (RL) approaches to train\nreal-time executable policy models for fleet scheduling. However, such policies\ncan often be brittle on out-of-distribution scenarios or edge cases. Moreover,\ntraining performance also deteriorates as the complexity (e.g., number of\nconstraints) of the problem increases. To address these issues, this paper\npresents an imitation learning approach where the RL-based policy exploits\nexpert demonstrations yielded by solving the exact optimization using a Genetic\nAlgorithm. The policy model comprises Graph Neural Network (GNN) based encoders\nthat embed the space of vertiports and aircraft, Transformer networks to encode\ndemand, passenger fare, and transport cost profiles, and a Multi-head attention\n(MHA) based decoder. Expert demonstrations are used through the Generative\nAdversarial Imitation Learning (GAIL) algorithm. Interfaced with a UAM\nsimulation environment involving 8 vertiports and 40 aircrafts, in terms of the\ndaily profits earned reward, the new imitative approach achieves better mean\nperformance and remarkable improvement in the case of unseen worst-case\nscenarios, compared to pure RL results.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Multiagent Systems"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}