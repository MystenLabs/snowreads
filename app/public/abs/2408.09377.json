{"id":"2408.09377","title":"Mutual Information Multinomial Estimation","authors":"Yanzhi Chen, Zijing Ou, Adrian Weller, Yingzhen Li","authorsParsed":[["Chen","Yanzhi",""],["Ou","Zijing",""],["Weller","Adrian",""],["Li","Yingzhen",""]],"versions":[{"version":"v1","created":"Sun, 18 Aug 2024 06:27:30 GMT"}],"updateDate":"2024-08-20","timestamp":1723962450000,"abstract":"  Estimating mutual information (MI) is a fundamental yet challenging task in\ndata science and machine learning. This work proposes a new estimator for\nmutual information. Our main discovery is that a preliminary estimate of the\ndata distribution can dramatically help estimate. This preliminary estimate\nserves as a bridge between the joint and the marginal distribution, and by\ncomparing with this bridge distribution we can easily obtain the true\ndifference between the joint distributions and the marginal distributions.\nExperiments on diverse tasks including non-Gaussian synthetic problems with\nknown ground-truth and real-world applications demonstrate the advantages of\nour method.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Information Theory","Mathematics/Information Theory","Statistics/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}