{"id":"2408.03404","title":"Set2Seq Transformer: Learning Permutation Aware Set Representations of\n  Artistic Sequences","authors":"Athanasios Efthymiou, Stevan Rudinac, Monika Kackovic, Nachoem\n  Wijnberg and Marcel Worring","authorsParsed":[["Efthymiou","Athanasios",""],["Rudinac","Stevan",""],["Kackovic","Monika",""],["Wijnberg","Nachoem",""],["Worring","Marcel",""]],"versions":[{"version":"v1","created":"Tue, 6 Aug 2024 18:55:31 GMT"}],"updateDate":"2024-08-08","timestamp":1722970531000,"abstract":"  We propose Set2Seq Transformer, a novel sequential multiple instance\narchitecture, that learns to rank permutation aware set representations of\nsequences. First, we illustrate that learning temporal position-aware\nrepresentations of discrete timesteps can greatly improve static visual\nmultiple instance learning methods that do not regard temporality and\nconcentrate almost exclusively on visual content analysis. We further\ndemonstrate the significant advantages of end-to-end sequential multiple\ninstance learning, integrating visual content and temporal information in a\nmultimodal manner. As application we focus on fine art analysis related tasks.\nTo that end, we show that our Set2Seq Transformer can leverage visual set and\ntemporal position-aware representations for modelling visual artists' oeuvres\nfor predicting artistic success. Finally, through extensive quantitative and\nqualitative evaluation using a novel dataset, WikiArt-Seq2Rank, and a visual\nlearning-to-rank downstream task, we show that our Set2Seq Transformer captures\nessential temporal information improving the performance of strong static and\nsequential multiple instance learning methods for predicting artistic success.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}