{"id":"2408.08192","title":"Stochastic Semi-Gradient Descent for Learning Mean Field Games with\n  Population-Aware Function Approximation","authors":"Chenyu Zhang, Xu Chen, Xuan Di","authorsParsed":[["Zhang","Chenyu",""],["Chen","Xu",""],["Di","Xuan",""]],"versions":[{"version":"v1","created":"Thu, 15 Aug 2024 14:51:50 GMT"}],"updateDate":"2024-08-16","timestamp":1723733510000,"abstract":"  Mean field games (MFGs) model the interactions within a large-population\nmulti-agent system using the population distribution. Traditional learning\nmethods for MFGs are based on fixed-point iteration (FPI), which calculates\nbest responses and induced population distribution separately and sequentially.\nHowever, FPI-type methods suffer from inefficiency and instability, due to\noscillations caused by the forward-backward procedure. This paper considers an\nonline learning method for MFGs, where an agent updates its policy and\npopulation estimates simultaneously and fully asynchronously, resulting in a\nsimple stochastic gradient descent (SGD) type method called SemiSGD. Not only\ndoes SemiSGD exhibit numerical stability and efficiency, but it also provides a\nnovel perspective by treating the value function and population distribution as\na unified parameter. We theoretically show that SemiSGD directs this unified\nparameter along a descent direction to the mean field equilibrium. Motivated by\nthis perspective, we develop a linear function approximation (LFA) for both the\nvalue function and the population distribution, resulting in the first\npopulation-aware LFA for MFGs on continuous state-action space. Finite-time\nconvergence and approximation error analysis are provided for SemiSGD equipped\nwith population-aware LFA.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Computer Science and Game Theory","Computing Research Repository/Multiagent Systems","Mathematics/Optimization and Control"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}