{"id":"2407.05760","title":"Dirichlet process mixture model based on topologically augmented signal\n  representation for clustering infant vocalizations","authors":"Guillem Bonafos and Clara Bourot and Pierre Pudlo and Jean-Marc\n  Freyermuth and Laurence Reboul and Samuel Tron\\c{c}on and Arnaud Rey","authorsParsed":[["Bonafos","Guillem",""],["Bourot","Clara",""],["Pudlo","Pierre",""],["Freyermuth","Jean-Marc",""],["Reboul","Laurence",""],["Tron√ßon","Samuel",""],["Rey","Arnaud",""]],"versions":[{"version":"v1","created":"Mon, 8 Jul 2024 09:12:52 GMT"}],"updateDate":"2024-09-06","timestamp":1720429972000,"abstract":"  Based on audio recordings made once a month during the first 12 months of a\nchild's life, we propose a new method for clustering this set of vocalizations.\nWe use a topologically augmented representation of the vocalizations, employing\ntwo persistence diagrams for each vocalization: one computed on the surface of\nits spectrogram and one on the Takens' embeddings of the vocalization. A\nsynthetic persistent variable is derived for each diagram and added to the\nMFCCs (Mel-frequency cepstral coefficients). Using this representation, we fit\na non-parametric Bayesian mixture model with a Dirichlet process prior to model\nthe number of components. This procedure leads to a novel data-driven\ncategorization of vocal productions. Our findings reveal the presence of 8\nclusters of vocalizations, allowing us to compare their temporal distribution\nand acoustic profiles in the first 12 months of life.\n","subjects":["Statistics/Applications","Computing Research Repository/Sound","Electrical Engineering and Systems Science/Audio and Speech Processing","Statistics/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"jTsMCiYcrw5rFw9AIv8g1IA5s-xZCMhLRr-U2pthemE","pdfSize":"329757"}
