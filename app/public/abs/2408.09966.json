{"id":"2408.09966","title":"Mask in the Mirror: Implicit Sparsification","authors":"Tom Jacobs and Rebekka Burkholz","authorsParsed":[["Jacobs","Tom",""],["Burkholz","Rebekka",""]],"versions":[{"version":"v1","created":"Mon, 19 Aug 2024 13:14:02 GMT"}],"updateDate":"2024-08-20","timestamp":1724073242000,"abstract":"  Sparsifying deep neural networks to reduce their inference cost is an NP-hard\nproblem and difficult to optimize due to its mixed discrete and continuous\nnature. Yet, as we prove, continuous sparsification has already an implicit\nbias towards sparsity that would not require common projections of relaxed mask\nvariables. While implicit rather than explicit regularization induces benefits,\nit usually does not provide enough flexibility in practice, as only a specific\ntarget sparsity is obtainable. To exploit its potential for continuous\nsparsification, we propose a way to control the strength of the implicit bias.\nBased on the mirror flow framework, we derive resulting convergence and\noptimality guarantees in the context of underdetermined linear regression and\ndemonstrate the utility of our insights in more general neural network\nsparsification experiments, achieving significant performance gains,\nparticularly in the high-sparsity regime. Our theoretical contribution might be\nof independent interest, as we highlight a way to enter the rich regime and\nshow that implicit bias is controllable by a time-dependent Bregman potential.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}