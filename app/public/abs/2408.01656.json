{"id":"2408.01656","title":"Deep Reinforcement Learning for Dynamic Order Picking in Warehouse\n  Operations","authors":"Sasan Mahmoudinazlou, Abhay Sobhanan, Hadi Charkhgard, Ali Eshragh,\n  George Dunn","authorsParsed":[["Mahmoudinazlou","Sasan",""],["Sobhanan","Abhay",""],["Charkhgard","Hadi",""],["Eshragh","Ali",""],["Dunn","George",""]],"versions":[{"version":"v1","created":"Sat, 3 Aug 2024 03:56:46 GMT"}],"updateDate":"2024-08-06","timestamp":1722657406000,"abstract":"  Order picking is a crucial operation in warehouses that significantly impacts\noverall efficiency and profitability. This study addresses the dynamic order\npicking problem, a significant concern in modern warehouse management where\nreal-time adaptation to fluctuating order arrivals and efficient picker routing\nare crucial. Traditional methods, often assuming fixed order sets, fall short\nin this dynamic environment. We utilize Deep Reinforcement Learning (DRL) as a\nsolution methodology to handle the inherent uncertainties in customer demands.\nWe focus on a single-block warehouse with an autonomous picking device,\neliminating human behavioral factors. Our DRL framework enables the dynamic\noptimization of picker routes, significantly reducing order throughput times,\nespecially under high order arrival rates. Experiments demonstrate a\nsubstantial decrease in order throughput time and unfulfilled orders compared\nto benchmark algorithms. We further investigate integrating a hyperparameter in\nthe reward function that allows for flexible balancing between distance\ntraveled and order completion time. Finally, we demonstrate the robustness of\nour DRL model for out-of-sample test instances.\n","subjects":["Mathematics/Optimization and Control","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}