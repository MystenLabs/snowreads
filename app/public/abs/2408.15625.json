{"id":"2408.15625","title":"CBF-LLM: Safe Control for LLM Alignment","authors":"Yuya Miyaoka, Masaki Inoue","authorsParsed":[["Miyaoka","Yuya",""],["Inoue","Masaki",""]],"versions":[{"version":"v1","created":"Wed, 28 Aug 2024 08:25:22 GMT"}],"updateDate":"2024-08-29","timestamp":1724833522000,"abstract":"  This paper proposes a control-based framework for aligning large language\nmodels (LLMs) by leveraging a control barrier function (CBF) to ensure\nuser-desirable text generation. The presented framework applies the safety\nfilter, designed based on the CBF, to the output generation of the baseline\nLLM, i.e., the sequence of the token, with the aim of intervening in the\ngenerated text. The overall text-generation system is implemented with Llama 3\nand a RoBERTa model, and the source code is available at\nhttps://github.com/Mya-Mya/CBF-LLM. The experiment demonstrates its control\nability and effectiveness in reducing the number of interventions needed for\nuser-specified alignment tasks.\n","subjects":["Electrical Engineering and Systems Science/Systems and Control","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language","Computing Research Repository/Systems and Control"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/"}