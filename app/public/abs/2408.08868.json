{"id":"2408.08868","title":"A Hassle-free Algorithm for Private Learning in Practice: Don't Use Tree\n  Aggregation, Use BLTs","authors":"H. Brendan McMahan, Zheng Xu, Yanxiang Zhang","authorsParsed":[["McMahan","H. Brendan",""],["Xu","Zheng",""],["Zhang","Yanxiang",""]],"versions":[{"version":"v1","created":"Fri, 16 Aug 2024 17:52:22 GMT"}],"updateDate":"2024-08-19","timestamp":1723830742000,"abstract":"  The state-of-the-art for training on-device language models for mobile\nkeyboard applications combines federated learning (FL) with differential\nprivacy (DP) via the DP-Follow-the-Regularized-Leader (DP-FTRL) algorithm. Two\nvariants of DP-FTRL are used in practice, tree aggregation and matrix\nfactorization. However, tree aggregation suffers from significantly suboptimal\nprivacy/utility tradeoffs, while matrix mechanisms require expensive\noptimization parameterized by hard-to-estimate-in-advance constants, and high\nruntime memory costs.This paper extends the recently introduced Buffered Linear\nToeplitz (BLT) mechanism to multi-participation scenarios. Our BLT-DP-FTRL\nmaintains the ease-of-use advantages of tree aggregation, while essentially\nmatching matrix factorization in terms of utility and privacy. We evaluate\nBLT-DP-FTRL on the StackOverflow dataset, serving as a re-producible simulation\nbenchmark, and across four on-device language model tasks in a production FL\nsystem. Our empirical results highlight the advantages of the BLT mechanism and\nelevate the practicality and effectiveness of DP in real-world scenarios.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}