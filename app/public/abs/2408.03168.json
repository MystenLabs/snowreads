{"id":"2408.03168","title":"Training on the Fly: On-device Self-supervised Learning aboard\n  Nano-drones within 20 mW","authors":"Elia Cereda and Alessandro Giusti and Daniele Palossi","authorsParsed":[["Cereda","Elia",""],["Giusti","Alessandro",""],["Palossi","Daniele",""]],"versions":[{"version":"v1","created":"Tue, 6 Aug 2024 13:11:36 GMT"}],"updateDate":"2024-08-07","timestamp":1722949896000,"abstract":"  Miniaturized cyber-physical systems (CPSes) powered by tiny machine learning\n(TinyML), such as nano-drones, are becoming an increasingly attractive\ntechnology. Their small form factor (i.e., ~10cm diameter) ensures vast\napplicability, ranging from the exploration of narrow disaster scenarios to\nsafe human-robot interaction. Simple electronics make these CPSes inexpensive,\nbut strongly limit the computational, memory, and sensing resources available\non board. In real-world applications, these limitations are further exacerbated\nby domain shift. This fundamental machine learning problem implies that model\nperception performance drops when moving from the training domain to a\ndifferent deployment one. To cope with and mitigate this general problem, we\npresent a novel on-device fine-tuning approach that relies only on the limited\nultra-low power resources available aboard nano-drones. Then, to overcome the\nlack of ground-truth training labels aboard our CPS, we also employ a\nself-supervised method based on ego-motion consistency. Albeit our work builds\non top of a specific real-world vision-based human pose estimation task, it is\nwidely applicable for many embedded TinyML use cases. Our 512-image on-device\ntraining procedure is fully deployed aboard an ultra-low power GWT GAP9\nSystem-on-Chip and requires only 1MB of memory while consuming as low as 19mW\nor running in just 510ms (at 38mW). Finally, we demonstrate the benefits of our\non-device learning approach by field-testing our closed-loop CPS, showing a\nreduction in horizontal position error of up to 26% vs. a non-fine-tuned\nstate-of-the-art baseline. In the most challenging never-seen-before\nenvironment, our on-device learning procedure makes the difference between\nsucceeding or failing the mission.\n","subjects":["Computing Research Repository/Robotics","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Systems and Control","Electrical Engineering and Systems Science/Systems and Control"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}