{"id":"2408.02439","title":"Long Input Benchmark for Russian Analysis","authors":"Igor Churin, Murat Apishev, Maria Tikhonova, Denis Shevelev, Aydar\n  Bulatov, Yuri Kuratov, Sergej Averkiev, Alena Fenogenova","authorsParsed":[["Churin","Igor",""],["Apishev","Murat",""],["Tikhonova","Maria",""],["Shevelev","Denis",""],["Bulatov","Aydar",""],["Kuratov","Yuri",""],["Averkiev","Sergej",""],["Fenogenova","Alena",""]],"versions":[{"version":"v1","created":"Mon, 5 Aug 2024 12:59:35 GMT"}],"updateDate":"2024-08-06","timestamp":1722862775000,"abstract":"  Recent advancements in Natural Language Processing (NLP) have fostered the\ndevelopment of Large Language Models (LLMs) that can solve an immense variety\nof tasks. One of the key aspects of their application is their ability to work\nwith long text documents and to process long sequences of tokens. This has\ncreated a demand for proper evaluation of long-context understanding. To\naddress this need for the Russian language, we propose LIBRA (Long Input\nBenchmark for Russian Analysis), which comprises 21 adapted datasets to study\nthe LLM's abilities to understand long texts thoroughly. The tests are divided\ninto four complexity groups and allow the evaluation of models across various\ncontext lengths ranging from 4k up to 128k tokens. We provide the open-source\ndatasets, codebase, and public leaderboard for LIBRA to guide forthcoming\nresearch.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/"}