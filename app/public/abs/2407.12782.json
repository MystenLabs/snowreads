{"id":"2407.12782","title":"Contrastive Adversarial Training for Unsupervised Domain Adaptation","authors":"Jiahong Chen, Zhilin Zhang, Lucy Li, Behzad Shahrasbi, Arjun Mishra","authorsParsed":[["Chen","Jiahong",""],["Zhang","Zhilin",""],["Li","Lucy",""],["Shahrasbi","Behzad",""],["Mishra","Arjun",""]],"versions":[{"version":"v1","created":"Wed, 17 Jul 2024 17:59:21 GMT"}],"updateDate":"2024-07-18","timestamp":1721239161000,"abstract":"  Domain adversarial training has shown its effective capability for finding\ndomain invariant feature representations and been successfully adopted for\nvarious domain adaptation tasks. However, recent advances of large models\n(e.g., vision transformers) and emerging of complex adaptation scenarios (e.g.,\nDomainNet) make adversarial training being easily biased towards source domain\nand hardly adapted to target domain. The reason is twofold: relying on large\namount of labelled data from source domain for large model training and lacking\nof labelled data from target domain for fine-tuning. Existing approaches widely\nfocused on either enhancing discriminator or improving the training stability\nfor the backbone networks. Due to unbalanced competition between the feature\nextractor and the discriminator during the adversarial training, existing\nsolutions fail to function well on complex datasets. To address this issue, we\nproposed a novel contrastive adversarial training (CAT) approach that leverages\nthe labeled source domain samples to reinforce and regulate the feature\ngeneration for target domain. Typically, the regulation forces the target\nfeature distribution being similar to the source feature distribution. CAT\naddressed three major challenges in adversarial learning: 1) ensure the feature\ndistributions from two domains as indistinguishable as possible for the\ndiscriminator, resulting in a more robust domain-invariant feature generation;\n2) encourage target samples moving closer to the source in the feature space,\nreducing the requirement for generalizing classifier trained on the labeled\nsource domain to unlabeled target domain; 3) avoid directly aligning unpaired\nsource and target samples within mini-batch. CAT can be easily plugged into\nexisting models and exhibits significant performance improvements.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}