{"id":"2408.03059","title":"Learning to Turn: Diffusion Imitation for Robust Row Turning in\n  Under-Canopy Robots","authors":"Arun N. Sivakumar, Pranay Thangeda, Yixiao Fang, Mateus V. Gasparino,\n  Jose Cuaran, Melkior Ornik, Girish Chowdhary","authorsParsed":[["Sivakumar","Arun N.",""],["Thangeda","Pranay",""],["Fang","Yixiao",""],["Gasparino","Mateus V.",""],["Cuaran","Jose",""],["Ornik","Melkior",""],["Chowdhary","Girish",""]],"versions":[{"version":"v1","created":"Tue, 6 Aug 2024 09:21:46 GMT"}],"updateDate":"2024-08-07","timestamp":1722936106000,"abstract":"  Under-canopy agricultural robots require robust navigation capabilities to\nenable full autonomy but struggle with tight row turning between crop rows due\nto degraded GPS reception, visual aliasing, occlusion, and complex vehicle\ndynamics. We propose an imitation learning approach using diffusion policies to\nlearn row turning behaviors from demonstrations provided by human operators or\nprivileged controllers. Simulation experiments in a corn field environment show\npotential in learning this task with only visual observations and velocity\nstates. However, challenges remain in maintaining control within rows and\nhandling varied initial conditions, highlighting areas for future improvement.\n","subjects":["Computing Research Repository/Robotics"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/"}