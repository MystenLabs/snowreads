{"id":"2407.12822","title":"Lightweight Large Language Model for Medication Enquiry: Med-Pal","authors":"Kabilan Elangovan, Jasmine Chiat Ling Ong, Liyuan Jin, Benjamin Jun\n  Jie Seng, Yu Heng Kwan, Lit Soo Tan, Ryan Jian Zhong, Justina Koi Li Ma, YuHe\n  Ke, Nan Liu, Kathleen M Giacomini, Daniel Shu Wei Ting","authorsParsed":[["Elangovan","Kabilan",""],["Ong","Jasmine Chiat Ling",""],["Jin","Liyuan",""],["Seng","Benjamin Jun Jie",""],["Kwan","Yu Heng",""],["Tan","Lit Soo",""],["Zhong","Ryan Jian",""],["Ma","Justina Koi Li",""],["Ke","YuHe",""],["Liu","Nan",""],["Giacomini","Kathleen M",""],["Ting","Daniel Shu Wei",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 03:32:39 GMT"}],"updateDate":"2024-07-19","timestamp":1719891159000,"abstract":"  Large Language Models (LLMs) have emerged as a potential solution to assist\ndigital health development with patient education, commonly medication-related\nenquires. We trained and validated Med-Pal, a medication domain-specific\nLLM-chatbot fine-tuned with a fine-grained and expert curated dataset from a\nselection of five light-weighted open-source LLMs of smaller parameter size (7\nbillion or less) regarding computational constraints and prioritizing\noperational efficiency. A multi-disciplinary team performed a clinical\nevaluation of LLMs responses using the SCORE criteria, focusing on safety,\naccuracy, bias, reproducibility, and ease of understanding. Best performing\nlight-weighted LLM was chosen as Med-Pal for further engineering with\nguard-railing using adversarial prompting. Med-Pal and existing light-weighted\nLLMs, including pretrained Biomistral and finetuned Meerkat, were validated on\nan independent dataset on a broad range of medication-related questions (231 in\ntotal), 12 different question types across 14 different medication classes.\nMistral-7b emerged as the top performer among selected lightweight LLMs,\nachieving the highest median score of 14 and 71.9% high-quality responses in\naccuracy and safety domains, hence chosen as the backbone LLM for Med-Pal. When\ncompared against Biomistral, Med-pal outperformed in generating responses\nappropriate for patient communication, with significant reductions bias and\nerrors typical of general LLMs. Comparable performance was observed when\ncomparing Med-Pal with Meerkat. Med-Pal showcases the feasibility of developing\nand employing fine-tuned light-weighted LLMs to enhance digital health\ncommunications.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/publicdomain/zero/1.0/"}