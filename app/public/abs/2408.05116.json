{"id":"2408.05116","title":"Concept learning of parameterized quantum models from limited\n  measurements","authors":"Beng Yee Gan, Po-Wei Huang, Elies Gil-Fuster, Patrick Rebentrost","authorsParsed":[["Gan","Beng Yee",""],["Huang","Po-Wei",""],["Gil-Fuster","Elies",""],["Rebentrost","Patrick",""]],"versions":[{"version":"v1","created":"Fri, 9 Aug 2024 15:07:42 GMT"}],"updateDate":"2024-08-12","timestamp":1723216062000,"abstract":"  Classical learning of the expectation values of observables for quantum\nstates is a natural variant of learning quantum states or channels. While\nlearning-theoretic frameworks establish the sample complexity and the number of\nmeasurement shots per sample required for learning such statistical quantities,\nthe interplay between these two variables has not been adequately quantified\nbefore. In this work, we take the probabilistic nature of quantum measurements\ninto account in classical modelling and discuss these quantities under a single\nunified learning framework. We provide provable guarantees for learning\nparameterized quantum models that also quantify the asymmetrical effects and\ninterplay of the two variables on the performance of learning algorithms. These\nresults show that while increasing the sample size enhances the learning\nperformance of classical machines, even with single-shot estimates, the\nimprovements from increasing measurements become asymptotically trivial beyond\na constant factor. We further apply our framework and theoretical guarantees to\nstudy the impact of measurement noise on the classical surrogation of\nparameterized quantum circuit models. Our work provides new tools to analyse\nthe operational influence of finite measurement noise in the classical learning\nof quantum systems.\n","subjects":["Physics/Quantum Physics","Computing Research Repository/Machine Learning","Statistics/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}