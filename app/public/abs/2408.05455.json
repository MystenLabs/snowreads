{"id":"2408.05455","title":"Multimodal generative semantic communication based on latent diffusion\n  model","authors":"Weiqi Fu, Lianming Xu, Xin Wu, Haoyang Wei, Li Wang","authorsParsed":[["Fu","Weiqi",""],["Xu","Lianming",""],["Wu","Xin",""],["Wei","Haoyang",""],["Wang","Li",""]],"versions":[{"version":"v1","created":"Sat, 10 Aug 2024 06:23:41 GMT"}],"updateDate":"2024-08-13","timestamp":1723271021000,"abstract":"  In emergencies, the ability to quickly and accurately gather environmental\ndata and command information, and to make timely decisions, is particularly\ncritical. Traditional semantic communication frameworks, primarily based on a\nsingle modality, are susceptible to complex environments and lighting\nconditions, thereby limiting decision accuracy. To this end, this paper\nintroduces a multimodal generative semantic communication framework named\nmm-GESCO. The framework ingests streams of visible and infrared modal image\ndata, generates fused semantic segmentation maps, and transmits them using a\ncombination of one-hot encoding and zlib compression techniques to enhance data\ntransmission efficiency. At the receiving end, the framework can reconstruct\nthe original multimodal images based on the semantic maps. Additionally, a\nlatent diffusion model based on contrastive learning is designed to align\ndifferent modal data within the latent space, allowing mm-GESCO to reconstruct\nlatent features of any modality presented at the input. Experimental results\ndemonstrate that mm-GESCO achieves a compression ratio of up to 200 times,\nsurpassing the performance of existing semantic communication frameworks and\nexhibiting excellent performance in downstream tasks such as object\nclassification and detection.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Networking and Internet Architecture"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}