{"id":"2408.11261","title":"Towards Analyzing and Mitigating Sycophancy in Large Vision-Language\n  Models","authors":"Yunpu Zhao, Rui Zhang, Junbin Xiao, Changxin Ke, Ruibo Hou, Yifan Hao,\n  Qi Guo, Yunji Chen","authorsParsed":[["Zhao","Yunpu",""],["Zhang","Rui",""],["Xiao","Junbin",""],["Ke","Changxin",""],["Hou","Ruibo",""],["Hao","Yifan",""],["Guo","Qi",""],["Chen","Yunji",""]],"versions":[{"version":"v1","created":"Wed, 21 Aug 2024 01:03:21 GMT"}],"updateDate":"2024-08-22","timestamp":1724202201000,"abstract":"  Large Vision-Language Models (LVLMs) have shown significant capability in\nvision-language understanding. However, one critical issue that persists in\nthese models is sycophancy, which means models are unduly influenced by leading\nor deceptive prompts, resulting in biased outputs and hallucinations. Despite\nthe progress in LVLMs, evaluating and mitigating sycophancy is yet much\nunder-explored. In this work, we fill this gap by systematically analyzing\nsycophancy on various VL benchmarks with curated leading queries and further\nproposing a text contrastive decoding method for mitigation. While the specific\nsycophantic behavior varies significantly among models, our analysis reveals\nthe severe deficiency of all LVLMs in resilience of sycophancy across various\ntasks. For improvement, we propose Leading Query Contrastive Decoding (LQCD), a\nmodel-agnostic method focusing on calibrating the LVLMs' over-reliance on\nleading cues by identifying and suppressing the probabilities of sycophancy\ntokens at the decoding stage. Extensive experiments show that LQCD effectively\nmitigate sycophancy, outperforming both prompt engineering methods and common\nmethods for hallucination mitigation. We further demonstrate that LQCD does not\nhurt but even slightly improves LVLMs' responses to neutral queries, suggesting\nit being a more effective strategy for general-purpose decoding but not limited\nto sycophancy.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}