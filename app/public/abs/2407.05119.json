{"id":"2407.05119","title":"Open-Event Procedure Planning in Instructional Videos","authors":"Yilu Wu, Hanlin Wang, Jing Wang, Limin Wang","authorsParsed":[["Wu","Yilu",""],["Wang","Hanlin",""],["Wang","Jing",""],["Wang","Limin",""]],"versions":[{"version":"v1","created":"Sat, 6 Jul 2024 16:11:46 GMT"}],"updateDate":"2024-07-09","timestamp":1720282306000,"abstract":"  Given the current visual observations, the traditional procedure planning\ntask in instructional videos requires a model to generate goal-directed plans\nwithin a given action space. All previous methods for this task conduct\ntraining and inference under the same action space, and they can only plan for\npre-defined events in the training set. We argue this setting is not applicable\nfor human assistance in real lives and aim to propose a more general and\npractical planning paradigm. Specifically, in this paper, we introduce a new\ntask named Open-event Procedure Planning (OEPP), which extends the traditional\nprocedure planning to the open-event setting. OEPP aims to verify whether a\nplanner can transfer the learned knowledge to similar events that have not been\nseen during training. We rebuild a new benchmark of OpenEvent for this task\nbased on existing datasets and divide the events involved into base and novel\nparts. During the data collection process, we carefully ensure the transfer\nability of procedural knowledge for base and novel events by evaluating the\nsimilarity between the descriptions of different event steps with multiple\nstages. Based on the collected data, we further propose a simple and general\nframework specifically designed for OEPP, and conduct extensive study with\nvarious baseline methods, providing a detailed and insightful analysis on the\nresults for this task.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}