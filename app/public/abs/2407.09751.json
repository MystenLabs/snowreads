{"id":"2407.09751","title":"TASeg: Temporal Aggregation Network for LiDAR Semantic Segmentation","authors":"Xiaopei Wu, Yuenan Hou, Xiaoshui Huang, Binbin Lin, Tong He, Xinge\n  Zhu, Yuexin Ma, Boxi Wu, Haifeng Liu, Deng Cai, Wanli Ouyang","authorsParsed":[["Wu","Xiaopei",""],["Hou","Yuenan",""],["Huang","Xiaoshui",""],["Lin","Binbin",""],["He","Tong",""],["Zhu","Xinge",""],["Ma","Yuexin",""],["Wu","Boxi",""],["Liu","Haifeng",""],["Cai","Deng",""],["Ouyang","Wanli",""]],"versions":[{"version":"v1","created":"Sat, 13 Jul 2024 03:00:16 GMT"}],"updateDate":"2024-07-16","timestamp":1720839616000,"abstract":"  Training deep models for LiDAR semantic segmentation is challenging due to\nthe inherent sparsity of point clouds. Utilizing temporal data is a natural\nremedy against the sparsity problem as it makes the input signal denser.\nHowever, previous multi-frame fusion algorithms fall short in utilizing\nsufficient temporal information due to the memory constraint, and they also\nignore the informative temporal images. To fully exploit rich information\nhidden in long-term temporal point clouds and images, we present the Temporal\nAggregation Network, termed TASeg. Specifically, we propose a Temporal LiDAR\nAggregation and Distillation (TLAD) algorithm, which leverages historical\npriors to assign different aggregation steps for different classes. It can\nlargely reduce memory and time overhead while achieving higher accuracy.\nBesides, TLAD trains a teacher injected with gt priors to distill the model,\nfurther boosting the performance. To make full use of temporal images, we\ndesign a Temporal Image Aggregation and Fusion (TIAF) module, which can greatly\nexpand the camera FOV and enhance the present features. Temporal LiDAR points\nin the camera FOV are used as mediums to transform temporal image features to\nthe present coordinate for temporal multi-modal fusion. Moreover, we develop a\nStatic-Moving Switch Augmentation (SMSA) algorithm, which utilizes sufficient\ntemporal information to enable objects to switch their motion states freely,\nthus greatly increasing static and moving training samples. Our TASeg ranks 1st\non three challenging tracks, i.e., SemanticKITTI single-scan track, multi-scan\ntrack and nuScenes LiDAR segmentation track, strongly demonstrating the\nsuperiority of our method. Codes are available at\nhttps://github.com/LittlePey/TASeg.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}