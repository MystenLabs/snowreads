{"id":"2408.08766","title":"VF-NeRF: Learning Neural Vector Fields for Indoor Scene Reconstruction","authors":"Albert Gassol Puigjaner, Edoardo Mello Rella, Erik Sandstr\\\"om, Ajad\n  Chhatkuli, Luc Van Gool","authorsParsed":[["Puigjaner","Albert Gassol",""],["Rella","Edoardo Mello",""],["Sandstr√∂m","Erik",""],["Chhatkuli","Ajad",""],["Van Gool","Luc",""]],"versions":[{"version":"v1","created":"Fri, 16 Aug 2024 14:22:02 GMT"}],"updateDate":"2024-08-19","timestamp":1723818122000,"abstract":"  Implicit surfaces via neural radiance fields (NeRF) have shown surprising\naccuracy in surface reconstruction. Despite their success in reconstructing\nrichly textured surfaces, existing methods struggle with planar regions with\nweak textures, which account for the majority of indoor scenes. In this paper,\nwe address indoor dense surface reconstruction by revisiting key aspects of\nNeRF in order to use the recently proposed Vector Field (VF) as the implicit\nrepresentation. VF is defined by the unit vector directed to the nearest\nsurface point. It therefore flips direction at the surface and equals to the\nexplicit surface normals. Except for this flip, VF remains constant along\nplanar surfaces and provides a strong inductive bias in representing planar\nsurfaces. Concretely, we develop a novel density-VF relationship and a training\nscheme that allows us to learn VF via volume rendering By doing this, VF-NeRF\ncan model large planar surfaces and sharp corners accurately. We show that,\nwhen depth cues are available, our method further improves and achieves\nstate-of-the-art results in reconstructing indoor scenes and rendering novel\nviews. We extensively evaluate VF-NeRF on indoor datasets and run ablations of\nits components.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}