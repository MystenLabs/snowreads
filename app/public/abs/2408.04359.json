{"id":"2408.04359","title":"Advances in Bayesian model selection consistency for high-dimensional\n  generalized linear models","authors":"Jeyong Lee, Minwoo Chae and Ryan Martin","authorsParsed":[["Lee","Jeyong",""],["Chae","Minwoo",""],["Martin","Ryan",""]],"versions":[{"version":"v1","created":"Thu, 8 Aug 2024 10:45:42 GMT"}],"updateDate":"2024-08-09","timestamp":1723113942000,"abstract":"  Uncovering genuine relationships between a response variable of interest and\na large collection of covariates is a fundamental and practically important\nproblem. In the context of Gaussian linear models, both the Bayesian and\nnon-Bayesian literature is well-developed and there are no substantial\ndifferences in the model selection consistency results available from the two\nschools. For the more challenging generalized linear models (GLMs), however,\nBayesian model selection consistency results are lacking in several ways. In\nthis paper, we construct a Bayesian posterior distribution using an appropriate\ndata-dependent prior and develop its asymptotic concentration properties using\nnew theoretical techniques. In particular, we leverage Spokoiny's powerful\nnon-asymptotic theory to obtain sharp quadratic approximations of the GLM's\nlog-likelihood function, which leads to tight bounds on the errors associated\nwith the model-specific maximum likelihood estimators and the Laplace\napproximation of our Bayesian marginal likelihood. In turn, these improved\nbounds lead to significantly stronger, near-optimal Bayesian model selection\nconsistency results, e.g., far weaker beta-min conditions, compared to those\navailable in the existing literature. In particular, our results are applicable\nto the Poisson regression model, in which the score function is not\nsub-Gaussian.\n","subjects":["Mathematics/Statistics Theory","Statistics/Statistics Theory"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}