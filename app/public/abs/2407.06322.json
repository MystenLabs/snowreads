{"id":"2407.06322","title":"MagMax: Leveraging Model Merging for Seamless Continual Learning","authors":"Daniel Marczak, Bart{\\l}omiej Twardowski, Tomasz Trzci\\'nski,\n  Sebastian Cygert","authorsParsed":[["Marczak","Daniel",""],["Twardowski","Bartłomiej",""],["Trzciński","Tomasz",""],["Cygert","Sebastian",""]],"versions":[{"version":"v1","created":"Mon, 8 Jul 2024 18:38:52 GMT"},{"version":"v2","created":"Mon, 29 Jul 2024 22:17:31 GMT"}],"updateDate":"2024-07-31","timestamp":1720463932000,"abstract":"  This paper introduces a continual learning approach named MagMax, which\nutilizes model merging to enable large pre-trained models to continuously learn\nfrom new data without forgetting previously acquired knowledge. Distinct from\ntraditional continual learning methods that aim to reduce forgetting during\ntask training, MagMax combines sequential fine-tuning with a maximum magnitude\nweight selection for effective knowledge integration across tasks. Our initial\ncontribution is an extensive examination of model merging techniques, revealing\nthat simple approaches like weight averaging and random weight selection\nsurprisingly hold up well in various continual learning contexts. More\nimportantly, we present MagMax, a novel model-merging strategy that enables\ncontinual learning of large pre-trained models for successive tasks. Our\nthorough evaluation demonstrates the superiority of MagMax in various\nscenarios, including class- and domain-incremental learning settings. The code\nis available at this URL: https://github.com/danielm1405/magmax.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"A6CoxsB54H03unV2G39bC6kyGEanSImTq5oVK3kucOU","pdfSize":"2640129"}
