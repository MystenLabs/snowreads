{"id":"2408.14135","title":"Foodfusion: A Novel Approach for Food Image Composition via Diffusion\n  Models","authors":"Chaohua Shi, Xuan Wang, Si Shi, Xule Wang, Mingrui Zhu, Nannan Wang,\n  Xinbo Gao","authorsParsed":[["Shi","Chaohua",""],["Wang","Xuan",""],["Shi","Si",""],["Wang","Xule",""],["Zhu","Mingrui",""],["Wang","Nannan",""],["Gao","Xinbo",""]],"versions":[{"version":"v1","created":"Mon, 26 Aug 2024 09:32:16 GMT"}],"updateDate":"2024-08-27","timestamp":1724664736000,"abstract":"  Food image composition requires the use of existing dish images and\nbackground images to synthesize a natural new image, while diffusion models\nhave made significant advancements in image generation, enabling the\nconstruction of end-to-end architectures that yield promising results. However,\nexisting diffusion models face challenges in processing and fusing information\nfrom multiple images and lack access to high-quality publicly available\ndatasets, which prevents the application of diffusion models in food image\ncomposition. In this paper, we introduce a large-scale, high-quality food image\ncomposite dataset, FC22k, which comprises 22,000 foreground, background, and\nground truth ternary image pairs. Additionally, we propose a novel food image\ncomposition method, Foodfusion, which leverages the capabilities of the\npre-trained diffusion models and incorporates a Fusion Module for processing\nand integrating foreground and background information. This fused information\naligns the foreground features with the background structure by merging the\nglobal structural information at the cross-attention layer of the denoising\nUNet. To further enhance the content and structure of the background, we also\nintegrate a Content-Structure Control Module. Extensive experiments demonstrate\nthe effectiveness and scalability of our proposed method.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}