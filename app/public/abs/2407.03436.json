{"id":"2407.03436","title":"A Role of Environmental Complexity on Representation Learning in Deep\n  Reinforcement Learning Agents","authors":"Andrew Liu, Alla Borisyuk","authorsParsed":[["Liu","Andrew",""],["Borisyuk","Alla",""]],"versions":[{"version":"v1","created":"Wed, 3 Jul 2024 18:27:26 GMT"}],"updateDate":"2024-07-08","timestamp":1720031246000,"abstract":"  The environments where individuals live can present diverse navigation\nchallenges, resulting in varying navigation abilities and strategies. Inspired\nby differing urban layouts and the Dual Solutions Paradigm test used for human\nnavigators, we developed a simulated navigation environment to train deep\nreinforcement learning agents in a shortcut usage task. We modulated the\nfrequency of exposure to a shortcut and navigation cue, leading to the\ndevelopment of artificial agents with differing abilities. We examined the\nencoded representations in artificial neural networks driving these agents,\nrevealing intricate dynamics in representation learning, and correlated them\nwith shortcut use preferences. Furthermore, we demonstrated methods to analyze\nrepresentations across a population of nodes, which proved effective in finding\npatterns in what would otherwise be noisy single-node data. These techniques\nmay also have broader applications in studying neural activity. From our\nobservations in representation learning dynamics, we propose insights for human\nnavigation learning, emphasizing the importance of navigation challenges in\ndeveloping strong landmark knowledge over repeated exposures to landmarks\nalone.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}