{"id":"2408.16930","title":"VLM-KD: Knowledge Distillation from VLM for Long-Tail Visual Recognition","authors":"Zaiwei Zhang, Gregory P. Meyer, Zhichao Lu, Ashish Shrivastava,\n  Avinash Ravichandran, Eric M. Wolff","authorsParsed":[["Zhang","Zaiwei",""],["Meyer","Gregory P.",""],["Lu","Zhichao",""],["Shrivastava","Ashish",""],["Ravichandran","Avinash",""],["Wolff","Eric M.",""]],"versions":[{"version":"v1","created":"Thu, 29 Aug 2024 22:13:29 GMT"}],"updateDate":"2024-09-02","timestamp":1724969609000,"abstract":"  For visual recognition, knowledge distillation typically involves\ntransferring knowledge from a large, well-trained teacher model to a smaller\nstudent model. In this paper, we introduce an effective method to distill\nknowledge from an off-the-shelf vision-language model (VLM), demonstrating that\nit provides novel supervision in addition to those from a conventional\nvision-only teacher model. Our key technical contribution is the development of\na framework that generates novel text supervision and distills free-form text\ninto a vision encoder. We showcase the effectiveness of our approach, termed\nVLM-KD, across various benchmark datasets, showing that it surpasses several\nstate-of-the-art long-tail visual classifiers. To our knowledge, this work is\nthe first to utilize knowledge distillation with text supervision generated by\nan off-the-shelf VLM and apply it to vanilla randomly initialized vision\nencoders.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}