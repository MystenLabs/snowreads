{"id":"2408.08206","title":"WaterSplatting: Fast Underwater 3D Scene Reconstruction Using Gaussian\n  Splatting","authors":"Huapeng Li and Wenxuan Song and Tianao Xu and Alexandre Elsig and\n  Jonas Kulhanek","authorsParsed":[["Li","Huapeng",""],["Song","Wenxuan",""],["Xu","Tianao",""],["Elsig","Alexandre",""],["Kulhanek","Jonas",""]],"versions":[{"version":"v1","created":"Thu, 15 Aug 2024 15:16:49 GMT"}],"updateDate":"2024-08-16","timestamp":1723735009000,"abstract":"  The underwater 3D scene reconstruction is a challenging, yet interesting\nproblem with applications ranging from naval robots to VR experiences. The\nproblem was successfully tackled by fully volumetric NeRF-based methods which\ncan model both the geometry and the medium (water). Unfortunately, these\nmethods are slow to train and do not offer real-time rendering. More recently,\n3D Gaussian Splatting (3DGS) method offered a fast alternative to NeRFs.\nHowever, because it is an explicit method that renders only the geometry, it\ncannot render the medium and is therefore unsuited for underwater\nreconstruction. Therefore, we propose a novel approach that fuses volumetric\nrendering with 3DGS to handle underwater data effectively. Our method employs\n3DGS for explicit geometry representation and a separate volumetric field\n(queried once per pixel) for capturing the scattering medium. This dual\nrepresentation further allows the restoration of the scenes by removing the\nscattering medium. Our method outperforms state-of-the-art NeRF-based methods\nin rendering quality on the underwater SeaThru-NeRF dataset. Furthermore, it\ndoes so while offering real-time rendering performance, addressing the\nefficiency limitations of existing methods. Web:\nhttps://water-splatting.github.io\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}