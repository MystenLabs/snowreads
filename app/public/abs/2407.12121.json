{"id":"2407.12121","title":"FoodMem: Near Real-time and Precise Food Video Segmentation","authors":"Ahmad AlMughrabi, Adri\\'an Gal\\'an, Ricardo Marques, Petia Radeva","authorsParsed":[["AlMughrabi","Ahmad",""],["Galán","Adrián",""],["Marques","Ricardo",""],["Radeva","Petia",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 19:15:07 GMT"}],"updateDate":"2024-07-18","timestamp":1721157307000,"abstract":"  Food segmentation, including in videos, is vital for addressing real-world\nhealth, agriculture, and food biotechnology issues. Current limitations lead to\ninaccurate nutritional analysis, inefficient crop management, and suboptimal\nfood processing, impacting food security and public health. Improving\nsegmentation techniques can enhance dietary assessments, agricultural\nproductivity, and the food production process. This study introduces the\ndevelopment of a robust framework for high-quality, near-real-time segmentation\nand tracking of food items in videos, using minimal hardware resources. We\npresent FoodMem, a novel framework designed to segment food items from video\nsequences of 360-degree unbounded scenes. FoodMem can consistently generate\nmasks of food portions in a video sequence, overcoming the limitations of\nexisting semantic segmentation models, such as flickering and prohibitive\ninference speeds in video processing contexts. To address these issues, FoodMem\nleverages a two-phase solution: a transformer segmentation phase to create\ninitial segmentation masks and a memory-based tracking phase to monitor food\nmasks in complex scenes. Our framework outperforms current state-of-the-art\nfood segmentation models, yielding superior performance across various\nconditions, such as camera angles, lighting, reflections, scene complexity, and\nfood diversity. This results in reduced segmentation noise, elimination of\nartifacts, and completion of missing segments. Here, we also introduce a new\nannotated food dataset encompassing challenging scenarios absent in previous\nbenchmarks. Extensive experiments conducted on Nutrition5k and Vegetables &\nFruits datasets demonstrate that FoodMem enhances the state-of-the-art by 2.5%\nmean average precision in food video segmentation and is 58 x faster on\naverage.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/"}