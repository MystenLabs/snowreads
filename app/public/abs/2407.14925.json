{"id":"2407.14925","title":"When Qualitative Research Meets Large Language Model: Exploring the\n  Potential of QualiGPT as a Tool for Qualitative Coding","authors":"He Zhang, Chuhao Wu, Jingyi Xie, Fiona Rubino, Sydney Graver, ChanMin\n  Kim, John M. Carroll, Jie Cai","authorsParsed":[["Zhang","He",""],["Wu","Chuhao",""],["Xie","Jingyi",""],["Rubino","Fiona",""],["Graver","Sydney",""],["Kim","ChanMin",""],["Carroll","John M.",""],["Cai","Jie",""]],"versions":[{"version":"v1","created":"Sat, 20 Jul 2024 16:25:25 GMT"}],"updateDate":"2024-07-23","timestamp":1721492725000,"abstract":"  Qualitative research, renowned for its in-depth exploration of complex\nphenomena, often involves time-intensive analysis, particularly during the\ncoding stage. Existing software for qualitative evaluation frequently lacks\nautomatic coding capabilities, user-friendliness, and cost-effectiveness. The\nadvent of Large Language Models (LLMs) like GPT-3 and its successors marks a\ntransformative era for enhancing qualitative analysis. This paper introduces\nQualiGPT, a tool developed to address the challenges associated with using\nChatGPT for qualitative analysis. Through a comparative analysis of traditional\nmanual coding and QualiGPT's performance on both simulated and real datasets,\nincorporating both inductive and deductive coding approaches, we demonstrate\nthat QualiGPT significantly improves the qualitative analysis process. Our\nfindings show that QualiGPT enhances efficiency, transparency, and\naccessibility in qualitative coding. The tool's performance was evaluated using\ninter-rater reliability (IRR) measures, with results indicating substantial\nagreement between human coders and QualiGPT in various coding scenarios. In\naddition, we also discuss the implications of integrating AI into qualitative\nresearch workflows and outline future directions for enhancing human-AI\ncollaboration in this field.\n","subjects":["Computing Research Repository/Human-Computer Interaction"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}