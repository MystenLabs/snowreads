{"id":"2407.11325","title":"VISA: Reasoning Video Object Segmentation via Large Language Models","authors":"Cilin Yan, Haochen Wang, Shilin Yan, Xiaolong Jiang, Yao Hu, Guoliang\n  Kang, Weidi Xie, Efstratios Gavves","authorsParsed":[["Yan","Cilin",""],["Wang","Haochen",""],["Yan","Shilin",""],["Jiang","Xiaolong",""],["Hu","Yao",""],["Kang","Guoliang",""],["Xie","Weidi",""],["Gavves","Efstratios",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 02:29:29 GMT"}],"updateDate":"2024-07-17","timestamp":1721096969000,"abstract":"  Existing Video Object Segmentation (VOS) relies on explicit user\ninstructions, such as categories, masks, or short phrases, restricting their\nability to perform complex video segmentation requiring reasoning with world\nknowledge. In this paper, we introduce a new task, Reasoning Video Object\nSegmentation (ReasonVOS). This task aims to generate a sequence of segmentation\nmasks in response to implicit text queries that require complex reasoning\nabilities based on world knowledge and video contexts, which is crucial for\nstructured environment understanding and object-centric interactions, pivotal\nin the development of embodied AI. To tackle ReasonVOS, we introduce VISA\n(Video-based large language Instructed Segmentation Assistant), to leverage the\nworld knowledge reasoning capabilities of multi-modal LLMs while possessing the\nability to segment and track objects in videos with a mask decoder. Moreover,\nwe establish a comprehensive benchmark consisting of 35,074 instruction-mask\nsequence pairs from 1,042 diverse videos, which incorporates complex world\nknowledge reasoning into segmentation tasks for instruction-tuning and\nevaluation purposes of ReasonVOS models. Experiments conducted on 8 datasets\ndemonstrate the effectiveness of VISA in tackling complex reasoning\nsegmentation and vanilla referring segmentation in both video and image\ndomains. The code and dataset are available at\nhttps://github.com/cilinyan/VISA.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}