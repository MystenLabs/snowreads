{"id":"2407.18999","title":"Graph-based Unsupervised Disentangled Representation Learning via\n  Multimodal Large Language Models","authors":"Baao Xie, Qiuyu Chen, Yunnan Wang, Zequn Zhang, Xin Jin and Wenjun\n  Zeng","authorsParsed":[["Xie","Baao",""],["Chen","Qiuyu",""],["Wang","Yunnan",""],["Zhang","Zequn",""],["Jin","Xin",""],["Zeng","Wenjun",""]],"versions":[{"version":"v1","created":"Fri, 26 Jul 2024 15:32:21 GMT"}],"updateDate":"2024-07-30","timestamp":1722007941000,"abstract":"  Disentangled representation learning (DRL) aims to identify and decompose\nunderlying factors behind observations, thus facilitating data perception and\ngeneration. However, current DRL approaches often rely on the unrealistic\nassumption that semantic factors are statistically independent. In reality,\nthese factors may exhibit correlations, which off-the-shelf solutions have yet\nto properly address. To tackle this challenge, we introduce a bidirectional\nweighted graph-based framework, to learn factorized attributes and their\ninterrelations within complex data. Specifically, we propose a $\\beta$-VAE\nbased module to extract factors as the initial nodes of the graph, and leverage\nthe multimodal large language model (MLLM) to discover and rank latent\ncorrelations, thereby updating the weighted edges. By integrating these\ncomplementary modules, our model successfully achieves fine-grained, practical\nand unsupervised disentanglement. Experiments demonstrate our method's superior\nperformance in disentanglement and reconstruction. Furthermore, the model\ninherits enhanced interpretability and generalizability from MLLMs.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}