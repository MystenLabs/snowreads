{"id":"2407.05584","title":"Exploring Real-Time Music-to-Image Systems for Creative Inspiration in\n  Music Creation","authors":"Meng Yang, Maria Teresa Llano, Jon McCormack","authorsParsed":[["Yang","Meng",""],["Llano","Maria Teresa",""],["McCormack","Jon",""]],"versions":[{"version":"v1","created":"Mon, 8 Jul 2024 03:43:49 GMT"}],"updateDate":"2024-07-09","timestamp":1720410229000,"abstract":"  This paper presents a study on the use of a real-time music-to-image system\nas a mechanism to support and inspire musicians during their creative process.\nThe system takes MIDI messages from a keyboard as input which are then\ninterpreted and analysed using state-of-the-art generative AI models. Based on\nthe perceived emotion and music structure, the system's interpretation is\nconverted into visual imagery that is presented in real-time to musicians. We\nconducted a user study in which musicians improvised and composed using the\nsystem. Our findings show that most musicians found the generated images were a\nnovel mechanism when playing, evidencing the potential of music-to-image\nsystems to inspire and enhance their creative process.\n","subjects":["Computing Research Repository/Human-Computer Interaction"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}