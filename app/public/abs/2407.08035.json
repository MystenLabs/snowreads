{"id":"2407.08035","title":"FsPONER: Few-shot Prompt Optimization for Named Entity Recognition in\n  Domain-specific Scenarios","authors":"Yongjian Tang, Rakebul Hasan and Thomas Runkler","authorsParsed":[["Tang","Yongjian",""],["Hasan","Rakebul",""],["Runkler","Thomas",""]],"versions":[{"version":"v1","created":"Wed, 10 Jul 2024 20:32:50 GMT"}],"updateDate":"2024-07-12","timestamp":1720643570000,"abstract":"  Large Language Models (LLMs) have provided a new pathway for Named Entity\nRecognition (NER) tasks. Compared with fine-tuning, LLM-powered prompting\nmethods avoid the need for training, conserve substantial computational\nresources, and rely on minimal annotated data. Previous studies have achieved\ncomparable performance to fully supervised BERT-based fine-tuning approaches on\ngeneral NER benchmarks. However, none of the previous approaches has\ninvestigated the efficiency of LLM-based few-shot learning in domain-specific\nscenarios. To address this gap, we introduce FsPONER, a novel approach for\noptimizing few-shot prompts, and evaluate its performance on domain-specific\nNER datasets, with a focus on industrial manufacturing and maintenance, while\nusing multiple LLMs -- GPT-4-32K, GPT-3.5-Turbo, LLaMA 2-chat, and Vicuna.\nFsPONER consists of three few-shot selection methods based on random sampling,\nTF-IDF vectors, and a combination of both. We compare these methods with a\ngeneral-purpose GPT-NER method as the number of few-shot examples increases and\nevaluate their optimal NER performance against fine-tuned BERT and LLaMA\n2-chat. In the considered real-world scenarios with data scarcity, FsPONER with\nTF-IDF surpasses fine-tuned models by approximately 10% in F1 score.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Information Retrieval"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}