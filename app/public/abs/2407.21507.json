{"id":"2407.21507","title":"FSSC: Federated Learning of Transformer Neural Networks for Semantic\n  Image Communication","authors":"Yuna Yan, Xin Zhang, Lixin Li, Wensheng Lin, Rui Li, Wenchi Cheng, Zhu\n  Han","authorsParsed":[["Yan","Yuna",""],["Zhang","Xin",""],["Li","Lixin",""],["Lin","Wensheng",""],["Li","Rui",""],["Cheng","Wenchi",""],["Han","Zhu",""]],"versions":[{"version":"v1","created":"Wed, 31 Jul 2024 10:25:24 GMT"}],"updateDate":"2024-08-01","timestamp":1722421524000,"abstract":"  In this paper, we address the problem of image semantic communication in a\nmulti-user deployment scenario and propose a federated learning (FL) strategy\nfor a Swin Transformer-based semantic communication system (FSSC). Firstly, we\ndemonstrate that the adoption of a Swin Transformer for joint source-channel\ncoding (JSCC) effectively extracts semantic information in the communication\nsystem. Next, the FL framework is introduced to collaboratively learn a global\nmodel by aggregating local model parameters, rather than directly sharing\nclients' data. This approach enhances user privacy protection and reduces the\nworkload on the server or mobile edge. Simulation evaluations indicate that our\nmethod outperforms the typical JSCC algorithm and traditional separate-based\ncommunication algorithms. Particularly after integrating local semantics, the\nglobal aggregation model has further increased the Peak Signal-to-Noise Ratio\n(PSNR) by more than 2dB, thoroughly proving the effectiveness of our algorithm.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning","Electrical Engineering and Systems Science/Image and Video Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}