{"id":"2408.17358","title":"Hold Me Tight: Stable Encoder-Decoder Design for Speech Enhancement","authors":"Daniel Haider and Felix Perfler and Vincent Lostanlen and Martin Ehler\n  and Peter Balazs","authorsParsed":[["Haider","Daniel",""],["Perfler","Felix",""],["Lostanlen","Vincent",""],["Ehler","Martin",""],["Balazs","Peter",""]],"versions":[{"version":"v1","created":"Fri, 30 Aug 2024 15:49:31 GMT"}],"updateDate":"2024-09-02","timestamp":1725032971000,"abstract":"  Convolutional layers with 1-D filters are often used as frontend to encode\naudio signals. Unlike fixed time-frequency representations, they can adapt to\nthe local characteristics of input data. However, 1-D filters on raw audio are\nhard to train and often suffer from instabilities. In this paper, we address\nthese problems with hybrid solutions, i.e., combining theory-driven and\ndata-driven approaches. First, we preprocess the audio signals via a auditory\nfilterbank, guaranteeing good frequency localization for the learned encoder.\nSecond, we use results from frame theory to define an unsupervised learning\nobjective that encourages energy conservation and perfect reconstruction.\nThird, we adapt mixed compressed spectral norms as learning objectives to the\nencoder coefficients. Using these solutions in a low-complexity\nencoder-mask-decoder model significantly improves the perceptual evaluation of\nspeech quality (PESQ) in speech enhancement.\n","subjects":["Computing Research Repository/Sound","Computing Research Repository/Machine Learning","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"ZdPyYHXrtJ594t1n1KcSlAJ9OkwH9mRLK4o4mbM6WGQ","pdfSize":"1718075"}
