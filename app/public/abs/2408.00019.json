{"id":"2408.00019","title":"WebApp1K: A Practical Code-Generation Benchmark for Web App Development","authors":"Yi Cui","authorsParsed":[["Cui","Yi",""]],"versions":[{"version":"v1","created":"Tue, 30 Jul 2024 18:49:26 GMT"}],"updateDate":"2024-08-02","timestamp":1722365366000,"abstract":"  We introduce WebApp1K, a practical code-generation benchmark to measure LLM\nability to develop web apps. This benchmark aims to calibrate LLM output and\naid the models to progressively improve code correctness and functionality. The\nbenchmark is lightweight and easy to run. We present the initial version of\nWebApp1K, and share our findings of running the benchmark against the latest\nfrontier LLMs. First, open source LLMs deliver impressive performance, closely\ntrailing behind GPT-4o and Claude 3.5. Second, model size has strong\ncorrelation with code correctness. Third, no prompting techniques have been\nfound to lift performance either universally to all models, or significantly to\na single model.\n","subjects":["Computing Research Repository/Software Engineering","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"FcKBCU0l5YiSZe97-hYx7sKJBamdBkfYG4E-cZ_es6o","pdfSize":"122878"}
