{"id":"2408.04041","title":"A Deixis-Centered Approach for Documenting Remote Synchronous\n  Communication around Data Visualizations","authors":"Chang Han and Katherine E. Isaacs","authorsParsed":[["Han","Chang",""],["Isaacs","Katherine E.",""]],"versions":[{"version":"v1","created":"Wed, 7 Aug 2024 18:47:55 GMT"}],"updateDate":"2024-08-09","timestamp":1723056475000,"abstract":"  Referential gestures, or as termed in linguistics, deixis, are an essential\npart of communication around data visualizations. Despite their importance,\nsuch gestures are often overlooked when documenting data analysis meetings.\nTranscripts, for instance, fail to capture gestures, and video recordings may\nnot adequately capture or emphasize them. We introduce a novel method for\ndocumenting collaborative data meetings that treats deixis as a first-class\ncitizen. Our proposed framework captures cursor-based gestural data along with\naudio and converts them into interactive documents. The framework leverages a\nlarge language model to identify word correspondences with gestures. These\nidentified references are used to create context-based annotations in the\nresulting interactive document. We assess the effectiveness of our proposed\nmethod through a user study, finding that participants preferred our automated\ninteractive documentation over recordings, transcripts, and manual note-taking.\nFurthermore, we derive a preliminary taxonomy of cursor-based deictic gestures\nfrom participant actions during the study. This taxonomy offers further\nopportunities for better utilizing cursor-based deixis in collaborative data\nanalysis scenarios.\n","subjects":["Computing Research Repository/Human-Computer Interaction"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"17v2DCepu0fdi_KMJSCRXG7NQYOEF9SdKo_AC7JM8sQ","pdfSize":"6060095"}
