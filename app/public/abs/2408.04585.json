{"id":"2408.04585","title":"Towards Resilient and Efficient LLMs: A Comparative Study of Efficiency,\n  Performance, and Adversarial Robustness","authors":"Xiaojing Fan and Chunliang Tao","authorsParsed":[["Fan","Xiaojing",""],["Tao","Chunliang",""]],"versions":[{"version":"v1","created":"Thu, 8 Aug 2024 16:54:40 GMT"},{"version":"v2","created":"Fri, 9 Aug 2024 21:09:31 GMT"},{"version":"v3","created":"Sat, 14 Sep 2024 03:19:10 GMT"}],"updateDate":"2024-09-17","timestamp":1723136080000,"abstract":"  With the increasing demand for practical applications of Large Language\nModels (LLMs), many attention-efficient models have been developed to balance\nperformance and computational cost. However, the adversarial robustness of\nthese models remains under-explored. In this work, we design a framework to\ninvestigate the trade-off between efficiency, performance, and adversarial\nrobustness of LLMs and conduct extensive experiments on three prominent models\nwith varying levels of complexity and efficiency -- Transformer++, Gated Linear\nAttention (GLA) Transformer, and MatMul-Free LM -- utilizing the GLUE and\nAdvGLUE datasets. The AdvGLUE dataset extends the GLUE dataset with adversarial\nsamples designed to challenge model robustness. Our results show that while the\nGLA Transformer and MatMul-Free LM achieve slightly lower accuracy on GLUE\ntasks, they demonstrate higher efficiency and either superior or comparative\nrobustness on AdvGLUE tasks compared to Transformer++ across different attack\nlevels. These findings highlight the potential of simplified architectures to\nachieve a compelling balance between efficiency, performance, and adversarial\nrobustness, offering valuable insights for applications where resource\nconstraints and resilience to adversarial attacks are critical.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}