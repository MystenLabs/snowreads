{"id":"2407.01704","title":"Weight Clipping for Deep Continual and Reinforcement Learning","authors":"Mohamed Elsayed, Qingfeng Lan, Clare Lyle, A. Rupam Mahmood","authorsParsed":[["Elsayed","Mohamed",""],["Lan","Qingfeng",""],["Lyle","Clare",""],["Mahmood","A. Rupam",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 18:29:29 GMT"}],"updateDate":"2024-07-03","timestamp":1719858569000,"abstract":"  Many failures in deep continual and reinforcement learning are associated\nwith increasing magnitudes of the weights, making them hard to change and\npotentially causing overfitting. While many methods address these learning\nfailures, they often change the optimizer or the architecture, a complexity\nthat hinders widespread adoption in various systems. In this paper, we focus on\nlearning failures that are associated with increasing weight norm and we\npropose a simple technique that can be easily added on top of existing learning\nsystems: clipping neural network weights to limit them to a specific range. We\nstudy the effectiveness of weight clipping in a series of supervised and\nreinforcement learning experiments. Our empirical results highlight the\nbenefits of weight clipping for generalization, addressing loss of plasticity\nand policy collapse, and facilitating learning with a large replay ratio.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"wO5VP6KNJ8dnOt_zwWRGa3GfRG15VfPIx0ULFMN5zmM","pdfSize":"4121502"}
