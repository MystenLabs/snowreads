{"id":"2408.11449","title":"Enabling Small Models for Zero-Shot Classification through Model Label\n  Learning","authors":"Jia Zhang, Zhi Zhou, Lan-Zhe Guo and Yu-Feng Li","authorsParsed":[["Zhang","Jia",""],["Zhou","Zhi",""],["Guo","Lan-Zhe",""],["Li","Yu-Feng",""]],"versions":[{"version":"v1","created":"Wed, 21 Aug 2024 09:08:26 GMT"}],"updateDate":"2024-08-22","timestamp":1724231306000,"abstract":"  Vision-language models (VLMs) like CLIP have demonstrated impressive\nzero-shot ability in image classification tasks by aligning text and images but\nsuffer inferior performance compared with task-specific expert models. On the\ncontrary, expert models excel in their specialized domains but lack zero-shot\nability for new tasks. How to obtain both the high performance of expert models\nand zero-shot ability is an important research direction. In this paper, we\nattempt to demonstrate that by constructing a model hub and aligning models\nwith their functionalities using model labels, new tasks can be solved in a\nzero-shot manner by effectively selecting and reusing models in the hub. We\nintroduce a novel paradigm, Model Label Learning (MLL), which bridges the gap\nbetween models and their functionalities through a Semantic Directed Acyclic\nGraph (SDAG) and leverages an algorithm, Classification Head Combination\nOptimization (CHCO), to select capable models for new tasks. Compared with the\nfoundation model paradigm, it is less costly and more scalable, i.e., the\nzero-shot ability grows with the sizes of the model hub. Experiments on seven\nreal-world datasets validate the effectiveness and efficiency of MLL,\ndemonstrating that expert models can be effectively reused for zero-shot tasks.\nOur code will be released publicly.\n","subjects":["Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}