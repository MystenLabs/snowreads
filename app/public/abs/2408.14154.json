{"id":"2408.14154","title":"Investigating the effect of Mental Models in User Interaction with an\n  Adaptive Dialog Agent","authors":"Lindsey Vanderlyn, Dirk V\\\"ath, Ngoc Thang Vu","authorsParsed":[["Vanderlyn","Lindsey",""],["VÃ¤th","Dirk",""],["Vu","Ngoc Thang",""]],"versions":[{"version":"v1","created":"Mon, 26 Aug 2024 09:57:19 GMT"}],"updateDate":"2024-08-27","timestamp":1724666239000,"abstract":"  Mental models play an important role in whether user interaction with\nintelligent systems, such as dialog systems is successful or not. Adaptive\ndialog systems present the opportunity to align a dialog agent's behavior with\nheterogeneous user expectations. However, there has been little research into\nwhat mental models users form when interacting with a task-oriented dialog\nsystem, how these models affect users' interactions, or what role system\nadaptation can play in this process, making it challenging to avoid damage to\nhuman-AI partnership. In this work, we collect a new publicly available dataset\nfor exploring user mental models about information seeking dialog systems. We\ndemonstrate that users have a variety of conflicting mental models about such\nsystems, the validity of which directly impacts the success of their\ninteractions and perceived usability of system. Furthermore, we show that\nadapting a dialog agent's behavior to better align with users' mental models,\neven when done implicitly, can improve perceived usability, dialog efficiency,\nand success. To this end, we argue that implicit adaptation can be a valid\nstrategy for task-oriented dialog systems, so long as developers first have a\nsolid understanding of users' mental models.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"vagnIk13Eqs5jyXcm_Bw8iUXuiB-pjBEB0Jc6KPI-hU","pdfSize":"3292597"}
