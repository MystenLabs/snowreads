{"id":"2408.11221","title":"On the Potential of Open-Vocabulary Models for Object Detection in\n  Unusual Street Scenes","authors":"Sadia Ilyas, Ido Freeman, Matthias Rottmann","authorsParsed":[["Ilyas","Sadia",""],["Freeman","Ido",""],["Rottmann","Matthias",""]],"versions":[{"version":"v1","created":"Tue, 20 Aug 2024 22:39:52 GMT"}],"updateDate":"2024-08-22","timestamp":1724193592000,"abstract":"  Out-of-distribution (OOD) object detection is a critical task focused on\ndetecting objects that originate from a data distribution different from that\nof the training data. In this study, we investigate to what extent\nstate-of-the-art open-vocabulary object detectors can detect unusual objects in\nstreet scenes, which are considered as OOD or rare scenarios with respect to\ncommon street scene datasets. Specifically, we evaluate their performance on\nthe OoDIS Benchmark, which extends RoadAnomaly21 and RoadObstacle21 from\nSegmentMeIfYouCan, as well as LostAndFound, which was recently extended to\nobject level annotations. The objective of our study is to uncover\nshort-comings of contemporary object detectors in challenging real-world, and\nparticularly in open-world scenarios. Our experiments reveal that open\nvocabulary models are promising for OOD object detection scenarios, however far\nfrom perfect. Substantial improvements are required before they can be reliably\ndeployed in real-world applications. We benchmark four state-of-the-art\nopen-vocabulary object detection models on three different datasets.\nNoteworthily, Grounding DINO achieves the best results on RoadObstacle21 and\nLostAndFound in our study with an AP of 48.3% and 25.4% respectively.\nYOLO-World excels on RoadAnomaly21 with an AP of 21.2%.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}