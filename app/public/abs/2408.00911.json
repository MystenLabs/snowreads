{"id":"2408.00911","title":"Distance-Preserving Generative Modeling of Spatial Transcriptomics","authors":"Wenbin Zhou and Jin-Hong Du","authorsParsed":[["Zhou","Wenbin",""],["Du","Jin-Hong",""]],"versions":[{"version":"v1","created":"Thu, 1 Aug 2024 21:04:27 GMT"}],"updateDate":"2024-08-05","timestamp":1722546267000,"abstract":"  Spatial transcriptomics data is invaluable for understanding the spatial\norganization of gene expression in tissues. There have been consistent efforts\nin studying how to effectively utilize the associated spatial information for\nrefining gene expression modeling. We introduce a class of distance-preserving\ngenerative models for spatial transcriptomics, which utilizes the provided\nspatial information to regularize the learned representation space of gene\nexpressions to have a similar pair-wise distance structure. This helps the\nlatent space to capture meaningful encodings of genes in spatial proximity. We\ncarry out theoretical analysis over a tractable loss function for this purpose\nand formalize the overall learning objective as a regularized evidence lower\nbound. Our framework grants compatibility with any variational-inference-based\ngenerative models for gene expression modeling. Empirically, we validate our\nproposed method on the mouse brain tissues Visium dataset and observe improved\nperformance with variational autoencoders and scVI used as backbone models.\n","subjects":["Computing Research Repository/Machine Learning","Statistics/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"qwkvznvzFwtBqK6sha0qiEl1iPP1AWBzZS108uZPJus","pdfSize":"2216975"}
