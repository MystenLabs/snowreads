{"id":"2407.11859","title":"Mitigating Background Shift in Class-Incremental Semantic Segmentation","authors":"Gilhan Park, WonJun Moon, SuBeen Lee, Tae-Young Kim, and Jae-Pil Heo","authorsParsed":[["Park","Gilhan",""],["Moon","WonJun",""],["Lee","SuBeen",""],["Kim","Tae-Young",""],["Heo","Jae-Pil",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 15:44:37 GMT"}],"updateDate":"2024-07-17","timestamp":1721144677000,"abstract":"  Class-Incremental Semantic Segmentation(CISS) aims to learn new classes\nwithout forgetting the old ones, using only the labels of the new classes. To\nachieve this, two popular strategies are employed: 1) pseudo-labeling and\nknowledge distillation to preserve prior knowledge; and 2) background weight\ntransfer, which leverages the broad coverage of background in learning new\nclasses by transferring background weight to the new class classifier. However,\nthe first strategy heavily relies on the old model in detecting old classes\nwhile undetected pixels are regarded as the background, thereby leading to the\nbackground shift towards the old classes(i.e., misclassification of old class\nas background). Additionally, in the case of the second approach, initializing\nthe new class classifier with background knowledge triggers a similar\nbackground shift issue, but towards the new classes. To address these issues,\nwe propose a background-class separation framework for CISS. To begin with,\nselective pseudo-labeling and adaptive feature distillation are to distill only\ntrustworthy past knowledge. On the other hand, we encourage the separation\nbetween the background and new classes with a novel orthogonal objective along\nwith label-guided output distillation. Our state-of-the-art results validate\nthe effectiveness of these proposed methods.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}