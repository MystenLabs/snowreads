{"id":"2407.01375","title":"Transferable-guided Attention Is All You Need for Video Domain\n  Adaptation","authors":"Andr\\'e Sacilotti, Samuel Felipe dos Santos, Nicu Sebe, Jurandy\n  Almeida","authorsParsed":[["Sacilotti","Andr√©",""],["Santos","Samuel Felipe dos",""],["Sebe","Nicu",""],["Almeida","Jurandy",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 15:29:27 GMT"},{"version":"v2","created":"Tue, 17 Sep 2024 10:35:46 GMT"}],"updateDate":"2024-09-18","timestamp":1719847767000,"abstract":"  Unsupervised domain adaptation (UDA) in videos is a challenging task that\nremains not well explored compared to image-based UDA techniques. Although\nvision transformers (ViT) achieve state-of-the-art performance in many computer\nvision tasks, their use in video UDA has been little explored. Our key idea is\nto use transformer layers as a feature encoder and incorporate spatial and\ntemporal transferability relationships into the attention mechanism. A\nTransferable-guided Attention (TransferAttn) framework is then developed to\nexploit the capacity of the transformer to adapt cross-domain knowledge across\ndifferent backbones. To improve the transferability of ViT, we introduce a\nnovel and effective module, named Domain Transferable-guided Attention Block\n(DTAB). DTAB compels ViT to focus on the spatio-temporal transferability\nrelationship among video frames by changing the self-attention mechanism to a\ntransferability attention mechanism. Extensive experiments were conducted on\nUCF-HMDB, Kinetics-Gameplay, and Kinetics-NEC Drone datasets, with different\nbackbones, like ResNet101, I3D, and STAM, to verify the effectiveness of\nTransferAttn compared with state-of-the-art approaches. Also, we demonstrate\nthat DTAB yields performance gains when applied to other state-of-the-art\ntransformer-based UDA methods from both video and image domains. Our code is\navailable at https://github.com/Andre-Sacilotti/transferattn-project-code.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}