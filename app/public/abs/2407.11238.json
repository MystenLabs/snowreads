{"id":"2407.11238","title":"Evaluating geometric accuracy of NeRF reconstructions compared to SLAM\n  method","authors":"Adam Korycki, Colleen Josephson, Steve McGuire","authorsParsed":[["Korycki","Adam",""],["Josephson","Colleen",""],["McGuire","Steve",""]],"versions":[{"version":"v1","created":"Mon, 15 Jul 2024 21:04:11 GMT"},{"version":"v2","created":"Thu, 25 Jul 2024 20:40:13 GMT"}],"updateDate":"2024-07-29","timestamp":1721077451000,"abstract":"  As Neural Radiance Field (NeRF) implementations become faster, more efficient\nand accurate, their applicability to real world mapping tasks becomes more\naccessible. Traditionally, 3D mapping, or scene reconstruction, has relied on\nexpensive LiDAR sensing. Photogrammetry can perform image-based 3D\nreconstruction but is computationally expensive and requires extremely dense\nimage representation to recover complex geometry and photorealism. NeRFs\nperform 3D scene reconstruction by training a neural network on sparse image\nand pose data, achieving superior results to photogrammetry with less input\ndata. This paper presents an evaluation of two NeRF scene reconstructions for\nthe purpose of estimating the diameter of a vertical PVC cylinder. One of these\nare trained on commodity iPhone data and the other is trained on robot-sourced\nimagery and poses. This neural-geometry is compared to state-of-the-art\nlidar-inertial SLAM in terms of scene noise and metric-accuracy.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Robotics"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"oywUWtFsTLdww2KUtqPSm0hINGU9vjBU1xXMvGQG7E8","pdfSize":"4923791"}
