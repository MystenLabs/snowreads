{"id":"2407.09983","title":"WeConvene: Learned Image Compression with Wavelet-Domain Convolution and\n  Entropy Model","authors":"Haisheng Fu, Jie Liang, Zhenman Fang, Jingning Han, Feng Liang, Guohe\n  Zhang","authorsParsed":[["Fu","Haisheng",""],["Liang","Jie",""],["Fang","Zhenman",""],["Han","Jingning",""],["Liang","Feng",""],["Zhang","Guohe",""]],"versions":[{"version":"v1","created":"Sat, 13 Jul 2024 19:13:38 GMT"}],"updateDate":"2024-07-16","timestamp":1720898018000,"abstract":"  Recently learned image compression (LIC) has achieved great progress and even\noutperformed the traditional approach using DCT or discrete wavelet transform\n(DWT). However, LIC mainly reduces spatial redundancy in the autoencoder\nnetworks and entropy coding, but has not fully removed the frequency-domain\ncorrelation explicitly as in DCT or DWT. To leverage the best of both worlds,\nwe propose a surprisingly simple but efficient framework, which introduces the\nDWT to both the convolution layers and entropy coding of CNN-based LIC. First,\nin both the core and hyperprior autoencoder networks, we propose a\nWavelet-domain Convolution (WeConv) module, which performs convolution after\nDWT, and then converts the data back to spatial domain via inverse DWT. This\nmodule is used at selected layers in a CNN network to reduce the\nfrequency-domain correlation explicitly and make the signal sparser in DWT\ndomain. We also propose a wavelet-domain Channel-wise Auto-Regressive entropy\nModel (WeChARM), where the output latent representations from the encoder\nnetwork are first transformed by the DWT, before applying quantization and\nentropy coding, as in the traditional paradigm. Moreover, the entropy coding is\nsplit into two steps. We first code all low-frequency DWT coefficients, and\nthen use them as prior to code high-frequency coefficients. The channel-wise\nentropy coding is further used in each step. By combining WeConv and WeChARM,\nthe proposed WeConvene scheme achieves superior R-D performance compared to\nother state-of-the-art LIC methods as well as the latest H.266/VVC. For the\nKodak dataset and the baseline network with -0.4% BD-Rate saving over\nH.266/VVC, introducing WeConv with the simplest Haar transform improves the\nsaving to -4.7%. This is quite impressive given the simplicity of the Haar\ntransform. Enabling Haar-based WeChARM entropy coding further boosts the saving\nto -8.2%.\n","subjects":["Statistics/Applications"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}