{"id":"2407.14013","title":"Well-conditioned Primal-Dual Interior-point Method for Accurate Low-rank\n  Semidefinite Programming","authors":"Hong-Ming Chiu, Richard Y. Zhang","authorsParsed":[["Chiu","Hong-Ming",""],["Zhang","Richard Y.",""]],"versions":[{"version":"v1","created":"Fri, 19 Jul 2024 04:03:30 GMT"}],"updateDate":"2024-07-22","timestamp":1721361810000,"abstract":"  We describe how the low-rank structure in an SDP can be exploited to reduce\nthe per-iteration cost of a convex primal-dual interior-point method down to\n$O(n^{3})$ time and $O(n^{2})$ memory, even at very high accuracies. A\ntraditional difficulty is the dense Newton subproblem at each iteration, which\nbecomes progressively ill-conditioned as progress is made towards the solution.\nPreconditioners have previously been proposed to improve conditioning, but\nthese can be expensive to set up, and become ineffective as the preconditioner\nitself becomes increasingly ill-conditioned at high accuracies. Instead, we\npresent a \\emph{well-conditioned reformulation} of the Newton subproblem that\nis cheap to set up, and whose condition number is guaranteed to remain bounded\nover all iterations of the interior-point method. In theory, applying an inner\niterative method to the reformulation reduces the per-iteration cost of the\nouter interior-point method to $O(n^{3})$ time and $O(n^{2})$ memory. We also\npresent a \\emph{well-conditioned preconditioner} that theoretically increases\nthe outer per-iteration cost to $O(n^{3}r^{3})$ time and $O(n^{2}r^{2})$\nmemory, where $r$ is an upper-bound on the solution rank, but in practice\ngreatly improves the convergence of the inner iterations.\n","subjects":["Mathematics/Optimization and Control"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}