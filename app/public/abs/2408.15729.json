{"id":"2408.15729","title":"LM-PUB-QUIZ: A Comprehensive Framework for Zero-Shot Evaluation of\n  Relational Knowledge in Language Models","authors":"Max Ploner and Jacek Wiland and Sebastian Pohl and Alan Akbik","authorsParsed":[["Ploner","Max",""],["Wiland","Jacek",""],["Pohl","Sebastian",""],["Akbik","Alan",""]],"versions":[{"version":"v1","created":"Wed, 28 Aug 2024 11:44:52 GMT"}],"updateDate":"2024-08-29","timestamp":1724845492000,"abstract":"  Knowledge probing evaluates the extent to which a language model (LM) has\nacquired relational knowledge during its pre-training phase. It provides a\ncost-effective means of comparing LMs of different sizes and training setups\nand is useful for monitoring knowledge gained or lost during continual learning\n(CL). In prior work, we presented an improved knowledge probe called BEAR\n(Wiland et al., 2024), which enables the comparison of LMs trained with\ndifferent pre-training objectives (causal and masked LMs) and addresses issues\nof skewed distributions in previous probes to deliver a more unbiased reading\nof LM knowledge. With this paper, we present LM-PUB- QUIZ, a Python framework\nand leaderboard built around the BEAR probing mechanism that enables\nresearchers and practitioners to apply it in their work. It provides options\nfor standalone evaluation and direct integration into the widely-used training\npipeline of the Hugging Face TRANSFORMERS library. Further, it provides a\nfine-grained analysis of different knowledge types to assist users in better\nunderstanding the knowledge in each evaluated LM. We publicly release\nLM-PUB-QUIZ as an open-source project.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by-sa/4.0/","blobId":"MdfUF2K1MOv6aOLAuQPh8IYu10rURHWYNNxBtZGppx4","pdfSize":"364458"}
