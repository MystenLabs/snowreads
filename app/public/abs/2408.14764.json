{"id":"2408.14764","title":"SynthDoc: Bilingual Documents Synthesis for Visual Document\n  Understanding","authors":"Chuanghao Ding and Xuejing Liu and Wei Tang and Juan Li and Xiaoliang\n  Wang and Rui Zhao and Cam-Tu Nguyen and Fei Tan","authorsParsed":[["Ding","Chuanghao",""],["Liu","Xuejing",""],["Tang","Wei",""],["Li","Juan",""],["Wang","Xiaoliang",""],["Zhao","Rui",""],["Nguyen","Cam-Tu",""],["Tan","Fei",""]],"versions":[{"version":"v1","created":"Tue, 27 Aug 2024 03:31:24 GMT"}],"updateDate":"2024-08-28","timestamp":1724729484000,"abstract":"  This paper introduces SynthDoc, a novel synthetic document generation\npipeline designed to enhance Visual Document Understanding (VDU) by generating\nhigh-quality, diverse datasets that include text, images, tables, and charts.\nAddressing the challenges of data acquisition and the limitations of existing\ndatasets, SynthDoc leverages publicly available corpora and advanced rendering\ntools to create a comprehensive and versatile dataset. Our experiments,\nconducted using the Donut model, demonstrate that models trained with\nSynthDoc's data achieve superior performance in pre-training read tasks and\nmaintain robustness in downstream tasks, despite language inconsistencies. The\nrelease of a benchmark dataset comprising 5,000 image-text pairs not only\nshowcases the pipeline's capabilities but also provides a valuable resource for\nthe VDU community to advance research and development in document image\nrecognition. This work significantly contributes to the field by offering a\nscalable solution to data scarcity and by validating the efficacy of end-to-end\nmodels in parsing complex, real-world documents.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Multimedia"],"license":"http://creativecommons.org/licenses/by/4.0/"}