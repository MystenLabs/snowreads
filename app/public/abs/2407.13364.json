{"id":"2407.13364","title":"Geometric Active Exploration in Markov Decision Processes: the Benefit\n  of Abstraction","authors":"Riccardo De Santi, Federico Arangath Joseph, Noah Liniger, Mirco\n  Mutti, Andreas Krause","authorsParsed":[["De Santi","Riccardo",""],["Joseph","Federico Arangath",""],["Liniger","Noah",""],["Mutti","Mirco",""],["Krause","Andreas",""]],"versions":[{"version":"v1","created":"Thu, 18 Jul 2024 10:15:51 GMT"}],"updateDate":"2024-07-19","timestamp":1721297751000,"abstract":"  How can a scientist use a Reinforcement Learning (RL) algorithm to design\nexperiments over a dynamical system's state space? In the case of finite and\nMarkovian systems, an area called Active Exploration (AE) relaxes the\noptimization problem of experiments design into Convex RL, a generalization of\nRL admitting a wider notion of reward. Unfortunately, this framework is\ncurrently not scalable and the potential of AE is hindered by the vastness of\nexperiment spaces typical of scientific discovery applications. However, these\nspaces are often endowed with natural geometries, e.g., permutation invariance\nin molecular design, that an agent could leverage to improve the statistical\nand computational efficiency of AE. To achieve this, we bridge AE and MDP\nhomomorphisms, which offer a way to exploit known geometric structures via\nabstraction. Towards this goal, we make two fundamental contributions: we\nextend MDP homomorphisms formalism to Convex RL, and we present, to the best of\nour knowledge, the first analysis that formally captures the benefit of\nabstraction via homomorphisms on sample efficiency. Ultimately, we propose the\nGeometric Active Exploration (GAE) algorithm, which we analyse theoretically\nand experimentally in environments motivated by problems in scientific\ndiscovery.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}