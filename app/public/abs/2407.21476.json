{"id":"2407.21476","title":"On the Problem of Text-To-Speech Model Selection for Synthetic Data\n  Generation in Automatic Speech Recognition","authors":"Nick Rossenbach, Ralf Schl\\\"uter, Sakriani Sakti","authorsParsed":[["Rossenbach","Nick",""],["Schl√ºter","Ralf",""],["Sakti","Sakriani",""]],"versions":[{"version":"v1","created":"Wed, 31 Jul 2024 09:37:27 GMT"}],"updateDate":"2024-08-01","timestamp":1722418647000,"abstract":"  The rapid development of neural text-to-speech (TTS) systems enabled its\nusage in other areas of natural language processing such as automatic speech\nrecognition (ASR) or spoken language translation (SLT). Due to the large number\nof different TTS architectures and their extensions, selecting which TTS\nsystems to use for synthetic data creation is not an easy task. We use the\ncomparison of five different TTS decoder architectures in the scope of\nsynthetic data generation to show the impact on CTC-based speech recognition\ntraining. We compare the recognition results to computable metrics like NISQA\nMOS and intelligibility, finding that there are no clear relations to the ASR\nperformance. We also observe that for data generation auto-regressive decoding\nperforms better than non-autoregressive decoding, and propose an approach to\nquantify TTS generalization capabilities.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning","Computing Research Repository/Sound","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}