{"id":"2407.00851","title":"SAFE: a SAR Feature Extractor based on self-supervised learning and\n  masked Siamese ViTs","authors":"Max Muzeau, Joana Frontera-Pons, Chengfang Ren, Jean-Philippe Ovarlez","authorsParsed":[["Muzeau","Max",""],["Frontera-Pons","Joana",""],["Ren","Chengfang",""],["Ovarlez","Jean-Philippe",""]],"versions":[{"version":"v1","created":"Sun, 30 Jun 2024 23:11:20 GMT"}],"updateDate":"2024-07-02","timestamp":1719789080000,"abstract":"  Due to its all-weather and day-and-night capabilities, Synthetic Aperture\nRadar imagery is essential for various applications such as disaster\nmanagement, earth monitoring, change detection and target recognition. However,\nthe scarcity of labeled SAR data limits the performance of most deep learning\nalgorithms. To address this issue, we propose a novel self-supervised learning\nframework based on masked Siamese Vision Transformers to create a General SAR\nFeature Extractor coined SAFE. Our method leverages contrastive learning\nprinciples to train a model on unlabeled SAR data, extracting robust and\ngeneralizable features. SAFE is applicable across multiple SAR acquisition\nmodes and resolutions. We introduce tailored data augmentation techniques\nspecific to SAR imagery, such as sub-aperture decomposition and despeckling.\nComprehensive evaluations on various downstream tasks, including few-shot\nclassification, segmentation, visualization, and pattern detection, demonstrate\nthe effectiveness and versatility of the proposed approach. Our network\ncompetes with or surpasses other state-of-the-art methods in few-shot\nclassification and segmentation tasks, even without being trained on the\nsensors used for the evaluation.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Electrical Engineering and Systems Science/Image and Video Processing"],"license":"http://creativecommons.org/licenses/by/4.0/"}