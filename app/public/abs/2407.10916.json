{"id":"2407.10916","title":"When Heterophily Meets Heterogeneity: New Graph Benchmarks and Effective\n  Methods","authors":"Junhong Lin, Xiaojie Guo, Shuaicheng Zhang, Dawei Zhou, Yada Zhu,\n  Julian Shun","authorsParsed":[["Lin","Junhong",""],["Guo","Xiaojie",""],["Zhang","Shuaicheng",""],["Zhou","Dawei",""],["Zhu","Yada",""],["Shun","Julian",""]],"versions":[{"version":"v1","created":"Mon, 15 Jul 2024 17:18:42 GMT"}],"updateDate":"2024-07-16","timestamp":1721063922000,"abstract":"  Many real-world graphs frequently present challenges for graph learning due\nto the presence of both heterophily and heterogeneity. However, existing\nbenchmarks for graph learning often focus on heterogeneous graphs with\nhomophily or homogeneous graphs with heterophily, leaving a gap in\nunderstanding how methods perform on graphs that are both heterogeneous and\nheterophilic. To bridge this gap, we introduce H2GB, a novel graph benchmark\nthat brings together the complexities of both the heterophily and heterogeneity\nproperties of graphs. Our benchmark encompasses 9 diverse real-world datasets\nacross 5 domains, 28 baseline model implementations, and 26 benchmark results.\nIn addition, we present a modular graph transformer framework UnifiedGT and a\nnew model variant, H2G-former, that excels at this challenging benchmark. By\nintegrating masked label embeddings, cross-type heterogeneous attention, and\ntype-specific FFNs, H2G-former effectively tackles graph heterophily and\nheterogeneity. Extensive experiments across 26 baselines on H2GB reveal\ninadequacies of current models on heterogeneous heterophilic graph learning,\nand demonstrate the superiority of our H2G-former over existing solutions. Both\nthe benchmark and the framework are available on GitHub\n(https://github.com/junhongmit/H2GB) and PyPI (https://pypi.org/project/H2GB),\nand documentation can be found at https://junhongmit.github.io/H2GB/.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Social and Information Networks"],"license":"http://creativecommons.org/licenses/by/4.0/"}