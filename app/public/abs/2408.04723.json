{"id":"2408.04723","title":"Survey: Transformer-based Models in Data Modality Conversion","authors":"Elyas Rashno, Amir Eskandari, Aman Anand, and Farhana Zulkernine","authorsParsed":[["Rashno","Elyas",""],["Eskandari","Amir",""],["Anand","Aman",""],["Zulkernine","Farhana",""]],"versions":[{"version":"v1","created":"Thu, 8 Aug 2024 18:39:14 GMT"}],"updateDate":"2024-08-12","timestamp":1723142354000,"abstract":"  Transformers have made significant strides across various artificial\nintelligence domains, including natural language processing, computer vision,\nand audio processing. This success has naturally garnered considerable interest\nfrom both academic and industry researchers. Consequently, numerous Transformer\nvariants (often referred to as X-formers) have been developed for these fields.\nHowever, a thorough and systematic review of these modality-specific\nconversions remains lacking. Modality Conversion involves the transformation of\ndata from one form of representation to another, mimicking the way humans\nintegrate and interpret sensory information. This paper provides a\ncomprehensive review of transformer-based models applied to the primary\nmodalities of text, vision, and speech, discussing their architectures,\nconversion methodologies, and applications. By synthesizing the literature on\nmodality conversion, this survey aims to underline the versatility and\nscalability of transformers in advancing AI-driven content generation and\nunderstanding.\n","subjects":["Electrical Engineering and Systems Science/Image and Video Processing","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language","Electrical Engineering and Systems Science/Signal Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}