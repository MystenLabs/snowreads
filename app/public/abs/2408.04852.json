{"id":"2408.04852","title":"MSG-Chart: Multimodal Scene Graph for ChartQA","authors":"Yue Dai, Soyeon Caren Han, Wei Liu","authorsParsed":[["Dai","Yue",""],["Han","Soyeon Caren",""],["Liu","Wei",""]],"versions":[{"version":"v1","created":"Fri, 9 Aug 2024 04:11:23 GMT"}],"updateDate":"2024-08-12","timestamp":1723176683000,"abstract":"  Automatic Chart Question Answering (ChartQA) is challenging due to the\ncomplex distribution of chart elements with patterns of the underlying data not\nexplicitly displayed in charts. To address this challenge, we design a joint\nmultimodal scene graph for charts to explicitly represent the relationships\nbetween chart elements and their patterns. Our proposed multimodal scene graph\nincludes a visual graph and a textual graph to jointly capture the structural\nand semantical knowledge from the chart. This graph module can be easily\nintegrated with different vision transformers as inductive bias. Our\nexperiments demonstrate that incorporating the proposed graph module enhances\nthe understanding of charts' elements' structure and semantics, thereby\nimproving performance on publicly available benchmarks, ChartQA and OpenCQA.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}