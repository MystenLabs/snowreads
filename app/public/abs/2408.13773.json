{"id":"2408.13773","title":"SAB:A Stealing and Robust Backdoor Attack based on Steganographic\n  Algorithm against Federated Learning","authors":"Weida Xu, Yang Xu, Sicong Zhang","authorsParsed":[["Xu","Weida",""],["Xu","Yang",""],["Zhang","Sicong",""]],"versions":[{"version":"v1","created":"Sun, 25 Aug 2024 08:54:08 GMT"}],"updateDate":"2024-08-27","timestamp":1724576048000,"abstract":"  Federated learning, an innovative network architecture designed to safeguard\nuser privacy, is gaining widespread adoption in the realm of technology.\nHowever, given the existence of backdoor attacks in federated learning,\nexploring the security of federated learning is significance. Nevertheless, the\nbackdoors investigated in current federated learning research can be readily\ndetected by human inspection or resisted by detection algorithms. Accordingly,\na new goal has been set to develop stealing and robust federated learning\nbackdoor attacks. In this paper, we introduce a novel approach, SAB, tailored\nspecifically for backdoor attacks in federated learning, presenting an\nalternative gradient updating mechanism. SAB attack based on steganographic\nalgorithm, using image steganographic algorithm to build a full-size trigger to\nimprove the accuracy of backdoors and use multiple loss joint computation to\nproduce triggers. SAB exhibits smaller distances to benign samples and greater\nimperceptibility to the human eye. As such, our triggers are capable of\nmitigating or evading specific backdoor defense methods. In SAB, the\nbottom-95\\% method is applied to extend the lifespan of backdoor attacks. It\nupdates the gradient on minor value points to reduce the probability of being\ncleaned. Finally, the generalization of backdoors is enhanced with\nSparse-update to improve the backdoor accuracy.\n","subjects":["Computing Research Repository/Cryptography and Security","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}