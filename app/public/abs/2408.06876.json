{"id":"2408.06876","title":"Decision-Focused Learning to Predict Action Costs for Planning","authors":"Jayanta Mandi, Marco Foschini, Daniel Holler, Sylvie Thiebaux, Jorg\n  Hoffmann, Tias Guns","authorsParsed":[["Mandi","Jayanta",""],["Foschini","Marco",""],["Holler","Daniel",""],["Thiebaux","Sylvie",""],["Hoffmann","Jorg",""],["Guns","Tias",""]],"versions":[{"version":"v1","created":"Tue, 13 Aug 2024 13:14:54 GMT"},{"version":"v2","created":"Mon, 26 Aug 2024 11:29:07 GMT"}],"updateDate":"2024-08-27","timestamp":1723554894000,"abstract":"  In many automated planning applications, action costs can be hard to specify.\nAn example is the time needed to travel through a certain road segment, which\ndepends on many factors, such as the current weather conditions. A natural way\nto address this issue is to learn to predict these parameters based on input\nfeatures (e.g., weather forecasts) and use the predicted action costs in\nautomated planning afterward. Decision-Focused Learning (DFL) has been\nsuccessful in learning to predict the parameters of combinatorial optimization\nproblems in a way that optimizes solution quality rather than prediction\nquality. This approach yields better results than treating prediction and\noptimization as separate tasks. In this paper, we investigate for the first\ntime the challenges of implementing DFL for automated planning in order to\nlearn to predict the action costs. There are two main challenges to overcome:\n(1) planning systems are called during gradient descent learning, to solve\nplanning problems with negative action costs, which are not supported in\nplanning. We propose novel methods for gradient computation to avoid this\nissue. (2) DFL requires repeated planner calls during training, which can limit\nthe scalability of the method. We experiment with different methods\napproximating the optimal plan as well as an easy-to-implement caching\nmechanism to speed up the learning process. As the first work that addresses\nDFL for automated planning, we demonstrate that the proposed gradient\ncomputation consistently yields significantly better plans than predictions\naimed at minimizing prediction error; and that caching can temper the\ncomputation requirements.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Robotics"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"1UVTBTIeWqAxNfPuBaLX7MUrEsbuai9MPfyr-0tTaNU","pdfSize":"618367"}
