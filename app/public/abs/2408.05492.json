{"id":"2408.05492","title":"ZePo: Zero-Shot Portrait Stylization with Faster Sampling","authors":"Jin Liu, Huaibo Huang, Jie Cao, Ran He","authorsParsed":[["Liu","Jin",""],["Huang","Huaibo",""],["Cao","Jie",""],["He","Ran",""]],"versions":[{"version":"v1","created":"Sat, 10 Aug 2024 08:53:41 GMT"}],"updateDate":"2024-08-13","timestamp":1723280021000,"abstract":"  Diffusion-based text-to-image generation models have significantly advanced\nthe field of art content synthesis. However, current portrait stylization\nmethods generally require either model fine-tuning based on examples or the\nemployment of DDIM Inversion to revert images to noise space, both of which\nsubstantially decelerate the image generation process. To overcome these\nlimitations, this paper presents an inversion-free portrait stylization\nframework based on diffusion models that accomplishes content and style feature\nfusion in merely four sampling steps. We observed that Latent Consistency\nModels employing consistency distillation can effectively extract\nrepresentative Consistency Features from noisy images. To blend the Consistency\nFeatures extracted from both content and style images, we introduce a Style\nEnhancement Attention Control technique that meticulously merges content and\nstyle features within the attention space of the target image. Moreover, we\npropose a feature merging strategy to amalgamate redundant features in\nConsistency Features, thereby reducing the computational load of attention\ncontrol. Extensive experiments have validated the effectiveness of our proposed\nframework in enhancing stylization efficiency and fidelity. The code is\navailable at \\url{https://github.com/liujin112/ZePo}.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}