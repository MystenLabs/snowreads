{"id":"2408.13566","title":"Control-Informed Reinforcement Learning for Chemical Processes","authors":"Maximilian Bloor, Akhil Ahmed, Niki Kotecha, Mehmet Mercang\\\"oz,\n  Calvin Tsay, Ehecactl Antonio Del Rio Chanona","authorsParsed":[["Bloor","Maximilian",""],["Ahmed","Akhil",""],["Kotecha","Niki",""],["Mercang√∂z","Mehmet",""],["Tsay","Calvin",""],["Chanona","Ehecactl Antonio Del Rio",""]],"versions":[{"version":"v1","created":"Sat, 24 Aug 2024 12:36:37 GMT"},{"version":"v2","created":"Tue, 27 Aug 2024 15:17:18 GMT"}],"updateDate":"2024-08-28","timestamp":1724502997000,"abstract":"  This work proposes a control-informed reinforcement learning (CIRL) framework\nthat integrates proportional-integral-derivative (PID) control components into\nthe architecture of deep reinforcement learning (RL) policies. The proposed\napproach augments deep RL agents with a PID controller layer, incorporating\nprior knowledge from control theory into the learning process. CIRL improves\nperformance and robustness by combining the best of both worlds: the\ndisturbance-rejection and setpoint-tracking capabilities of PID control and the\nnonlinear modeling capacity of deep RL. Simulation studies conducted on a\ncontinuously stirred tank reactor system demonstrate the improved performance\nof CIRL compared to both conventional model-free deep RL and static PID\ncontrollers. CIRL exhibits better setpoint-tracking ability, particularly when\ngeneralizing to trajectories outside the training distribution, suggesting\nenhanced generalization capabilities. Furthermore, the embedded prior control\nknowledge within the CIRL policy improves its robustness to unobserved system\ndisturbances. The control-informed RL framework combines the strengths of\nclassical control and reinforcement learning to develop sample-efficient and\nrobust deep reinforcement learning algorithms, with potential applications in\ncomplex industrial systems.\n","subjects":["Electrical Engineering and Systems Science/Systems and Control","Computing Research Repository/Systems and Control"],"license":"http://creativecommons.org/licenses/by-sa/4.0/"}