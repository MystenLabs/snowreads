{"id":"2408.02412","title":"PENDRAM: Enabling High-Performance and Energy-Efficient Processing of\n  Deep Neural Networks through a Generalized DRAM Data Mapping Policy","authors":"Rachmad Vidya Wicaksana Putra, Muhammad Abdullah Hanif, Muhammad\n  Shafique","authorsParsed":[["Putra","Rachmad Vidya Wicaksana",""],["Hanif","Muhammad Abdullah",""],["Shafique","Muhammad",""]],"versions":[{"version":"v1","created":"Mon, 5 Aug 2024 12:11:09 GMT"}],"updateDate":"2024-08-06","timestamp":1722859869000,"abstract":"  Convolutional Neural Networks (CNNs), a prominent type of Deep Neural\nNetworks (DNNs), have emerged as a state-of-the-art solution for solving\nmachine learning tasks. To improve the performance and energy efficiency of CNN\ninference, the employment of specialized hardware accelerators is prevalent.\nHowever, CNN accelerators still face performance- and energy-efficiency\nchallenges due to high off-chip memory (DRAM) access latency and energy, which\nare especially crucial for latency- and energy-constrained embedded\napplications. Moreover, different DRAM architectures have different profiles of\naccess latency and energy, thus making it challenging to optimize them for high\nperformance and energy-efficient CNN accelerators. To address this, we present\nPENDRAM, a novel design space exploration methodology that enables\nhigh-performance and energy-efficient CNN acceleration through a generalized\nDRAM data mapping policy. Specifically, it explores the impact of different\nDRAM data mapping policies and DRAM architectures across different CNN\npartitioning and scheduling schemes on the DRAM access latency and energy, then\nidentifies the pareto-optimal design choices. The experimental results show\nthat our DRAM data mapping policy improves the energy-delay-product of DRAM\naccesses in the CNN accelerator over other mapping policies by up to 96%. In\nthis manner, our PENDRAM methodology offers high-performance and\nenergy-efficient CNN acceleration under any given DRAM architectures for\ndiverse embedded AI applications.\n","subjects":["Computing Research Repository/Hardware Architecture","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning","Computing Research Repository/Neural and Evolutionary Computing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}