{"id":"2408.16732","title":"Automatic detection of Mild Cognitive Impairment using high-dimensional\n  acoustic features in spontaneous speech","authors":"Cong Zhang, Wenxing Guo, Hongsheng Dai","authorsParsed":[["Zhang","Cong",""],["Guo","Wenxing",""],["Dai","Hongsheng",""]],"versions":[{"version":"v1","created":"Thu, 29 Aug 2024 17:23:43 GMT"}],"updateDate":"2024-08-30","timestamp":1724952223000,"abstract":"  This study addresses the TAUKADIAL challenge, focusing on the classification\nof speech from people with Mild Cognitive Impairment (MCI) and neurotypical\ncontrols. We conducted three experiments comparing five machine-learning\nmethods: Random Forests, Sparse Logistic Regression, k-Nearest Neighbors,\nSparse Support Vector Machine, and Decision Tree, utilizing 1076 acoustic\nfeatures automatically extracted using openSMILE. In Experiment 1, the entire\ndataset was used to train a language-agnostic model. Experiment 2 introduced a\nlanguage detection step, leading to separate model training for each language.\nExperiment 3 further enhanced the language-agnostic model from Experiment 1,\nwith a specific focus on evaluating the robustness of the models using\nout-of-sample test data. Across all three experiments, results consistently\nfavored models capable of handling high-dimensional data, such as Random Forest\nand Sparse Logistic Regression, in classifying speech from MCI and controls.\n","subjects":["Quantitative Biology/Neurons and Cognition","Computing Research Repository/Sound","Electrical Engineering and Systems Science/Audio and Speech Processing","Quantitative Biology/Quantitative Methods"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/"}