{"id":"2407.00556","title":"Revisiting Vision-Language Features Adaptation and Inconsistency for\n  Social Media Popularity Prediction","authors":"Chih-Chung Hsu, Chia-Ming Lee, Yu-Fan Lin, Yi-Shiuan Chou, Chih-Yu\n  Jian and Chi-Han Tsai","authorsParsed":[["Hsu","Chih-Chung",""],["Lee","Chia-Ming",""],["Lin","Yu-Fan",""],["Chou","Yi-Shiuan",""],["Jian","Chih-Yu",""],["Tsai","Chi-Han",""]],"versions":[{"version":"v1","created":"Sun, 30 Jun 2024 01:18:37 GMT"}],"updateDate":"2024-07-02","timestamp":1719710317000,"abstract":"  Social media popularity (SMP) prediction is a complex task involving\nmulti-modal data integration. While pre-trained vision-language models (VLMs)\nlike CLIP have been widely adopted for this task, their effectiveness in\ncapturing the unique characteristics of social media content remains\nunexplored. This paper critically examines the applicability of CLIP-based\nfeatures in SMP prediction, focusing on the overlooked phenomenon of semantic\ninconsistency between images and text in social media posts. Through extensive\nanalysis, we demonstrate that this inconsistency increases with post\npopularity, challenging the conventional use of VLM features. We provide a\ncomprehensive investigation of semantic inconsistency across different\npopularity intervals and analyze the impact of VLM feature adaptation on SMP\ntasks. Our experiments reveal that incorporating inconsistency measures and\nadapted text features significantly improves model performance, achieving an\nSRC of 0.729 and an MAE of 1.227. These findings not only enhance SMP\nprediction accuracy but also provide crucial insights for developing more\ntargeted approaches in social media analysis.\n","subjects":["Computing Research Repository/Multimedia"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"7eZJY5Je0jrxcOCtqzG5Eq4FMTN5YxrA1iT5TEkVkso","pdfSize":"1542168"}
