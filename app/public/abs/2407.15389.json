{"id":"2407.15389","title":"Poisoning with A Pill: Circumventing Detection in Federated Learning","authors":"Hanxi Guo, Hao Wang, Tao Song, Tianhang Zheng, Yang Hua, Haibing Guan\n  and Xiangyu Zhang","authorsParsed":[["Guo","Hanxi",""],["Wang","Hao",""],["Song","Tao",""],["Zheng","Tianhang",""],["Hua","Yang",""],["Guan","Haibing",""],["Zhang","Xiangyu",""]],"versions":[{"version":"v1","created":"Mon, 22 Jul 2024 05:34:47 GMT"}],"updateDate":"2024-07-23","timestamp":1721626487000,"abstract":"  Without direct access to the client's data, federated learning (FL) is\nwell-known for its unique strength in data privacy protection among existing\ndistributed machine learning techniques. However, its distributive and\niterative nature makes FL inherently vulnerable to various poisoning attacks.\nTo counteract these threats, extensive defenses have been proposed to filter\nout malicious clients, using various detection metrics. Based on our analysis\nof existing attacks and defenses, we find that there is a lack of attention to\nmodel redundancy. In neural networks, various model parameters contribute\ndifferently to the model's performance. However, existing attacks in FL\nmanipulate all the model update parameters with the same strategy, making them\neasily detectable by common defenses. Meanwhile, the defenses also tend to\nanalyze the overall statistical features of the entire model updates, leaving\nroom for sophisticated attacks. Based on these observations, this paper\nproposes a generic and attack-agnostic augmentation approach designed to\nenhance the effectiveness and stealthiness of existing FL poisoning attacks\nagainst detection in FL, pointing out the inherent flaws of existing defenses\nand exposing the necessity of fine-grained FL security. Specifically, we employ\na three-stage methodology that strategically constructs, generates, and injects\npoison (generated by existing attacks) into a pill (a tiny subnet with a novel\nstructure) during the FL training, named as pill construction, pill poisoning,\nand pill injection accordingly. Extensive experimental results show that FL\npoisoning attacks enhanced by our method can bypass all the popular defenses,\nand can gain an up to 7x error rate increase, as well as on average a more than\n2x error rate increase on both IID and non-IID data, in both cross-silo and\ncross-device FL systems.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Cryptography and Security","Computing Research Repository/Distributed, Parallel, and Cluster Computing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}