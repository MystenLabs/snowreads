{"id":"2408.15176","title":"Unlocking Potential in Pre-Trained Music Language Models for Versatile\n  Multi-Track Music Arrangement","authors":"Longshen Ou, Jingwei Zhao, Ziyu Wang, Gus Xia, Ye Wang","authorsParsed":[["Ou","Longshen",""],["Zhao","Jingwei",""],["Wang","Ziyu",""],["Xia","Gus",""],["Wang","Ye",""]],"versions":[{"version":"v1","created":"Tue, 27 Aug 2024 16:18:51 GMT"}],"updateDate":"2024-08-28","timestamp":1724775531000,"abstract":"  Large language models have shown significant capabilities across various\ndomains, including symbolic music generation. However, leveraging these\npre-trained models for controllable music arrangement tasks, each requiring\ndifferent forms of musical information as control, remains a novel challenge.\nIn this paper, we propose a unified sequence-to-sequence framework that enables\nthe fine-tuning of a symbolic music language model for multiple multi-track\narrangement tasks, including band arrangement, piano reduction, drum\narrangement, and voice separation. Our experiments demonstrate that the\nproposed approach consistently achieves higher musical quality compared to\ntask-specific baselines across all four tasks. Furthermore, through additional\nexperiments on probing analysis, we show the pre-training phase equips the\nmodel with essential knowledge to understand musical conditions, which is hard\nto acquired solely through task-specific fine-tuning.\n","subjects":["Computing Research Repository/Sound","Computing Research Repository/Computation and Language","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}