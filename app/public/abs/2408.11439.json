{"id":"2408.11439","title":"BAdd: Bias Mitigation through Bias Addition","authors":"Ioannis Sarridis, Christos Koutlis, Symeon Papadopoulos, Christos Diou","authorsParsed":[["Sarridis","Ioannis",""],["Koutlis","Christos",""],["Papadopoulos","Symeon",""],["Diou","Christos",""]],"versions":[{"version":"v1","created":"Wed, 21 Aug 2024 08:50:31 GMT"}],"updateDate":"2024-08-22","timestamp":1724230231000,"abstract":"  Computer vision (CV) datasets often exhibit biases that are perpetuated by\ndeep learning models. While recent efforts aim to mitigate these biases and\nfoster fair representations, they fail in complex real-world scenarios. In\nparticular, existing methods excel in controlled experiments involving\nbenchmarks with single-attribute injected biases, but struggle with\nmulti-attribute biases being present in well-established CV datasets. Here, we\nintroduce BAdd, a simple yet effective method that allows for learning fair\nrepresentations invariant to the attributes introducing bias by incorporating\nfeatures representing these attributes into the backbone. BAdd is evaluated on\nseven benchmarks and exhibits competitive performance, surpassing\nstate-of-the-art methods on both single- and multi-attribute benchmarks.\nNotably, BAdd achieves +27.5% and +5.5% absolute accuracy improvements on the\nchallenging multi-attribute benchmarks, FB-Biased-MNIST and CelebA,\nrespectively.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-sa/4.0/"}