{"id":"2407.05537","title":"Optimal treatment strategies for prioritized outcomes","authors":"Kyle Duke, Eric B. Laber, Marie Davidian, Michael Newcomb, Brian\n  Mustanksi","authorsParsed":[["Duke","Kyle",""],["Laber","Eric B.",""],["Davidian","Marie",""],["Newcomb","Michael",""],["Mustanksi","Brian",""]],"versions":[{"version":"v1","created":"Mon, 8 Jul 2024 00:56:51 GMT"}],"updateDate":"2024-07-09","timestamp":1720400211000,"abstract":"  Dynamic treatment regimes formalize precision medicine as a sequence of\ndecision rules, one for each stage of clinical intervention, that map current\npatient information to a recommended intervention. Optimal regimes are\ntypically defined as maximizing some functional of a scalar outcome's\ndistribution, e.g., the distribution's mean or median. However, in many\nclinical applications, there are multiple outcomes of interest. We consider the\nproblem of estimating an optimal regime when there are multiple outcomes that\nare ordered by priority but which cannot be readily combined by domain experts\ninto a meaningful single scalar outcome. We propose a definition of optimality\nin this setting and show that an optimal regime with respect to this definition\nleads to maximal mean utility under a large class of utility functions.\nFurthermore, we use inverse reinforcement learning to identify a composite\noutcome that most closely aligns with our definition within a pre-specified\nclass. Simulation experiments and an application to data from a sequential\nmultiple assignment randomized trial (SMART) on HIV/STI prevention illustrate\nthe usefulness of the proposed approach.\n","subjects":["Statistics/Methodology"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}