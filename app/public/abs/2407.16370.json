{"id":"2407.16370","title":"Evolutionary Prompt Design for LLM-Based Post-ASR Error Correction","authors":"Rithik Sachdev and Zhong-Qiu Wang and Chao-Han Huck Yang","authorsParsed":[["Sachdev","Rithik",""],["Wang","Zhong-Qiu",""],["Yang","Chao-Han Huck",""]],"versions":[{"version":"v1","created":"Tue, 23 Jul 2024 10:38:49 GMT"}],"updateDate":"2024-07-24","timestamp":1721731129000,"abstract":"  Building upon the strength of modern large language models (LLMs), generative\nerror correction (GEC) has emerged as a promising paradigm that can elevate the\nperformance of modern automatic speech recognition (ASR) systems. One\nrepresentative approach is to leverage in-context learning to prompt LLMs so\nthat a better hypothesis can be generated by the LLMs based on a\ncarefully-designed prompt and an $N$-best list of hypotheses produced by ASR\nsystems. However, it is yet unknown whether the existing prompts are the most\neffective ones for the task of post-ASR error correction. In this context, this\npaper first explores alternative prompts to identify an initial set of\neffective prompts, and then proposes to employ an evolutionary prompt\noptimization algorithm to refine the initial prompts. Evaluations results on\nthe CHiME-4 subset of the Task $1$ of the SLT $2024$ GenSEC challenge show the\neffectiveness and potential of the proposed algorithms.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Sound","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by/4.0/"}