{"id":"2407.02687","title":"No Training, No Problem: Rethinking Classifier-Free Guidance for\n  Diffusion Models","authors":"Seyedmorteza Sadat, Manuel Kansy, Otmar Hilliges, Romann M. Weber","authorsParsed":[["Sadat","Seyedmorteza",""],["Kansy","Manuel",""],["Hilliges","Otmar",""],["Weber","Romann M.",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 22:04:00 GMT"}],"updateDate":"2024-07-04","timestamp":1719957840000,"abstract":"  Classifier-free guidance (CFG) has become the standard method for enhancing\nthe quality of conditional diffusion models. However, employing CFG requires\neither training an unconditional model alongside the main diffusion model or\nmodifying the training procedure by periodically inserting a null condition.\nThere is also no clear extension of CFG to unconditional models. In this paper,\nwe revisit the core principles of CFG and introduce a new method, independent\ncondition guidance (ICG), which provides the benefits of CFG without the need\nfor any special training procedures. Our approach streamlines the training\nprocess of conditional diffusion models and can also be applied during\ninference on any pre-trained conditional model. Additionally, by leveraging the\ntime-step information encoded in all diffusion networks, we propose an\nextension of CFG, called time-step guidance (TSG), which can be applied to any\ndiffusion model, including unconditional ones. Our guidance techniques are easy\nto implement and have the same sampling cost as CFG. Through extensive\nexperiments, we demonstrate that ICG matches the performance of standard CFG\nacross various conditional diffusion models. Moreover, we show that TSG\nimproves generation quality in a manner similar to CFG, without relying on any\nconditional information.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}