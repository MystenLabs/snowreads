{"id":"2408.09576","title":"A Markov Random Field Multi-Modal Variational AutoEncoder","authors":"Fouad Oubari, Mohamed El Baha, Raphael Meunier, Rodrigue D\\'ecatoire,\n  Mathilde Mougeot","authorsParsed":[["Oubari","Fouad",""],["Baha","Mohamed El",""],["Meunier","Raphael",""],["DÃ©catoire","Rodrigue",""],["Mougeot","Mathilde",""]],"versions":[{"version":"v1","created":"Sun, 18 Aug 2024 19:27:30 GMT"}],"updateDate":"2024-08-20","timestamp":1724009250000,"abstract":"  Recent advancements in multimodal Variational AutoEncoders (VAEs) have\nhighlighted their potential for modeling complex data from multiple modalities.\nHowever, many existing approaches use relatively straightforward aggregating\nschemes that may not fully capture the complex dynamics present between\ndifferent modalities. This work introduces a novel multimodal VAE that\nincorporates a Markov Random Field (MRF) into both the prior and posterior\ndistributions. This integration aims to capture complex intermodal interactions\nmore effectively. Unlike previous models, our approach is specifically designed\nto model and leverage the intricacies of these relationships, enabling a more\nfaithful representation of multimodal data. Our experiments demonstrate that\nour model performs competitively on the standard PolyMNIST dataset and shows\nsuperior performance in managing complex intermodal dependencies in a specially\ndesigned synthetic dataset, intended to test intricate relationships.\n","subjects":["Computing Research Repository/Machine Learning","Statistics/Machine Learning"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/"}