{"id":"2408.01715","title":"Joint Universal Adversarial Perturbations with Interpretations","authors":"Liang-bo Ning, Zeyu Dai, Wenqi Fan, Jingran Su, Chao Pan, Luning Wang,\n  Qing Li","authorsParsed":[["Ning","Liang-bo",""],["Dai","Zeyu",""],["Fan","Wenqi",""],["Su","Jingran",""],["Pan","Chao",""],["Wang","Luning",""],["Li","Qing",""]],"versions":[{"version":"v1","created":"Sat, 3 Aug 2024 08:58:04 GMT"}],"updateDate":"2024-08-06","timestamp":1722675484000,"abstract":"  Deep neural networks (DNNs) have significantly boosted the performance of\nmany challenging tasks. Despite the great development, DNNs have also exposed\ntheir vulnerability. Recent studies have shown that adversaries can manipulate\nthe predictions of DNNs by adding a universal adversarial perturbation (UAP) to\nbenign samples. On the other hand, increasing efforts have been made to help\nusers understand and explain the inner working of DNNs by highlighting the most\ninformative parts (i.e., attribution maps) of samples with respect to their\npredictions. Moreover, we first empirically find that such attribution maps\nbetween benign and adversarial examples have a significant discrepancy, which\nhas the potential to detect universal adversarial perturbations for defending\nagainst adversarial attacks. This finding motivates us to further investigate a\nnew research problem: whether there exist universal adversarial perturbations\nthat are able to jointly attack DNNs classifier and its interpretation with\nmalicious desires. It is challenging to give an explicit answer since these two\nobjectives are seemingly conflicting. In this paper, we propose a novel\nattacking framework to generate joint universal adversarial perturbations\n(JUAP), which can fool the DNNs model and misguide the inspection from\ninterpreters simultaneously. Comprehensive experiments on various datasets\ndemonstrate the effectiveness of the proposed method JUAP for joint attacks. To\nthe best of our knowledge, this is the first effort to study UAP for jointly\nattacking both DNNs and interpretations.\n","subjects":["Computing Research Repository/Cryptography and Security","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}