{"id":"2408.10533","title":"FAGStyle: Feature Augmentation on Geodesic Surface for Zero-shot\n  Text-guided Diffusion Image Style Transfer","authors":"Yuexing Han, Liheng Ruan, Bing Wang","authorsParsed":[["Han","Yuexing",""],["Ruan","Liheng",""],["Wang","Bing",""]],"versions":[{"version":"v1","created":"Tue, 20 Aug 2024 04:20:11 GMT"},{"version":"v2","created":"Wed, 21 Aug 2024 02:24:43 GMT"}],"updateDate":"2024-08-22","timestamp":1724127611000,"abstract":"  The goal of image style transfer is to render an image guided by a style\nreference while maintaining the original content. Existing image-guided methods\nrely on specific style reference images, restricting their wider application\nand potentially compromising result quality. As a flexible alternative,\ntext-guided methods allow users to describe the desired style using text\nprompts. Despite their versatility, these methods often struggle with\nmaintaining style consistency, reflecting the described style accurately, and\npreserving the content of the target image. To address these challenges, we\nintroduce FAGStyle, a zero-shot text-guided diffusion image style transfer\nmethod. Our approach enhances inter-patch information interaction by\nincorporating the Sliding Window Crop technique and Feature Augmentation on\nGeodesic Surface into our style control loss. Furthermore, we integrate a\nPre-Shape self-correlation consistency loss to ensure content consistency.\nFAGStyle demonstrates superior performance over existing methods, consistently\nachieving stylization that retains the semantic content of the source image.\nExperimental results confirms the efficacy of FAGStyle across a diverse range\nof source contents and styles, both imagined and common.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}