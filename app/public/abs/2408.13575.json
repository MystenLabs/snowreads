{"id":"2408.13575","title":"Can Visual Foundation Models Achieve Long-term Point Tracking?","authors":"G\\\"orkay Aydemir, Weidi Xie, Fatma G\\\"uney","authorsParsed":[["Aydemir","Görkay",""],["Xie","Weidi",""],["Güney","Fatma",""]],"versions":[{"version":"v1","created":"Sat, 24 Aug 2024 12:58:08 GMT"}],"updateDate":"2024-08-27","timestamp":1724504288000,"abstract":"  Large-scale vision foundation models have demonstrated remarkable success\nacross various tasks, underscoring their robust generalization capabilities.\nWhile their proficiency in two-view correspondence has been explored, their\neffectiveness in long-term correspondence within complex environments remains\nunexplored. To address this, we evaluate the geometric awareness of visual\nfoundation models in the context of point tracking: (i) in zero-shot settings,\nwithout any training; (ii) by probing with low-capacity layers; (iii) by\nfine-tuning with Low Rank Adaptation (LoRA). Our findings indicate that\nfeatures from Stable Diffusion and DINOv2 exhibit superior geometric\ncorrespondence abilities in zero-shot settings. Furthermore, DINOv2 achieves\nperformance comparable to supervised models in adaptation settings,\ndemonstrating its potential as a strong initialization for correspondence\nlearning.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"aWeQ1T12dk6x1esYJhtwzssNXtWlcv-5wGF7KhY5OXU","pdfSize":"3901498"}
