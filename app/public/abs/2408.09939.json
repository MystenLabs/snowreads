{"id":"2408.09939","title":"\"Image, Tell me your story!\" Predicting the original meta-context of\n  visual misinformation","authors":"Jonathan Tonglet, Marie-Francine Moens, Iryna Gurevych","authorsParsed":[["Tonglet","Jonathan",""],["Moens","Marie-Francine",""],["Gurevych","Iryna",""]],"versions":[{"version":"v1","created":"Mon, 19 Aug 2024 12:21:34 GMT"},{"version":"v2","created":"Tue, 20 Aug 2024 08:59:22 GMT"}],"updateDate":"2024-08-21","timestamp":1724070094000,"abstract":"  To assist human fact-checkers, researchers have developed automated\napproaches for visual misinformation detection. These methods assign veracity\nscores by identifying inconsistencies between the image and its caption, or by\ndetecting forgeries in the image. However, they neglect a crucial point of the\nhuman fact-checking process: identifying the original meta-context of the\nimage. By explaining what is actually true about the image, fact-checkers can\nbetter detect misinformation, focus their efforts on check-worthy visual\ncontent, engage in counter-messaging before misinformation spreads widely, and\nmake their explanation more convincing. Here, we fill this gap by introducing\nthe task of automated image contextualization. We create 5Pils, a dataset of\n1,676 fact-checked images with question-answer pairs about their original\nmeta-context. Annotations are based on the 5 Pillars fact-checking framework.\nWe implement a first baseline that grounds the image in its original\nmeta-context using the content of the image and textual evidence retrieved from\nthe open web. Our experiments show promising results while highlighting several\nopen challenges in retrieval and reasoning. We make our code and data publicly\navailable.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by-sa/4.0/"}