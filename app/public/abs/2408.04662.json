{"id":"2408.04662","title":"Citekit: A Modular Toolkit for Large Language Model Citation Generation","authors":"Jiajun Shen, Tong Zhou, Suifeng Zhao, Yubo Chen, Kang Liu","authorsParsed":[["Shen","Jiajun",""],["Zhou","Tong",""],["Zhao","Suifeng",""],["Chen","Yubo",""],["Liu","Kang",""]],"versions":[{"version":"v1","created":"Tue, 6 Aug 2024 02:13:15 GMT"}],"updateDate":"2024-08-12","timestamp":1722910395000,"abstract":"  Enabling Large Language Models (LLMs) to generate citations in\nQuestion-Answering (QA) tasks is an emerging paradigm aimed at enhancing the\nverifiability of their responses when LLMs are utilizing external references to\ngenerate an answer. However, there is currently no unified framework to\nstandardize and fairly compare different citation generation methods, leading\nto difficulties in reproducing different methods and a comprehensive\nassessment. To cope with the problems above, we introduce \\name, an open-source\nand modular toolkit designed to facilitate the implementation and evaluation of\nexisting citation generation methods, while also fostering the development of\nnew approaches to improve citation quality in LLM outputs. This tool is highly\nextensible, allowing users to utilize 4 main modules and 14 components to\nconstruct a pipeline, evaluating an existing method or innovative designs. Our\nexperiments with two state-of-the-art LLMs and 11 citation generation baselines\ndemonstrate varying strengths of different modules in answer accuracy and\ncitation quality improvement, as well as the challenge of enhancing\ngranularity. Based on our analysis of the effectiveness of components, we\npropose a new method, self-RAG \\snippet, obtaining a balanced answer accuracy\nand citation quality. Citekit is released at\nhttps://github.com/SjJ1017/Citekit.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/"}