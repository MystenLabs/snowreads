{"id":"2407.01742","title":"The Continuous Tensor Abstraction: Where Indices are Real","authors":"Jaeyeon Won, Willow Ahrens, Joel S. Emer, Saman Amarasinghe","authorsParsed":[["Won","Jaeyeon",""],["Ahrens","Willow",""],["Emer","Joel S.",""],["Amarasinghe","Saman",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 19:19:30 GMT"}],"updateDate":"2024-07-03","timestamp":1719861570000,"abstract":"  This paper introduces the continuous tensor abstraction, allowing indices to\ntake real-number values (e.g., A[3.14]), and provides a continuous loop\nconstruct that iterates over the infinitely large set of real numbers. This\npaper expands the existing tensor abstraction to include continuous tensors\nthat exhibit a piecewise-constant property, enabling the transformation of an\ninfinite amount of computation into a finite amount. Additionally, we present a\nnew tensor format abstraction for storing continuous tensors and a code\ngeneration technique that automatically generates kernels for the continuous\ntensor abstraction. Our approach introduces a novel method for loop-level\nreasoning in domains like computational geometry and computer graphics,\ntraditionally unexplored in tensor programming models. Our approach\ndemonstrates comparable performance to hand-optimized kernels in leading\nlibraries across diverse applications. Compared to hand-implemented libraries\non a CPU, our compiler-based implementation achieves an average speedup of\n9.20x on 2D radius search with ~100x fewer lines of code (LoC), 1.22x on\ngenomic interval overlapping queries (with ~26x LoC saving), and 1.69x on\ntrilinear interpolation in Neural Radiance Field (with ~9x LoC saving).\n","subjects":["Computing Research Repository/Programming Languages"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}