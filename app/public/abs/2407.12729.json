{"id":"2407.12729","title":"FlexFL: Heterogeneous Federated Learning via APoZ-Guided Flexible\n  Pruning in Uncertain Scenarios","authors":"Zekai Chen, Chentao Jia, Ming Hu, Xiaofei Xie, Anran Li, Mingsong Chen","authorsParsed":[["Chen","Zekai",""],["Jia","Chentao",""],["Hu","Ming",""],["Xie","Xiaofei",""],["Li","Anran",""],["Chen","Mingsong",""]],"versions":[{"version":"v1","created":"Wed, 17 Jul 2024 16:48:21 GMT"}],"updateDate":"2024-07-18","timestamp":1721234901000,"abstract":"  Along with the increasing popularity of Deep Learning (DL) techniques, more\nand more Artificial Intelligence of Things (AIoT) systems are adopting\nfederated learning (FL) to enable privacy-aware collaborative learning among\nAIoT devices. However, due to the inherent data and device heterogeneity\nissues, existing FL-based AIoT systems suffer from the model selection problem.\nAlthough various heterogeneous FL methods have been investigated to enable\ncollaborative training among heterogeneous models, there is still a lack of i)\nwise heterogeneous model generation methods for devices, ii) consideration of\nuncertain factors, and iii) performance guarantee for large models, thus\nstrongly limiting the overall FL performance. To address the above issues, this\npaper introduces a novel heterogeneous FL framework named FlexFL. By adopting\nour Average Percentage of Zeros (APoZ)-guided flexible pruning strategy, FlexFL\ncan effectively derive best-fit models for heterogeneous devices to explore\ntheir greatest potential. Meanwhile, our proposed adaptive local pruning\nstrategy allows AIoT devices to prune their received models according to their\nvarying resources within uncertain scenarios. Moreover, based on self-knowledge\ndistillation, FlexFL can enhance the inference performance of large models by\nlearning knowledge from small models. Comprehensive experimental results show\nthat, compared to state-of-the-art heterogeneous FL methods, FlexFL can\nsignificantly improve the overall inference accuracy by up to 14.24%.\n","subjects":["Computing Research Repository/Distributed, Parallel, and Cluster Computing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}