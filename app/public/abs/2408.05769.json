{"id":"2408.05769","title":"LI-TTA: Language Informed Test-Time Adaptation for Automatic Speech\n  Recognition","authors":"Eunseop Yoon, Hee Suk Yoon, John Harvill, Mark Hasegawa-Johnson, Chang\n  D. Yoo","authorsParsed":[["Yoon","Eunseop",""],["Yoon","Hee Suk",""],["Harvill","John",""],["Hasegawa-Johnson","Mark",""],["Yoo","Chang D.",""]],"versions":[{"version":"v1","created":"Sun, 11 Aug 2024 13:19:27 GMT"}],"updateDate":"2024-08-13","timestamp":1723382367000,"abstract":"  Test-Time Adaptation (TTA) has emerged as a crucial solution to the domain\nshift challenge, wherein the target environment diverges from the original\ntraining environment. A prime exemplification is TTA for Automatic Speech\nRecognition (ASR), which enhances model performance by leveraging output\nprediction entropy minimization as a self-supervision signal. However, a key\nlimitation of this self-supervision lies in its primary focus on acoustic\nfeatures, with minimal attention to the linguistic properties of the input. To\naddress this gap, we propose Language Informed Test-Time Adaptation (LI-TTA),\nwhich incorporates linguistic insights during TTA for ASR. LI-TTA integrates\ncorrections from an external language model to merge linguistic with acoustic\ninformation by minimizing the CTC loss from the correction alongside the\nstandard TTA loss. With extensive experiments, we show that LI-TTA effectively\nimproves the performance of TTA for ASR in various distribution shift\nsituations.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Sound","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}