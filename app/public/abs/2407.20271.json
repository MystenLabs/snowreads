{"id":"2407.20271","title":"Learn while Unlearn: An Iterative Unlearning Framework for Generative\n  Language Models","authors":"Haoyu Tang, Ye Liu, Xukai Liu, Kai Zhang, Yanghai Zhang, Qi Liu,\n  Enhong Chen","authorsParsed":[["Tang","Haoyu",""],["Liu","Ye",""],["Liu","Xukai",""],["Zhang","Kai",""],["Zhang","Yanghai",""],["Liu","Qi",""],["Chen","Enhong",""]],"versions":[{"version":"v1","created":"Thu, 25 Jul 2024 07:09:35 GMT"}],"updateDate":"2024-07-31","timestamp":1721891375000,"abstract":"  Recent advancements in machine learning, especially in Natural Language\nProcessing (NLP), have led to the development of sophisticated models trained\non vast datasets, but this progress has raised concerns about potential\nsensitive information leakage. In response, regulatory measures like the EU\nGeneral Data Protection Regulation (GDPR) have driven the exploration of\nMachine Unlearning techniques, which aim to enable models to selectively forget\ncertain data entries. While early approaches focused on pre-processing methods,\nrecent research has shifted towards training-based machine unlearning methods.\nHowever, many existing methods require access to original training data, posing\nchallenges in scenarios where such data is unavailable. Besides, directly\nfacilitating unlearning may undermine the language model's general expressive\nability. To this end, in this paper, we introduce the Iterative Contrastive\nUnlearning (ICU) framework, which addresses these challenges by incorporating\nthree key components. We propose a Knowledge Unlearning Induction module for\nunlearning specific target sequences and a Contrastive Learning Enhancement\nmodule to prevent degrading in generation capacity. Additionally, an Iterative\nUnlearning Refinement module is integrated to make the process more adaptive to\neach target sample respectively. Experimental results demonstrate the efficacy\nof ICU in maintaining performance while efficiently unlearning sensitive\ninformation, offering a promising avenue for privacy-conscious machine learning\napplications.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}