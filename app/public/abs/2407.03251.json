{"id":"2407.03251","title":"ACTRESS: Active Retraining for Semi-supervised Visual Grounding","authors":"Weitai Kang, Mengxue Qu, Yunchao Wei, Yan Yan","authorsParsed":[["Kang","Weitai",""],["Qu","Mengxue",""],["Wei","Yunchao",""],["Yan","Yan",""]],"versions":[{"version":"v1","created":"Wed, 3 Jul 2024 16:33:31 GMT"},{"version":"v2","created":"Sat, 6 Jul 2024 15:20:26 GMT"}],"updateDate":"2024-07-09","timestamp":1720024411000,"abstract":"  Semi-Supervised Visual Grounding (SSVG) is a new challenge for its sparse\nlabeled data with the need for multimodel understanding. A previous study,\nRefTeacher, makes the first attempt to tackle this task by adopting the\nteacher-student framework to provide pseudo confidence supervision and\nattention-based supervision. However, this approach is incompatible with\ncurrent state-of-the-art visual grounding models, which follow the\nTransformer-based pipeline. These pipelines directly regress results without\nregion proposals or foreground binary classification, rendering them unsuitable\nfor fitting in RefTeacher due to the absence of confidence scores. Furthermore,\nthe geometric difference in teacher and student inputs, stemming from different\ndata augmentations, induces natural misalignment in attention-based\nconstraints. To establish a compatible SSVG framework, our paper proposes the\nACTive REtraining approach for Semi-Supervised Visual Grounding, abbreviated as\nACTRESS. Initially, the model is enhanced by incorporating an additional\nquantized detection head to expose its detection confidence. Building upon\nthis, ACTRESS consists of an active sampling strategy and a selective\nretraining strategy. The active sampling strategy iteratively selects\nhigh-quality pseudo labels by evaluating three crucial aspects: Faithfulness,\nRobustness, and Confidence, optimizing the utilization of unlabeled data. The\nselective retraining strategy retrains the model with periodic\nre-initialization of specific parameters, facilitating the model's escape from\nlocal minima. Extensive experiments demonstrates our superior performance on\nwidely-used benchmark datasets.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}