{"id":"2407.00600","title":"GenderBias-\\emph{VL}: Benchmarking Gender Bias in Vision Language Models\n  via Counterfactual Probing","authors":"Yisong Xiao, Aishan Liu, QianJia Cheng, Zhenfei Yin, Siyuan Liang,\n  Jiapeng Li, Jing Shao, Xianglong Liu, Dacheng Tao","authorsParsed":[["Xiao","Yisong",""],["Liu","Aishan",""],["Cheng","QianJia",""],["Yin","Zhenfei",""],["Liang","Siyuan",""],["Li","Jiapeng",""],["Shao","Jing",""],["Liu","Xianglong",""],["Tao","Dacheng",""]],"versions":[{"version":"v1","created":"Sun, 30 Jun 2024 05:55:15 GMT"}],"updateDate":"2024-07-02","timestamp":1719726915000,"abstract":"  Large Vision-Language Models (LVLMs) have been widely adopted in various\napplications; however, they exhibit significant gender biases. Existing\nbenchmarks primarily evaluate gender bias at the demographic group level,\nneglecting individual fairness, which emphasizes equal treatment of similar\nindividuals. This research gap limits the detection of discriminatory\nbehaviors, as individual fairness offers a more granular examination of biases\nthat group fairness may overlook. For the first time, this paper introduces the\nGenderBias-\\emph{VL} benchmark to evaluate occupation-related gender bias in\nLVLMs using counterfactual visual questions under individual fairness criteria.\nTo construct this benchmark, we first utilize text-to-image diffusion models to\ngenerate occupation images and their gender counterfactuals. Subsequently, we\ngenerate corresponding textual occupation options by identifying stereotyped\noccupation pairs with high semantic similarity but opposite gender proportions\nin real-world statistics. This method enables the creation of large-scale\nvisual question counterfactuals to expose biases in LVLMs, applicable in both\nmultimodal and unimodal contexts through modifying gender attributes in\nspecific modalities. Overall, our GenderBias-\\emph{VL} benchmark comprises\n34,581 visual question counterfactual pairs, covering 177 occupations. Using\nour benchmark, we extensively evaluate 15 commonly used open-source LVLMs (\\eg,\nLLaVA) and state-of-the-art commercial APIs, including GPT-4o and Gemini-Pro.\nOur findings reveal widespread gender biases in existing LVLMs. Our benchmark\noffers: (1) a comprehensive dataset for occupation-related gender bias\nevaluation; (2) an up-to-date leaderboard on LVLM biases; and (3) a nuanced\nunderstanding of the biases presented by these models. \\footnote{The dataset\nand code are available at the \\href{https://genderbiasvl.github.io/}{website}.}\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"22u27dRTWfKHm4J7X_bMt2NRrGTJe-HF6_4QpMDnBbo","pdfSize":"809373","objectId":"0xeaab1f98250a4b0bd538ddb356528244afac9c2bb8d2316feb7274c4086c66e3","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
