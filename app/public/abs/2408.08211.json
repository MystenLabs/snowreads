{"id":"2408.08211","title":"Learned Multimodal Compression for Autonomous Driving","authors":"Hadi Hadizadeh and Ivan V. Baji\\'c","authorsParsed":[["Hadizadeh","Hadi",""],["BajiÄ‡","Ivan V.",""]],"versions":[{"version":"v1","created":"Thu, 15 Aug 2024 15:20:55 GMT"}],"updateDate":"2024-08-16","timestamp":1723735255000,"abstract":"  Autonomous driving sensors generate an enormous amount of data. In this\npaper, we explore learned multimodal compression for autonomous driving,\nspecifically targeted at 3D object detection. We focus on camera and LiDAR\nmodalities and explore several coding approaches. One approach involves joint\ncoding of fused modalities, while others involve coding one modality first,\nfollowed by conditional coding of the other modality. We evaluate the\nperformance of these coding schemes on the nuScenes dataset. Our experimental\nresults indicate that joint coding of fused modalities yields better results\ncompared to the alternatives.\n","subjects":["Electrical Engineering and Systems Science/Image and Video Processing","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}