{"id":"2407.01292","title":"Preserving Relative Localization of FoV-Limited Drone Swarm via Active\n  Mutual Observation","authors":"Lianjie Guo, Zaitian Gongye, Ziyi Xu, Yingjian Wang, Xin Zhou, Jinni\n  Zhou, and Fei Gao","authorsParsed":[["Guo","Lianjie",""],["Gongye","Zaitian",""],["Xu","Ziyi",""],["Wang","Yingjian",""],["Zhou","Xin",""],["Zhou","Jinni",""],["Gao","Fei",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 13:45:59 GMT"}],"updateDate":"2024-07-02","timestamp":1719841559000,"abstract":"  Relative state estimation is crucial for vision-based swarms to estimate and\ncompensate for the unavoidable drift of visual odometry. For autonomous drones\nequipped with the most compact sensor setting -- a stereo camera that provides\na limited field of view (FoV), the demand for mutual observation for relative\nstate estimation conflicts with the demand for environment observation. To\nbalance the two demands for FoV limited swarms by acquiring mutual observations\nwith a safety guarantee, this paper proposes an active localization correction\nsystem, which plans camera orientations via a yaw planner during the flight.\nThe yaw planner manages the contradiction by calculating suitable timing and\nyaw angle commands based on the evaluation of localization uncertainty\nestimated by the Kalman Filter. Simulation validates the scalability of our\nalgorithm. In real-world experiments, we reduce positioning drift by up to 65%\nand managed to maintain a given formation in both indoor and outdoor GPS-denied\nflight, from which the accuracy, efficiency, and robustness of the proposed\nsystem are verified.\n","subjects":["Computing Research Repository/Robotics"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}