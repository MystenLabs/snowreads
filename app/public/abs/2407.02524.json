{"id":"2407.02524","title":"Meta Large Language Model Compiler: Foundation Models of Compiler\n  Optimization","authors":"Chris Cummins, Volker Seeker, Dejan Grubisic, Baptiste Roziere, Jonas\n  Gehring, Gabriel Synnaeve, Hugh Leather","authorsParsed":[["Cummins","Chris",""],["Seeker","Volker",""],["Grubisic","Dejan",""],["Roziere","Baptiste",""],["Gehring","Jonas",""],["Synnaeve","Gabriel",""],["Leather","Hugh",""]],"versions":[{"version":"v1","created":"Thu, 27 Jun 2024 21:47:48 GMT"}],"updateDate":"2024-07-04","timestamp":1719524868000,"abstract":"  Large Language Models (LLMs) have demonstrated remarkable capabilities across\na variety of software engineering and coding tasks. However, their application\nin the domain of code and compiler optimization remains underexplored. Training\nLLMs is resource-intensive, requiring substantial GPU hours and extensive data\ncollection, which can be prohibitive. To address this gap, we introduce Meta\nLarge Language Model Compiler (LLM Compiler), a suite of robust, openly\navailable, pre-trained models specifically designed for code optimization\ntasks. Built on the foundation of Code Llama, LLM Compiler enhances the\nunderstanding of compiler intermediate representations (IRs), assembly\nlanguage, and optimization techniques. The model has been trained on a vast\ncorpus of 546 billion tokens of LLVM-IR and assembly code and has undergone\ninstruction fine-tuning to interpret compiler behavior. LLM Compiler is\nreleased under a bespoke commercial license to allow wide reuse and is\navailable in two sizes: 7 billion and 13 billion parameters. We also present\nfine-tuned versions of the model, demonstrating its enhanced capabilities in\noptimizing code size and disassembling from x86_64 and ARM assembly back into\nLLVM-IR. These achieve 77% of the optimising potential of an autotuning search,\nand 45% disassembly round trip (14% exact match). This release aims to provide\na scalable, cost-effective foundation for further research and development in\ncompiler optimization by both academic researchers and industry practitioners.\n","subjects":["Computing Research Repository/Programming Languages","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"6rZ36XpQm-TBBem7wavQYBurFANNbwMYpNBMNwOynlI","pdfSize":"1524275","objectId":"0x3d9db9f36f5159f654138f54ecf4badecc14a83fc0e65a99f3681df80fc9f20f","registeredEpoch":"3","certifiedEpoch":"3","startEpoch":"3","endEpoch":"203"}
