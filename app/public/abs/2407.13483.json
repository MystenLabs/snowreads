{"id":"2407.13483","title":"SCAPE: A Simple and Strong Category-Agnostic Pose Estimator","authors":"Yujia Liang, Zixuan Ye, Wenze Liu, Hao Lu","authorsParsed":[["Liang","Yujia",""],["Ye","Zixuan",""],["Liu","Wenze",""],["Lu","Hao",""]],"versions":[{"version":"v1","created":"Thu, 18 Jul 2024 13:02:57 GMT"}],"updateDate":"2024-07-19","timestamp":1721307777000,"abstract":"  Category-Agnostic Pose Estimation (CAPE) aims to localize keypoints on an\nobject of any category given few exemplars in an in-context manner. Prior arts\ninvolve sophisticated designs, e.g., sundry modules for similarity calculation\nand a two-stage framework, or takes in extra heatmap generation and\nsupervision. We notice that CAPE is essentially a task about feature matching,\nwhich can be solved within the attention process. Therefore we first streamline\nthe architecture into a simple baseline consisting of several pure\nself-attention layers and an MLP regression head -- this simplification means\nthat one only needs to consider the attention quality to boost the performance\nof CAPE. Towards an effective attention process for CAPE, we further introduce\ntwo key modules: i) a global keypoint feature perceptor to inject global\nsemantic information into support keypoints, and ii) a keypoint attention\nrefiner to enhance inter-node correlation between keypoints. They jointly form\na Simple and strong Category-Agnostic Pose Estimator (SCAPE). Experimental\nresults show that SCAPE outperforms prior arts by 2.2 and 1.3 PCK under 1-shot\nand 5-shot settings with faster inference speed and lighter model capacity,\nexcelling in both accuracy and efficiency. Code and models are available at\nhttps://github.com/tiny-smart/SCAPE\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}