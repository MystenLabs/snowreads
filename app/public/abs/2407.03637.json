{"id":"2407.03637","title":"QET: Enhancing Quantized LLM Parameters and KV cache Compression through\n  Element Substitution and Residual Clustering","authors":"Yanshu Wang, Wang Li, Zhaoqian Yao and Tong Yang","authorsParsed":[["Wang","Yanshu",""],["Li","Wang",""],["Yao","Zhaoqian",""],["Yang","Tong",""]],"versions":[{"version":"v1","created":"Thu, 4 Jul 2024 05:13:58 GMT"},{"version":"v2","created":"Mon, 19 Aug 2024 03:18:59 GMT"},{"version":"v3","created":"Wed, 21 Aug 2024 02:32:43 GMT"},{"version":"v4","created":"Fri, 6 Sep 2024 08:28:01 GMT"}],"updateDate":"2024-09-09","timestamp":1720070038000,"abstract":"  The matrix quantization entails representing matrix elements in a more\nspace-efficient form to reduce storage usage, with dequantization restoring the\noriginal matrix for use. We formulate the Quantization Error Minimization (QEM)\nproblem as minimizing the distance between a matrix before and after\nquantization, under the condition that the quantized matrix occupies the same\nmemory space. Matrix quantization is crucial in various applications, including\nLarge Language Models (LLMs) weight quantization, vector databases, KV cache\nquantization, graph compression, and image compression. Recent advancements in\nLLMs, such as GPT-4 and BERT, have highlighted the importance of matrix\ncompression due to the large size of parameters and KV cache, which are stored\nas matrices.\n  We propose Quantum Entanglement Trees (QET) to address the QEM problem by\nleveraging the local orderliness of matrix elements, involving iterative\nelement swapping to form a locally ordered matrix. This matrix is then grouped\nand quantized by columns. To enhance QET, we introduce two optimizations:\nfurther quantizing residuals to reduce MSE, and using masking and batch\nprocessing to accelerate the algorithm.\n  Experimental results demonstrate that QET can effectively reduce MSE to\n5.05%, 13.33%, and 11.89% of the current best method on the LLM dataset, K\ncache, and V cache, respectively. Our contributions include the abstraction of\nthe QEM problem, the design of the QET algorithm, and the proposal of two\noptimizations to improve accuracy and speed.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}