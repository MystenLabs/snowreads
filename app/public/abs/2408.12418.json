{"id":"2408.12418","title":"CODE: Confident Ordinary Differential Editing","authors":"Bastien van Delft, Tommaso Martorella, Alexandre Alahi","authorsParsed":[["van Delft","Bastien",""],["Martorella","Tommaso",""],["Alahi","Alexandre",""]],"versions":[{"version":"v1","created":"Thu, 22 Aug 2024 14:12:20 GMT"}],"updateDate":"2024-08-23","timestamp":1724335940000,"abstract":"  Conditioning image generation facilitates seamless editing and the creation\nof photorealistic images. However, conditioning on noisy or Out-of-Distribution\n(OoD) images poses significant challenges, particularly in balancing fidelity\nto the input and realism of the output. We introduce Confident Ordinary\nDifferential Editing (CODE), a novel approach for image synthesis that\neffectively handles OoD guidance images. Utilizing a diffusion model as a\ngenerative prior, CODE enhances images through score-based updates along the\nprobability-flow Ordinary Differential Equation (ODE) trajectory. This method\nrequires no task-specific training, no handcrafted modules, and no assumptions\nregarding the corruptions affecting the conditioning image. Our method is\ncompatible with any diffusion model. Positioned at the intersection of\nconditional image generation and blind image restoration, CODE operates in a\nfully blind manner, relying solely on a pre-trained generative model. Our\nmethod introduces an alternative approach to blind restoration: instead of\ntargeting a specific ground truth image based on assumptions about the\nunderlying corruption, CODE aims to increase the likelihood of the input image\nwhile maintaining fidelity. This results in the most probable in-distribution\nimage around the input. Our contributions are twofold. First, CODE introduces a\nnovel editing method based on ODE, providing enhanced control, realism, and\nfidelity compared to its SDE-based counterpart. Second, we introduce a\nconfidence interval-based clipping method, which improves CODE's effectiveness\nby allowing it to disregard certain pixels or information, thus enhancing the\nrestoration process in a blind manner. Experimental results demonstrate CODE's\neffectiveness over existing methods, particularly in scenarios involving severe\ndegradation or OoD inputs.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}