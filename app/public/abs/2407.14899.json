{"id":"2407.14899","title":"Hyperspectral Unmixing Under Endmember Variability: A Variational\n  Inference Framework","authors":"Yuening Li, Xiao Fu, Junbin Liu, and Wing-Kin Ma","authorsParsed":[["Li","Yuening",""],["Fu","Xiao",""],["Liu","Junbin",""],["Ma","Wing-Kin",""]],"versions":[{"version":"v1","created":"Sat, 20 Jul 2024 15:16:14 GMT"}],"updateDate":"2024-07-23","timestamp":1721488574000,"abstract":"  This work proposes a variational inference (VI) framework for hyperspectral\nunmixing in the presence of endmember variability (HU-EV). An EV-accounted\nnoisy linear mixture model (LMM) is considered, and the presence of outliers is\nalso incorporated into the model. Following the marginalized maximum likelihood\n(MML) principle, a VI algorithmic structure is designed for probabilistic\ninference for HU-EV. Specifically, a patch-wise static endmember assumption is\nemployed to exploit spatial smoothness and to try to overcome the ill-posed\nnature of the HU-EV problem. The design facilitates lightweight, continuous\noptimization-based updates under a variety of endmember priors. Some of the\npriors, such as the Beta prior, were previously used under computationally\nheavy, sampling-based probabilistic HU-EV methods. The effectiveness of the\nproposed framework is demonstrated through synthetic, semi-real, and real-data\nexperiments.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/"}