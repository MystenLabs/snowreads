{"id":"2408.00337","title":"DistillGrasp: Integrating Features Correlation with Knowledge\n  Distillation for Depth Completion of Transparent Objects","authors":"Yiheng Huang, Junhong Chen, Nick Michiels, Muhammad Asim, Luc Claesen,\n  and Wenyin Liu","authorsParsed":[["Huang","Yiheng",""],["Chen","Junhong",""],["Michiels","Nick",""],["Asim","Muhammad",""],["Claesen","Luc",""],["Liu","Wenyin",""]],"versions":[{"version":"v1","created":"Thu, 1 Aug 2024 07:17:10 GMT"}],"updateDate":"2024-08-02","timestamp":1722496630000,"abstract":"  Due to the visual properties of reflection and refraction, RGB-D cameras\ncannot accurately capture the depth of transparent objects, leading to\nincomplete depth maps. To fill in the missing points, recent studies tend to\nexplore new visual features and design complex networks to reconstruct the\ndepth, however, these approaches tremendously increase computation, and the\ncorrelation of different visual features remains a problem. To this end, we\npropose an efficient depth completion network named DistillGrasp which\ndistillates knowledge from the teacher branch to the student branch.\nSpecifically, in the teacher branch, we design a position correlation block\n(PCB) that leverages RGB images as the query and key to search for the\ncorresponding values, guiding the model to establish correct correspondence\nbetween two features and transfer it to the transparent areas. For the student\nbranch, we propose a consistent feature correlation module (CFCM) that retains\nthe reliable regions of RGB images and depth maps respectively according to the\nconsistency and adopts a CNN to capture the pairwise relationship for depth\ncompletion. To avoid the student branch only learning regional features from\nthe teacher branch, we devise a distillation loss that not only considers the\ndistance loss but also the object structure and edge information. Extensive\nexperiments conducted on the ClearGrasp dataset manifest that our teacher\nnetwork outperforms state-of-the-art methods in terms of accuracy and\ngeneralization, and the student network achieves competitive results with a\nhigher speed of 48 FPS. In addition, the significant improvement in a\nreal-world robotic grasping system illustrates the effectiveness and robustness\nof our proposed system.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Information Retrieval"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}