{"id":"2407.17967","title":"Lightweight Language-driven Grasp Detection using Conditional\n  Consistency Model","authors":"Nghia Nguyen, Minh Nhat Vu, Baoru Huang, An Vuong, Ngan Le, Thieu Vo,\n  Anh Nguyen","authorsParsed":[["Nguyen","Nghia",""],["Vu","Minh Nhat",""],["Huang","Baoru",""],["Vuong","An",""],["Le","Ngan",""],["Vo","Thieu",""],["Nguyen","Anh",""]],"versions":[{"version":"v1","created":"Thu, 25 Jul 2024 11:39:20 GMT"}],"updateDate":"2024-07-26","timestamp":1721907560000,"abstract":"  Language-driven grasp detection is a fundamental yet challenging task in\nrobotics with various industrial applications. In this work, we present a new\napproach for language-driven grasp detection that leverages the concept of\nlightweight diffusion models to achieve fast inference time. By integrating\ndiffusion processes with grasping prompts in natural language, our method can\neffectively encode visual and textual information, enabling more accurate and\nversatile grasp positioning that aligns well with the text query. To overcome\nthe long inference time problem in diffusion models, we leverage the image and\ntext features as the condition in the consistency model to reduce the number of\ndenoising timesteps during inference. The intensive experimental results show\nthat our method outperforms other recent grasp detection methods and\nlightweight diffusion models by a clear margin. We further validate our method\nin real-world robotic experiments to demonstrate its fast inference time\ncapability.\n","subjects":["Computing Research Repository/Robotics","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}