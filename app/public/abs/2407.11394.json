{"id":"2407.11394","title":"DreamCatalyst: Fast and High-Quality 3D Editing via Controlling\n  Editability and Identity Preservation","authors":"Jiwook Kim, Seonho Lee, Jaeyo Shin, Jiho Choi, and Hyunjung Shim","authorsParsed":[["Kim","Jiwook",""],["Lee","Seonho",""],["Shin","Jaeyo",""],["Choi","Jiho",""],["Shim","Hyunjung",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 05:26:14 GMT"}],"updateDate":"2024-07-17","timestamp":1721107574000,"abstract":"  Score distillation sampling (SDS) has emerged as an effective framework in\ntext-driven 3D editing tasks due to its inherent 3D consistency. However,\nexisting SDS-based 3D editing methods suffer from extensive training time and\nlead to low-quality results, primarily because these methods deviate from the\nsampling dynamics of diffusion models. In this paper, we propose DreamCatalyst,\na novel framework that interprets SDS-based editing as a diffusion reverse\nprocess. Our objective function considers the sampling dynamics, thereby making\nthe optimization process of DreamCatalyst an approximation of the diffusion\nreverse process in editing tasks. DreamCatalyst aims to reduce training time\nand improve editing quality. DreamCatalyst presents two modes: (1) a faster\nmode, which edits the NeRF scene in only about 25 minutes, and (2) a\nhigh-quality mode, which produces superior results in less than 70 minutes.\nSpecifically, our high-quality mode outperforms current state-of-the-art NeRF\nediting methods both in terms of speed and quality. See more extensive results\non our project page: https://dream-catalyst.github.io.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Graphics","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}