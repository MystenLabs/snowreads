{"id":"2408.10548","title":"Language Modeling on Tabular Data: A Survey of Foundations, Techniques\n  and Evolution","authors":"Yucheng Ruan, Xiang Lan, Jingying Ma, Yizhi Dong, Kai He, Mengling\n  Feng","authorsParsed":[["Ruan","Yucheng",""],["Lan","Xiang",""],["Ma","Jingying",""],["Dong","Yizhi",""],["He","Kai",""],["Feng","Mengling",""]],"versions":[{"version":"v1","created":"Tue, 20 Aug 2024 04:59:19 GMT"}],"updateDate":"2024-08-21","timestamp":1724129959000,"abstract":"  Tabular data, a prevalent data type across various domains, presents unique\nchallenges due to its heterogeneous nature and complex structural\nrelationships. Achieving high predictive performance and robustness in tabular\ndata analysis holds significant promise for numerous applications. Influenced\nby recent advancements in natural language processing, particularly transformer\narchitectures, new methods for tabular data modeling have emerged. Early\ntechniques concentrated on pre-training transformers from scratch, often\nencountering scalability issues. Subsequently, methods leveraging pre-trained\nlanguage models like BERT have been developed, which require less data and\nyield enhanced performance. The recent advent of large language models, such as\nGPT and LLaMA, has further revolutionized the field, facilitating more advanced\nand diverse applications with minimal fine-tuning. Despite the growing\ninterest, a comprehensive survey of language modeling techniques for tabular\ndata remains absent. This paper fills this gap by providing a systematic review\nof the development of language modeling for tabular data, encompassing: (1) a\ncategorization of different tabular data structures and data types; (2) a\nreview of key datasets used in model training and tasks used for evaluation;\n(3) a summary of modeling techniques including widely-adopted data processing\nmethods, popular architectures, and training objectives; (4) the evolution from\nadapting traditional Pre-training/Pre-trained language models to the\nutilization of large language models; (5) an identification of persistent\nchallenges and potential future research directions in language modeling for\ntabular data analysis. GitHub page associated with this survey is available at:\nhttps://github.com/lanxiang1017/Language-Modeling-on-Tabular-Data-Survey.git.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}