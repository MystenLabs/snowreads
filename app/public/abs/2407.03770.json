{"id":"2407.03770","title":"HYBRINFOX at CheckThat! 2024 -- Task 2: Enriching BERT Models with the\n  Expert System VAGO for Subjectivity Detection","authors":"Morgane Casanova, Julien Chanson, Benjamin Icard, G\\'eraud Faye,\n  Guillaume Gadek, Guillaume Gravier, Paul \\'Egr\\'e","authorsParsed":[["Casanova","Morgane",""],["Chanson","Julien",""],["Icard","Benjamin",""],["Faye","Géraud",""],["Gadek","Guillaume",""],["Gravier","Guillaume",""],["Égré","Paul",""]],"versions":[{"version":"v1","created":"Thu, 4 Jul 2024 09:29:19 GMT"}],"updateDate":"2024-07-08","timestamp":1720085359000,"abstract":"  This paper presents the HYBRINFOX method used to solve Task 2 of Subjectivity\ndetection of the CLEF 2024 CheckThat! competition. The specificity of the\nmethod is to use a hybrid system, combining a RoBERTa model, fine-tuned for\nsubjectivity detection, a frozen sentence-BERT (sBERT) model to capture\nsemantics, and several scores calculated by the English version of the expert\nsystem VAGO, developed independently of this task to measure vagueness and\nsubjectivity in texts based on the lexicon. In English, the HYBRINFOX method\nranked 1st with a macro F1 score of 0.7442 on the evaluation data. For the\nother languages, the method used a translation step into English, producing\nmore mixed results (ranking 1st in Multilingual and 2nd in Italian over the\nbaseline, but under the baseline in Bulgarian, German, and Arabic). We explain\nthe principles of our hybrid approach, and outline ways in which the method\ncould be improved for other languages besides English.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/"}