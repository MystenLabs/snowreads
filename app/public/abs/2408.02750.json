{"id":"2408.02750","title":"Privacy-Safe Iris Presentation Attack Detection","authors":"Mahsa Mitcheff, Patrick Tinsley, Adam Czajka","authorsParsed":[["Mitcheff","Mahsa",""],["Tinsley","Patrick",""],["Czajka","Adam",""]],"versions":[{"version":"v1","created":"Mon, 5 Aug 2024 18:09:02 GMT"}],"updateDate":"2024-08-07","timestamp":1722881342000,"abstract":"  This paper proposes a framework for a privacy-safe iris presentation attack\ndetection (PAD) method, designed solely with synthetically-generated,\nidentity-leakage-free iris images. Once trained, the method is evaluated in a\nclassical way using state-of-the-art iris PAD benchmarks. We designed two\ngenerative models for the synthesis of ISO/IEC 19794-6-compliant iris images.\nThe first model synthesizes bona fide-looking samples. To avoid ``identity\nleakage,'' the generated samples that accidentally matched those used in the\nmodel's training were excluded. The second model synthesizes images of irises\nwith textured contact lenses and is conditioned by a given contact lens brand\nto have better control over textured contact lens appearance when forming the\ntraining set. Our experiments demonstrate that models trained solely on\nsynthetic data achieve a lower but still reasonable performance when compared\nto solutions trained with iris images collected from human subjects. This is\nthe first-of-its-kind attempt to use solely synthetic data to train a\nfully-functional iris PAD solution, and despite the performance gap between\nregular and the proposed methods, this study demonstrates that with the\nincreasing fidelity of generative models, creating such privacy-safe iris PAD\nmethods may be possible. The source codes and generative models trained for\nthis work are offered along with the paper.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Electrical Engineering and Systems Science/Image and Video Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}