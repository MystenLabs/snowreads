{"id":"2407.00499","title":"ConU: Conformal Uncertainty in Large Language Models with Correctness\n  Coverage Guarantees","authors":"Zhiyuan Wang, Jinhao Duan, Lu Cheng, Yue Zhang, Qingni Wang, Hengtao\n  Shen, Xiaofeng Zhu, Xiaoshuang Shi, Kaidi Xu","authorsParsed":[["Wang","Zhiyuan",""],["Duan","Jinhao",""],["Cheng","Lu",""],["Zhang","Yue",""],["Wang","Qingni",""],["Shen","Hengtao",""],["Zhu","Xiaofeng",""],["Shi","Xiaoshuang",""],["Xu","Kaidi",""]],"versions":[{"version":"v1","created":"Sat, 29 Jun 2024 17:33:07 GMT"}],"updateDate":"2024-07-02","timestamp":1719682387000,"abstract":"  Uncertainty quantification (UQ) in natural language generation (NLG) tasks\nremains an open challenge, exacerbated by the intricate nature of the recent\nlarge language models (LLMs). This study investigates adapting conformal\nprediction (CP), which can convert any heuristic measure of uncertainty into\nrigorous theoretical guarantees by constructing prediction sets, for black-box\nLLMs in open-ended NLG tasks. We propose a sampling-based uncertainty measure\nleveraging self-consistency and develop a conformal uncertainty criterion by\nintegrating the uncertainty condition aligned with correctness into the design\nof the CP algorithm. Experimental results indicate that our uncertainty measure\ngenerally surpasses prior state-of-the-art methods. Furthermore, we calibrate\nthe prediction sets within the model's unfixed answer distribution and achieve\nstrict control over the correctness coverage rate across 6 LLMs on 4 free-form\nNLG datasets, spanning general-purpose and medical domains, while the small\naverage set size further highlights the efficiency of our method in providing\ntrustworthy guarantees for practical open-ended NLG applications.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}