{"id":"2408.10846","title":"Harmonizing Attention: Training-free Texture-aware Geometry Transfer","authors":"Eito Ikuta, Yohan Lee, Akihiro Iohara, Yu Saito and Toshiyuki Tanaka","authorsParsed":[["Ikuta","Eito",""],["Lee","Yohan",""],["Iohara","Akihiro",""],["Saito","Yu",""],["Tanaka","Toshiyuki",""]],"versions":[{"version":"v1","created":"Mon, 19 Aug 2024 12:06:25 GMT"},{"version":"v2","created":"Sun, 1 Sep 2024 14:57:12 GMT"}],"updateDate":"2024-09-05","timestamp":1724069185000,"abstract":"  Extracting geometry features from photographic images independently of\nsurface texture and transferring them onto different materials remains a\ncomplex challenge. In this study, we introduce Harmonizing Attention, a novel\ntraining-free approach that leverages diffusion models for texture-aware\ngeometry transfer. Our method employs a simple yet effective modification of\nself-attention layers, allowing the model to query information from multiple\nreference images within these layers. This mechanism is seamlessly integrated\ninto the inversion process as Texture-aligning Attention and into the\ngeneration process as Geometry-aligning Attention. This dual-attention approach\nensures the effective capture and transfer of material-independent geometry\nfeatures while maintaining material-specific textural continuity, all without\nthe need for model fine-tuning.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Multimedia"],"license":"http://creativecommons.org/licenses/by/4.0/"}