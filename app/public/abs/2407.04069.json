{"id":"2407.04069","title":"A Systematic Survey and Critical Review on Evaluating Large Language\n  Models: Challenges, Limitations, and Recommendations","authors":"Md Tahmid Rahman Laskar, Sawsan Alqahtani, M Saiful Bari, Mizanur\n  Rahman, Mohammad Abdullah Matin Khan, Haidar Khan, Israt Jahan, Amran\n  Bhuiyan, Chee Wei Tan, Md Rizwan Parvez, Enamul Hoque, Shafiq Joty, Jimmy\n  Huang","authorsParsed":[["Laskar","Md Tahmid Rahman",""],["Alqahtani","Sawsan",""],["Bari","M Saiful",""],["Rahman","Mizanur",""],["Khan","Mohammad Abdullah Matin",""],["Khan","Haidar",""],["Jahan","Israt",""],["Bhuiyan","Amran",""],["Tan","Chee Wei",""],["Parvez","Md Rizwan",""],["Hoque","Enamul",""],["Joty","Shafiq",""],["Huang","Jimmy",""]],"versions":[{"version":"v1","created":"Thu, 4 Jul 2024 17:15:37 GMT"}],"updateDate":"2024-07-08","timestamp":1720113337000,"abstract":"  Large Language Models (LLMs) have recently gained significant attention due\nto their remarkable capabilities in performing diverse tasks across various\ndomains. However, a thorough evaluation of these models is crucial before\ndeploying them in real-world applications to ensure they produce reliable\nperformance. Despite the well-established importance of evaluating LLMs in the\ncommunity, the complexity of the evaluation process has led to varied\nevaluation setups, causing inconsistencies in findings and interpretations. To\naddress this, we systematically review the primary challenges and limitations\ncausing these inconsistencies and unreliable evaluations in various steps of\nLLM evaluation. Based on our critical review, we present our perspectives and\nrecommendations to ensure LLM evaluations are reproducible, reliable, and\nrobust.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}