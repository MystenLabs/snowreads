{"id":"2407.08216","title":"Multimodal contrastive learning for spatial gene expression prediction\n  using histology images","authors":"Wenwen Min, Zhiceng Shi, Jun Zhang, Jun Wan and Changmiao Wang","authorsParsed":[["Min","Wenwen",""],["Shi","Zhiceng",""],["Zhang","Jun",""],["Wan","Jun",""],["Wang","Changmiao",""]],"versions":[{"version":"v1","created":"Thu, 11 Jul 2024 06:33:38 GMT"}],"updateDate":"2024-07-12","timestamp":1720679618000,"abstract":"  In recent years, the advent of spatial transcriptomics (ST) technology has\nunlocked unprecedented opportunities for delving into the complexities of gene\nexpression patterns within intricate biological systems. Despite its\ntransformative potential, the prohibitive cost of ST technology remains a\nsignificant barrier to its widespread adoption in large-scale studies. An\nalternative, more cost-effective strategy involves employing artificial\nintelligence to predict gene expression levels using readily accessible\nwhole-slide images (WSIs) stained with Hematoxylin and Eosin (H\\&E). However,\nexisting methods have yet to fully capitalize on multimodal information\nprovided by H&E images and ST data with spatial location. In this paper, we\npropose \\textbf{mclSTExp}, a multimodal contrastive learning with Transformer\nand Densenet-121 encoder for Spatial Transcriptomics Expression prediction. We\nconceptualize each spot as a \"word\", integrating its intrinsic features with\nspatial context through the self-attention mechanism of a Transformer encoder.\nThis integration is further enriched by incorporating image features via\ncontrastive learning, thereby enhancing the predictive capability of our model.\nOur extensive evaluation of \\textbf{mclSTExp} on two breast cancer datasets and\na skin squamous cell carcinoma dataset demonstrates its superior performance in\npredicting spatial gene expression. Moreover, mclSTExp has shown promise in\ninterpreting cancer-specific overexpressed genes, elucidating immune-related\ngenes, and identifying specialized spatial domains annotated by pathologists.\nOur source code is available at https://github.com/shizhiceng/mclSTExp.\n","subjects":["Electrical Engineering and Systems Science/Image and Video Processing","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computer Vision and Pattern Recognition","Quantitative Biology/Quantitative Methods"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}