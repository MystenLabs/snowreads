{"id":"2408.06506","title":"TacSL: A Library for Visuotactile Sensor Simulation and Learning","authors":"Iretiayo Akinola, Jie Xu, Jan Carius, Dieter Fox, and Yashraj Narang","authorsParsed":[["Akinola","Iretiayo",""],["Xu","Jie",""],["Carius","Jan",""],["Fox","Dieter",""],["Narang","Yashraj",""]],"versions":[{"version":"v1","created":"Mon, 12 Aug 2024 21:44:43 GMT"}],"updateDate":"2024-08-14","timestamp":1723499083000,"abstract":"  For both humans and robots, the sense of touch, known as tactile sensing, is\ncritical for performing contact-rich manipulation tasks. Three key challenges\nin robotic tactile sensing are 1) interpreting sensor signals, 2) generating\nsensor signals in novel scenarios, and 3) learning sensor-based policies. For\nvisuotactile sensors, interpretation has been facilitated by their close\nrelationship with vision sensors (e.g., RGB cameras). However, generation is\nstill difficult, as visuotactile sensors typically involve contact,\ndeformation, illumination, and imaging, all of which are expensive to simulate;\nin turn, policy learning has been challenging, as simulation cannot be\nleveraged for large-scale data collection. We present \\textbf{TacSL}\n(\\textit{taxel}), a library for GPU-based visuotactile sensor simulation and\nlearning. \\textbf{TacSL} can be used to simulate visuotactile images and\nextract contact-force distributions over $200\\times$ faster than the prior\nstate-of-the-art, all within the widely-used Isaac Gym simulator. Furthermore,\n\\textbf{TacSL} provides a learning toolkit containing multiple sensor models,\ncontact-intensive training environments, and online/offline algorithms that can\nfacilitate policy learning for sim-to-real applications. On the algorithmic\nside, we introduce a novel online reinforcement-learning algorithm called\nasymmetric actor-critic distillation (\\sysName), designed to effectively and\nefficiently learn tactile-based policies in simulation that can transfer to the\nreal world. Finally, we demonstrate the utility of our library and algorithms\nby evaluating the benefits of distillation and multimodal sensing for\ncontact-rich manip ulation tasks, and most critically, performing sim-to-real\ntransfer. Supplementary videos and results are at\n\\url{https://iakinola23.github.io/tacsl/}.\n","subjects":["Computing Research Repository/Robotics"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}