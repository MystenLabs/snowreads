{"id":"2408.09798","title":"Enhance Modality Robustness in Text-Centric Multimodal Alignment with\n  Adversarial Prompting","authors":"Yun-Da Tsai, Ting-Yu Yen, Keng-Te Liao, Shou-De Lin","authorsParsed":[["Tsai","Yun-Da",""],["Yen","Ting-Yu",""],["Liao","Keng-Te",""],["Lin","Shou-De",""]],"versions":[{"version":"v1","created":"Mon, 19 Aug 2024 08:44:55 GMT"}],"updateDate":"2024-08-20","timestamp":1724057095000,"abstract":"  Converting different modalities into generalized text, which then serves as\ninput prompts for large language models (LLMs), is a common approach for\naligning multimodal models, particularly when pairwise data is limited.\nText-centric alignment method leverages the unique properties of text as a\nmodality space, transforming diverse inputs into a unified textual\nrepresentation, thereby enabling downstream models to effectively interpret\nvarious modal inputs. This study evaluates the quality and robustness of\nmultimodal representations in the face of noise imperfections, dynamic input\norder permutations, and missing modalities, revealing that current text-centric\nalignment methods can compromise downstream robustness. To address this issue,\nwe propose a new text-centric adversarial training approach that significantly\nenhances robustness compared to traditional robust training methods and\npre-trained multimodal foundation models. Our findings underscore the potential\nof this approach to improve the robustness and adaptability of multimodal\nrepresentations, offering a promising solution for dynamic and real-world\napplications.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}