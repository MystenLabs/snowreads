{"id":"2408.11638","title":"Improving Query-by-Vocal Imitation with Contrastive Learning and Audio\n  Pretraining","authors":"Jonathan Greif, Florian Schmid, Paul Primus, Gerhard Widmer","authorsParsed":[["Greif","Jonathan",""],["Schmid","Florian",""],["Primus","Paul",""],["Widmer","Gerhard",""]],"versions":[{"version":"v1","created":"Wed, 21 Aug 2024 14:07:06 GMT"}],"updateDate":"2024-08-22","timestamp":1724249226000,"abstract":"  Query-by-Vocal Imitation (QBV) is about searching audio files within\ndatabases using vocal imitations created by the user's voice. Since most humans\ncan effectively communicate sound concepts through voice, QBV offers the more\nintuitive and convenient approach compared to text-based search. To fully\nleverage QBV, developing robust audio feature representations for both the\nvocal imitation and the original sound is crucial. In this paper, we present a\nnew system for QBV that utilizes the feature extraction capabilities of\nConvolutional Neural Networks pre-trained with large-scale general-purpose\naudio datasets. We integrate these pre-trained models into a dual encoder\narchitecture and fine-tune them end-to-end using contrastive learning. A\ndistinctive aspect of our proposed method is the fine-tuning strategy of\npre-trained models using an adapted NT-Xent loss for contrastive learning,\ncreating a shared embedding space for reference recordings and vocal\nimitations. The proposed system significantly enhances audio retrieval\nperformance, establishing a new state of the art on both coarse- and\nfine-grained QBV tasks.\n","subjects":["Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}