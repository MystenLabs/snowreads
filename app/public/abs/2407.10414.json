{"id":"2407.10414","title":"Teaching CORnet Human fMRI Representations for Enhanced Model-Brain\n  Alignment","authors":"Zitong Lu and Yile Wang","authorsParsed":[["Lu","Zitong",""],["Wang","Yile",""]],"versions":[{"version":"v1","created":"Mon, 15 Jul 2024 03:31:42 GMT"}],"updateDate":"2024-07-16","timestamp":1721014302000,"abstract":"  Deep convolutional neural networks (DCNNs) have demonstrated excellent\nperformance in object recognition and have been found to share some\nsimilarities with brain visual processing. However, the substantial gap between\nDCNNs and human visual perception still exists. Functional magnetic resonance\nimaging (fMRI) as a widely used technique in cognitive neuroscience can record\nneural activation in the human visual cortex during the process of visual\nperception. Can we teach DCNNs human fMRI signals to achieve a more brain-like\nmodel? To answer this question, this study proposed ReAlnet-fMRI, a model based\non the SOTA vision model CORnet but optimized using human fMRI data through a\nmulti-layer encoding-based alignment framework. This framework has been shown\nto effectively enable the model to learn human brain representations. The\nfMRI-optimized ReAlnet-fMRI exhibited higher similarity to the human brain than\nboth CORnet and the control model in within-and across-subject as well as\nwithin- and across-modality model-brain (fMRI and EEG) alignment evaluations.\nAdditionally, we conducted an in-depth analyses to investigate how the internal\nrepresentations of ReAlnet-fMRI differ from CORnet in encoding various object\ndimensions. These findings provide the possibility of enhancing the\nbrain-likeness of visual models by integrating human neural data, helping to\nbridge the gap between computer vision and visual neuroscience.\n","subjects":["Electrical Engineering and Systems Science/Image and Video Processing","Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Machine Learning","Quantitative Biology/Neurons and Cognition"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/"}