{"id":"2407.20799","title":"SpotFormer: Multi-Scale Spatio-Temporal Transformer for Facial\n  Expression Spotting","authors":"Yicheng Deng, Hideaki Hayashi, Hajime Nagahara","authorsParsed":[["Deng","Yicheng",""],["Hayashi","Hideaki",""],["Nagahara","Hajime",""]],"versions":[{"version":"v1","created":"Tue, 30 Jul 2024 13:02:08 GMT"}],"updateDate":"2024-07-31","timestamp":1722344528000,"abstract":"  Facial expression spotting, identifying periods where facial expressions\noccur in a video, is a significant yet challenging task in facial expression\nanalysis. The issues of irrelevant facial movements and the challenge of\ndetecting subtle motions in micro-expressions remain unresolved, hindering\naccurate expression spotting. In this paper, we propose an efficient framework\nfor facial expression spotting. First, we propose a Sliding Window-based\nMulti-Resolution Optical flow (SW-MRO) feature, which calculates\nmulti-resolution optical flow of the input image sequence within compact\nsliding windows. The window length is tailored to perceive complete\nmicro-expressions and distinguish between general macro- and micro-expressions.\nSW-MRO can effectively reveal subtle motions while avoiding severe head\nmovement problems. Second, we propose SpotFormer, a multi-scale spatio-temporal\nTransformer that simultaneously encodes spatio-temporal relationships of the\nSW-MRO features for accurate frame-level probability estimation. In SpotFormer,\nour proposed Facial Local Graph Pooling (FLGP) and convolutional layers are\napplied for multi-scale spatio-temporal feature extraction. We show the\nvalidity of the architecture of SpotFormer by comparing it with several model\nvariants. Third, we introduce supervised contrastive learning into SpotFormer\nto enhance the discriminability between different types of expressions.\nExtensive experiments on SAMM-LV and CAS(ME)^2 show that our method outperforms\nstate-of-the-art models, particularly in micro-expression spotting.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}