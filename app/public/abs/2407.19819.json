{"id":"2407.19819","title":"Detecting Unsafe Behavior in Neural Network Imitation Policies for\n  Caregiving Robotics","authors":"Andrii Tytarenko","authorsParsed":[["Tytarenko","Andrii",""]],"versions":[{"version":"v1","created":"Mon, 29 Jul 2024 09:12:49 GMT"}],"updateDate":"2024-07-30","timestamp":1722244369000,"abstract":"  In this paper, the application of imitation learning in caregiving robotics\nis explored, aiming at addressing the increasing demand for automated\nassistance in caring for the elderly and disabled. Leveraging advancements in\ndeep learning and control algorithms, the study focuses on training neural\nnetwork policies using offline demonstrations. A key challenge addressed is the\n\"Policy Stopping\" problem, crucial for enhancing safety in imitation\nlearning-based policies, particularly diffusion policies. Novel solutions\nproposed include ensemble predictors and adaptations of the normalizing\nflow-based algorithm for early anomaly detection. Comparative evaluations\nagainst anomaly detection methods like VAE and Tran-AD demonstrate superior\nperformance on assistive robotics benchmarks. The paper concludes by discussing\nthe further research in integrating safety models into policy training, crucial\nfor the reliable deployment of neural network policies in caregiving robotics.\n","subjects":["Computing Research Repository/Robotics"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"3KRoDFy5xBeYNSz23T1tnI0hNZqxvFIfSLh9ClDeQ_8","pdfSize":"317635","objectId":"0x948fd3ba91545797a99abd118e4167cfb8503d318d6ff8c1d57516e42f0bca3f","registeredEpoch":"2","certifiedEpoch":"2","startEpoch":"2","endEpoch":"202"}
