{"id":"2408.09066","title":"Brain Inspired Probabilistic Occupancy Grid Mapping with\n  Hyperdimensional Computing","authors":"Shay Snyder (1), Andrew Capodieci (2), David Gorsich (3), and Maryam\n  Parsa (1) ((1) George Mason University, (2) Neya Robotics, (3) US Army Ground\n  Vehicle Systems Center)","authorsParsed":[["Snyder","Shay",""],["Capodieci","Andrew",""],["Gorsich","David",""],["Parsa","Maryam",""]],"versions":[{"version":"v1","created":"Sat, 17 Aug 2024 01:45:48 GMT"},{"version":"v2","created":"Mon, 26 Aug 2024 14:53:19 GMT"},{"version":"v3","created":"Tue, 27 Aug 2024 17:36:11 GMT"}],"updateDate":"2024-08-28","timestamp":1723859148000,"abstract":"  Real-time robotic systems require advanced perception, computation, and\naction capability. However, the main bottleneck in current autonomous systems\nis the trade-off between computational capability, energy efficiency and model\ndeterminism. World modeling, a key objective of many robotic systems, commonly\nuses occupancy grid mapping (OGM) as the first step towards building an\nend-to-end robotic system with perception, planning, autonomous maneuvering,\nand decision making capabilities. OGM divides the environment into discrete\ncells and assigns probability values to attributes such as occupancy and\ntraversability. Existing methods fall into two categories: traditional methods\nand neural methods. Traditional methods rely on dense statistical calculations,\nwhile neural methods employ deep learning for probabilistic information\nprocessing. Recent works formulate a deterministic theory of neural computation\nat the intersection of cognitive science and vector symbolic architectures. In\nthis study, we propose a Fourier-based hyperdimensional OGM system, VSA-OGM,\ncombined with a novel application of Shannon entropy that retains the\ninterpretability and stability of traditional methods along with the improved\ncomputational efficiency of neural methods. Our approach, validated across\nmultiple datasets, achieves similar accuracy to covariant traditional methods\nwhile approximately reducing latency by 200x and memory by 1000x. Compared to\ninvariant traditional methods, we see similar accuracy values while reducing\nlatency by 3.7x. Moreover, we achieve 1.5x latency reductions compared to\nneural methods while eliminating the need for domain-specific model training.\n","subjects":["Computing Research Repository/Robotics","Computing Research Repository/Emerging Technologies"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"Cuje3PGVB0DICH-DRx8m9huyU5tEw8W-KUodqVpisxg","pdfSize":"27060985"}
