{"id":"2407.01761","title":"DRAGON: Drone and Ground Gaussian Splatting for 3D Building\n  Reconstruction","authors":"Yujin Ham, Mateusz Michalkiewicz, Guha Balakrishnan","authorsParsed":[["Ham","Yujin",""],["Michalkiewicz","Mateusz",""],["Balakrishnan","Guha",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 19:52:32 GMT"}],"updateDate":"2024-07-03","timestamp":1719863552000,"abstract":"  3D building reconstruction from imaging data is an important task for many\napplications ranging from urban planning to reconnaissance. Modern Novel View\nsynthesis (NVS) methods like NeRF and Gaussian Splatting offer powerful\ntechniques for developing 3D models from natural 2D imagery in an unsupervised\nfashion. These algorithms generally require input training views surrounding\nthe scene of interest, which, in the case of large buildings, is typically not\navailable across all camera elevations. In particular, the most readily\navailable camera viewpoints at scale across most buildings are at near-ground\n(e.g., with mobile phones) and aerial (drones) elevations. However, due to the\nsignificant difference in viewpoint between drone and ground image sets, camera\nregistration - a necessary step for NVS algorithms - fails. In this work we\npropose a method, DRAGON, that can take drone and ground building imagery as\ninput and produce a 3D NVS model. The key insight of DRAGON is that\nintermediate elevation imagery may be extrapolated by an NVS algorithm itself\nin an iterative procedure with perceptual regularization, thereby bridging the\nvisual feature gap between the two elevations and enabling registration. We\ncompiled a semi-synthetic dataset of 9 large building scenes using Google Earth\nStudio, and quantitatively and qualitatively demonstrate that DRAGON can\ngenerate compelling renderings on this dataset compared to baseline strategies.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}