{"id":"2407.16192","title":"How to Leverage Personal Textual Knowledge for Personalized\n  Conversational Information Retrieval","authors":"Fengran Mo, Longxiang Zhao, Kaiyu Huang, Yue Dong, Degen Huang,\n  Jian-Yun Nie","authorsParsed":[["Mo","Fengran",""],["Zhao","Longxiang",""],["Huang","Kaiyu",""],["Dong","Yue",""],["Huang","Degen",""],["Nie","Jian-Yun",""]],"versions":[{"version":"v1","created":"Tue, 23 Jul 2024 05:34:41 GMT"}],"updateDate":"2024-07-24","timestamp":1721712881000,"abstract":"  Personalized conversational information retrieval (CIR) combines\nconversational and personalizable elements to satisfy various users' complex\ninformation needs through multi-turn interaction based on their backgrounds.\nThe key promise is that the personal textual knowledge base (PTKB) can improve\nthe CIR effectiveness because the retrieval results can be more related to the\nuser's background. However, PTKB is noisy: not every piece of knowledge in PTKB\nis relevant to the specific query at hand. In this paper, we explore and test\nseveral ways to select knowledge from PTKB and use it for query reformulation\nby using a large language model (LLM). The experimental results show the PTKB\nmight not always improve the search results when used alone, but LLM can help\ngenerate a more appropriate personalized query when high-quality guidance is\nprovided.\n","subjects":["Computing Research Repository/Information Retrieval","Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}