{"id":"2407.08151","title":"Enrich the content of the image Using Context-Aware Copy Paste","authors":"Qiushi Guo","authorsParsed":[["Guo","Qiushi",""]],"versions":[{"version":"v1","created":"Thu, 11 Jul 2024 03:07:28 GMT"}],"updateDate":"2024-07-12","timestamp":1720667248000,"abstract":"  Data augmentation remains a widely utilized technique in deep learning,\nparticularly in tasks such as image classification, semantic segmentation, and\nobject detection. Among them, Copy-Paste is a simple yet effective method and\ngain great attention recently. However, existing Copy-Paste often overlook\ncontextual relevance between source and target images, resulting in\ninconsistencies in generated outputs. To address this challenge, we propose a\ncontext-aware approach that integrates Bidirectional Latent Information\nPropagation (BLIP) for content extraction from source images. By matching\nextracted content information with category information, our method ensures\ncohesive integration of target objects using Segment Anything Model (SAM) and\nYou Only Look Once (YOLO). This approach eliminates the need for manual\nannotation, offering an automated and user-friendly solution. Experimental\nevaluations across diverse datasets demonstrate the effectiveness of our method\nin enhancing data diversity and generating high-quality pseudo-images across\nvarious computer vision tasks.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}