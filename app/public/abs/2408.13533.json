{"id":"2408.13533","title":"Pandora's Box or Aladdin's Lamp: A Comprehensive Analysis Revealing the\n  Role of RAG Noise in Large Language Models","authors":"Jinyang Wu and Feihu Che and Chuyuan Zhang and Jianhua Tao and Shuai\n  Zhang and Pengpeng Shao","authorsParsed":[["Wu","Jinyang",""],["Che","Feihu",""],["Zhang","Chuyuan",""],["Tao","Jianhua",""],["Zhang","Shuai",""],["Shao","Pengpeng",""]],"versions":[{"version":"v1","created":"Sat, 24 Aug 2024 09:23:01 GMT"}],"updateDate":"2024-08-27","timestamp":1724491381000,"abstract":"  Retrieval-Augmented Generation (RAG) has emerged as a crucial method for\naddressing hallucinations in large language models (LLMs). While recent\nresearch has extended RAG models to complex noisy scenarios, these explorations\noften confine themselves to limited noise types and presuppose that noise is\ninherently detrimental to LLMs, potentially deviating from real-world retrieval\nenvironments and restricting practical applicability. In this paper, we define\nseven distinct noise types from a linguistic perspective and establish a Noise\nRAG Benchmark (NoiserBench), a comprehensive evaluation framework encompassing\nmultiple datasets and reasoning tasks. Through empirical evaluation of eight\nrepresentative LLMs with diverse architectures and scales, we reveal that these\nnoises can be further categorized into two practical groups: noise that is\nbeneficial to LLMs (aka beneficial noise) and noise that is harmful to LLMs\n(aka harmful noise). While harmful noise generally impairs performance,\nbeneficial noise may enhance several aspects of model capabilities and overall\nperformance. Our analysis offers insights for developing more robust, adaptable\nRAG solutions and mitigating hallucinations across diverse retrieval scenarios.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}