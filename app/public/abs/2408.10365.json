{"id":"2408.10365","title":"AI-Driven Review Systems: Evaluating LLMs in Scalable and Bias-Aware\n  Academic Reviews","authors":"Keith Tyser, Ben Segev, Gaston Longhitano, Xin-Yu Zhang, Zachary\n  Meeks, Jason Lee, Uday Garg, Nicholas Belsten, Avi Shporer, Madeleine Udell,\n  Dov Te'eni, Iddo Drori","authorsParsed":[["Tyser","Keith",""],["Segev","Ben",""],["Longhitano","Gaston",""],["Zhang","Xin-Yu",""],["Meeks","Zachary",""],["Lee","Jason",""],["Garg","Uday",""],["Belsten","Nicholas",""],["Shporer","Avi",""],["Udell","Madeleine",""],["Te'eni","Dov",""],["Drori","Iddo",""]],"versions":[{"version":"v1","created":"Mon, 19 Aug 2024 19:10:38 GMT"}],"updateDate":"2024-08-21","timestamp":1724094638000,"abstract":"  Automatic reviewing helps handle a large volume of papers, provides early\nfeedback and quality control, reduces bias, and allows the analysis of trends.\nWe evaluate the alignment of automatic paper reviews with human reviews using\nan arena of human preferences by pairwise comparisons. Gathering human\npreference may be time-consuming; therefore, we also use an LLM to\nautomatically evaluate reviews to increase sample efficiency while reducing\nbias. In addition to evaluating human and LLM preferences among LLM reviews, we\nfine-tune an LLM to predict human preferences, predicting which reviews humans\nwill prefer in a head-to-head battle between LLMs. We artificially introduce\nerrors into papers and analyze the LLM's responses to identify limitations, use\nadaptive review questions, meta prompting, role-playing, integrate visual and\ntextual analysis, use venue-specific reviewing materials, and predict human\npreferences, improving upon the limitations of the traditional review\nprocesses. We make the reviews of publicly available arXiv and open-access\nNature journal papers available online, along with a free service which helps\nauthors review and revise their research papers and improve their quality. This\nwork develops proof-of-concept LLM reviewing systems that quickly deliver\nconsistent, high-quality reviews and evaluate their quality. We mitigate the\nrisks of misuse, inflated review scores, overconfident ratings, and skewed\nscore distributions by augmenting the LLM with multiple documents, including\nthe review form, reviewer guide, code of ethics and conduct, area chair\nguidelines, and previous year statistics, by finding which errors and\nshortcomings of the paper may be detected by automated reviews, and evaluating\npairwise reviewer preferences. This work identifies and addresses the\nlimitations of using LLMs as reviewers and evaluators and enhances the quality\nof the reviewing process.\n","subjects":["Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"jaJfVUZkMi7px2hFRHsY8x1V-VtrySjO91wP7BPp6WM","pdfSize":"10387929"}
