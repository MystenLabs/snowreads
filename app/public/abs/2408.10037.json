{"id":"2408.10037","title":"SHARP: Segmentation of Hands and Arms by Range using Pseudo-Depth for\n  Enhanced Egocentric 3D Hand Pose Estimation and Action Recognition","authors":"Wiktor Mucha, Michael Wray, Martin Kampel","authorsParsed":[["Mucha","Wiktor",""],["Wray","Michael",""],["Kampel","Martin",""]],"versions":[{"version":"v1","created":"Mon, 19 Aug 2024 14:30:29 GMT"}],"updateDate":"2024-08-20","timestamp":1724077829000,"abstract":"  Hand pose represents key information for action recognition in the egocentric\nperspective, where the user is interacting with objects. We propose to improve\negocentric 3D hand pose estimation based on RGB frames only by using\npseudo-depth images. Incorporating state-of-the-art single RGB image depth\nestimation techniques, we generate pseudo-depth representations of the frames\nand use distance knowledge to segment irrelevant parts of the scene. The\nresulting depth maps are then used as segmentation masks for the RGB frames.\nExperimental results on H2O Dataset confirm the high accuracy of the estimated\npose with our method in an action recognition task. The 3D hand pose, together\nwith information from object detection, is processed by a transformer-based\naction recognition network, resulting in an accuracy of 91.73%, outperforming\nall state-of-the-art methods. Estimations of 3D hand pose result in competitive\nperformance with existing methods with a mean pose error of 28.66 mm. This\nmethod opens up new possibilities for employing distance information in\negocentric 3D hand pose estimation without relying on depth sensors.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"l4TOj5cHabd_nlu5t5Yvb9zl0Lqi4zk08DxiXjYmOsI","pdfSize":"8485759"}
