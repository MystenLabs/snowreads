{"id":"2407.13947","title":"Event-Triggered Reinforcement Learning Based Joint Resource Allocation\n  for Ultra-Reliable Low-Latency V2X Communications","authors":"Nasir Khan and Sinem Coleri","authorsParsed":[["Khan","Nasir",""],["Coleri","Sinem",""]],"versions":[{"version":"v1","created":"Thu, 18 Jul 2024 23:55:07 GMT"}],"updateDate":"2024-07-22","timestamp":1721346907000,"abstract":"  Future 6G-enabled vehicular networks face the challenge of ensuring\nultra-reliable low-latency communication (URLLC) for delivering safety-critical\ninformation in a timely manner. Existing resource allocation schemes for\nvehicle-to-everything (V2X) communication systems primarily rely on traditional\noptimization-based algorithms. However, these methods often fail to guarantee\nthe strict reliability and latency requirements of URLLC applications in\ndynamic vehicular environments due to the high complexity and communication\noverhead of the solution methodologies. This paper proposes a novel deep\nreinforcement learning (DRL) based framework for the joint power and block\nlength allocation to minimize the worst-case decoding-error probability in the\nfinite block length (FBL) regime for a URLLC-based downlink V2X communication\nsystem. The problem is formulated as a non-convex mixed-integer nonlinear\nprogramming problem (MINLP). Initially, an algorithm grounded in optimization\ntheory is developed based on deriving the joint convexity of the decoding error\nprobability in the block length and transmit power variables within the region\nof interest. Subsequently, an efficient event-triggered DRL-based algorithm is\nproposed to solve the joint optimization problem. Incorporating event-triggered\nlearning into the DRL framework enables assessing whether to initiate the DRL\nprocess, thereby reducing the number of DRL process executions while\nmaintaining reasonable reliability performance. Simulation results demonstrate\nthat the proposed event-triggered DRL scheme can achieve 95% of the performance\nof the joint optimization scheme while reducing the DRL executions by up to 24%\nfor different network settings.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}