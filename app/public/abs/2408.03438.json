{"id":"2408.03438","title":"Enhanced Reverberation as Supervision for Unsupervised Speech Separation","authors":"Kohei Saijo, Gordon Wichern, Fran\\c{c}ois G. Germain, Zexu Pan,\n  Jonathan Le Roux","authorsParsed":[["Saijo","Kohei",""],["Wichern","Gordon",""],["Germain","Fran√ßois G.",""],["Pan","Zexu",""],["Roux","Jonathan Le",""]],"versions":[{"version":"v1","created":"Tue, 6 Aug 2024 20:25:09 GMT"}],"updateDate":"2024-08-08","timestamp":1722975909000,"abstract":"  Reverberation as supervision (RAS) is a framework that allows for training\nmonaural speech separation models from multi-channel mixtures in an\nunsupervised manner. In RAS, models are trained so that sources predicted from\na mixture at an input channel can be mapped to reconstruct a mixture at a\ntarget channel. However, stable unsupervised training has so far only been\nachieved in over-determined source-channel conditions, leaving the key\ndetermined case unsolved. This work proposes enhanced RAS (ERAS) for solving\nthis problem. Through qualitative analysis, we found that stable training can\nbe achieved by leveraging the loss term to alleviate the frequency-permutation\nproblem. Separation performance is also boosted by adding a novel loss term\nwhere separated signals mapped back to their own input mixture are used as\npseudo-targets for the signals separated from other channels and mapped to the\nsame channel. Experimental results demonstrate high stability and performance\nof ERAS.\n","subjects":["Electrical Engineering and Systems Science/Audio and Speech Processing","Computing Research Repository/Sound"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}