{"id":"2408.01372","title":"Spatial-Spectral Morphological Mamba for Hyperspectral Image\n  Classification","authors":"Muhammad Ahmad, Muhammad Hassaan Farooq Butt, Muhammad Usama, Adil\n  Mehmood Khan, Manuel Mazzara, Salvatore Distefano, Hamad Ahmed Altuwaijri,\n  Swalpa Kumar Roy, Jocelyn Chanussot, Danfeng Hong","authorsParsed":[["Ahmad","Muhammad",""],["Butt","Muhammad Hassaan Farooq",""],["Usama","Muhammad",""],["Khan","Adil Mehmood",""],["Mazzara","Manuel",""],["Distefano","Salvatore",""],["Altuwaijri","Hamad Ahmed",""],["Roy","Swalpa Kumar",""],["Chanussot","Jocelyn",""],["Hong","Danfeng",""]],"versions":[{"version":"v1","created":"Fri, 2 Aug 2024 16:28:51 GMT"},{"version":"v2","created":"Fri, 23 Aug 2024 10:57:07 GMT"}],"updateDate":"2024-08-26","timestamp":1722616131000,"abstract":"  In recent years, the emergence of Transformers with self-attention mechanism\nhas revolutionized the hyperspectral image (HSI) classification. However, these\nmodels face major challenges in computational efficiency, as their complexity\nincreases quadratically with the sequence length. The Mamba architecture,\nleveraging a state space model (SSM), offers a more efficient alternative to\nTransformers. This paper introduces the Spatial-Spectral Morphological Mamba\n(MorpMamba) model in which, a token generation module first converts the HSI\npatch into spatial-spectral tokens. These tokens are then processed by\nmorphological operations, which compute structural and shape information using\ndepthwise separable convolutional operations. The extracted information is\nenhanced in a feature enhancement module that adjusts the spatial and spectral\ntokens based on the center region of the HSI sample, allowing for effective\ninformation fusion within each block. Subsequently, the tokens are refined\nthrough a multi-head self-attention which further improves the feature space.\nFinally, the combined information is fed into the state space block for\nclassification and the creation of the ground truth map. Experiments on widely\nused HSI datasets demonstrate that the MorpMamba model outperforms (parametric\nefficiency) both CNN and Transformer models. The source code will be made\npublicly available at \\url{https://github.com/MHassaanButt/MorpMamba}.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Electrical Engineering and Systems Science/Image and Video Processing"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"TU4d7n9tVRRO8_108wn8PDmE0wzsKXaQnXx5ozoqTCk","pdfSize":"11757540"}
