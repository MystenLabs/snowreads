{"id":"2407.15335","title":"Addressing Out-of-Distribution Challenges in Image Semantic\n  Communication Systems with Multi-modal Large Language Models","authors":"Feifan Zhang, Yuyang Du, Kexin Chen, Yulin Shao, Soung Chang Liew","authorsParsed":[["Zhang","Feifan",""],["Du","Yuyang",""],["Chen","Kexin",""],["Shao","Yulin",""],["Liew","Soung Chang",""]],"versions":[{"version":"v1","created":"Mon, 22 Jul 2024 02:46:44 GMT"}],"updateDate":"2024-07-23","timestamp":1721616404000,"abstract":"  Semantic communication is a promising technology for next-generation wireless\nnetworks. However, the out-of-distribution (OOD) problem, where a pre-trained\nmachine learning (ML) model is applied to unseen tasks that are outside the\ndistribution of its training data, may compromise the integrity of semantic\ncompression. This paper explores the use of multi-modal large language models\n(MLLMs) to address the OOD issue in image semantic communication. We propose a\nnovel \"Plan A - Plan B\" framework that leverages the broad knowledge and strong\ngeneralization ability of an MLLM to assist a conventional ML model when the\nlatter encounters an OOD input in the semantic encoding process. Furthermore,\nwe propose a Bayesian optimization scheme that reshapes the probability\ndistribution of the MLLM's inference process based on the contextual\ninformation of the image. The optimization scheme significantly enhances the\nMLLM's performance in semantic compression by 1) filtering out irrelevant\nvocabulary in the original MLLM output; and 2) using contextual similarities\nbetween prospective answers of the MLLM and the background information as prior\nknowledge to modify the MLLM's probability distribution during inference.\nFurther, at the receiver side of the communication system, we put forth a\n\"generate-criticize\" framework that utilizes the cooperation of multiple MLLMs\nto enhance the reliability of image reconstruction.\n","subjects":["Electrical Engineering and Systems Science/Signal Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}