{"id":"2407.12438","title":"Semantic-Aware Representation of Multi-Modal Data for Data Ingress: A\n  Literature Review","authors":"Pierre Lamart, Yinan Yu, Christian Berger","authorsParsed":[["Lamart","Pierre",""],["Yu","Yinan",""],["Berger","Christian",""]],"versions":[{"version":"v1","created":"Wed, 17 Jul 2024 09:49:11 GMT"}],"updateDate":"2024-07-18","timestamp":1721209751000,"abstract":"  Machine Learning (ML) is continuously permeating a growing amount of\napplication domains. Generative AI such as Large Language Models (LLMs) also\nsees broad adoption to process multi-modal data such as text, images, audio,\nand video. While the trend is to use ever-larger datasets for training,\nmanaging this data efficiently has become a significant practical challenge in\nthe industry-double as much data is certainly not double as good. Rather the\nopposite is important since getting an understanding of the inherent quality\nand diversity of the underlying data lakes is a growing challenge for\napplication-specific ML as well as for fine-tuning foundation models.\nFurthermore, information retrieval (IR) from expanding data lakes is\ncomplicated by the temporal dimension inherent in time-series data which must\nbe considered to determine its semantic value. This study focuses on the\ndifferent semantic-aware techniques to extract embeddings from mono-modal,\nmulti-modal, and cross-modal data to enhance IR capabilities in a growing data\nlake. Articles were collected to summarize information about the\nstate-of-the-art techniques focusing on applications of embedding for three\ndifferent categories of data modalities.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}