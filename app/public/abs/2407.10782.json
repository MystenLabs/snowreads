{"id":"2407.10782","title":"LVCP: LiDAR-Vision Tightly Coupled Collaborative Real-time Relative\n  Positioning","authors":"Zhuozhu Jian, Qixuan Li, Shengtao Zheng, Xueqian Wang and Xinlei Chen","authorsParsed":[["Jian","Zhuozhu",""],["Li","Qixuan",""],["Zheng","Shengtao",""],["Wang","Xueqian",""],["Chen","Xinlei",""]],"versions":[{"version":"v1","created":"Mon, 15 Jul 2024 15:01:43 GMT"}],"updateDate":"2024-07-16","timestamp":1721055703000,"abstract":"  In air-ground collaboration scenarios without GPS and prior maps, the\nrelative positioning of drones and unmanned ground vehicles (UGVs) has always\nbeen a challenge. For a drone equipped with monocular camera and an UGV\nequipped with LiDAR as an external sensor, we propose a robust and real-time\nrelative pose estimation method (LVCP) based on the tight coupling of vision\nand LiDAR point cloud information, which does not require prior information\nsuch as maps or precise initial poses. Given that large-scale point clouds\ngenerated by 3D sensors has more accurate spatial geometric information than\nthe feature point cloud generated by image, we utilize LiDAR point clouds to\ncorrect the drift in visual-inertial odometry (VIO) when the camera undergoes\nsignificant shaking or the IMU has a low signal-to-noise ratio. To achieve\nthis, we propose a novel coarse-to-fine framework for LiDAR-vision\ncollaborative localization. In this framework, we construct point-plane\nassociation based on spatial geometric information, and innovatively construct\na point-aided Bundle Adjustment (BA) problem as the backend to simultaneously\nestimate the relative pose of the camera and LiDAR and correct the VIO drift.\nIn this process, we propose a particle swarm optimization (PSO) based sampling\nalgorithm to complete the coarse estimation of the current camera-LiDAR pose.\nIn this process, the initial pose of the camera used for sampling is obtained\nbased on VIO propagation, and the valid feature-plane association number (VFPN)\nis used to trigger PSO-sampling process. Additionally, we propose a method that\ncombines Structure from Motion (SFM) and multi-level sampling to initialize the\nalgorithm, addressing the challenge of lacking initial values.\n","subjects":["Computing Research Repository/Robotics"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}