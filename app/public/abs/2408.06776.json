{"id":"2408.06776","title":"Robust Deep Reinforcement Learning for Inverter-based Volt-Var Control\n  in Partially Observable Distribution Networks","authors":"Qiong Liu, Ye Guo, and Tong Xu","authorsParsed":[["Liu","Qiong",""],["Guo","Ye",""],["Xu","Tong",""]],"versions":[{"version":"v1","created":"Tue, 13 Aug 2024 10:02:10 GMT"}],"updateDate":"2024-08-14","timestamp":1723543330000,"abstract":"  Inverter-based volt-var control is studied in this paper. One key issue in\nDRL-based approaches is the limited measurement deployment in active\ndistribution networks, which leads to problems of a partially observable state\nand unknown reward. To address those problems, this paper proposes a robust DRL\napproach with a conservative critic and a surrogate reward. The conservative\ncritic utilizes the quantile regression technology to estimate conservative\nstate-action value function based on the partially observable state, which\nhelps to train a robust policy; the surrogate rewards of power loss and voltage\nviolation are designed that can be calculated from the limited measurements.\nThe proposed approach optimizes the power loss of the whole network and the\nvoltage profile of buses with measurable voltages while indirectly improving\nthe voltage profile of other buses. Extensive simulations verify the\neffectiveness of the robust DRL approach in different limited measurement\nconditions, even when only the active power injection of the root bus and less\nthan 10% of bus voltages are measurable.\n","subjects":["Electrical Engineering and Systems Science/Systems and Control","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Systems and Control"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}