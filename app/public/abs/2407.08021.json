{"id":"2407.08021","title":"Field Deployment of Multi-Agent Reinforcement Learning Based Variable\n  Speed Limit Controllers","authors":"Yuhang Zhang, Zhiyao Zhang, Marcos Qui\\~nones-Grueiro, William\n  Barbour, Clay Weston, Gautam Biswas, Daniel Work","authorsParsed":[["Zhang","Yuhang",""],["Zhang","Zhiyao",""],["Qui√±ones-Grueiro","Marcos",""],["Barbour","William",""],["Weston","Clay",""],["Biswas","Gautam",""],["Work","Daniel",""]],"versions":[{"version":"v1","created":"Wed, 10 Jul 2024 19:59:59 GMT"}],"updateDate":"2024-07-12","timestamp":1720641599000,"abstract":"  This article presents the first field deployment of a multi-agent\nreinforcement-learning (MARL) based variable speed limit (VSL) control system\non the I-24 freeway near Nashville, Tennessee. We describe how we train MARL\nagents in a traffic simulator and directly deploy the simulation-based policy\non a 17-mile stretch of Interstate 24 with 67 VSL controllers. We use invalid\naction masking and several safety guards to ensure the posted speed limits\nsatisfy the real-world constraints from the traffic management center and the\nTennessee Department of Transportation. Since the time of launch of the system\nthrough April, 2024, the system has made approximately 10,000,000 decisions on\n8,000,000 trips. The analysis of the controller shows that the MARL policy\ntakes control for up to 98% of the time without intervention from safety\nguards. The time-space diagrams of traffic speed and control commands\nillustrate how the algorithm behaves during rush hour. Finally, we quantify the\ndomain mismatch between the simulation and real-world data and demonstrate the\nrobustness of the MARL policy to this mismatch.\n","subjects":["Computing Research Repository/Multiagent Systems"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}