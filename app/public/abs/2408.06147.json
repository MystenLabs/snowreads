{"id":"2408.06147","title":"Self-Supervised Learning on MeerKAT Wide-Field Continuum Images","authors":"Erica Lastufka, Omkar Bait, Olga Taran, Mariia Drozdova, Vitaliy\n  Kinakh, Davide Piras, Marc Audard, Miroslava Dessauges-Zavadsky, Taras\n  Holotyak, Daniel Schaerer, Svyatoslav Voloshynovskiy","authorsParsed":[["Lastufka","Erica",""],["Bait","Omkar",""],["Taran","Olga",""],["Drozdova","Mariia",""],["Kinakh","Vitaliy",""],["Piras","Davide",""],["Audard","Marc",""],["Dessauges-Zavadsky","Miroslava",""],["Holotyak","Taras",""],["Schaerer","Daniel",""],["Voloshynovskiy","Svyatoslav",""]],"versions":[{"version":"v1","created":"Mon, 12 Aug 2024 13:42:27 GMT"}],"updateDate":"2024-08-13","timestamp":1723470147000,"abstract":"  Self-supervised learning (SSL) applied to natural images has demonstrated a\nremarkable ability to learn meaningful, low-dimension representations without\nlabels, resulting in models that are adaptable to many different tasks. Until\nnow, applications of SSL to astronomical images have been limited to Galaxy Zoo\ndatasets, which require a significant amount of pre-processing to prepare\nsparse images centered on a single galaxy. With wide-field survey instruments\nat the forefront of the Square Kilometer Array (SKA) era, this approach to\ngathering training data is impractical. We demonstrate that continuum images\nfrom surveys like the MeerKAT Galactic Cluster Legacy Survey (MGCLS) can be\nsuccessfully used with SSL, without extracting single-galaxy cutouts. Using the\nSSL framework DINO, we experiment with various preprocessing steps,\naugmentations, and architectures to determine the optimal approach for this\ndata. We train both ResNet50 and Vision Transformer (ViT) backbones. Our models\nmatch state-of-the-art results (trained on Radio Galaxy Zoo) for FRI/FRII\nmorphology classification. Furthermore, they predict the number of compact\nsources via linear regression with much higher accuracy. However, fine-tuning\nresults in similar performance between our models, the state-of-the-art, and\nopen-source models on multi-class morphology classification. Using source-rich\ncrops from wide-field images to train multi-purpose models is an easily\nscalable approach that significantly reduces data preparation time. For the\ntasks evaluated in this work, twenty thousand crops is sufficient training data\nfor models that produce results similar to state-of-the-art. In the future,\ncomplex tasks like source detection and characterization, together with\ndomain-specific tasks, ought to demonstrate the true advantages of training\nmodels with radio astronomy data over natural-image foundation models.\n","subjects":["Astrophysics/Instrumentation and Methods for Astrophysics"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/"}