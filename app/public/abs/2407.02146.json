{"id":"2407.02146","title":"Coderivative-Based Newton Methods with Wolfe Linesearch for Nonsmooth\n  Optimization","authors":"Miantao Chao, Boris S. Mordukhovich, Zijian Shi, Jin Zhang","authorsParsed":[["Chao","Miantao",""],["Mordukhovich","Boris S.",""],["Shi","Zijian",""],["Zhang","Jin",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 10:42:15 GMT"},{"version":"v2","created":"Wed, 3 Jul 2024 05:15:46 GMT"}],"updateDate":"2024-07-04","timestamp":1719916935000,"abstract":"  This paper introduces and develops novel coderivative-based Newton methods\nwith Wolfe linesearch conditions to solve various classes of problems in\nnonsmooth optimization. We first propose a generalized regularized Newton\nmethod with Wolfe linesearch (GRNM-W) for unconstrained $C^{1,1}$ minimization\nproblems (which are second-order nonsmooth) and establish global as well as\nlocal superlinear convergence of their iterates. To deal with convex composite\nminimization problems (which are first-order nonsmooth and can be constrained),\nwe combine the proposed GRNM-W with two algorithmic frameworks: the\nforward-backward envelope and the augmented Lagrangian method resulting in the\ntwo new algorithms called CNFB and CNAL, respectively. Finally, we present\nnumerical results to solve Lasso and support vector machine problems appearing\nin, e.g., machine learning and statistics, which demonstrate the efficiency of\nthe proposed algorithms.\n","subjects":["Mathematics/Optimization and Control"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}