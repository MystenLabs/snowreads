{"id":"2408.00591","title":"Regional quality estimation for echocardiography using deep learning","authors":"Gilles Van De Vyver, Svein-Erik M{\\aa}s{\\o}y, H{\\aa}vard Dalen,\n  Bj{\\o}rnar Leangen Grenne, Espen Holte, Sindre Hellum Olaisen, John Nyberg,\n  Andreas {\\O}stvik, Lasse L{\\o}vstakken, and Erik Smistad","authorsParsed":[["Van De Vyver","Gilles",""],["Måsøy","Svein-Erik",""],["Dalen","Håvard",""],["Grenne","Bjørnar Leangen",""],["Holte","Espen",""],["Olaisen","Sindre Hellum",""],["Nyberg","John",""],["Østvik","Andreas",""],["Løvstakken","Lasse",""],["Smistad","Erik",""]],"versions":[{"version":"v1","created":"Thu, 1 Aug 2024 14:20:47 GMT"},{"version":"v2","created":"Tue, 27 Aug 2024 09:09:18 GMT"}],"updateDate":"2024-08-28","timestamp":1722522047000,"abstract":"  Automatic estimation of cardiac ultrasound image quality can be beneficial\nfor guiding operators and ensuring the accuracy of clinical measurements.\nPrevious work often fails to distinguish the view correctness of the\nechocardiogram from the image quality. Additionally, previous studies only\nprovide a global image quality value, which limits their practical utility. In\nthis work, we developed and compared three methods to estimate image quality:\n1) classic pixel-based metrics like the generalized contrast-to-noise ratio\n(gCNR) on myocardial segments as region of interest and left ventricle lumen as\nbackground, obtained using a U-Net segmentation 2) local image coherence\nderived from a U-Net model that predicts coherence from B-Mode images 3) a deep\nconvolutional network that predicts the quality of each region directly in an\nend-to-end fashion. We evaluate each method against manual regional image\nquality annotations by three experienced cardiologists. The results indicate\npoor performance of the gCNR metric, with Spearman correlation to the\nannotations of rho = 0.24. The end-to-end learning model obtains the best\nresult, rho = 0.69, comparable to the inter-observer correlation, rho = 0.63.\nFinally, the coherence-based method, with rho = 0.58, outperformed the\nclassical metrics and is more generic than the end-to-end approach.\n","subjects":["Electrical Engineering and Systems Science/Image and Video Processing","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}