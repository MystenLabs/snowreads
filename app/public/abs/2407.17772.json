{"id":"2407.17772","title":"ERIT Lightweight Multimodal Dataset for Elderly Emotion Recognition and\n  Multimodal Fusion Evaluation","authors":"Rita Frieske and Bertram E. Shi","authorsParsed":[["Frieske","Rita",""],["Shi","Bertram E.",""]],"versions":[{"version":"v1","created":"Thu, 25 Jul 2024 05:02:27 GMT"}],"updateDate":"2024-08-01","timestamp":1721883747000,"abstract":"  ERIT is a novel multimodal dataset designed to facilitate research in a\nlightweight multimodal fusion. It contains text and image data collected from\nvideos of elderly individuals reacting to various situations, as well as seven\nemotion labels for each data sample. Because of the use of labeled images of\nelderly users reacting emotionally, it is also facilitating research on emotion\nrecognition in an underrepresented age group in machine learning visual emotion\nrecognition. The dataset is validated through comprehensive experiments\nindicating its importance in neural multimodal fusion research.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Computation and Language","Computing Research Repository/Computers and Society"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"6ixhvhdcS_xlEmY1bolzFNcYy1Ax04ivWbd4pXAQvyw","pdfSize":"2124480"}
