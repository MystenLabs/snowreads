{"id":"2407.19825","title":"Concise Thoughts: Impact of Output Length on LLM Reasoning and Cost","authors":"Sania Nayab, Giulio Rossolini, Giorgio Buttazzo, Nicolamaria Manes and\n  Fabrizio Giacomelli","authorsParsed":[["Nayab","Sania",""],["Rossolini","Giulio",""],["Buttazzo","Giorgio",""],["Manes","Nicolamaria",""],["Giacomelli","Fabrizio",""]],"versions":[{"version":"v1","created":"Mon, 29 Jul 2024 09:21:52 GMT"}],"updateDate":"2024-07-30","timestamp":1722244912000,"abstract":"  Today's large language models (LLMs) can solve challenging question-answering\ntasks, and prompt engineering techniques, such as chain-of-thought (CoT), have\ngained attention for enhancing the explanation and correctness of outputs.\nNevertheless, models require significant time to generate answers augmented\nwith lengthy reasoning details. To address this issue, this paper analyzes the\nimpact of output lengths on LLM inference pipelines and proposes novel metrics\nto evaluate them in terms of \\textit{correct conciseness}. It also examines the\nimpact of controlling output length through a refined prompt engineering\nstrategy, Constrained-CoT (CCoT), which encourages the model to limit output\nlength. Experiments on pre-trained LLMs demonstrated the benefit of the\nproposed metrics and the effectiveness of CCoT across different models. For\ninstance, constraining the reasoning of LLaMA2-70b to 100 words improves the\naccuracy from 36.01\\% (CoT) to 41.07\\% (CCoT) on the GSM8K dataset, while\nreducing the average output length by 28 words.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"y9ZknM3KSJ8_lwnceKEUzAFD956wX_SkU2Fj6mpPLyM","pdfSize":"596876"}
