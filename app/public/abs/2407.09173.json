{"id":"2407.09173","title":"Conformal Inductive Graph Neural Networks","authors":"Soroush H. Zargarbashi, Aleksandar Bojchevski","authorsParsed":[["Zargarbashi","Soroush H.",""],["Bojchevski","Aleksandar",""]],"versions":[{"version":"v1","created":"Fri, 12 Jul 2024 11:12:49 GMT"}],"updateDate":"2024-07-15","timestamp":1720782769000,"abstract":"  Conformal prediction (CP) transforms any model's output into prediction sets\nguaranteed to include (cover) the true label. CP requires exchangeability, a\nrelaxation of the i.i.d. assumption, to obtain a valid distribution-free\ncoverage guarantee. This makes it directly applicable to transductive\nnode-classification. However, conventional CP cannot be applied in inductive\nsettings due to the implicit shift in the (calibration) scores caused by\nmessage passing with the new nodes. We fix this issue for both cases of node\nand edge-exchangeable graphs, recovering the standard coverage guarantee\nwithout sacrificing statistical efficiency. We further prove that the guarantee\nholds independently of the prediction time, e.g. upon arrival of a new\nnode/edge or at any subsequent moment.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}