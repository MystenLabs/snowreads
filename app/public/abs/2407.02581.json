{"id":"2407.02581","title":"Robust ADAS: Enhancing Robustness of Machine Learning-based Advanced\n  Driver Assistance Systems for Adverse Weather","authors":"Muhammad Zaeem Shahzad, Muhammad Abdullah Hanif, Muhammad Shafique","authorsParsed":[["Shahzad","Muhammad Zaeem",""],["Hanif","Muhammad Abdullah",""],["Shafique","Muhammad",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 18:03:52 GMT"}],"updateDate":"2024-07-04","timestamp":1719943432000,"abstract":"  In the realm of deploying Machine Learning-based Advanced Driver Assistance\nSystems (ML-ADAS) into real-world scenarios, adverse weather conditions pose a\nsignificant challenge. Conventional ML models trained on clear weather data\nfalter when faced with scenarios like extreme fog or heavy rain, potentially\nleading to accidents and safety hazards. This paper addresses this issue by\nproposing a novel approach: employing a Denoising Deep Neural Network as a\npreprocessing step to transform adverse weather images into clear weather\nimages, thereby enhancing the robustness of ML-ADAS systems. The proposed\nmethod eliminates the need for retraining all subsequent Depp Neural Networks\n(DNN) in the ML-ADAS pipeline, thus saving computational resources and time.\nMoreover, it improves driver visualization, which is critical for safe\nnavigation in adverse weather conditions. By leveraging the UNet architecture\ntrained on an augmented KITTI dataset with synthetic adverse weather images, we\ndevelop the Weather UNet (WUNet) DNN to remove weather artifacts. Our study\ndemonstrates substantial performance improvements in object detection with\nWUNet preprocessing under adverse weather conditions. Notably, in scenarios\ninvolving extreme fog, our proposed solution improves the mean Average\nPrecision (mAP) score of the YOLOv8n from 4% to 70%.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}