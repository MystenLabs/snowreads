{"id":"2408.05090","title":"Loc4Plan: Locating Before Planning for Outdoor Vision and Language\n  Navigation","authors":"Huilin Tian and Jingke Meng and Wei-Shi Zheng and Yuan-Ming Li and\n  Junkai Yan and Yunong Zhang","authorsParsed":[["Tian","Huilin",""],["Meng","Jingke",""],["Zheng","Wei-Shi",""],["Li","Yuan-Ming",""],["Yan","Junkai",""],["Zhang","Yunong",""]],"versions":[{"version":"v1","created":"Fri, 9 Aug 2024 14:31:09 GMT"}],"updateDate":"2024-08-12","timestamp":1723213869000,"abstract":"  Vision and Language Navigation (VLN) is a challenging task that requires\nagents to understand instructions and navigate to the destination in a visual\nenvironment.One of the key challenges in outdoor VLN is keeping track of which\npart of the instruction was completed. To alleviate this problem, previous\nworks mainly focus on grounding the natural language to the visual input, but\nneglecting the crucial role of the agent's spatial position information in the\ngrounding process. In this work, we first explore the substantial effect of\nspatial position locating on the grounding of outdoor VLN, drawing inspiration\nfrom human navigation. In real-world navigation scenarios, before planning a\npath to the destination, humans typically need to figure out their current\nlocation. This observation underscores the pivotal role of spatial localization\nin the navigation process. In this work, we introduce a novel framework,\nLocating be for Planning (Loc4Plan), designed to incorporate spatial perception\nfor action planning in outdoor VLN tasks. The main idea behind Loc4Plan is to\nperform the spatial localization before planning a decision action based on\ncorresponding guidance, which comprises a block-aware spatial locating (BAL)\nmodule and a spatial-aware action planning (SAP) module. Specifically, to help\nthe agent perceive its spatial location in the environment, we propose to learn\na position predictor that measures how far the agent is from the next\nintersection for reflecting its position, which is achieved by the BAL module.\nAfter the locating process, we propose the SAP module to incorporate spatial\ninformation to ground the corresponding guidance and enhance the precision of\naction planning. Extensive experiments on the Touchdown and map2seq datasets\nshow that the proposed Loc4Plan outperforms the SOTA methods.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Multimedia"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}