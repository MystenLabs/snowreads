{"id":"2408.14957","title":"Applying ViT in Generalized Few-shot Semantic Segmentation","authors":"Liyuan Geng, Jinhong Xia, Yuanhe Guo","authorsParsed":[["Geng","Liyuan",""],["Xia","Jinhong",""],["Guo","Yuanhe",""]],"versions":[{"version":"v1","created":"Tue, 27 Aug 2024 11:04:53 GMT"}],"updateDate":"2024-08-28","timestamp":1724756693000,"abstract":"  This paper explores the capability of ViT-based models under the generalized\nfew-shot semantic segmentation (GFSS) framework. We conduct experiments with\nvarious combinations of backbone models, including ResNets and pretrained\nVision Transformer (ViT)-based models, along with decoders featuring a linear\nclassifier, UPerNet, and Mask Transformer. The structure made of DINOv2 and\nlinear classifier takes the lead on popular few-shot segmentation bench mark\nPASCAL-$5^i$, substantially outperforming the best of ResNet structure by 116%\nin one-shot scenario. We demonstrate the great potential of large pretrained\nViT-based model on GFSS task, and expect further improvement on testing\nbenchmarks. However, a potential caveat is that when applying pure ViT-based\nmodel and large scale ViT decoder, the model is easy to overfit.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}