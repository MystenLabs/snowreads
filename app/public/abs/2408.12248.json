{"id":"2408.12248","title":"PRG: Prompt-Based Distillation Without Annotation via Proxy Relational\n  Graph","authors":"Yijin Xu, Jialun Liu, Hualiang Wei, Wenhui Li","authorsParsed":[["Xu","Yijin",""],["Liu","Jialun",""],["Wei","Hualiang",""],["Li","Wenhui",""]],"versions":[{"version":"v1","created":"Thu, 22 Aug 2024 09:36:26 GMT"}],"updateDate":"2024-08-23","timestamp":1724319386000,"abstract":"  In this paper, we propose a new distillation method for extracting knowledge\nfrom Large Foundation Models (LFM) into lightweight models, introducing a novel\nsupervision mode that does not require manually annotated data. While LFMs\nexhibit exceptional zero-shot classification abilities across datasets, relying\nsolely on LFM-generated embeddings for distillation poses two main challenges:\nLFM's task-irrelevant knowledge and the high density of features. The transfer\nof task-irrelevant knowledge could compromise the student model's\ndiscriminative capabilities, and the high density of features within target\ndomains obstructs the extraction of discriminative knowledge essential for the\ntask. To address this issue, we introduce the Proxy Relational Graph (PRG)\nmethod. We initially extract task-relevant knowledge from LFMs by calculating a\nweighted average of logits obtained through text prompt embeddings. Then we\nconstruct sample-class proxy graphs for LFM and student models, respectively,\nto model the correlation between samples and class proxies. Then, we achieve\nthe distillation of selective knowledge by aligning the relational graphs\nproduced by both the LFM and the student model. Specifically, the distillation\nfrom LFM to the student model is achieved through two types of alignment: 1)\naligning the sample nodes produced by the student model with those produced by\nthe LFM, and 2) aligning the edge relationships in the student model's graph\nwith those in the LFM's graph. Our experimental results validate the\neffectiveness of PRG, demonstrating its ability to leverage the extensive\nknowledge base of LFMs while skillfully circumventing their inherent\nlimitations in focused learning scenarios. Notably, in our annotation-free\nframework, PRG achieves an accuracy of 76.23\\% (T: 77.9\\%) on CIFAR-100 and\n72.44\\% (T: 75.3\\%) on the ImageNet-1K.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}