{"id":"2407.12023","title":"CMMaTH: A Chinese Multi-modal Math Skill Evaluation Benchmark for\n  Foundation Models","authors":"Zhong-Zhi Li, Ming-Liang Zhang, Fei Yin, Zhi-Long Ji, Jin-Feng Bai,\n  Zhen-Ru Pan, Fan-Hu Zeng, Jian Xu, Jia-Xin Zhang, Cheng-Lin Liu","authorsParsed":[["Li","Zhong-Zhi",""],["Zhang","Ming-Liang",""],["Yin","Fei",""],["Ji","Zhi-Long",""],["Bai","Jin-Feng",""],["Pan","Zhen-Ru",""],["Zeng","Fan-Hu",""],["Xu","Jian",""],["Zhang","Jia-Xin",""],["Liu","Cheng-Lin",""]],"versions":[{"version":"v1","created":"Fri, 28 Jun 2024 02:35:51 GMT"}],"updateDate":"2024-07-18","timestamp":1719542151000,"abstract":"  Due to the rapid advancements in multimodal large language models, evaluating\ntheir multimodal mathematical capabilities continues to receive wide attention.\nDespite the datasets like MathVista proposed benchmarks for assessing\nmathematical capabilities in multimodal scenarios, there is still a lack of\ncorresponding evaluation tools and datasets for fine-grained assessment in the\ncontext of K12 education in Chinese language. To systematically evaluate the\ncapability of multimodal large models in solving Chinese multimodal\nmathematical problems, we propose a Chinese Multi-modal Math Skill Evaluation\nBenchmark, named CMMaTH, contraining 23k multimodal K12 math related questions,\nforming the largest Chinese multimodal mathematical problem benchmark to date.\nCMMaTH questions from elementary to high school levels, provide increased\ndiversity in problem types, solution objectives, visual elements, detailed\nknowledge points, and standard solution annotations. We have constructed an\nopen-source tool GradeGPT integrated with the CMMaTH dataset, facilitating\nstable, rapid, and cost-free model evaluation. Our data and code are available.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}