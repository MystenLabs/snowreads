{"id":"2407.16397","title":"On ADMM in Heterogeneous Federated Learning: Personalization,\n  Robustness, and Fairness","authors":"Shengkun Zhu, Jinshan Zeng, Sheng Wang, Yuan Sun, Xiaodong Li, Yuan\n  Yao, Zhiyong Peng","authorsParsed":[["Zhu","Shengkun",""],["Zeng","Jinshan",""],["Wang","Sheng",""],["Sun","Yuan",""],["Li","Xiaodong",""],["Yao","Yuan",""],["Peng","Zhiyong",""]],"versions":[{"version":"v1","created":"Tue, 23 Jul 2024 11:35:42 GMT"}],"updateDate":"2024-07-24","timestamp":1721734542000,"abstract":"  Statistical heterogeneity is a root cause of tension among accuracy,\nfairness, and robustness of federated learning (FL), and is key in paving a\npath forward. Personalized FL (PFL) is an approach that aims to reduce the\nimpact of statistical heterogeneity by developing personalized models for\nindividual users, while also inherently providing benefits in terms of fairness\nand robustness. However, existing PFL frameworks focus on improving the\nperformance of personalized models while neglecting the global model. Moreover,\nthese frameworks achieve sublinear convergence rates and rely on strong\nassumptions. In this paper, we propose FLAME, an optimization framework by\nutilizing the alternating direction method of multipliers (ADMM) to train\npersonalized and global models. We propose a model selection strategy to\nimprove performance in situations where clients have different types of\nheterogeneous data. Our theoretical analysis establishes the global convergence\nand two kinds of convergence rates for FLAME under mild assumptions. We\ntheoretically demonstrate that FLAME is more robust and fair than the\nstate-of-the-art methods on a class of linear problems. Our experimental\nfindings show that FLAME outperforms state-of-the-art methods in convergence\nand accuracy, and it achieves higher test accuracy under various attacks and\nperforms more uniformly across clients.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/"}