{"id":"2407.08561","title":"MapLocNet: Coarse-to-Fine Feature Registration for Visual\n  Re-Localization in Navigation Maps","authors":"Hang Wu, Zhenghao Zhang, Siyuan Lin, Xiangru Mu, Qiang Zhao, Ming\n  Yang, Tong Qin","authorsParsed":[["Wu","Hang",""],["Zhang","Zhenghao",""],["Lin","Siyuan",""],["Mu","Xiangru",""],["Zhao","Qiang",""],["Yang","Ming",""],["Qin","Tong",""]],"versions":[{"version":"v1","created":"Thu, 11 Jul 2024 14:51:18 GMT"}],"updateDate":"2024-07-12","timestamp":1720709478000,"abstract":"  Robust localization is the cornerstone of autonomous driving, especially in\nchallenging urban environments where GPS signals suffer from multipath errors.\nTraditional localization approaches rely on high-definition (HD) maps, which\nconsist of precisely annotated landmarks. However, building HD map is expensive\nand challenging to scale up. Given these limitations, leveraging navigation\nmaps has emerged as a promising low-cost alternative for localization. Current\napproaches based on navigation maps can achieve highly accurate localization,\nbut their complex matching strategies lead to unacceptable inference latency\nthat fails to meet the real-time demands. To address these limitations, we\npropose a novel transformer-based neural re-localization method. Inspired by\nimage registration, our approach performs a coarse-to-fine neural feature\nregistration between navigation map and visual bird's-eye view features. Our\nmethod significantly outperforms the current state-of-the-art OrienterNet on\nboth the nuScenes and Argoverse datasets, which is nearly 10%/20% localization\naccuracy and 30/16 FPS improvement on single-view and surround-view input\nsettings, separately. We highlight that our research presents an HD-map-free\nlocalization method for autonomous driving, offering cost-effective, reliable,\nand scalable performance in challenging driving environments.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}