{"id":"2407.08250","title":"Gradient Boosting Reinforcement Learning","authors":"Benjamin Fuhrer, Chen Tessler, Gal Dalal","authorsParsed":[["Fuhrer","Benjamin",""],["Tessler","Chen",""],["Dalal","Gal",""]],"versions":[{"version":"v1","created":"Thu, 11 Jul 2024 07:52:33 GMT"}],"updateDate":"2024-07-12","timestamp":1720684353000,"abstract":"  Neural networks (NN) achieve remarkable results in various tasks, but lack\nkey characteristics: interpretability, support for categorical features, and\nlightweight implementations suitable for edge devices. While ongoing efforts\naim to address these challenges, Gradient Boosting Trees (GBT) inherently meet\nthese requirements. As a result, GBTs have become the go-to method for\nsupervised learning tasks in many real-world applications and competitions.\nHowever, their application in online learning scenarios, notably in\nreinforcement learning (RL), has been limited. In this work, we bridge this gap\nby introducing Gradient-Boosting RL (GBRL), a framework that extends the\nadvantages of GBT to the RL domain. Using the GBRL framework, we implement\nvarious actor-critic algorithms and compare their performance with their NN\ncounterparts. Inspired by shared backbones in NN we introduce a tree-sharing\napproach for policy and value functions with distinct learning rates, enhancing\nlearning efficiency over millions of interactions. GBRL achieves competitive\nperformance across a diverse array of tasks, excelling in domains with\nstructured or categorical features. Additionally, we present a\nhigh-performance, GPU-accelerated implementation that integrates seamlessly\nwith widely-used RL libraries (available at https://github.com/NVlabs/gbrl).\nGBRL expands the toolkit for RL practitioners, demonstrating the viability and\npromise of GBT within the RL paradigm, particularly in domains characterized by\nstructured or categorical features.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}