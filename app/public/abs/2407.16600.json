{"id":"2407.16600","title":"DHGS: Decoupled Hybrid Gaussian Splatting for Driving Scene","authors":"Xi Shi, Lingli Chen, Peng Wei, Xi Wu, Tian Jiang, Yonggang Luo,\n  Lecheng Xie","authorsParsed":[["Shi","Xi",""],["Chen","Lingli",""],["Wei","Peng",""],["Wu","Xi",""],["Jiang","Tian",""],["Luo","Yonggang",""],["Xie","Lecheng",""]],"versions":[{"version":"v1","created":"Tue, 23 Jul 2024 16:03:02 GMT"},{"version":"v2","created":"Mon, 29 Jul 2024 07:55:54 GMT"},{"version":"v3","created":"Sun, 18 Aug 2024 02:39:19 GMT"}],"updateDate":"2024-08-20","timestamp":1721750582000,"abstract":"  Existing Gaussian splatting methods often fall short in achieving\nsatisfactory novel view synthesis in driving scenes, primarily due to the\nabsence of crafty designs and geometric constraints for the involved elements.\nThis paper introduces a novel neural rendering method termed Decoupled Hybrid\nGaussian Splatting (DHGS), targeting at promoting the rendering quality of\nnovel view synthesis for static driving scenes. The novelty of this work lies\nin the decoupled and hybrid pixel-level blender for road and non-road layers,\nwithout the conventional unified differentiable rendering logic for the entire\nscene. Still, consistency and continuity in superimposition are preserved\nthrough the proposed depth-ordered hybrid rendering strategy. Additionally, an\nimplicit road representation comprised of a Signed Distance Function (SDF) is\ntrained to supervise the road surface with subtle geometric attributes.\nAccompanied by the use of auxiliary transmittance loss and consistency loss,\nnovel images with imperceptible boundary and elevated fidelity are ultimately\nobtained. Substantial experiments on the Waymo dataset prove that DHGS\noutperforms the state-of-the-art methods. The project page where more video\nevidences are given is: https://ironbrotherstyle.github.io/dhgs_web.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}