{"id":"2408.12315","title":"Large Language Models Are Self-Taught Reasoners: Enhancing LLM\n  Applications via Tailored Problem-Solving Demonstrations","authors":"Kai Tzu-iunn Ong, Taeyoon Kwon, Jinyoung Yeo","authorsParsed":[["Ong","Kai Tzu-iunn",""],["Kwon","Taeyoon",""],["Yeo","Jinyoung",""]],"versions":[{"version":"v1","created":"Thu, 22 Aug 2024 11:41:35 GMT"}],"updateDate":"2024-08-23","timestamp":1724326895000,"abstract":"  Guiding large language models with a selected set of human-authored\ndemonstrations is a common practice for improving LLM applications. However,\nhuman effort can be costly, especially in specialized domains (e.g., clinical\ndiagnosis), and does not guarantee optimal performance due to the potential\ndiscrepancy of target skills between selected demonstrations and real test\ninstances. Motivated by these, this paper explores the automatic creation of\ncustomized demonstrations, whose target skills align with the given target\ninstance. We present SELF-TAUGHT, a problem-solving framework, which\nfacilitates demonstrations that are \"tailored\" to the target problem and\n\"filtered\" for better quality (i.e., correctness) in a zero-shot manner. In 15\ntasks of multiple-choice questions of diverse domains and the diagnosis of\nAlzheimer's disease (AD) with real-world patients, SELF-TAUGHT achieves\nsuperior performance to strong baselines (e.g., Few-shot CoT, Plan-and-Solve,\nAuto-CoT). We conduct comprehensive analyses on SELF-TAUGHT, including its\ngeneralizability to existing prompting methods and different LLMs, the quality\nof its intermediate generation, and more.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/"}