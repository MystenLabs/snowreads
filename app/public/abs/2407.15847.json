{"id":"2407.15847","title":"LLMmap: Fingerprinting For Large Language Models","authors":"Dario Pasquini, Evgenios M. Kornaropoulos and Giuseppe Ateniese","authorsParsed":[["Pasquini","Dario",""],["Kornaropoulos","Evgenios M.",""],["Ateniese","Giuseppe",""]],"versions":[{"version":"v1","created":"Mon, 22 Jul 2024 17:59:45 GMT"},{"version":"v2","created":"Wed, 24 Jul 2024 16:07:00 GMT"},{"version":"v3","created":"Mon, 9 Sep 2024 19:36:55 GMT"}],"updateDate":"2024-09-11","timestamp":1721671185000,"abstract":"  We introduce LLMmap, a first-generation fingerprinting technique targeted at\nLLM-integrated applications. LLMmap employs an active fingerprinting approach,\nsending carefully crafted queries to the application and analyzing the\nresponses to identify the specific LLM version in use. Our query selection is\ninformed by domain expertise on how LLMs generate uniquely identifiable\nresponses to thematically varied prompts. With as few as 8 interactions, LLMmap\ncan accurately identify 42 different LLM versions with over 95% accuracy. More\nimportantly, LLMmap is designed to be robust across different application\nlayers, allowing it to identify LLM versions--whether open-source or\nproprietary--from various vendors, operating under various unknown system\nprompts, stochastic sampling hyperparameters, and even complex generation\nframeworks such as RAG or Chain-of-Thought. We discuss potential mitigations\nand demonstrate that, against resourceful adversaries, effective\ncountermeasures may be challenging or even unrealizable.\n","subjects":["Computing Research Repository/Cryptography and Security","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}