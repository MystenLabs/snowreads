{"id":"2407.08632","title":"Generalization Error Matters in Decentralized Learning Under Byzantine\n  Attacks","authors":"Haoxiang Ye and Qing Ling","authorsParsed":[["Ye","Haoxiang",""],["Ling","Qing",""]],"versions":[{"version":"v1","created":"Thu, 11 Jul 2024 16:12:53 GMT"}],"updateDate":"2024-07-12","timestamp":1720714373000,"abstract":"  Recently, decentralized learning has emerged as a popular peer-to-peer signal\nand information processing paradigm that enables model training across\ngeographically distributed agents in a scalable manner, without the presence of\nany central server. When some of the agents are malicious (also termed as\nByzantine), resilient decentralized learning algorithms are able to limit the\nimpact of these Byzantine agents without knowing their number and identities,\nand have guaranteed optimization errors. However, analysis of the\ngeneralization errors, which are critical to implementations of the trained\nmodels, is still lacking. In this paper, we provide the first analysis of the\ngeneralization errors for a class of popular Byzantine-resilient decentralized\nstochastic gradient descent (DSGD) algorithms. Our theoretical results reveal\nthat the generalization errors cannot be entirely eliminated because of the\npresence of the Byzantine agents, even if the number of training samples are\ninfinitely large. Numerical experiments are conducted to confirm our\ntheoretical results.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}