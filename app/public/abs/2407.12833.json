{"id":"2407.12833","title":"ESQA: Event Sequences Question Answering","authors":"Irina Abdullaeva, Andrei Filatov, Mikhail Orlov, Ivan Karpukhin,\n  Viacheslav Vasilev, Denis Dimitrov, Andrey Kuznetsov, Ivan Kireev, Andrey\n  Savchenko","authorsParsed":[["Abdullaeva","Irina",""],["Filatov","Andrei",""],["Orlov","Mikhail",""],["Karpukhin","Ivan",""],["Vasilev","Viacheslav",""],["Dimitrov","Denis",""],["Kuznetsov","Andrey",""],["Kireev","Ivan",""],["Savchenko","Andrey",""]],"versions":[{"version":"v1","created":"Wed, 3 Jul 2024 15:41:54 GMT"},{"version":"v2","created":"Fri, 19 Jul 2024 07:38:35 GMT"}],"updateDate":"2024-07-22","timestamp":1720021314000,"abstract":"  Event sequences (ESs) arise in many practical domains including finance,\nretail, social networks, and healthcare. In the context of machine learning,\nevent sequences can be seen as a special type of tabular data with annotated\ntimestamps. Despite the importance of ESs modeling and analysis, little effort\nwas made in adapting large language models (LLMs) to the ESs domain. In this\npaper, we highlight the common difficulties of ESs processing and propose a\nnovel solution capable of solving multiple downstream tasks with little or no\nfinetuning. In particular, we solve the problem of working with long sequences\nand improve time and numeric features processing. The resulting method, called\nESQA, effectively utilizes the power of LLMs and, according to extensive\nexperiments, achieves state-of-the-art results in the ESs domain.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"yC6_iDLGKbiIhzMhb0kdfC_UaWodVsoOzIhs_CzclM0","pdfSize":"1065039"}
