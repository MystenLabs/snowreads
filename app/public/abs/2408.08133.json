{"id":"2408.08133","title":"EXPLAIN, AGREE, LEARN: Scaling Learning for Neural Probabilistic Logic","authors":"Victor Verreet, Lennert De Smet, Luc De Raedt, Emanuele Sansone","authorsParsed":[["Verreet","Victor",""],["De Smet","Lennert",""],["De Raedt","Luc",""],["Sansone","Emanuele",""]],"versions":[{"version":"v1","created":"Thu, 15 Aug 2024 13:07:51 GMT"}],"updateDate":"2024-08-16","timestamp":1723727271000,"abstract":"  Neural probabilistic logic systems follow the neuro-symbolic (NeSy) paradigm\nby combining the perceptive and learning capabilities of neural networks with\nthe robustness of probabilistic logic. Learning corresponds to likelihood\noptimization of the neural networks. However, to obtain the likelihood exactly,\nexpensive probabilistic logic inference is required. To scale learning to more\ncomplex systems, we therefore propose to instead optimize a sampling based\nobjective. We prove that the objective has a bounded error with respect to the\nlikelihood, which vanishes when increasing the sample count. Furthermore, the\nerror vanishes faster by exploiting a new concept of sample diversity. We then\ndevelop the EXPLAIN, AGREE, LEARN (EXAL) method that uses this objective.\nEXPLAIN samples explanations for the data. AGREE reweighs each explanation in\nconcordance with the neural component. LEARN uses the reweighed explanations as\na signal for learning. In contrast to previous NeSy methods, EXAL can scale to\nlarger problem sizes while retaining theoretical guarantees on the error.\nExperimentally, our theoretical claims are verified and EXAL outperforms recent\nNeSy methods when scaling up the MNIST addition and Warcraft pathfinding\nproblems.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"DN7MbEscF6-T_ECY8mYxMxVYGnYfCyh-QDu6Bpp8qYk","pdfSize":"976669"}
