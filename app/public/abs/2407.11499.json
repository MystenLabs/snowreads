{"id":"2407.11499","title":"Bridge Past and Future: Overcoming Information Asymmetry in Incremental\n  Object Detection","authors":"Qijie Mo, Yipeng Gao, Shenghao Fu, Junkai Yan, Ancong Wu, Wei-Shi\n  Zheng","authorsParsed":[["Mo","Qijie",""],["Gao","Yipeng",""],["Fu","Shenghao",""],["Yan","Junkai",""],["Wu","Ancong",""],["Zheng","Wei-Shi",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 08:37:12 GMT"}],"updateDate":"2024-07-17","timestamp":1721119032000,"abstract":"  In incremental object detection, knowledge distillation has been proven to be\nan effective way to alleviate catastrophic forgetting. However, previous works\nfocused on preserving the knowledge of old models, ignoring that images could\nsimultaneously contain categories from past, present, and future stages. The\nco-occurrence of objects makes the optimization objectives inconsistent across\ndifferent stages since the definition for foreground objects differs across\nvarious stages, which limits the model's performance greatly. To overcome this\nproblem, we propose a method called ``Bridge Past and Future'' (BPF), which\naligns models across stages, ensuring consistent optimization directions. In\naddition, we propose a novel Distillation with Future (DwF) loss, fully\nleveraging the background probability to mitigate the forgetting of old classes\nwhile ensuring a high level of adaptability in learning new classes. Extensive\nexperiments are conducted on both Pascal VOC and MS COCO benchmarks. Without\nmemory, BPF outperforms current state-of-the-art methods under various\nsettings. The code is available at https://github.com/iSEE-Laboratory/BPF.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}