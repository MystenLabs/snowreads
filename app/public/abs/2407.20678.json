{"id":"2407.20678","title":"The Susceptibility of Example-Based Explainability Methods to Class\n  Outliers","authors":"Ikhtiyor Nematov, Dimitris Sacharidis, Tomer Sagi, Katja Hose","authorsParsed":[["Nematov","Ikhtiyor",""],["Sacharidis","Dimitris",""],["Sagi","Tomer",""],["Hose","Katja",""]],"versions":[{"version":"v1","created":"Tue, 30 Jul 2024 09:20:15 GMT"},{"version":"v2","created":"Thu, 1 Aug 2024 14:09:12 GMT"}],"updateDate":"2024-08-02","timestamp":1722331215000,"abstract":"  This study explores the impact of class outliers on the effectiveness of\nexample-based explainability methods for black-box machine learning models. We\nreformulate existing explainability evaluation metrics, such as correctness and\nrelevance, specifically for example-based methods, and introduce a new metric,\ndistinguishability. Using these metrics, we highlight the shortcomings of\ncurrent example-based explainability methods, including those who attempt to\nsuppress class outliers. We conduct experiments on two datasets, a text\nclassification dataset and an image classification dataset, and evaluate the\nperformance of four state-of-the-art explainability methods. Our findings\nunderscore the need for robust techniques to tackle the challenges posed by\nclass outliers.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}