{"id":"2407.13937","title":"Boosting Online 3D Multi-Object Tracking through Camera-Radar Cross\n  Check","authors":"Sheng-Yao Kuan, Jen-Hao Cheng, Hsiang-Wei Huang, Wenhao Chai,\n  Cheng-Yen Yang, Hugo Latapie, Gaowen Liu, Bing-Fei Wu, Jenq-Neng Hwang","authorsParsed":[["Kuan","Sheng-Yao",""],["Cheng","Jen-Hao",""],["Huang","Hsiang-Wei",""],["Chai","Wenhao",""],["Yang","Cheng-Yen",""],["Latapie","Hugo",""],["Liu","Gaowen",""],["Wu","Bing-Fei",""],["Hwang","Jenq-Neng",""]],"versions":[{"version":"v1","created":"Thu, 18 Jul 2024 23:32:27 GMT"}],"updateDate":"2024-07-22","timestamp":1721345547000,"abstract":"  In the domain of autonomous driving, the integration of multi-modal\nperception techniques based on data from diverse sensors has demonstrated\nsubstantial progress. Effectively surpassing the capabilities of\nstate-of-the-art single-modality detectors through sensor fusion remains an\nactive challenge. This work leverages the respective advantages of cameras in\nperspective view and radars in Bird's Eye View (BEV) to greatly enhance overall\ndetection and tracking performance. Our approach, Camera-Radar Associated\nFusion Tracking Booster (CRAFTBooster), represents a pioneering effort to\nenhance radar-camera fusion in the tracking stage, contributing to improved 3D\nMOT accuracy. The superior experimental results on the K-Radaar dataset, which\nexhibit 5-6% on IDF1 tracking performance gain, validate the potential of\neffective sensor fusion in advancing autonomous driving.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"rF5ZCQtKVrza_1qGygPfsN_jSS419SHqV1VjECFAL84","pdfSize":"2501684"}
