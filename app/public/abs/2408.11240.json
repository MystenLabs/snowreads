{"id":"2408.11240","title":"Asymmetric Graph Error Control with Low Complexity in Causal Bandits","authors":"Chen Peng, Di Zhang and Urbashi Mitra","authorsParsed":[["Peng","Chen",""],["Zhang","Di",""],["Mitra","Urbashi",""]],"versions":[{"version":"v1","created":"Tue, 20 Aug 2024 23:37:08 GMT"}],"updateDate":"2024-08-22","timestamp":1724197028000,"abstract":"  In this paper, the causal bandit problem is investigated, in which the\nobjective is to select an optimal sequence of interventions on nodes in a\ncausal graph. It is assumed that the graph is governed by linear structural\nequations; it is further assumed that both the causal topology and the\ndistribution of interventions are unknown. By exploiting the causal\nrelationships between the nodes whose signals contribute to the reward,\ninterventions are optimized. First, based on the difference between the two\ntypes of graph identification errors (false positives and negatives), a causal\ngraph learning method is proposed, which strongly reduces sample complexity\nrelative to the prior art by learning sub-graphs. Under the assumption of\nGaussian exogenous inputs and minimum-mean squared error weight estimation, a\nnew uncertainty bound tailored to the causal bandit problem is derived. This\nuncertainty bound drives an upper confidence bound based intervention selection\nto optimize the reward. To cope with non-stationary bandits, a sub-graph change\ndetection mechanism is proposed, with high sample efficiency. Numerical results\ncompare the new methodology to existing schemes and show a substantial\nperformance improvement in both stationary and non-stationary settings.\nCompared to existing approaches, the proposed scheme takes 67% fewer samples to\nlearn the causal structure and achieves an average reward gain of 85%.\n","subjects":["Computing Research Repository/Machine Learning","Electrical Engineering and Systems Science/Signal Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}