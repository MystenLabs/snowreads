{"id":"2408.07884","title":"Instruct Large Language Models to Generate Scientific Literature Survey\n  Step by Step","authors":"Yuxuan Lai, Yupeng Wu, Yidan Wang, Wenpeng Hu, Chen Zheng","authorsParsed":[["Lai","Yuxuan",""],["Wu","Yupeng",""],["Wang","Yidan",""],["Hu","Wenpeng",""],["Zheng","Chen",""]],"versions":[{"version":"v1","created":"Thu, 15 Aug 2024 02:07:11 GMT"}],"updateDate":"2024-08-16","timestamp":1723687631000,"abstract":"  Abstract. Automatically generating scientific literature surveys is a\nvaluable task that can significantly enhance research efficiency. However, the\ndiverse and complex nature of information within a literature survey poses\nsubstantial challenges for generative models. In this paper, we design a series\nof prompts to systematically leverage large language models (LLMs), enabling\nthe creation of comprehensive literature surveys through a step-by-step\napproach. Specifically, we design prompts to guide LLMs to sequentially\ngenerate the title, abstract, hierarchical headings, and the main content of\nthe literature survey. We argue that this design enables the generation of the\nheadings from a high-level perspective. During the content generation process,\nthis design effectively harnesses relevant information while minimizing costs\nby restricting the length of both input and output content in LLM queries. Our\nimplementation with Qwen-long achieved third place in the NLPCC 2024 Scientific\nLiterature Survey Generation evaluation task, with an overall score only 0.03%\nlower than the second-place team. Additionally, our soft heading recall is\n95.84%, the second best among the submissions. Thanks to the efficient prompt\ndesign and the low cost of the Qwen-long API, our method reduces the expense\nfor generating each literature survey to 0.1 RMB, enhancing the practical value\nof our method.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}