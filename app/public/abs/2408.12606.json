{"id":"2408.12606","title":"Towards Non-invasive and Personalized Management of Breast Cancer\n  Patients from Multiparametric MRI via A Large Mixture-of-Modality-Experts\n  Model","authors":"Luyang Luo, Mingxiang Wu, Mei Li, Yi Xin, Qiong Wang, Varut\n  Vardhanabhuti, Winnie CW Chu, Zhenhui Li, Juan Zhou, Pranav Rajpurkar, Hao\n  Chen","authorsParsed":[["Luo","Luyang",""],["Wu","Mingxiang",""],["Li","Mei",""],["Xin","Yi",""],["Wang","Qiong",""],["Vardhanabhuti","Varut",""],["Chu","Winnie CW",""],["Li","Zhenhui",""],["Zhou","Juan",""],["Rajpurkar","Pranav",""],["Chen","Hao",""]],"versions":[{"version":"v1","created":"Thu, 8 Aug 2024 05:04:13 GMT"},{"version":"v2","created":"Mon, 2 Sep 2024 00:52:01 GMT"}],"updateDate":"2024-09-04","timestamp":1723093453000,"abstract":"  Breast magnetic resonance imaging (MRI) is the imaging technique with the\nhighest sensitivity for detecting breast cancer and is routinely used for women\nat high risk. Despite the comprehensive multiparametric protocol of breast MRI,\nexisting artificial intelligence-based studies predominantly rely on single\nsequences and have limited validation. Here we report a large\nmixture-of-modality-experts model (MOME) that integrates multiparametric MRI\ninformation within a unified structure, offering a noninvasive method for\npersonalized breast cancer management. We have curated the largest\nmultiparametric breast MRI dataset, involving 5,205 patients from three\nhospitals in the north, southeast, and southwest of China, for the development\nand extensive evaluation of our model. MOME demonstrated accurate and robust\nidentification of breast cancer. It achieved comparable performance for\nmalignancy recognition to that of four senior radiologists and significantly\noutperformed a junior radiologist, with 0.913 AUROC, 0.948 AUPRC, 0.905 F1\nscore, and 0.723 MCC. Our findings suggest that MOME could reduce the need for\nbiopsies in BI-RADS 4 patients with a ratio of 7.3%, classify triple-negative\nbreast cancer with an AUROC of 0.709, and predict pathological complete\nresponse to neoadjuvant chemotherapy with an AUROC of 0.694. The model further\nsupports scalable and interpretable inference, adapting to missing modalities\nand providing decision explanations by highlighting lesions and measuring\nmodality contributions. MOME exemplifies a discriminative, robust, scalable,\nand interpretable multimodal model, paving the way for noninvasive,\npersonalized management of breast cancer patients based on multiparametric\nbreast imaging data.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/"}