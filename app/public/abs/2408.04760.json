{"id":"2408.04760","title":"Embodied Uncertainty-Aware Object Segmentation","authors":"Xiaolin Fang and Leslie Pack Kaelbling and Tom\\'as Lozano-P\\'erez","authorsParsed":[["Fang","Xiaolin",""],["Kaelbling","Leslie Pack",""],["Lozano-Pérez","Tomás",""]],"versions":[{"version":"v1","created":"Thu, 8 Aug 2024 21:29:22 GMT"}],"updateDate":"2024-08-12","timestamp":1723152562000,"abstract":"  We introduce uncertainty-aware object instance segmentation (UncOS) and\ndemonstrate its usefulness for embodied interactive segmentation. To deal with\nuncertainty in robot perception, we propose a method for generating a\nhypothesis distribution of object segmentation. We obtain a set of\nregion-factored segmentation hypotheses together with confidence estimates by\nmaking multiple queries of large pre-trained models. This process can produce\nsegmentation results that achieve state-of-the-art performance on unseen object\nsegmentation problems. The output can also serve as input to a belief-driven\nprocess for selecting robot actions to perturb the scene to reduce ambiguity.\nWe demonstrate the effectiveness of this method in real-robot experiments.\nWebsite: https://sites.google.com/view/embodied-uncertain-seg\n","subjects":["Computing Research Repository/Robotics","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}