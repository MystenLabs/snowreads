{"id":"2408.06755","title":"Sumotosima: A Framework and Dataset for Classifying and Summarizing\n  Otoscopic Images","authors":"Eram Anwarul Khan, Anas Anwarul Haq Khan","authorsParsed":[["Khan","Eram Anwarul",""],["Khan","Anas Anwarul Haq",""]],"versions":[{"version":"v1","created":"Tue, 13 Aug 2024 09:26:41 GMT"}],"updateDate":"2024-08-14","timestamp":1723541201000,"abstract":"  Otoscopy is a diagnostic procedure to examine the ear canal and eardrum using\nan otoscope. It identifies conditions like infections, foreign bodies, ear drum\nperforations and ear abnormalities. We propose a novel resource efficient deep\nlearning and transformer based framework, Sumotosima (Summarizer for otoscopic\nimages), an end-to-end pipeline for classification followed by summarization.\nOur framework works on combination of triplet and cross-entropy losses.\nAdditionally, we use Knowledge Enhanced Multimodal BART whose input is fused\ntextual and image embedding. The objective is to provide summaries that are\nwell-suited for patients, ensuring clarity and efficiency in understanding\notoscopic images. Given the lack of existing datasets, we have curated our own\nOCASD (Otoscopic Classification And Summary Dataset), which includes 500 images\nwith 5 unique categories annotated with their class and summaries by\nOtolaryngologists. Sumotosima achieved a result of 98.03%, which is 7.00%,\n3.10%, 3.01% higher than K-Nearest Neighbors, Random Forest and Support Vector\nMachines, respectively, in classification tasks. For summarization, Sumotosima\noutperformed GPT-4o and LLaVA by 88.53% and 107.57% in ROUGE scores,\nrespectively. We have made our code and dataset publicly available at\nhttps://github.com/anas2908/Sumotosima\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by-sa/4.0/"}