{"id":"2408.12692","title":"Unlocking Intrinsic Fairness in Stable Diffusion","authors":"Eunji Kim, Siwon Kim, Rahim Entezari, Sungroh Yoon","authorsParsed":[["Kim","Eunji",""],["Kim","Siwon",""],["Entezari","Rahim",""],["Yoon","Sungroh",""]],"versions":[{"version":"v1","created":"Thu, 22 Aug 2024 19:12:52 GMT"}],"updateDate":"2024-08-26","timestamp":1724353972000,"abstract":"  Recent text-to-image models like Stable Diffusion produce photo-realistic\nimages but often show demographic biases. Previous debiasing methods focused on\ntraining-based approaches, failing to explore the root causes of bias and\noverlooking Stable Diffusion's potential for unbiased image generation. In this\npaper, we demonstrate that Stable Diffusion inherently possesses fairness,\nwhich can be unlocked to achieve debiased outputs. Through carefully designed\nexperiments, we identify the excessive bonding between text prompts and the\ndiffusion process as a key source of bias. To address this, we propose a novel\napproach that perturbs text conditions to unleash Stable Diffusion's intrinsic\nfairness. Our method effectively mitigates bias without additional tuning,\nwhile preserving image-text alignment and image quality.\n","subjects":["Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/"}