{"id":"2408.17373","title":"Augmented Reality without Borders: Achieving Precise Localization\n  Without Maps","authors":"Albert Gassol Puigjaner, Irvin Aloise, Patrik Schmuck","authorsParsed":[["Puigjaner","Albert Gassol",""],["Aloise","Irvin",""],["Schmuck","Patrik",""]],"versions":[{"version":"v1","created":"Fri, 30 Aug 2024 16:08:49 GMT"},{"version":"v2","created":"Mon, 2 Sep 2024 12:53:40 GMT"},{"version":"v3","created":"Wed, 4 Sep 2024 13:47:59 GMT"}],"updateDate":"2024-09-05","timestamp":1725034129000,"abstract":"  Visual localization is crucial for Computer Vision and Augmented Reality (AR)\napplications, where determining the camera or device's position and orientation\nis essential to accurately interact with the physical environment. Traditional\nmethods rely on detailed 3D maps constructed using Structure from Motion (SfM)\nor Simultaneous Localization and Mapping (SLAM), which is computationally\nexpensive and impractical for dynamic or large-scale environments. We introduce\nMARLoc, a novel localization framework for AR applications that uses known\nrelative transformations within image sequences to perform intra-sequence\ntriangulation, generating 3D-2D correspondences for pose estimation and\nrefinement. MARLoc eliminates the need for pre-built SfM maps, providing\naccurate and efficient localization suitable for dynamic outdoor environments.\nEvaluation with benchmark datasets and real-world experiments demonstrates\nMARLoc's state-of-the-art performance and robustness. By integrating MARLoc\ninto an AR device, we highlight its capability to achieve precise localization\nin real-world outdoor scenarios, showcasing its practical effectiveness and\npotential to enhance visual localization in AR applications.\n","subjects":["Computing Research Repository/Robotics"],"license":"http://creativecommons.org/licenses/by/4.0/"}