{"id":"2407.05311","title":"MMAD: Multi-label Micro-Action Detection in Videos","authors":"Kun Li, Dan Guo, Pengyu Liu, Guoliang Chen, Meng Wang","authorsParsed":[["Li","Kun",""],["Guo","Dan",""],["Liu","Pengyu",""],["Chen","Guoliang",""],["Wang","Meng",""]],"versions":[{"version":"v1","created":"Sun, 7 Jul 2024 09:45:14 GMT"}],"updateDate":"2024-07-09","timestamp":1720345514000,"abstract":"  Human body actions are an important form of non-verbal communication in\nsocial interactions. This paper focuses on a specific subset of body actions\nknown as micro-actions, which are subtle, low-intensity body movements that\nprovide a deeper understanding of inner human feelings. In real-world\nscenarios, human micro-actions often co-occur, with multiple micro-actions\noverlapping in time, such as simultaneous head and hand movements. However,\ncurrent research primarily focuses on recognizing individual micro-actions\nwhile overlooking their co-occurring nature. To narrow this gap, we propose a\nnew task named Multi-label Micro-Action Detection (MMAD), which involves\nidentifying all micro-actions in a given short video, determining their start\nand end times, and categorizing them. Achieving this requires a model capable\nof accurately capturing both long-term and short-term action relationships to\nlocate and classify multiple micro-actions. To support the MMAD task, we\nintroduce a new dataset named Multi-label Micro-Action-52 (MMA-52),\nspecifically designed to facilitate the detailed analysis and exploration of\ncomplex human micro-actions. The proposed MMA-52 dataset is available at:\nhttps://github.com/VUT-HFUT/Micro-Action.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}