{"id":"2408.08499","title":"The Limitations of Model Retraining in the Face of Performativity","authors":"Anmol Kabra, Kumar Kshitij Patel","authorsParsed":[["Kabra","Anmol",""],["Patel","Kumar Kshitij",""]],"versions":[{"version":"v1","created":"Fri, 16 Aug 2024 02:53:01 GMT"}],"updateDate":"2024-08-19","timestamp":1723776781000,"abstract":"  We study stochastic optimization in the context of performative shifts, where\nthe data distribution changes in response to the deployed model. We demonstrate\nthat naive retraining can be provably suboptimal even for simple distribution\nshifts. The issue worsens when models are retrained given a finite number of\nsamples at each retraining step. We show that adding regularization to\nretraining corrects both of these issues, attaining provably optimal models in\nthe face of distribution shifts. Our work advocates rethinking how machine\nlearning models are retrained in the presence of performative effects.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Computer Science and Game Theory"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}