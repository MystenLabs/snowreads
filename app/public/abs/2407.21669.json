{"id":"2407.21669","title":"Synth-Empathy: Towards High-Quality Synthetic Empathy Data","authors":"Hao Liang, Linzhuang Sun, Jingxuan Wei, Xijie Huang, Linkun Sun, Bihui\n  Yu, Conghui He, Wentao Zhang","authorsParsed":[["Liang","Hao",""],["Sun","Linzhuang",""],["Wei","Jingxuan",""],["Huang","Xijie",""],["Sun","Linkun",""],["Yu","Bihui",""],["He","Conghui",""],["Zhang","Wentao",""]],"versions":[{"version":"v1","created":"Wed, 31 Jul 2024 15:12:24 GMT"},{"version":"v2","created":"Sat, 10 Aug 2024 15:04:28 GMT"}],"updateDate":"2024-08-13","timestamp":1722438744000,"abstract":"  In recent years, with the rapid advancements in large language models (LLMs),\nachieving excellent empathetic response capabilities has become a crucial\nprerequisite. Consequently, managing and understanding empathetic datasets have\ngained increasing significance. However, empathetic data are typically\nhuman-labeled, leading to insufficient datasets and wasted human labor. In this\nwork, we present Synth-Empathy, an LLM-based data generation and quality and\ndiversity selection pipeline that automatically generates high-quality\nempathetic data while discarding low-quality data. With the data generated from\na low empathetic model, we are able to further improve empathetic response\nperformance and achieve state-of-the-art (SoTA) results across multiple\nbenchmarks. Moreover, our model achieves SoTA performance on various human\nevaluation benchmarks, demonstrating its effectiveness and robustness in\nreal-world applications. Furthermore, we show the trade-off between data\nquantity and quality, providing insights into empathetic data generation and\nselection.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"ZZEaReEj4jMTvGX7Yor4d9vy6O-Wh7x1XVrALvN1PUQ","pdfSize":"3006306"}
