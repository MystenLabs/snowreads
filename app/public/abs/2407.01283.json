{"id":"2407.01283","title":"Energy-Aware Decentralized Learning with Intermittent Model Training","authors":"Akash Dhasade, Paolo Dini, Elia Guerra, Anne-Marie Kermarrec, Marco\n  Miozzo, Rafael Pires, Rishi Sharma, Martijn de Vos","authorsParsed":[["Dhasade","Akash",""],["Dini","Paolo",""],["Guerra","Elia",""],["Kermarrec","Anne-Marie",""],["Miozzo","Marco",""],["Pires","Rafael",""],["Sharma","Rishi",""],["de Vos","Martijn",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 13:39:03 GMT"}],"updateDate":"2024-07-02","timestamp":1719841143000,"abstract":"  Decentralized learning (DL) offers a powerful framework where nodes\ncollaboratively train models without sharing raw data and without the\ncoordination of a central server. In the iterative rounds of DL, models are\ntrained locally, shared with neighbors in the topology, and aggregated with\nother models received from neighbors. Sharing and merging models contribute to\nconvergence towards a consensus model that generalizes better across the\ncollective data captured at training time. In addition, the energy consumption\nwhile sharing and merging model parameters is negligible compared to the energy\nspent during the training phase. Leveraging this fact, we present SkipTrain, a\nnovel DL algorithm, which minimizes energy consumption in decentralized\nlearning by strategically skipping some training rounds and substituting them\nwith synchronization rounds. These training-silent periods, besides saving\nenergy, also allow models to better mix and finally produce models with\nsuperior accuracy than typical DL algorithms that train at every round. Our\nempirical evaluations with 256 nodes demonstrate that SkipTrain reduces energy\nconsumption by 50% and increases model accuracy by up to 12% compared to\nD-PSGD, the conventional DL algorithm.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Distributed, Parallel, and Cluster Computing"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"QJYbOIAVle-wKH6SQThORcEr0v_zcB7Zrisq3yGhfEM","pdfSize":"1125385"}
