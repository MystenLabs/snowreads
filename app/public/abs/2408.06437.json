{"id":"2408.06437","title":"HAT: History-Augmented Anchor Transformer for Online Temporal Action\n  Localization","authors":"Sakib Reza, Yuexi Zhang, Mohsen Moghaddam, Octavia Camps","authorsParsed":[["Reza","Sakib",""],["Zhang","Yuexi",""],["Moghaddam","Mohsen",""],["Camps","Octavia",""]],"versions":[{"version":"v1","created":"Mon, 12 Aug 2024 18:29:48 GMT"}],"updateDate":"2024-08-14","timestamp":1723487388000,"abstract":"  Online video understanding often relies on individual frames, leading to\nframe-by-frame predictions. Recent advancements such as Online Temporal Action\nLocalization (OnTAL), extend this approach to instance-level predictions.\nHowever, existing methods mainly focus on short-term context, neglecting\nhistorical information. To address this, we introduce the History-Augmented\nAnchor Transformer (HAT) Framework for OnTAL. By integrating historical\ncontext, our framework enhances the synergy between long-term and short-term\ninformation, improving the quality of anchor features crucial for\nclassification and localization. We evaluate our model on both procedural\negocentric (PREGO) datasets (EGTEA and EPIC) and standard non-PREGO OnTAL\ndatasets (THUMOS and MUSES). Results show that our model outperforms\nstate-of-the-art approaches significantly on PREGO datasets and achieves\ncomparable or slightly superior performance on non-PREGO datasets, underscoring\nthe importance of leveraging long-term history, especially in procedural and\negocentric action scenarios. Code is available at:\nhttps://github.com/sakibreza/ECCV24-HAT/\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-sa/4.0/"}