{"id":"2408.12814","title":"From Few to More: Scribble-based Medical Image Segmentation via Masked\n  Context Modeling and Continuous Pseudo Labels","authors":"Zhisong Wang, Yiwen Ye, Ziyang Chen, Minglei Shu, Yong Xia","authorsParsed":[["Wang","Zhisong",""],["Ye","Yiwen",""],["Chen","Ziyang",""],["Shu","Minglei",""],["Xia","Yong",""]],"versions":[{"version":"v1","created":"Fri, 23 Aug 2024 03:19:20 GMT"}],"updateDate":"2024-08-26","timestamp":1724383160000,"abstract":"  Scribble-based weakly supervised segmentation techniques offer comparable\nperformance to fully supervised methods while significantly reducing annotation\ncosts, making them an appealing alternative. Existing methods often rely on\nauxiliary tasks to enforce semantic consistency and use hard pseudo labels for\nsupervision. However, these methods often overlook the unique requirements of\nmodels trained with sparse annotations. Since the model must predict pixel-wise\nsegmentation maps with limited annotations, the ability to handle varying\nlevels of annotation richness is critical. In this paper, we adopt the\nprinciple of `from few to more' and propose MaCo, a weakly supervised framework\ndesigned for medical image segmentation. MaCo employs masked context modeling\n(MCM) and continuous pseudo labels (CPL). MCM uses an attention-based masking\nstrategy to disrupt the input image, compelling the model's predictions to\nremain consistent with those of the original image. CPL converts scribble\nannotations into continuous pixel-wise labels by applying an exponential decay\nfunction to distance maps, resulting in continuous maps that represent the\nconfidence of each pixel belonging to a specific category, rather than using\nhard pseudo labels. We evaluate MaCo against other weakly supervised methods\nusing three public datasets. The results indicate that MaCo outperforms\ncompeting methods across all datasets, setting a new record in weakly\nsupervised medical image segmentation.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}