{"id":"2407.04472","title":"EventChat: Implementation and user-centric evaluation of a large\n  language model-driven conversational recommender system for exploring leisure\n  events in an SME context","authors":"Hannes Kunstmann, Joseph Ollier, Joel Persson, Florian von Wangenheim","authorsParsed":[["Kunstmann","Hannes",""],["Ollier","Joseph",""],["Persson","Joel",""],["von Wangenheim","Florian",""]],"versions":[{"version":"v1","created":"Fri, 5 Jul 2024 12:42:31 GMT"},{"version":"v2","created":"Mon, 8 Jul 2024 14:50:49 GMT"},{"version":"v3","created":"Tue, 9 Jul 2024 13:31:00 GMT"}],"updateDate":"2024-07-10","timestamp":1720183351000,"abstract":"  Large language models (LLMs) present an enormous evolution in the strategic\npotential of conversational recommender systems (CRS). Yet to date, research\nhas predominantly focused upon technical frameworks to implement LLM-driven\nCRS, rather than end-user evaluations or strategic implications for firms,\nparticularly from the perspective of a small to medium enterprises (SME) that\nmakeup the bedrock of the global economy. In the current paper, we detail the\ndesign of an LLM-driven CRS in an SME setting, and its subsequent performance\nin the field using both objective system metrics and subjective user\nevaluations. While doing so, we additionally outline a short-form revised\nResQue model for evaluating LLM-driven CRS, enabling replicability in a rapidly\nevolving field. Our results reveal good system performance from a user\nexperience perspective (85.5% recommendation accuracy) but underscore latency,\ncost, and quality issues challenging business viability. Notably, with a median\ncost of $0.04 per interaction and a latency of 5.7s, cost-effectiveness and\nresponse time emerge as crucial areas for achieving a more user-friendly and\neconomically viable LLM-driven CRS for SME settings. One major driver of these\ncosts is the use of an advanced LLM as a ranker within the retrieval-augmented\ngeneration (RAG) technique. Our results additionally indicate that relying\nsolely on approaches such as Prompt-based learning with ChatGPT as the\nunderlying LLM makes it challenging to achieve satisfying quality in a\nproduction environment. Strategic considerations for SMEs deploying an\nLLM-driven CRS are outlined, particularly considering trade-offs in the current\ntechnical landscape.\n","subjects":["Computing Research Repository/Information Retrieval","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/"}