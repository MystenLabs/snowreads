{"id":"2407.01617","title":"Subjective fairness in algorithmic decision-support","authors":"Sarra Tajouri, Alexis Tsouki\\`as","authorsParsed":[["Tajouri","Sarra",""],["Tsouki√†s","Alexis",""]],"versions":[{"version":"v1","created":"Fri, 28 Jun 2024 14:37:39 GMT"}],"updateDate":"2024-07-03","timestamp":1719585459000,"abstract":"  The treatment of fairness in decision-making literature usually involves\nquantifying fairness using objective measures. This work takes a critical\nstance to highlight the limitations of these approaches (group fairness and\nindividual fairness) using sociological insights. First, we expose how these\nmetrics often fail to reflect societal realities. By neglecting crucial\nhistorical, cultural, and social factors, they fall short of capturing all\ndiscriminatory practices. Second, we redefine fairness as a subjective property\nmoving from a top-down to a bottom-up approach. This shift allows the inclusion\nof diverse stakeholders perceptions, recognizing that fairness is not merely\nabout objective metrics but also about individuals views on their treatment.\nFinally, we aim to use explanations as a mean to achieve fairness. Our approach\nemploys explainable clustering to form groups based on individuals subjective\nperceptions to ensure that individuals who see themselves as similar receive\nsimilar treatment. We emphasize the role of explanations in achieving fairness,\nfocusing not only on procedural fairness but also on providing subjective\nexplanations to convince stakeholders of their fair treatment.\n","subjects":["Computing Research Repository/Computers and Society"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/"}