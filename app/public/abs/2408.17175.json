{"id":"2408.17175","title":"Codec Does Matter: Exploring the Semantic Shortcoming of Codec for Audio\n  Language Model","authors":"Zhen Ye, Peiwen Sun, Jiahe Lei, Hongzhan Lin, Xu Tan, Zheqi Dai,\n  Qiuqiang Kong, Jianyi Chen, Jiahao Pan, Qifeng Liu, Yike Guo, Wei Xue","authorsParsed":[["Ye","Zhen",""],["Sun","Peiwen",""],["Lei","Jiahe",""],["Lin","Hongzhan",""],["Tan","Xu",""],["Dai","Zheqi",""],["Kong","Qiuqiang",""],["Chen","Jianyi",""],["Pan","Jiahao",""],["Liu","Qifeng",""],["Guo","Yike",""],["Xue","Wei",""]],"versions":[{"version":"v1","created":"Fri, 30 Aug 2024 10:24:07 GMT"},{"version":"v2","created":"Thu, 19 Sep 2024 09:13:39 GMT"}],"updateDate":"2024-09-20","timestamp":1725013447000,"abstract":"  Recent advancements in audio generation have been significantly propelled by\nthe capabilities of Large Language Models (LLMs). The existing research on\naudio LLM has primarily focused on enhancing the architecture and scale of\naudio language models, as well as leveraging larger datasets, and generally,\nacoustic codecs, such as EnCodec, are used for audio tokenization. However,\nthese codecs were originally designed for audio compression, which may lead to\nsuboptimal performance in the context of audio LLM. Our research aims to\naddress the shortcomings of current audio LLM codecs, particularly their\nchallenges in maintaining semantic integrity in generated audio. For instance,\nexisting methods like VALL-E, which condition acoustic token generation on text\ntranscriptions, often suffer from content inaccuracies and elevated word error\nrates (WER) due to semantic misinterpretations of acoustic tokens, resulting in\nword skipping and errors. To overcome these issues, we propose a\nstraightforward yet effective approach called X-Codec. X-Codec incorporates\nsemantic features from a pre-trained semantic encoder before the Residual\nVector Quantization (RVQ) stage and introduces a semantic reconstruction loss\nafter RVQ. By enhancing the semantic ability of the codec, X-Codec\nsignificantly reduces WER in speech synthesis tasks and extends these benefits\nto non-speech applications, including music and sound generation. Our\nexperiments in text-to-speech, music continuation, and text-to-sound tasks\ndemonstrate that integrating semantic information substantially improves the\noverall performance of language models in audio generation. Our code and demo\nare available (Demo: https://x-codec-audio.github.io Code:\nhttps://github.com/zhenye234/xcodec)\n","subjects":["Electrical Engineering and Systems Science/Audio and Speech Processing","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language","Computing Research Repository/Sound"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"sGy_KL3ATSc0vSvQ81bY0PLmgp_qiDzOep0pZ2rIwRc","pdfSize":"330744"}
