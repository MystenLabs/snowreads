{"id":"2408.04705","title":"Overlay-based Decentralized Federated Learning in Bandwidth-limited\n  Networks","authors":"Yudi Huang, Tingyang Sun, Ting He","authorsParsed":[["Huang","Yudi",""],["Sun","Tingyang",""],["He","Ting",""]],"versions":[{"version":"v1","created":"Thu, 8 Aug 2024 18:05:11 GMT"}],"updateDate":"2024-08-12","timestamp":1723140311000,"abstract":"  The emerging machine learning paradigm of decentralized federated learning\n(DFL) has the promise of greatly boosting the deployment of artificial\nintelligence (AI) by directly learning across distributed agents without\ncentralized coordination. Despite significant efforts on improving the\ncommunication efficiency of DFL, most existing solutions were based on the\nsimplistic assumption that neighboring agents are physically adjacent in the\nunderlying communication network, which fails to correctly capture the\ncommunication cost when learning over a general bandwidth-limited network, as\nencountered in many edge networks. In this work, we address this gap by\nleveraging recent advances in network tomography to jointly design the\ncommunication demands and the communication schedule for overlay-based DFL in\nbandwidth-limited networks without requiring explicit cooperation from the\nunderlying network. By carefully analyzing the structure of our problem, we\ndecompose it into a series of optimization problems that can each be solved\nefficiently, to collectively minimize the total training time. Extensive\ndata-driven simulations show that our solution can significantly accelerate DFL\nin comparison with state-of-the-art designs.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Networking and Internet Architecture"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}