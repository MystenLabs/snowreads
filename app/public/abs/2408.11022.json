{"id":"2408.11022","title":"Improved global performance guarantees of second-order methods in convex\n  minimization","authors":"Pavel Dvurechensky and Yurii Nesterov","authorsParsed":[["Dvurechensky","Pavel",""],["Nesterov","Yurii",""]],"versions":[{"version":"v1","created":"Tue, 20 Aug 2024 17:23:25 GMT"}],"updateDate":"2024-08-21","timestamp":1724174605000,"abstract":"  In this paper, we attempt to compare two distinct branches of research on\nsecond-order optimization methods. The first one studies self-concordant\nfunctions and barriers, the main assumption being that the third derivative of\nthe objective is bounded by the second derivative. The second branch studies\ncubic regularized Newton methods (CRNMs) with the main assumption that the\nsecond derivative is Lipschitz continuous. We develop a new theoretical\nanalysis for a path-following scheme (PFS) for general self-concordant\nfunctions, as opposed to the classical path-following scheme developed for\nself-concordant barriers. We show that the complexity bound for this scheme is\nbetter than that of the Damped Newton Method (DNM) and show that our method has\nglobal superlinear convergence. We propose also a new predictor-corrector\npath-following scheme (PCPFS) that leads to further improvement of constant\nfactors in the complexity guarantees for minimizing general self-concordant\nfunctions. We also apply path-following schemes to different classes of\nconstrained optimization problems and obtain the resulting complexity bounds.\nFinally, we analyze an important subclass of general self-concordant functions,\nnamely a class of strongly convex functions with Lipschitz continuous second\nderivative, and show that for this subclass CRNMs give even better complexity\nbounds.\n","subjects":["Mathematics/Optimization and Control"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}