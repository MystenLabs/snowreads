{"id":"2408.11937","title":"Distributed alternating gradient descent for convex semi-infinite\n  programs over a network","authors":"Ashwin Aravind, Debasish Chatterjee, Ashish Cherukuri","authorsParsed":[["Aravind","Ashwin",""],["Chatterjee","Debasish",""],["Cherukuri","Ashish",""]],"versions":[{"version":"v1","created":"Wed, 21 Aug 2024 18:41:51 GMT"}],"updateDate":"2024-08-23","timestamp":1724265711000,"abstract":"  This paper presents a first-order distributed algorithm for solving a convex\nsemi-infinite program (SIP) over a time-varying network. In this setting, the\nobjective function associated with the optimization problem is a summation of a\nset of functions, each held by one node in a network. The semi-infinite\nconstraint, on the other hand, is known to all agents. The nodes collectively\naim to solve the problem using local data about the objective and limited\ncommunication capabilities depending on the network topology. Our algorithm is\nbuilt on three key ingredients: consensus step, gradient descent in the local\nobjective, and local gradient descent iterations in the constraint at a node\nwhen the estimate violates the semi-infinite constraint. The algorithm is\nconstructed, and its parameters are prescribed in such a way that the iterates\nheld by each agent provably converge to an optimizer. That is, as the algorithm\nprogresses, the estimates achieve consensus, and the constraint violation and\nthe error in the optimal value are bounded above by vanishing terms. A\nsimulation example illustrates our results.\n","subjects":["Mathematics/Optimization and Control","Computing Research Repository/Systems and Control","Electrical Engineering and Systems Science/Systems and Control"],"license":"http://creativecommons.org/licenses/by/4.0/"}