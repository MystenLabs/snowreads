{"id":"2408.14232","title":"Efficient Active Flow Control Strategy for Confined Square Cylinder Wake\n  Using Deep Learning-Based Surrogate Model and Reinforcement Learning","authors":"Meng Zhang, Mustafa Z. Yousif, Minze Xu, Haifeng Zhou, Linqi Yu and\n  HeeChang Lim","authorsParsed":[["Zhang","Meng",""],["Yousif","Mustafa Z.",""],["Xu","Minze",""],["Zhou","Haifeng",""],["Yu","Linqi",""],["Lim","HeeChang",""]],"versions":[{"version":"v1","created":"Mon, 26 Aug 2024 12:48:10 GMT"}],"updateDate":"2024-08-27","timestamp":1724676490000,"abstract":"  This study presents a deep learning model-based reinforcement learning\n(DL-MBRL) approach for active control of two-dimensional (2D) wake flow past a\nsquare cylinder using antiphase jets. The DL-MBRL framework alternates between\ninteracting with a deep learning surrogate model (DL-SM) and computational\nfluid dynamics (CFD) simulations to suppress wake vortex shedding,\nsignificantly reducing computational costs. The DL-SM, which combines a\nTransformer and a multiscale enhanced super-resolution generative adversarial\nnetwork (MS-ESRGAN), effectively models complex flow dynamics, efficiently\nemulating the CFD environment. Trained on 2D direct numerical simulation (DNS)\ndata, the Transformer and MS-ESRGAN demonstrated excellent agreement with DNS\nresults, validating the DL-SM's accuracy. Error analysis suggests replacing the\nDL-SM with CFD every five interactions to maintain reliability. While DL-MBRL\nshowed less robust convergence than model-free reinforcement learning (MFRL)\nduring training, it reduced training time by 49.2%, from 41.87 hours to 20.62\nhours. Both MFRL and DL-MBRL achieved a 98% reduction in shedding energy and a\n95% reduction in the standard deviation of the lift coefficient (C_L). However,\nMFRL exhibited a nonzero mean lift coefficient due to insufficient exploration,\nwhereas DL-MBRL improved exploration by leveraging the randomness of the DL-SM,\nresolving the nonzero mean C_L issue. This study demonstrates that DL-MBRL is\nnot only comparably effective but also superior to MFRL in flow stabilization,\nwith significantly reduced training time, highlighting the potential of\ncombining deep reinforcement learning with DL-SM for enhanced active flow\ncontrol.\n","subjects":["Physics/Fluid Dynamics"],"license":"http://creativecommons.org/publicdomain/zero/1.0/","blobId":"dlhy5gjpZU4d0Er0XEKoQWse93uerNpBz0e6cMKIXVU","pdfSize":"3260688"}
