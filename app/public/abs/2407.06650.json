{"id":"2407.06650","title":"An Automatic Quality Metric for Evaluating Simultaneous Interpretation","authors":"Mana Makinae, Katsuhito Sudoh, Mararu Yamada, Satoshi Nakamura","authorsParsed":[["Makinae","Mana",""],["Sudoh","Katsuhito",""],["Yamada","Mararu",""],["Nakamura","Satoshi",""]],"versions":[{"version":"v1","created":"Tue, 9 Jul 2024 08:21:40 GMT"},{"version":"v2","created":"Fri, 13 Sep 2024 14:39:33 GMT"}],"updateDate":"2024-09-16","timestamp":1720513300000,"abstract":"  Simultaneous interpretation (SI), the translation of one language to another\nin real time, starts translation before the original speech has finished. Its\nevaluation needs to consider both latency and quality. This trade-off is\nchallenging especially for distant word order language pairs such as English\nand Japanese. To handle this word order gap, interpreters maintain the word\norder of the source language as much as possible to keep up with original\nlanguage to minimize its latency while maintaining its quality, whereas in\ntranslation reordering happens to keep fluency in the target language. This\nmeans outputs synchronized with the source language are desirable based on the\nreal SI situation, and it's a key for further progress in computational SI and\nsimultaneous machine translation (SiMT). In this work, we propose an automatic\nevaluation metric for SI and SiMT focusing on word order synchronization. Our\nevaluation metric is based on rank correlation coefficients, leveraging\ncross-lingual pre-trained language models. Our experimental results on\nNAIST-SIC-Aligned and JNPC showed our metrics' effectiveness to measure word\norder synchronization between source and target language.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/"}