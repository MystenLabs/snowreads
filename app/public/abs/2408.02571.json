{"id":"2408.02571","title":"Contrastive Learning-based Multi Modal Architecture for Emoticon\n  Prediction by Employing Image-Text Pairs","authors":"Ananya Pandey, Dinesh Kumar Vishwakarma","authorsParsed":[["Pandey","Ananya",""],["Vishwakarma","Dinesh Kumar",""]],"versions":[{"version":"v1","created":"Mon, 5 Aug 2024 15:45:59 GMT"}],"updateDate":"2024-08-06","timestamp":1722872759000,"abstract":"  The emoticons are symbolic representations that generally accompany the\ntextual content to visually enhance or summarize the true intention of a\nwritten message. Although widely utilized in the realm of social media, the\ncore semantics of these emoticons have not been extensively explored based on\nmultiple modalities. Incorporating textual and visual information within a\nsingle message develops an advanced way of conveying information. Hence, this\nresearch aims to analyze the relationship among sentences, visuals, and\nemoticons. For an orderly exposition, this paper initially provides a detailed\nexamination of the various techniques for extracting multimodal features,\nemphasizing the pros and cons of each method. Through conducting a\ncomprehensive examination of several multimodal algorithms, with specific\nemphasis on the fusion approaches, we have proposed a novel contrastive\nlearning based multimodal architecture. The proposed model employs the joint\ntraining of dual-branch encoder along with the contrastive learning to\naccurately map text and images into a common latent space. Our key finding is\nthat by integrating the principle of contrastive learning with that of the\nother two branches yields superior results. The experimental results\ndemonstrate that our suggested methodology surpasses existing multimodal\napproaches in terms of accuracy and robustness. The proposed model attained an\naccuracy of 91% and an MCC-score of 90% while assessing emoticons using the\nMultimodal-Twitter Emoticon dataset acquired from Twitter. We provide evidence\nthat deep features acquired by contrastive learning are more efficient,\nsuggesting that the proposed fusion technique also possesses strong\ngeneralisation capabilities for recognising emoticons across several modes.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","blobId":"49Y769qyda6yeulJmC_vonUdV6g_Ugv2D25z-e-nZsQ","pdfSize":"1713174","txDigest":"EnY29nkbWbaverfdybAp1s6419PGhe9qwJFxSDGgPA2z","endEpoch":"1","status":"CERTIFIED"}
