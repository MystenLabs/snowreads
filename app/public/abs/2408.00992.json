{"id":"2408.00992","title":"Fairness in Large Language Models in Three Hours","authors":"Thang Doan Viet, Zichong Wang, Minh Nhat Nguyen, Wenbin Zhang","authorsParsed":[["Viet","Thang Doan",""],["Wang","Zichong",""],["Nguyen","Minh Nhat",""],["Zhang","Wenbin",""]],"versions":[{"version":"v1","created":"Fri, 2 Aug 2024 03:44:14 GMT"},{"version":"v2","created":"Mon, 5 Aug 2024 02:09:58 GMT"},{"version":"v3","created":"Thu, 8 Aug 2024 01:23:11 GMT"}],"updateDate":"2024-08-09","timestamp":1722570254000,"abstract":"  Large Language Models (LLMs) have demonstrated remarkable success across\nvarious domains but often lack fairness considerations, potentially leading to\ndiscriminatory outcomes against marginalized populations. Unlike fairness in\ntraditional machine learning, fairness in LLMs involves unique backgrounds,\ntaxonomies, and fulfillment techniques. This tutorial provides a systematic\noverview of recent advances in the literature concerning fair LLMs, beginning\nwith real-world case studies to introduce LLMs, followed by an analysis of bias\ncauses therein. The concept of fairness in LLMs is then explored, summarizing\nthe strategies for evaluating bias and the algorithms designed to promote\nfairness. Additionally, resources for assessing bias in LLMs, including\ntoolkits and datasets, are compiled, and current research challenges and open\nquestions in the field are discussed. The repository is available at\n\\url{https://github.com/LavinWong/Fairness-in-Large-Language-Models}.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}