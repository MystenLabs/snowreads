{"id":"2408.04098","title":"Performance and Non-adversarial Robustness of the Segment Anything Model\n  2 in Surgical Video Segmentation","authors":"Yiqing Shen, Hao Ding, Xinyuan Shao, Mathias Unberath","authorsParsed":[["Shen","Yiqing",""],["Ding","Hao",""],["Shao","Xinyuan",""],["Unberath","Mathias",""]],"versions":[{"version":"v1","created":"Wed, 7 Aug 2024 21:33:07 GMT"},{"version":"v2","created":"Fri, 16 Aug 2024 12:51:05 GMT"}],"updateDate":"2024-08-19","timestamp":1723066387000,"abstract":"  Fully supervised deep learning (DL) models for surgical video segmentation\nhave been shown to struggle with non-adversarial, real-world corruptions of\nimage quality including smoke, bleeding, and low illumination. Foundation\nmodels for image segmentation, such as the segment anything model (SAM) that\nfocuses on interactive prompt-based segmentation, move away from semantic\nclasses and thus can be trained on larger and more diverse data, which offers\noutstanding zero-shot generalization with appropriate user prompts. Recently,\nbuilding upon this success, SAM-2 has been proposed to further extend the\nzero-shot interactive segmentation capabilities from independent frame-by-frame\nto video segmentation. In this paper, we present a first experimental study\nevaluating SAM-2's performance on surgical video data. Leveraging the\nSegSTRONG-C MICCAI EndoVIS 2024 sub-challenge dataset, we assess SAM-2's\neffectiveness on uncorrupted endoscopic sequences and evaluate its\nnon-adversarial robustness on videos with corrupted image quality simulating\nsmoke, bleeding, and low brightness conditions under various prompt strategies.\nOur experiments demonstrate that SAM-2, in zero-shot manner, can achieve\ncompetitive or even superior performance compared to fully-supervised deep\nlearning models on surgical video data, including under non-adversarial\ncorruptions of image quality. Additionally, SAM-2 consistently outperforms the\noriginal SAM and its medical variants across all conditions. Finally,\nframe-sparse prompting can consistently outperform frame-wise prompting for\nSAM-2, suggesting that allowing SAM-2 to leverage its temporal modeling\ncapabilities leads to more coherent and accurate segmentation compared to\nfrequent prompting.\n","subjects":["Electrical Engineering and Systems Science/Image and Video Processing"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"Qg_DO_IzVF3nKFk68ovEgkMjCF-ZHc2L1xymq0FoLys","pdfSize":"468661"}
