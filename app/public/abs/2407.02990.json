{"id":"2407.02990","title":"Graph and Skipped Transformer: Exploiting Spatial and Temporal Modeling\n  Capacities for Efficient 3D Human Pose Estimation","authors":"Mengmeng Cui, Kunbo Zhang, Zhenan Sun","authorsParsed":[["Cui","Mengmeng",""],["Zhang","Kunbo",""],["Sun","Zhenan",""]],"versions":[{"version":"v1","created":"Wed, 3 Jul 2024 10:42:09 GMT"}],"updateDate":"2024-07-04","timestamp":1720003329000,"abstract":"  In recent years, 2D-to-3D pose uplifting in monocular 3D Human Pose\nEstimation (HPE) has attracted widespread research interest. GNN-based methods\nand Transformer-based methods have become mainstream architectures due to their\nadvanced spatial and temporal feature learning capacities. However, existing\napproaches typically construct joint-wise and frame-wise attention alignments\nin spatial and temporal domains, resulting in dense connections that introduce\nconsiderable local redundancy and computational overhead. In this paper, we\ntake a global approach to exploit spatio-temporal information and realise\nefficient 3D HPE with a concise Graph and Skipped Transformer architecture.\nSpecifically, in Spatial Encoding stage, coarse-grained body parts are deployed\nto construct Spatial Graph Network with a fully data-driven adaptive topology,\nensuring model flexibility and generalizability across various poses. In\nTemporal Encoding and Decoding stages, a simple yet effective Skipped\nTransformer is proposed to capture long-range temporal dependencies and\nimplement hierarchical feature aggregation. A straightforward Data Rolling\nstrategy is also developed to introduce dynamic information into 2D pose\nsequence. Extensive experiments are conducted on Human3.6M, MPI-INF-3DHP and\nHuman-Eva benchmarks. G-SFormer series methods achieve superior performances\ncompared with previous state-of-the-arts with only around ten percent of\nparameters and significantly reduced computational complexity. Additionally,\nG-SFormer also exhibits outstanding robustness to inaccuracies in detected 2D\nposes.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}