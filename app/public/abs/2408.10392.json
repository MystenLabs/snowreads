{"id":"2408.10392","title":"Value Alignment from Unstructured Text","authors":"Inkit Padhi, Karthikeyan Natesan Ramamurthy, Prasanna Sattigeri,\n  Manish Nagireddy, Pierre Dognin, Kush R. Varshney","authorsParsed":[["Padhi","Inkit",""],["Ramamurthy","Karthikeyan Natesan",""],["Sattigeri","Prasanna",""],["Nagireddy","Manish",""],["Dognin","Pierre",""],["Varshney","Kush R.",""]],"versions":[{"version":"v1","created":"Mon, 19 Aug 2024 20:22:08 GMT"}],"updateDate":"2024-08-21","timestamp":1724098928000,"abstract":"  Aligning large language models (LLMs) to value systems has emerged as a\nsignificant area of research within the fields of AI and NLP. Currently, this\nalignment process relies on the availability of high-quality supervised and\npreference data, which can be both time-consuming and expensive to curate or\nannotate. In this paper, we introduce a systematic end-to-end methodology for\naligning LLMs to the implicit and explicit values represented in unstructured\ntext data. Our proposed approach leverages the use of scalable synthetic data\ngeneration techniques to effectively align the model to the values present in\nthe unstructured data. Through two distinct use-cases, we demonstrate the\nefficiency of our methodology on the Mistral-7B-Instruct model. Our approach\ncredibly aligns LLMs to the values embedded within documents, and shows\nimproved performance against other approaches, as quantified through the use of\nautomatic metrics and win rates.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}