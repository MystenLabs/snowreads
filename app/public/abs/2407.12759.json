{"id":"2407.12759","title":"A survey and taxonomy of methods interpreting random forest models","authors":"Maissae Haddouchi and Abdelaziz Berrado","authorsParsed":[["Haddouchi","Maissae",""],["Berrado","Abdelaziz",""]],"versions":[{"version":"v1","created":"Wed, 17 Jul 2024 17:33:32 GMT"}],"updateDate":"2024-07-18","timestamp":1721237612000,"abstract":"  The interpretability of random forest (RF) models is a research topic of\ngrowing interest in the machine learning (ML) community. In the state of the\nart, RF is considered a powerful learning ensemble given its predictive\nperformance, flexibility, and ease of use. Furthermore, the inner process of\nthe RF model is understandable because it uses an intuitive and intelligible\napproach for building the RF decision tree ensemble. However, the RF resulting\nmodel is regarded as a \"black box\" because of its numerous deep decision trees.\nGaining visibility over the entire process that induces the final decisions by\nexploring each decision tree is complicated, if not impossible. This complexity\nlimits the acceptance and implementation of RF models in several fields of\napplication. Several papers have tackled the interpretation of RF models. This\npaper aims to provide an extensive review of methods used in the literature to\ninterpret RF resulting models. We have analyzed these methods and classified\nthem based on different axes. Although this review is not exhaustive, it\nprovides a taxonomy of various techniques that should guide users in choosing\nthe most appropriate tools for interpreting RF models, depending on the\ninterpretability aspects sought. It should also be valuable for researchers who\naim to focus their work on the interpretability of RF or ML black boxes in\ngeneral.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}