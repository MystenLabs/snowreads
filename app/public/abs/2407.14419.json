{"id":"2407.14419","title":"HOTS3D: Hyper-Spherical Optimal Transport for Semantic Alignment of\n  Text-to-3D Generation","authors":"Zezeng Li, Weimin Wang, WenHai Li, Na Lei, and Xianfeng Gu","authorsParsed":[["Li","Zezeng",""],["Wang","Weimin",""],["Li","WenHai",""],["Lei","Na",""],["Gu","Xianfeng",""]],"versions":[{"version":"v1","created":"Fri, 19 Jul 2024 15:43:24 GMT"}],"updateDate":"2024-07-22","timestamp":1721403804000,"abstract":"  Recent CLIP-guided 3D generation methods have achieved promising results but\nstruggle with generating faithful 3D shapes that conform with input text due to\nthe gap between text and image embeddings. To this end, this paper proposes\nHOTS3D which makes the first attempt to effectively bridge this gap by aligning\ntext features to the image features with spherical optimal transport (SOT).\nHowever, in high-dimensional situations, solving the SOT remains a challenge.\nTo obtain the SOT map for high-dimensional features obtained from CLIP encoding\nof two modalities, we mathematically formulate and derive the solution based on\nVillani's theorem, which can directly align two hyper-sphere distributions\nwithout manifold exponential maps. Furthermore, we implement it by leveraging\ninput convex neural networks (ICNNs) for the optimal Kantorovich potential.\nWith the optimally mapped features, a diffusion-based generator and a\nNerf-based decoder are subsequently utilized to transform them into 3D shapes.\nExtensive qualitative and qualitative comparisons with state-of-the-arts\ndemonstrate the superiority of the proposed HOTS3D for 3D shape generation,\nespecially on the consistency with text semantics.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}