{"id":"2408.04124","title":"Investigating Adversarial Attacks in Software Analytics via Machine\n  Learning Explainability","authors":"MD Abdul Awal, Mrigank Rochan, and Chanchal K. Roy","authorsParsed":[["Awal","MD Abdul",""],["Rochan","Mrigank",""],["Roy","Chanchal K.",""]],"versions":[{"version":"v1","created":"Wed, 7 Aug 2024 23:21:55 GMT"}],"updateDate":"2024-08-09","timestamp":1723072915000,"abstract":"  With the recent advancements in machine learning (ML), numerous ML-based\napproaches have been extensively applied in software analytics tasks to\nstreamline software development and maintenance processes. Nevertheless,\nstudies indicate that despite their potential usefulness, ML models are\nvulnerable to adversarial attacks, which may result in significant monetary\nlosses in these processes. As a result, the ML models' robustness against\nadversarial attacks must be assessed before they are deployed in software\nanalytics tasks. Despite several techniques being available for adversarial\nattacks in software analytics tasks, exploring adversarial attacks using ML\nexplainability is largely unexplored. Therefore, this study aims to investigate\nthe relationship between ML explainability and adversarial attacks to measure\nthe robustness of ML models in software analytics tasks. In addition, unlike\nmost existing attacks that directly perturb input-space, our attack approach\nfocuses on perturbing feature-space. Our extensive experiments, involving six\ndatasets, three ML explainability techniques, and seven ML models, demonstrate\nthat ML explainability can be used to conduct successful adversarial attacks on\nML models in software analytics tasks. This is achieved by modifying only the\ntop 1-3 important features identified by ML explainability techniques.\nConsequently, the ML models under attack fail to accurately predict up to 86.6%\nof instances that were correctly predicted before adversarial attacks,\nindicating the models' low robustness against such attacks. Finally, our\nproposed technique demonstrates promising results compared to four\nstate-of-the-art adversarial attack techniques targeting tabular data.\n","subjects":["Computing Research Repository/Software Engineering"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"e3VRqQOs1jrd32iv_9RY3Zi7YtRzY1LTK0X3RK5ejsM","pdfSize":"2071497"}
