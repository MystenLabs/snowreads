{"id":"2408.12130","title":"S-EPOA: Overcoming the Indivisibility of Annotations with Skill-Driven\n  Preference-Based Reinforcement Learning","authors":"Ni Mu, Yao Luan, Yiqin Yang, Qing-shan Jia","authorsParsed":[["Mu","Ni",""],["Luan","Yao",""],["Yang","Yiqin",""],["Jia","Qing-shan",""]],"versions":[{"version":"v1","created":"Thu, 22 Aug 2024 04:54:25 GMT"}],"updateDate":"2024-08-23","timestamp":1724302465000,"abstract":"  Preference-based reinforcement learning (PbRL) stands out by utilizing human\npreferences as a direct reward signal, eliminating the need for intricate\nreward engineering. However, despite its potential, traditional PbRL methods\nare often constrained by the indivisibility of annotations, which impedes the\nlearning process. In this paper, we introduce a groundbreaking approach,\nSkill-Enhanced Preference Optimization Algorithm~(S-EPOA), which addresses the\nannotation indivisibility issue by integrating skill mechanisms into the\npreference learning framework. Specifically, we first conduct the unsupervised\npretraining to learn useful skills. Then, we propose a novel query selection\nmechanism to balance the information gain and discriminability over the learned\nskill space. Experimental results on a range of tasks, including robotic\nmanipulation and locomotion, demonstrate that S-EPOA significantly outperforms\nconventional PbRL methods in terms of both robustness and learning efficiency.\nThe results highlight the effectiveness of skill-driven learning in overcoming\nthe challenges posed by annotation indivisibility.\n","subjects":["Computing Research Repository/Artificial Intelligence"],"license":"http://creativecommons.org/licenses/by/4.0/"}