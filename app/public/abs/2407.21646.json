{"id":"2407.21646","title":"Towards Achieving Human Parity on End-to-end Simultaneous Speech\n  Translation via LLM Agent","authors":"Shanbo Cheng, Zhichao Huang, Tom Ko, Hang Li, Ningxin Peng, Lu Xu,\n  Qini Zhang","authorsParsed":[["Cheng","Shanbo",""],["Huang","Zhichao",""],["Ko","Tom",""],["Li","Hang",""],["Peng","Ningxin",""],["Xu","Lu",""],["Zhang","Qini",""]],"versions":[{"version":"v1","created":"Wed, 31 Jul 2024 14:48:27 GMT"},{"version":"v2","created":"Fri, 30 Aug 2024 06:50:51 GMT"}],"updateDate":"2024-09-02","timestamp":1722437307000,"abstract":"  In this paper, we present Cross Language Agent -- Simultaneous\nInterpretation, CLASI, a high-quality and human-like Simultaneous Speech\nTranslation (SiST) System. Inspired by professional human interpreters, we\nutilize a novel data-driven read-write strategy to balance the translation\nquality and latency. To address the challenge of translating in-domain\nterminologies, CLASI employs a multi-modal retrieving module to obtain relevant\ninformation to augment the translation. Supported by LLMs, our approach can\ngenerate error-tolerated translation by considering the input audio, historical\ncontext, and retrieved information. Experimental results show that our system\noutperforms other systems by significant margins. Aligned with professional\nhuman interpreters, we evaluate CLASI with a better human evaluation metric,\nvalid information proportion (VIP), which measures the amount of information\nthat can be successfully conveyed to the listeners. In the real-world\nscenarios, where the speeches are often disfluent, informal, and unclear, CLASI\nachieves VIP of 81.3% and 78.0% for Chinese-to-English and English-to-Chinese\ntranslation directions, respectively. In contrast, state-of-the-art commercial\nor open-source systems only achieve 35.4% and 41.6%. On the extremely hard\ndataset, where other systems achieve under 13% VIP, CLASI can still achieve 70%\nVIP.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Sound","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}