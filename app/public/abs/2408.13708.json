{"id":"2408.13708","title":"InSpaceType: Dataset and Benchmark for Reconsidering Cross-Space Type\n  Performance in Indoor Monocular Depth","authors":"Cho-Ying Wu, Quankai Gao, Chin-Cheng Hsu, Te-Lin Wu, Jing-Wen Chen,\n  Ulrich Neumann","authorsParsed":[["Wu","Cho-Ying",""],["Gao","Quankai",""],["Hsu","Chin-Cheng",""],["Wu","Te-Lin",""],["Chen","Jing-Wen",""],["Neumann","Ulrich",""]],"versions":[{"version":"v1","created":"Sun, 25 Aug 2024 02:39:55 GMT"}],"updateDate":"2024-08-27","timestamp":1724553595000,"abstract":"  Indoor monocular depth estimation helps home automation, including robot\nnavigation or AR/VR for surrounding perception. Most previous methods primarily\nexperiment with the NYUv2 Dataset and concentrate on the overall performance in\ntheir evaluation. However, their robustness and generalization to diversely\nunseen types or categories for indoor spaces (spaces types) have yet to be\ndiscovered. Researchers may empirically find degraded performance in a released\npretrained model on custom data or less-frequent types. This paper studies the\ncommon but easily overlooked factor-space type and realizes a model's\nperformance variances across spaces. We present InSpaceType Dataset, a\nhigh-quality RGBD dataset for general indoor scenes, and benchmark 13 recent\nstate-of-the-art methods on InSpaceType. Our examination shows that most of\nthem suffer from performance imbalance between head and tailed types, and some\ntop methods are even more severe. The work reveals and analyzes underlying bias\nin detail for transparency and robustness. We extend the analysis to a total of\n4 datasets and discuss the best practice in synthetic data curation for\ntraining indoor monocular depth. Further, dataset ablation is conducted to find\nout the key factor in generalization. This work marks the first in-depth\ninvestigation of performance variances across space types and, more\nimportantly, releases useful tools, including datasets and codes, to closely\nexamine your pretrained depth models. Data and code:\nhttps://depthcomputation.github.io/DepthPublic/\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by-sa/4.0/","blobId":"R1IltDQrY5wmRzcVCI16B3vfOrlRbbjh5eMU1fSNTAY","pdfSize":"10339288"}
