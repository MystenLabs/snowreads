{"id":"2407.15098","title":"SeqMIA: Sequential-Metric Based Membership Inference Attack","authors":"Hao Li, Zheng Li, Siyuan Wu, Chengrui Hu, Yutong Ye, Min Zhang,\n  Dengguo Feng, Yang Zhang","authorsParsed":[["Li","Hao",""],["Li","Zheng",""],["Wu","Siyuan",""],["Hu","Chengrui",""],["Ye","Yutong",""],["Zhang","Min",""],["Feng","Dengguo",""],["Zhang","Yang",""]],"versions":[{"version":"v1","created":"Sun, 21 Jul 2024 09:11:08 GMT"}],"updateDate":"2024-07-23","timestamp":1721553068000,"abstract":"  Most existing membership inference attacks (MIAs) utilize metrics (e.g.,\nloss) calculated on the model's final state, while recent advanced attacks\nleverage metrics computed at various stages, including both intermediate and\nfinal stages, throughout the model training. Nevertheless, these attacks often\nprocess multiple intermediate states of the metric independently, ignoring\ntheir time-dependent patterns. Consequently, they struggle to effectively\ndistinguish between members and non-members who exhibit similar metric values,\nparticularly resulting in a high false-positive rate.\n  In this study, we delve deeper into the new membership signals in the\nblack-box scenario. We identify a new, more integrated membership signal: the\nPattern of Metric Sequence, derived from the various stages of model training.\nWe contend that current signals provide only partial perspectives of this new\nsignal: the new one encompasses both the model's multiple intermediate and\nfinal states, with a greater emphasis on temporal patterns among them. Building\nupon this signal, we introduce a novel attack method called Sequential-metric\nbased Membership Inference Attack (SeqMIA). Specifically, we utilize knowledge\ndistillation to obtain a set of distilled models representing various stages of\nthe target model's training. We then assess multiple metrics on these distilled\nmodels in chronological order, creating distilled metric sequence. We finally\nintegrate distilled multi-metric sequences as a sequential multiformat and\nemploy an attention-based RNN attack model for inference. Empirical results\nshow SeqMIA outperforms all baselines, especially can achieve an order of\nmagnitude improvement in terms of TPR @ 0.1% FPR. Furthermore, we delve into\nthe reasons why this signal contributes to SeqMIA's high attack performance,\nand assess various defense mechanisms against SeqMIA.\n","subjects":["Computing Research Repository/Cryptography and Security","Computing Research Repository/Machine Learning"],"license":"http://creativecommons.org/licenses/by/4.0/"}