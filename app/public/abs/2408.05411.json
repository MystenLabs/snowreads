{"id":"2408.05411","title":"How Does Audio Influence Visual Attention in Omnidirectional Videos?\n  Database and Model","authors":"Yuxin Zhu, Huiyu Duan, Kaiwei Zhang, Yucheng Zhu, Xilei Zhu, Long\n  Teng, Xiongkuo Min, Guangtao Zhai","authorsParsed":[["Zhu","Yuxin",""],["Duan","Huiyu",""],["Zhang","Kaiwei",""],["Zhu","Yucheng",""],["Zhu","Xilei",""],["Teng","Long",""],["Min","Xiongkuo",""],["Zhai","Guangtao",""]],"versions":[{"version":"v1","created":"Sat, 10 Aug 2024 02:45:46 GMT"}],"updateDate":"2024-08-13","timestamp":1723257946000,"abstract":"  Understanding and predicting viewer attention in omnidirectional videos\n(ODVs) is crucial for enhancing user engagement in virtual and augmented\nreality applications. Although both audio and visual modalities are essential\nfor saliency prediction in ODVs, the joint exploitation of these two modalities\nhas been limited, primarily due to the absence of large-scale audio-visual\nsaliency databases and comprehensive analyses. This paper comprehensively\ninvestigates audio-visual attention in ODVs from both subjective and objective\nperspectives. Specifically, we first introduce a new audio-visual saliency\ndatabase for omnidirectional videos, termed AVS-ODV database, containing 162\nODVs and corresponding eye movement data collected from 60 subjects under three\naudio modes including mute, mono, and ambisonics. Based on the constructed\nAVS-ODV database, we perform an in-depth analysis of how audio influences\nvisual attention in ODVs. To advance the research on audio-visual saliency\nprediction for ODVs, we further establish a new benchmark based on the AVS-ODV\ndatabase by testing numerous state-of-the-art saliency models, including\nvisual-only models and audio-visual models. In addition, given the limitations\nof current models, we propose an innovative omnidirectional audio-visual\nsaliency prediction network (OmniAVS), which is built based on the U-Net\narchitecture, and hierarchically fuses audio and visual features from the\nmultimodal aligned embedding space. Extensive experimental results demonstrate\nthat the proposed OmniAVS model outperforms other state-of-the-art models on\nboth ODV AVS prediction and traditional AVS predcition tasks. The AVS-ODV\ndatabase and OmniAVS model will be released to facilitate future research.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}