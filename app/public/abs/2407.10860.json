{"id":"2407.10860","title":"Human-Centric Transformer for Domain Adaptive Action Recognition","authors":"Kun-Yu Lin, Jiaming Zhou, Wei-Shi Zheng","authorsParsed":[["Lin","Kun-Yu",""],["Zhou","Jiaming",""],["Zheng","Wei-Shi",""]],"versions":[{"version":"v1","created":"Mon, 15 Jul 2024 16:10:11 GMT"}],"updateDate":"2024-07-16","timestamp":1721059811000,"abstract":"  We study the domain adaptation task for action recognition, namely domain\nadaptive action recognition, which aims to effectively transfer action\nrecognition power from a label-sufficient source domain to a label-free target\ndomain. Since actions are performed by humans, it is crucial to exploit human\ncues in videos when recognizing actions across domains. However, existing\nmethods are prone to losing human cues but prefer to exploit the correlation\nbetween non-human contexts and associated actions for recognition, and the\ncontexts of interest agnostic to actions would reduce recognition performance\nin the target domain. To overcome this problem, we focus on uncovering\nhuman-centric action cues for domain adaptive action recognition, and our\nconception is to investigate two aspects of human-centric action cues, namely\nhuman cues and human-context interaction cues. Accordingly, our proposed\nHuman-Centric Transformer (HCTransformer) develops a decoupled human-centric\nlearning paradigm to explicitly concentrate on human-centric action cues in\ndomain-variant video feature learning. Our HCTransformer first conducts\nhuman-aware temporal modeling by a human encoder, aiming to avoid a loss of\nhuman cues during domain-invariant video feature learning. Then, by a\nTransformer-like architecture, HCTransformer exploits domain-invariant and\naction-correlated contexts by a context encoder, and further models\ndomain-invariant interaction between humans and action-correlated contexts. We\nconduct extensive experiments on three benchmarks, namely UCF-HMDB,\nKinetics-NecDrone and EPIC-Kitchens-UDA, and the state-of-the-art performance\ndemonstrates the effectiveness of our proposed HCTransformer.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}