{"id":"2408.04575","title":"SCENE: Evaluating Explainable AI Techniques Using Soft Counterfactuals","authors":"Haoran Zheng, Utku Pamuksuz","authorsParsed":[["Zheng","Haoran",""],["Pamuksuz","Utku",""]],"versions":[{"version":"v1","created":"Thu, 8 Aug 2024 16:36:24 GMT"},{"version":"v2","created":"Fri, 16 Aug 2024 06:01:15 GMT"}],"updateDate":"2024-08-19","timestamp":1723134984000,"abstract":"  Explainable Artificial Intelligence (XAI) plays a crucial role in enhancing\nthe transparency and accountability of AI models, particularly in natural\nlanguage processing (NLP) tasks. However, popular XAI methods such as LIME and\nSHAP have been found to be unstable and potentially misleading, underscoring\nthe need for a standardized evaluation approach. This paper introduces SCENE\n(Soft Counterfactual Evaluation for Natural language Explainability), a novel\nevaluation method that leverages large language models (LLMs) to generate Soft\nCounterfactual explanations in a zero-shot manner. By focusing on token-based\nsubstitutions, SCENE creates contextually appropriate and semantically\nmeaningful Soft Counterfactuals without extensive fine-tuning. SCENE adopts\nValiditysoft and Csoft metrics to assess the effectiveness of model-agnostic\nXAI methods in text classification tasks. Applied to CNN, RNN, and Transformer\narchitectures, SCENE provides valuable insights into the strengths and\nlimitations of various XAI techniques.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"hCbQRJ0S-Wmiuh1zcOzFGUfRBc-UUdNs7YUtrj6PaYI","pdfSize":"582576"}
