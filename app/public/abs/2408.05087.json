{"id":"2408.05087","title":"Bootstrap Latents of Nodes and Neighbors for Graph Self-Supervised\n  Learning","authors":"Yunhui Liu, Huaisong Zhang, Tieke He, Tao Zheng, Jianhua Zhao","authorsParsed":[["Liu","Yunhui",""],["Zhang","Huaisong",""],["He","Tieke",""],["Zheng","Tao",""],["Zhao","Jianhua",""]],"versions":[{"version":"v1","created":"Fri, 9 Aug 2024 14:17:52 GMT"}],"updateDate":"2024-08-12","timestamp":1723213072000,"abstract":"  Contrastive learning is a significant paradigm in graph self-supervised\nlearning. However, it requires negative samples to prevent model collapse and\nlearn discriminative representations. These negative samples inevitably lead to\nheavy computation, memory overhead and class collision, compromising the\nrepresentation learning. Recent studies present that methods obviating negative\nsamples can attain competitive performance and scalability enhancements,\nexemplified by bootstrapped graph latents (BGRL). However, BGRL neglects the\ninherent graph homophily, which provides valuable insights into underlying\npositive pairs. Our motivation arises from the observation that subtly\nintroducing a few ground-truth positive pairs significantly improves BGRL.\nAlthough we can't obtain ground-truth positive pairs without labels under the\nself-supervised setting, edges in the graph can reflect noisy positive pairs,\ni.e., neighboring nodes often share the same label. Therefore, we propose to\nexpand the positive pair set with node-neighbor pairs. Subsequently, we\nintroduce a cross-attention module to predict the supportiveness score of a\nneighbor with respect to the anchor node. This score quantifies the positive\nsupport from each neighboring node, and is encoded into the training objective.\nConsequently, our method mitigates class collision from negative and noisy\npositive samples, concurrently enhancing intra-class compactness. Extensive\nexperiments are conducted on five benchmark datasets and three downstream task\nnode classification, node clustering, and node similarity search. The results\ndemonstrate that our method generates node representations with enhanced\nintra-class compactness and achieves state-of-the-art performance.\n","subjects":["Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}