{"id":"2408.15582","title":"Spectral Masking with Explicit Time-Context Windowing for Neural\n  Network-Based Monaural Speech Enhancement","authors":"Luan Vin\\'icius Fiorio, Boris Karanov, Bruno Defraene, Johan David,\n  Wim van Houtum, Frans Widdershoven, Ronald M. Aarts","authorsParsed":[["Fiorio","Luan Vin√≠cius",""],["Karanov","Boris",""],["Defraene","Bruno",""],["David","Johan",""],["van Houtum","Wim",""],["Widdershoven","Frans",""],["Aarts","Ronald M.",""]],"versions":[{"version":"v1","created":"Wed, 28 Aug 2024 07:08:09 GMT"}],"updateDate":"2024-08-29","timestamp":1724828889000,"abstract":"  We propose and analyze the use of an explicit time-context window for neural\nnetwork-based spectral masking speech enhancement to leverage signal context\ndependencies between neighboring frames. In particular, we concentrate on soft\nmasking and loss computed on the time-frequency representation of the\nreconstructed speech. We show that the application of a time-context windowing\nfunction at both input and output of the neural network model improves the soft\nmask estimation process by combining multiple estimates taken from different\ncontexts. The proposed approach is only applied as post-optimization in\ninference mode, not requiring additional layers or special training for the\nneural network model. Our results show that the method consistently increases\nboth intelligibility and signal quality of the denoised speech, as demonstrated\nfor two classes of convolutional-based speech enhancement models. Importantly,\nthe proposed method requires only a negligible ($\\leq1\\%$) increase in the\nnumber of model parameters, making it suitable for hardware-constrained\napplications.\n","subjects":["Electrical Engineering and Systems Science/Audio and Speech Processing","Computing Research Repository/Sound"],"license":"http://creativecommons.org/licenses/by/4.0/"}