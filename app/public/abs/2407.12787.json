{"id":"2407.12787","title":"GameVibe: A Multimodal Affective Game Corpus","authors":"Matthew Barthet, Maria Kaselimi, Kosmas Pinitas, Konstantinos\n  Makantasis, Antonios Liapis, Georgios N. Yannakakis","authorsParsed":[["Barthet","Matthew",""],["Kaselimi","Maria",""],["Pinitas","Kosmas",""],["Makantasis","Konstantinos",""],["Liapis","Antonios",""],["Yannakakis","Georgios N.",""]],"versions":[{"version":"v1","created":"Mon, 17 Jun 2024 10:52:52 GMT"}],"updateDate":"2024-07-19","timestamp":1718621572000,"abstract":"  As online video and streaming platforms continue to grow, affective computing\nresearch has undergone a shift towards more complex studies involving multiple\nmodalities. However, there is still a lack of readily available datasets with\nhigh-quality audiovisual stimuli. In this paper, we present GameVibe, a novel\naffect corpus which consists of multimodal audiovisual stimuli, including\nin-game behavioural observations and third-person affect labels for viewer\nengagement. The corpus consists of videos from a diverse set of publicly\navailable gameplay sessions across 30 games, with particular attention to\nensure high-quality stimuli with good audiovisual and gameplay diversity.\nFurthermore, we present an analysis on the reliability of the annotators in\nterms of inter-annotator agreement.\n","subjects":["Computing Research Repository/Human-Computer Interaction","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}