{"id":"2407.10403","title":"Cooperative Reward Shaping for Multi-Agent Pathfinding","authors":"Zhenyu Song, Ronghao Zheng, Senlin Zhang, Meiqin Liu","authorsParsed":[["Song","Zhenyu",""],["Zheng","Ronghao",""],["Zhang","Senlin",""],["Liu","Meiqin",""]],"versions":[{"version":"v1","created":"Mon, 15 Jul 2024 02:44:41 GMT"}],"updateDate":"2024-07-18","timestamp":1721011481000,"abstract":"  The primary objective of Multi-Agent Pathfinding (MAPF) is to plan efficient\nand conflict-free paths for all agents. Traditional multi-agent path planning\nalgorithms struggle to achieve efficient distributed path planning for multiple\nagents. In contrast, Multi-Agent Reinforcement Learning (MARL) has been\ndemonstrated as an effective approach to achieve this objective. By modeling\nthe MAPF problem as a MARL problem, agents can achieve efficient path planning\nand collision avoidance through distributed strategies under partial\nobservation. However, MARL strategies often lack cooperation among agents due\nto the absence of global information, which subsequently leads to reduced MAPF\nefficiency. To address this challenge, this letter introduces a unique reward\nshaping technique based on Independent Q-Learning (IQL). The aim of this method\nis to evaluate the influence of one agent on its neighbors and integrate such\nan interaction into the reward function, leading to active cooperation among\nagents. This reward shaping method facilitates cooperation among agents while\noperating in a distributed manner. The proposed approach has been evaluated\nthrough experiments across various scenarios with different scales and agent\ncounts. The results are compared with those from other state-of-the-art (SOTA)\nplanners. The evidence suggests that the approach proposed in this letter\nparallels other planners in numerous aspects, and outperforms them in scenarios\nfeaturing a large number of agents.\n","subjects":["Computing Research Repository/Artificial Intelligence","Computing Research Repository/Robotics"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}