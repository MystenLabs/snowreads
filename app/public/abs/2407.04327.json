{"id":"2407.04327","title":"TF-SASM: Training-free Spatial-aware Sparse Memory for Multi-object\n  Tracking","authors":"Thuc Nguyen-Quang and Minh-Triet Tran","authorsParsed":[["Nguyen-Quang","Thuc",""],["Tran","Minh-Triet",""]],"versions":[{"version":"v1","created":"Fri, 5 Jul 2024 07:55:19 GMT"},{"version":"v2","created":"Mon, 15 Jul 2024 08:13:39 GMT"}],"updateDate":"2024-07-16","timestamp":1720166119000,"abstract":"  Multi-object tracking (MOT) in computer vision remains a significant\nchallenge, requiring precise localization and continuous tracking of multiple\nobjects in video sequences. The emergence of data sets that emphasize robust\nreidentification, such as DanceTrack, has highlighted the need for effective\nsolutions. While memory-based approaches have shown promise, they often suffer\nfrom high computational complexity and memory usage due to storing feature at\nevery single frame. In this paper, we propose a novel memory-based approach\nthat selectively stores critical features based on object motion and\noverlapping awareness, aiming to enhance efficiency while minimizing\nredundancy. As a result, our method not only store longer temporal information\nwith limited number of stored features in the memory, but also diversify states\nof a particular object to enhance the association performance. Our approach\nsignificantly improves over MOTRv2 in the DanceTrack test set, demonstrating a\ngain of 2.0% AssA score and 2.1% in IDF1 score.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"uk_Ag4H5ovFZxs6eyhcnEnDgvhbfggThNlcrkYy2S2E","pdfSize":"1081718"}
