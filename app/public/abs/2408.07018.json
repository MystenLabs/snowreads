{"id":"2408.07018","title":"Efficient Human-Object-Interaction (EHOI) Detection via Interaction\n  Label Coding and Conditional Decision","authors":"Tsung-Shan Yang, Yun-Cheng Wang, Chengwei Wei, Suya You, C.-C. Jay Kuo","authorsParsed":[["Yang","Tsung-Shan",""],["Wang","Yun-Cheng",""],["Wei","Chengwei",""],["You","Suya",""],["Kuo","C. -C. Jay",""]],"versions":[{"version":"v1","created":"Tue, 13 Aug 2024 16:34:06 GMT"}],"updateDate":"2024-08-14","timestamp":1723566846000,"abstract":"  Human-Object Interaction (HOI) detection is a fundamental task in image\nunderstanding. While deep-learning-based HOI methods provide high performance\nin terms of mean Average Precision (mAP), they are computationally expensive\nand opaque in training and inference processes. An Efficient HOI (EHOI)\ndetector is proposed in this work to strike a good balance between detection\nperformance, inference complexity, and mathematical transparency. EHOI is a\ntwo-stage method. In the first stage, it leverages a frozen object detector to\nlocalize the objects and extract various features as intermediate outputs. In\nthe second stage, the first-stage outputs predict the interaction type using\nthe XGBoost classifier. Our contributions include the application of error\ncorrection codes (ECCs) to encode rare interaction cases, which reduces the\nmodel size and the complexity of the XGBoost classifier in the second stage.\nAdditionally, we provide a mathematical formulation of the relabeling and\ndecision-making process. Apart from the architecture, we present qualitative\nresults to explain the functionalities of the feedforward modules. Experimental\nresults demonstrate the advantages of ECC-coded interaction labels and the\nexcellent balance of detection performance and complexity of the proposed EHOI\nmethod.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"yJD0_KtNnoQwCoT_FOuPKjacso42g3wHXPaVYGOXJO4","pdfSize":"2834798"}
