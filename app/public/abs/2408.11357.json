{"id":"2408.11357","title":"HumanCoser: Layered 3D Human Generation via Semantic-Aware Diffusion\n  Model","authors":"Yi Wang, Jian Ma, Ruizhi Shao, Qiao Feng, Yu-kun Lai, Kun Li","authorsParsed":[["Wang","Yi",""],["Ma","Jian",""],["Shao","Ruizhi",""],["Feng","Qiao",""],["Lai","Yu-kun",""],["Li","Kun",""]],"versions":[{"version":"v1","created":"Wed, 21 Aug 2024 06:00:11 GMT"}],"updateDate":"2024-08-22","timestamp":1724220011000,"abstract":"  This paper aims to generate physically-layered 3D humans from text prompts.\nExisting methods either generate 3D clothed humans as a whole or support only\ntight and simple clothing generation, which limits their applications to\nvirtual try-on and part-level editing. To achieve physically-layered 3D human\ngeneration with reusable and complex clothing, we propose a novel layer-wise\ndressed human representation based on a physically-decoupled diffusion model.\nSpecifically, to achieve layer-wise clothing generation, we propose a\ndual-representation decoupling framework for generating clothing decoupled from\nthe human body, in conjunction with an innovative multi-layer fusion volume\nrendering method. To match the clothing with different body shapes, we propose\nan SMPL-driven implicit field deformation network that enables the free\ntransfer and reuse of clothing. Extensive experiments demonstrate that our\napproach not only achieves state-of-the-art layered 3D human generation with\ncomplex clothing but also supports virtual try-on and layered human animation.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}