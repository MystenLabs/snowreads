{"id":"2407.10446","title":"DDFAD: Dataset Distillation Framework for Audio Data","authors":"Wenbo Jiang and Rui Zhang and Hongwei Li and Xiaoyuan Liu and Haomiao\n  Yang and Shui Yu","authorsParsed":[["Jiang","Wenbo",""],["Zhang","Rui",""],["Li","Hongwei",""],["Liu","Xiaoyuan",""],["Yang","Haomiao",""],["Yu","Shui",""]],"versions":[{"version":"v1","created":"Mon, 15 Jul 2024 05:23:35 GMT"}],"updateDate":"2024-07-23","timestamp":1721021015000,"abstract":"  Deep neural networks (DNNs) have achieved significant success in numerous\napplications. The remarkable performance of DNNs is largely attributed to the\navailability of massive, high-quality training datasets. However, processing\nsuch massive training data requires huge computational and storage resources.\nDataset distillation is a promising solution to this problem, offering the\ncapability to compress a large dataset into a smaller distilled dataset. The\nmodel trained on the distilled dataset can achieve comparable performance to\nthe model trained on the whole dataset.\n  While dataset distillation has been demonstrated in image data, none have\nexplored dataset distillation for audio data. In this work, for the first time,\nwe propose a Dataset Distillation Framework for Audio Data (DDFAD).\nSpecifically, we first propose the Fused Differential MFCC (FD-MFCC) as\nextracted features for audio data. After that, the FD-MFCC is distilled through\nthe matching training trajectory distillation method. Finally, we propose an\naudio signal reconstruction algorithm based on the Griffin-Lim Algorithm to\nreconstruct the audio signal from the distilled FD-MFCC. Extensive experiments\ndemonstrate the effectiveness of DDFAD on various audio datasets. In addition,\nwe show that DDFAD has promising application prospects in many applications,\nsuch as continual learning and neural architecture search.\n","subjects":["Computing Research Repository/Sound","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Databases","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}