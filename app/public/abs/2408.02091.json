{"id":"2408.02091","title":"Past Movements-Guided Motion Representation Learning for Human Motion\n  Prediction","authors":"Junyu Shi and Baoxuan Wang","authorsParsed":[["Shi","Junyu",""],["Wang","Baoxuan",""]],"versions":[{"version":"v1","created":"Sun, 4 Aug 2024 17:00:37 GMT"}],"updateDate":"2024-08-06","timestamp":1722790837000,"abstract":"  Human motion prediction based on 3D skeleton is a significant challenge in\ncomputer vision, primarily focusing on the effective representation of motion.\nIn this paper, we propose a self-supervised learning framework designed to\nenhance motion representation. This framework consists of two stages: first,\nthe network is pretrained through the self-reconstruction of past sequences,\nand the guided reconstruction of future sequences based on past movements. We\ndesign a velocity-based mask strategy to focus on the joints with large-scale\nmoving. Subsequently, the pretrained network undergoes finetuning for specific\ntasks. Self-reconstruction, guided by patterns of past motion, substantially\nimproves the model's ability to represent the spatiotemporal relationships\namong joints but also captures the latent relationships between past and future\nsequences. This capability is crucial for motion prediction tasks that solely\ndepend on historical motion data. By employing this straightforward yet\neffective training paradigm, our method outperforms existing\n\\textit{state-of-the-art} methods, reducing the average prediction errors by\n8.8\\% across Human3.6M, 3DPW, and AMASS datasets. The code is available at\nhttps://github.com/JunyuShi02/PMG-MRL.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"rl6edufHgbSzXC-xbo5NALG_icfPGqZq1u_YbHyIGbY","pdfSize":"1187662"}
