{"id":"2408.11878","title":"Open-FinLLMs: Open Multimodal Large Language Models for Financial\n  Applications","authors":"Qianqian Xie and Dong Li and Mengxi Xiao and Zihao Jiang and Ruoyu\n  Xiang and Xiao Zhang and Zhengyu Chen and Yueru He and Weiguang Han and Yuzhe\n  Yang and Shunian Chen and Yifei Zhang and Lihang Shen and Daniel Kim and\n  Zhiwei Liu and Zheheng Luo and Yangyang Yu and Yupeng Cao and Zhiyang Deng\n  and Zhiyuan Yao and Haohang Li and Duanyu Feng and Yongfu Dai and VijayaSai\n  Somasundaram and Peng Lu and Yilun Zhao and Yitao Long and Guojun Xiong and\n  Kaleb Smith and Honghai Yu and Yanzhao Lai and Min Peng and Jianyun Nie and\n  Jordan W. Suchow and Xiao-Yang Liu and Benyou Wang and Alejandro Lopez-Lira\n  and Jimin Huang and Sophia Ananiadou","authorsParsed":[["Xie","Qianqian",""],["Li","Dong",""],["Xiao","Mengxi",""],["Jiang","Zihao",""],["Xiang","Ruoyu",""],["Zhang","Xiao",""],["Chen","Zhengyu",""],["He","Yueru",""],["Han","Weiguang",""],["Yang","Yuzhe",""],["Chen","Shunian",""],["Zhang","Yifei",""],["Shen","Lihang",""],["Kim","Daniel",""],["Liu","Zhiwei",""],["Luo","Zheheng",""],["Yu","Yangyang",""],["Cao","Yupeng",""],["Deng","Zhiyang",""],["Yao","Zhiyuan",""],["Li","Haohang",""],["Feng","Duanyu",""],["Dai","Yongfu",""],["Somasundaram","VijayaSai",""],["Lu","Peng",""],["Zhao","Yilun",""],["Long","Yitao",""],["Xiong","Guojun",""],["Smith","Kaleb",""],["Yu","Honghai",""],["Lai","Yanzhao",""],["Peng","Min",""],["Nie","Jianyun",""],["Suchow","Jordan W.",""],["Liu","Xiao-Yang",""],["Wang","Benyou",""],["Lopez-Lira","Alejandro",""],["Huang","Jimin",""],["Ananiadou","Sophia",""]],"versions":[{"version":"v1","created":"Tue, 20 Aug 2024 16:15:28 GMT"}],"updateDate":"2024-08-23","timestamp":1724170528000,"abstract":"  Large language models (LLMs) have advanced financial applications, yet they\noften lack sufficient financial knowledge and struggle with tasks involving\nmulti-modal inputs like tables and time series data. To address these\nlimitations, we introduce \\textit{Open-FinLLMs}, a series of Financial LLMs. We\nbegin with FinLLaMA, pre-trained on a 52 billion token financial corpus,\nincorporating text, tables, and time-series data to embed comprehensive\nfinancial knowledge. FinLLaMA is then instruction fine-tuned with 573K\nfinancial instructions, resulting in FinLLaMA-instruct, which enhances task\nperformance. Finally, we present FinLLaVA, a multimodal LLM trained with 1.43M\nimage-text instructions to handle complex financial data types. Extensive\nevaluations demonstrate FinLLaMA's superior performance over LLaMA3-8B,\nLLaMA3.1-8B, and BloombergGPT in both zero-shot and few-shot settings across 19\nand 4 datasets, respectively. FinLLaMA-instruct outperforms GPT-4 and other\nFinancial LLMs on 15 datasets. FinLLaVA excels in understanding tables and\ncharts across 4 multimodal tasks. Additionally, FinLLaMA achieves impressive\nSharpe Ratios in trading simulations, highlighting its robust financial\napplication capabilities. We will continually maintain and improve our models\nand benchmarks to support ongoing innovation in academia and industry.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Computational Engineering, Finance, and Science","Quantitative Finance/Computational Finance"],"license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","blobId":"6BWH2s8lXi3h2b7htB6nUMvvj3tuF_f8e-JDlFDq33E","pdfSize":"4126452"}
