{"id":"2407.17792","title":"Harnessing Temporal Causality for Advanced Temporal Action Detection","authors":"Shuming Liu, Lin Sui, Chen-Lin Zhang, Fangzhou Mu, Chen Zhao, Bernard\n  Ghanem","authorsParsed":[["Liu","Shuming",""],["Sui","Lin",""],["Zhang","Chen-Lin",""],["Mu","Fangzhou",""],["Zhao","Chen",""],["Ghanem","Bernard",""]],"versions":[{"version":"v1","created":"Thu, 25 Jul 2024 06:03:02 GMT"},{"version":"v2","created":"Fri, 26 Jul 2024 01:16:07 GMT"}],"updateDate":"2024-07-29","timestamp":1721887382000,"abstract":"  As a fundamental task in long-form video understanding, temporal action\ndetection (TAD) aims to capture inherent temporal relations in untrimmed videos\nand identify candidate actions with precise boundaries. Over the years, various\nnetworks, including convolutions, graphs, and transformers, have been explored\nfor effective temporal modeling for TAD. However, these modules typically treat\npast and future information equally, overlooking the crucial fact that changes\nin action boundaries are essentially causal events. Inspired by this insight,\nwe propose leveraging the temporal causality of actions to enhance TAD\nrepresentation by restricting the model's access to only past or future\ncontext. We introduce CausalTAD, which combines causal attention and causal\nMamba to achieve state-of-the-art performance on multiple benchmarks. Notably,\nwith CausalTAD, we ranked 1st in the Action Recognition, Action Detection, and\nAudio-Based Interaction Detection tracks at the EPIC-Kitchens Challenge 2024,\nas well as 1st in the Moment Queries track at the Ego4D Challenge 2024. Our\ncode is available at https://github.com/sming256/OpenTAD/.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}