{"id":"2407.20256","title":"Making LLMs Work for Enterprise Data Tasks","authors":"\\c{C}a\\u{g}atay Demiralp and Fabian Wenz and Peter Baile Chen and Moe\n  Kayali and Nesime Tatbul and Michael Stonebraker","authorsParsed":[["Demiralp","Çağatay",""],["Wenz","Fabian",""],["Chen","Peter Baile",""],["Kayali","Moe",""],["Tatbul","Nesime",""],["Stonebraker","Michael",""]],"versions":[{"version":"v1","created":"Mon, 22 Jul 2024 21:16:59 GMT"}],"updateDate":"2024-07-31","timestamp":1721683019000,"abstract":"  Large language models (LLMs) know little about enterprise database tables in\nthe private data ecosystem, which substantially differ from web text in\nstructure and content. As LLMs' performance is tied to their training data, a\ncrucial question is how useful they can be in improving enterprise database\nmanagement and analysis tasks. To address this, we contribute experimental\nresults on LLMs' performance for text-to-SQL and semantic column-type detection\ntasks on enterprise datasets. The performance of LLMs on enterprise data is\nsignificantly lower than on benchmark datasets commonly used. Informed by our\nfindings and feedback from industry practitioners, we identify three\nfundamental challenges -- latency, cost, and quality -- and propose potential\nsolutions to use LLMs in enterprise data workflows effectively.\n","subjects":["Computing Research Repository/Databases","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}