{"id":"2407.07487","title":"Review-LLM: Harnessing Large Language Models for Personalized Review\n  Generation","authors":"Qiyao Peng, Hongtao Liu, Hongyan Xu, Qing Yang, Minglai Shao, Wenjun\n  Wang","authorsParsed":[["Peng","Qiyao",""],["Liu","Hongtao",""],["Xu","Hongyan",""],["Yang","Qing",""],["Shao","Minglai",""],["Wang","Wenjun",""]],"versions":[{"version":"v1","created":"Wed, 10 Jul 2024 09:22:19 GMT"}],"updateDate":"2024-07-11","timestamp":1720603339000,"abstract":"  Product review generation is an important task in recommender systems, which\ncould provide explanation and persuasiveness for the recommendation. Recently,\nLarge Language Models (LLMs, e.g., ChatGPT) have shown superior text modeling\nand generating ability, which could be applied in review generation. However,\ndirectly applying the LLMs for generating reviews might be troubled by the\n``polite'' phenomenon of the LLMs and could not generate personalized reviews\n(e.g., negative reviews). In this paper, we propose Review-LLM that customizes\nLLMs for personalized review generation. Firstly, we construct the prompt input\nby aggregating user historical behaviors, which include corresponding item\ntitles and reviews. This enables the LLMs to capture user interest features and\nreview writing style. Secondly, we incorporate ratings as indicators of\nsatisfaction into the prompt, which could further improve the model's\nunderstanding of user preferences and the sentiment tendency control of\ngenerated reviews. Finally, we feed the prompt text into LLMs, and use\nSupervised Fine-Tuning (SFT) to make the model generate personalized reviews\nfor the given user and target item. Experimental results on the real-world\ndataset show that our fine-tuned model could achieve better review generation\nperformance than existing close-source LLMs.\n","subjects":["Computing Research Repository/Computation and Language"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}