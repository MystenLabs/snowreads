{"id":"2408.00273","title":"3D U-KAN Implementation for Multi-modal MRI Brain Tumor Segmentation","authors":"Tianze Tang, Yanbing Chen, Hai Shu","authorsParsed":[["Tang","Tianze",""],["Chen","Yanbing",""],["Shu","Hai",""]],"versions":[{"version":"v1","created":"Thu, 1 Aug 2024 04:27:10 GMT"}],"updateDate":"2024-08-02","timestamp":1722486430000,"abstract":"  We explore the application of U-KAN, a U-Net based network enhanced with\nKolmogorov-Arnold Network (KAN) layers, for 3D brain tumor segmentation using\nmulti-modal MRI data. We adapt the original 2D U-KAN model to the 3D task, and\nintroduce a variant called UKAN-SE, which incorporates Squeeze-and-Excitation\nmodules for global attention. We compare the performance of U-KAN and UKAN-SE\nagainst existing methods such as U-Net, Attention U-Net, and Swin UNETR, using\nthe BraTS 2024 dataset. Our results show that U-KAN and UKAN-SE, with\napproximately 10.6 million parameters, achieve exceptional efficiency,\nrequiring only about 1/4 of the training time of U-Net and Attention U-Net, and\n1/6 that of Swin UNETR, while surpassing these models across most evaluation\nmetrics. Notably, UKAN-SE slightly outperforms U-KAN.\n","subjects":["Electrical Engineering and Systems Science/Image and Video Processing","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}