{"id":"2407.02543","title":"Towards the Next Frontier in Speech Representation Learning Using\n  Disentanglement","authors":"Varun Krishna and Sriram Ganapathy","authorsParsed":[["Krishna","Varun",""],["Ganapathy","Sriram",""]],"versions":[{"version":"v1","created":"Tue, 2 Jul 2024 07:13:35 GMT"}],"updateDate":"2024-07-04","timestamp":1719904415000,"abstract":"  The popular frameworks for self-supervised learning of speech representations\nhave largely focused on frame-level masked prediction of speech regions. While\nthis has shown promising downstream task performance for speech recognition and\nrelated tasks, this has largely ignored factors of speech that are encoded at\ncoarser level, like characteristics of the speaker or channel that remain\nconsistent through-out a speech utterance. In this work, we propose a framework\nfor Learning Disentangled Self Supervised (termed as Learn2Diss)\nrepresentations of speech, which consists of frame-level and an utterance-level\nencoder modules. The two encoders are initially learned independently, where\nthe frame-level model is largely inspired by existing self supervision\ntechniques, thereby learning pseudo-phonemic representations, while the\nutterance-level encoder is inspired by constrastive learning of pooled\nembeddings, thereby learning pseudo-speaker representations. The joint learning\nof these two modules consists of disentangling the two encoders using a mutual\ninformation based criterion. With several downstream evaluation experiments, we\nshow that the proposed Learn2Diss achieves state-of-the-art results on a\nvariety of tasks, with the frame-level encoder representations improving\nsemantic tasks, while the utterance-level representations improve non-semantic\ntasks.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning","Computing Research Repository/Sound","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by/4.0/"}