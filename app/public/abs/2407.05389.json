{"id":"2407.05389","title":"Image-Conditional Diffusion Transformer for Underwater Image Enhancement","authors":"Xingyang Nie, Su Pan, Xiaoyu Zhai, Shifei Tao, Fengzhong Qu, Biao\n  Wang, Huilin Ge, and Guojie Xiao","authorsParsed":[["Nie","Xingyang",""],["Pan","Su",""],["Zhai","Xiaoyu",""],["Tao","Shifei",""],["Qu","Fengzhong",""],["Wang","Biao",""],["Ge","Huilin",""],["Xiao","Guojie",""]],"versions":[{"version":"v1","created":"Sun, 7 Jul 2024 14:34:31 GMT"}],"updateDate":"2024-07-09","timestamp":1720362871000,"abstract":"  Underwater image enhancement (UIE) has attracted much attention owing to its\nimportance for underwater operation and marine engineering. Motivated by the\nrecent advance in generative models, we propose a novel UIE method based on\nimage-conditional diffusion transformer (ICDT). Our method takes the degraded\nunderwater image as the conditional input and converts it into latent space\nwhere ICDT is applied. ICDT replaces the conventional U-Net backbone in a\ndenoising diffusion probabilistic model (DDPM) with a transformer, and thus\ninherits favorable properties such as scalability from transformers.\nFurthermore, we train ICDT with a hybrid loss function involving variances to\nachieve better log-likelihoods, which meanwhile significantly accelerates the\nsampling process. We experimentally assess the scalability of ICDTs and compare\nwith prior works in UIE on the Underwater ImageNet dataset. Besides good\nscaling properties, our largest model, ICDT-XL/2, outperforms all comparison\nmethods, achieving state-of-the-art (SOTA) quality of image enhancement.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}