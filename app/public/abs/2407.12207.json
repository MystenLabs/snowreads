{"id":"2407.12207","title":"NeuSurfEmb: A Complete Pipeline for Dense Correspondence-based 6D Object\n  Pose Estimation without CAD Models","authors":"Francesco Milano, Jen Jen Chung, Hermann Blum, Roland Siegwart, Lionel\n  Ott","authorsParsed":[["Milano","Francesco",""],["Chung","Jen Jen",""],["Blum","Hermann",""],["Siegwart","Roland",""],["Ott","Lionel",""]],"versions":[{"version":"v1","created":"Tue, 16 Jul 2024 22:48:22 GMT"}],"updateDate":"2024-07-18","timestamp":1721170102000,"abstract":"  State-of-the-art approaches for 6D object pose estimation assume the\navailability of CAD models and require the user to manually set up\nphysically-based rendering (PBR) pipelines for synthetic training data\ngeneration. Both factors limit the application of these methods in real-world\nscenarios. In this work, we present a pipeline that does not require CAD models\nand allows training a state-of-the-art pose estimator requiring only a small\nset of real images as input. Our method is based on a NeuS2 object\nrepresentation, that we learn through a semi-automated procedure based on\nStructure-from-Motion (SfM) and object-agnostic segmentation. We exploit the\nnovel-view synthesis ability of NeuS2 and simple cut-and-paste augmentation to\nautomatically generate photorealistic object renderings, which we use to train\nthe correspondence-based SurfEmb pose estimator. We evaluate our method on the\nLINEMOD-Occlusion dataset, extensively studying the impact of its individual\ncomponents and showing competitive performance with respect to approaches based\non CAD models and PBR data. We additionally demonstrate the ease of use and\neffectiveness of our pipeline on self-collected real-world objects, showing\nthat our method outperforms state-of-the-art CAD-model-free approaches, with\nbetter accuracy and robustness to mild occlusions. To allow the robotics\ncommunity to benefit from this system, we will publicly release it at\nhttps://www.github.com/ethz-asl/neusurfemb.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Computing Research Repository/Robotics"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}