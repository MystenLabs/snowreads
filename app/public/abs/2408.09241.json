{"id":"2408.09241","title":"Re-boosting Self-Collaboration Parallel Prompt GAN for Unsupervised\n  Image Restoration","authors":"Xin Lin, Yuyan Zhou, Jingtong Yue, Chao Ren, Kelvin C.K. Chan, Lu Qi,\n  Ming-Hsuan Yang","authorsParsed":[["Lin","Xin",""],["Zhou","Yuyan",""],["Yue","Jingtong",""],["Ren","Chao",""],["Chan","Kelvin C. K.",""],["Qi","Lu",""],["Yang","Ming-Hsuan",""]],"versions":[{"version":"v1","created":"Sat, 17 Aug 2024 16:26:59 GMT"}],"updateDate":"2024-08-20","timestamp":1723912019000,"abstract":"  Unsupervised restoration approaches based on generative adversarial networks\n(GANs) offer a promising solution without requiring paired datasets. Yet, these\nGAN-based approaches struggle to surpass the performance of conventional\nunsupervised GAN-based frameworks without significantly modifying model\nstructures or increasing the computational complexity. To address these issues,\nwe propose a self-collaboration (SC) strategy for existing restoration models.\nThis strategy utilizes information from the previous stage as feedback to guide\nsubsequent stages, achieving significant performance improvement without\nincreasing the framework's inference complexity. The SC strategy comprises a\nprompt learning (PL) module and a restorer ($Res$). It iteratively replaces the\nprevious less powerful fixed restorer $\\overline{Res}$ in the PL module with a\nmore powerful $Res$. The enhanced PL module generates better\npseudo-degraded/clean image pairs, leading to a more powerful $Res$ for the\nnext iteration. Our SC can significantly improve the $Res$'s performance by\nover 1.5 dB without adding extra parameters or computational complexity during\ninference. Meanwhile, existing self-ensemble (SE) and our SC strategies enhance\nthe performance of pre-trained restorers from different perspectives. As SE\nincreases computational complexity during inference, we propose a re-boosting\nmodule to the SC (Reb-SC) to improve the SC strategy further by incorporating\nSE into SC without increasing inference time. This approach further enhances\nthe restorer's performance by approximately 0.3 dB. Extensive experimental\nresults on restoration tasks demonstrate that the proposed model performs\nfavorably against existing state-of-the-art unsupervised restoration methods.\nSource code and trained models are publicly available at:\n\\url{https://github.com/linxin0/RSCP2GAN}.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition","Electrical Engineering and Systems Science/Image and Video Processing"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}