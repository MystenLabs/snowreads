{"id":"2407.15861","title":"Adversarial Attacks and Defenses on Text-to-Image Diffusion Models: A\n  Survey","authors":"Chenyu Zhang, Mingwang Hu, Wenhui Li and Lanjun Wang","authorsParsed":[["Zhang","Chenyu",""],["Hu","Mingwang",""],["Li","Wenhui",""],["Wang","Lanjun",""]],"versions":[{"version":"v1","created":"Wed, 10 Jul 2024 13:50:31 GMT"},{"version":"v2","created":"Fri, 13 Sep 2024 04:11:30 GMT"}],"updateDate":"2024-09-16","timestamp":1720619431000,"abstract":"  Recently, the text-to-image diffusion model has gained considerable attention\nfrom the community due to its exceptional image generation capability. A\nrepresentative model, Stable Diffusion, amassed more than 10 million users\nwithin just two months of its release. This surge in popularity has facilitated\nstudies on the robustness and safety of the model, leading to the proposal of\nvarious adversarial attack methods. Simultaneously, there has been a marked\nincrease in research focused on defense methods to improve the robustness and\nsafety of these models. In this survey, we provide a comprehensive review of\nthe literature on adversarial attacks and defenses targeting text-to-image\ndiffusion models. We begin with an overview of text-to-image diffusion models,\nfollowed by an introduction to a taxonomy of adversarial attacks and an\nin-depth review of existing attack methods. We then present a detailed analysis\nof current defense methods that improve model robustness and safety. Finally,\nwe discuss ongoing challenges and explore promising future research directions.\nFor a complete list of the adversarial attack and defense methods covered in\nthis survey, please refer to our curated repository at\nhttps://github.com/datar001/Awesome-AD-on-T2IDM.\n","subjects":["Computing Research Repository/Cryptography and Security","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}