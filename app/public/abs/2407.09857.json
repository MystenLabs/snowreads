{"id":"2407.09857","title":"IFTR: An Instance-Level Fusion Transformer for Visual Collaborative\n  Perception","authors":"Shaohong Wang, Lu Bin, Xinyu Xiao, Zhiyu Xiang, Hangguan Shan, Eryun\n  Liu","authorsParsed":[["Wang","Shaohong",""],["Bin","Lu",""],["Xiao","Xinyu",""],["Xiang","Zhiyu",""],["Shan","Hangguan",""],["Liu","Eryun",""]],"versions":[{"version":"v1","created":"Sat, 13 Jul 2024 11:38:15 GMT"}],"updateDate":"2024-07-16","timestamp":1720870695000,"abstract":"  Multi-agent collaborative perception has emerged as a widely recognized\ntechnology in the field of autonomous driving in recent years. However, current\ncollaborative perception predominantly relies on LiDAR point clouds, with\nsignificantly less attention given to methods using camera images. This\nseverely impedes the development of budget-constrained collaborative systems\nand the exploitation of the advantages offered by the camera modality. This\nwork proposes an instance-level fusion transformer for visual collaborative\nperception (IFTR), which enhances the detection performance of camera-only\ncollaborative perception systems through the communication and sharing of\nvisual features. To capture the visual information from multiple agents, we\ndesign an instance feature aggregation that interacts with the visual features\nof individual agents using predefined grid-shaped bird eye view (BEV) queries,\ngenerating more comprehensive and accurate BEV features. Additionally, we\ndevise a cross-domain query adaptation as a heuristic to fuse 2D priors,\nimplicitly encoding the candidate positions of targets. Furthermore, IFTR\noptimizes communication efficiency by sending instance-level features,\nachieving an optimal performance-bandwidth trade-off. We evaluate the proposed\nIFTR on a real dataset, DAIR-V2X, and two simulated datasets, OPV2V and V2XSet,\nachieving performance improvements of 57.96%, 9.23% and 12.99% in AP@70 metrics\ncompared to the previous SOTAs, respectively. Extensive experiments demonstrate\nthe superiority of IFTR and the effectiveness of its key components. The code\nis available at https://github.com/wangsh0111/IFTR.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}