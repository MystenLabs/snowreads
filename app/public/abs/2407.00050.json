{"id":"2407.00050","title":"FoldToken2: Learning compact, invariant and generative protein structure\n  language","authors":"Zhangyang Gao, Cheng Tan, Stan Z. Li","authorsParsed":[["Gao","Zhangyang",""],["Tan","Cheng",""],["Li","Stan Z.",""]],"versions":[{"version":"v1","created":"Tue, 11 Jun 2024 09:24:51 GMT"}],"updateDate":"2024-07-02","timestamp":1718097891000,"abstract":"  The equivalent nature of 3D coordinates has posed long term challenges in\nprotein structure representation learning, alignment, and generation. Can we\ncreate a compact and invariant language that equivalently represents protein\nstructures? Towards this goal, we propose FoldToken2 to transfer equivariant\nstructures into discrete tokens, while maintaining the recoverability of the\noriginal structures. From FoldToken1 to FoldToken2, we improve three key\ncomponents: (1) invariant structure encoder, (2) vector-quantized compressor,\nand (3) equivalent structure decoder. We evaluate FoldToken2 on the protein\nstructure reconstruction task and show that it outperforms previous FoldToken1\nby 20\\% in TMScore and 81\\% in RMSD. FoldToken2 probably be the first method\nthat works well on both single-chain and multi-chain protein structures\nquantization. We believe that FoldToken2 will inspire further improvement in\nprotein structure representation learning, structure alignment, and structure\ngeneration tasks.\n","subjects":["Quantitative Biology/Biomolecules","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Machine Learning"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}