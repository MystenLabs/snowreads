{"id":"2407.09437","title":"Let Me DeCode You: Decoder Conditioning with Tabular Data","authors":"Tomasz Szczepa\\'nski, Michal K. Grzeszczyk, Szymon P{\\l}otka, Arleta\n  Adamowicz, Piotr Fudalej, Przemys{\\l}aw Korzeniowski, Tomasz Trzci\\'nski and\n  Arkadiusz Sitek","authorsParsed":[["Szczepański","Tomasz",""],["Grzeszczyk","Michal K.",""],["Płotka","Szymon",""],["Adamowicz","Arleta",""],["Fudalej","Piotr",""],["Korzeniowski","Przemysław",""],["Trzciński","Tomasz",""],["Sitek","Arkadiusz",""]],"versions":[{"version":"v1","created":"Fri, 12 Jul 2024 17:14:33 GMT"}],"updateDate":"2024-07-15","timestamp":1720804473000,"abstract":"  Training deep neural networks for 3D segmentation tasks can be challenging,\noften requiring efficient and effective strategies to improve model\nperformance. In this study, we introduce a novel approach, DeCode, that\nutilizes label-derived features for model conditioning to support the decoder\nin the reconstruction process dynamically, aiming to enhance the efficiency of\nthe training process. DeCode focuses on improving 3D segmentation performance\nthrough the incorporation of conditioning embedding with learned numerical\nrepresentation of 3D-label shape features. Specifically, we develop an\napproach, where conditioning is applied during the training phase to guide the\nnetwork toward robust segmentation. When labels are not available during\ninference, our model infers the necessary conditioning embedding directly from\nthe input data, thanks to a feed-forward network learned during the training\nphase. This approach is tested using synthetic data and cone-beam computed\ntomography (CBCT) images of teeth. For CBCT, three datasets are used: one\npublicly available and two in-house. Our results show that DeCode significantly\noutperforms traditional, unconditioned models in terms of generalization to\nunseen data, achieving higher accuracy at a reduced computational cost. This\nwork represents the first of its kind to explore conditioning strategies in 3D\ndata segmentation, offering a novel and more efficient method for leveraging\nannotated data. Our code, pre-trained models are publicly available at\nhttps://github.com/SanoScience/DeCode .\n","subjects":["Electrical Engineering and Systems Science/Image and Video Processing","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}