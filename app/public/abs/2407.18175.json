{"id":"2407.18175","title":"Quasar-ViT: Hardware-Oriented Quantization-Aware Architecture Search for\n  Vision Transformers","authors":"Zhengang Li, Alec Lu, Yanyue Xie, Zhenglun Kong, Mengshu Sun, Hao\n  Tang, Zhong Jia Xue, Peiyan Dong, Caiwen Ding, Yanzhi Wang, Xue Lin, Zhenman\n  Fang","authorsParsed":[["Li","Zhengang",""],["Lu","Alec",""],["Xie","Yanyue",""],["Kong","Zhenglun",""],["Sun","Mengshu",""],["Tang","Hao",""],["Xue","Zhong Jia",""],["Dong","Peiyan",""],["Ding","Caiwen",""],["Wang","Yanzhi",""],["Lin","Xue",""],["Fang","Zhenman",""]],"versions":[{"version":"v1","created":"Thu, 25 Jul 2024 16:35:46 GMT"}],"updateDate":"2024-07-26","timestamp":1721925346000,"abstract":"  Vision transformers (ViTs) have demonstrated their superior accuracy for\ncomputer vision tasks compared to convolutional neural networks (CNNs).\nHowever, ViT models are often computation-intensive for efficient deployment on\nresource-limited edge devices. This work proposes Quasar-ViT, a\nhardware-oriented quantization-aware architecture search framework for ViTs, to\ndesign efficient ViT models for hardware implementation while preserving the\naccuracy. First, Quasar-ViT trains a supernet using our row-wise flexible\nmixed-precision quantization scheme, mixed-precision weight entanglement, and\nsupernet layer scaling techniques. Then, it applies an efficient\nhardware-oriented search algorithm, integrated with hardware latency and\nresource modeling, to determine a series of optimal subnets from supernet under\ndifferent inference latency targets. Finally, we propose a series of\nmodel-adaptive designs on the FPGA platform to support the architecture search\nand mitigate the gap between the theoretical computation reduction and the\npractical inference speedup. Our searched models achieve 101.5, 159.6, and\n251.6 frames-per-second (FPS) inference speed on the AMD/Xilinx ZCU102 FPGA\nwith 80.4%, 78.6%, and 74.9% top-1 accuracy, respectively, for the ImageNet\ndataset, consistently outperforming prior works.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}