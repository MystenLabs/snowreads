{"id":"2408.11697","title":"Robust 3D Gaussian Splatting for Novel View Synthesis in Presence of\n  Distractors","authors":"Paul Ungermann, Armin Ettenhofer, Matthias Nie{\\ss}ner, Barbara\n  Roessle","authorsParsed":[["Ungermann","Paul",""],["Ettenhofer","Armin",""],["Nie√üner","Matthias",""],["Roessle","Barbara",""]],"versions":[{"version":"v1","created":"Wed, 21 Aug 2024 15:21:27 GMT"}],"updateDate":"2024-08-22","timestamp":1724253687000,"abstract":"  3D Gaussian Splatting has shown impressive novel view synthesis results;\nnonetheless, it is vulnerable to dynamic objects polluting the input data of an\notherwise static scene, so called distractors. Distractors have severe impact\non the rendering quality as they get represented as view-dependent effects or\nresult in floating artifacts. Our goal is to identify and ignore such\ndistractors during the 3D Gaussian optimization to obtain a clean\nreconstruction. To this end, we take a self-supervised approach that looks at\nthe image residuals during the optimization to determine areas that have likely\nbeen falsified by a distractor. In addition, we leverage a pretrained\nsegmentation network to provide object awareness, enabling more accurate\nexclusion of distractors. This way, we obtain segmentation masks of distractors\nto effectively ignore them in the loss formulation. We demonstrate that our\napproach is robust to various distractors and strongly improves rendering\nquality on distractor-polluted scenes, improving PSNR by 1.86dB compared to 3D\nGaussian Splatting.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://creativecommons.org/licenses/by/4.0/"}