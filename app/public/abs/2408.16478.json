{"id":"2408.16478","title":"MICDrop: Masking Image and Depth Features via Complementary Dropout for\n  Domain-Adaptive Semantic Segmentation","authors":"Linyan Yang, Lukas Hoyer, Mark Weber, Tobias Fischer, Dengxin Dai,\n  Laura Leal-Taix\\'e, Marc Pollefeys, Daniel Cremers, Luc Van Gool","authorsParsed":[["Yang","Linyan",""],["Hoyer","Lukas",""],["Weber","Mark",""],["Fischer","Tobias",""],["Dai","Dengxin",""],["Leal-Taix√©","Laura",""],["Pollefeys","Marc",""],["Cremers","Daniel",""],["Van Gool","Luc",""]],"versions":[{"version":"v1","created":"Thu, 29 Aug 2024 12:15:10 GMT"}],"updateDate":"2024-08-30","timestamp":1724933710000,"abstract":"  Unsupervised Domain Adaptation (UDA) is the task of bridging the domain gap\nbetween a labeled source domain, e.g., synthetic data, and an unlabeled target\ndomain. We observe that current UDA methods show inferior results on fine\nstructures and tend to oversegment objects with ambiguous appearance. To\naddress these shortcomings, we propose to leverage geometric information, i.e.,\ndepth predictions, as depth discontinuities often coincide with segmentation\nboundaries. We show that naively incorporating depth into current UDA methods\ndoes not fully exploit the potential of this complementary information. To this\nend, we present MICDrop, which learns a joint feature representation by masking\nimage encoder features while inversely masking depth encoder features. With\nthis simple yet effective complementary masking strategy, we enforce the use of\nboth modalities when learning the joint feature representation. To aid this\nprocess, we propose a feature fusion module to improve both global as well as\nlocal information sharing while being robust to errors in the depth\npredictions. We show that our method can be plugged into various recent UDA\nmethods and consistently improve results across standard UDA benchmarks,\nobtaining new state-of-the-art performances.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}