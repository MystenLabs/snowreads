{"id":"2408.13986","title":"AgentMove: Predicting Human Mobility Anywhere Using Large Language Model\n  based Agentic Framework","authors":"Jie Feng, Yuwei Du, Jie Zhao, Yong Li","authorsParsed":[["Feng","Jie",""],["Du","Yuwei",""],["Zhao","Jie",""],["Li","Yong",""]],"versions":[{"version":"v1","created":"Mon, 26 Aug 2024 02:36:55 GMT"}],"updateDate":"2024-08-27","timestamp":1724639815000,"abstract":"  Human mobility prediction plays a crucial role in various real-world\napplications. Although deep learning based models have shown promising results\nover the past decade, their reliance on extensive private mobility data for\ntraining and their inability to perform zero-shot predictions, have hindered\nfurther advancements. Recently, attempts have been made to apply large language\nmodels (LLMs) to mobility prediction task. However, their performance has been\nconstrained by the absence of a systematic design of workflow. They directly\ngenerate the final output using LLMs, which limits the potential of LLMs to\nuncover complex mobility patterns and underestimates their extensive reserve of\nglobal geospatial knowledge. In this paper, we introduce AgentMove, a\nsystematic agentic prediction framework to achieve generalized mobility\nprediction for any cities worldwide. In AgentMove, we first decompose the\nmobility prediction task into three sub-tasks and then design corresponding\nmodules to complete these subtasks, including spatial-temporal memory for\nindividual mobility pattern mining, world knowledge generator for modeling the\neffects of urban structure and collective knowledge extractor for capturing the\nshared patterns among population. Finally, we combine the results of three\nmodules and conduct a reasoning step to generate the final predictions.\nExtensive experiments on mobility data from two sources in 12 cities\ndemonstrate that AgentMove outperforms the best baseline more than 8% in\nvarious metrics and it shows robust predictions with various LLMs as base and\nalso less geographical bias across cities. Codes and data can be found in\nhttps://github.com/tsinghua-fib-lab/AgentMove.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language","Computing Research Repository/Information Retrieval"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"_9ByuoE9gjQ_PXhpqgS6fw9QBoSjExzUTm0l4ULxgbQ","pdfSize":"3234261"}
