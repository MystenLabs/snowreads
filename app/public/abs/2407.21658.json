{"id":"2407.21658","title":"Beat this! Accurate beat tracking without DBN postprocessing","authors":"Francesco Foscarin, Jan Schl\\\"uter, Gerhard Widmer","authorsParsed":[["Foscarin","Francesco",""],["Schl√ºter","Jan",""],["Widmer","Gerhard",""]],"versions":[{"version":"v1","created":"Wed, 31 Jul 2024 14:59:17 GMT"}],"updateDate":"2024-08-01","timestamp":1722437957000,"abstract":"  We propose a system for tracking beats and downbeats with two objectives:\ngenerality across a diverse music range, and high accuracy. We achieve\ngenerality by training on multiple datasets -- including solo instrument\nrecordings, pieces with time signature changes, and classical music with high\ntempo variations -- and by removing the commonly used Dynamic Bayesian Network\n(DBN) postprocessing, which introduces constraints on the meter and tempo. For\nhigh accuracy, among other improvements, we develop a loss function tolerant to\nsmall time shifts of annotations, and an architecture alternating convolutions\nwith transformers either over frequency or time. Our system surpasses the\ncurrent state of the art in F1 score despite using no DBN. However, it can\nstill fail, especially for difficult and underrepresented genres, and performs\nworse on continuity metrics, so we publish our model, code, and preprocessed\ndatasets, and invite others to beat this.\n","subjects":["Computing Research Repository/Sound","Computing Research Repository/Machine Learning","Electrical Engineering and Systems Science/Audio and Speech Processing"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"b9wk_epIOw_7vwhtRpi46D4SI32MOPiS_U9FM4vHke8","pdfSize":"398543"}
