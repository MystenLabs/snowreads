{"id":"2407.01463","title":"Retrieval-augmented generation in multilingual settings","authors":"Nadezhda Chirkova, David Rau, Herv\\'e D\\'ejean, Thibault Formal,\n  St\\'ephane Clinchant, Vassilina Nikoulina","authorsParsed":[["Chirkova","Nadezhda",""],["Rau","David",""],["Déjean","Hervé",""],["Formal","Thibault",""],["Clinchant","Stéphane",""],["Nikoulina","Vassilina",""]],"versions":[{"version":"v1","created":"Mon, 1 Jul 2024 16:56:50 GMT"}],"updateDate":"2024-07-02","timestamp":1719853010000,"abstract":"  Retrieval-augmented generation (RAG) has recently emerged as a promising\nsolution for incorporating up-to-date or domain-specific knowledge into large\nlanguage models (LLMs) and improving LLM factuality, but is predominantly\nstudied in English-only settings. In this work, we consider RAG in the\nmultilingual setting (mRAG), i.e. with user queries and the datastore in 13\nlanguages, and investigate which components and with which adjustments are\nneeded to build a well-performing mRAG pipeline, that can be used as a strong\nbaseline in future works. Our findings highlight that despite the availability\nof high-quality off-the-shelf multilingual retrievers and generators,\ntask-specific prompt engineering is needed to enable generation in user\nlanguages. Moreover, current evaluation metrics need adjustments for\nmultilingual setting, to account for variations in spelling named entities. The\nmain limitations to be addressed in future works include frequent\ncode-switching in non-Latin alphabet languages, occasional fluency errors,\nwrong reading of the provided documents, or irrelevant retrieval. We release\nthe code for the resulting mRAG baseline pipeline at\nhttps://github.com/naver/bergen.\n","subjects":["Computing Research Repository/Computation and Language","Computing Research Repository/Artificial Intelligence"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}