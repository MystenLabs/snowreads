{"id":"2408.13045","title":"Adaptive complexity of log-concave sampling","authors":"Huanjian Zhou, Baoxiang Wang, Masashi Sugiyama","authorsParsed":[["Zhou","Huanjian",""],["Wang","Baoxiang",""],["Sugiyama","Masashi",""]],"versions":[{"version":"v1","created":"Fri, 23 Aug 2024 13:06:43 GMT"}],"updateDate":"2024-08-26","timestamp":1724418403000,"abstract":"  In large-data applications, such as the inference process of diffusion\nmodels, it is desirable to design sampling algorithms with a high degree of\nparallelization. In this work, we study the adaptive complexity of sampling,\nwhich is the minimal number of sequential rounds required to achieve sampling\ngiven polynomially many queries executed in parallel at each round. For\nunconstrained sampling, we examine distributions that are log-smooth or\nlog-Lipschitz and log strongly or non-strongly concave. We show that an almost\nlinear iteration algorithm cannot return a sample with a specific exponentially\nsmall accuracy under total variation distance. For box-constrained sampling, we\nshow that an almost linear iteration algorithm cannot return a sample with\nsup-polynomially small accuracy under total variation distance for log-concave\ndistributions. Our proof relies upon novel analysis with the characterization\nof the output for the hardness potentials based on the chain-like structure\nwith random partition and classical smoothing techniques.\n","subjects":["Computing Research Repository/Data Structures and Algorithms"],"license":"http://creativecommons.org/licenses/by/4.0/"}