{"id":"2407.00106","title":"UnUnlearning: Unlearning is not sufficient for content regulation in\n  advanced generative AI","authors":"Ilia Shumailov, Jamie Hayes, Eleni Triantafillou, Guillermo\n  Ortiz-Jimenez, Nicolas Papernot, Matthew Jagielski, Itay Yona, Heidi Howard,\n  Eugene Bagdasaryan","authorsParsed":[["Shumailov","Ilia",""],["Hayes","Jamie",""],["Triantafillou","Eleni",""],["Ortiz-Jimenez","Guillermo",""],["Papernot","Nicolas",""],["Jagielski","Matthew",""],["Yona","Itay",""],["Howard","Heidi",""],["Bagdasaryan","Eugene",""]],"versions":[{"version":"v1","created":"Thu, 27 Jun 2024 10:24:35 GMT"}],"updateDate":"2024-07-02","timestamp":1719483875000,"abstract":"  Exact unlearning was first introduced as a privacy mechanism that allowed a\nuser to retract their data from machine learning models on request. Shortly\nafter, inexact schemes were proposed to mitigate the impractical costs\nassociated with exact unlearning. More recently unlearning is often discussed\nas an approach for removal of impermissible knowledge i.e. knowledge that the\nmodel should not possess such as unlicensed copyrighted, inaccurate, or\nmalicious information. The promise is that if the model does not have a certain\nmalicious capability, then it cannot be used for the associated malicious\npurpose. In this paper we revisit the paradigm in which unlearning is used for\nin Large Language Models (LLMs) and highlight an underlying inconsistency\narising from in-context learning. Unlearning can be an effective control\nmechanism for the training phase, yet it does not prevent the model from\nperforming an impermissible act during inference. We introduce a concept of\nununlearning, where unlearned knowledge gets reintroduced in-context,\neffectively rendering the model capable of behaving as if it knows the\nforgotten knowledge. As a result, we argue that content filtering for\nimpermissible knowledge will be required and even exact unlearning schemes are\nnot enough for effective content regulation. We discuss feasibility of\nununlearning for modern LLMs and examine broader implications.\n","subjects":["Computing Research Repository/Machine Learning","Computing Research Repository/Artificial Intelligence","Computing Research Repository/Computation and Language","Computing Research Repository/Cryptography and Security"],"license":"http://creativecommons.org/licenses/by/4.0/","blobId":"pN8latuy1w0s1H_XceRoFwXNAG2JbsEeGSF0ZjOWTxo","pdfSize":"1154763"}
