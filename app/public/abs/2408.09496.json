{"id":"2408.09496","title":"StyleBrush: Style Extraction and Transfer from a Single Image","authors":"Wancheng Feng, Wanquan Feng, Dawei Huang, Jiaming Pei, Guangliang\n  Cheng, Lukun Wang","authorsParsed":[["Feng","Wancheng",""],["Feng","Wanquan",""],["Huang","Dawei",""],["Pei","Jiaming",""],["Cheng","Guangliang",""],["Wang","Lukun",""]],"versions":[{"version":"v1","created":"Sun, 18 Aug 2024 14:27:20 GMT"}],"updateDate":"2024-08-20","timestamp":1723991240000,"abstract":"  Stylization for visual content aims to add specific style patterns at the\npixel level while preserving the original structural features. Compared with\nusing predefined styles, stylization guided by reference style images is more\nchallenging, where the main difficulty is to effectively separate style from\nstructural elements. In this paper, we propose StyleBrush, a method that\naccurately captures styles from a reference image and ``brushes'' the extracted\nstyle onto other input visual content. Specifically, our architecture consists\nof two branches: ReferenceNet, which extracts style from the reference image,\nand Structure Guider, which extracts structural features from the input image,\nthus enabling image-guided stylization. We utilize LLM and T2I models to create\na dataset comprising 100K high-quality style images, encompassing a diverse\nrange of styles and contents with high aesthetic score. To construct training\npairs, we crop different regions of the same training image. Experiments show\nthat our approach achieves state-of-the-art results through both qualitative\nand quantitative analyses. We will release our code and dataset upon acceptance\nof the paper.\n","subjects":["Computing Research Repository/Computer Vision and Pattern Recognition"],"license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/"}