[{"id":"2407.09099","title":"Music Proofreading with RefinPaint: Where and How to Modify Compositions\n  given Context","authorsParsed":[["Ramoneda","Pedro",""],["Rocamora","Martin",""],["Akama","Taketo",""]],"timestamp":1720774347000,"metadataBlobId":null},{"id":"2407.14364","title":"Towards Assessing Data Replication in Music Generation with Music\n  Similarity Metrics on Raw Audio","authorsParsed":[["Batlle-Roca","Roser",""],["Liao","Wei-Hisang",""],["Serra","Xavier",""],["Mitsufuji","Yuki",""],["Gómez","Emilia",""]],"timestamp":1721400731000,"metadataBlobId":null},{"id":"2407.20955","title":"Emotion-driven Piano Music Generation via Two-stage Disentanglement and\n  Functional Representation","authorsParsed":[["Huang","Jingyue",""],["Chen","Ke",""],["Yang","Yi-Hsuan",""]],"timestamp":1722356968000,"metadataBlobId":null},{"id":"2407.14525","title":"Morse Code-Enabled Speech Recognition for Individuals with Visual and\n  Hearing Impairments","authorsParsed":[["Choudhury","Ritabrata Roy",""]],"timestamp":1720346069000,"metadataBlobId":null},{"id":"2407.10828","title":"Towards Enhanced Classification of Abnormal Lung sound in Multi-breath:\n  A Light Weight Multi-label and Multi-head Attention Classification Method","authorsParsed":[["Chua","Yi-Wei",""],["Cheng","Yun-Chien",""]],"timestamp":1721058002000,"metadataBlobId":"FpjB9gCndaukv11cB1A5V3FY1Pv3DukOJ4Ti5YWPyfI"},{"id":"2407.19265","title":"Towards Robust Few-shot Class Incremental Learning in Audio\n  Classification using Contrastive Representation","authorsParsed":[["Singh","Riyansha",""],["Nema","Parinita",""],["Kurmi","Vinod K",""]],"timestamp":1722089785000,"metadataBlobId":"XJdW0fDgCGX94H82sUraVE284f4wcQnliSmyZYllnKY"},{"id":"2407.04416","title":"Sound-VECaps: Improving Audio Generation with Visual Enhanced Captions","authorsParsed":[["Yuan","Yi",""],["Jia","Dongya",""],["Zhuang","Xiaobin",""],["Chen","Yuanzhe",""],["Liu","Zhengxi",""],["Chen","Zhuo",""],["Wang","Yuping",""],["Wang","Yuxuan",""],["Liu","Xubo",""],["Kang","Xiyuan",""],["Plumbley","Mark D.",""],["Wang","Wenwu",""]],"timestamp":1720177633000,"metadataBlobId":null},{"id":"2407.06078","title":"Few-Shot Keyword Spotting from Mixed Speech","authorsParsed":[["Yuan","Junming",""],["Shi","Ying",""],["Li","LanTian",""],["Wang","Dong",""],["Hamdulla","Askar",""]],"timestamp":1720145153000,"metadataBlobId":null},{"id":"2407.16564","title":"Audio Prompt Adapter: Unleashing Music Editing Abilities for\n  Text-to-Music with Lightweight Finetuning","authorsParsed":[["Tsai","Fang-Duo",""],["Wu","Shih-Lun",""],["Kim","Haven",""],["Chen","Bo-Yu",""],["Cheng","Hao-Chung",""],["Yang","Yi-Hsuan",""]],"timestamp":1721747778000,"metadataBlobId":null},{"id":"2407.03887","title":"Unsupervised speech enhancement with spectral kurtosis and double deep\n  priors","authorsParsed":[["Ohnaka","Hien",""],["Miyazaki","Ryoichi",""]],"timestamp":1720095913000,"metadataBlobId":"3h8qboGsr_mYgBrnbbPZslGDGf6O-yuqIQPZWMOC-F4"},{"id":"2407.17172","title":"Speech Editing -- a Summary","authorsParsed":[["Kässmann","Tobias",""],["Liu","Yining",""],["Liu","Danni",""]],"timestamp":1721820177000,"metadataBlobId":"hCzpABDImfr4bMoyPJ8PtgW9bIbxGPT3Sw8Pbn7YoIA"},{"id":"2407.04379","title":"A Mapping Strategy for Interacting with Latent Audio Synthesis Using\n  Artistic Materials","authorsParsed":[["Zheng","Shuoyang",""],["Sedó","Anna Xambó",""],["Bryan-Kinns","Nick",""]],"timestamp":1720171964000,"metadataBlobId":"JSXGazqTJFcGr6dwRcvrRw8muRYnOFlNwyel217yfAc"},{"id":"2407.20989","title":"Contrasting Deep Learning Models for Direct Respiratory Insufficiency\n  Detection Versus Blood Oxygen Saturation Estimation","authorsParsed":[["Gauy","Marcelo Matheus",""],["Koza","Natalia Hitomi",""],["Morita","Ricardo Mikio",""],["Stanzione","Gabriel Rocha",""],["Junior","Arnaldo Candido",""],["Berti","Larissa Cristina",""],["Levin","Anna Sara Shafferman",""],["Sabino","Ester Cerdeira",""],["Svartman","Flaviane Romani Fernandes",""],["Finger","Marcelo",""]],"timestamp":1722360376000,"metadataBlobId":"Ro9cEUiJulCUeuhTeomZrv59IvjE69THTjeKjA0la6E"},{"id":"2407.17844","title":"Innovative Speech-Based Deep Learning Approaches for Parkinson's Disease\n  Classification: A Systematic Review","authorsParsed":[["van Gelderen","Lisanne",""],["Tejedor-García","Cristian",""]],"timestamp":1721894299000,"metadataBlobId":"UC2QQqUyDuJWnpkWjwZkhfAdi5_z1H_taPQ49Hf6gqU"},{"id":"2407.02277","title":"MelodyT5: A Unified Score-to-Score Transformer for Symbolic Music\n  Processing","authorsParsed":[["Wu","Shangda",""],["Wang","Yashan",""],["Li","Xiaobing",""],["Yu","Feng",""],["Sun","Maosong",""]],"timestamp":1719929191000,"metadataBlobId":null},{"id":"2407.03966","title":"Serialized Output Training by Learned Dominance","authorsParsed":[["Shi","Ying",""],["Li","Lantian",""],["Yin","Shi",""],["Wang","Dong",""],["Han","Jiqing",""]],"timestamp":1720103762000,"metadataBlobId":"kZP6Rqxx3vBXov4Usru59BKfoYns2pHP3ofZYwC8LM4"},{"id":"2407.08647","title":"From Real to Cloned Singer Identification","authorsParsed":[["Desblancs","Dorian",""],["Meseguer-Brocal","Gabriel",""],["Hennequin","Romain",""],["Moussallam","Manuel",""]],"timestamp":1720715121000,"metadataBlobId":"538ij5-YmLkN57ARUu_5hKS01q4jit-K5xamJYTQ__g"},{"id":"2407.19900","title":"Practical and Reproducible Symbolic Music Generation by Large Language\n  Models with Structural Embeddings","authorsParsed":[["Rhyu","Seungyeon",""],["Yang","Kichang",""],["Cho","Sungjun",""],["Kim","Jaehyeon",""],["Lee","Kyogu",""],["Lee","Moontae",""]],"timestamp":1722252250000,"metadataBlobId":null},{"id":"2407.19224","title":"RAVSS: Robust Audio-Visual Speech Separation in Multi-Speaker Scenarios\n  with Missing Visual Cues","authorsParsed":[["Pan","Tianrui",""],["Liu","Jie",""],["Wang","Bohan",""],["Tang","Jie",""],["Wu","Gangshan",""]],"timestamp":1722074183000,"metadataBlobId":"EsOla1fu1L-cFcN9tIfclMG5sxSrgnMQ08-8l2yn6nU"},{"id":"2407.13439","title":"Reducing Barriers to the Use of Marginalised Music Genres in AI","authorsParsed":[["Bryan-Kinns","Nick",""],["Li","Zijin",""]],"timestamp":1721304604000,"metadataBlobId":null},{"id":"2407.19862","title":"Wavespace: A Highly Explorable Wavetable Generator","authorsParsed":[["Lee","Hazounne",""],["Kim","Kihong",""],["Lee","Sungho",""],["Lee","Kyogu",""]],"timestamp":1722249102000,"metadataBlobId":"_tRfCIC3Al7HYsGne8C_BniwuSFNfWe1tu2gFeDENs0"},{"id":"2407.02156","title":"Towards Training Music Taggers on Synthetic Data","authorsParsed":[["Kroher","Nadine",""],["Manangu","Steven",""],["Pikrakis","Aggelos",""]],"timestamp":1719917663000,"metadataBlobId":null},{"id":"2407.10468","title":"LiteFocus: Accelerated Diffusion Inference for Long Audio Synthesis","authorsParsed":[["Tan","Zhenxiong",""],["Ma","Xinyin",""],["Fang","Gongfan",""],["Wang","Xinchao",""]],"timestamp":1721026145000,"metadataBlobId":"WhHqThvx5tiYrEcXifoGP6kmA71XeXilnuwUFhnonMY"},{"id":"2407.07464","title":"Video-to-Audio Generation with Hidden Alignment","authorsParsed":[["Xu","Manjie",""],["Li","Chenxing",""],["Ren","Yong",""],["Chen","Rilin",""],["Gu","Yu",""],["Liang","Wei",""],["Yu","Dong",""]],"timestamp":1720600839000,"metadataBlobId":"pR6MdRdvKvuKl4xi-R84Q5f930opA9rbLZNZJ0I7Tn0"},{"id":"2407.01452","title":"On Feature Learning for Titi Monkey Activity Detection","authorsParsed":[["Ravuri","Aditya",""],["Muir","Jen",""],["Lawrence","Neil D.",""]],"timestamp":1719852399000,"metadataBlobId":"2YYpNA4gg-fJVHVSzIqr0nGYdon9ywWvvWdN8tMIQpY"},{"id":"2407.03132","title":"Speaker- and Text-Independent Estimation of Articulatory Movements and\n  Phoneme Alignments from Speech","authorsParsed":[["Weise","Tobias",""],["Klumpp","Philipp",""],["Demir","Kubilay Can",""],["Pérez-Toro","Paula Andrea",""],["Schuster","Maria",""],["Noeth","Elmar",""],["Heismann","Bjoern",""],["Maier","Andreas",""],["Yang","Seung Hee",""]],"timestamp":1720015984000,"metadataBlobId":null},{"id":"2407.07598","title":"Targeted Augmented Data for Audio Deepfake Detection","authorsParsed":[["Astrid","Marcella",""],["Ghorbel","Enjie",""],["Aouada","Djamila",""]],"timestamp":1720614713000,"metadataBlobId":"OFMoLLVH-FDmkFhccvdBzZXc-5-EjkUyyPe_pmksLv8"},{"id":"2407.13083","title":"Modeling and Driving Human Body Soundfields through Acoustic Primitives","authorsParsed":[["Huang","Chao",""],["Markovic","Dejan",""],["Xu","Chenliang",""],["Richard","Alexander",""]],"timestamp":1721264713000,"metadataBlobId":null},{"id":"2407.00531","title":"Interpreting Pretrained Speech Models for Automatic Speech Assessment of\n  Voice Disorders","authorsParsed":[["Lau","Hok-Shing",""],["Huntly","Mark",""],["Morgan","Nathon",""],["Iyenoma","Adesua",""],["Zeng","Biao",""],["Bashford","Tim",""]],"timestamp":1719695688000,"metadataBlobId":null},{"id":"2407.08951","title":"Audio Spotforming Using Nonnegative Tensor Factorization with\n  Attractor-Based Regularization","authorsParsed":[["Ayano","Shoma",""],["Li","Li",""],["Seki","Shogo",""],["Kitamura","Daichi",""]],"timestamp":1720753825000,"metadataBlobId":"mIvPZQrE7_TRLdbfV_Pzad3hDDHJMwZsfOi9Dum0VHw"},{"id":"2407.01317","title":"Leveraging Speaker Embeddings in End-to-End Neural Diarization for\n  Two-Speaker Scenarios","authorsParsed":[["Alvarez-Trejos","Juan Ignacio",""],["Labrador","Beltrán",""],["Lozano-Diez","Alicia",""]],"timestamp":1719843988000,"metadataBlobId":null},{"id":"2407.11492","title":"MMSD-Net: Towards Multi-modal Stuttering Detection","authorsParsed":[["Nie","Liangyu",""],["Kadiri","Sudarsana Reddy",""],["Agrawal","Ruchit",""]],"timestamp":1721118419000,"metadataBlobId":"tKcW10CL-ZH6Kb2tEEfma_39NChJbGWb1DSzD-yOPTA"},{"id":"2407.04547","title":"Real-time Timbre Remapping with Differentiable DSP","authorsParsed":[["Shier","Jordie",""],["Saitis","Charalampos",""],["Robertson","Andrew",""],["McPherson","Andrew",""]],"timestamp":1720189972000,"metadataBlobId":"lSIrW6lR_recu7jHbI1C8-8coAQP3sXkz2PhsX7N5Lk"},{"id":"2407.01143","title":"Are you sure? Analysing Uncertainty Quantification Approaches for\n  Real-world Speech Emotion Recognition","authorsParsed":[["Schrüfer","Oliver",""],["Milling","Manuel",""],["Burkhardt","Felix",""],["Eyben","Florian",""],["Schuller","Björn",""]],"timestamp":1719828668000,"metadataBlobId":null},{"id":"2407.01499","title":"Pictures Of MIDI: Controlled Music Generation via Graphical Prompts for\n  Image-Based Diffusion Inpainting","authorsParsed":[["Hawley","Scott H.",""]],"timestamp":1719855825000,"metadataBlobId":"wabTgJpq74E83Y1b9UC8bh4018BouduG1bSUP4iLnVA"},{"id":"2407.14358","title":"Stable Audio Open","authorsParsed":[["Evans","Zach",""],["Parker","Julian D.",""],["Carr","CJ",""],["Zukowski","Zack",""],["Taylor","Josiah",""],["Pons","Jordi",""]],"timestamp":1721400023000,"metadataBlobId":null},{"id":"2407.04333","title":"PAGURI: a user experience study of creative interaction with\n  text-to-music models","authorsParsed":[["Ronchini","Francesca",""],["Comanducci","Luca",""],["Perego","Gabriele",""],["Antonacci","Fabio",""]],"timestamp":1720167355000,"metadataBlobId":null},{"id":"2407.06947","title":"Audio-Language Datasets of Scenes and Events: A Survey","authorsParsed":[["Wijngaard","Gijs",""],["Formisano","Elia",""],["Esposito","Michele",""],["Dumontier","Michel",""]],"timestamp":1720538615000,"metadataBlobId":null},{"id":"2407.20111","title":"Enhancing Anti-spoofing Countermeasures Robustness through Joint\n  Optimization and Transfer Learning","authorsParsed":[["Wang","Yikang",""],["Wang","Xingming",""],["Nishizaki","Hiromitsu",""],["Li","Ming",""]],"timestamp":1722267565000,"metadataBlobId":"AvNiQRu6kDAKpl_bOLHHpIj-9yXBCTByvUikpzRZ6ss"},{"id":"2407.10646","title":"Towards zero-shot amplifier modeling: One-to-many amplifier modeling via\n  tone embedding control","authorsParsed":[["Chen","Yu-Hua",""],["Yeh","Yen-Tung",""],["Cheng","Yuan-Chiao",""],["Wu","Jui-Te",""],["Ho","Yu-Hsiang",""],["Jang","Jyh-Shing Roger",""],["Yang","Yi-Hsuan",""]],"timestamp":1721045096000,"metadataBlobId":"jQnP0HtjTgkpHAxRIMQtEZIRlE-D1rhwV1aflBCn2Lo"},{"id":"2407.21391","title":"Design and Development of Laughter Recognition System Based on\n  Multimodal Fusion and Deep Learning","authorsParsed":[["Zhao","Fuzheng",""],["Bai","Yu",""]],"timestamp":1722411073000,"metadataBlobId":"XYp1PbSGVxlWdAnTUmlpUdbo8cls9WHd3WwaLHYxCCU"},{"id":"2407.15216","title":"Explainability Paths for Sustained Artistic Practice with AI","authorsParsed":[["Tecks","Austin",""],["Peschlow","Thomas",""],["Vigliensoni","Gabriel",""]],"timestamp":1721580494000,"metadataBlobId":"YBWuYi3lDuQRlKsuJsbuE0sVpp2tC7EcNd5hvabxZTk"},{"id":"2407.15060","title":"MusiConGen: Rhythm and Chord Control for Transformer-Based Text-to-Music\n  Generation","authorsParsed":[["Lan","Yun-Han",""],["Hsiao","Wen-Yi",""],["Cheng","Hao-Chung",""],["Yang","Yi-Hsuan",""]],"timestamp":1721539673000,"metadataBlobId":"tXt9nRuuhzhudT2DAiqY1Mxo_cbk7KqF7Jix0wYEZKE"},{"id":"2407.08239","title":"An Unsupervised Domain Adaptation Method for Locating Manipulated Region\n  in partially fake Audio","authorsParsed":[["Zeng","Siding",""],["Yi","Jiangyan",""],["Tao","Jianhua",""],["Chen","Yujie",""],["Liang","Shan",""],["Ren","Yong",""],["Zhang","Xiaohui",""]],"timestamp":1720683136000,"metadataBlobId":"_u-agSZE0S0TGTgkslOFf1cu5rRtEmAvPene9Vu8zz0"},{"id":"2407.17716","title":"Describe Where You Are: Improving Noise-Robustness for Speech Emotion\n  Recognition with Text Description of the Environment","authorsParsed":[["Leem","Seong-Gyun",""],["Fulford","Daniel",""],["Onnela","Jukka-Pekka",""],["Gard","David",""],["Busso","Carlos",""]],"timestamp":1721874640000,"metadataBlobId":null},{"id":"2407.01860","title":"Constant Directivity Loudspeaker Beamforming","authorsParsed":[["Luo","Yuancheng",""]],"timestamp":1719879187000,"metadataBlobId":"RJHmngqaJeS_5z8z_Hn05bxIKkAEpDtzoUsDpfaJtjg"},{"id":"2407.00766","title":"An Attribute Interpolation Method in Speech Synthesis by Model Merging","authorsParsed":[["Murata","Masato",""],["Miyazaki","Koichi",""],["Koriyama","Tomoki",""]],"timestamp":1719766896000,"metadataBlobId":"aIxil3jLjLQokvBGOJwBZezuRaYDY7Csh3O2JDO9-c0"},{"id":"2407.18062","title":"Audio Entailment: Assessing Deductive Reasoning for Audio Understanding","authorsParsed":[["Deshmukh","Soham",""],["Han","Shuo",""],["Bukhari","Hazim",""],["Elizalde","Benjamin",""],["Gamper","Hannes",""],["Singh","Rita",""],["Raj","Bhiksha",""]],"timestamp":1721917076000,"metadataBlobId":null},{"id":"2407.06060","title":"MERGE -- A Bimodal Dataset for Static Music Emotion Recognition","authorsParsed":[["Louro","Pedro Lima",""],["Redinho","Hugo",""],["Santos","Ricardo",""],["Malheiro","Ricardo",""],["Panda","Renato",""],["Paiva","Rui Pedro",""]],"timestamp":1720454464000,"metadataBlobId":null},{"id":"2407.04482","title":"Controlling Whisper: Universal Acoustic Adversarial Attacks to Control\n  Speech Foundation Models","authorsParsed":[["Raina","Vyas",""],["Gales","Mark",""]],"timestamp":1720184671000,"metadataBlobId":null},{"id":"2407.18879","title":"Utilizing TTS Synthesized Data for Efficient Development of Keyword\n  Spotting Model","authorsParsed":[["Park","Hyun Jin",""],["Agarwal","Dhruuv",""],["Chen","Neng",""],["Sun","Rentao",""],["Partridge","Kurt",""],["Chen","Justin",""],["Zhang","Harry",""],["Zhu","Pai",""],["Bartel","Jacob",""],["Kastner","Kyle",""],["Wang","Gary",""],["Rosenberg","Andrew",""],["Wang","Quan",""]],"timestamp":1722014690000,"metadataBlobId":"IEdwkhdWNQzpQwS4NnOOEF5Y2V9DMaXUUhLxggO9igE"},{"id":"2407.01291","title":"Lightweight Zero-shot Text-to-Speech with Mixture of Adapters","authorsParsed":[["Fujita","Kenichi",""],["Ashihara","Takanori",""],["Delcroix","Marc",""],["Ijima","Yusuke",""]],"timestamp":1719841531000,"metadataBlobId":null},{"id":"2407.12671","title":"GraphMuse: A Library for Symbolic Music Graph Processing","authorsParsed":[["Karystinaios","Emmanouil",""],["Widmer","Gerhard",""]],"timestamp":1721231649000,"metadataBlobId":null},{"id":"2407.09346","title":"A Preliminary Investigation on Flexible Singing Voice Synthesis Through\n  Decomposed Framework with Inferrable Features","authorsParsed":[["Violeta","Lester Phillip",""],["Akama","Taketo",""]],"timestamp":1720797743000,"metadataBlobId":null},{"id":"2407.01777","title":"Deepfake Audio Detection Using Spectrogram-based Feature and Ensemble of\n  Deep Learning Models","authorsParsed":[["Pham","Lam",""],["Lam","Phat",""],["Nguyen","Truong",""],["Nguyen","Huyen",""],["Schindler","Alexander",""]],"timestamp":1719864643000,"metadataBlobId":null},{"id":"2407.18424","title":"Model-driven Heart Rate Estimation and Heart Murmur Detection based on\n  Phonocardiogram","authorsParsed":[["Nie","Jingping",""],["Liu","Ran",""],["Mahasseni","Behrooz",""],["Azemi","Erdrin",""],["Mitra","Vikramjit",""]],"timestamp":1721948181000,"metadataBlobId":"_AUSBQfKEgVawfU1r3f6-zEDbulx9PznX9auW0-qsHc"},{"id":"2407.18985","title":"Implementation and Applications of WakeWords Integrated with Speaker\n  Recognition: A Case Study","authorsParsed":[["Filho","Alexandre Costa Ferro",""],["de Oliveira","Elisa Ayumi Masasi",""],["Brito","Iago Alves",""],["Bittencourt","Pedro Martins",""]],"timestamp":1721872946000,"metadataBlobId":null},{"id":"2407.05870","title":"Cervical Auscultation Machine Learning for Dysphagia Assessment","authorsParsed":[["Chia","An An",""],["Lum","Stacy",""],["Boo","Michelle",""],["Tan","Rex",""],["T","Balamurali B",""],["Chen","Jer-Ming",""]],"timestamp":1720441909000,"metadataBlobId":"PW6luOa2zkFlVt20ddsu2mlF-kKTBQFQHnY68bZLuRA"},{"id":"2407.21531","title":"Can LLMs \"Reason\" in Music? An Evaluation of LLMs' Capability of Music\n  Understanding and Generation","authorsParsed":[["Zhou","Ziya",""],["Wu","Yuhang",""],["Wu","Zhiyue",""],["Zhang","Xinyue",""],["Yuan","Ruibin",""],["Ma","Yinghao",""],["Wang","Lu",""],["Benetos","Emmanouil",""],["Xue","Wei",""],["Guo","Yike",""]],"timestamp":1722425386000,"metadataBlobId":"Yg7bDsiYVGcSkSPrFMIKigFzzfLwk3o3iIYpLzEEOn0"},{"id":"2407.00188","title":"A Novel Labeled Human Voice Signal Dataset for Misbehavior Detection","authorsParsed":[["Raza","Ali","","Department of Software Engineering The University Of Lahore,\n  Lahore, Pakistan"],["Younas","Faizan","","Department of Computer Science &\n  Information Technology, The University Of Lahore, Lahore, Pakistan"]],"timestamp":1719600907000,"metadataBlobId":null},{"id":"2407.03470","title":"Prosody-Driven Privacy-Preserving Dementia Detection","authorsParsed":[["Woszczyk","Dominika",""],["Aloufi","Ranya",""],["Demetriou","Soteris",""]],"timestamp":1720035287000,"metadataBlobId":"6IoHBVeVH3CryHUftADva2xu3ZegOJm47AvLfSNt6nI"},{"id":"2407.10328","title":"The Interpretation Gap in Text-to-Music Generation Models","authorsParsed":[["Zang","Yongyi",""],["Zhang","Yixiao",""]],"timestamp":1720990268000,"metadataBlobId":"w20_Y7wage1sm-tL3yS67GusWH4h1dnUTotu8aax66g"},{"id":"2407.00657","title":"Improving Real-Time Music Accompaniment Separation with MMDenseNet","authorsParsed":[["Wang","Chun-Hsiang",""],["Wang","Chung-Che",""],["Wang","Jun-You",""],["Jang","Jyh-Shing Roger",""],["Chu","Yen-Hsun",""]],"timestamp":1719745209000,"metadataBlobId":null},{"id":"2407.11641","title":"Investigating the Effect of Label Topology and Training Criterion on ASR\n  Performance and Alignment Quality","authorsParsed":[["Raissi","Tina",""],["Lüscher","Christoph",""],["Berger","Simon",""],["Schlüter","Ralf",""],["Ney","Hermann",""]],"timestamp":1721131367000,"metadataBlobId":null},{"id":"2407.10462","title":"BandControlNet: Parallel Transformers-based Steerable Popular Music\n  Generation with Fine-Grained Spatiotemporal Features","authorsParsed":[["Luo","Jing",""],["Yang","Xinyu",""],["Herremans","Dorien",""]],"timestamp":1721025205000,"metadataBlobId":null},{"id":"2407.05608","title":"A Benchmark for Multi-speaker Anonymization","authorsParsed":[["Miao","Xiaoxiao",""],["Tao","Ruijie",""],["Zeng","Chang",""],["Wang","Xin",""]],"timestamp":1720414123000,"metadataBlobId":"17dFj8oz1YzsToDMLUHv8et99KV_OU60NECe35WK8w8"},{"id":"2407.03110","title":"A Toolchain for Comprehensive Audio/Video Analysis Using Deep Learning\n  Based Multimodal Approach (A use case of riot or violent context detection)","authorsParsed":[["Pham","Lam",""],["Lam","Phat",""],["Nguyen","Tin",""],["Tang","Hieu",""],["Schindler","Alexander",""]],"timestamp":1714635271000,"metadataBlobId":"uwM0nDhsjrv8GiAvFr1Wj9UwzeAaNWOkKJ7MDgR-GEI"},{"id":"2407.20445","title":"Futga: Towards Fine-grained Music Understanding through\n  Temporally-enhanced Generative Augmentation","authorsParsed":[["Wu","Junda",""],["Novack","Zachary",""],["Namburi","Amit",""],["Dai","Jiaheng",""],["Dong","Hao-Wen",""],["Xie","Zhouhang",""],["Chen","Carol",""],["McAuley","Julian",""]],"timestamp":1722293612000,"metadataBlobId":null},{"id":"2407.03440","title":"Advanced Framework for Animal Sound Classification With Features\n  Optimization","authorsParsed":[["Yang","Qiang",""],["Chen","Xiuying",""],["Ma","Changsheng",""],["Duarte","Carlos M.",""],["Zhang","Xiangliang",""]],"timestamp":1720031627000,"metadataBlobId":"jXI-Bkz4QAGq3H148QBVypc5ii6b5EGHloznx1SGE-M"},{"id":"2407.08658","title":"Evaluating Voice Command Pipelines for Drone Control: From STT and LLM\n  to Direct Classification and Siamese Networks","authorsParsed":[["Simões","Lucca Emmanuel Pineli",""],["Rodrigues","Lucas Brandão",""],["Silva","Rafaela Mota",""],["da Silva","Gustavo Rodrigues",""]],"timestamp":1720624526000,"metadataBlobId":"D-zOs73_QKEO4iMhZR1Yl8MrVEagBIqXLp17EwwS0Iw"},{"id":"2407.18571","title":"Speech Bandwidth Expansion Via High Fidelity Generative Adversarial\n  Networks","authorsParsed":[["Salhab","Mahmoud",""],["Harmanani","Haidar",""]],"timestamp":1721980487000,"metadataBlobId":"CDD1HWYQ_XCJ6FhKfjMM9bD_P4T2LQpcV4VpRjYhkgA"},{"id":"2407.19823","title":"Analyzing and reducing the synthetic-to-real transfer gap in Music\n  Information Retrieval: the task of automatic drum transcription","authorsParsed":[["Zehren","Mickaël",""],["Alunno","Marco",""],["Bientinesi","Paolo",""]],"timestamp":1722244636000,"metadataBlobId":null},{"id":"2407.04578","title":"Resource-Efficient Speech Quality Prediction through Quantization Aware\n  Training and Binary Activation Maps","authorsParsed":[["Nilsson","Mattias",""],["Miccini","Riccardo",""],["Laroche","Clément",""],["Piechowiak","Tobias",""],["Zenke","Friedemann",""]],"timestamp":1720192500000,"metadataBlobId":null},{"id":"2407.08691","title":"ElasticAST: An Audio Spectrogram Transformer for All Length and\n  Resolutions","authorsParsed":[["Feng","Jiu",""],["Erol","Mehmet Hamza",""],["Chung","Joon Son",""],["Senocak","Arda",""]],"timestamp":1720718996000,"metadataBlobId":null},{"id":"2407.20883","title":"PiCoGen: Generate Piano Covers with a Two-stage Approach","authorsParsed":[["Tan","Chih-Pin",""],["Guan","Shuen-Huei",""],["Yang","Yi-Hsuan",""]],"timestamp":1722351482000,"metadataBlobId":"qkgXYf_PPtsJ1g3CoxMJ6ZDEaaZ_0GYgXLWsc6lsqSA"},{"id":"2407.06291","title":"Transfer Learning with Pseudo Multi-Label Birdcall Classification for\n  DS@GT BirdCLEF 2024","authorsParsed":[["Miyaguchi","Anthony",""],["Cheung","Adrian",""],["Gustineli","Murilo",""],["Kim","Ashley",""]],"timestamp":1720461859000,"metadataBlobId":"EObQQS5x8cSXG-iS77_ZNDU2zprngyIGj5TOBqpMC3Y"},{"id":"2407.07408","title":"STONE: Self-supervised Tonality Estimator","authorsParsed":[["Kong","Yuexuan",""],["Lostanlen","Vincent",""],["Meseguer-Brocal","Gabriel",""],["Wong","Stella",""],["Lagrange","Mathieu",""],["Hennequin","Romain",""]],"timestamp":1720595396000,"metadataBlobId":null},{"id":"2407.05368","title":"Music Era Recognition Using Supervised Contrastive Learning and Artist\n  Information","authorsParsed":[["He","Qiqi",""],["Song","Xuchen",""],["Hao","Weituo",""],["Wang","Ju-Chiang",""],["Lu","Wei-Tsung",""],["Li","Wei",""]],"timestamp":1720359835000,"metadataBlobId":null},{"id":"2407.03892","title":"On the Effectiveness of Acoustic BPE in Decoder-Only TTS","authorsParsed":[["Li","Bohan",""],["Shen","Feiyu",""],["Guo","Yiwei",""],["Wang","Shuai",""],["Chen","Xie",""],["Yu","Kai",""]],"timestamp":1720096532000,"metadataBlobId":"WykibhV6t2Jn5EyfNB5woJ4dSJivDBYN3mrnnwQ5g-U"},{"id":"2407.13035","title":"Pre-Trained Foundation Model representations to uncover Breathing\n  patterns in Speech","authorsParsed":[["Mitra","Vikramjit",""],["Chatterjee","Anirban",""],["Zhai","Ke",""],["Weng","Helen",""],["Hill","Ayuko",""],["Hay","Nicole",""],["Webb","Christopher",""],["Cheng","Jamie",""],["Azemi","Erdrin",""]],"timestamp":1721253438000,"metadataBlobId":null},{"id":"2407.14700","title":"Composer's Assistant 2: Interactive Multi-Track MIDI Infilling with\n  Fine-Grained User Control","authorsParsed":[["Malandro","Martin E.",""]],"timestamp":1721431689000,"metadataBlobId":null},{"id":"2407.18541","title":"Towards Improving NAM-to-Speech Synthesis Intelligibility using\n  Self-Supervised Speech Models","authorsParsed":[["Shah","Neil",""],["Karande","Shirish",""],["Gandhi","Vineet",""]],"timestamp":1721976241000,"metadataBlobId":null},{"id":"2407.21658","title":"Beat this! Accurate beat tracking without DBN postprocessing","authorsParsed":[["Foscarin","Francesco",""],["Schlüter","Jan",""],["Widmer","Gerhard",""]],"timestamp":1722437957000,"metadataBlobId":null},{"id":"2407.21545","title":"Robust Lossy Audio Compression Identification","authorsParsed":[["Koops","Hendrik Vincent",""],["Micchi","Gianluca",""],["Quinton","Elio",""]],"timestamp":1722427771000,"metadataBlobId":null},{"id":"2407.13333","title":"Using Speech Foundational Models in Loss Functions for Hearing Aid\n  Speech Enhancement","authorsParsed":[["Sutherland","Robert",""],["Close","George",""],["Hain","Thomas",""],["Goetze","Stefan",""],["Barker","Jon",""]],"timestamp":1721295177000,"metadataBlobId":null},{"id":"2407.16417","title":"On the Utility of Speech and Audio Foundation Models for Marmoset Call\n  Analysis","authorsParsed":[["Sarkar","Eklavya",""],["-Doss","Mathew Magimai.",""]],"timestamp":1721736044000,"metadataBlobId":null},{"id":"2407.21615","title":"Between the AI and Me: Analysing Listeners' Perspectives on AI- and\n  Human-Composed Progressive Metal Music","authorsParsed":[["Sarmento","Pedro",""],["Loth","Jackson",""],["Barthet","Mathieu",""]],"timestamp":1722434625000,"metadataBlobId":"oc616SwusxaGAPpL4D3iy_rL_XgZleGlW0KMmShx3GM"},{"id":"2407.16639","title":"Distortion Recovery: A Two-Stage Method for Guitar Effect Removal","authorsParsed":[["Lee","Ying-Shuo",""],["Peng","Yueh-Po",""],["Wu","Jui-Te",""],["Cheng","Ming",""],["Su","Li",""],["Yang","Yi-Hsuan",""]],"timestamp":1721753713000,"metadataBlobId":"QQgDV0zJ5R5vvuIf5H9-oMDiv_kBE2gCbePdR5JsMrM"},{"id":"2407.20176","title":"Emotion-Driven Melody Harmonization via Melodic Variation and Functional\n  Representation","authorsParsed":[["Huang","Jingyue",""],["Yang","Yi-Hsuan",""]],"timestamp":1722272712000,"metadataBlobId":"lLMq6onl3MOMQts2GF31pfyu5PT8_ofd_fP5kbgTOGI"},{"id":"2407.20808","title":"Abusive Speech Detection in Indic Languages Using Acoustic Features","authorsParsed":[["Spiesberger","Anika A.",""],["Triantafyllopoulos","Andreas",""],["Tsangko","Iosif",""],["Schuller","Björn W.",""]],"timestamp":1722345218000,"metadataBlobId":"rIohHrqRZZ8eT_6AusoI2XmuTlVuTmcvFaXxPjzXKhg"},{"id":"2407.10048","title":"Whisper-SV: Adapting Whisper for Low-data-resource Speaker Verification","authorsParsed":[["Zhang","Li",""],["Jiang","Ning",""],["Wang","Qing",""],["Li","Yue",""],["Lu","Quan",""],["Xie","Lei",""]],"timestamp":1720923712000,"metadataBlobId":null},{"id":"2407.17167","title":"Zero-Shot vs. Few-Shot Multi-Speaker TTS Using Pre-trained Czech\n  SpeechT5 Model","authorsParsed":[["Lehečka","Jan",""],["Hanzlíček","Zdeněk",""],["Matoušek","Jindřich",""],["Tihelka","Daniel",""]],"timestamp":1721819646000,"metadataBlobId":"B7PGnHg-XGhznoZBk0l-ecr4zJ15u0GK_a_7QvFDaU0"},{"id":"2407.15300","title":"SELM: Enhancing Speech Emotion Recognition for Out-of-Domain Scenarios","authorsParsed":[["Bukhari","Hazim",""],["Deshmukh","Soham",""],["Dhamyal","Hira",""],["Raj","Bhiksha",""],["Singh","Rita",""]],"timestamp":1721606480000,"metadataBlobId":"GeP1BC4C3cZpLqlrOfV-BwzaH-5odzqYTEpteusmqHw"},{"id":"2407.13266","title":"How Private is Low-Frequency Speech Audio in the Wild? An Analysis of\n  Verbal Intelligibility by Humans and Machines","authorsParsed":[["Liu","Ailin",""],["Vunderink","Pepijn",""],["Quiros","Jose Vargas",""],["Raman","Chirag",""],["Hung","Hayley",""]],"timestamp":1721290616000,"metadataBlobId":null}]