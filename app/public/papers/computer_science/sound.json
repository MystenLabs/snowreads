[{"id":"2412.00319","title":"Improving speaker verification robustness with synthetic emotional\n  utterances","authorsParsed":[["Koditala","Nikhil Kumar",""],["Ju","Chelsea Jui-Ting",""],["Li","Ruirui",""],["Jin","Minho",""],["Chadha","Aman",""],["Stolcke","Andreas",""]],"timestamp":1732933106000,"metadataBlobId":"LMXmbBOFJE-sl6rVj9tRNPb1u1YumS0_QIPmfnAPZPA"},{"id":"2412.00325","title":"MusicGen-Chord: Advancing Music Generation through Chord Progressions\n  and Interactive Web-UI","authorsParsed":[["Jung","Jongmin",""],["Jansson","Andreas",""],["Jeong","Dasaem",""]],"timestamp":1732934985000,"metadataBlobId":"x3cb5ilt3QOYqeqAw5rnxfQ0U931UQan9IPV8FL1f8c"},{"id":"2412.00456","title":"Personal Sound Zones and Shielded Localized Communication through Active\n  Acoustic Control","authorsParsed":[["Egarguin","Neil Jerome A.",""],["Onofrei","Daniel",""]],"timestamp":1732968250000,"metadataBlobId":"LM8L1KzOySxSsf118ZC_6M2nTscVBaocWHjHtOFyhBs"},{"id":"2412.00571","title":"From Audio Deepfake Detection to AI-Generated Music Detection -- A\n  Pathway and Overview","authorsParsed":[["Li","Yupei",""],["Milling","Manuel",""],["Specia","Lucia",""],["Schuller","Björn W.",""]],"timestamp":1732996403000,"metadataBlobId":"r9F_EiBaZM54t6oVHiQxF-INkOUy6M2X0jAjP6WETWE"},{"id":"2412.00591","title":"Audio Atlas: Visualizing and Exploring Audio Datasets","authorsParsed":[["Lanzendörfer","Luca A.",""],["Grötschla","Florian",""],["Valizada","Uzeyir",""],["Wattenhofer","Roger",""]],"timestamp":1733002520000,"metadataBlobId":"aehdyTPsP8n1oWHfzeCGqmfAw1iIzcsSom1TxIVUwxY"},{"id":"2412.01100","title":"The Codec Language Model-based Zero-Shot Spontaneous Style TTS System\n  for CoVoC Challenge 2024","authorsParsed":[["Zhou","Shuoyi",""],["Zhou","Yixuan",""],["Li","Weiqin",""],["Chen","Jun",""],["Ye","Runchuan",""],["Wu","Weihao",""],["Lin","Zijian",""],["Lei","Shun",""],["Wu","Zhiyong",""]],"timestamp":1733113062000,"metadataBlobId":"Ak_RTU-vRWwJemF9vofmyuS5zWwq5ASf1BB4XV4kWQY"},{"id":"2412.01530","title":"Generative AI-based data augmentation for improved bioacoustic\n  classification in noisy environments","authorsParsed":[["Gibbons","Anthony",""],["King","Emma",""],["Donohue","Ian",""],["Parnell","Andrew",""]],"timestamp":1733149226000},{"id":"2412.03267","title":"Detecting abnormal heart sound using mobile phones and on-device IConNet","authorsParsed":[["Vu","Linh",""],["Tran","Thu",""]],"timestamp":1733314701000,"metadataBlobId":"ahjVUwicE4NA3P8GhekVRppbmp3UOCuyYH3rQSmdD9U"},{"id":"2412.03373","title":"Exploring trends in audio mixes and masters: Insights from a dataset\n  analysis","authorsParsed":[["Mourgela","Angeliki",""],["Quinton","Elio",""],["Bissas","Spyridon",""],["Reiss","Joshua D.",""],["Ronan","David",""]],"timestamp":1733324480000,"metadataBlobId":"9_N9BWlpzXcR4vpE8mLMKgwcR5BVlZUrq1yxjlaSkMg"},{"id":"2412.03633","title":"NBM: an Open Dataset for the Acoustic Monitoring of Nocturnal Migratory\n  Birds in Europe","authorsParsed":[["Airale","Louis",""],["Pajot","Adrien",""],["Linossier","Juliette",""]],"timestamp":1733338545000,"metadataBlobId":"lV_G1pz6UAd0hVgGHlP_kjkdLmpejqey42F9gbHD-0Q"},{"id":"2412.03784","title":"Speech Recognition-based Feature Extraction for Enhanced Automatic\n  Severity Classification in Dysarthric Speech","authorsParsed":[["Choi","Yerin",""],["Lee","Jeehyun",""],["Koo","Myoung-Wan",""]],"timestamp":1733357573000,"metadataBlobId":"VS9Dq-91ZrwR-jacZ3y3VG5_7WcJijE2Yy5MUzcgnjg"},{"id":"2412.03771","title":"Diffusion in Zero-Shot Learning for Environmental Audio","authorsParsed":[["Sims","Ysobel",""],["Chalup","Stephan",""],["Mendes","Alexandre",""]],"timestamp":1733354320000,"metadataBlobId":"6xyY0D_9hXExstrk_xf5DbQumEntweKMqnK9lHeLftc"},{"id":"2412.04100","title":"Missing Melodies: AI Music Generation and its \"Nearly\" Complete Omission\n  of the Global South","authorsParsed":[["Mehta","Atharva",""],["Chauhan","Shivam",""],["Choudhury","Monojit",""]],"timestamp":1733400642000,"metadataBlobId":"ljQ4dDAsYT_P4GEkfOJ_aCVQZ7F2Wn6ajtJaZ9biu2s"},{"id":"2412.04610","title":"Exploring Transformer-Based Music Overpainting for Jazz Piano Variations","authorsParsed":[["Row","Eleanor",""],["Shanin","Ivan",""],["Fazekas","György",""]],"timestamp":1733431703000,"metadataBlobId":"Utiq98rF-iOqlzeVP438mFAm1vOo8Hw00TQInPPpLhQ"},{"id":"2412.04746","title":"Diff4Steer: Steerable Diffusion Prior for Generative Music Retrieval\n  with Semantic Guidance","authorsParsed":[["Bao","Xuchan",""],["Li","Judith Yue",""],["Wan","Zhong Yi",""],["Su","Kun",""],["Denk","Timo",""],["Lee","Joonseok",""],["Kuzmin","Dima",""],["Sha","Fei",""]],"timestamp":1733455098000,"metadataBlobId":"Kmc8bkG3BABnk-jjx2iAD1TNbmymUxL7ONhUXIO2P8k"},{"id":"2412.04917","title":"Continuous Speech Tokens Makes LLMs Robust Multi-Modality Learners","authorsParsed":[["Yuan","Ze",""],["Liu","Yanqing",""],["Liu","Shujie",""],["Zhao","Sheng",""]],"timestamp":1733480164000,"metadataBlobId":"VD10mgoDqMQj3mh4dGnA_hua-o7Rvo18ounMMXEZ7xQ"},{"id":"2412.05558","title":"WavFusion: Towards wav2vec 2.0 Multimodal Speech Emotion Recognition","authorsParsed":[["Li","Feng",""],["Luo","Jiusong",""],["Xia","Wanjun",""]],"timestamp":1733553819000,"metadataBlobId":"jwsncYD_6DwhN9M2Uf81A5JSboJsaFkU_h2fg5dh9Xc"},{"id":"2412.05951","title":"When Vision Models Meet Parameter Efficient Look-Aside Adapters Without\n  Large-Scale Audio Pretraining","authorsParsed":[["Yeo","Juan",""],["Jang","Jinkwan",""],["Chae","Kyubyung",""],["Mun","Seongkyu",""],["Kim","Taesup",""]],"timestamp":1733667270000,"metadataBlobId":"jDB24GnYj7rKn1ykIvDvNw-Xv3hHXW7NWYZCSe6GBf8"},{"id":"2412.06001","title":"M6: Multi-generator, Multi-domain, Multi-lingual and cultural,\n  Multi-genres, Multi-instrument Machine-Generated Music Detection Databases","authorsParsed":[["Li","Yupei",""],["Li","Hanqian",""],["Specia","Lucia",""],["Schuller","Björn W.",""]],"timestamp":1733678583000,"metadataBlobId":"Ysr0O8RKZ5tPY0dqpb5qHfvV35do5LrXNvdenoQakP8"},{"id":"2412.06703","title":"Source Separation & Automatic Transcription for Music","authorsParsed":[["Derby","Bradford",""],["Dunker","Lucas",""],["Galchar","Samarth",""],["Jarmale","Shashank",""],["Setti","Akash",""]],"timestamp":1733766554000,"metadataBlobId":"5reLHsIaRHdE6N7JuABWl1IdtlpxoC1Md_9tJcn2jZ8"},{"id":"2412.06617","title":"AI TrackMate: Finally, Someone Who Will Give Your Music More Than Just\n  \"Sounds Great!\"","authorsParsed":[["Jiang","Yi-Lin",""],["Hsiung","Chia-Ho",""],["Yeh","Yen-Tung",""],["Chen","Lu-Rong",""],["Chen","Bo-Yu",""]],"timestamp":1733760584000,"metadataBlobId":"i5MQqS67UFGcIyBToiwYjjEpmYbNvcSlZzztIgH__A8"},{"id":"2412.06660","title":"MuMu-LLaMA: Multi-modal Music Understanding and Generation via Large\n  Language Models","authorsParsed":[["Liu","Shansong",""],["Hussain","Atin Sakkeer",""],["Wu","Qilong",""],["Sun","Chenshuo",""],["Shan","Ying",""]],"timestamp":1733763575000,"metadataBlobId":"Iqj73Ra-X7N2UvIKUVcBMNUO9wa4fB-dzVV17Mvk2Lg"},{"id":"2412.07316","title":"Preserving Speaker Information in Direct Speech-to-Speech Translation\n  with Non-Autoregressive Generation and Pretraining","authorsParsed":[["Zhou","Rui",""],["Ito","Akinori",""],["Nose","Takashi",""]],"timestamp":1733821131000,"metadataBlobId":"xAB__n-GBC607ZQhzHtyhyJ_t21O3Ovu9BebZG3bIcU"},{"id":"2412.07948","title":"Frechet Music Distance: A Metric For Generative Symbolic Music\n  Evaluation","authorsParsed":[["Retkowski","Jan",""],["Stępniak","Jakub",""],["Modrzejewski","Mateusz",""]],"timestamp":1733869339000,"metadataBlobId":"YqJy4cy05-pD0mN5jjBpTCegFH7-kfKvty930N71Y2M"},{"id":"2412.08117","title":"LatentSpeech: Latent Diffusion for Text-To-Speech Generation","authorsParsed":[["Lou","Haowei",""],["Paik","Helen",""],["Haghighi","Pari Delir",""],["Hu","Wen",""],["Yao","Lina",""]],"timestamp":1733896506000,"metadataBlobId":"wsUndOx2SeztdHcDMNW6fRXROzmRVLUWjVf2LI2xsRo"},{"id":"2412.08112","title":"Aligner-Guided Training Paradigm: Advancing Text-to-Speech Models with\n  Aligner Guided Duration","authorsParsed":[["Lou","Haowei",""],["Paik","Helen",""],["Hu","Wen",""],["Yao","Lina",""]],"timestamp":1733895552000,"metadataBlobId":"EGD-FJVHwIkt_fsm-OEsDKHKozHN7mBm1EGjnwNR79Q"},{"id":"2412.08356","title":"Zero-Shot Mono-to-Binaural Speech Synthesis","authorsParsed":[["Levkovitch","Alon",""],["Salazar","Julian",""],["Mariooryad","Soroosh",""],["Skerry-Ryan","RJ",""],["Bar","Nadav",""],["Kleijn","Bastiaan",""],["Nachmani","Eliya",""]],"timestamp":1733922049000,"metadataBlobId":"lXS3Af_LCrVeGnoADqln5dCQpwWi43DUMfLFWLRbka0"},{"id":"2412.08550","title":"Sketch2Sound: Controllable Audio Generation via Time-Varying Signals and\n  Sonic Imitations","authorsParsed":[["García","Hugo Flores",""],["Nieto","Oriol",""],["Salamon","Justin",""],["Pardo","Bryan",""],["Seetharaman","Prem",""]],"timestamp":1733937081000,"metadataBlobId":"43C_4j_LJLnFZVRKEo323Hg_ba0AcIorvAzb7d34XvQ"},{"id":"2412.08683","title":"Emotional Vietnamese Speech-Based Depression Diagnosis Using Dynamic\n  Attention Mechanism","authorsParsed":[["D.","Quang-Anh N.",""],["Ha","Manh-Hung",""],["Dinh","Thai Kim",""],["Pham","Minh-Duc",""],["Van","Ninh Nguyen",""]],"timestamp":1733943159000,"metadataBlobId":"oZS7fUnRjLPB7vKUWEmdxTe7Df-IKdAOZWW7kgyJI30"},{"id":"2412.08608","title":"AdvWave: Stealthy Adversarial Jailbreak Attack against Large\n  Audio-Language Models","authorsParsed":[["Kang","Mintong",""],["Xu","Chejian",""],["Li","Bo",""]],"timestamp":1733941857000,"metadataBlobId":"i2JkNn2j8qZFClg045FOp4Vmlaa6gY0x1ZXWqTEM84c"},{"id":"2412.09168","title":"YingSound: Video-Guided Sound Effects Generation with Multi-modal\n  Chain-of-Thought Controls","authorsParsed":[["Chen","Zihao",""],["Zhang","Haomin",""],["Di","Xinhan",""],["Wang","Haoyu",""],["Shan","Sizhe",""],["Zheng","Junjie",""],["Liang","Yunming",""],["Fan","Yihan",""],["Zhu","Xinfa",""],["Tian","Wenjie",""],["Wang","Yihua",""],["Ding","Chaofan",""],["Xie","Lei",""]],"timestamp":1734000957000,"metadataBlobId":"BHkbpLlO7Yyw4Jk38MjPcnXrbxXOcVwLujxz62ujbwU"},{"id":"2412.09317","title":"Multimodal Sentiment Analysis based on Video and Audio Inputs","authorsParsed":[["Fernandez","Antonio",""],["Awinat","Suzan",""]],"timestamp":1734014530000,"metadataBlobId":"dgfiC9rET6RTO7kPn07OTFfq3pTfzNQy8LeSz6YBlqQ"},{"id":"2412.09789","title":"SILA: Signal-to-Language Augmentation for Enhanced Control in\n  Text-to-Audio Generation","authorsParsed":[["Kumar","Sonal",""],["Seetharaman","Prem",""],["Salamon","Justin",""],["Manocha","Dinesh",""],["Nieto","Oriol",""]],"timestamp":1734055641000,"metadataBlobId":"2FFZijiLaqcCnx0813GYYnqhZCRiLvEMez0MiNoqmWc"},{"id":"2412.09928","title":"Leveraging Multimodal Methods and Spontaneous Speech for Alzheimer's\n  Disease Identification","authorsParsed":[["Gao","Yifan",""],["Guo","Long",""],["Liu","Hong",""]],"timestamp":1734074911000,"metadataBlobId":"PwaWZz3UTq-uNuX-kl2bLBeSTIsLaw7N871nLyzdQXs"},{"id":"2412.10011","title":"Enhanced Speech Emotion Recognition with Efficient Channel Attention\n  Guided Deep CNN-BiLSTM Framework","authorsParsed":[["Kundu","Niloy Kumar",""],["Kobir","Sarah",""],["Ahmed","Md. Rayhan",""],["Aktar","Tahmina",""],["Roy","Niloya",""]],"timestamp":1734083703000,"metadataBlobId":"NEFhJK8cDI488QEAj-P0T4hyTUA4weEr2VTB_zy_b3g"},{"id":"2412.10469","title":"Comparative Analysis of Mel-Frequency Cepstral Coefficients and Wavelet\n  Based Audio Signal Processing for Emotion Detection and Mental Health\n  Assessment in Spoken Speech","authorsParsed":[["Agbo","Idoko",""],["El-Sayed","Dr Hoda",""],["Sarker","M. D Kamruzzan",""]],"timestamp":1734044111000,"metadataBlobId":"rok0Jzm2Fsxb8rUQf5dulUs-rfNllxgRIP896anlCbI"},{"id":"2412.10649","title":"Hidden Echoes Survive Training in Audio To Audio Generative Instrument\n  Models","authorsParsed":[["Tralie","Christopher J.",""],["Amery","Matt",""],["Douglas","Benjamin",""],["Utz","Ian",""]],"timestamp":1734143805000,"metadataBlobId":"McTHHLJx333x7XsTyHEKq0id1UwFTwnkLmtUVLvTCuo"},{"id":"2412.10857","title":"Robust Persian Digit Recognition in Noisy Environments Using Hybrid\n  CNN-BiGRU Model","authorsParsed":[["Nasr-Esfahani","Ali",""],["Bekrani","Mehdi",""],["Rajabi","Roozbeh",""]],"timestamp":1734189102000,"metadataBlobId":"Ej9alSn2hYA5nJ5DTkXzvPHhdoOvUDS02uxafbUiS-4"},{"id":"2412.10968","title":"Composers' Evaluations of an AI Music Tool: Insights for Human-Centred\n  Design","authorsParsed":[["Row","Eleanor",""],["Fazekas","György",""]],"timestamp":1734209783000,"metadataBlobId":"S_ApBNHCeBhZ_fSahnIiZCha2W1WKIN2fhvTFodNLqc"},{"id":"2412.11272","title":"Efficient Whisper on Streaming Speech","authorsParsed":[["Wang","Rongxiang",""],["Xu","Zhiming",""],["Lin","Felix Xiaozhu",""]],"timestamp":1734287257000,"metadataBlobId":"az4YM-D3ySia0nfKNH6BNf04-ogc1qCpCzslOUNTPF8"},{"id":"2412.11551","title":"Region-Based Optimization in Continual Learning for Audio Deepfake\n  Detection","authorsParsed":[["Chen","Yujie",""],["Yi","Jiangyan",""],["Fan","Cunhang",""],["Tao","Jianhua",""],["Ren","Yong",""],["Zeng","Siding",""],["Zhang","Chu Yuan",""],["Yan","Xinrui",""],["Gu","Hao",""],["Xue","Jun",""],["Wang","Chenglong",""],["Lv","Zhao",""],["Zhang","Xiaohui",""]],"timestamp":1734338049000,"metadataBlobId":"4clRg3yr261-cIfG-XJmhvDsCT8ZLQ8v0WINnESceRQ"},{"id":"2412.11769","title":"Does it Chug? Towards a Data-Driven Understanding of Guitar Tone\n  Description","authorsParsed":[["Sutar","Pratik",""],["Naradowsky","Jason",""],["Miyao","Yusuke",""]],"timestamp":1734356659000,"metadataBlobId":"cXb9Z9x1bDa4-Lv8NEi5CXqBWGivx6DofF-Bb0c-4Fw"},{"id":"2412.12111","title":"Voice Biomarker Analysis and Automated Severity Classification of\n  Dysarthric Speech in a Multilingual Context","authorsParsed":[["Yeo","Eunjung",""]],"timestamp":1733011500000,"metadataBlobId":"U39ZiApUuTiEX3TZPZAm7sBiT1eRAfj9j-XQiLYhGcM"},{"id":"2412.12498","title":"Hierarchical Control of Emotion Rendering in Speech Synthesis","authorsParsed":[["Inoue","Sho",""],["Zhou","Kun",""],["Wang","Shuai",""],["Li","Haizhou",""]],"timestamp":1734404525000,"metadataBlobId":"6_KSyvVH3sUuTRDl0iPc5yDMa5LjyDnQBzUkIlT1yCI"},{"id":"2412.12395","title":"Sound Classification of Four Insect Classes","authorsParsed":[["Wang","Yinxuan",""],["Vhaduri","Sudip",""]],"timestamp":1734390208000,"metadataBlobId":"nP6edwNiAxykemODlPH5S_EBieJnEotU6Up-bKc6PBc"},{"id":"2412.12512","title":"Libri2Vox Dataset: Target Speaker Extraction with Diverse Speaker\n  Conditions and Synthetic Data","authorsParsed":[["Liu","Yun",""],["Liu","Xuechen",""],["Miao","Xiaoxiao",""],["Yamagishi","Junichi",""]],"timestamp":1734408413000,"metadataBlobId":"UngjcsG6ZaJ4DsQeRC1MN8lgOJdAFBvOi5Yl12sZODI"},{"id":"2412.12760","title":"CAMEL: Cross-Attention Enhanced Mixture-of-Experts and Language Bias for\n  Code-Switching Speech Recognition","authorsParsed":[["Wang","He",""],["Wan","Xucheng",""],["Zheng","Naijun",""],["Liu","Kai",""],["Zhou","Huan",""],["Li","Guojian",""],["Xie","Lei",""]],"timestamp":1734431106000,"metadataBlobId":"ET2fVd-1XKnA83gpQKsSvVoiFdXi-aSfQIBoh8QJTow"},{"id":"2412.13037","title":"TAME: Temporal Audio-based Mamba for Enhanced Drone Trajectory\n  Estimation and Classification","authorsParsed":[["Xiao","Zhenyuan",""],["Hu","Huanran",""],["Xu","Guili",""],["He","Junwei",""]],"timestamp":1734451231000,"metadataBlobId":"9QLTqN49sHXIJoPQoz_tpdvM53aJLdn3lvmp-ub6Bak"},{"id":"2412.13279","title":"Synthetic Speech Classification: IEEE Signal Processing Cup 2022\n  challenge","authorsParsed":[["Rahmun","Mahieyin",""],["Khan","Rafat Hasan",""],["Aurpa","Tanjim Taharat",""],["Khan","Sadia",""],["Nahiyan","Zulker Nayeen",""],["Almas","Mir Sayad Bin",""],["Rajib","Rakibul Hasan",""],["Hassan","Syeda Sakira",""]],"timestamp":1734462902000,"metadataBlobId":"D7OuP97tOcPRXkSRBXM1bKQ-FGy503pYh5mbBMrtqgc"},{"id":"2412.13421","title":"Detecting Machine-Generated Music with Explainability -- A Challenge and\n  Early Benchmarks","authorsParsed":[["Li","Yupei",""],["Sun","Qiyang",""],["Li","Hanqian",""],["Specia","Lucia",""],["Schuller","Björn W.",""]],"timestamp":1734485794000,"metadataBlobId":"-FmPaymLiiTtf7peKDfAW-j-o8enJ4EYz83oeZcxxNY"},{"id":"2412.13514","title":"Tuning Music Education: AI-Powered Personalization in Learning Music","authorsParsed":[["Sanganeria","Mayank",""],["Gala","Rohan",""]],"timestamp":1734499542000,"metadataBlobId":"IA_Oir5OAU_KIdNswSXQLmgqPYgGf5ZB4A4IDVlxci0"},{"id":"2412.15023","title":"Stable-V2A: Synthesis of Synchronized Sound Effects with Temporal and\n  Semantic Controls","authorsParsed":[["Gramaccioni","Riccardo Fosco",""],["Marinoni","Christian",""],["Postolache","Emilian",""],["Comunità","Marco",""],["Cosmo","Luca",""],["Reiss","Joshua D.",""],["Comminiello","Danilo",""]],"timestamp":1734626239000,"metadataBlobId":"oR-U6p2BcovWR6N9S2WlTs4ZIREU5wsYt8jqSxVG2Go"},{"id":"2412.16176","title":"Efficient VoIP Communications through LLM-based Real-Time Speech\n  Reconstruction and Call Prioritization for Emergency Services","authorsParsed":[["Venkateshperumal","Danush",""],["Rafi","Rahman Abdul",""],["Ahmed","Shakil",""],["Khokhar","Ashfaq",""]],"timestamp":1733764960000,"metadataBlobId":"1dsAAasDz0z38P-CuM_ZmPnvmwRcm3D_Sc96RHTh6Nc"},{"id":"2412.16182","title":"Decoding Poultry Vocalizations -- Natural Language Processing and\n  Transformer Models for Semantic and Emotional Analysis","authorsParsed":[["Manikandan","Venkatraman",""],["Neethirajan","Suresh",""]],"timestamp":1733899472000,"metadataBlobId":"RRO0X6UH1WWo_MzV_HfCFbukMFpFQHMNy87gNoC0mRk"},{"id":"2412.16267","title":"A Classification Benchmark for Artificial Intelligence Detection of\n  Laryngeal Cancer from Patient Speech","authorsParsed":[["Paterson","Mary",""],["Moor","James",""],["Cutillo","Luisa",""]],"timestamp":1734690843000,"metadataBlobId":"yiI8FvfMfZQwf7HwGstz60vPZdHfF2NgqFdCvy2kY5A"},{"id":"2412.16530","title":"Improving Lip-synchrony in Direct Audio-Visual Speech-to-Speech\n  Translation","authorsParsed":[["Goncalves","Lucas",""],["Mathur","Prashant",""],["Niu","Xing",""],["Houston","Brady",""],["Lavania","Chandrashekhar",""],["Vishnubhotla","Srikanth",""],["Sun","Lijia",""],["Ferritto","Anthony",""]],"timestamp":1734768952000,"metadataBlobId":"5P2ei6tlgjBfCLNO9sisQtL4fVR72VkNVYKYd4bhg4c"},{"id":"2412.16928","title":"AV-DTEC: Self-Supervised Audio-Visual Fusion for Drone Trajectory\n  Estimation and Classification","authorsParsed":[["Xiao","Zhenyuan",""],["Yang","Yizhuo",""],["Xu","Guili",""],["Zeng","Xianglong",""],["Yuan","Shenghai",""]],"timestamp":1734857895000,"metadataBlobId":"zLqIuGesVRQ9mAjqg0mAOr_YmXnhNRpYlpNJYxEZNpo"},{"id":"2412.16861","title":"SoundLoc3D: Invisible 3D Sound Source Localization and Classification\n  Using a Multimodal RGB-D Acoustic Camera","authorsParsed":[["He","Yuhang",""],["Shin","Sangyun",""],["Cherian","Anoop",""],["Trigoni","Niki",""],["Markham","Andrew",""]],"timestamp":1734843857000,"metadataBlobId":"UKgtPw3tbRs26w4Dc7FlniVWvVmC6FVKtd3piv9ZR6Q"},{"id":"2412.17212","title":"Trainingless Adaptation of Pretrained Models for Environmental Sound\n  Classification","authorsParsed":[["Tonami","Noriyuki",""],["Kohno","Wataru",""],["Imoto","Keisuke",""],["Yajima","Yoshiyuki",""],["Mishima","Sakiko",""],["Kondo","Reishi",""],["Hino","Tomoyuki",""]],"timestamp":1734918628000,"metadataBlobId":"tN3gPr2dq-Hr3PEKYCYvY6HJ0FoMOQR9XtO84obTCIg"},{"id":"2412.17306","title":"Multiple Consistency-guided Test-Time Adaptation for Contrastive\n  Audio-Language Models with Unlabeled Audio","authorsParsed":[["Chen","Gongyu",""],["Zhang","Haomin",""],["Ding","Chaofan",""],["Chen","Zihao",""],["Di","Xinhan",""]],"timestamp":1734933232000,"metadataBlobId":"VHFDAyJQOPOwVlMtMAqJFjkBjf37xsTTqPHDCLlIe7A"},{"id":"2412.17667","title":"VERSA: A Versatile Evaluation Toolkit for Speech, Audio, and Music","authorsParsed":[["Shi","Jiatong",""],["Shim","Hye-jin",""],["Tian","Jinchuan",""],["Arora","Siddhant",""],["Wu","Haibin",""],["Petermann","Darius",""],["Yip","Jia Qi",""],["Zhang","You",""],["Tang","Yuxun",""],["Zhang","Wangyou",""],["Alharthi","Dareen Safar",""],["Huang","Yichen",""],["Saito","Koichi",""],["Han","Jionghao",""],["Zhao","Yiwen",""],["Donahue","Chris",""],["Watanabe","Shinji",""]],"timestamp":1734969201000,"metadataBlobId":"VowI-p2R56DjyfRxqAf8gdxZ3xYeEgzCSdPI8ioGrUc"},{"id":"2412.17924","title":"Are audio DeepFake detection models polyglots?","authorsParsed":[["Marek","Bartłomiej",""],["Kawa","Piotr",""],["Syga","Piotr",""]],"timestamp":1734982373000,"metadataBlobId":"gunMeJExqhsamliEcUuuqPOFo_XvnIHT3Pz56E6sOAo"},{"id":"2412.18061","title":"Lla-VAP: LSTM Ensemble of Llama and VAP for Turn-Taking Prediction","authorsParsed":[["Jeon","Hyunbae",""],["Guintu","Frederic",""],["Sahni","Rayvant",""]],"timestamp":1734999638000,"metadataBlobId":"aIPpyrZBtk74iLOfQAIPF_8MnOPhqpA0U_uLw6B7-tM"},{"id":"2412.18217","title":"U-Mamba-Net: A highly efficient Mamba-based U-net style network for\n  noisy and reverberant speech separation","authorsParsed":[["Dang","Shaoxiang",""],["Matsumoto","Tetsuya",""],["Takeuchi","Yoshinori",""],["Kudo","Hiroaki",""]],"timestamp":1735023081000,"metadataBlobId":"Tq59Cq3pgtdDsJcGg9Vudd_WL6YdRmUu8KUR5oqFmc8"},{"id":"2412.18157","title":"Smooth-Foley: Creating Continuous Sound for Video-to-Audio Generation\n  Under Semantic Guidance","authorsParsed":[["Zhang","Yaoyun",""],["Xu","Xuenan",""],["Wu","Mengyue",""]],"timestamp":1735014586000,"metadataBlobId":"WkYtXKucddJt82i2DmkBTlqaZfgcIBPwMVWCUqUedro"},{"id":"2412.18191","title":"Explaining Speaker and Spoof Embeddings via Probing","authorsParsed":[["Liu","Xuechen",""],["Yamagishi","Junichi",""],["Sahidullah","Md",""],["kinnunen","Tomi",""]],"timestamp":1735019809000,"metadataBlobId":"fcrN6vSVPdh0Usk2u2s5aFetLU1ENR7Obqv63Mm2hck"},{"id":"2412.18836","title":"MRI2Speech: Speech Synthesis from Articulatory Movements Recorded by\n  Real-time MRI","authorsParsed":[["Shah","Neil",""],["Kashyap","Ayan",""],["Karande","Shirish",""],["Gandhi","Vineet",""]],"timestamp":1735116583000,"metadataBlobId":"rTmSI_H7AsMapdpUaxtAsd5CT-1q3INYRwBq3lHnhG0"},{"id":"2412.18710","title":"Simi-SFX: A similarity-based conditioning method for controllable sound\n  effect synthesis","authorsParsed":[["Liu","Yunyi",""],["Jin","Craig",""]],"timestamp":1735085690000,"metadataBlobId":"Fp3x2Qy1xUbbkpc2AruhpmKpAfiqr3xXKDuRIRtgQm0"},{"id":"2412.18839","title":"Advancing NAM-to-Speech Conversion with Novel Methods and the MultiNAM\n  Dataset","authorsParsed":[["Shah","Neil",""],["Karande","Shirish",""],["Gandhi","Vineet",""]],"timestamp":1735117044000,"metadataBlobId":"Km3OiaSTjrt7zjkn-6Vf_DjFDINpR5kn0rvUfEpF3FI"},{"id":"2412.18955","title":"Leave-One-EquiVariant: Alleviating invariance-related information loss\n  in contrastive music representations","authorsParsed":[["Guinot","Julien",""],["Quinton","Elio",""],["Fazekas","György",""]],"timestamp":1735150004000,"metadataBlobId":"Xd_blO3G_RA97k6kjVqNYs6SD-DlgpZpBLR5RjHU74o"},{"id":"2412.19123","title":"CoheDancers: Enhancing Interactive Group Dance Generation through\n  Music-Driven Coherence Decomposition","authorsParsed":[["Yang","Kaixing",""],["Tang","Xulong",""],["Wu","Haoyu",""],["Xue","Qinliang",""],["Qin","Biao",""],["Liu","Hongyan",""],["Fan","Zhaoxin",""]],"timestamp":1735202833000,"metadataBlobId":"CLjALriBQP9O5s8LZuTWW_LZaXyAv0P64Pn26BAXjTA"},{"id":"2412.19200","title":"Personalized Dynamic Music Emotion Recognition with Dual-Scale\n  Attention-Based Meta-Learning","authorsParsed":[["Zhang","Dengming",""],["You","Weitao",""],["Liu","Ziheng",""],["Sun","Lingyun",""],["Chen","Pei",""]],"timestamp":1735217255000,"metadataBlobId":"eOxxoitRb5P7r8OxxJXL6SQM_pQYkGwTBbZrzAG_rQA"},{"id":"2412.19351","title":"ETTA: Elucidating the Design Space of Text-to-Audio Models","authorsParsed":[["Lee","Sang-gil",""],["Kong","Zhifeng",""],["Goel","Arushi",""],["Kim","Sungwon",""],["Valle","Rafael",""],["Catanzaro","Bryan",""]],"timestamp":1735247592000,"metadataBlobId":"XoTQI62mKUF7O5cU5DFQ-JD3gFTo4DRlxmUzIVrd8iE"},{"id":"2412.19909","title":"Mouth Articulation-Based Anchoring for Improved Cross-Corpus Speech\n  Emotion Recognition","authorsParsed":[["Upadhyay","Shreya G.",""],["Salman","Ali N.",""],["Busso","Carlos",""],["Lee","Chi-Chun",""]],"timestamp":1735329645000,"metadataBlobId":"KcRD88xDqUzVEJqWInX9UFNZyIVxGAG5CqTa1CP4iPQ"},{"id":"2412.20155","title":"Stable-TTS: Stable Speaker-Adaptive Text-to-Speech Synthesis via Prosody\n  Prompting","authorsParsed":[["Han","Wooseok",""],["Kang","Minki",""],["Kim","Changhun",""],["Yang","Eunho",""]],"timestamp":1735394070000,"metadataBlobId":"sTcRgIxya-QUHRSUY0gNus5N2SipN6EO2xV_m5TI9uI"},{"id":"2412.21037","title":"TangoFlux: Super Fast and Faithful Text to Audio Generation with Flow\n  Matching and Clap-Ranked Preference Optimization","authorsParsed":[["Hung","Chia-Yu",""],["Majumder","Navonil",""],["Kong","Zhifeng",""],["Mehrish","Ambuj",""],["Valle","Rafael",""],["Catanzaro","Bryan",""],["Poria","Soujanya",""]],"timestamp":1735574564000,"metadataBlobId":"bQM-eb86sT98s_S5o-9nGBr-CI13J2yMkg6z-fYtkfE"}]