[{"id":"2412.00319","title":"Improving speaker verification robustness with synthetic emotional\n  utterances","authorsParsed":[["Koditala","Nikhil Kumar",""],["Ju","Chelsea Jui-Ting",""],["Li","Ruirui",""],["Jin","Minho",""],["Chadha","Aman",""],["Stolcke","Andreas",""]],"timestamp":1732933106000,"metadataBlobId":"qVbST4JIwrB93p3HZnBO-LALw6ofvmUso2idoGox1io"},{"id":"2412.00325","title":"MusicGen-Chord: Advancing Music Generation through Chord Progressions\n  and Interactive Web-UI","authorsParsed":[["Jung","Jongmin",""],["Jansson","Andreas",""],["Jeong","Dasaem",""]],"timestamp":1732934985000,"metadataBlobId":"QFtHYBKoTthHuP1qvAEXII1L_dVv47Av-ODjkXmTUx4"},{"id":"2412.00456","title":"Personal Sound Zones and Shielded Localized Communication through Active\n  Acoustic Control","authorsParsed":[["Egarguin","Neil Jerome A.",""],["Onofrei","Daniel",""]],"timestamp":1732968250000,"metadataBlobId":"xVlWvjAD1DhEzuxG0bO5kXUrNNi4921U3DVewqZ0xWw"},{"id":"2412.00571","title":"From Audio Deepfake Detection to AI-Generated Music Detection -- A\n  Pathway and Overview","authorsParsed":[["Li","Yupei",""],["Milling","Manuel",""],["Specia","Lucia",""],["Schuller","Björn W.",""]],"timestamp":1732996403000,"metadataBlobId":"kj1DMElmFPxqqVCOx47T97EqQt2W1ip7DHS1R__ugyA"},{"id":"2412.00591","title":"Audio Atlas: Visualizing and Exploring Audio Datasets","authorsParsed":[["Lanzendörfer","Luca A.",""],["Grötschla","Florian",""],["Valizada","Uzeyir",""],["Wattenhofer","Roger",""]],"timestamp":1733002520000,"metadataBlobId":"lixS0tMoB_tLrzXOSc_4l1qX9P3UMCDYSdsoVlmXYNo"},{"id":"2412.01100","title":"The Codec Language Model-based Zero-Shot Spontaneous Style TTS System\n  for CoVoC Challenge 2024","authorsParsed":[["Zhou","Shuoyi",""],["Zhou","Yixuan",""],["Li","Weiqin",""],["Chen","Jun",""],["Ye","Runchuan",""],["Wu","Weihao",""],["Lin","Zijian",""],["Lei","Shun",""],["Wu","Zhiyong",""]],"timestamp":1733113062000,"metadataBlobId":"e05P8S_aTzB4HA6FK86V6WV97VXm0GoI1lPcLOIiFSA"},{"id":"2412.01530","title":"Generative AI-based data augmentation for improved bioacoustic\n  classification in noisy environments","authorsParsed":[["Gibbons","Anthony",""],["King","Emma",""],["Donohue","Ian",""],["Parnell","Andrew",""]],"timestamp":1733149226000,"metadataBlobId":"sAmOhGuN0mUxKOn87kgTfljEObAWSrJfjQafq_DGWnc"},{"id":"2412.03267","title":"Detecting abnormal heart sound using mobile phones and on-device IConNet","authorsParsed":[["Vu","Linh",""],["Tran","Thu",""]],"timestamp":1733314701000,"metadataBlobId":"pGnYcvAbhc5tnV2v7Kv_Qv9tJJfSkV6F2W8Y4tlEfKk"},{"id":"2412.03373","title":"Exploring trends in audio mixes and masters: Insights from a dataset\n  analysis","authorsParsed":[["Mourgela","Angeliki",""],["Quinton","Elio",""],["Bissas","Spyridon",""],["Reiss","Joshua D.",""],["Ronan","David",""]],"timestamp":1733324480000,"metadataBlobId":"aSZwTHWrMNHugXR9aSqyUsJ9zJLjECP4qzVlUVs4S-Y"},{"id":"2412.03633","title":"NBM: an Open Dataset for the Acoustic Monitoring of Nocturnal Migratory\n  Birds in Europe","authorsParsed":[["Airale","Louis",""],["Pajot","Adrien",""],["Linossier","Juliette",""]],"timestamp":1733338545000,"metadataBlobId":"-EjYJSCwyYfhd0nToVPl5Neg-faxoM19vQiuiNPbQdE"},{"id":"2412.03784","title":"Speech Recognition-based Feature Extraction for Enhanced Automatic\n  Severity Classification in Dysarthric Speech","authorsParsed":[["Choi","Yerin",""],["Lee","Jeehyun",""],["Koo","Myoung-Wan",""]],"timestamp":1733357573000,"metadataBlobId":"s_X-E9QMtqrHCGXvbLlWObjsm1IvpR4xh2IkAg95hsQ"},{"id":"2412.03771","title":"Diffusion in Zero-Shot Learning for Environmental Audio","authorsParsed":[["Sims","Ysobel",""],["Chalup","Stephan",""],["Mendes","Alexandre",""]],"timestamp":1733354320000,"metadataBlobId":"d-okkO_V0k-AyJnpIzB1o8HzDYCwBCrh5eJdqDjvrnY"},{"id":"2412.04100","title":"Missing Melodies: AI Music Generation and its \"Nearly\" Complete Omission\n  of the Global South","authorsParsed":[["Mehta","Atharva",""],["Chauhan","Shivam",""],["Choudhury","Monojit",""]],"timestamp":1733400642000,"metadataBlobId":"y0xiqNymsxMPUU9lSTs4yujeoXF3UuEE94A0k82I6d0"},{"id":"2412.04610","title":"Exploring Transformer-Based Music Overpainting for Jazz Piano Variations","authorsParsed":[["Row","Eleanor",""],["Shanin","Ivan",""],["Fazekas","György",""]],"timestamp":1733431703000,"metadataBlobId":"OjkSaP4en2LZkt7ipnIwG6zh-_DQ9XB8Ggwsq5sM9Dk"},{"id":"2412.04746","title":"Diff4Steer: Steerable Diffusion Prior for Generative Music Retrieval\n  with Semantic Guidance","authorsParsed":[["Bao","Xuchan",""],["Li","Judith Yue",""],["Wan","Zhong Yi",""],["Su","Kun",""],["Denk","Timo",""],["Lee","Joonseok",""],["Kuzmin","Dima",""],["Sha","Fei",""]],"timestamp":1733455098000,"metadataBlobId":"MpNdN-kz_zbv9iOIEHyki7K6o3YpwC8zOKSefXMAMkI"},{"id":"2412.04917","title":"Continuous Speech Tokens Makes LLMs Robust Multi-Modality Learners","authorsParsed":[["Yuan","Ze",""],["Liu","Yanqing",""],["Liu","Shujie",""],["Zhao","Sheng",""]],"timestamp":1733480164000,"metadataBlobId":"rDRfr2y1lv8Vx8M47p0Hr6b-dYzsIKLHWNWrsI6YjK4"},{"id":"2412.05558","title":"WavFusion: Towards wav2vec 2.0 Multimodal Speech Emotion Recognition","authorsParsed":[["Li","Feng",""],["Luo","Jiusong",""],["Xia","Wanjun",""]],"timestamp":1733553819000,"metadataBlobId":"fzEAoT-xdwo_ZkYPM13mZscFv-V9b-ZfNwMS0qSIFuc"},{"id":"2412.05951","title":"When Vision Models Meet Parameter Efficient Look-Aside Adapters Without\n  Large-Scale Audio Pretraining","authorsParsed":[["Yeo","Juan",""],["Jang","Jinkwan",""],["Chae","Kyubyung",""],["Mun","Seongkyu",""],["Kim","Taesup",""]],"timestamp":1733667270000,"metadataBlobId":"ikfJZVoYi3Hqk2h0dM0TZoUlwhcUn6ol2YE9FY7GuZo"},{"id":"2412.06001","title":"M6: Multi-generator, Multi-domain, Multi-lingual and cultural,\n  Multi-genres, Multi-instrument Machine-Generated Music Detection Databases","authorsParsed":[["Li","Yupei",""],["Li","Hanqian",""],["Specia","Lucia",""],["Schuller","Björn W.",""]],"timestamp":1733678583000,"metadataBlobId":"lfy0Z92JV-kP-mhsVx43FUa2eMjT-Q-UCzYuRfiH5_4"},{"id":"2412.06703","title":"Source Separation & Automatic Transcription for Music","authorsParsed":[["Derby","Bradford",""],["Dunker","Lucas",""],["Galchar","Samarth",""],["Jarmale","Shashank",""],["Setti","Akash",""]],"timestamp":1733766554000,"metadataBlobId":"casusuYAbvrXPwiXuDhfRcBD-PSp4sBEjm5MpPxdOH4"},{"id":"2412.06617","title":"AI TrackMate: Finally, Someone Who Will Give Your Music More Than Just\n  \"Sounds Great!\"","authorsParsed":[["Jiang","Yi-Lin",""],["Hsiung","Chia-Ho",""],["Yeh","Yen-Tung",""],["Chen","Lu-Rong",""],["Chen","Bo-Yu",""]],"timestamp":1733760584000,"metadataBlobId":"enlDwrdvr6E7-wOlt3_6uZ0heqiEzjmi3ss5wYDiH4o"},{"id":"2412.06660","title":"MuMu-LLaMA: Multi-modal Music Understanding and Generation via Large\n  Language Models","authorsParsed":[["Liu","Shansong",""],["Hussain","Atin Sakkeer",""],["Wu","Qilong",""],["Sun","Chenshuo",""],["Shan","Ying",""]],"timestamp":1733763575000,"metadataBlobId":"jNyQAaXjvrtot-5XfLjE7pHlcVnVTjgpx7Xud2cHSG0"},{"id":"2412.07316","title":"Preserving Speaker Information in Direct Speech-to-Speech Translation\n  with Non-Autoregressive Generation and Pretraining","authorsParsed":[["Zhou","Rui",""],["Ito","Akinori",""],["Nose","Takashi",""]],"timestamp":1733821131000,"metadataBlobId":"7KAhSZtrMcsWMeCMhBECIma3wPaG0lZPvLgp6Th36sk"},{"id":"2412.07948","title":"Frechet Music Distance: A Metric For Generative Symbolic Music\n  Evaluation","authorsParsed":[["Retkowski","Jan",""],["Stępniak","Jakub",""],["Modrzejewski","Mateusz",""]],"timestamp":1733869339000,"metadataBlobId":"ce6dPkBn_CHpdRue7n6o4J7UEZAsRbs4UG3pYCFGWZE"},{"id":"2412.08117","title":"LatentSpeech: Latent Diffusion for Text-To-Speech Generation","authorsParsed":[["Lou","Haowei",""],["Paik","Helen",""],["Haghighi","Pari Delir",""],["Hu","Wen",""],["Yao","Lina",""]],"timestamp":1733896506000,"metadataBlobId":"S8_39_9UAv6Wm3yevccmm9zELA6pMZ2pqzmKlZ8CdRQ"},{"id":"2412.08112","title":"Aligner-Guided Training Paradigm: Advancing Text-to-Speech Models with\n  Aligner Guided Duration","authorsParsed":[["Lou","Haowei",""],["Paik","Helen",""],["Hu","Wen",""],["Yao","Lina",""]],"timestamp":1733895552000,"metadataBlobId":"_h8akxtc5lgrKnbIrLqPFq-RvLXPtXlChwOZj33zAC0"},{"id":"2412.08356","title":"Zero-Shot Mono-to-Binaural Speech Synthesis","authorsParsed":[["Levkovitch","Alon",""],["Salazar","Julian",""],["Mariooryad","Soroosh",""],["Skerry-Ryan","RJ",""],["Bar","Nadav",""],["Kleijn","Bastiaan",""],["Nachmani","Eliya",""]],"timestamp":1733922049000,"metadataBlobId":"Hq7XQ9E9RlpgmSowzv9gr2Q3rogYpmV7UX4erAQxMk4"},{"id":"2412.08550","title":"Sketch2Sound: Controllable Audio Generation via Time-Varying Signals and\n  Sonic Imitations","authorsParsed":[["García","Hugo Flores",""],["Nieto","Oriol",""],["Salamon","Justin",""],["Pardo","Bryan",""],["Seetharaman","Prem",""]],"timestamp":1733937081000,"metadataBlobId":"AnSCoVm6ZcTIJda2k1qcCNPeQXagrROrwBTtVjK9yTs"},{"id":"2412.08683","title":"Emotional Vietnamese Speech-Based Depression Diagnosis Using Dynamic\n  Attention Mechanism","authorsParsed":[["D.","Quang-Anh N.",""],["Ha","Manh-Hung",""],["Dinh","Thai Kim",""],["Pham","Minh-Duc",""],["Van","Ninh Nguyen",""]],"timestamp":1733943159000,"metadataBlobId":"xrCZLHWQfhPP5_XplUDQWKFt39VdolffNkNbleyOpUw"},{"id":"2412.08608","title":"AdvWave: Stealthy Adversarial Jailbreak Attack against Large\n  Audio-Language Models","authorsParsed":[["Kang","Mintong",""],["Xu","Chejian",""],["Li","Bo",""]],"timestamp":1733941857000,"metadataBlobId":"fJeZ1JhBTX7oOJh9_e6RY0JMehMfFea587ogTE-B5wc"},{"id":"2412.09168","title":"YingSound: Video-Guided Sound Effects Generation with Multi-modal\n  Chain-of-Thought Controls","authorsParsed":[["Chen","Zihao",""],["Zhang","Haomin",""],["Di","Xinhan",""],["Wang","Haoyu",""],["Shan","Sizhe",""],["Zheng","Junjie",""],["Liang","Yunming",""],["Fan","Yihan",""],["Zhu","Xinfa",""],["Tian","Wenjie",""],["Wang","Yihua",""],["Ding","Chaofan",""],["Xie","Lei",""]],"timestamp":1734000957000,"metadataBlobId":"hogSSLAV_s1UvyBSNimS9MkTrH5DRkXIohueB5sMgkg"},{"id":"2412.09317","title":"Multimodal Sentiment Analysis based on Video and Audio Inputs","authorsParsed":[["Fernandez","Antonio",""],["Awinat","Suzan",""]],"timestamp":1734014530000,"metadataBlobId":"9wL581N28G0CjVcjcspQ8FuHckZiKINnBbENgIDpwW8"},{"id":"2412.09789","title":"SILA: Signal-to-Language Augmentation for Enhanced Control in\n  Text-to-Audio Generation","authorsParsed":[["Kumar","Sonal",""],["Seetharaman","Prem",""],["Salamon","Justin",""],["Manocha","Dinesh",""],["Nieto","Oriol",""]],"timestamp":1734055641000,"metadataBlobId":"5niug-LBAqlve2m2eXzQQFXbLJiwvdvc0I3f2sv6m80"},{"id":"2412.09928","title":"Leveraging Multimodal Methods and Spontaneous Speech for Alzheimer's\n  Disease Identification","authorsParsed":[["Gao","Yifan",""],["Guo","Long",""],["Liu","Hong",""]],"timestamp":1734074911000,"metadataBlobId":"x-dxH8j5IuW_4nIkGguC7IfcR6a8HU9P5qEuKM0irrU"},{"id":"2412.10011","title":"Enhanced Speech Emotion Recognition with Efficient Channel Attention\n  Guided Deep CNN-BiLSTM Framework","authorsParsed":[["Kundu","Niloy Kumar",""],["Kobir","Sarah",""],["Ahmed","Md. Rayhan",""],["Aktar","Tahmina",""],["Roy","Niloya",""]],"timestamp":1734083703000,"metadataBlobId":"8cbgETnwUSAO-5YeijAH18pis2ToNR1Qy35J1FnSAX0"},{"id":"2412.10469","title":"Comparative Analysis of Mel-Frequency Cepstral Coefficients and Wavelet\n  Based Audio Signal Processing for Emotion Detection and Mental Health\n  Assessment in Spoken Speech","authorsParsed":[["Agbo","Idoko",""],["El-Sayed","Dr Hoda",""],["Sarker","M. D Kamruzzan",""]],"timestamp":1734044111000,"metadataBlobId":"UISKa-fe_G2TxqgtMRD62Ias08v1Lvdy7niPhxVUBg4"},{"id":"2412.10649","title":"Hidden Echoes Survive Training in Audio To Audio Generative Instrument\n  Models","authorsParsed":[["Tralie","Christopher J.",""],["Amery","Matt",""],["Douglas","Benjamin",""],["Utz","Ian",""]],"timestamp":1734143805000,"metadataBlobId":"8WGmhpTG92HXlj02g7yCf_sie2nf4TBW0GQ66YF5hck"},{"id":"2412.10857","title":"Robust Persian Digit Recognition in Noisy Environments Using Hybrid\n  CNN-BiGRU Model","authorsParsed":[["Nasr-Esfahani","Ali",""],["Bekrani","Mehdi",""],["Rajabi","Roozbeh",""]],"timestamp":1734189102000,"metadataBlobId":"swp3gK7Q5T3cNUCK-usAMqHpjL1G_Sb1o8uZ5OAnxjw"},{"id":"2412.10968","title":"Composers' Evaluations of an AI Music Tool: Insights for Human-Centred\n  Design","authorsParsed":[["Row","Eleanor",""],["Fazekas","György",""]],"timestamp":1734209783000,"metadataBlobId":"vauPiowybYNRNrrnktW87-AeUgVLJCur6KjJd91EmnM"},{"id":"2412.11272","title":"Efficient Whisper on Streaming Speech","authorsParsed":[["Wang","Rongxiang",""],["Xu","Zhiming",""],["Lin","Felix Xiaozhu",""]],"timestamp":1734287257000,"metadataBlobId":"tJOh_pmy-oOK5yECznaRQrZ-inNUgLw4dBpbtHnUX1w"},{"id":"2412.11551","title":"Region-Based Optimization in Continual Learning for Audio Deepfake\n  Detection","authorsParsed":[["Chen","Yujie",""],["Yi","Jiangyan",""],["Fan","Cunhang",""],["Tao","Jianhua",""],["Ren","Yong",""],["Zeng","Siding",""],["Zhang","Chu Yuan",""],["Yan","Xinrui",""],["Gu","Hao",""],["Xue","Jun",""],["Wang","Chenglong",""],["Lv","Zhao",""],["Zhang","Xiaohui",""]],"timestamp":1734338049000,"metadataBlobId":"KlkMUMZ9BXpk1nmuXleXEz9BG098Lxx1x42Bjw5sQtw"},{"id":"2412.11769","title":"Does it Chug? Towards a Data-Driven Understanding of Guitar Tone\n  Description","authorsParsed":[["Sutar","Pratik",""],["Naradowsky","Jason",""],["Miyao","Yusuke",""]],"timestamp":1734356659000,"metadataBlobId":"HjSdR6XyR03XZs4ivYxLoOdCtzs1z4tFqXNx-UCqlUQ"},{"id":"2412.12111","title":"Voice Biomarker Analysis and Automated Severity Classification of\n  Dysarthric Speech in a Multilingual Context","authorsParsed":[["Yeo","Eunjung",""]],"timestamp":1733011500000,"metadataBlobId":"gMtgy-8kUphpL3tNWrNlw0-ZVztfXuej_PaVysRLvPQ"},{"id":"2412.12498","title":"Hierarchical Control of Emotion Rendering in Speech Synthesis","authorsParsed":[["Inoue","Sho",""],["Zhou","Kun",""],["Wang","Shuai",""],["Li","Haizhou",""]],"timestamp":1734404525000,"metadataBlobId":"NfpwkstgpZWQlbjoJu8zz5qClSdYGONhSbKELWTUNvA"},{"id":"2412.12395","title":"Sound Classification of Four Insect Classes","authorsParsed":[["Wang","Yinxuan",""],["Vhaduri","Sudip",""]],"timestamp":1734390208000,"metadataBlobId":"KyeFvj01PdB8BNn872PRNZ27PPqTHWfOLNunzl2ryWc"},{"id":"2412.12512","title":"Libri2Vox Dataset: Target Speaker Extraction with Diverse Speaker\n  Conditions and Synthetic Data","authorsParsed":[["Liu","Yun",""],["Liu","Xuechen",""],["Miao","Xiaoxiao",""],["Yamagishi","Junichi",""]],"timestamp":1734408413000,"metadataBlobId":"1hPJklOrK_Z3T4Y-KLvT4E24Au0zt5W20Y44tAKiXcw"},{"id":"2412.12760","title":"CAMEL: Cross-Attention Enhanced Mixture-of-Experts and Language Bias for\n  Code-Switching Speech Recognition","authorsParsed":[["Wang","He",""],["Wan","Xucheng",""],["Zheng","Naijun",""],["Liu","Kai",""],["Zhou","Huan",""],["Li","Guojian",""],["Xie","Lei",""]],"timestamp":1734431106000,"metadataBlobId":"JIHpxADErGONC0K1NNDdBbkXL1F1tmq-SxGjM7qDnUE"},{"id":"2412.13037","title":"TAME: Temporal Audio-based Mamba for Enhanced Drone Trajectory\n  Estimation and Classification","authorsParsed":[["Xiao","Zhenyuan",""],["Hu","Huanran",""],["Xu","Guili",""],["He","Junwei",""]],"timestamp":1734451231000,"metadataBlobId":"O-hxzmakBCKcuXXBO_21ZHYglU96BtRIa-n94tA_nqo"},{"id":"2412.13279","title":"Synthetic Speech Classification: IEEE Signal Processing Cup 2022\n  challenge","authorsParsed":[["Rahmun","Mahieyin",""],["Khan","Rafat Hasan",""],["Aurpa","Tanjim Taharat",""],["Khan","Sadia",""],["Nahiyan","Zulker Nayeen",""],["Almas","Mir Sayad Bin",""],["Rajib","Rakibul Hasan",""],["Hassan","Syeda Sakira",""]],"timestamp":1734462902000,"metadataBlobId":"GqFgcZDuA2XpeElNv4EVgAxaVnAHl7Cih9IS5hDQKQk"},{"id":"2412.13421","title":"Detecting Machine-Generated Music with Explainability -- A Challenge and\n  Early Benchmarks","authorsParsed":[["Li","Yupei",""],["Sun","Qiyang",""],["Li","Hanqian",""],["Specia","Lucia",""],["Schuller","Björn W.",""]],"timestamp":1734485794000,"metadataBlobId":"iMfOKB52yRIbau1g5knRGbxhPWT-jqIrsZIn1QXYfDU"},{"id":"2412.13514","title":"Tuning Music Education: AI-Powered Personalization in Learning Music","authorsParsed":[["Sanganeria","Mayank",""],["Gala","Rohan",""]],"timestamp":1734499542000,"metadataBlobId":"_60T7qOSKxXxzwJ5Pf0po2fEMFnXQLUOeyNwg2NQWso"},{"id":"2412.15023","title":"Stable-V2A: Synthesis of Synchronized Sound Effects with Temporal and\n  Semantic Controls","authorsParsed":[["Gramaccioni","Riccardo Fosco",""],["Marinoni","Christian",""],["Postolache","Emilian",""],["Comunità","Marco",""],["Cosmo","Luca",""],["Reiss","Joshua D.",""],["Comminiello","Danilo",""]],"timestamp":1734626239000,"metadataBlobId":"KzJ-iyy7JbEhvKtGHNO7vujqvJPBurxew3yDIWL2Mp0"},{"id":"2412.16176","title":"Efficient VoIP Communications through LLM-based Real-Time Speech\n  Reconstruction and Call Prioritization for Emergency Services","authorsParsed":[["Venkateshperumal","Danush",""],["Rafi","Rahman Abdul",""],["Ahmed","Shakil",""],["Khokhar","Ashfaq",""]],"timestamp":1733764960000,"metadataBlobId":"72vDfHrjOOLgA2SzohG8JYorST02Lj82JBDvYHfmfGM"},{"id":"2412.16182","title":"Decoding Poultry Vocalizations -- Natural Language Processing and\n  Transformer Models for Semantic and Emotional Analysis","authorsParsed":[["Manikandan","Venkatraman",""],["Neethirajan","Suresh",""]],"timestamp":1733899472000,"metadataBlobId":"3tKpuEB6YxWXP7kX1fTV140TW9F-pbGIHbb1eiAdshg"},{"id":"2412.16267","title":"A Classification Benchmark for Artificial Intelligence Detection of\n  Laryngeal Cancer from Patient Speech","authorsParsed":[["Paterson","Mary",""],["Moor","James",""],["Cutillo","Luisa",""]],"timestamp":1734690843000,"metadataBlobId":"oj69cuG7E0YrpZqzt3UmKMSZk_6bIJhTEwhjaxCvesE"},{"id":"2412.16530","title":"Improving Lip-synchrony in Direct Audio-Visual Speech-to-Speech\n  Translation","authorsParsed":[["Goncalves","Lucas",""],["Mathur","Prashant",""],["Niu","Xing",""],["Houston","Brady",""],["Lavania","Chandrashekhar",""],["Vishnubhotla","Srikanth",""],["Sun","Lijia",""],["Ferritto","Anthony",""]],"timestamp":1734768952000,"metadataBlobId":"o9EwZ2XV2qNvYlkRxsFwVGMTAmw-ig-m6RHUJgSqvjU"},{"id":"2412.16928","title":"AV-DTEC: Self-Supervised Audio-Visual Fusion for Drone Trajectory\n  Estimation and Classification","authorsParsed":[["Xiao","Zhenyuan",""],["Yang","Yizhuo",""],["Xu","Guili",""],["Zeng","Xianglong",""],["Yuan","Shenghai",""]],"timestamp":1734857895000,"metadataBlobId":"mn3txRu9PLNNwyVzLI9jkUIK70CNlQTea2-NVz2Noyo"},{"id":"2412.16861","title":"SoundLoc3D: Invisible 3D Sound Source Localization and Classification\n  Using a Multimodal RGB-D Acoustic Camera","authorsParsed":[["He","Yuhang",""],["Shin","Sangyun",""],["Cherian","Anoop",""],["Trigoni","Niki",""],["Markham","Andrew",""]],"timestamp":1734843857000,"metadataBlobId":"_4kFNy734ujGzUFknWcPdqJozSJDE2pHqNT6ANpVHjs"},{"id":"2412.17212","title":"Trainingless Adaptation of Pretrained Models for Environmental Sound\n  Classification","authorsParsed":[["Tonami","Noriyuki",""],["Kohno","Wataru",""],["Imoto","Keisuke",""],["Yajima","Yoshiyuki",""],["Mishima","Sakiko",""],["Kondo","Reishi",""],["Hino","Tomoyuki",""]],"timestamp":1734918628000,"metadataBlobId":"a_eT_viEen8hXINgc1znMNXcFu379aDZrsasniURKWY"},{"id":"2412.17306","title":"Multiple Consistency-guided Test-Time Adaptation for Contrastive\n  Audio-Language Models with Unlabeled Audio","authorsParsed":[["Chen","Gongyu",""],["Zhang","Haomin",""],["Ding","Chaofan",""],["Chen","Zihao",""],["Di","Xinhan",""]],"timestamp":1734933232000,"metadataBlobId":"LvTf2owuj7FBeDLtXn9Z-xD08O1hkDB5yrAFYhHFWFQ"},{"id":"2412.17667","title":"VERSA: A Versatile Evaluation Toolkit for Speech, Audio, and Music","authorsParsed":[["Shi","Jiatong",""],["Shim","Hye-jin",""],["Tian","Jinchuan",""],["Arora","Siddhant",""],["Wu","Haibin",""],["Petermann","Darius",""],["Yip","Jia Qi",""],["Zhang","You",""],["Tang","Yuxun",""],["Zhang","Wangyou",""],["Alharthi","Dareen Safar",""],["Huang","Yichen",""],["Saito","Koichi",""],["Han","Jionghao",""],["Zhao","Yiwen",""],["Donahue","Chris",""],["Watanabe","Shinji",""]],"timestamp":1734969201000,"metadataBlobId":"bQXZkOTR9oOf3ZaESd8IjUGxqVMS2HdkS3OhVMpf8hs"},{"id":"2412.17924","title":"Are audio DeepFake detection models polyglots?","authorsParsed":[["Marek","Bartłomiej",""],["Kawa","Piotr",""],["Syga","Piotr",""]],"timestamp":1734982373000,"metadataBlobId":"D8RGox69EXOhEj0bsVWE8uNZ92ClDnTRLj4EornFfkg"},{"id":"2412.18061","title":"Lla-VAP: LSTM Ensemble of Llama and VAP for Turn-Taking Prediction","authorsParsed":[["Jeon","Hyunbae",""],["Guintu","Frederic",""],["Sahni","Rayvant",""]],"timestamp":1734999638000,"metadataBlobId":"IUqKu8CNozugGx_PrauRW-yDOR4zniqQdlwSnwjNQis"},{"id":"2412.18217","title":"U-Mamba-Net: A highly efficient Mamba-based U-net style network for\n  noisy and reverberant speech separation","authorsParsed":[["Dang","Shaoxiang",""],["Matsumoto","Tetsuya",""],["Takeuchi","Yoshinori",""],["Kudo","Hiroaki",""]],"timestamp":1735023081000,"metadataBlobId":"lAuXtjAkpOECj-TTnyFnRm7x2S9PupMJaqxLaW0yiMo"},{"id":"2412.18157","title":"Smooth-Foley: Creating Continuous Sound for Video-to-Audio Generation\n  Under Semantic Guidance","authorsParsed":[["Zhang","Yaoyun",""],["Xu","Xuenan",""],["Wu","Mengyue",""]],"timestamp":1735014586000,"metadataBlobId":"ASyD3iF3Zhqmng5Sz7byfgHCOzifW0jodzieyp-kT0E"},{"id":"2412.18191","title":"Explaining Speaker and Spoof Embeddings via Probing","authorsParsed":[["Liu","Xuechen",""],["Yamagishi","Junichi",""],["Sahidullah","Md",""],["kinnunen","Tomi",""]],"timestamp":1735019809000,"metadataBlobId":"5w5NQMtRgn7hTmYYqPsc_iGKLUWkzirUHdzRhxbqBBE"},{"id":"2412.18836","title":"MRI2Speech: Speech Synthesis from Articulatory Movements Recorded by\n  Real-time MRI","authorsParsed":[["Shah","Neil",""],["Kashyap","Ayan",""],["Karande","Shirish",""],["Gandhi","Vineet",""]],"timestamp":1735116583000,"metadataBlobId":"vRs9HYjn5xgtta0IRlMVy41JpqEn5Ro2sx_w8WmuunQ"},{"id":"2412.18710","title":"Simi-SFX: A similarity-based conditioning method for controllable sound\n  effect synthesis","authorsParsed":[["Liu","Yunyi",""],["Jin","Craig",""]],"timestamp":1735085690000,"metadataBlobId":"wrxSygLg2xqOy4Bku1lM5vdLtY7XrfregQWLMwn5FA4"},{"id":"2412.18839","title":"Advancing NAM-to-Speech Conversion with Novel Methods and the MultiNAM\n  Dataset","authorsParsed":[["Shah","Neil",""],["Karande","Shirish",""],["Gandhi","Vineet",""]],"timestamp":1735117044000,"metadataBlobId":"9wCY3-NzH2wAiPK1lKKD2SHq_eakS8NraieMS6RuM_g"},{"id":"2412.18955","title":"Leave-One-EquiVariant: Alleviating invariance-related information loss\n  in contrastive music representations","authorsParsed":[["Guinot","Julien",""],["Quinton","Elio",""],["Fazekas","György",""]],"timestamp":1735150004000,"metadataBlobId":"xwuxjvnTLrUUlnfWmD6QWxgzt-BFdOnRA_WPE--R5ho"},{"id":"2412.19123","title":"CoheDancers: Enhancing Interactive Group Dance Generation through\n  Music-Driven Coherence Decomposition","authorsParsed":[["Yang","Kaixing",""],["Tang","Xulong",""],["Wu","Haoyu",""],["Xue","Qinliang",""],["Qin","Biao",""],["Liu","Hongyan",""],["Fan","Zhaoxin",""]],"timestamp":1735202833000,"metadataBlobId":"F29lsjf9yu0duWFjrq48DxQXYnOr9YWepSczPVvYb0U"},{"id":"2412.19200","title":"Personalized Dynamic Music Emotion Recognition with Dual-Scale\n  Attention-Based Meta-Learning","authorsParsed":[["Zhang","Dengming",""],["You","Weitao",""],["Liu","Ziheng",""],["Sun","Lingyun",""],["Chen","Pei",""]],"timestamp":1735217255000,"metadataBlobId":"39jB_dER5ZM5nRuaGHchfTeShU6CSQKfdTiwkP00DjA"},{"id":"2412.19351","title":"ETTA: Elucidating the Design Space of Text-to-Audio Models","authorsParsed":[["Lee","Sang-gil",""],["Kong","Zhifeng",""],["Goel","Arushi",""],["Kim","Sungwon",""],["Valle","Rafael",""],["Catanzaro","Bryan",""]],"timestamp":1735247592000,"metadataBlobId":"O3G0PxUeWETHpvKNu9uRydxBloggK9kiWswiiEPuP0s"},{"id":"2412.19909","title":"Mouth Articulation-Based Anchoring for Improved Cross-Corpus Speech\n  Emotion Recognition","authorsParsed":[["Upadhyay","Shreya G.",""],["Salman","Ali N.",""],["Busso","Carlos",""],["Lee","Chi-Chun",""]],"timestamp":1735329645000,"metadataBlobId":"sN1wxD3yIDMyBnUSHm5Zp8srsDJ8OHPiM_oGbF3Nz-I"},{"id":"2412.20155","title":"Stable-TTS: Stable Speaker-Adaptive Text-to-Speech Synthesis via Prosody\n  Prompting","authorsParsed":[["Han","Wooseok",""],["Kang","Minki",""],["Kim","Changhun",""],["Yang","Eunho",""]],"timestamp":1735394070000,"metadataBlobId":"PD9Y2LySS1eM8KP_hs6NKAXYckatVqIt_oYaMQAzu9Q"},{"id":"2412.21037","title":"TangoFlux: Super Fast and Faithful Text to Audio Generation with Flow\n  Matching and Clap-Ranked Preference Optimization","authorsParsed":[["Hung","Chia-Yu",""],["Majumder","Navonil",""],["Kong","Zhifeng",""],["Mehrish","Ambuj",""],["Valle","Rafael",""],["Catanzaro","Bryan",""],["Poria","Soujanya",""]],"timestamp":1735574564000,"metadataBlobId":"wsSBCYxZsjTxnHCnwUGkmD90yi_pnzat1nivQI4I6jY"}]