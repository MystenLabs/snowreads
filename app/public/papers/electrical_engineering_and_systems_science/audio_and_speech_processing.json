[{"id":"2407.15423","title":"Integrating IP Broadcasting with Audio Tags: Workflow and Challenges","authorsParsed":[["Burchett-Vass","Rhys",""],["Singh","Arshdeep",""],["Bibbó","Gabriel",""],["Plumbley","Mark D.",""]],"timestamp":1721631621000,"metadataBlobId":"hk0Pn_wN7dqemRVRSr9OL4C4o3yqDx_-tYrS7W_98nU"},{"id":"2407.15641","title":"Generating Sample-Based Musical Instruments Using Neural Audio Codec\n  Language Models","authorsParsed":[["Nercessian","Shahan",""],["Imort","Johannes",""],["Devis","Ninon",""],["Blang","Frederik",""]],"timestamp":1721656798000,"metadataBlobId":"NFiFuq9ApTii1WDjcXb179BnEqFCSuL5Vvmhqrpo9u8"},{"id":"2407.00291","title":"FMSG-JLESS Submission for DCASE 2024 Task4 on Sound Event Detection with\n  Heterogeneous Training Dataset and Potentially Missing Labels","authorsParsed":[["Xiao","Yang",""],["Yin","Han",""],["Bai","Jisheng",""],["Das","Rohan Kumar",""]],"timestamp":1719630660000,"metadataBlobId":"bk0kGvKb_PCCVGkybFJ8lpG4mAsP9hcDzeXeO0Gjfmg"},{"id":"2407.11365","title":"Team HYU ASML ROBOVOX SP Cup 2024 System Description","authorsParsed":[["Choi","Jeong-Hwan",""],["Kim","Gaeun",""],["Lee","Hee-Jae",""],["Ahn","Seyun",""],["Kim","Hyun-Soo",""],["Chang","Joon-Hyuk",""]],"timestamp":1721102750000,"metadataBlobId":"V7uEAPRYKnL6hw-RkdsZwnF1R-Soy22lscEQIxCnlDo"},{"id":"2407.02749","title":"VAE-based Phoneme Alignment Using Gradient Annealing and SSL Acoustic\n  Features","authorsParsed":[["Koriyama","Tomoki",""]],"timestamp":1719971484000,"metadataBlobId":"2wQuN35U_1HX1MuyYSfAc0f7jPIFZdTdJ5NGNC1Paoo"},{"id":"2407.03656","title":"WildDESED: An LLM-Powered Dataset for Wild Domestic Environment Sound\n  Event Detection System","authorsParsed":[["Xiao","Yang",""],["Das","Rohan Kumar",""]],"timestamp":1720072459000,"metadataBlobId":"1IKSLqMgr7IJjs16sfoChHRQpbh7XBf5Kdxp9qdwjxA"},{"id":"2407.13840","title":"Semi-Supervised Contrastive Learning of Musical Representations","authorsParsed":[["Guinot","Julien",""],["Quinton","Elio",""],["Fazekas","György",""]],"timestamp":1721326900000,"metadataBlobId":"kUE0Owj2VbydjE3etfCxPmMhuvTL9PW5wApfG3sDp2E"},{"id":"2407.05744","title":"Automating Urban Soundscape Enhancements with AI: In-situ Assessment of\n  Quality and Restorativeness in Traffic-Exposed Residential Areas","authorsParsed":[["Lam","Bhan",""],["Ong","Zhen-Ting",""],["Ooi","Kenneth",""],["Ong","Wen-Hui",""],["Wong","Trevor",""],["Watcharasupat","Karn N.",""],["Boey","Vanessa",""],["Lee","Irene",""],["Hong","Joo Young",""],["Kang","Jian",""],["Lee","Kar Fye Alvin",""],["Christopoulos","Georgios",""],["Gan","Woon-Seng",""]],"timestamp":1720428523000,"metadataBlobId":"YH3ukoHA4WQib0PT0pUgAeRLfNYJUBGdsXXb3L2_vaU"},{"id":"2407.21211","title":"Self-Supervised Models in Automatic Whispered Speech Recognition","authorsParsed":[["Farhadipour","Aref",""],["Asadi","Homa",""],["Dellwo","Volker",""]],"timestamp":1722375937000,"metadataBlobId":"rMoP-c20YOJGGkccJimtceVjh7gEPkcyq6dE1md2Jp8"},{"id":"2407.20935","title":"$T\\bar{a}laGen:$ A System for Automatic $T\\bar{a}la$ Identification and\n  Generation","authorsParsed":[["Kodag","Rahul Bapusaheb",""],["Jindal","Himanshu",""],["Arora","Vipul",""]],"timestamp":1722356150000,"metadataBlobId":"w27HeMzbKxMEDoOMZTnu5h5QaPyU8pLPIWztexEqWTY"},{"id":"2407.17416","title":"Explaining Spectrograms in Machine Learning: A Study on Neural Networks\n  for Speech Classification","authorsParsed":[["James","Jesin",""],["T.","Balamurali B.",""],["Abeysinghe","Binu",""],["Liu","Junchen",""]],"timestamp":1720597038000,"metadataBlobId":"tsvUcCVR07ybGMTPzIgowMfAn95wFVi6PifAOZFNHUM"},{"id":"2407.04439","title":"XLSR-Transducer: Streaming ASR for Self-Supervised Pretrained Models","authorsParsed":[["Kumar","Shashi",""],["Madikeri","Srikanth",""],["Zuluaga-Gomez","Juan",""],["Villatoro-Tello","Esaú",""],["Nigmatulina","Iuliia",""],["Motlicek","Petr",""],["E","Manjunath K",""],["Ganapathiraju","Aravind",""]],"timestamp":1720179671000,"metadataBlobId":"Jw822KWAiix8hOpfdhvVStz2ZCwiqRYuo-CbIxt227U"},{"id":"2407.13220","title":"MEDIC: Zero-shot Music Editing with Disentangled Inversion Control","authorsParsed":[["Liu","Huadai",""],["Wang","Jialei",""],["Huang","Rongjie",""],["Liu","Yang",""],["Xu","Jiayang",""],["Zhao","Zhou",""]],"timestamp":1721286343000,"metadataBlobId":"hqXBu_kdcF2h3oQ4iiKX9gwWqDdq0CxosX916fuU4rQ"},{"id":"2407.04518","title":"From Audio Encoders to Piano Judges: Benchmarking Performance\n  Understanding for Solo Piano","authorsParsed":[["Zhang","Huan",""],["Liang","Jinhua",""],["Dixon","Simon",""]],"timestamp":1720188087000,"metadataBlobId":"jXazNEICyyBA3u1EZJQIAB_TjN9R2Bd5KpVAWPq6UCg"},{"id":"2407.01927","title":"TTSlow: Slow Down Text-to-Speech with Efficiency Robustness Evaluations","authorsParsed":[["Gao","Xiaoxue",""],["Chen","Yiming",""],["Yue","Xianghu",""],["Tsao","Yu",""],["Chen","Nancy F.",""]],"timestamp":1719891836000,"metadataBlobId":"T55s3d7QWDmYJgYVGdGECJM3VE2uu-vpj3EANnqQJXw"},{"id":"2407.08889","title":"Diff-MST: Differentiable Mixing Style Transfer","authorsParsed":[["Vanka","Soumya Sai",""],["Steinmetz","Christian",""],["Rolland","Jean-Baptiste",""],["Reiss","Joshua",""],["Fazekas","George",""]],"timestamp":1720739207000,"metadataBlobId":"myOrymjoqz2R3Ifn7jc_yuG6OXkWblwVJ2kx0Qm72MM"},{"id":"2407.18083","title":"Detection of manatee vocalisations using the Audio Spectrogram\n  Transformer","authorsParsed":[["Schiappacasse","Stefano",""],["de Wolff","Taco",""],["Henaut","Yann",""],["Cervera","Regina",""],["Charles","Aviva",""],["Tobar","Felipe",""]],"timestamp":1721918810000,"metadataBlobId":"P5aiseG6uxsr_VE9-ky8jrmdN4Cf8WG6eReVFo_ljf4"},{"id":"2407.18516","title":"Integrating Posture Control in Speech Motor Models: A\n  Parallel-Structured Simulation Approach","authorsParsed":[["Liu","Yadong",""],["Fels","Sidney",""],["Shamei","Arian",""],["Khan","Najeeb",""],["Gick","Bryan",""]],"timestamp":1721970751000,"metadataBlobId":"rotXbt2lWb13qN_eZBNefs8TwbLRm-Ya_ICSKAqf3Do"},{"id":"2407.17119","title":"Automatic Detection and Annotation of Sperm Whale Codas","authorsParsed":[["Gubnitsky","Guy",""],["Mevorach","Yaly",""],["Gero","Shane",""],["Gruber","David F.",""],["Diamant","Roee",""]],"timestamp":1721813343000,"metadataBlobId":"CppBtELhQx2tNG4KWqjtoIpUX3MHQNlWfWf0WlqezTI"},{"id":"2407.08752","title":"From Modular to End-to-End Speaker Diarization","authorsParsed":[["Landini","Federico",""]],"timestamp":1719500979000,"metadataBlobId":"110vaqbjBOCuiUbZPErMtMD7tHd-lp9nDK8kDeG9KYQ"},{"id":"2407.06342","title":"XANE Background Acoustic Embeddings: Ablation and Clustering Analysis","authorsParsed":[["Sharma","Dushyant",""],["Fosburgh","James",""],["Dumpala","Sri Harsha",""],["Sastri","Chandramouli Shama",""],["Kruchinin","Stanislav Yu.",""],["Naylor","Patrick A.",""]],"timestamp":1720466627000,"metadataBlobId":"W_UsW39SRJiZnVZEku_Hdpgu0jE3v5VDQy0qqmhYz7Q"},{"id":"2407.12467","title":"BSC-UPC at EmoSPeech-IberLEF2024: Attention Pooling for Emotion\n  Recognition","authorsParsed":[["Casals-Salvador","Marc",""],["Costa","Federico",""],["India","Miquel",""],["Hernando","Javier",""]],"timestamp":1721212648000,"metadataBlobId":"gjZblffHKbEWNnr5FFvQER--c42GG9WKZJ7H9aK417M"},{"id":"2407.12038","title":"ICAGC 2024: Inspirational and Convincing Audio Generation Challenge 2024","authorsParsed":[["Fu","Ruibo",""],["Liu","Rui",""],["Qiang","Chunyu",""],["Gao","Yingming",""],["Lu","Yi",""],["Shi","Shuchen",""],["Wang","Tao",""],["Li","Ya",""],["Wen","Zhengqi",""],["Zhang","Chen",""],["Bu","Hui",""],["Liu","Yukun",""],["Qi","Xin",""],["Li","Guanjun",""]],"timestamp":1719839716000,"metadataBlobId":"zvT3II2QFyzfnwu_lZNMVBlKi23WsxmUN44haMSxulI"},{"id":"2407.03563","title":"Learning Video Temporal Dynamics with Cross-Modal Attention for Robust\n  Audio-Visual Speech Recognition","authorsParsed":[["Kim","Sungnyun",""],["Jang","Kangwook",""],["Bae","Sangmin",""],["Kim","Hoirin",""],["Yun","Se-Young",""]],"timestamp":1720056320000,"metadataBlobId":"_ls7n3Z7mf9ipoJ3EAe0SQ1xqio2nV4eJwJwa3GwnFA"},{"id":"2407.01779","title":"peerRTF: Robust MVDR Beamforming Using Graph Convolutional Network","authorsParsed":[["Levi","Daniel",""],["Sofer","Amit",""],["Gannot","Sharon",""]],"timestamp":1719864824000,"metadataBlobId":"A92BJOx5XvSDfLd8P-1pkG5D_swNOfhSaa3GSo9yevU"},{"id":"2407.04270","title":"Who Finds This Voice Attractive? A Large-Scale Experiment Using\n  In-the-Wild Data","authorsParsed":[["Suda","Hitoshi",""],["Watanabe","Aya",""],["Takamichi","Shinnosuke",""]],"timestamp":1720158718000,"metadataBlobId":"rmtJkXQRAF77Zh65zycxizOC9KuDfKX3nhDfNmRD9TQ"},{"id":"2407.10759","title":"Qwen2-Audio Technical Report","authorsParsed":[["Chu","Yunfei",""],["Xu","Jin",""],["Yang","Qian",""],["Wei","Haojie",""],["Wei","Xipin",""],["Guo","Zhifang",""],["Leng","Yichong",""],["Lv","Yuanjun",""],["He","Jinzheng",""],["Lin","Junyang",""],["Zhou","Chang",""],["Zhou","Jingren",""]],"timestamp":1721054289000,"metadataBlobId":"BshJTXmqWfPjZJZuphDixH6reY_mg9ypCcwVJek3RVM"},{"id":"2407.07275","title":"Remastering Divide and Remaster: A Cinematic Audio Source Separation\n  Dataset with Multilingual Support","authorsParsed":[["Watcharasupat","Karn N.",""],["Wu","Chih-Wei",""],["Orife","Iroro",""]],"timestamp":1720568377000,"metadataBlobId":"9CkJk2UFUsZ-VhujH8688LKGtl7mEmebI-N9yRLC2LM"},{"id":"2407.04291","title":"We Need Variations in Speech Synthesis: Sub-center Modelling for Speaker\n  Embeddings","authorsParsed":[["Ulgen","Ismail Rasim",""],["Busso","Carlos",""],["Hansen","John H. L.",""],["Sisman","Berrak",""]],"timestamp":1720162464000,"metadataBlobId":"tamlVvyxKqtbPv8NSkbu9568Vnz0DZpPdzyNIo82K5U"},{"id":"2407.01963","title":"Towards Unsupervised Speaker Diarization System for Multilingual\n  Telephone Calls Using Pre-trained Whisper Model and Mixture of Sparse\n  Autoencoders","authorsParsed":[["Lam","Phat",""],["Pham","Lam",""],["Nguyen","Truong",""],["Ngo","Dat",""],["Pham","Thinh",""],["Nguyen","Tin",""],["Nguyen","Loi Khanh",""],["Schindler","Alexander",""]],"timestamp":1719898952000,"metadataBlobId":"4CNK4dF-W2qA5QzwEX-jTIgFOZgEY9P_6KER2uvKb-k"},{"id":"2407.10108","title":"Advancing Continual Learning for Robust Deepfake Audio Classification","authorsParsed":[["Dong","Feiyi",""],["Tang","Qingchen",""],["Bai","Yichen",""],["Wang","Zihan",""]],"timestamp":1720942344000,"metadataBlobId":"w3f6-HJxoSDRcwFhSgPLElEs27UIIo8znTQdLFefBTA"},{"id":"2407.08017","title":"Phonetic Richness for Improved Automatic Speaker Verification","authorsParsed":[["Klein","Nicholas",""],["Sivaraman","Ganesh",""],["Khoury","Elie",""]],"timestamp":1720641101000,"metadataBlobId":"oRlZZ1kWMgicZmm5f8aNeMCsnm7nvHSocewfgFV8fyw"},{"id":"2407.04034","title":"Optimizing a-DCF for Spoofing-Robust Speaker Verification","authorsParsed":[["Kurnaz","Oğuzhan",""],["Mishra","Jagabandhu",""],["Kinnunen","Tomi H.",""],["Hanilçi","Cemal",""]],"timestamp":1720110001000,"metadataBlobId":"IrpksPAM4hU-WQwUsSN8Pmb_s3uEmSrRh0TUBWZCbLQ"},{"id":"2407.10054","title":"The feasibility of sound zone control using an array of parametric array\n  loudspeakers","authorsParsed":[["Zhuang","Tao",""],["Zhong","Jia-Xin",""],["Lu","Jing",""]],"timestamp":1720925390000,"metadataBlobId":"HWjDMx2BwMjgisYCaAFptg9MvqfUCnu0LK3hTIbTbHs"},{"id":"2407.12743","title":"TalTech-IRIT-LIS Speaker and Language Diarization Systems for DISPLACE\n  2024","authorsParsed":[["Kalda","Joonas",""],["Alumäe","Tanel",""],["Lebourdais","Martin",""],["Bredin","Hervé",""],["Baroudi","Séverin",""],["Marxer","Ricard",""]],"timestamp":1721235741000,"metadataBlobId":"JDBFkUd1zlJHyTIw4Zj9V7ftujSiqru_Sh9C5L9QQII"},{"id":"2407.05471","title":"Fine-Grained and Interpretable Neural Speech Editing","authorsParsed":[["Morrison","Max",""],["Churchwell","Cameron",""],["Pruyne","Nathan",""],["Pardo","Bryan",""]],"timestamp":1720379152000,"metadataBlobId":"Sr_j9_-_FXW2Uw1e68zT40kWJYNO7utRU6o_D0PFN9k"},{"id":"2407.03648","title":"High Fidelity Text-Guided Music Generation and Editing via Single-Stage\n  Flow Matching","authorsParsed":[["Lan","Gael Le",""],["Shi","Bowen",""],["Ni","Zhaoheng",""],["Srinivasan","Sidd",""],["Kumar","Anurag",""],["Ellis","Brian",""],["Kant","David",""],["Nagaraja","Varun",""],["Chang","Ernie",""],["Hsu","Wei-Ning",""],["Shi","Yangyang",""],["Chandra","Vikas",""]],"timestamp":1720071529000,"metadataBlobId":"OcVbgy31zKllBGz3YVy2o8sYoRXkCXzSRnPnsuplrTM"},{"id":"2407.16691","title":"Automatic Equalization for Individual Instrument Tracks Using\n  Convolutional Neural Networks","authorsParsed":[["Mockenhaupt","Florian",""],["Rieber","Joscha Simon",""],["Nercessian","Shahan",""]],"timestamp":1721757325000,"metadataBlobId":"eB3nX6C5SbZ0J6ABN7wNpHMmrQiYtM9FlqlXKreVPGs"},{"id":"2407.21414","title":"Towards interfacing large language models with ASR systems using\n  confidence measures and prompting","authorsParsed":[["Naderi","Maryam",""],["Hermann","Enno",""],["Nanchen","Alexandre",""],["Hovsepyan","Sevada",""],["-Doss","Mathew Magimai.",""]],"timestamp":1722412841000,"metadataBlobId":"RmgyIV6W3qUgQ9U1C8rIM1cfk0k5QESAJyCtbOjcnfY"},{"id":"2407.03654","title":"Mixstyle based Domain Generalization for Sound Event Detection with\n  Heterogeneous Training Data","authorsParsed":[["Xiao","Yang",""],["Yin","Han",""],["Bai","Jisheng",""],["Das","Rohan Kumar",""]],"timestamp":1720072240000,"metadataBlobId":"LJLINWDMrzccF0AO9YGAyF95yrdpeZmTy5eCu2YQvrE"},{"id":"2407.07801","title":"AVCap: Leveraging Audio-Visual Features as Text Tokens for Captioning","authorsParsed":[["Kim","Jongsuk",""],["Shin","Jiwon",""],["Kim","Junmo",""]],"timestamp":1720628269000,"metadataBlobId":"jjJEtmmBidqHR1qvnA9v3PXlgsPp5RfXkvqhLoh3xBI"},{"id":"2407.19989","title":"Blind Acoustic Parameter Estimation Through Task-Agnostic Embeddings\n  Using Latent Approximations","authorsParsed":[["Götz","Philipp",""],["Tuna","Cagdas",""],["Brendel","Andreas",""],["Walther","Andreas",""],["Habets","Emanuël A. P.",""]],"timestamp":1722259332000,"metadataBlobId":"xIevPjWb7jERow2J-tLCcBeI6JEUtLEMJYPG2tC7m28"},{"id":"2407.04675","title":"Seed-ASR: Understanding Diverse Speech and Contexts with LLM-based\n  Speech Recognition","authorsParsed":[["Bai","Ye",""],["Chen","Jingping",""],["Chen","Jitong",""],["Chen","Wei",""],["Chen","Zhuo",""],["Ding","Chuang",""],["Dong","Linhao",""],["Dong","Qianqian",""],["Du","Yujiao",""],["Gao","Kepan",""],["Gao","Lu",""],["Guo","Yi",""],["Han","Minglun",""],["Han","Ting",""],["Hu","Wenchao",""],["Hu","Xinying",""],["Hu","Yuxiang",""],["Hua","Deyu",""],["Huang","Lu",""],["Huang","Mingkun",""],["Huang","Youjia",""],["Jin","Jishuo",""],["Kong","Fanliu",""],["Lan","Zongwei",""],["Li","Tianyu",""],["Li","Xiaoyang",""],["Li","Zeyang",""],["Lin","Zehua",""],["Liu","Rui",""],["Liu","Shouda",""],["Lu","Lu",""],["Lu","Yizhou",""],["Ma","Jingting",""],["Ma","Shengtao",""],["Pei","Yulin",""],["Shen","Chen",""],["Tan","Tian",""],["Tian","Xiaogang",""],["Tu","Ming",""],["Wang","Bo",""],["Wang","Hao",""],["Wang","Yuping",""],["Wang","Yuxuan",""],["Xia","Hanzhang",""],["Xia","Rui",""],["Xie","Shuangyi",""],["Xu","Hongmin",""],["Yang","Meng",""],["Zhang","Bihong",""],["Zhang","Jun",""],["Zhang","Wanyi",""],["Zhang","Yang",""],["Zhang","Yawei",""],["Zheng","Yijie",""],["Zou","Ming",""]],"timestamp":1720201083000,"metadataBlobId":"vc-OdF-pq3gS72TNrAzNy3dH6sspDoE6dyHfe5-oulE"},{"id":"2407.18927","title":"ASGIR: Audio Spectrogram Transformer Guided Classification And\n  Information Retrieval For Birds","authorsParsed":[["Chaudhuri","Yashwardhan",""],["Mundra","Paridhi",""],["Batra","Arnesh",""],["Phukan","Orchid Chetia",""],["Buduru","Arun Balaji",""]],"timestamp":1720585939000,"metadataBlobId":"9M_UKJ4v8vuNyTeTNZ7qkM7m0otD6LGWNkj1FEkdMHM"},{"id":"2407.09732","title":"Speech Slytherin: Examining the Performance and Efficiency of Mamba for\n  Speech Separation, Recognition, and Synthesis","authorsParsed":[["Jiang","Xilin",""],["Li","Yinghao Aaron",""],["Florea","Adrian Nicolas",""],["Han","Cong",""],["Mesgarani","Nima",""]],"timestamp":1720830921000,"metadataBlobId":"9FrHKdt3WgnX7gK8ba-6WuEiZFgfcUhEG7rAF5ZgaXI"},{"id":"2407.17430","title":"A Comprehensive Review and Taxonomy of Audio-Visual Synchronization\n  Techniques for Realistic Speech Animation","authorsParsed":[["Fernandes","Jose Geraldo",""],["Nascimento","Sinval",""],["Dominguete","Daniel",""],["Oliveira","André",""],["Rotsen","Lucas",""],["Souza","Gabriel",""],["Brochero","David",""],["Facury","Luiz",""],["Vilela","Mateus",""],["Costa","Hebert",""],["Coelho","Frederico",""],["Braga","Antônio P.",""]],"timestamp":1721840746000,"metadataBlobId":"irECd_X0058llnhzjvn2xUDH8PJK3idFTdVN6DUaK6s"},{"id":"2407.10303","title":"Improving Neural Biasing for Contextual Speech Recognition by Early\n  Context Injection and Text Perturbation","authorsParsed":[["Huang","Ruizhe",""],["Yarmohammadi","Mahsa",""],["Khudanpur","Sanjeev",""],["Povey","Daniel",""]],"timestamp":1720985553000,"metadataBlobId":"AVjRM82_VGgLXd7TJ5BzJcmHQHvOXy8fdawtakj8jdk"},{"id":"2407.02049","title":"Accompanied Singing Voice Synthesis with Fully Text-controlled Melody","authorsParsed":[["Li","Ruiqi",""],["Hong","Zhiqing",""],["Wang","Yongqi",""],["Zhang","Lichao",""],["Huang","Rongjie",""],["Zheng","Siqi",""],["Zhao","Zhou",""]],"timestamp":1719908618000,"metadataBlobId":"OTas-OSAtAPBteUXMmu4mFD1vcjhylKUjQ363THfSMI"},{"id":"2407.11828","title":"Vibravox: A Dataset of French Speech Captured with Body-conduction Audio\n  Sensors","authorsParsed":[["Hauret","Julien",""],["Olivier","Malo",""],["Joubaud","Thomas",""],["Langrenne","Christophe",""],["Poirée","Sarah",""],["Zimpfer","Véronique",""],["Bavu","Éric",""]],"timestamp":1721142970000,"metadataBlobId":"Bu0tQajP6kyNqPWXxCTqSXewAPlqEjXHDGOwLPZ3SuY"},{"id":"2407.16643","title":"Synthesizer Sound Matching Using Audio Spectrogram Transformers","authorsParsed":[["Bruford","Fred",""],["Blang","Frederik",""],["Nercessian","Shahan",""]],"timestamp":1721753894000,"metadataBlobId":"pwGV9FrCJgaKfko5EKiNZgHJMk2JiBQKV8VSzjPz7Hk"},{"id":"2407.05421","title":"ASRRL-TTS: Agile Speaker Representation Reinforcement Learning for\n  Text-to-Speech Speaker Adaptation","authorsParsed":[["Fu","Ruibo",""],["Qi","Xin",""],["Wen","Zhengqi",""],["Tao","Jianhua",""],["Wang","Tao",""],["Qiang","Chunyu",""],["Wang","Zhiyong",""],["Lu","Yi",""],["Wang","Xiaopeng",""],["Shi","Shuchen",""],["Liu","Yukun",""],["Liu","Xuefei",""],["Zhang","Shuai",""]],"timestamp":1720367891000,"metadataBlobId":"7KcOc4FnZHzkTmMuJZg7r_x-Q1FsF5va-DQAd8IhID0"},{"id":"2407.13242","title":"Fade-in Reverberation in Multi-room Environments Using the Common-Slope\n  Model","authorsParsed":[["Lee","Kyung Yun",""],["Meyer-Kahlen","Nils",""],["Götz","Georg",""],["Svensson","U. Peter",""],["Schlecht","Sebastian J.",""],["Välimäki","Vesa",""]],"timestamp":1721289071000,"metadataBlobId":"qk6qbEg9hkWKfPySrLEKpdZfRJfvI2emaoomketmMfY"},{"id":"2407.03661","title":"Configurable DOA Estimation using Incremental Learning","authorsParsed":[["Xiao","Yang",""],["Das","Rohan Kumar",""]],"timestamp":1720072972000,"metadataBlobId":"68aV9cTO68IE5DFoPrqiPzWWxIpGuhBQCggzeGQUbW4"},{"id":"2407.14006","title":"MSceneSpeech: A Multi-Scene Speech Dataset For Expressive Speech\n  Synthesis","authorsParsed":[["Yang","Qian",""],["Zuo","Jialong",""],["Su","Zhe",""],["Jiang","Ziyue",""],["Li","Mingze",""],["Zhao","Zhou",""],["Chen","Feiyang",""],["Wang","Zhefeng",""],["Huai","Baoxing",""]],"timestamp":1721360208000,"metadataBlobId":"EL8AV0si2dFRlrdG_jCQ51ppD26H_iN0tJkDjexhAGg"},{"id":"2407.15458","title":"EMO-Codec: An In-Depth Look at Emotion Preservation capacity of Legacy\n  and Neural Codec Models With Subjective and Objective Evaluations","authorsParsed":[["Ren","Wenze",""],["Lin","Yi-Cheng",""],["Chou","Huang-Cheng",""],["Wu","Haibin",""],["Wu","Yi-Chiao",""],["Lee","Chi-Chun",""],["Lee","Hung-yi",""],["Tsao","Yu",""]],"timestamp":1721636056000,"metadataBlobId":"WXYNmQNOQxIGSIodJFz8G2E-SSIihd__-Fk836Oqxfc"},{"id":"2407.05361","title":"Emilia: An Extensive, Multilingual, and Diverse Speech Dataset for\n  Large-Scale Speech Generation","authorsParsed":[["He","Haorui",""],["Shang","Zengqiang",""],["Wang","Chaoren",""],["Li","Xuyuan",""],["Gu","Yicheng",""],["Hua","Hua",""],["Liu","Liwei",""],["Yang","Chen",""],["Li","Jiaqi",""],["Shi","Peiyang",""],["Wang","Yuancheng",""],["Chen","Kai",""],["Zhang","Pengyuan",""],["Wu","Zhizheng",""]],"timestamp":1720358694000,"metadataBlobId":"HGAcKktRR90aW3RVEwAic9A6lSelNLgvKbwMSfH5ez4"},{"id":"2407.19834","title":"Frequency & Channel Attention Network for Small Footprint Noisy Spoken\n  Keyword Spotting","authorsParsed":[["Lin","Yuanxi",""],["Gapanyuk","Yuriy Evgenyevich",""]],"timestamp":1722246328000,"metadataBlobId":"fNPl72v6ucikhYFfsnXyNlf_I2FOuauOL_YL-CtW_po"},{"id":"2407.21030","title":"Cluster and Separate: a GNN Approach to Voice and Staff Prediction for\n  Score Engraving","authorsParsed":[["Foscarin","Francesco",""],["Karystinaios","Emmanouil",""],["Nakamura","Eita",""],["Widmer","Gerhard",""]],"timestamp":1721054173000,"metadataBlobId":"AaOwOdQKNvzB_WLtkS8x6Z_HX_DvcP5Umz3vIWVPQkY"},{"id":"2407.16074","title":"Schr\\\"odinger Bridge for Generative Speech Enhancement","authorsParsed":[["Jukić","Ante",""],["Korostik","Roman",""],["Balam","Jagadeesh",""],["Ginsburg","Boris",""]],"timestamp":1721686640000,"metadataBlobId":"s5t4EfPx2HkZnyOlghemAR8HcMFyONCU60vkLxiDsys"},{"id":"2407.03657","title":"UCIL: An Unsupervised Class Incremental Learning Approach for Sound\n  Event Detection","authorsParsed":[["Xiao","Yang",""],["Das","Rohan Kumar",""]],"timestamp":1720072650000,"metadataBlobId":"UWmK3Oi9qnewAprjC5BRdB6hHqUp9iOTHUDBp_vHbNw"},{"id":"2407.19485","title":"ctPuLSE: Close-Talk, and Pseudo-Label Based Far-Field, Speech\n  Enhancement","authorsParsed":[["Wang","Zhong-Qiu",""]],"timestamp":1722170485000,"metadataBlobId":"htL1gW9wrMUSn9FGgSrQzwsUh9X6O92PpBrPooeCy9E"},{"id":"2407.18926","title":"VoxMed: One-Step Respiratory Disease Classifier using Digital\n  Stethoscope Sounds","authorsParsed":[["Mundra","Paridhi",""],["Sharma","Manik",""],["Chaudhuri","Yashwardhan",""],["Phukan","Orchid Chetia",""],["Buduru","Arun Balaji",""]],"timestamp":1720585582000,"metadataBlobId":"kCcAU_oPyZtmF6Za3oBoZOzg_yQqc-cmU09wgosLU2U"},{"id":"2407.10603","title":"Leave No Knowledge Behind During Knowledge Distillation: Towards\n  Practical and Effective Knowledge Distillation for Code-Switching ASR Using\n  Realistic Data","authorsParsed":[["Tseng","Liang-Hsuan",""],["Chen","Zih-Ching",""],["Chang","Wei-Shun",""],["Lee","Cheng-Kuang",""],["Huang","Tsung-Ren",""],["Lee","Hung-yi",""]],"timestamp":1721039114000,"metadataBlobId":"o4c5IRRirvwXToYvTmtBKGfBgpsUq9IbzhRe0XbPvbU"},{"id":"2407.08016","title":"Source Tracing of Audio Deepfake Systems","authorsParsed":[["Klein","Nicholas",""],["Chen","Tianxiang",""],["Tak","Hemlata",""],["Casal","Ricardo",""],["Khoury","Elie",""]],"timestamp":1720640950000,"metadataBlobId":"8kiWH2-KQcHsRkbaX8fJxp_QfvW8HboP0zTFPeYYih4"},{"id":"2407.06957","title":"Listen and Speak Fairly: A Study on Semantic Gender Bias in Speech\n  Integrated Large Language Models","authorsParsed":[["Lin","Yi-Cheng",""],["Lin","Tzu-Quan",""],["Yang","Chih-Kai",""],["Lu","Ke-Han",""],["Chen","Wei-Chih",""],["Kuan","Chun-Yi",""],["Lee","Hung-yi",""]],"timestamp":1720539343000,"metadataBlobId":"BdeNtfRXM5fMLEiK9nW7HANMoq3e-FFLiaY0_CQR4gw"},{"id":"2407.05516","title":"Differentiable Modal Synthesis for Physical Modeling of Planar String\n  Sound and Motion Simulation","authorsParsed":[["Lee","Jin Woo",""],["Park","Jaehyun",""],["Choi","Min Jun",""],["Lee","Kyogu",""]],"timestamp":1720395411000,"metadataBlobId":"Xgq47Oeqf6EkdDmSkOjSodraXwb776ald_M3Uw5FEZ0"},{"id":"2407.11516","title":"The VoicePrivacy 2022 Challenge: Progress and Perspectives in Voice\n  Anonymisation","authorsParsed":[["Panariello","Michele",""],["Tomashenko","Natalia",""],["Wang","Xin",""],["Miao","Xiaoxiao",""],["Champion","Pierre",""],["Nourtel","Hubert",""],["Todisco","Massimiliano",""],["Evans","Nicholas",""],["Vincent","Emmanuel",""],["Yamagishi","Junichi",""]],"timestamp":1721119897000,"metadataBlobId":"7cedUGFclVXWRxnecmyqdvfCAfpxEEInSIrbGP8DR04"},{"id":"2407.01857","title":"SpeakerBeam-SS: Real-time Target Speaker Extraction with Lightweight\n  Conv-TasNet and State Space Modeling","authorsParsed":[["Sato","Hiroshi",""],["Moriya","Takafumi",""],["Mimura","Masato",""],["Horiguchi","Shota",""],["Ochiai","Tsubasa",""],["Ashihara","Takanori",""],["Ando","Atsushi",""],["Shinayama","Kentaro",""],["Delcroix","Marc",""]],"timestamp":1719878356000,"metadataBlobId":"e46xR8HBxBxX6Vtdi_TYfgOR7xIdxpMEnATarpmua04"},{"id":"2407.01774","title":"Audio-Visual Approach For Multimodal Concurrent Speaker Detection","authorsParsed":[["Eliav","Amit",""],["Gannot","Sharon",""]],"timestamp":1719864417000,"metadataBlobId":"i6x0sn2DeH-u5n2miUZOp5kKd3h8M87f8__bxxrQE5M"},{"id":"2407.09021","title":"Squeeze-and-Excite ResNet-Conformers for Sound Event Localization,\n  Detection, and Distance Estimation for DCASE 2024 Challenge","authorsParsed":[["Yeow","Jun Wei",""],["Tan","Ee-Leng",""],["Bai","Jisheng",""],["Peksi","Santi",""],["Gan","Woon-Seng",""]],"timestamp":1720765401000,"metadataBlobId":"s03SHD5CM9f4_FqNUKrkdtH1QBlKxw4GHvHOAhu0DSc"},{"id":"2407.17902","title":"Multi-Stage Face-Voice Association Learning with Keynote Speaker\n  Diarization","authorsParsed":[["Tao","Ruijie",""],["Shi","Zhan",""],["Jiang","Yidi",""],["Truong","Duc-Tuan",""],["Chng","Eng-Siong",""],["Alioto","Massimo",""],["Li","Haizhou",""]],"timestamp":1721900764000,"metadataBlobId":"OHJz5zU4SVWSyg5Iewq_p5AhpawRAl5kfkQ-M-WdUy0"},{"id":"2407.12380","title":"PCQ: Emotion Recognition in Speech via Progressive Channel Querying","authorsParsed":[["Wang","Xincheng",""],["Wang","Liejun",""],["Yu","Yinfeng",""],["Jiao","Xinxin",""]],"timestamp":1721203096000,"metadataBlobId":"gUcgno5BdDxCoOHPAjXLKC5IPk0MkcWeiwTAtljIkJM"},{"id":"2407.14172","title":"Topology-Independent GEVD-Based Distributed Adaptive Node-Specific\n  Signal Estimation in Ad-Hoc Wireless Acoustic Sensor Networks","authorsParsed":[["Didier","Paul",""],["van Waterschoot","Toon",""],["Moonen","Marc",""]],"timestamp":1721383259000,"metadataBlobId":"oRJZRNAhZhX_bjuU548IhYcmYx3t05SjdnLG0Gc0XWM"}]