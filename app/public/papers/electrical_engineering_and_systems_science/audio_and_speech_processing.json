[{"id":"2407.15423","title":"Integrating IP Broadcasting with Audio Tags: Workflow and Challenges","authorsParsed":[["Burchett-Vass","Rhys",""],["Singh","Arshdeep",""],["Bibbó","Gabriel",""],["Plumbley","Mark D.",""]],"timestamp":1721631621000,"metadataBlobId":"lpTqLeyx4Q5nCQtwryekGSZVQNMp7rCIdGhfEaHI7Zk"},{"id":"2407.15641","title":"Generating Sample-Based Musical Instruments Using Neural Audio Codec\n  Language Models","authorsParsed":[["Nercessian","Shahan",""],["Imort","Johannes",""],["Devis","Ninon",""],["Blang","Frederik",""]],"timestamp":1721656798000,"metadataBlobId":"csqSmSNBQWG1OijygQapOd2spZ3C-Oq18_7W0AiuMqA"},{"id":"2407.00291","title":"FMSG-JLESS Submission for DCASE 2024 Task4 on Sound Event Detection with\n  Heterogeneous Training Dataset and Potentially Missing Labels","authorsParsed":[["Xiao","Yang",""],["Yin","Han",""],["Bai","Jisheng",""],["Das","Rohan Kumar",""]],"timestamp":1719630660000,"metadataBlobId":"tEMf3PoAh6jNcnQz1ek8ZxfjZO9p46ix8S6VjDt0mkU"},{"id":"2407.11365","title":"Team HYU ASML ROBOVOX SP Cup 2024 System Description","authorsParsed":[["Choi","Jeong-Hwan",""],["Kim","Gaeun",""],["Lee","Hee-Jae",""],["Ahn","Seyun",""],["Kim","Hyun-Soo",""],["Chang","Joon-Hyuk",""]],"timestamp":1721102750000,"metadataBlobId":"J1FwQoIjtE08ZH--zzBAfwf2AKlv0IUAZlDapnTXZnI"},{"id":"2407.02749","title":"VAE-based Phoneme Alignment Using Gradient Annealing and SSL Acoustic\n  Features","authorsParsed":[["Koriyama","Tomoki",""]],"timestamp":1719971484000,"metadataBlobId":"MPj9d2RqYtb8w2kGOosG7NNnKvhu0zFy8AQ8MkEzf0Q"},{"id":"2407.03656","title":"WildDESED: An LLM-Powered Dataset for Wild Domestic Environment Sound\n  Event Detection System","authorsParsed":[["Xiao","Yang",""],["Das","Rohan Kumar",""]],"timestamp":1720072459000,"metadataBlobId":"a7_045i6lnNFqRrt9uUJVK0TVUBfX1reIK_m5QLh1Hk"},{"id":"2407.13840","title":"Semi-Supervised Contrastive Learning of Musical Representations","authorsParsed":[["Guinot","Julien",""],["Quinton","Elio",""],["Fazekas","György",""]],"timestamp":1721326900000,"metadataBlobId":"aJ75Keu-Qy_V78XC63hYKGY4MDyhI9O0Rc8rLoBz9b4"},{"id":"2407.05744","title":"Automating Urban Soundscape Enhancements with AI: In-situ Assessment of\n  Quality and Restorativeness in Traffic-Exposed Residential Areas","authorsParsed":[["Lam","Bhan",""],["Ong","Zhen-Ting",""],["Ooi","Kenneth",""],["Ong","Wen-Hui",""],["Wong","Trevor",""],["Watcharasupat","Karn N.",""],["Boey","Vanessa",""],["Lee","Irene",""],["Hong","Joo Young",""],["Kang","Jian",""],["Lee","Kar Fye Alvin",""],["Christopoulos","Georgios",""],["Gan","Woon-Seng",""]],"timestamp":1720428523000,"metadataBlobId":"InRYwxkUkZhzDIIOw1NFxF4NutmVqSDY_vMp-9dSTBE"},{"id":"2407.21211","title":"Self-Supervised Models in Automatic Whispered Speech Recognition","authorsParsed":[["Farhadipour","Aref",""],["Asadi","Homa",""],["Dellwo","Volker",""]],"timestamp":1722375937000,"metadataBlobId":"dS2ACUGG0jL0D9LT9I5nZntlojOs_azGwfvDNQ9b8aQ"},{"id":"2407.20935","title":"$T\\bar{a}laGen:$ A System for Automatic $T\\bar{a}la$ Identification and\n  Generation","authorsParsed":[["Kodag","Rahul Bapusaheb",""],["Jindal","Himanshu",""],["Arora","Vipul",""]],"timestamp":1722356150000,"metadataBlobId":"kGelL4OdRbCiBTWDhTAMbRIpjIiXMa2vI6hqTlQ-8xA"},{"id":"2407.17416","title":"Explaining Spectrograms in Machine Learning: A Study on Neural Networks\n  for Speech Classification","authorsParsed":[["James","Jesin",""],["T.","Balamurali B.",""],["Abeysinghe","Binu",""],["Liu","Junchen",""]],"timestamp":1720597038000,"metadataBlobId":"pTCaQ-P5RqUmqp8DbhCw8MvX0iewuJaTMmWLsJuqPrA"},{"id":"2407.04439","title":"XLSR-Transducer: Streaming ASR for Self-Supervised Pretrained Models","authorsParsed":[["Kumar","Shashi",""],["Madikeri","Srikanth",""],["Zuluaga-Gomez","Juan",""],["Villatoro-Tello","Esaú",""],["Nigmatulina","Iuliia",""],["Motlicek","Petr",""],["E","Manjunath K",""],["Ganapathiraju","Aravind",""]],"timestamp":1720179671000,"metadataBlobId":"JYvlRXXDPaYLLlw3408BHYug2VjWmAT3eYTybVkqi_Y"},{"id":"2407.13220","title":"MEDIC: Zero-shot Music Editing with Disentangled Inversion Control","authorsParsed":[["Liu","Huadai",""],["Wang","Jialei",""],["Huang","Rongjie",""],["Liu","Yang",""],["Xu","Jiayang",""],["Zhao","Zhou",""]],"timestamp":1721286343000,"metadataBlobId":"gkIPh2VttH3ZjmAWvkPtu3PO2XnLdk_egzZG58UvSeE"},{"id":"2407.04518","title":"From Audio Encoders to Piano Judges: Benchmarking Performance\n  Understanding for Solo Piano","authorsParsed":[["Zhang","Huan",""],["Liang","Jinhua",""],["Dixon","Simon",""]],"timestamp":1720188087000,"metadataBlobId":"B2r7QF3WdvKdrCE__7u1C7vf3zqND9cmS_oSSPCcI-w"},{"id":"2407.01927","title":"TTSlow: Slow Down Text-to-Speech with Efficiency Robustness Evaluations","authorsParsed":[["Gao","Xiaoxue",""],["Chen","Yiming",""],["Yue","Xianghu",""],["Tsao","Yu",""],["Chen","Nancy F.",""]],"timestamp":1719891836000,"metadataBlobId":"5ivOKQGTS3o3b7Hkj0Kwf4Ij4cSeMQOlOfmB-vcgBu0"},{"id":"2407.08889","title":"Diff-MST: Differentiable Mixing Style Transfer","authorsParsed":[["Vanka","Soumya Sai",""],["Steinmetz","Christian",""],["Rolland","Jean-Baptiste",""],["Reiss","Joshua",""],["Fazekas","George",""]],"timestamp":1720739207000,"metadataBlobId":"PZ7iPpH76pe85KmcqHmDfViKyDXU3QPU_X-DjfzNxi0"},{"id":"2407.18083","title":"Detection of manatee vocalisations using the Audio Spectrogram\n  Transformer","authorsParsed":[["Schiappacasse","Stefano",""],["de Wolff","Taco",""],["Henaut","Yann",""],["Cervera","Regina",""],["Charles","Aviva",""],["Tobar","Felipe",""]],"timestamp":1721918810000,"metadataBlobId":"IvoDtNtcaWaN98Dzrz1mwumkkyC8Blsy7ayOkWrzW_Y"},{"id":"2407.18516","title":"Integrating Posture Control in Speech Motor Models: A\n  Parallel-Structured Simulation Approach","authorsParsed":[["Liu","Yadong",""],["Fels","Sidney",""],["Shamei","Arian",""],["Khan","Najeeb",""],["Gick","Bryan",""]],"timestamp":1721970751000,"metadataBlobId":"Hl4h_7kKhn9R0XSIPi24urrMh25f1xmDhgV7kIYTAWk"},{"id":"2407.17119","title":"Automatic Detection and Annotation of Sperm Whale Codas","authorsParsed":[["Gubnitsky","Guy",""],["Mevorach","Yaly",""],["Gero","Shane",""],["Gruber","David F.",""],["Diamant","Roee",""]],"timestamp":1721813343000,"metadataBlobId":"SJi253jENvW4vLWrK28Lrc4Ckfj-w8yiJKnigZW9d5k"},{"id":"2407.08752","title":"From Modular to End-to-End Speaker Diarization","authorsParsed":[["Landini","Federico",""]],"timestamp":1719500979000,"metadataBlobId":"YZnRg62cS14uTIChuX-dusQM4ZzqVYVdUXHKvRCBk7Y"},{"id":"2407.06342","title":"XANE Background Acoustic Embeddings: Ablation and Clustering Analysis","authorsParsed":[["Sharma","Dushyant",""],["Fosburgh","James",""],["Dumpala","Sri Harsha",""],["Sastri","Chandramouli Shama",""],["Kruchinin","Stanislav Yu.",""],["Naylor","Patrick A.",""]],"timestamp":1720466627000,"metadataBlobId":"S764amATLE1ny7l3rPnuG-58tD5JtypjTWV6dOk_s4I"},{"id":"2407.12467","title":"BSC-UPC at EmoSPeech-IberLEF2024: Attention Pooling for Emotion\n  Recognition","authorsParsed":[["Casals-Salvador","Marc",""],["Costa","Federico",""],["India","Miquel",""],["Hernando","Javier",""]],"timestamp":1721212648000,"metadataBlobId":"hKzloGcpa0QYRqiyq1ZK72wjhRem7O175InMduZQJmU"},{"id":"2407.12038","title":"ICAGC 2024: Inspirational and Convincing Audio Generation Challenge 2024","authorsParsed":[["Fu","Ruibo",""],["Liu","Rui",""],["Qiang","Chunyu",""],["Gao","Yingming",""],["Lu","Yi",""],["Shi","Shuchen",""],["Wang","Tao",""],["Li","Ya",""],["Wen","Zhengqi",""],["Zhang","Chen",""],["Bu","Hui",""],["Liu","Yukun",""],["Qi","Xin",""],["Li","Guanjun",""]],"timestamp":1719839716000,"metadataBlobId":"zaLezxKtsdKITwfAKg-x91pBiCMvY39IciVbT3YBzxo"},{"id":"2407.03563","title":"Learning Video Temporal Dynamics with Cross-Modal Attention for Robust\n  Audio-Visual Speech Recognition","authorsParsed":[["Kim","Sungnyun",""],["Jang","Kangwook",""],["Bae","Sangmin",""],["Kim","Hoirin",""],["Yun","Se-Young",""]],"timestamp":1720056320000,"metadataBlobId":"n8PPPOgjWdCWpUnRRRulvFZBBwgms5mOCRMWmsJg7pw"},{"id":"2407.01779","title":"peerRTF: Robust MVDR Beamforming Using Graph Convolutional Network","authorsParsed":[["Levi","Daniel",""],["Sofer","Amit",""],["Gannot","Sharon",""]],"timestamp":1719864824000,"metadataBlobId":"IZ3_sWSg2_EHjAqiQZx6583DUGoaogBBR2WEucb076U"},{"id":"2407.04270","title":"Who Finds This Voice Attractive? A Large-Scale Experiment Using\n  In-the-Wild Data","authorsParsed":[["Suda","Hitoshi",""],["Watanabe","Aya",""],["Takamichi","Shinnosuke",""]],"timestamp":1720158718000,"metadataBlobId":"pNjOMPxX4ieafUaL_KkXjpphMIzkma0uD3uUlQj-J6U"},{"id":"2407.10759","title":"Qwen2-Audio Technical Report","authorsParsed":[["Chu","Yunfei",""],["Xu","Jin",""],["Yang","Qian",""],["Wei","Haojie",""],["Wei","Xipin",""],["Guo","Zhifang",""],["Leng","Yichong",""],["Lv","Yuanjun",""],["He","Jinzheng",""],["Lin","Junyang",""],["Zhou","Chang",""],["Zhou","Jingren",""]],"timestamp":1721054289000,"metadataBlobId":"qF2NMImA3J1c0kSXkYK2rMO8UUV8lnA63fGr-vLUmD4"},{"id":"2407.07275","title":"Remastering Divide and Remaster: A Cinematic Audio Source Separation\n  Dataset with Multilingual Support","authorsParsed":[["Watcharasupat","Karn N.",""],["Wu","Chih-Wei",""],["Orife","Iroro",""]],"timestamp":1720568377000,"metadataBlobId":"TGuVBqVgqrK1RFYOMaXYcFav_ob_IOds9LgFrIYkXJ0"},{"id":"2407.04291","title":"We Need Variations in Speech Synthesis: Sub-center Modelling for Speaker\n  Embeddings","authorsParsed":[["Ulgen","Ismail Rasim",""],["Busso","Carlos",""],["Hansen","John H. L.",""],["Sisman","Berrak",""]],"timestamp":1720162464000,"metadataBlobId":"OFtx8UBr2bGTu318_7A_QiNLsibNhSl-mD8HnCWbug0"},{"id":"2407.01963","title":"Towards Unsupervised Speaker Diarization System for Multilingual\n  Telephone Calls Using Pre-trained Whisper Model and Mixture of Sparse\n  Autoencoders","authorsParsed":[["Lam","Phat",""],["Pham","Lam",""],["Nguyen","Truong",""],["Ngo","Dat",""],["Pham","Thinh",""],["Nguyen","Tin",""],["Nguyen","Loi Khanh",""],["Schindler","Alexander",""]],"timestamp":1719898952000,"metadataBlobId":"OI3zBqfT7rwZ9Ft1Fimhj7KLPtuo7kfw4vFwm6vn6P0"},{"id":"2407.10108","title":"Advancing Continual Learning for Robust Deepfake Audio Classification","authorsParsed":[["Dong","Feiyi",""],["Tang","Qingchen",""],["Bai","Yichen",""],["Wang","Zihan",""]],"timestamp":1720942344000,"metadataBlobId":"AKgcWhul2tsDg0tgJl6sdb4C87T7rDmmm10kkCZPexg"},{"id":"2407.08017","title":"Phonetic Richness for Improved Automatic Speaker Verification","authorsParsed":[["Klein","Nicholas",""],["Sivaraman","Ganesh",""],["Khoury","Elie",""]],"timestamp":1720641101000,"metadataBlobId":"HhfXEAM0hzgQc167pCAAvjb8G90qzDQXpJVvnDr-0lw"},{"id":"2407.04034","title":"Optimizing a-DCF for Spoofing-Robust Speaker Verification","authorsParsed":[["Kurnaz","Oğuzhan",""],["Mishra","Jagabandhu",""],["Kinnunen","Tomi H.",""],["Hanilçi","Cemal",""]],"timestamp":1720110001000,"metadataBlobId":"1klIScSE83PZaYR2tEIZ2jTi5SUAp-1LHotNWwEwqxQ"},{"id":"2407.10054","title":"The feasibility of sound zone control using an array of parametric array\n  loudspeakers","authorsParsed":[["Zhuang","Tao",""],["Zhong","Jia-Xin",""],["Lu","Jing",""]],"timestamp":1720925390000,"metadataBlobId":"GhiEkstpOfN9Cey_Oj-1BLAbNirjEHEfdBlPBBlg_t4"},{"id":"2407.12743","title":"TalTech-IRIT-LIS Speaker and Language Diarization Systems for DISPLACE\n  2024","authorsParsed":[["Kalda","Joonas",""],["Alumäe","Tanel",""],["Lebourdais","Martin",""],["Bredin","Hervé",""],["Baroudi","Séverin",""],["Marxer","Ricard",""]],"timestamp":1721235741000,"metadataBlobId":"KQTzv--a4_tbRA_sWo41fXzC8xzBuLtzUkHorG0fSRo"},{"id":"2407.05471","title":"Fine-Grained and Interpretable Neural Speech Editing","authorsParsed":[["Morrison","Max",""],["Churchwell","Cameron",""],["Pruyne","Nathan",""],["Pardo","Bryan",""]],"timestamp":1720379152000,"metadataBlobId":"iEB23hIXhuwSX_3gdcQ1ODmuZNABhgyzVxG2jAYz6PI"},{"id":"2407.03648","title":"High Fidelity Text-Guided Music Generation and Editing via Single-Stage\n  Flow Matching","authorsParsed":[["Lan","Gael Le",""],["Shi","Bowen",""],["Ni","Zhaoheng",""],["Srinivasan","Sidd",""],["Kumar","Anurag",""],["Ellis","Brian",""],["Kant","David",""],["Nagaraja","Varun",""],["Chang","Ernie",""],["Hsu","Wei-Ning",""],["Shi","Yangyang",""],["Chandra","Vikas",""]],"timestamp":1720071529000,"metadataBlobId":"uP3bakjsr-s6JAcSSm0ZFUwfUOxN69QZ1l3vGbsGeUg"},{"id":"2407.16691","title":"Automatic Equalization for Individual Instrument Tracks Using\n  Convolutional Neural Networks","authorsParsed":[["Mockenhaupt","Florian",""],["Rieber","Joscha Simon",""],["Nercessian","Shahan",""]],"timestamp":1721757325000,"metadataBlobId":"OBX9eRyUoSDObT7ycP_hAyxF-dGe__7tktqW8ol41JQ"},{"id":"2407.21414","title":"Towards interfacing large language models with ASR systems using\n  confidence measures and prompting","authorsParsed":[["Naderi","Maryam",""],["Hermann","Enno",""],["Nanchen","Alexandre",""],["Hovsepyan","Sevada",""],["-Doss","Mathew Magimai.",""]],"timestamp":1722412841000,"metadataBlobId":"DFKSRe05sglwDYhYEcU51l8dLp5kuYlTff13ggtAAaE"},{"id":"2407.03654","title":"Mixstyle based Domain Generalization for Sound Event Detection with\n  Heterogeneous Training Data","authorsParsed":[["Xiao","Yang",""],["Yin","Han",""],["Bai","Jisheng",""],["Das","Rohan Kumar",""]],"timestamp":1720072240000,"metadataBlobId":"27yghhtH0ZVRqXHghNLJIYx_TAjwppYFwQ-o0IxtkAU"},{"id":"2407.07801","title":"AVCap: Leveraging Audio-Visual Features as Text Tokens for Captioning","authorsParsed":[["Kim","Jongsuk",""],["Shin","Jiwon",""],["Kim","Junmo",""]],"timestamp":1720628269000,"metadataBlobId":"gToNMMoMtJZxJ6hqB_OPItyJeF34HrFQvIIhtAmGCrM"},{"id":"2407.19989","title":"Blind Acoustic Parameter Estimation Through Task-Agnostic Embeddings\n  Using Latent Approximations","authorsParsed":[["Götz","Philipp",""],["Tuna","Cagdas",""],["Brendel","Andreas",""],["Walther","Andreas",""],["Habets","Emanuël A. P.",""]],"timestamp":1722259332000,"metadataBlobId":"bz6iytXyDIQfJCJAvtZG5QYrWH4SUUCysHrMNJ82Kyk"},{"id":"2407.04675","title":"Seed-ASR: Understanding Diverse Speech and Contexts with LLM-based\n  Speech Recognition","authorsParsed":[["Bai","Ye",""],["Chen","Jingping",""],["Chen","Jitong",""],["Chen","Wei",""],["Chen","Zhuo",""],["Ding","Chuang",""],["Dong","Linhao",""],["Dong","Qianqian",""],["Du","Yujiao",""],["Gao","Kepan",""],["Gao","Lu",""],["Guo","Yi",""],["Han","Minglun",""],["Han","Ting",""],["Hu","Wenchao",""],["Hu","Xinying",""],["Hu","Yuxiang",""],["Hua","Deyu",""],["Huang","Lu",""],["Huang","Mingkun",""],["Huang","Youjia",""],["Jin","Jishuo",""],["Kong","Fanliu",""],["Lan","Zongwei",""],["Li","Tianyu",""],["Li","Xiaoyang",""],["Li","Zeyang",""],["Lin","Zehua",""],["Liu","Rui",""],["Liu","Shouda",""],["Lu","Lu",""],["Lu","Yizhou",""],["Ma","Jingting",""],["Ma","Shengtao",""],["Pei","Yulin",""],["Shen","Chen",""],["Tan","Tian",""],["Tian","Xiaogang",""],["Tu","Ming",""],["Wang","Bo",""],["Wang","Hao",""],["Wang","Yuping",""],["Wang","Yuxuan",""],["Xia","Hanzhang",""],["Xia","Rui",""],["Xie","Shuangyi",""],["Xu","Hongmin",""],["Yang","Meng",""],["Zhang","Bihong",""],["Zhang","Jun",""],["Zhang","Wanyi",""],["Zhang","Yang",""],["Zhang","Yawei",""],["Zheng","Yijie",""],["Zou","Ming",""]],"timestamp":1720201083000,"metadataBlobId":"k9FhziEuu4KwICj7nY3pIr7owdH4lgF0hrtIa0ixN8A"},{"id":"2407.18927","title":"ASGIR: Audio Spectrogram Transformer Guided Classification And\n  Information Retrieval For Birds","authorsParsed":[["Chaudhuri","Yashwardhan",""],["Mundra","Paridhi",""],["Batra","Arnesh",""],["Phukan","Orchid Chetia",""],["Buduru","Arun Balaji",""]],"timestamp":1720585939000,"metadataBlobId":"uu9l3569_Sga8jbDCTK77CB7z00k9fI8aAqWcRp-Z2o"},{"id":"2407.09732","title":"Speech Slytherin: Examining the Performance and Efficiency of Mamba for\n  Speech Separation, Recognition, and Synthesis","authorsParsed":[["Jiang","Xilin",""],["Li","Yinghao Aaron",""],["Florea","Adrian Nicolas",""],["Han","Cong",""],["Mesgarani","Nima",""]],"timestamp":1720830921000,"metadataBlobId":"9h4ukvYjW372R_MLrXvA8cIfCEoBmXI3lYLADdrez6A"},{"id":"2407.17430","title":"A Comprehensive Review and Taxonomy of Audio-Visual Synchronization\n  Techniques for Realistic Speech Animation","authorsParsed":[["Fernandes","Jose Geraldo",""],["Nascimento","Sinval",""],["Dominguete","Daniel",""],["Oliveira","André",""],["Rotsen","Lucas",""],["Souza","Gabriel",""],["Brochero","David",""],["Facury","Luiz",""],["Vilela","Mateus",""],["Costa","Hebert",""],["Coelho","Frederico",""],["Braga","Antônio P.",""]],"timestamp":1721840746000,"metadataBlobId":"n1st32O-j4U3HxoMmBuMy9gzr9EwQA-cz2hTMNedjik"},{"id":"2407.10303","title":"Improving Neural Biasing for Contextual Speech Recognition by Early\n  Context Injection and Text Perturbation","authorsParsed":[["Huang","Ruizhe",""],["Yarmohammadi","Mahsa",""],["Khudanpur","Sanjeev",""],["Povey","Daniel",""]],"timestamp":1720985553000,"metadataBlobId":"5SrcSu0MHnzA1NgVqlhrHihAD_d7jmQzA-I52F6OpUU"},{"id":"2407.02049","title":"Accompanied Singing Voice Synthesis with Fully Text-controlled Melody","authorsParsed":[["Li","Ruiqi",""],["Hong","Zhiqing",""],["Wang","Yongqi",""],["Zhang","Lichao",""],["Huang","Rongjie",""],["Zheng","Siqi",""],["Zhao","Zhou",""]],"timestamp":1719908618000,"metadataBlobId":"x07DU72rD8tWlE6OKyv6gnBK9VIj8avop4_ZTK0Iao4"},{"id":"2407.11828","title":"Vibravox: A Dataset of French Speech Captured with Body-conduction Audio\n  Sensors","authorsParsed":[["Hauret","Julien",""],["Olivier","Malo",""],["Joubaud","Thomas",""],["Langrenne","Christophe",""],["Poirée","Sarah",""],["Zimpfer","Véronique",""],["Bavu","Éric",""]],"timestamp":1721142970000,"metadataBlobId":"h8omulJOP-njKbtRpghuMivsjaEfeG2WNZ1-8swpD3Y"},{"id":"2407.16643","title":"Synthesizer Sound Matching Using Audio Spectrogram Transformers","authorsParsed":[["Bruford","Fred",""],["Blang","Frederik",""],["Nercessian","Shahan",""]],"timestamp":1721753894000,"metadataBlobId":"P2qzpHRldp3__OWLjo6WkIp4xM8tnB7k8PB5pOmbtUk"},{"id":"2407.05421","title":"ASRRL-TTS: Agile Speaker Representation Reinforcement Learning for\n  Text-to-Speech Speaker Adaptation","authorsParsed":[["Fu","Ruibo",""],["Qi","Xin",""],["Wen","Zhengqi",""],["Tao","Jianhua",""],["Wang","Tao",""],["Qiang","Chunyu",""],["Wang","Zhiyong",""],["Lu","Yi",""],["Wang","Xiaopeng",""],["Shi","Shuchen",""],["Liu","Yukun",""],["Liu","Xuefei",""],["Zhang","Shuai",""]],"timestamp":1720367891000,"metadataBlobId":"jXiKP16z3me6O5erES5mbo7-7k4vPzNWrnAbLiGO6xk"},{"id":"2407.13242","title":"Fade-in Reverberation in Multi-room Environments Using the Common-Slope\n  Model","authorsParsed":[["Lee","Kyung Yun",""],["Meyer-Kahlen","Nils",""],["Götz","Georg",""],["Svensson","U. Peter",""],["Schlecht","Sebastian J.",""],["Välimäki","Vesa",""]],"timestamp":1721289071000,"metadataBlobId":"prAVhxvthSfbwH0Id5Yf37bmOvYQpMY3RSDB99KqMR0"},{"id":"2407.03661","title":"Configurable DOA Estimation using Incremental Learning","authorsParsed":[["Xiao","Yang",""],["Das","Rohan Kumar",""]],"timestamp":1720072972000,"metadataBlobId":"fZWqctH80yAHZL_0c7Vb4zrfvGJa_2b4w1n5rqc_tow"},{"id":"2407.14006","title":"MSceneSpeech: A Multi-Scene Speech Dataset For Expressive Speech\n  Synthesis","authorsParsed":[["Yang","Qian",""],["Zuo","Jialong",""],["Su","Zhe",""],["Jiang","Ziyue",""],["Li","Mingze",""],["Zhao","Zhou",""],["Chen","Feiyang",""],["Wang","Zhefeng",""],["Huai","Baoxing",""]],"timestamp":1721360208000,"metadataBlobId":"muxEu1YGvEKBF4q1K1IazlTyX5ywXNQfrgsZ2Uq_M1s"},{"id":"2407.15458","title":"EMO-Codec: An In-Depth Look at Emotion Preservation capacity of Legacy\n  and Neural Codec Models With Subjective and Objective Evaluations","authorsParsed":[["Ren","Wenze",""],["Lin","Yi-Cheng",""],["Chou","Huang-Cheng",""],["Wu","Haibin",""],["Wu","Yi-Chiao",""],["Lee","Chi-Chun",""],["Lee","Hung-yi",""],["Tsao","Yu",""]],"timestamp":1721636056000,"metadataBlobId":"-vHvB0SZRQ7F_ITXFrRDANWOvF8pwzDPzb6TyWBa3oM"},{"id":"2407.05361","title":"Emilia: An Extensive, Multilingual, and Diverse Speech Dataset for\n  Large-Scale Speech Generation","authorsParsed":[["He","Haorui",""],["Shang","Zengqiang",""],["Wang","Chaoren",""],["Li","Xuyuan",""],["Gu","Yicheng",""],["Hua","Hua",""],["Liu","Liwei",""],["Yang","Chen",""],["Li","Jiaqi",""],["Shi","Peiyang",""],["Wang","Yuancheng",""],["Chen","Kai",""],["Zhang","Pengyuan",""],["Wu","Zhizheng",""]],"timestamp":1720358694000,"metadataBlobId":"AnElVyk0onowKeIvgyw16kjfqCiwLk8EyP-sYFfe9Os"},{"id":"2407.19834","title":"Frequency & Channel Attention Network for Small Footprint Noisy Spoken\n  Keyword Spotting","authorsParsed":[["Lin","Yuanxi",""],["Gapanyuk","Yuriy Evgenyevich",""]],"timestamp":1722246328000,"metadataBlobId":"Ul4C3SRItfg8PJVBrxhdvL985Ze-aqipIi8rIoFxdik"},{"id":"2407.21030","title":"Cluster and Separate: a GNN Approach to Voice and Staff Prediction for\n  Score Engraving","authorsParsed":[["Foscarin","Francesco",""],["Karystinaios","Emmanouil",""],["Nakamura","Eita",""],["Widmer","Gerhard",""]],"timestamp":1721054173000,"metadataBlobId":"MRZrqB6xgWW3fQHU08pvte_YHcTn9LRs2HOmzoVVzBw"},{"id":"2407.16074","title":"Schr\\\"odinger Bridge for Generative Speech Enhancement","authorsParsed":[["Jukić","Ante",""],["Korostik","Roman",""],["Balam","Jagadeesh",""],["Ginsburg","Boris",""]],"timestamp":1721686640000,"metadataBlobId":"fckaVMklF7eA6m2ky9hVvIIZkifiw8UYmShHKwZEyWU"},{"id":"2407.03657","title":"UCIL: An Unsupervised Class Incremental Learning Approach for Sound\n  Event Detection","authorsParsed":[["Xiao","Yang",""],["Das","Rohan Kumar",""]],"timestamp":1720072650000,"metadataBlobId":"aJ4Zo2rwtfRg6DnM2jR3-0ZD0SQvWAZlTlBa4dPLJuk"},{"id":"2407.19485","title":"ctPuLSE: Close-Talk, and Pseudo-Label Based Far-Field, Speech\n  Enhancement","authorsParsed":[["Wang","Zhong-Qiu",""]],"timestamp":1722170485000,"metadataBlobId":"u3ETFId5_xpBYcn2GEF9YC6MzfrhGT2I2WbSINnV6fI"},{"id":"2407.18926","title":"VoxMed: One-Step Respiratory Disease Classifier using Digital\n  Stethoscope Sounds","authorsParsed":[["Mundra","Paridhi",""],["Sharma","Manik",""],["Chaudhuri","Yashwardhan",""],["Phukan","Orchid Chetia",""],["Buduru","Arun Balaji",""]],"timestamp":1720585582000,"metadataBlobId":"Wm-ZXW6LSzpL6dzkO8BqLe3klPvgckE4uTymkk975Aw"},{"id":"2407.10603","title":"Leave No Knowledge Behind During Knowledge Distillation: Towards\n  Practical and Effective Knowledge Distillation for Code-Switching ASR Using\n  Realistic Data","authorsParsed":[["Tseng","Liang-Hsuan",""],["Chen","Zih-Ching",""],["Chang","Wei-Shun",""],["Lee","Cheng-Kuang",""],["Huang","Tsung-Ren",""],["Lee","Hung-yi",""]],"timestamp":1721039114000,"metadataBlobId":"Qa2rWnbae_RuuyjueDWofYDd3ebIMjosSK7C4GvEYxc"},{"id":"2407.08016","title":"Source Tracing of Audio Deepfake Systems","authorsParsed":[["Klein","Nicholas",""],["Chen","Tianxiang",""],["Tak","Hemlata",""],["Casal","Ricardo",""],["Khoury","Elie",""]],"timestamp":1720640950000,"metadataBlobId":"_jiaFTtbunTlxWhTW8S_YuGPhMTCzhdBvRfPn4vMnmk"},{"id":"2407.06957","title":"Listen and Speak Fairly: A Study on Semantic Gender Bias in Speech\n  Integrated Large Language Models","authorsParsed":[["Lin","Yi-Cheng",""],["Lin","Tzu-Quan",""],["Yang","Chih-Kai",""],["Lu","Ke-Han",""],["Chen","Wei-Chih",""],["Kuan","Chun-Yi",""],["Lee","Hung-yi",""]],"timestamp":1720539343000,"metadataBlobId":"8wdrwrfDVHRMs6LHivUruZwoYRGEi2sSU3Ry3hgx6I4"},{"id":"2407.05516","title":"Differentiable Modal Synthesis for Physical Modeling of Planar String\n  Sound and Motion Simulation","authorsParsed":[["Lee","Jin Woo",""],["Park","Jaehyun",""],["Choi","Min Jun",""],["Lee","Kyogu",""]],"timestamp":1720395411000,"metadataBlobId":"ZCJY9WlP59jfyiYTIWmneKQTeAfbOeZzeNx2DYinUM4"},{"id":"2407.11516","title":"The VoicePrivacy 2022 Challenge: Progress and Perspectives in Voice\n  Anonymisation","authorsParsed":[["Panariello","Michele",""],["Tomashenko","Natalia",""],["Wang","Xin",""],["Miao","Xiaoxiao",""],["Champion","Pierre",""],["Nourtel","Hubert",""],["Todisco","Massimiliano",""],["Evans","Nicholas",""],["Vincent","Emmanuel",""],["Yamagishi","Junichi",""]],"timestamp":1721119897000,"metadataBlobId":"e2BcId_1k2gMSYRwKrI-72JDNqgYSueH5tfbpHUIl7I"},{"id":"2407.01857","title":"SpeakerBeam-SS: Real-time Target Speaker Extraction with Lightweight\n  Conv-TasNet and State Space Modeling","authorsParsed":[["Sato","Hiroshi",""],["Moriya","Takafumi",""],["Mimura","Masato",""],["Horiguchi","Shota",""],["Ochiai","Tsubasa",""],["Ashihara","Takanori",""],["Ando","Atsushi",""],["Shinayama","Kentaro",""],["Delcroix","Marc",""]],"timestamp":1719878356000,"metadataBlobId":"h-tqDmQ4ABJC4yLbd--bOpMy3zqjd3HA6bbY-FF5L_Q"},{"id":"2407.01774","title":"Audio-Visual Approach For Multimodal Concurrent Speaker Detection","authorsParsed":[["Eliav","Amit",""],["Gannot","Sharon",""]],"timestamp":1719864417000,"metadataBlobId":"g18IaMktRkkF1nEpbti5RGxVUTHl8SoiTNTM7Qqvkbk"},{"id":"2407.09021","title":"Squeeze-and-Excite ResNet-Conformers for Sound Event Localization,\n  Detection, and Distance Estimation for DCASE 2024 Challenge","authorsParsed":[["Yeow","Jun Wei",""],["Tan","Ee-Leng",""],["Bai","Jisheng",""],["Peksi","Santi",""],["Gan","Woon-Seng",""]],"timestamp":1720765401000,"metadataBlobId":"aO71bUSfRMBIgrNCgqlZpjx7cIZAcQme4bmGhkPqrLA"},{"id":"2407.17902","title":"Multi-Stage Face-Voice Association Learning with Keynote Speaker\n  Diarization","authorsParsed":[["Tao","Ruijie",""],["Shi","Zhan",""],["Jiang","Yidi",""],["Truong","Duc-Tuan",""],["Chng","Eng-Siong",""],["Alioto","Massimo",""],["Li","Haizhou",""]],"timestamp":1721900764000,"metadataBlobId":"DF67tz5xJXLdu4OsgDzg2foIqoAzi0Cf7bU12hlE99g"},{"id":"2407.12380","title":"PCQ: Emotion Recognition in Speech via Progressive Channel Querying","authorsParsed":[["Wang","Xincheng",""],["Wang","Liejun",""],["Yu","Yinfeng",""],["Jiao","Xinxin",""]],"timestamp":1721203096000,"metadataBlobId":"GQpCFaB6HTNhnPUB0d2G0hd1MvgE8S89_oZLspj9wng"},{"id":"2407.14172","title":"Topology-Independent GEVD-Based Distributed Adaptive Node-Specific\n  Signal Estimation in Ad-Hoc Wireless Acoustic Sensor Networks","authorsParsed":[["Didier","Paul",""],["van Waterschoot","Toon",""],["Moonen","Marc",""]],"timestamp":1721383259000,"metadataBlobId":"dQkKwZQ5nHxDpUkC329z-b-f6TNeUpZwGq9lgvFgmOE"}]